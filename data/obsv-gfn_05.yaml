- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Monitoring with Metrics Using Grafana Mimir and Prometheus
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Grafana Mimir 和 Prometheus 进行指标监控
- en: This chapter will introduce the **Prometheus query language** (**PromQL**).
    Like LogQL, PromQL can be used to select and filter metrics streams and process
    numeric data with operators and functions, enabling you to build quick and efficient
    queries that will support establishing an observable system. We will also explore
    and compare the various protocols that can be used to output metrics from systems.
    Finally, we will explore the architecture of **Prometheus** and **Mimir** to understand
    how Mimir fills the need for a highly scalable system.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍 **Prometheus 查询语言**（**PromQL**）。与 LogQL 类似，PromQL 可以用来选择和筛选指标流，并使用运算符和函数处理数值数据，使您能够构建快速高效的查询，从而支持建立可观察系统。我们还将探索并比较用于输出系统指标的各种协议。最后，我们将探索
    **Prometheus** 和 **Mimir** 的架构，以了解 Mimir 如何满足高可扩展系统的需求。
- en: 'We will cover the following main topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将覆盖以下主要内容：
- en: Updating the OpenTelemetry collector for metrics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新 OpenTelemetry 采集器以收集指标
- en: Introducing PromQL
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 PromQL
- en: Exploring data collection and metric protocols
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索数据收集和指标协议
- en: Understanding data storage architectures
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解数据存储架构
- en: Using exemplars in Grafana
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Grafana 中使用示例数据
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, you will need the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，您将需要以下内容：
- en: The OpenTelemetry demo application set up in [*Chapter 3*](B18277_03.xhtml#_idTextAnchor063)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 [*第 3 章*](B18277_03.xhtml#_idTextAnchor063) 中设置的 OpenTelemetry 演示应用程序
- en: The Grafana Cloud instance set up in [*Chapter 3*](B18277_03.xhtml#_idTextAnchor063)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 [*第 3 章*](B18277_03.xhtml#_idTextAnchor063) 中设置的 Grafana Cloud 实例
- en: Docker and Kubernetes
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 和 Kubernetes
- en: You'll find the code for this chapter in the GitHub repository at [https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter5](https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter5).
    You'll find the *Code in Action* videos for this chapter at [https://packt.link/A2g91](https://packt.link/A2g91).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 GitHub 仓库中的 [https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter5](https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter5)
    找到本章的代码。您可以在 [https://packt.link/A2g91](https://packt.link/A2g91) 找到本章的 *Code
    in Action* 视频。
- en: Updating the OpenTelemetry demo application
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新 OpenTelemetry 演示应用程序
- en: 'For this chapter, we have prepared an updated version of `OTEL-Collector.yaml`,
    which will add additional labels to metrics for you to explore. Full details on
    this process are available from the Git repository in the `README.md` file. This
    process will apply the new version of the collector configuration to your demo
    application:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，我们已经准备了更新版本的 `OTEL-Collector.yaml` 文件，该文件将为您添加更多的标签，以便您进一步探索。有关此过程的详细信息，请参阅
    Git 仓库中的 `README.md` 文件。此过程将把新的采集器配置应用于您的演示应用程序：
- en: 'Using Helm, we will apply the updated configuration file to our Kubernetes
    cluster:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Helm，我们将更新的配置文件应用于我们的 Kubernetes 集群：
- en: '[PRE0]'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Validate upgrade was successful:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证升级是否成功：
- en: '[PRE1]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This new configuration adds the collection of metrics from the Kubernetes cluster
    and the OpenTelemetry collector. The configuration also does some necessary relabeling.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新配置增加了从 Kubernetes 集群和 OpenTelemetry 采集器收集指标的功能。该配置还做了一些必要的重新标记。
- en: Now that we are collecting more data from our local demo application, let’s
    introduce the language used to query that data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们从本地演示应用程序收集更多的数据，让我们介绍用于查询这些数据的语言。
- en: Introducing PromQL
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 PromQL
- en: '**Prometheus** was initially developed by SoundCloud in 2012; the project was
    accepted by the *Cloud Native Computing Foundation* in 2016 as the second incubated
    project (after Kubernetes), and version 1.0 was released shortly after. PromQL
    is an integral part of Prometheus, which is used to query stored data and produce
    dashboards and alerts.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**Prometheus** 最初由 SoundCloud 于 2012 年开发；该项目于 2016 年被 *Cloud Native Computing
    Foundation* 接受成为第二个孵化项目（继 Kubernetes 之后），并且很快发布了 1.0 版本。PromQL 是 Prometheus 的一个重要组成部分，用于查询存储的数据并生成仪表盘和警报。'
- en: 'Before we delve into the details of the language, let’s briefly look at the
    following ways in which Prometheus-compatible systems interact with metrics data:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨语言的细节之前，让我们简要地看一下 Prometheus 兼容系统与指标数据交互的几种方式：
- en: '**Ingesting metrics**: Prometheus-compatible systems accept a timestamp, key-value
    labels, and a sample value. As the details of the **Prometheus Time Series Database**
    (**TSDB**) are quite complicated, the following diagram shows a simplified example
    of how an individual sample for a metric is stored once it has been ingested:'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**摄取度量**：与 Prometheus 兼容的系统接受时间戳、键值标签和样本值。由于 **Prometheus 时间序列数据库**（**TSDB**）的细节相当复杂，下面的图示展示了度量的单个样本在摄取后如何存储的简化示例：'
- en: '![Figure 5.1 – A simplified view of metric data stored in the TSDB](img/B18277_05_1.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.1 – 存储在 TSDB 中的度量数据简化视图](img/B18277_05_1.jpg)'
- en: Figure 5.1 – A simplified view of metric data stored in the TSDB
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1 – 存储在 TSDB 中的度量数据简化视图
- en: '`__name__` value creates a `app_frontend_requests`.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`__name__` 值会创建一个 `app_frontend_requests`。'
- en: Each unique set of labels creates a **time series**. In the preceding figure,
    the set of all labels is the time series.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每一组唯一的标签都会创建一个**时间序列**。在前面的图示中，所有标签的集合即为时间序列。
- en: A time series will contain multiple **samples**, each with a unique timestamp.
    The preceding figure shows a single sample, but over time, multiple samples will
    be collected for each time series.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个时间序列将包含多个**样本**，每个样本都有一个唯一的时间戳。前面的图示展示了一个单一的样本，但随着时间的推移，每个时间序列将会收集多个样本。
- en: The number of unique values for a metric label is referred to as the **cardinality**
    of the label. Highly cardinal labels should be avoided, as they significantly
    increase the storage costs of the metric.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 度量标签的唯一值数量被称为标签的**基数**。应避免使用基数较高的标签，因为它们会显著增加度量的存储成本。
- en: 'The following diagram shows a single metric containing two time series and
    five samples:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个包含两个时间序列和五个样本的单一度量：
- en: '![Figure 5.2 – An example of samples from multiple time series](img/B18277_05_2.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.2 – 多个时间序列的样本示例](img/B18277_05_2.jpg)'
- en: Figure 5.2 – An example of samples from multiple time series
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2 – 多个时间序列的样本示例
- en: 'In Grafana, we can see a representation of the time series and samples from
    a metric. To do this, follow these steps:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Grafana 中，我们可以查看度量的时间序列和样本的表现。为此，请按照以下步骤操作：
- en: In your Grafana instance, select **Explore** in the menu.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的 Grafana 实例中，选择菜单中的 **Explore**。
- en: Choose your Prometheus data source, which will be labeled as `grafanacloud-<team>-prom
    (default)`.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择你的 Prometheus 数据源，标签为 `grafanacloud-<team>-prom (default)`。
- en: 'In the **Metric** dropdown, choose **app_frontend_requests_total**, and under
    **Options**, set **Format** to **Table**, and then click on **Run query**. This
    will show you all the samples and time series in the metric over the selected
    time range. You should see data like this:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 **Metric** 下拉菜单中，选择 **app_frontend_requests_total**，在 **Options** 下，将 **Format**
    设置为 **Table**，然后点击 **Run query**。这将显示选定时间范围内度量中的所有样本和时间序列。你应该看到如下数据：
- en: '![Figure 5.3 – Visualizing the samples and time series that make up a metric](img/B18277_05_3.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.3 – 可视化构成度量的样本和时间序列](img/B18277_05_3.jpg)'
- en: Figure 5.3 – Visualizing the samples and time series that make up a metric
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3 – 可视化构成度量的样本和时间序列
- en: Now that we understand the data structure, let’s explore PromQL.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了数据结构，接下来让我们探索 PromQL。
- en: An overview of PromQL features
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PromQL 功能概述
- en: In this section, we will take you through the features that PromQL has. We will
    start with an explanation of the data types, and then we will look at how to select
    data, how to work on multiple datasets, and how to use functions. As PromQL is
    a query language, it’s important to know how to manipulate data to produce alerts
    and dashboards.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将向你介绍 PromQL 的功能。我们将从数据类型的解释开始，然后我们将讨论如何选择数据、如何处理多个数据集以及如何使用函数。由于 PromQL
    是一种查询语言，了解如何操作数据以生成警报和仪表板非常重要。
- en: Data types
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据类型
- en: 'PromQL offers three data types, which are important, as the functions and operators
    in PromQL will work differently depending on the data types presented:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: PromQL 提供了三种数据类型，这些数据类型非常重要，因为 PromQL 中的函数和运算符会根据所呈现的数据类型有所不同：
- en: '**Instant vectors** are a data type that stores a set of time series containing
    a single sample, all sharing the same timestamp – that is, it presents values
    at a specific instant in time:'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**瞬时向量**是一种数据类型，用来存储包含单个样本的时间序列集合，这些样本共享相同的时间戳——也就是说，它表示在某一特定时刻的值：'
- en: '![Figure 5.4 – An instant vector](img/B18277_05_4.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.4 – 一个瞬时向量](img/B18277_05_4.jpg)'
- en: Figure 5.4 – An instant vector
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4 – 一个瞬时向量
- en: '**Range vectors** store a set of time series, each containing a range of samples
    with different timestamps:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**范围向量**存储一组时间序列，每个时间序列包含具有不同时间戳的样本范围：'
- en: '![Figure 5.5 – Range vectors](img/B18277_05_5.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.5 – 范围向量](img/B18277_05_5.jpg)'
- en: Figure 5.5 – Range vectors
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5 – 范围向量
- en: '**Scalars** are simple numeric values, with no labels or timestamps involved.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标量**是简单的数值，没有涉及标签或时间戳。'
- en: Selecting data
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择数据
- en: 'PromQL offers several tools for you to select data to show in a dashboard or
    alert, or just to understand a system’s state. Some of these are described in
    the following table:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: PromQL 提供了多种工具，用于选择要在仪表盘或告警中显示的数据，或仅用于了解系统的状态。以下表格描述了其中的一些：
- en: '| **Name** | **Syntax** | **Operators** | **Scope** |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **语法** | **运算符** | **作用范围** |'
- en: '| Metric selector | `metric_name` |  | Selects a metric |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 度量选择器 | `metric_name` |  | 选择一个度量 |'
- en: '| Range selector | `[``5m]` | `ms`, `s`, `m`, `h`, `d`, `w`, and `y` | Selects
    samples |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 范围选择器 | `[``5m]` | `ms`、`s`、`m`、`h`、`d`、`w` 和 `y` | 选择样本 |'
- en: '| Label selector | `{``label="value", foo!="bar"}` | `=`, `!=`, `=~`, and `!~`
    | Selects and filters time series using labels |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 标签选择器 | `{``label="value", foo!="bar"}` | `=`、`!=`、`=~` 和 `!~` | 使用标签选择和过滤时间序列
    |'
- en: '| Offset modifier | `offset 5m` | `ms`, `s`, `m`, `h`, `d`, `w`, and `y` |
    Offsets the evaluation time from the current point in time by the specified amount
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 偏移修饰符 | `offset 5m` | `ms`、`s`、`m`、`h`、`d`、`w` 和 `y` | 将评估时间从当前时间点偏移指定的时间
    |'
- en: '| `@` modifier | `@` `1686561123` | `@` | Sets the evaluation time to a specific
    time for instant or range vectors. This modifier uses epoch timestamps |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| `@` 修饰符 | `@` `1686561123` | `@` | 将评估时间设置为特定时间，适用于瞬时或范围向量。该修饰符使用纪元时间戳 |'
- en: Table 5.1 – The selection operators available in PromQL
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5.1 – PromQL 中可用的选择运算符
- en: In addition to the operators that allow us to select data, PromQL offers a selection
    of operators to compare multiple sets of data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 除了允许我们选择数据的运算符外，PromQL 还提供了一些运算符，用于比较多个数据集。
- en: Operators between two datasets
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 两个数据集之间的运算符
- en: Some data is easily provided by a single metric, while other useful information
    needs to be created from multiple metrics. The following operators allow you to
    combine datasets.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 有些数据由单一度量轻松提供，而其他有用的信息则需要从多个度量中创建。以下运算符允许你将数据集进行组合。
- en: '| **Name** | **Syntax** | **Operators** | **Scope** |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **语法** | **运算符** | **作用范围** |'
- en: '| Arithmetic operators | `a + b` | `+`, `-`, `*`, `/`, `%`, and `^` | Arithmetic
    operations on instant vectors and scalars; scope depends on the data type of `a`
    and `b`. It’s important to note that vectors are matched on *all* labels. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| 算术运算符 | `a + b` | `+`、`-`、`*`、`/`、`%` 和 `^` | 对瞬时向量和标量进行算术运算；作用范围取决于 `a`
    和 `b` 的数据类型。需要注意的是，向量会在*所有*标签上进行匹配。 |'
- en: '| Comparison operators | `a == b` | `==`, `!=`, `>`, `<`, `>=`, and `<=` |
    Filters instant vectors and scalars based on the comparison; scope depends on
    the data type of `a` and `b`. |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| 比较运算符 | `a == b` | `==`、`!=`、`>`、`<`、`>=` 和 `<=` | 基于比较过滤瞬时向量和标量；作用范围取决于
    `a` 和 `b` 的数据类型。 |'
- en: '| Aggregation operators | `sum by (``label) (a)` | `sum()`, `min()`, `max()`,
    `avg()`, `group()`, `stddev()`, `stdvar()`, `count()`, `count_values()`, `bottomk()`,
    `topk()`, and `quantile()` | Aggregation operations on a single instant vector.These
    operators offer the `without` and `by` clauses to modify how results are grouped
    by label. |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 聚合运算符 | `sum by (``label) (a)` | `sum()`、`min()`、`max()`、`avg()`、`group()`、`stddev()`、`stdvar()`、`count()`、`count_values()`、`bottomk()`、`topk()`
    和 `quantile()` | 对单一瞬时向量进行聚合操作。 这些运算符提供了 `without` 和 `by` 子句，以修改结果按标签分组的方式。 |'
- en: '| One-to-one vector matching | `a +` `on b` | `on()` and `ignoring()` | Modifies
    vector matching to specific labels (`on`) or ignoring a label (ignoring) |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 一对一向量匹配 | `a +` `on b` | `on()` 和 `ignoring()` | 将向量匹配修改为特定标签（`on`）或忽略某标签（`ignoring`）
    |'
- en: '| One-to-many/many-to-one vector matching using group modifiers | `a +` `group_left
    b` | `group_left()` and `group_right()` | Modifies the vector matching in cases
    of many-to-one or one-to-many matching.Grouping can use a label list to include
    a label in the results. |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| 使用组修饰符进行一对多/多对一向量匹配 | `a +` `group_left b` | `group_left()` 和 `group_right()`
    | 在多对一或一对多匹配的情况下，修改向量匹配。分组可以使用标签列表来包含标签在结果中 |'
- en: '| Many-to-many vector matching using logical operators | `a` `and b` | `and`,
    `or`, and `unless` | Modifies vector matching in cases of many-to-many matching,
    based on logical operations between labels and the values of `a` and `b` |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 使用逻辑运算符进行多对多向量匹配 | `a` `and b` | `and`、`or` 和 `unless` | 在多对多匹配的情况下，基于标签和
    `a`、`b` 的值之间的逻辑运算修改向量匹配 |'
- en: Table 5.2 – The comparison operators available in PromQL
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 表5.2 – PromQL中可用的比较运算符
- en: Vector matching is an initially confusing topic; to clarify it, let’s consider
    examples for the three cases of vector matching – *one-to-one*, *one-to-many*/*many-to-one*,
    and *many-to-many*.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 向量匹配是一个最初会让人感到困惑的话题；为了澄清这一点，我们来考虑向量匹配的三种情况 —— *一对一*、*一对多*/*多对一* 和 *多对多*。
- en: 'By default, when combining vectors, all label names and values are matched.
    This means that for each element of the vector, the operator will try to find
    a single matching element from the second vector. Let’s consider a simple example:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，当组合向量时，所有标签名称和值都会被匹配。这意味着对于每个向量元素，运算符会尝试从第二个向量中找到一个匹配的元素。让我们来看一个简单的例子：
- en: '`10{color=blue,smell=ocean}`'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`10{color=blue,smell=ocean}`'
- en: '`31{color=red,smell=cinnamon}`'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`31{color=red,smell=cinnamon}`'
- en: '`27{color=green,smell=grass}`'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`27{color=green,smell=grass}`'
- en: '`19{color=blue,smell=ocean}`*   `8{color=red,smell=cinnamon}`*   `14{color=green,smell=jungle}`*   `29{color=blue,smell=ocean}`*   `39
    {color=red,smell=cinnamon}`*   `29{color=blue}`*   `39{color=red}`*   `41{color=green}`'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`19{color=blue,smell=ocean}`*   `8{color=red,smell=cinnamon}`*   `14{color=green,smell=jungle}`*   `29{color=blue,smell=ocean}`*   `39
    {color=red,smell=cinnamon}`*   `29{color=blue}`*   `39{color=red}`*   `41{color=green}`'
- en: When `color=blue` and `smell=ocean`, `A{} + B{}` gives `10 + 19 = 29`, and when
    `color=red` and `smell=cinnamon`, `A{} + B{}` gives `31 + 8 = 29`. The other elements
    do not match the two vectors so are ignored.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 当`color=blue`和`smell=ocean`时，`A{} + B{}`的结果是`10 + 19 = 29`，而当`color=red`和`smell=cinnamon`时，`A{}
    + B{}`的结果是`31 + 8 = 29`。其他元素与这两个向量不匹配，因此会被忽略。
- en: When we sum the vectors using `on (color)`, we will only match on the `color`
    label; so now, the two green elements match and are summed.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们使用`on (color)`进行向量求和时，我们只会根据`color`标签进行匹配；因此，现在这两个绿色元素会匹配并被求和。
- en: 'This example works when there is a *one-to-one* relationship of labels between
    vector **A** and vector **B**. However, sometimes there may be a *many-to-one*
    or *one-to-many* relationship – that is, vector A or vector B may have more than
    one element that matches the other vector. In these cases, Prometheus will give
    an error, and grouping syntax must be used. Let’s look at another example to illustrate
    this:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 当向量**A**和向量**B**之间存在*一对一*关系时，这个例子是有效的。然而，有时也可能存在*多对一*或*一对多*的关系 —— 也就是说，向量A或向量B中可能有多个元素与另一个向量的元素匹配。在这些情况下，Prometheus会报错，并且必须使用分组语法。让我们看另一个例子来说明这一点：
- en: '`7{color=blue,smell=ocean}`'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`7{color=blue,smell=ocean}`'
- en: '`5{color=red,smell=cinamon}`'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`5{color=red,smell=cinamon}`'
- en: '`2{color=blue,smell=powder}`'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`2{color=blue,smell=powder}`'
- en: '`20{color=blue,smell=ocean}`*   `8{color=red,smell=cinamon}`*   `14{color=green,smell=jungle}`*   `27{color=blue,smell=ocean}`*   `13{color=red,smell=cinamon}`*   `22{color=blue,smell=powder}`'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`20{color=blue,smell=ocean}`*   `8{color=red,smell=cinamon}`*   `14{color=green,smell=jungle}`*   `27{color=blue,smell=ocean}`*   `13{color=red,smell=cinamon}`*   `22{color=blue,smell=powder}`'
- en: Now, we have two different elements in vector `color=blue`. The `group_left`
    command will use the labels from vector `22`, when the item matching in vector
    `group_right` operator will behave in the opposite direction.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们在向量`color=blue`中有两个不同的元素。`group_left`命令将使用向量`22`中的标签，当在`group_right`操作符中进行匹配时，行为将朝着相反的方向进行。
- en: 'The final option is a *many-to-many* vector match. These matches use the logical
    operators `and`, `unless`, and `or` to combine parts of vectors **A** and **B**.
    Let’s see some examples:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 最后的选项是*多对多*的向量匹配。这些匹配使用逻辑运算符`and`、`unless`和`or`来组合向量**A**和**B**的部分元素。让我们看一些例子：
- en: '`10{color=blue,smell=ocean}`'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`10{color=blue,smell=ocean}`'
- en: '`31{color=red,smell=cinamon}`'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`31{color=red,smell=cinamon}`'
- en: '`27{color=green,smell=grass}`'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`27{color=green,smell=grass}`'
- en: '`19{color=blue,smell=ocean}`*   `8{color=red,smell=cinamon}`*   `14{color=green,smell=jungle}`*   `10{color=blue,smell=ocean}`*   `31{color=red,smell=cinamon}`*   `27{color=green,smell=grass}`*   `10{color=blue,smell=ocean}`*   `31{color=red,smell=cinamon}`*   `27{color=green,smell=grass}`*   `14{color=green,smell=jungle}`'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`19{color=blue,smell=ocean}`*   `8{color=red,smell=cinamon}`*   `14{color=green,smell=jungle}`*   `10{color=blue,smell=ocean}`*   `31{color=red,smell=cinamon}`*   `27{color=green,smell=grass}`*   `10{color=blue,smell=ocean}`*   `31{color=red,smell=cinamon}`*   `27{color=green,smell=grass}`*   `14{color=green,smell=jungle}`'
- en: Unlike the previous examples, mathematical operators are not being used here,
    so the values of the elements are the values from vector **A**, but only the elements
    of **A** that match the logical condition in **B** are returned.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 与前面的示例不同，这里没有使用数学运算符，因此元素的值来自向量**A**，但只有与向量**B**中的逻辑条件匹配的**A**元素会被返回。
- en: Now that we understand the operators, let’s quickly introduce PromQL functions
    before we look at a practical example of writing PromQL. We will explore a practical
    example of their use in the *Writing* *PromQL* section.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了运算符，让我们在看一个实际的 PromQL 写作示例之前，快速介绍一下 PromQL 函数。我们将在 *Writing* *PromQL*
    部分探讨它们的实际用法。
- en: Functions
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 函数
- en: 'PromQL offers about 60 different functions. The full list of functions can
    be found on the Prometheus w[ebsite: https://prometheus.io/docs/prometheus/latest/querying/f](https://prometheus.io/docs/prometheus/latest/querying/functions)unctions.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: PromQL 提供约 60 种不同的函数。可以在 Prometheus 网站上找到完整的函数列表：[https://prometheus.io/docs/prometheus/latest/querying/functions](https://prometheus.io/docs/prometheus/latest/querying/functions)。
- en: Now that we’ve looked at the functions available in PromQL, let’s explore writing
    a PromQL query.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看过 PromQL 中可用的函数，让我们探索编写一个 PromQL 查询。
- en: Writing PromQL
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写 PromQL
- en: While technical descriptions of a language are useful for reference, this section
    will follow the process of building a query so that the language can be seen in
    context. Having your Grafana instance open in **Explorer** will help you follow
    along. In the following sections, we’ll write practical examples using the selectors,
    operators, and modifiers we introduced in the previous section.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管语言的技术描述对于参考是有用的，但本节将遵循构建查询的过程，以便可以在上下文中看到语言。在接下来的几节中，我们将使用在前一节中介绍的选择器、运算符和修饰符编写实际的示例。
- en: Metric selection
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 指标选择
- en: When we looked at metric labels, we saw how you can select metrics in PromQL
    with the `metric_name{}` syntax. This can be typed directly into a query using
    the `app_frontend_requests_total`. If it does not, use the **Metric** dropdown
    to select this metric. You should see results like in *Figure 5**.3*. This method
    of selection returns an instant vector, as described in *Figure 5**.4*.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看指标标签时，我们看到您可以使用 `metric_name{}` 语法在 PromQL 中选择指标。这可以直接键入查询中的 `app_frontend_requests_total`。如果没有，请使用
    **Metric** 下拉菜单选择此指标。您应该看到类似于 *Figure 5.3* 中的结果。这种选择方法返回一个瞬时向量，如 *Figure 5.4*
    中所述。
- en: 'The syntax is similar for returning a range vector, as described in *Figure
    5**.5*. We just need to add the range we are interested in – `metric_name[range]`.
    The range must include the time units, which can range from milliseconds (ms)
    to years (y). It’s important to note that queries using range vectors need to
    be run with a query type of **Instant**. If a query type of **Range** or **Both**
    (the default) is selected, then you will receive an error. Here is an example
    of the error you will see:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 返回范围向量的语法与 *Figure 5.5* 中描述的类似。我们只需要添加我们感兴趣的范围 - `metric_name[range]`。范围必须包括时间单位，可以从毫秒（ms）到年（y）。重要的是要注意，使用范围向量的查询需要以
    **Instant** 查询类型运行。如果选择了 **Range** 或 **Both**（默认），那么您将收到错误。以下是您将看到的错误示例：
- en: '![Figure 5.6 – An error when using a range vector in a range query](img/B18277_05_6.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.6 – 在范围查询中使用范围向量时出错](img/B18277_05_6.jpg)'
- en: Figure 5.6 – An error when using a range vector in a range query
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6 – 在范围查询中使用范围向量时出错
- en: Time series selection and operators
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 时间序列选择和运算符
- en: 'As time series are made up of a unique set of labels, we can expand our query
    to only look at specific data – for example, only requests that target the cart
    API of the OpenTelemetry demo application. The following steps will filter our
    query to show only the requests that target the `/``api/cart` endpoint:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 由于时间序列由一组唯一的标签组成，我们可以扩展我们的查询，仅查看特定数据 - 例如，仅请求目标为 OpenTelemetry 演示应用程序的购物车 API。以下步骤将过滤我们的查询，仅显示目标为
    `/api/cart` 终端的请求：
- en: 'Switch to the **Table** view at the top right of the **Results** panel:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换到 **Results** 面板右上角的 **Table** 视图：
- en: '![Figure 5.7 – Using the Table view in the PromQL results](img/B18277_05_7.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.7 – 在 PromQL 结果中使用表视图](img/B18277_05_7.jpg)'
- en: Figure 5.7 – Using the Table view in the PromQL results
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7 – 在 PromQL 结果中使用表视图
- en: 'Hover your mouse over a value for the target; you should see this icon:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将鼠标悬停在目标值上，您应该看到这个图标：
- en: '![Figure 5.8 – Filter for value](img/B18277_05_8.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.8 – 值的过滤器](img/B18277_05_8.jpg)'
- en: Figure 5.8 – Filter for value
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8 – 值的过滤器
- en: 'Click on the plus icon, and you will see that we have a new label filter and
    our PromQL now says the following: `app_frontend_requests_total{target="/api/cart"}`.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单击加号图标，您将看到我们有一个新的标签过滤器，我们的 PromQL 现在如下所示：`app_frontend_requests_total{target="/api/cart"}`。
- en: 'Let’s only show the `GET` method requests as well; you can do this by using
    the `=`: Checks for an exact match of a string. For example, `target="/api/cart"`
    will match only when the `target` label is `/api/cart/`.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们只显示 `GET` 方法的请求；你可以使用 `=` 来实现：检查字符串的精确匹配。例如，`target="/api/cart"` 只会在 `target`
    标签为 `/api/cart/` 时匹配。
- en: '`!=`: Checks for anything other than an exact match. `target!="/api/cart"`
    will match everything except when the `target` label is `/api/cart/`.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`!=`：检查是否与精确匹配不同。`target!="/api/cart"` 会匹配所有情况，除了 `target` 标签为 `/api/cart/`
    的情况。'
- en: '`=~`: Checks for a regex match. For example, `target=~"/api/.*"` will match
    when the `target` label starts with `/api/`. This includes `/api/cart/`, `/api/horse/`,
    and `/api/cart/foo/bar/`.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`=~`：检查是否与正则表达式匹配。例如，`target=~"/api/.*"` 会在 `target` 标签以 `/api/` 开头时匹配。这包括
    `/api/cart/`、`/api/horse/` 和 `/api/cart/foo/bar/`。'
- en: '`!~`: Checks for anything other than a regex match. `target!~"/api/.+"` will
    match when the `target` label is `/api/` or `/checkout/` but will not match `/api/cart/`,
    `/api/horse/`, and `/api/cart/foo/bar/`.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`!~`：检查是否与正则表达式不匹配。`target!~"/api/.+"` 会在 `target` 标签为 `/api/` 或 `/checkout/`
    时匹配，但不会匹配 `/api/cart/`、`/api/horse/` 和 `/api/cart/foo/bar/`。'
- en: While we’re looking at the table, you should also see a column titled `metric_name{}`
    is equivalent to `{__name__="metric_name"}`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们查看表格时，应该还会看到一个名为 `metric_name{}` 的列，它等同于 `{__name__="metric_name"}`。
- en: We’ve now selected data and filtered it to the endpoint we’re interested in,
    but a raw count of the requests that were made is difficult to interpret. Let’s
    look at how to transform this count into something more useful, using a function.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经选择了数据并将其筛选到感兴趣的端点，但对请求进行的原始计数难以解读。让我们看看如何使用函数将这个计数转换为更有用的信息。
- en: Functions, aggregation, and operators
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 函数、聚合和运算符
- en: 'PromQL is a nested language, so to apply a function to a selected set of data,
    you simply enclose the data selection with the function. Our query so far looks
    like this:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: PromQL 是一种嵌套语言，因此要对选定的数据集应用函数，只需将数据选择放入函数中。到目前为止，我们的查询如下所示：
- en: '[PRE2]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This query returns the count of requests at each sample point. For most purposes,
    we are more interested in the rate of requests that hit that endpoint. This will
    allow us to answer questions such as what the peak rate is, or whether the rate
    is higher now or lower than at another point in time. The function to get this
    information is the `rate()` function. We can plug our current query into the function
    like this:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这个查询返回每个采样点的请求计数。对于大多数目的，我们更关心的是命中该端点的请求的速率。这将使我们能够回答诸如峰值速率是多少，或者现在的速率是否比某个时间点的速率高或低等问题。获取这些信息的函数是
    `rate()` 函数。我们可以将当前查询插入到该函数中，如下所示：
- en: '[PRE3]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The rate function takes an input of a range vector, so we have added the special
    `[$__rate_interval]` time variable. This is a Grafana feature that instructs Grafana
    to pick an appropriate interval, based on the scrape interval of the data source
    we have selected. This feature simplifies the technicalities of selecting the
    correct rate interval. A similar process is used for aggregation and other operators.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`rate` 函数接受一个范围向量作为输入，因此我们添加了特殊的 `[$__rate_interval]` 时间变量。这是 Grafana 的一个功能，指示
    Grafana 根据我们选择的数据源的抓取间隔来选择一个合适的间隔。这个功能简化了选择正确速率间隔的技术性操作。聚合和其他运算符也使用类似的过程。'
- en: Now that we know how to get the rate of requests to the `/api/cart` endpoint,
    let’s have a look at another example query.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何获取 `/api/cart` 端点的请求速率，让我们看一个另一个示例查询。
- en: HTTP success rate
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: HTTP 成功率
- en: A common **Service Level Indicator** (**SLI**) for a web application is the
    **success rate** of HTTP requests. In plain language, this is the number of successful
    HTTP requests/total HTTP requests. We will discuss the process of choosing good
    SLIs in [*Chapter 9*](B18277_09.xhtml#_idTextAnchor183).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 一个常见的 **服务水平指标** (**SLI**) 用于 Web 应用程序，是 HTTP 请求的 **成功率**。用简单的语言来说，这就是成功的 HTTP
    请求数与总 HTTP 请求数的比率。我们将在[*第9章*](B18277_09.xhtml#_idTextAnchor183)中讨论选择良好 SLI 的过程。
- en: 'A PromQL query like the following will produce the success rate SLI for the
    `app_frontend_requests_total` metric:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 像下面这样的 PromQL 查询将为 `app_frontend_requests_total` 指标生成成功率 SLI：
- en: '[PRE4]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can break this code down as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将这段代码拆解如下：
- en: Using `app_frontend_requests_total{status=~"2[0-9]{2}"}[5m]`, we select samples
    of the `app_frontend_requests` metric that have the `status` label, with a value
    between `200` and `299`. This uses regex to select the label range, and it is
    a range vector over a five-minute range. For those of you familiar with regex,
    Grafana requires the escaping of backslashes.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 `app_frontend_requests_total{status=~"2[0-9]{2}"}[5m]`，我们选择具有 `status` 标签且值在
    `200` 到 `299` 之间的 `app_frontend_requests` 指标样本。这使用正则表达式来选择标签范围，并且它是一个五分钟范围的区间向量。对于熟悉正则表达式的用户，Grafana
    需要对反斜杠进行转义。
- en: The `rate()` function calculates the per-second average rate of successful requests.
    This function returns an instant vector.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`rate()` 函数计算成功请求的每秒平均速率。该函数返回一个瞬时向量。'
- en: The previous functions have left all data grouped into the initial time series
    from it. However, for this query, we are not interested in the method, target,
    or any other labels. Instead, we are interested in knowing whether a particular
    instance of the application is failing, as a failing instance could be masked
    by many good instances. To achieve this, we use the `sum by (instance) ()` aggregation.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 之前的函数将所有数据分组到初始时间序列中。然而，对于这个查询，我们不关心方法、目标或任何其他标签。相反，我们关心的是某个特定实例的应用程序是否出现故障，因为一个故障实例可能会被许多正常实例掩盖。为此，我们使用
    `sum by (instance) ()` 聚合函数。
- en: The last line of the query mirrors the first line but removes the label selector,
    so we get the *total* requests.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询的最后一行与第一行相同，但去除了标签选择器，因此我们得到的是 *总* 请求。
- en: Finally, we use the arithmetic operator (`/`) to divide the successful requests
    by the total requests. The output of this query gives us a number that will be
    close to 1 when most requests are successful; as we see failures, this will trend
    downward to 0 when every request fails.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，我们使用算术运算符 (`/`) 将成功请求除以总请求数。此查询的输出将是一个数字，当大多数请求成功时，它接近 1；当出现故障时，随着每个请求的失败，值将趋向于
    0。
- en: 'Another common item to measure is the **duration** of requests made to the
    service. Durations are frequently represented as histogram data, and PromQL offers
    us many statistical tools we can use to understand our user’s experience. Let’s
    look at the following query:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个常见的衡量项目是对服务请求的 **持续时间**。持续时间通常表示为直方图数据，PromQL 提供了许多统计工具，帮助我们理解用户的体验。让我们看一下以下查询：
- en: '[PRE5]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `http_server_duration_milliseconds_bucket` metric is a histogram, which
    is indicated by the naming convention of `_bucket`. The `histogram_quantile()`
    function takes this histogram data and gives us the 95th percentile duration.
    This is calculated using the `le` (less than or equal to) label in the histogram
    data. While it might be tempting to use averages for this kind of calculation,
    percentiles offer us a more nuanced understanding of the data. The 95th percentile
    means that 95% of samples have a duration less than or equal to the value returned.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`http_server_duration_milliseconds_bucket` 指标是一个直方图，其命名约定中包含 `_bucket`。`histogram_quantile()`
    函数接受该直方图数据，并为我们提供第 95 百分位的持续时间。这是通过直方图数据中的 `le`（小于或等于）标签计算得出的。虽然使用平均值进行此类计算可能很诱人，但百分位数能为我们提供更细致的数据理解。第
    95 百分位意味着 95% 的样本持续时间小于或等于返回的值。'
- en: 'Grafana offers several helpful functions to understand a query:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana 提供了若干有用的函数，帮助理解查询：
- en: Above the query component is a slider titled **Explain**. Toggling this on will
    present a step-by-step breakdown of what a query is doing.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在查询组件上方有一个标题为 **Explain** 的滑块。打开此滑块将逐步展示查询的执行过程。
- en: Also, above the query component is a button titled **Kick start your query**.
    Clicking this will give a number of starter queries.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，在查询组件上方有一个名为 **Kick start your query** 的按钮。点击它将提供一些初始查询。
- en: Below the **Options** section is the query **Inspector**. This will give detailed
    information about the query, such as its total request time and the data returned.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 **选项** 部分下方是查询 **检查器**。它将提供有关查询的详细信息，例如总请求时间和返回的数据。
- en: 'Here is a screenshot showing the location of these options:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一张截图，显示了这些选项的位置：
- en: '![Figure 5.9 – Helpful functions for queries](img/B18277_05_9.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.9 – 查询的有用函数](img/B18277_05_9.jpg)'
- en: Figure 5.9 – Helpful functions for queries
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9 – 查询的有用函数
- en: Hopefully, you have a good grasp of the fundamentals of PromQL now and know
    what resources you have available to learn more. Whilst querying data is a major
    part of the day-to-day work in Grafana, it is good to have an understanding of
    how metrics data is collected.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 希望你现在对PromQL的基础知识有了很好的掌握，并且知道有哪些资源可以用来进一步学习。虽然查询数据是Grafana日常工作的一个重要部分，但了解度量数据是如何收集的也是很有帮助的。
- en: The OpenTelemetry demo that has been set up also produces metrics from the single-node
    Kubernetes cluster, the kubelet instance on the node, and the underlying host.
    We encourage you to explore these metrics and see what you can find.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 已设置的OpenTelemetry演示还会从单节点Kubernetes集群、节点上的kubelet实例和底层主机生成度量数据。我们鼓励你探索这些度量数据，看看你能发现什么。
- en: We’ve seen how to query the data stored in Prometheus-compatible systems. Now,
    let’s see how to collect data from your services.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了如何查询存储在Prometheus兼容系统中的数据。现在，让我们看看如何从你的服务中收集数据。
- en: Exploring data collection and metric protocols
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据收集和度量协议
- en: In [*Chapter 2*](B18277_02.xhtml#_idTextAnchor043), we introduced four common
    protocols in use to collect data from today’s software – **StatsD** and **DogStatsD**,
    **OpenTelemetry Protocol** (**OTLP**), and **Prometheus**. We also introduced
    **Simple Network Management Protocol** (**SNMP**), which is used in the networking
    and compute spaces. In this section, we’ll explore some of the features of these
    protocols.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第二章*](B18277_02.xhtml#_idTextAnchor043)中，我们介绍了四种当前用于从现代软件中收集数据的常用协议——**StatsD**和**DogStatsD**，**OpenTelemetry协议**（**OTLP**），以及**Prometheus**。我们还介绍了**简单网络管理协议**（**SNMP**），它广泛用于网络和计算领域。在本节中，我们将探讨这些协议的一些特点。
- en: There are two methods that metrics can be collected, push and pull. In a **push
    protocol**, the application or infrastructure must be configured with a destination
    to send metrics. In a **pull protocol**, the application or infrastructure is
    configured to expose metrics for another service to request. Both methods have
    advantages and disadvantages, it is also important to be aware of the potential
    security implications. In the following subsections, let’s delve into each protocol.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 度量数据的收集有两种方法，推送和拉取。在**推送协议**中，应用程序或基础设施必须配置一个目标地址来发送度量数据。在**拉取协议**中，应用程序或基础设施配置为暴露度量数据，供其他服务请求。两种方法各有优缺点，同时也需要意识到潜在的安全隐患。在接下来的子节中，我们将深入探讨每种协议。
- en: StatsD and DogStatsD
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StatsD和DogStatsD
- en: We have grouped StatsD and DogStatsD together, as they are identical for the
    purposes of what we are discussing in this chapter.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将StatsD和DogStatsD放在一起讨论，因为它们在本章所讨论的内容上是相同的。
- en: '`8125` in its default settings. These are things to consider when using StatsD:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '`8125`是其默认设置。这些是使用StatsD时需要考虑的事项：'
- en: StatsD uses UDP for transmission. This favors the speed of transmission over
    the guarantee of delivery.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: StatsD使用UDP进行传输。这更倾向于优先考虑传输速度，而非确保交付的可靠性。
- en: The protocol offers no support for authentication between the application and
    the receiving service. Depending on the environment, this could be a security
    concern.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该协议不支持应用程序与接收服务之间的身份验证。根据环境的不同，这可能成为一个安全隐患。
- en: It’s worth noting that common practice, especially in Kubernetes, is to expose
    the StatsD receiver on `localhost:8125`, thus limiting exposure and offering a
    standard for applications to use.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，尤其是在Kubernetes中，常见的做法是将StatsD接收器暴露在`localhost:8125`上，从而限制暴露范围并为应用程序提供一个标准。
- en: StatsD has quite wide support in data collection agents, usually via contributed
    receivers. The OpenTelemetry collector, FluentBit, Vector, Beats, Telegraf, and
    the StatsD daemon all support the protocol. Prometheus offers an exporter that
    takes StatsD format metrics and exposes them as a Prometheus scrape endpoint;
    this is recommended as an intermediate step to a full Prometheus migration.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: StatsD在数据收集代理中有广泛的支持，通常通过贡献的接收器实现。OpenTelemetry收集器、FluentBit、Vector、Beats、Telegraf和StatsD守护进程都支持该协议。Prometheus提供了一个导出器，将StatsD格式的度量数据转换为Prometheus抓取端点；这是一个建议的中间步骤，用于完整的Prometheus迁移。
- en: '**DogStatsD** is less well supported than the StatsD format it is derived from;
    it provides an expanded set of metrics to StatsD. The data collection agents that
    natively support DogStatsD are **Vector** and Datadog’s own agent. The OpenTelemetry
    collector currently has no support, but there are discussions in progress on adding
    this, and Datadog is an active participant in the OpenTelemetry project, so this
    is likely to change.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '**DogStatsD** 的支持不如其衍生自的 StatsD 格式；它为 StatsD 提供了一组扩展的指标。原生支持 DogStatsD 数据采集的代理包括
    **Vector** 和 Datadog 自家的代理。OpenTelemetry 采集器目前不支持此功能，但正在讨论将其加入，Datadog 也是 OpenTelemetry
    项目的积极参与者，因此这一点可能会发生变化。'
- en: OTLP
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: OTLP
- en: OTLP is also a *push protocol*, so destination knowledge is necessary. Like
    StatsD, OTLP is often implemented using the standard receiving endpoint of `localhost:4317`
    (`localhost:4318` (HTTP). OTLP supports both gRPC and HTTP and offers support
    for the authentication and acknowledgment between the client and server. OTLP
    also offers several quality-of-life items, such as **server-controlled throttling**
    and **GZIP compression**.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: OTLP 也是一个 *推送协议*，因此需要知道目标位置。像 StatsD 一样，OTLP 通常通过标准接收端点 `localhost:4317`（`localhost:4318`（HTTP））来实现。OTLP
    支持 gRPC 和 HTTP，并且支持客户端与服务器之间的认证和确认。OTLP 还提供了多个提升使用体验的功能，例如 **服务器控制的限流** 和 **GZIP
    压缩**。
- en: OpenTelemetry is in very active development, so this information is liable to
    change. As the project is a collaboration between several major vendors, agents
    from those vendors are increasingly supporting OTLP metrics. While other collection
    tools do not support OTLP input, the OpenTelemetry collector supports input from
    many sources. This means the OTEL collector is ideal for supporting a mixed estate.
    The vector collection agent also offers this versatility, and most things said
    about the OTEL collector can be applied to it as well.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 正在积极开发中，因此这些信息可能会发生变化。由于该项目是多个主要厂商的合作，来自这些厂商的代理程序正在越来越多地支持 OTLP
    指标。尽管其他采集工具不支持 OTLP 输入，但 OpenTelemetry 采集器支持来自多种来源的输入。这意味着 OTEL 采集器非常适合支持混合环境。Vector
    采集代理也提供了这种多功能性，大多数关于 OTEL 采集器的说法同样适用于它。
- en: Prometheus
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Prometheus
- en: Unlike StatsD and OTLP, Prometheus is a *pull protocol*. A client application
    needs to be configured to serve metrics on an endpoint, and then a Prometheus-compatible
    scraper is configured to collect those metrics at specific intervals. These metrics
    are commonly exposed on the `/metrics` endpoint, although some frameworks implement
    this differently (e.g., `/actuator/Prometheus` for Spring Boot).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 与 StatsD 和 OTLP 不同，Prometheus 是一个 *拉取协议*。客户端应用程序需要配置一个端点来提供指标，然后配置一个与 Prometheus
    兼容的抓取器，在特定的时间间隔内收集这些指标。这些指标通常暴露在 `/metrics` 端点上，尽管一些框架会以不同方式实现（例如 Spring Boot
    的 `/actuator/Prometheus`）。
- en: It may seem that using a pull configuration increases the configuration steps
    required. However, using a pull method does reduce the information needed by the
    application of its running environment. For example, the application configuration
    would remain the same if 0 or 10 clients read its metrics. This pull pattern also
    matches very closely with the pattern of liveness and readiness endpoints for
    applications in Kubernetes.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 可能看起来使用拉取配置会增加所需的配置步骤。然而，使用拉取方法确实减少了应用程序对其运行环境所需的配置信息。例如，如果有 0 或 10 个客户端读取其指标，应用程序的配置保持不变。这个拉取模式也与
    Kubernetes 中应用程序的存活和就绪端点模式非常契合。
- en: To assist in the server configuration, Prometheus offers a wide range of service
    discovery options, across many different platforms, including Kubernetes, DNS,
    and Consul. These discovery options include matching a specific name and collecting
    data if a label is present, and this range of options allows for quite complex
    architectures where needed.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 为了帮助服务器配置，Prometheus 提供了广泛的服务发现选项，涵盖多个不同平台，包括 Kubernetes、DNS 和 Consul。这些发现选项包括匹配特定名称并在存在标签时收集数据，这一范围的选项使得在需要时能够实现相当复杂的架构。
- en: The Prometheus format has good collector support; Prometheus, the OTEL Collector,
    Grafana Agent, Vector, Beats, and Telegraf all support the collection of these
    metrics.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 格式具有良好的采集器支持；Prometheus、OTEL Collector、Grafana Agent、Vector、Beats
    和 Telegraf 都支持采集这些指标。
- en: SNMP
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: SNMP
- en: SNMP is more complex than the other protocols discussed here, as it includes
    a lot of functionality for the management and monitoring of network-connected
    devices, such as switches and physical servers. The *monitoring* aspect of SNMP
    is a *pull protocol*, where a manager instance connects to agent software on devices
    and pulls data. There is additional functionality in **SNMP traps**, which allow
    a device to inform the manager about items as a data push. These traps are often
    of interest to track metrics from. It is worth noting that security can be a concern
    using SNMP, depending on how it is configured. SNMP offers a significant attack
    surface if configured incorrectly.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: SNMP 比我们在这里讨论的其他协议更为复杂，因为它包含了许多用于管理和监控网络连接设备的功能，例如交换机和物理服务器。SNMP 的*监控*方面是一个*拉取协议*，即管理实例连接到设备上的代理软件并拉取数据。**SNMP
    traps** 还有额外的功能，允许设备以数据推送的方式向管理者报告事件。这些 traps 经常被用于追踪度量数据。值得注意的是，使用 SNMP 时，安全性可能会成为一个问题，具体取决于配置方式。如果配置不当，SNMP
    会提供显著的攻击面。
- en: SNMP is very well supported, as the protocol has been active since 1988 and
    has good support from hardware vendors.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: SNMP 得到了很好的支持，因为该协议自 1988 年以来一直在使用，并且得到了硬件供应商的良好支持。
- en: We’ve now covered querying data using PromQL, and how data is produced and collected,
    so let’s now explore how Grafana stores metric data.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经讨论了如何使用 PromQL 查询数据，以及数据是如何生成和收集的，现在让我们来探讨 Grafana 如何存储度量数据。
- en: Understanding data storage architectures
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解数据存储架构
- en: '**Time Series Databases** (**TSDBs**) are ideally suited to handle metric data,
    as metrics need to record data at specific points in time, and TSDBs are structured
    to make this data easy to record and query. There are several TSDBs available,
    but as this book is focused on Grafana, we will only discuss **Graphite**, **Prometheus**,
    and **Mimir** in this section. This is aimed at giving you an understanding of
    the structure of data as it is stored, as well as an overview of how Mimir allows
    organizations to scale their data beyond the capabilities of Graphite and Prometheus.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '**时间序列数据库** (**TSDBs**) 理想地用于处理度量数据，因为度量需要在特定时间点记录数据，而 TSDB 被结构化为便于记录和查询这些数据。有多种
    TSDB 可供选择，但由于本书专注于 Grafana，因此我们将在本节中仅讨论 **Graphite**、**Prometheus** 和 **Mimir**。本节的目的是让你理解数据的存储结构，并概述
    Mimir 如何帮助组织将数据扩展到超越 Graphite 和 Prometheus 能力的水平。'
- en: Graphite architecture
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Graphite 架构
- en: Graphite has several components; we will discuss the storage component **Whisper**
    here. The Whisper TSDB uses a flat file structure, where each unique time series
    is a fixed-size file. This size is determined by the configuration of resolution
    and retention configured in Whisper. Gathering this data for a search requires
    each of these files to be read, which quickly becomes expensive in disk I/O. As
    there are no inbuilt items that manage data redundancy, Graphite is also unable
    to guarantee that data written to it will be protected from loss or corruption.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: Graphite 有多个组件；我们将在此讨论存储组件 **Whisper**。Whisper TSDB 使用扁平文件结构，其中每个唯一的时间序列都是一个固定大小的文件。这个大小由在
    Whisper 中配置的分辨率和保留策略来决定。为了进行搜索，必须读取这些文件中的每一个，这会迅速变得昂贵，特别是在磁盘 I/O 上。由于没有内建的管理数据冗余的项目，Graphite
    也无法保证写入的数据会免于丢失或损坏。
- en: However, the protocols introduced by Graphite to write data are still relevant
    although aging, so Grafana Cloud offers a Graphite ingest endpoint and query endpoint
    for teams that are already using this technology.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Graphite 引入的写入数据的协议尽管已显老化，但仍然相关，因此 Grafana Cloud 为已经使用该技术的团队提供了一个 Graphite
    数据接收端点和查询端点。
- en: Graphite was an early example of metrics, introduced in 2008; the limitations
    of query speed and data integrity outlined previously led to the creation of Prometheus,
    which we will discuss next.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Graphite 是一个早期的度量标准，于 2008 年引入；先前提到的查询速度和数据完整性的限制导致了 Prometheus 的诞生，接下来我们将讨论
    Prometheus。
- en: Prometheus architecture
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Prometheus 架构
- en: Prometheus stores data in an immutable `block`, which covers a fixed time range
    (by default, two hours). Inside a block are several `chunks`, which are capped
    at 512 MB; these files contain the sampled value. Alongside these `chunks` are
    metadata files – `index` and `meta.json`. The `index` file contains a table that
    records the labels contained in the block and a reference to the position of all
    samples, with these labels in the associated chunks. Highly cardinal metric labels
    cause a huge increase in the size of the `index` file and degrade read performance.
    The `meta.json` file contains metadata such as the min and max timestamp contained
    in the `block` and stats on the samples, series, and chunks contained and the
    version used.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 将数据存储在不可变的 `block` 中，`block` 覆盖一个固定的时间范围（默认是两小时）。在一个 `block` 中包含若干个
    `chunks`，这些 `chunks` 的大小上限为 512 MB；这些文件包含了采样的值。与这些 `chunks` 一起的是元数据文件——`index`
    和 `meta.json`。`index` 文件包含一个表格，记录了 `block` 中的标签以及指向所有样本在相关 `chunks` 中位置的引用。高基数的度量标签会导致
    `index` 文件大小的巨大增加，并降低读取性能。`meta.json` 文件包含如 `block` 中的最小和最大时间戳，以及包含的样本、序列和 `chunks`
    的统计信息，以及所使用的版本。
- en: To process data as it’s received, Prometheus also uses a `head block`, which
    is similar to the `block` used for storage, but it allows writes. This allows
    for the collection of a full two-hour block of data, ready for the index and metadata
    to be created when the block is finished. This process includes functionality
    to persist data on disk to prevent data loss. The `head block` consists of a `meta.json`
    file that records what has been received. When the end of the two-hour time block
    is reached, a new `head block` is created, and the old `head block` is transformed
    into a standard `block`, with the creation of an `index` and `chunks`.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 为了处理接收到的数据，Prometheus 还使用了一个 `head block`，它类似于用于存储的 `block`，但它允许写入。这使得可以收集完整的两小时数据块，等到数据块完成时，再创建
    `index` 和元数据。这个过程包括将数据持久化到磁盘上的功能，以防止数据丢失。`head block` 包含一个 `meta.json` 文件，记录了已接收的数据。当两小时时间块结束时，会创建一个新的
    `head block`，旧的 `head block` 会转变为一个标准的 `block`，并创建 `index` 和 `chunks`。
- en: 'The following figure shows the structure of a fictional Prometheus TSDB, with
    the `blocks`, `chunks`, `index`, and metadata files and the WAL highlighted:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个虚构的 Prometheus TSDB 的结构，其中突出了 `blocks`、`chunks`、`index` 和元数据文件以及 WAL：
- en: '![Figure 5.10 – The Prometheus TSDB](img/B18277_05_10.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.10 – Prometheus TSDB](img/B18277_05_10.jpg)'
- en: Figure 5.10 – The Prometheus TSDB
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10 – Prometheus TSDB
- en: The implementation of the Prometheus TSDB in Prometheus itself is limited, as
    it uses local storage, which is not clustered or replicated natively. While it
    is possible to improve the aspects of this, there is a fundamental limitation
    of only a single node carrying out reads and writes. These limitations are perfectly
    acceptable in the correct circumstances. However, when scaling the TSDB to accept
    many active time series, changes are needed. Handling these situations is what
    Mimir was designed to do.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 中的 Prometheus TSDB 实现有限，因为它使用本地存储，本地存储没有原生的集群或复制功能。虽然可以改善这些方面，但其根本限制在于只有一个节点执行读写操作。在适当的情况下，这些限制是完全可以接受的。然而，当
    TSDB 扩展以接受多个活跃的时间序列时，需要做出更改。处理这些情况正是 Mimir 设计的初衷。
- en: Mimir architecture
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Mimir 架构
- en: Mimir uses the same fundamental TSDB storage structures. However, unlike Prometheus,
    Mimir natively supports object stores for block files. The supported stores include
    Amazon S3, Google Cloud Storage, Microsoft Azure Storage, and OpenStack Swift.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: Mimir 使用相同的基础 TSDB 存储结构。然而，与 Prometheus 不同，Mimir 原生支持对象存储来存储块文件。支持的存储包括 Amazon
    S3、Google Cloud Storage、Microsoft Azure Storage 和 OpenStack Swift。
- en: By leveraging **object storage**, which is massively scalable, Mimir can handle
    the scaling problem experienced with Prometheus by adding new instances of the
    data-ingesting service. Mimir separates the incoming streams of data to a specific
    per-tenant TSDB, and each of these is assigned to an instance of the ingesting
    service. Like Prometheus, data is written to memory and the WAL by the ingester,
    and when the block is complete, it is written to object storage. To provide resilience
    Mimir will write each of these streams to multiple ingesters, and a compactor
    service will handle the process of merging the redundant blocks in object storage
    and removing duplicate samples.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用**对象存储**，Mimir 能够解决 Prometheus 所遇到的扩展问题，通过增加新的数据摄取服务实例来实现。Mimir 将传入的数据流分配到特定的每租户
    TSDB，并将每个数据流分配给一个摄取服务实例。像 Prometheus 一样，数据通过摄取器写入内存和 WAL，当块完成时，它被写入对象存储。为了提供弹性，Mimir
    会将这些数据流写入多个摄取器，并且一个压缩服务将处理合并对象存储中冗余块的过程，并删除重复样本。
- en: Like the horizontal scalability of the write pathway, Mimir also scales the
    read pathway. It does this by splitting an incoming query into shorter time ranges.
    Then, it distributes these smaller units of the query to multiple querier instances.
    By doing this, Mimir again leverages the benefits of the underlying object storage
    for a quick return of data.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于写路径的水平可扩展性，Mimir 也扩展了读路径。它通过将传入的查询拆分成更短的时间范围来实现这一点。然后，它将这些更小的查询单元分发给多个查询实例。通过这样做，Mimir
    再次利用底层对象存储的优势，实现数据的快速返回。
- en: 'The following diagram shows the read and write pathways for Mimir:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了 Mimir 的读写路径：
- en: '![Figure 5.11 – Mimir architecture](img/B18277_05_11.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.11 – Mimir 架构](img/B18277_05_11.jpg)'
- en: Figure 5.11 – Mimir architecture
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11 – Mimir 架构
- en: Metrics show us aggregated data, such as the total count of requests. It is
    helpful when exploring an *odd* metric value to be able to look at an example.
    In applications that are instrumented with traces and metrics, exemplars allow
    us to record a sample trace in our metric data. Let’s see this capability in action.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 指标显示的是聚合数据，如请求的总次数。当探索一个*异常*的指标值时，查看一个示例会很有帮助。在那些通过追踪和指标进行仪表化的应用中，示例允许我们在指标数据中记录一个样本追踪。让我们来看看这个功能的实际应用。
- en: Using exemplars in Grafana
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Grafana 中使用示例
- en: '**Exemplars** are functions in Grafana that allow us to pivot from an aggregated
    view of the system, given by metrics, to a detailed view of a single request,
    given by traces. Exemplars need to be configured at the *collection layer* and
    then sent to the *storage layer*.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '**示例**是 Grafana 中的功能，允许我们从系统的聚合视图（通过指标提供）切换到单个请求的详细视图（通过追踪提供）。示例需要在*采集层*进行配置，然后发送到*存储层*。'
- en: 'When they are available, you can view exemplars by doing the following:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 当示例可用时，你可以通过以下步骤查看示例：
- en: 'Open **Options** under the query, and toggle the **Exemplars** slider:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在查询下打开**选项**，并切换**示例**滑块：
- en: '![Figure 5.12 – The Exemplars toggle](img/B18277_05_12.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.12 – 示例切换按钮](img/B18277_05_12.jpg)'
- en: Figure 5.12 – The Exemplars toggle
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12 – 示例切换按钮
- en: 'Exemplars will appear as stars on the metrics chart:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 示例将作为星星出现在指标图表上：
- en: '![Figure 5.13 – An exemplar in metrics](img/B18277_05_13.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.13 – 指标中的示例](img/B18277_05_13.jpg)'
- en: Figure 5.13 – An exemplar in metrics
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13 – 指标中的示例
- en: 'Hovering over an individual exemplar will expand on the metrics data by showing
    information from the exemplar trace in the metrics view. We will explain these
    fields in more detail in [*Chapter 6*](B18277_06.xhtml#_idTextAnchor134), but
    some notable fields are the name and version of the process runtime and `span_id`,
    which would not usually be available in a purely metric view:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 将鼠标悬停在单个示例上时，将通过在指标视图中显示来自示例追踪的信息来扩展指标数据。我们将在[*第六章*](B18277_06.xhtml#_idTextAnchor134)中更详细地解释这些字段，但一些显著的字段包括进程运行时的名称和版本以及`span_id`，这些在纯粹的指标视图中通常无法获取：
- en: '![Figure 5.14 – Exemplar information](img/B18277_05_14.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.14 – 示例信息](img/B18277_05_14.jpg)'
- en: Figure 5.14 – Exemplar information
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.14 – 示例信息
- en: 'From an exemplar, you can also pivot from viewing metric data to looking at
    the trace in question by clicking on the **Query with Tempo (****Tempo)** button:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过示例，你还可以从查看指标数据切换到查看相关追踪，方法是点击**与 Tempo 查询（****Tempo）**按钮：
- en: '![Figure 5.15 – Opening an exemplar in Tempo](img/B18277_05_15.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.15 – 在 Tempo 中打开示例](img/B18277_05_15.jpg)'
- en: Figure 5.15 – Opening an exemplar in Tempo
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.15 – 在 Tempo 中打开示例
- en: We’ll discuss the details of tracing in more detail in [*Chapter 6*](B18277_06.xhtml#_idTextAnchor134),
    but this should give you a good introduction to using this kind of data in your
    metrics.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第6章*](B18277_06.xhtml#_idTextAnchor134)中详细讨论跟踪的具体内容，但这应当为你提供一个良好的介绍，帮助你在度量标准中使用这种数据。
- en: Summary
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored metrics in detail. We saw all the operators available
    in PromQL and wrote two queries using the language. With that foundation of querying
    knowledge, we looked at the tools available to collect data and the various protocols
    with which applications can share data. We then looked at the architecture for
    Prometheu, and saw how Mimir takes the concepts of Prometheus and turns them into
    a highly scalable data processing tool, able to meet the needs of organizations
    of any size. Our final exploration was of Exemplars, giving us a concrete data
    example to add context to the aggregated data seen in metrics.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们详细探讨了度量标准。我们了解了在PromQL中可用的所有操作符，并使用该语言编写了两个查询。在掌握了查询知识的基础上，我们查看了收集数据的工具以及应用程序共享数据的各种协议。接着，我们了解了Prometheus的架构，并看到Mimir如何将Prometheus的概念转化为一个高度可扩展的数据处理工具，能够满足任何规模组织的需求。我们最后探讨了Exemplars，为聚合数据提供了一个具体的数据示例，帮助我们更好地理解度量标准中的数据。
- en: The next chapter will explore how traces work in Grafana Tempo, which will show
    you how powerful the use of exemplars and logging trace and span information can
    be to create a truly observable system for your organization’s customers.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章将探讨Grafana Tempo中的跟踪工作原理，展示如何利用Exemplars以及日志追踪和跨度信息来为组织的客户创建一个真正可观察的系统。
