- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Deploying Real-World Projects with GitOps on Kubernetes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上使用 GitOps 部署真实世界项目
- en: In this chapter, you will embark on a practical journey that bridges the gap
    between theoretical knowledge and real-world knowledge application. As you delve
    into the intricate process of setting up a GitOps and Kubernetes-based development
    environment, you will gain firsthand experience in designing, developing, and
    deploying an application within this innovative framework. Through detailed guidance
    on architectural design, **Continuous Integration and Continuous Delivery** (**CI/CD**)
    processes, application scaling, and security, this chapter aims to equip you with
    the essential skills and insights needed to implement these cutting-edge technologies
    effectively in your projects. Whether you’re looking to enhance your organizational
    capabilities or to refine your personal technical expertise, the comprehensive
    real-life example provided here will serve as an invaluable resource for anyone
    aspiring to master GitOps and Kubernetes in practical settings.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将带你进行一次实践之旅，弥合理论知识与实际应用之间的鸿沟。在深入了解设置基于 GitOps 和 Kubernetes 的开发环境的复杂过程时，你将亲身体验在这一创新框架下设计、开发和部署应用程序的过程。本章通过对架构设计、**持续集成和持续交付**（**CI/CD**）流程、应用程序扩展性和安全性的详细指导，旨在帮助你掌握实现这些前沿技术所需的基本技能和见解，帮助你在项目中有效地应用它们。无论你是希望提升组织能力，还是提升个人技术水平，这里提供的全面真实案例将成为任何有志于在实际环境中掌握
    GitOps 和 Kubernetes 的人的宝贵资源。
- en: 'In this chapter, our focus will be on the following key areas:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点关注以下几个关键领域：
- en: Establishing a GitOps and Kubernetes development environment
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 建立 GitOps 和 Kubernetes 开发环境
- en: Implementing CI/CD with GitOps
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 GitOps 实现 CI/CD
- en: Designing for scalability and efficiency
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为扩展性和效率设计
- en: Resource management and scalability
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源管理和扩展性
- en: Monitoring and securing your application
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控和保护你的应用程序
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter builds on your existing knowledge of Git, Kubernetes, and GitOps
    tools such as **Argo CD** and Flux CD, which you acquired in earlier chapters.
    We will use an **Azure AKS** cluster deployed by Terraform using a GitHub workflow.
    Ensure that you have access to a Kubernetes setup and are familiar with CI/CD
    principles to fully benefit from the exercises.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章基于你在前面章节中学到的 Git、Kubernetes 以及 GitOps 工具（如**Argo CD**和 Flux CD）的知识。我们将使用一个通过
    GitHub 工作流使用 Terraform 部署的**Azure AKS**集群。确保你能够访问 Kubernetes 环境，并且熟悉 CI/CD 原则，以便充分利用本章的练习。
- en: 'All necessary code and resources are provided in the [*Chapter 11*](B22100_11.xhtml#_idTextAnchor209)
    folder of our dedicated GitHub repository:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 所有必要的代码和资源都已提供在我们的专用 GitHub 仓库的[*第 11 章*](B22100_11.xhtml#_idTextAnchor209)文件夹中：
- en: '[https://github.com/PacktPublishing/Implementing-GitOps-with-Kubernetes](https://github.com/PacktPublishing/Implementing-GitOps-with-Kubernetes)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://github.com/PacktPublishing/Implementing-GitOps-with-Kubernetes](https://github.com/PacktPublishing/Implementing-GitOps-with-Kubernetes)'
- en: Establishing a GitOps and Kubernetes development environment
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建立 GitOps 和 Kubernetes 开发环境
- en: Establishing a proper development environment is crucial for the successful
    implementation of GitOps practices. This environment serves as the backbone for
    both development and operations teams, enabling seamless integration and continuous
    delivery of applications. A well-configured development environment ensures that
    all changes to applications and infrastructure are version-controlled, traceable,
    and aligned with the declarative configurations stored in Git. This consistency
    between the development environment and production setups reduces the likelihood
    of errors and deployment failures, fostering a more reliable and robust delivery
    pipeline. By emphasizing the importance of a correct setup from the outset, teams
    can leverage GitOps to its fullest potential, ensuring that automated processes
    govern deployments and infrastructure management efficiently and effectively.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 建立一个合适的开发环境对于成功实施 GitOps 实践至关重要。这个环境作为开发和运维团队的支柱，使应用程序能够无缝集成和持续交付。一个配置良好的开发环境确保所有应用程序和基础设施的变更都经过版本控制、可追溯，并与存储在
    Git 中的声明性配置对齐。这种开发环境与生产环境之间的一致性减少了错误和部署失败的可能性，从而促进了更加可靠和健壮的交付管道。通过强调从一开始就正确设置的重要性，团队可以充分发挥
    GitOps 的潜力，确保自动化过程有效且高效地管理部署和基础设施。
- en: 'Installing and configuring Kubernetes for GitOps involves setting up your Kubernetes
    cluster in a way that integrates seamlessly with GitOps tools such as Flux CD
    (see the *Flux integration with Kubernetes* section in [*Chapter 4*](B22100_04.xhtml#_idTextAnchor065))
    or Argo CD (see the *Argo CD integration with Kubernetes* section in [*Chapter
    4*](B22100_04.xhtml#_idTextAnchor065)). What follows is a step-by-step guide that
    covers the setup process, ensuring that your Kubernetes environment is ready for
    a GitOps workflow:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 安装和配置 Kubernetes 以支持 GitOps 涉及以一种与 GitOps 工具（如 Flux CD（参见[*第 4 章*](B22100_04.xhtml#_idTextAnchor065)中的*Flux
    与 Kubernetes 集成*部分））或 Argo CD（参见[*第 4 章*](B22100_04.xhtml#_idTextAnchor065)中的*Argo
    CD 与 Kubernetes 集成*部分））无缝集成的方式来配置 Kubernetes 集群。接下来是一个逐步指南，涵盖了设置过程，确保你的 Kubernetes
    环境为 GitOps 工作流做好准备：
- en: Install a Kubernetes cluster and choose your environment. For learning and development,
    consider using **K3s** (refer to the *Exploring K3s as a lightweight Kubernetes
    distribution* section in [*Chapter 2*](B22100_02.xhtml#_idTextAnchor027)) or **minikube**.
    Both are suitable for running Kubernetes locally on your machine. For production
    or more scalable environments, consider cloud solutions such as **Amazon EKS**,
    Azure AKS, or **Google GKE**. To install minikube, follow the official minikube
    installation guide at [https://minikube.sigs.k8s.io](https://minikube.sigs.k8s.io).
    For deploying Kubernetes on cloud platforms, refer to the specific setup guides
    provided by the respective cloud providers. For the real-world scenario described
    in this chapter, we will use an AKS cluster.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装一个 Kubernetes 集群并选择你的环境。对于学习和开发，考虑使用**K3s**（参见[*第 2 章*](B22100_02.xhtml#_idTextAnchor027)中的*探索
    K3s 作为轻量级 Kubernetes 发行版*部分）或**minikube**。这两者都适合在本地机器上运行 Kubernetes。对于生产环境或更具可扩展性的环境，考虑使用云解决方案，如**Amazon
    EKS**、Azure AKS 或 **Google GKE**。要安装 minikube，请参考官方的 minikube 安装指南：[https://minikube.sigs.k8s.io](https://minikube.sigs.k8s.io)。对于在云平台上部署
    Kubernetes，请参阅各云提供商提供的具体设置指南。在本章描述的实际场景中，我们将使用 AKS 集群。
- en: 'Verify installation. Ensure that `kubectl`, the Kubernetes command-line tool,
    is installed and configured to communicate with your cluster. You can verify this
    by running the following:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证安装。确保已安装并配置了 `kubectl`，Kubernetes 的命令行工具，确保它可以与集群通信。你可以通过运行以下命令来验证：
- en: '[PRE0]'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This command should return the cluster details confirming that Kubernetes is
    up and running:'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此命令应返回集群的详细信息，确认 Kubernetes 已正常运行：
- en: '[PRE1]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Set up your namespace. It’s good practice to create a dedicated namespace for
    your GitOps tools:'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置你的命名空间。建议为你的 GitOps 工具创建一个专用的命名空间：
- en: '[PRE2]'
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Set up permissions. Set up **Role-Based Access Control** (**RBAC**) rules to
    ensure that your GitOps tools have the necessary permissions to manage resources.
    Most GitOps tools have specific RBAC configurations outlined in their setup guides.
    We will see a concrete example of how to set up RBAC in the *Configuring Kubernetes
    RBAC for user and role management* section of this chapter.
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置权限。设置**基于角色的访问控制**（**RBAC**）规则，以确保你的 GitOps 工具具有管理资源所需的权限。大多数 GitOps 工具在其安装指南中都列出了具体的
    RBAC 配置。我们将在本章的*为用户和角色管理配置 Kubernetes RBAC*部分看到如何设置 RBAC 的具体示例。
- en: Install your GitOps tool. Depending on your preference, select from tools such
    as Flux CD, Argo CD, Helm, or Kustomize. Each tool has unique strengths and supportive
    community backing. For more details about the mentioned GitOps tools, refer to
    the *Overview of popular GitOps tools* section in [*Chapter 4*](B22100_04.xhtml#_idTextAnchor065).
    Additionally, you can explore the *A deep dive into Helm and Kustomize*, *Argo
    CD integration with Kubernetes*, and *Flux CD integration with Kubernetes* sections
    of the same chapter.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装你的 GitOps 工具。根据你的偏好，从 Flux CD、Argo CD、Helm 或 Kustomize 等工具中选择。每个工具都有独特的优点和支持的社区。有关上述
    GitOps 工具的更多详细信息，请参阅[*第 4 章*](B22100_04.xhtml#_idTextAnchor065)中的*流行 GitOps 工具概览*部分。此外，你还可以探索本章中关于*深入了解
    Helm 和 Kustomize*、*Argo CD 与 Kubernetes 集成*和*Flux CD 与 Kubernetes 集成*的部分。
- en: Set up a Git repository. Configure the GitOps tool to track your Git repository
    where your Kubernetes manifests are stored. For guidance, refer to the *Kubernetes
    deployment with Azure DevOps* or the *Kubernetes deployment with AWS CodePipeline*
    section, both in [*Chapter 4*](B22100_04.xhtml#_idTextAnchor065). This setup process
    involves pointing the tool to your repository and specifying which branch and
    path to monitor for changes.
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置 Git 仓库。配置 GitOps 工具以跟踪存储 Kubernetes 清单的 Git 仓库。有关指导，请参阅 [*第 4 章*](B22100_04.xhtml#_idTextAnchor065)
    中的 *使用 Azure DevOps 部署 Kubernetes* 或 *使用 AWS CodePipeline 部署 Kubernetes* 部分。此设置过程包括将工具指向您的仓库，并指定要监控更改的分支和路径。
- en: Validate and test. Start by deploying a simple application using your GitOps
    tool to confirm that changes in your Git repository automatically trigger deployments
    in your Kubernetes cluster. Monitor the deployment using the GitOps tool’s dashboard
    or CLI to ensure that the application is deployed and running as expected. Test
    updates and rollbacks by modifying the application’s manifest in your Git repository
    and noting whether the changes are automatically implemented.
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证和测试。首先，使用您的 GitOps 工具部署一个简单的应用程序，以确认 Git 仓库中的更改会自动触发 Kubernetes 集群中的部署。通过
    GitOps 工具的仪表板或 CLI 监控部署，确保应用程序已按预期部署并运行。通过修改 Git 仓库中的应用程序清单并观察更改是否自动应用，测试更新和回滚。
- en: Most of the pipeline points have already been covered in more detail in previous
    chapters. They will be revisited in the next section, where will see how to implement
    a real-world scenario for CI/CD with GitOps.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 大部分流水线的要点在前几章中已有详细介绍。它们将在下一部分重新提及，我们将看到如何实现一个真实世界的 CI/CD GitOps 场景。
- en: Implementing CI/CD with GitOps
  id: totrans-28
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 GitOps 实现 CI/CD
- en: To implement a real-world CI/CD GitOps scenario, we need an application that
    no longer uses mocked data but instead utilizes concrete data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现一个真实世界的 CI/CD GitOps 场景，我们需要一个不再使用模拟数据而是使用具体数据的应用程序。
- en: In this section, we will expose a backend service for a weather application
    that fetches data from a real weather service, such as **OpenWeatherMap** ([https://openweathermap.org/](https://openweathermap.org/)),
    to the public internet.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将为天气应用程序暴露一个后端服务，该服务从一个真实的天气服务（例如 **OpenWeatherMap**，[https://openweathermap.org/](https://openweathermap.org/)）获取数据，并使其公开互联网。
- en: Given that the requirements for setting up our GitOps environment (installing
    a Kubernetes cluster and choosing your environment, verifying installation, and
    installing your GitOps tool) have already been met in the previous section of
    this chapter, the next step is to create a new GitHub repository. For example,
    you might create `gitops-for-real-world`, with a directory named `Step-01`. This
    directory will be used to add the code and files for subsequent steps.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于在本章前一部分中已经完成了设置 GitOps 环境的要求（安装 Kubernetes 集群、选择环境、验证安装以及安装 GitOps 工具），下一步是创建一个新的
    GitHub 仓库。例如，您可以创建 `gitops-for-real-world`，并创建一个名为 `Step-01` 的目录。此目录将用于添加后续步骤的代码和文件。
- en: Before proceeding, you need to create a free account with the `OpenWeatherMap`
    service or another similar service of your choice. Services like these typically
    require a token to query their API, which is used for authentication and billing
    purposes. It’s crucial to keep this token *confidential* and not share it. Please
    refer to the `OpenWeatherMap` documentation to create a new token. Soon, we will
    add this token as a **secret** in the Kubernetes cluster.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，您需要在 `OpenWeatherMap` 服务或您选择的其他类似服务上创建一个免费账户。这类服务通常需要一个令牌来查询其 API，用于身份验证和计费目的。保护该令牌的*机密性*至关重要，切勿共享它。请参阅
    `OpenWeatherMap` 文档以创建新令牌。稍后，我们将把此令牌作为 **秘密** 添加到 Kubernetes 集群中。
- en: Final objective and implementation
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 最终目标和实现
- en: To achieve our final objective, this section and the ones that follow will demonstrate
    the use of a **Python Flask application**, packaged as a **Docker image**. This
    image is built with a new tag at each commit and deployed on an Azure AKS cluster,
    which is provisioned automatically by the pipeline using Terraform for the **Infrastructure
    as Code** (**IaC**) component. Initially, the entire deployment chain—both IaC
    and the application—will be managed entirely by our GitHub CI/CD pipeline. Later,
    we will transition to using Argo CD for the deployment while keeping the CI processes
    within the GitHub workflow.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现我们的最终目标，本节及其后续章节将演示如何使用 **Python Flask 应用程序**，并将其打包为 **Docker 镜像**。每次提交时，这个镜像都会使用新的标签构建，并在
    Azure AKS 集群上部署，该集群由管道使用 Terraform 自动化提供，用于 **基础设施即代码** (**IaC**) 组件。最初，整个部署链——包括
    IaC 和应用程序——将完全由我们的 GitHub CI/CD 管道管理。之后，我们将过渡到使用 Argo CD 进行部署，同时保持 CI 过程在 GitHub
    工作流内。
- en: Ultimately, to test our service after it has been exposed to the public internet,
    we will perform **weather** requests for a specified city via the query string
    in a URL, such as [http://public-ip/weather?city=zurich](http://public-ip/weather?city=zurich).
    The response will be in JSON format, which can be rendered directly in the browser
    or with tools such as **curl**.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，为了在我们的服务公开到公共互联网后进行测试，我们将通过 URL 中的查询字符串进行**天气**请求，指定城市，例如 [http://public-ip/weather?city=zurich](http://public-ip/weather?city=zurich)。响应将以
    JSON 格式返回，可以直接在浏览器中呈现，或者使用 **curl** 等工具。
- en: Our pipeline will be developed as a GitHub workflow and will be composed as
    illustrated in *Figure 11**.1*.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的管道将作为 GitHub 工作流进行开发，并将按 *图 11.1* 所示进行组成。
- en: '![Figure 11.1 – A GitHub workflow pipeline](img/B22100_11_01.jpg)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.1 – GitHub 工作流管道](img/B22100_11_01.jpg)'
- en: Figure 11.1 – A GitHub workflow pipeline
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – GitHub 工作流管道
- en: CI/CD pipeline using GitHub Actions and Terraform
  id: totrans-39
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 GitHub Actions 和 Terraform 的 CI/CD 管道
- en: The pipeline in *Figure 11**.1* leverages Terraform for infrastructure management
    and deploys a Dockerized application to an AKS cluster, providing a practical
    example of modern DevOps practices. The code of the pipeline is too long to be
    explicitly added as content in this chapter. What follows are some important aspects
    that should be considered for a better understanding of that. The workflow description
    is contained in the `gitops-for-real-ci-cd-pipeline.yml` file in the `.github/workflows/`
    directory of the repository accompanying this chapter.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 11.1* 中的管道利用 Terraform 进行基础设施管理，并将 Docker 化的应用程序部署到 AKS 集群中，提供了现代 DevOps
    实践的一个实际示例。由于管道的代码过长，无法在本章中明确添加为内容，接下来列出了一些需要考虑的重要方面，以便更好地理解。工作流描述包含在存储库的 `.github/workflows/`
    目录中的 `gitops-for-real-ci-cd-pipeline.yml` 文件中。'
- en: Workflow trigger conditions
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作流触发条件
- en: 'The pipeline is configured to trigger on any push or pull request to the main
    branch with one exception: changes exclusively in the `Step-01/deployment` directory
    do not initiate the workflow. This precaution prevents redundant runs when only
    Kubernetes manifest files are updated, ensuring efficient use of resources and
    avoiding potential conflicts in continuous deployment scenarios.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 该管道被配置为在对主分支进行任何推送或拉取请求时触发，有一个例外：仅在 `Step-01/deployment` 目录中的更改不会启动工作流。此预防措施可防止在仅更新
    Kubernetes 清单文件时发生冗余运行，从而确保资源的高效使用，并避免在持续部署场景中可能出现的冲突。
- en: Terraform plan and apply
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Terraform 计划和应用
- en: 'The workflow begins with the `terraform-plan` job. This job executes several
    critical steps:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 工作流以 `terraform-plan` 作业开始。此作业执行几个关键步骤：
- en: '**Environment setup**: The job initializes by checking out the repository and
    setting up the Azure CLI with credentials stored securely as GitHub secrets. This
    step ensures that the workflow has access to manage resources in Azure.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**环境设置**：作业开始时会检出存储库，并设置带有 GitHub 密钥安全存储的 Azure CLI 凭据。此步骤确保工作流能够访问 Azure 以管理资源。'
- en: All the passwords, tokens, and other sensitive information used in the pipeline
    need to be configured as GitHub Actions Secrets, as illustrated in *Figure 11**.2*.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 管道中使用的所有密码、令牌和其他敏感信息需要配置为 GitHub Actions 密钥，如 *图 11.2* 所示。
- en: '![Figure 11.2 – GitHub secrets on the Actions secrets and variables page](img/B22100_11_02.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.2 – GitHub 在 Actions 秘密和变量页面上的密钥](img/B22100_11_02.jpg)'
- en: Figure 11.2 – GitHub secrets on the Actions secrets and variables page
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – GitHub 在 Actions 秘密和变量页面上的密钥
- en: '`terraform init` to prepare the Terraform environment, configuring backend
    storage for Terraform state files in Azure Blob Storage. The following code is
    extracted from the main pipeline:'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`terraform init` 用于准备 Terraform 环境，并在 Azure Blob Storage 中配置 Terraform 状态文件的后端存储。以下代码摘自主管道：'
- en: '[PRE3]'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '`terraform plan`), which is reviewed automatically to determine whether there
    are changes to apply. The plan is saved as an `terraform-apply` job.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`terraform plan`，该计划会自动进行审查，以确定是否有更改需要应用。该计划会保存为 `terraform-apply` 作业。'
- en: GitHub artifacts
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub 工件
- en: An artifact in GitHub Actions is a file or a collection of files produced during
    a workflow run. Artifacts can include binary files, logs, test results, or any
    other type of data that needs to be stored after a job is completed. These artifacts
    are typically used for storing build and test outputs to be used for debugging,
    deployment, or further processing in subsequent steps or future runs. GitHub stores
    these artifacts for a specified period, allowing them to be downloaded or shared
    across different jobs within the same workflow. This feature facilitates effective
    CI/CD practices by ensuring that outputs from one part of a workflow can easily
    be accessed and utilized in other parts, enhancing automation and continuity throughout
    the software development life cycle.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: GitHub Actions 中的工件是工作流运行过程中生成的一个文件或文件集合。工件可以包括二进制文件、日志、测试结果或任何其他需要在作业完成后存储的数据。这些工件通常用于存储构建和测试输出，以供调试、部署或在后续步骤或未来运行中进一步处理。GitHub
    会在指定时间内存储这些工件，允许在同一工作流中的不同作业之间下载或共享这些工件。该功能通过确保工作流中的一部分输出可以轻松地在其他部分访问和利用，从而促进了有效的
    CI/CD 实践，增强了软件开发生命周期中的自动化和连续性。
- en: Following planning, the `terraform-apply` job applies the approved changes to
    the infrastructure, ensuring that the actual state matches the expected state
    defined in the Terraform configurations. This part can take a few minutes due
    to the provisioning of the resources to Azure. Opening the Azure portal, the final
    provisioning should be similar to what is illustrated in *Figure 11**.3*.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在规划完成后，`terraform-apply` 作业将已批准的更改应用到基础设施，确保实际状态与在 Terraform 配置中定义的预期状态匹配。由于资源在
    Azure 上的配置，这部分可能需要几分钟。在打开 Azure 门户后，最终的配置应与*图 11.3*中所示相似。
- en: '![Figure 11.3 – Azure resources automatically provisioned by the GitHub workflow](img/B22100_11_03.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.3 – 由 GitHub 工作流自动配置的 Azure 资源](img/B22100_11_03.jpg)'
- en: Figure 11.3 – Azure resources automatically provisioned by the GitHub workflow
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 – 由 GitHub 工作流自动配置的 Azure 资源
- en: Docker image build and push
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Docker 镜像构建和推送
- en: 'Parallel to infrastructure management, the `docker-build-and-push` job handles
    the application side:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 与基础设施管理并行，`docker-build-and-push` 作业处理应用程序方面：
- en: '**Docker preparation**: The job sets up Docker environments using QEMU and
    Buildx, tools that enhance Docker’s capabilities on CI environments.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Docker 准备**：该作业使用 QEMU 和 Buildx 设置 Docker 环境，这些工具增强了 Docker 在 CI 环境中的功能。'
- en: '`Step-01` directory and pushes it to Docker Hub, tagging it with the **commit
    SHA** for immutability and traceability, as illustrated in *Figure 11**.4*.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Step-01` 目录并将其推送到 Docker Hub，使用 **commit SHA** 进行标记，以确保不可变性和可追溯性，如*图 11.4*所示。'
- en: '![Figure 11.4 – A Docker repository containing the built images with tags corresponding
    to the SHA number](img/B22100_11_04.jpg)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.4 – 一个 Docker 仓库，其中包含带有 SHA 编号标签的构建镜像](img/B22100_11_04.jpg)'
- en: Figure 11.4 – A Docker repository containing the built images with tags corresponding
    to the SHA number
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 – 一个 Docker 仓库，其中包含带有 SHA 编号标签的构建镜像
- en: Kubernetes deployment
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes 部署
- en: 'After the Docker image is pushed and the infrastructure is ready, the `deploy-to-kubernetes`
    job proceeds:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Docker 镜像推送并且基础设施准备就绪后，`deploy-to-kubernetes` 作业继续进行：
- en: '`kubectl` with the credentials for the Kubernetes cluster managed in Azure,
    ensuring that commands are executed against the correct cluster, as reported in
    the following code:'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 集群凭证的 `kubectl`，确保命令在正确的集群上执行，具体代码如下所示：
- en: '[PRE4]'
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '**Secrets and configurations**: It then deploys necessary Kubernetes secrets
    and configurations, such as API keys needed by the application, using best practices
    for secret management. The following code is extracted from the pipeline:'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**机密和配置**：接着，它部署应用程序所需的 Kubernetes 机密和配置，如 API 密钥，采用最佳的机密管理实践。以下代码摘自管道：'
- en: '[PRE5]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Idempotency
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 幂等性
- en: Idempotency, in the context of deploying resources, means that running the same
    deployment command multiple times will result in the same state without causing
    unintended changes or side effects after the initial application.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署资源的上下文中，幂等性意味着多次运行相同的部署命令将导致相同的状态，而不会在初次应用后产生不必要的更改或副作用。
- en: '`Step-01/deployment/backend-api-deployment.yaml`), which references the newly
    built Docker image, ensuring that the latest version of the application is deployed:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Step-01/deployment/backend-api-deployment.yaml`)，该文件引用了新构建的Docker镜像，确保部署的是应用的最新版本：'
- en: '[PRE6]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Beware!
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 注意！
- en: 'If you want to access the remote AKS cluster from your local development, you
    need to login Azure and execute the following command: `az aks get-credentials
    --resource-group gitops-real-rg --``name gitops-real-aks`'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想从本地开发访问远程AKS集群，你需要登录Azure并执行以下命令：`az aks get-credentials --resource-group
    gitops-real-rg --name gitops-real-aks`
- en: '**Testing**: Unlike local development, for this real-world example, we specified
    a **LoadBalancer** port in the deployment file, so AKS is automatically using
    a public IP address to expose our service to the public internet, as illustrated
    in *Figure 11**.5*.'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**测试**：与本地开发不同，在这个实际的例子中，我们在部署文件中指定了一个**LoadBalancer**端口，因此AKS会自动使用公共IP地址将我们的服务暴露到公共互联网，如*图11.5*所示。'
- en: '![Figure 11.5 – A public IP address used to expose the backand-api-service
    to the public internet](img/B22100_11_05.jpg)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
  zh: '![图11.5 – 用于将backand-api-service暴露到公共互联网的公共IP地址](img/B22100_11_05.jpg)'
- en: Figure 11.5 – A public IP address used to expose the backand-api-service to
    the public internet
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.5 – 用于将backand-api-service暴露到公共互联网的公共IP地址
- en: 'At this point, we can query our service using a URL like the one shown in *Figure
    11**.6* to obtain a response:'
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此时，我们可以使用类似于*图11.6*所示的URL查询我们的服务以获取响应：
- en: '![Figure 11.6 – An example of querying the service for Zurich city using real
    weather data](img/B22100_11_06.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图11.6 – 使用实时天气数据查询苏黎世市服务的示例](img/B22100_11_06.jpg)'
- en: Figure 11.6 – An example of querying the service for Zurich city using real
    weather data
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.6 – 使用实时天气数据查询苏黎世市服务的示例
- en: What we have obtained so far is a fully working CI/CD pipeline that exposes
    a service to the real world. We want to take it a step further by separating the
    CI pipeline from the CD pipeline using ArgoCD, as described in the next section.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经获得了一个完全可工作的CI/CD管道，将服务暴露到现实世界。我们希望更进一步，通过使用ArgoCD将CI管道和CD管道分开，正如下一节所述。
- en: Using Argo CD for the continuous deployment
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Argo CD进行持续部署
- en: In the world of modern software delivery, it’s crucial to ensure that our deployment
    practices are as reliable and scalable as possible. Argo CD, a declarative GitOps
    continuous delivery tool for Kubernetes, significantly enhances these aspects
    by automating deployment processes and syncing the desired application state defined
    in a Git repository with the production environment.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在现代软件交付的世界里，确保我们的部署实践尽可能可靠和可扩展至关重要。Argo CD，作为一种声明式的GitOps持续交付工具，专为Kubernetes设计，通过自动化部署过程并将Git仓库中定义的目标应用状态与生产环境同步，显著提升了这些方面。
- en: Transitioning to Argo CD
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向Argo CD过渡
- en: 'In this section, we will evolve our GitHub Actions workflow by transitioning
    the `deploy-app-to-kubernetes` stage to an `argo-cd-deployment` stage. The `argo-cd-deployment`
    stage in our GitHub Actions workflow encapsulates the following key operations:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过将`deploy-app-to-kubernetes`阶段过渡为`argo-cd-deployment`阶段来发展我们的GitHub
    Actions工作流。我们GitHub Actions工作流中的`argo-cd-deployment`阶段封装了以下关键操作：
- en: '**Argo CD setup**: First, the workflow initializes Argo CD in the Kubernetes
    cluster if it’s not already installed. This includes setting up the necessary
    namespaces and applying the Argo CD installation manifests directly from the official
    sources.'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**Argo CD设置**：首先，如果Kubernetes集群中未安装Argo CD，工作流将初始化它。这包括设置必要的命名空间，并直接从官方来源应用Argo
    CD安装清单。'
- en: '**Repository configuration**: The workflow then adds the Git repository containing
    the Kubernetes manifests to Argo CD. This step involves configuring Argo CD to
    monitor changes in the repository, which hosts the deployment definitions for
    the application.'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**仓库配置**：接下来，工作流将包含Kubernetes清单的Git仓库添加到Argo CD。此步骤涉及配置Argo CD来监视仓库中的更改，该仓库托管应用的部署定义。'
- en: '**Application deployment via Argo CD**: It then ensures that the specific namespace
    for the application is created and ready for deployment.'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**通过Argo CD进行应用部署**：接着，它确保为应用创建并准备好特定的命名空间以供部署。'
- en: '`argocd_deployment.yaml` file, which defines the Argo CD application. This
    manifest specifies the path to the Kubernetes deployment manifests within the
    Git repository, the revision target (e.g., `branch`), and synchronization policies.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`argocd_deployment.yaml` 文件定义了 Argo CD 应用程序。该清单指定了 Git 仓库中 Kubernetes 部署清单的路径、修订目标（例如，`branch`）和同步策略。'
- en: '**Sync trigger**: Optionally, this step triggers a manual sync if immediate
    deployment is required, though typically Argo CD would automatically detect changes
    based on its polling strategy.'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**同步触发**：可选地，如果需要立即部署，此步骤会触发手动同步，尽管通常 Argo CD 会根据其轮询策略自动检测到变更。'
- en: Managing downtime and ensuring continuity with Argo CD
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 管理停机时间并确保 Argo CD 的连续性
- en: When Argo CD experiences temporary downtime, the primary impact is on the synchronization
    and automated reconciliation of deployments in Kubernetes environments. During
    this period, any changes committed to the Git repository will not be synchronized
    with Kubernetes clusters, which means that updates, fixes, and new feature deployments
    are postponed. The automated reconciliation process, which ensures that the actual
    state of the Kubernetes environment matches the desired state specified in the
    Git repository, is also interrupted. This means that any discrepancies or configuration
    drifts that occur during the downtime will not be addressed until Argo CD is back
    online. Upon restoring Argo CD, it will automatically begin to process and apply
    all changes made during its downtime. The system will fetch the latest configurations
    from Git and proceed with the necessary reconciliations to align the Kubernetes
    clusters with the desired states from the repository. It’s important to note that
    the running applications themselves are not directly affected by Argo CD’s downtime;
    they will continue to operate as configured prior to the outage. However, to manage
    critical updates during such downtimes, teams might need to perform manual interventions,
    which should be handled carefully to avoid further complications once Argo CD
    resumes normal operation. Robust monitoring and alert systems are recommended
    to quickly detect any issues with Argo CD and to minimize the impact of such downtimes.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Argo CD 发生短暂停机时，主要的影响是 Kubernetes 环境中部署的同步和自动对比过程。在此期间，提交到 Git 仓库的任何更改都不会与
    Kubernetes 集群同步，这意味着更新、修复和新功能的部署会被推迟。自动对比过程——即确保 Kubernetes 环境的实际状态与 Git 仓库中指定的期望状态相匹配——也会中断。这意味着，在停机期间发生的任何不一致或配置漂移都不会得到解决，直到
    Argo CD 恢复上线。恢复 Argo CD 后，它将自动开始处理并应用在停机期间所做的所有更改。系统将从 Git 获取最新的配置，并进行必要的对比，以使
    Kubernetes 集群与仓库中的期望状态保持一致。需要注意的是，运行中的应用程序本身不会受到 Argo CD 停机的直接影响；它们将继续按停机前的配置运行。然而，为了在此类停机期间管理关键更新，团队可能需要执行手动干预，这应该小心处理，以避免
    Argo CD 恢复正常运行后出现进一步的问题。建议采用强大的监控和警报系统，以快速检测 Argo CD 的任何问题，并最大限度地减少停机带来的影响。
- en: 'To see the new workflow in action, we need to replace the contents of the `gitops-for-real-ci-cd-pipeline.yml`
    file in the `Step-02-ArgoCD-Deployment` folder with the contents of the file named
    in the same manner located in the `.github/workflows` subdirectory. We must then
    commit and push the updated code to trigger a workflow run, as illustrated in
    *Figure 11**.7*:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要查看新工作流的运行效果，我们需要将 `Step-02-ArgoCD-Deployment` 文件夹中 `gitops-for-real-ci-cd-pipeline.yml`
    文件的内容替换为 `.github/workflows` 子目录中同名文件的内容。然后，我们必须提交并推送更新的代码，以触发工作流的运行，如*图 11.7*所示：
- en: '![Figure 11.7 – A new workflow run is triggered after the commit and push of
    the new workflow definition](img/B22100_11_07.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.7 – 在提交并推送新的工作流定义后触发一个新的工作流运行](img/B22100_11_07.jpg)'
- en: Figure 11.7 – A new workflow run is triggered after the commit and push of the
    new workflow definition
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7 – 在提交并推送新的工作流定义后触发一个新的工作流运行
- en: 'The external IP and the admin password that were automatically generated during
    the setup process can be found in the log of the `Setup ArgoCD on AKS` task, as
    illustrated in *Figure 11**.8*. Be careful: this kind of information should not
    be exposed in real production environments. It is just a shortcut for the scope
    of this example.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置过程中自动生成的外部 IP 和管理员密码可以在 `Setup ArgoCD on AKS` 任务的日志中找到，如*图 11.8*所示。请注意：此类信息不应在实际生产环境中公开。这只是本示例范围内的一个快捷方式。
- en: '![Figure 11.8 – The Setup ArgoCD on AKS task log containing sensitive information](img/B22100_11_08.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图11.8 – 包含敏感信息的AKS上设置ArgoCD任务日志](img/B22100_11_08.jpg)'
- en: Figure 11.8 – The Setup ArgoCD on AKS task log containing sensitive information
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.8 – 包含敏感信息的AKS上设置ArgoCD任务日志
- en: 'At this point, we can log in to the admin UI of the deployed instance of Argo
    CD by typing [https://4.226.41.44/](https://4.226.41.44/) into your preferred
    browser (see *Figure 11**.9*):'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们可以通过在首选浏览器中输入[https://4.226.41.44/](https://4.226.41.44/)来登录到已部署实例的Argo
    CD管理员界面（见*图11.9*）：
- en: '![Figure 11.9 – The Argo CD home page after logging in, showing the deployment
    of the backend-api-weather-app pod](img/B22100_11_09.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_IMG
  zh: '![图11.9 – 登录后的Argo CD主页，显示backend-api-weather-app pod的部署情况](img/B22100_11_09.jpg)'
- en: Figure 11.9 – The Argo CD home page after logging in, showing the deployment
    of the backend-api-weather-app pod
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.9 – 登录后的Argo CD主页，显示backend-api-weather-app pod的部署情况
- en: Voilà! For this example, we didn’t activate **auto-sync**, so we just need to
    click on the **Sync Apps** button to synchronize our weather app application,
    as illustrated in *figure 11.10*.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！在这个例子中，我们没有启用**自动同步**，所以我们只需要点击**同步应用**按钮来同步我们的天气应用，如*图11.10*所示。
- en: '![Figure 11.10 – The Argo CD application is correctly synchronized with the
    GitHub repository](img/B22100_11_10.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![图11.10 – Argo CD应用已正确同步到GitHub仓库](img/B22100_11_10.jpg)'
- en: Figure 11.10 – The Argo CD application is correctly synchronized with the GitHub
    repository
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.10 – Argo CD应用已正确同步到GitHub仓库
- en: 'To test the Argo CD synchronization process, try changing the number of replicas
    from `1` to `5` (for instance) in the `backend-api-deployment.yaml` file and pushing
    the change to GitHub. The workflow will not be triggered because we specified
    the following value:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试Argo CD的同步过程，尝试将`backend-api-deployment.yaml`文件中的副本数量从`1`更改为`5`（例如），并将更改推送到GitHub。由于我们指定了以下值，工作流不会被触发：
- en: '[PRE7]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: However, Argo CD will notice the out-of-sync state and a new synchronization
    will be needed. Now that we have our CI/CD pipeline in place and working perfectly,
    it is time to introduce the topics of scalability and efficiency in the next section.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Argo CD会注意到不同步的状态，并且需要进行新的同步。现在，我们已经建立并完美运行了CI/CD流水线，接下来是介绍下一节中的可扩展性和效率主题。
- en: Designing for scalability and efficiency
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可扩展性和效率设计
- en: In this section, we will delve into designing for scalability and efficiency.
    These traits are essential in the architecture of modern applications, exemplified
    by our weather app. Scalability ensures that the application can handle growth,
    whether it’s an increasing number of users, data volume, or transaction frequency,
    without compromising performance. Efficiency involves optimizing resource use,
    which is crucial for minimizing costs and enhancing response times. We will explore
    architectural principles that support scalability, such as **microservices** and
    load balancing, and discuss how to manage compute, storage, and networking resources
    effectively. Additionally, we will look at tools and strategies to test scalability
    to ensure that the architecture can withstand real-world demands. By mastering
    these elements, you’ll learn how to design a scalable and efficient architecture
    that is well-suited for deployment on Kubernetes, enhancing the overall performance
    and reliability of applications such as our weather app.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将深入探讨可扩展性和效率的设计。这些特性在现代应用程序的架构中至关重要，以我们的天气应用为例。可扩展性确保应用能够应对增长，无论是用户数量、数据量还是交易频率的增加，而不会影响性能。效率则涉及资源使用的优化，对于降低成本和提高响应速度至关重要。我们将探讨支持可扩展性的架构原则，例如**微服务**和负载均衡，并讨论如何有效管理计算、存储和网络资源。此外，我们还将研究测试可扩展性的工具和策略，以确保架构能够应对现实世界的需求。通过掌握这些元素，你将学会如何设计一个可扩展且高效的架构，这种架构非常适合部署在Kubernetes上，提升像我们的天气应用这样的应用的整体性能和可靠性。
- en: Architectural principles
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 架构原则
- en: Architectural principles for designing scalable and efficient systems are critical
    in modern application development, especially as demands for performance and reliability
    increase. Key strategies include decoupling components to minimize dependencies,
    which facilitates easier maintenance and scaling. Emphasizing statelessness allows
    for the replication and distribution of components, enhancing the application’s
    resilience and responsiveness.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 设计可扩展和高效系统的架构原则在现代应用开发中至关重要，尤其是当对性能和可靠性的需求增加时。关键策略包括解耦组件以最小化依赖关系，从而便于维护和扩展。强调无状态性允许组件的复制和分布，从而增强应用的韧性和响应能力。
- en: Load balancing is essential to distribute incoming network loads evenly across
    multiple systems, preventing any single server from becoming overwhelmed and increasing
    the application’s availability. Horizontal scaling, or scaling out by adding more
    instances rather than adding resources to a single instance, is more cost-effective
    and increases fault tolerance.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 负载均衡对于将传入的网络负载均匀分配到多个系统至关重要，防止任何单一服务器过载，并提高应用的可用性。横向扩展，即通过增加更多实例而不是为单一实例增加资源，是一种更具成本效益的方式，并且提高了容错能力。
- en: Database sharding partitions data into smaller, more manageable segments, which
    is particularly beneficial for large datasets or high throughput demands. Sharding
    is great for improving performance. Caching frequently accessed data reduces latency
    and backend load by serving common requests without redundant data processing.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库分片将数据划分为更小、更易管理的部分，尤其对大数据集或高吞吐量的需求非常有益。分片有助于提升性能。缓存常访问的数据可以通过直接处理常见请求而不进行冗余数据处理，减少延迟并降低后端负载。
- en: Asynchronous processing of tasks enhances throughput and user experience by
    handling operations in a non-blocking manner. Adopting a microservices architecture
    allows for independent deployment, scaling, and management of each service. This
    modular approach not only boosts performance but also simplifies management as
    applications evolve, making it ideal for cloud-native environments managed by
    platforms such as Kubernetes. Although microservices architecture has been mentioned,
    it will not be part of the example discussed in this chapter.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 异步处理任务通过以非阻塞方式处理操作，提升了吞吐量和用户体验。采用微服务架构允许每个服务独立部署、扩展和管理。这种模块化方法不仅提高了性能，而且随着应用的演变简化了管理，使其非常适合由如Kubernetes这样的平台管理的云原生环境。尽管提到了微服务架构，但它不会是本章讨论的示例的一部分。
- en: Microservices architecture
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构
- en: Microservices architecture is an architectural style that structures an application
    as a collection of loosely coupled services, each of which implements a specific
    business capability. This approach enables developers to build and deploy services
    independently, which enhances flexibility and accelerates development cycles.
    By breaking down an application into small, manageable components, microservices
    allow for more granular scaling and efficient resource utilization. Each service
    can be developed, deployed, and scaled independently, often using different programming
    languages and technologies that best suit the task at hand. This modularity improves
    fault isolation, making it easier to identify and fix issues without affecting
    the entire system. Moreover, microservices facilitate CI/CD practices, promoting
    a more agile and resilient development process. Overall, microservice architecture
    fosters a more robust and scalable application environment that is capable of
    adapting to evolving business needs and technological advancements.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构是一种将应用结构化为一组松耦合服务的架构风格，每个服务实现特定的业务功能。这种方法使开发者能够独立构建和部署服务，从而提高灵活性并加速开发周期。通过将应用拆解为小的、可管理的组件，微服务使得更精细的扩展和高效的资源利用成为可能。每个服务都可以独立开发、部署和扩展，通常使用最适合任务的不同编程语言和技术。这种模块化提高了故障隔离，使得在不影响整个系统的情况下，更容易识别和修复问题。此外，微服务促进了CI/CD实践，推动了更加敏捷和韧性的开发过程。总体来说，微服务架构促进了一个更强大、更具可扩展性的应用环境，能够适应不断变化的业务需求和技术进步。
- en: Resource management
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 资源管理
- en: 'Effective resource management is crucial in application design and operation,
    especially in environments that aim to maximize efficiency and performance while
    minimizing costs. Managing compute, storage, and networking resources involves
    careful planning and orchestration to ensure that each component of an application
    has the necessary resources to perform optimally without wastage:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的资源管理在应用设计和操作中至关重要，特别是在那些旨在最大化效率和性能，同时最小化成本的环境中。管理计算、存储和网络资源需要精心规划和协调，以确保应用的每个组件都拥有足够的资源，能够在没有浪费的情况下发挥最佳性能：
- en: '**Compute management**: This involves provisioning the right amount of CPU
    and memory resources to meet the application’s requirements. Techniques such as
    **auto-scaling** and load balancing help distribute compute workloads evenly across
    the available infrastructure.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算管理**：涉及为满足应用需求而提供适当数量的 CPU 和内存资源。像**自动扩展**和负载均衡等技术有助于将计算工作负载均匀分配到可用基础设施上。'
- en: '**Storage management**: This ensures that data storage resources are allocated
    efficiently, keeping data accessibility and redundancy in mind. This includes
    choosing appropriate storage types and implementing data partitioning strategies
    to enhance performance and scalability.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储管理**：确保数据存储资源得以高效分配，同时考虑数据的可访问性和冗余性。这包括选择适当的存储类型和实施数据分区策略，以提高性能和可扩展性。'
- en: '**Networking management**: This focuses on efficiently configuring network
    resources to ensure fast and secure data transfer between application components.
    Proper network configuration reduces latency and prevents bottlenecks, making
    it essential for real-time data processing and delivery.'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络管理**：重点在于高效配置网络资源，以确保应用组件之间的数据传输快速且安全。适当的网络配置能够减少延迟，防止瓶颈，这对于实时数据处理和交付至关重要。'
- en: Together, these resource management practices ensure that applications can scale
    effectively and remain robust under varying operational conditions. Implementing
    resource management strategies also involves monitoring and analyzing resource
    usage to make informed decisions about adjustments and improvements, ensuring
    that resources are utilized in the most efficient way possible.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这些资源管理实践共同确保应用能够有效扩展，并在不同的操作条件下保持稳健。实施资源管理策略还需要监控和分析资源使用情况，以做出明智的调整和改进决策，确保资源以最有效的方式被利用。
- en: Testing for scalability
  id: totrans-123
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 可扩展性测试
- en: 'Testing for scalability is crucial for ensuring that applications perform well
    under expected loads and can handle growth in users, transactions, and data efficiently.
    Scalability testing involves a variety of techniques to simulate different environments
    and stresses on the system to uncover potential issues before they impact users:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 可扩展性测试对于确保应用在预期负载下能够良好运行，并且能够高效处理用户、事务和数据的增长至关重要。可扩展性测试涉及多种技术，模拟不同的环境和系统压力，旨在在问题影响用户之前发现潜在问题：
- en: '**Load testing**: Simulates a specific expected number of concurrent users
    or transactions to assess how the application behaves under normal conditions'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载测试**：模拟特定预期数量的并发用户或事务，以评估应用在正常条件下的表现。'
- en: '**Stress testing**: Pushes the application beyond its normal operational limits
    to discover its maximum capacity and understand its behavior under extreme conditions'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**压力测试**：将应用推向其正常操作极限，以发现其最大容量并了解其在极端条件下的行为。'
- en: '**Soak testing**: Runs the application under a heavy load for a prolonged period
    to identify issues such as memory leaks or slow degradation of performance'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**浸泡测试**：在重负载下长时间运行应用，以发现如内存泄漏或性能逐渐下降等问题。'
- en: '**Spike testing**: Checks the application’s ability to handle sudden and large
    spikes in traffic'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**激增测试**：检查应用在面对突如其来的大量流量时的处理能力。'
- en: '**Scalability testing**: Tests whether the application can scale up or down
    based on demand by gradually increasing the load and observing how additional
    resources affect the application’s capacity'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性测试**：通过逐步增加负载并观察额外资源如何影响应用的容量，测试应用是否能够根据需求进行扩展或缩减。'
- en: These tests often utilize automated testing tools and are conducted in staged
    environments that closely mimic real-world traffic patterns. Tools such as **Apache
    JMeter**, **LoadRunner**, and **Gatling**, along with cloud services such as **AWS
    CloudWatch** and **Google Cloud Monitoring**, are commonly employed to facilitate
    these tests. Through regular scalability testing across development and deployment
    phases, teams can ensure that their applications are robust, scalable, and ready
    to handle real-world operational demands.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这些测试通常使用自动化测试工具，并在阶段性环境中进行，这些环境非常接近真实的流量模式。诸如**Apache JMeter**、**LoadRunner**和**Gatling**等工具，以及**AWS
    CloudWatch**和**Google Cloud Monitoring**等云服务，通常用于促进这些测试。通过在开发和部署阶段进行定期的可扩展性测试，团队可以确保他们的应用程序是强健的、可扩展的，并能够应对真实世界的操作需求。
- en: Resources management and scalability
  id: totrans-131
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 资源管理与可扩展性
- en: In this section, we will continue to use the weather app to see how resource
    management, horizontal scaling, and scalability testing work in a real-world scenario.
    We can start with the optimization of resource usage.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将继续使用天气应用程序，看看资源管理、水平扩展和可扩展性测试在实际场景中的运作方式。我们可以从资源使用优化开始。
- en: Optimizing resource usage
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 优化资源使用
- en: 'To optimize resource usage in Kubernetes, setting up resource requests and
    limits is crucial. These settings ensure that pods receive the right amount of
    CPU and memory resources to function properly while also preventing any single
    application from consuming excessive cluster resources, which could affect other
    applications:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化Kubernetes中的资源使用，设置资源请求和限制至关重要。这些设置确保Pod获得正确数量的CPU和内存资源以正常运行，同时也防止任何单个应用程序消耗过多的集群资源，从而影响其他应用程序：
- en: '**Requests**: These are the amount of resources Kubernetes guarantees for a
    container. If a container requires more resources than its request and they are
    available on the node, it can consume more.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Requests**：这是Kubernetes为容器保证的资源数量。如果容器所需的资源超过其请求并且节点上有足够的资源，它可以消耗更多的资源。'
- en: '**Limits**: This is the maximum amount of resources a container can use. If
    a container tries to exceed this limit, the system will throttle its CPU usage.
    If the container exceeds its memory limit, Kubernetes might terminate it, depending
    on the situation.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Limits**：这是容器可以使用的最大资源数量。如果容器尝试超过此限制，系统将限制其CPU使用。如果容器超过其内存限制，Kubernetes可能会终止它，具体情况取决于当时的情况。'
- en: 'To test the use of requests and limits, we can try to update the `Step-01/deployment/backend-api-deployment.yaml`
    file by adding the following code block immediately after `key:` `WEATHER_API_KEY
    row`:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试请求和限制的使用，我们可以尝试更新`Step-01/deployment/backend-api-deployment.yaml`文件，在`key:`
    `WEATHER_API_KEY row`之后立即添加以下代码块：
- en: '[PRE8]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The previously mentioned code block specifies the resource requests and limits
    for a container. Here’s what each line means:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 前面提到的代码块指定了容器的资源请求和限制。以下是每行代码的含义：
- en: '`requests`:'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`requests`：'
- en: '`cpu: "100m"`: This requests 100 millicores (where 1,000 m equals 1 CPU core)
    for the container'
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cpu: "100m"`：这请求容器使用100毫核（1,000毫核等于1个CPU核心）'
- en: '`memory: "100Mi"`: This requests 100 mebibytes of memory'
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`memory: "100Mi"`：这请求100 MiB的内存'
- en: '`limits`:'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`limits`：'
- en: '`cpu: "150m"`: This sets a limit of 150 millicores for CPU usage by the container'
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cpu: "150m"`：这设置了容器CPU使用的150毫核限制'
- en: '`memory: "150Mi"`: This sets a memory limit of 150 mebibytes'
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`memory: "150Mi"`：这设置了150 MiB的内存限制'
- en: Now that we have defined requests and limits, in the next section, we will see
    how to implement the **Horizontal Pod Autoscaler** (**HPA**) in the next section.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经定义了请求和限制，在下一节中，我们将看到如何在下一节中实现**水平Pod自动扩展器**（**HPA**）。
- en: Implementing the HPA
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 实现HPA
- en: 'Implementing an HPA in Kubernetes is an effective way to automatically scale
    the number of pod replicas in a deployment, replication controller, or replica
    set based on observed CPU utilization or other select metrics such as memory usage
    or custom metrics. Here’s a step-by-step guide to setting up an HPA:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中实现HPA是一种有效的方法，可以根据观察到的CPU利用率或其他选定的度量标准（如内存使用或自定义指标）自动扩展部署、复制控制器或副本集中的Pod副本数量。以下是设置HPA的逐步指南：
- en: 'Ensure that the **Metrics Server**, which collects resource metrics from Kubelets
    and exposes them in Kubernetes through the Metrics API, is installed in the cluster.
    This is crucial for the HPA to make scaling decisions. We can install it with
    the following command:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保 **Metrics Server** 已在集群中安装，该服务器从 Kubelets 收集资源指标，并通过 Kubernetes 的 Metrics
    API 将其暴露。这个组件对于 HPA 做出扩缩容决策至关重要。我们可以使用以下命令进行安装：
- en: '[PRE9]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Setup will take a few minutes. At completion, verify the correct installation
    with the following command:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置过程将需要几分钟时间。完成后，请使用以下命令验证安装是否正确：
- en: '[PRE10]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This command should return the deployment details confirming that the Metrics
    Server is up and running:'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该命令应返回部署详情，确认 Metrics Server 已启动并运行：
- en: '[PRE11]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Create an HPA that scales based on CPU utilization:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个基于 CPU 利用率进行扩缩容的 HPA：
- en: '[PRE12]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This HPA is configured to maintain between `1` and `5` replicas of the pod,
    scaling up or down when the CPU utilization reaches 50%.
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该 HPA 配置为保持 pod 数量在 `1` 到 `5` 之间，当 CPU 利用率达到 50% 时进行扩缩容。
- en: Create a new `hpa.yaml` file in the `Step-01/deployment` folder with the content
    that we have described. Commit and push the code, then wait for the Argo CD application
    synchronization or force it if auto-sync is off.
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `Step-01/deployment` 文件夹中创建一个新的 `hpa.yaml` 文件，内容如我们所描述。提交并推送代码，然后等待 Argo CD
    应用程序同步，或者如果自动同步关闭，则强制同步。
- en: '![Figure 11.11– The Argo CD application synchronized with the HPA configuration
    in place](img/B22100_11_11.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.11– Argo CD 应用程序与 HPA 配置同步](img/B22100_11_11.jpg)'
- en: Figure 11.11– The Argo CD application synchronized with the HPA configuration
    in place
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.11– Argo CD 应用程序与 HPA 配置同步
- en: 'Use the following command to monitor the status and effectiveness of your HPA:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令监控你的 HPA 状态和效果：
- en: '[PRE13]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This will show the current number of replicas and whether the HPA is in the
    process of scaling up or down based on the current CPU utilization against the
    target set.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这将显示当前的副本数，并显示 HPA 是否正在根据当前的 CPU 利用率对比设置目标进行扩缩容。
- en: Testing for scalability – an example
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试可扩展性——一个示例
- en: 'Now that we have implemented the HPA and set up monitoring for it, our next
    step is to observe how Kubernetes dynamically scales the number of pods in response
    to changes in CPU utilization. By simulating varying loads, we can watch the HPA
    adjust the pod count to maintain optimal performance. This process ensures that
    our application scales efficiently, handling increases or decreases in demand
    without manual intervention. Understanding this behavior is crucial for optimizing
    resource management and cost-effectiveness within our Kubernetes environment.
    What follows is a guided step-by-step testing scenario:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经实现了 HPA 并设置了监控，接下来的步骤是观察 Kubernetes 如何根据 CPU 利用率变化动态地扩缩容 pod 数量。通过模拟不同的负载，我们可以看到
    HPA 如何调整 pod 数量以保持最佳性能。这个过程确保我们的应用能够高效扩展，自动应对需求的增加或减少，而无需人工干预。理解这一行为对于优化 Kubernetes
    环境中的资源管理和成本效益至关重要。以下是逐步测试场景：
- en: 'Create a Bash script for testing HPA. Use the `curl` command to make requests
    to the exposed weather service using various cities and include a random value
    in the query string to avoid caching. You can use the `hpa-testing.sh` script
    present in the repository accompanying this chapter as reference. Before executing
    the script, update `$baseUrl` to match your weather service’s URL. This might
    look as follows:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个用于测试 HPA 的 Bash 脚本。使用 `curl` 命令对暴露的天气服务发起请求，使用不同的城市，并在查询字符串中加入随机值以避免缓存。你可以参考本章附带的
    `hpa-testing.sh` 脚本。在执行脚本之前，请更新 `$baseUrl`，使其与天气服务的 URL 匹配。具体如下所示：
- en: '[PRE14]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Run this Bash script:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行该 Bash 脚本：
- en: 'Open a new terminal and make the script executable with the following:'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开一个新的终端，并使用以下命令使脚本可执行：
- en: '[PRE15]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Check the HPA status (see the sixth point in the *Implementing the HPA* section
    of this chapter). Use the following command to check the HPA status:'
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 HPA 状态（参见本章 *实现 HPA* 部分的第六点）。使用以下命令检查 HPA 状态：
- en: '[PRE16]'
  id: totrans-172
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You should see the current number of replicas and their scaling activities
    based on the CPU utilization:'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你应该看到当前的副本数以及它们基于 CPU 利用率的扩缩容活动：
- en: '[PRE17]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The HPA monitors the CPU utilization of the deployment and adjusts the number
    of pods accordingly to ensure optimal performance.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: HPA 监控部署的 CPU 利用率，并根据需要调整 pod 数量，以确保最佳性能。
- en: Initially, the CPU utilization is marked as `<unknown>`, likely due to metrics
    not being available or still being initialized. When the utilization stabilizes
    at 5%, which matches the target set in the HPA, there’s no change in the number
    of replicas and they remain at one. As CPU usage increases to 20%—well above the
    5% target—the HPA reacts by scaling up the number of replicas from `1` to `4`
    to handle the increased load.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 最初，CPU 使用率标记为`<unknown>`，这可能是由于指标不可用或仍在初始化。当使用率稳定在 5% 时，且与 HPA 中设置的目标匹配，副本数量没有变化，仍保持为一个。当
    CPU 使用率增加到 20%——远高于 5% 的目标时，HPA 通过将副本数量从`1`扩展到`4`来应对增加的负载。
- en: This elevated level of resource use persists briefly, keeping the replicas at
    `4`. However, when the utilization drops significantly to 3% and further down
    to 1%, the HPA initially doesn’t scale down immediately, possibly due to stabilization
    settings that prevent oscillations in pod count. Ultimately, as the low utilization
    continues, the HPA scales the number of pods back down to `1`.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 这种较高水平的资源使用持续了一段时间，副本数保持在`4`。然而，当使用率显著下降至 3% 并进一步下降到 1% 时，HPA 最初并未立即缩减副本数，这可能是由于稳定性设置防止了
    Pod 数量的波动。最终，随着低使用率的持续，HPA 将 Pod 数量缩减回`1`。
- en: This sequence demonstrates the HPA’s capability to dynamically scale application
    resources based on real-time data, thus ensuring that the deployment scales efficiently
    in response to workload changes. This dynamic adjustment helps manage resources
    effectively, maintaining application responsiveness and optimizing operational
    costs. The responsiveness of the HPA to changes in CPU utilization exemplifies
    how Kubernetes can automate scaling to maintain performance and resource efficiency
    without manual intervention.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 该序列展示了 HPA 根据实时数据动态扩展应用资源的能力，从而确保部署能够高效地响应工作负载变化。这种动态调整有助于有效管理资源，保持应用响应能力并优化运营成本。HPA
    对 CPU 使用率变化的响应示例了 Kubernetes 如何自动调整扩展，以保持性能和资源效率，而无需人工干预。
- en: As we ensure efficient resource management and scalability, it is equally important
    to turn our attention to monitoring and securing your application. In the next
    section, we will explore these crucial aspects of operational excellence.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在确保资源管理和可扩展性的同时，关注监控和保护应用程序同样重要。在接下来的部分，我们将探讨运营卓越的这些关键方面。
- en: Monitoring and securing your application
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控和保护你的应用程序
- en: Operational excellence in software deployment and management is a crucial factor
    for the success of any technology-driven organization. The keys to achieving this
    excellence are monitoring, scaling, and security, each serving as foundational
    pillars that ensure the smooth and efficient operation of applications in production
    environments.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 软件部署和管理中的运营卓越是任何技术驱动型组织成功的关键因素。实现这一卓越的关键在于监控、扩展和安全，这三者作为基础支柱，确保了应用程序在生产环境中的平稳高效运行。
- en: Monitoring is vital as it provides the visibility needed to understand the behavior
    of applications and systems in real time. Effective monitoring strategies help
    in identifying performance bottlenecks, predicting system failures, and gathering
    valuable data to aid in decision-making processes. This continuous oversight allows
    teams to respond proactively to issues before they affect the user experience
    or lead to more significant disruptions.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 监控至关重要，因为它提供了实时了解应用程序和系统行为所需的可见性。有效的监控策略有助于识别性能瓶颈、预测系统故障，并收集有价值的数据，以支持决策过程。这种持续的监督使团队能够主动响应问题，在它们影响用户体验或导致更大干扰之前解决问题。
- en: Security practices are critical to safeguard sensitive data and protect infrastructures
    from breaches and attacks. In an era where cyber threats are evolving rapidly,
    ensuring that robust security measures are in place is non-negotiable. Security
    protocols help in maintaining trust with customers, complying with regulatory
    requirements, and avoiding the financial and reputational damage associated with
    data breaches.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 安全实践对于保护敏感数据和防止基础设施受到入侵和攻击至关重要。在网络威胁迅速演变的时代，确保采取强有力的安全措施是不可谈判的。安全协议有助于维护与客户的信任，遵守监管要求，并避免与数据泄露相关的财务和声誉损害。
- en: Together, monitoring, scaling, and security form the backbone of operational
    excellence, supporting a stable, efficient, and secure environment for deploying
    and managing applications. Organizations that master these aspects are better
    positioned to leverage technology for business success, ensuring that they can
    deliver continuous value to users while adapting to the ever-changing digital
    landscape.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 监控、扩展和安全构成了运营卓越的支柱，支持一个稳定、高效、安全的环境，用于部署和管理应用程序。掌握这些方面的组织更能有效地利用技术推动业务成功，确保在不断变化的数字环境中持续为用户创造价值。
- en: Monitoring
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控
- en: 'Grafana and Prometheus are powerful tools that are widely used in the monitoring
    and observability landscape. They are particularly valuable for managing cloud-native
    applications deployed in dynamic environments such as Kubernetes:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana 和 Prometheus 是广泛使用的强大工具，在监控和可观察性领域中具有重要价值。它们对于管理在动态环境中部署的云原生应用（如 Kubernetes）尤其有用：
- en: '**Prometheus**: Prometheus is an open source monitoring system with a robust
    query language. It collects and stores its metrics as time-series data, meaning
    that each metric is stored with its exact time of recording. Prometheus is highly
    effective for recording real-time metrics in a high-availability environment.
    It supports a pull model for fetching data from monitored services, allowing it
    to actively scrape data from registered targets at specified intervals. This data
    can then be queried and analyzed to monitor the health and performance of applications.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus**：Prometheus 是一个开源的监控系统，具有强大的查询语言。它将度量值作为时间序列数据收集和存储，这意味着每个度量值都会记录其准确的时间。Prometheus
    在高可用性环境中记录实时度量值非常有效。它支持通过拉取模型从监控服务中获取数据，允许它按照指定的间隔主动抓取来自注册目标的数据。然后可以查询和分析这些数据，以监控应用程序的健康状况和性能。'
- en: '**Grafana**: Grafana is an open source analytics and visualization platform
    that integrates seamlessly with a multitude of data sources, including Prometheus.
    Grafana is used to create comprehensive dashboards that provide visualizations
    of metrics data. These dashboards allow developers and operations teams to visually
    interpret complex data to understand application behavior and resource usage,
    making it easier to spot trends, patterns, and potential problems.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Grafana**：Grafana 是一个开源的分析和可视化平台，能够与多种数据源（包括 Prometheus）无缝集成。Grafana 用于创建全面的仪表板，提供度量数据的可视化。这些仪表板帮助开发人员和运维团队通过可视化的方式解读复杂数据，理解应用程序的行为和资源使用，从而更容易发现趋势、模式和潜在问题。'
- en: Together, Prometheus and Grafana offer a powerful combination for data gathering,
    storage, and visualization, enhancing the ability to observe system behaviors,
    troubleshoot issues, and ensure that system performance aligns with user expectations
    and business objectives. This duo is particularly effective in a DevOps context,
    where continuous monitoring and feedback loops are critical to the software development
    and deployment life cycle.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 结合使用，Prometheus 和 Grafana 提供了强大的数据收集、存储和可视化组合，增强了观察系统行为、排查问题以及确保系统性能与用户期望和业务目标一致的能力。这个组合在
    DevOps 环境中尤为有效，持续监控和反馈回路对软件开发和部署生命周期至关重要。
- en: Setting up Prometheus and Grafana
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 Prometheus 和 Grafana
- en: 'The following are the necessary steps to set up Prometheus and Grafana on the
    AKS cluster:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是设置 Prometheus 和 Grafana 在 AKS 集群上的必要步骤：
- en: 'Add the Prometheus and Grafana Helm chart repository:'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加 Prometheus 和 Grafana Helm chart 仓库：
- en: '[PRE18]'
  id: totrans-193
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Update the Helm repository. Ensure that we are using the most up-to-date version:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新 Helm 仓库。确保我们使用的是最新版本：
- en: '[PRE19]'
  id: totrans-195
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: $ helm install prometheus \
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: $ helm install prometheus \
- en: prometheus-community/kube-prometheus-stack \
  id: totrans-197
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: prometheus-community/kube-prometheus-stack \
- en: --namespace gitops-real-monitoring \
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: --namespace gitops-real-monitoring \
- en: --create-namespace
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: --create-namespace
- en: '[PRE20]'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Check the entire deployment by typing the following command:'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入以下命令检查整个部署：
- en: '[PRE21]'
  id: totrans-202
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: admin username the password defined for the prom-operator.
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: admin 用户名和为 prom-operator 定义的密码。
- en: '[PRE22]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Expose Prometheus using the following command:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令暴露 Prometheus：
- en: '[PRE23]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'After logging in, you should be able to see the Grafana homepage. Click on
    the **Dashboards** menu item as illustrated in *Figure 11**.12*:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录后，你应该能够看到 Grafana 的主页。点击**仪表板**菜单项，如*图 11.12*所示：
- en: '![Figure 11.12 – The Grafana home page, with the Dashboards menu item highlighted](img/B22100_11_12.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.12 – Grafana 首页，突出显示仪表板菜单项](img/B22100_11_12.jpg)'
- en: Figure 11.12 – The Grafana home page, with the Dashboards menu item highlighted
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.12 – Grafana首页，突出显示仪表板菜单项
- en: Click on `weather-app-for-real`. You will see some interesting metrics on the
    Pods that are running there, as illustrated in *Figure 11**.13*.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`weather-app-for-real`。你将看到一些关于正在运行的Pods的有趣指标，如*图11.13*所示。
- en: '![Figure 11.13 – CPU, memory, and other metrics for the backend-api-weather
    pod](img/B22100_11_13.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![图11.13 – `backend-api-weather` Pod的CPU、内存及其他指标](img/B22100_11_13.jpg)'
- en: Figure 11.13 – CPU, memory, and other metrics for the backend-api-weather pod
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.13 – `backend-api-weather` Pod的CPU、内存及其他指标
- en: 'At this point, you have correctly and successfully set up Grafana and Prometheus.
    Now, you can see interesting statistics about the usage of `backend-api-weather-app`,
    which can be used to fine-tune the resource limits and requests, as discussed
    in the *Optimize resource usage* section of this chapter. In the next section,
    we will introduce another important aspect of Kubernetes management in the real
    world: Kubernetes security.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你已经正确并成功地设置了Grafana和Prometheus。现在，你可以查看关于`backend-api-weather-app`使用情况的有趣统计数据，这些数据可以用来微调资源限制和请求，正如本章的*优化资源使用*部分所讨论的那样。在接下来的部分，我们将介绍Kubernetes管理中的另一个重要方面：Kubernetes安全性。
- en: Understanding Kubernetes security
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解Kubernetes安全性
- en: 'Kubernetes, while robust and scalable, presents a unique set of security challenges
    that stem from its dynamic and distributed nature. Securing a Kubernetes cluster
    involves safeguarding the infrastructure, the applications running on it, and
    the data that it processes. Given the complexity of Kubernetes environments, security
    must be integrated into every layer of the cluster. Key aspects of Kubernetes
    security include the following:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes虽然强大且可扩展，但也带来了独特的安全挑战，这些挑战源于其动态和分布式的特性。保护Kubernetes集群涉及保护基础设施、运行其上的应用程序以及它所处理的数据。鉴于Kubernetes环境的复杂性，安全性必须集成到集群的每一层。Kubernetes安全的关键方面包括以下几点：
- en: '**Authentication and authorization**: This ensures that only verified users
    can access the cluster with methods such as certificates and tokens. It also controls
    user actions using mechanisms such as RBAC and **Attributed-Based Access** **Control**
    (**ABAC**).'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**身份验证与授权**：确保只有经过验证的用户才能访问集群，方法包括证书和令牌等。它还通过RBAC和**基于属性的访问控制**（**ABAC**）等机制控制用户的操作。'
- en: '**API security**: Protecting the Kubernetes API server, which acts as the central
    control unit for the cluster, is crucial. Securing access to the API involves
    using SSL/TLS encryption, API request auditing, and limiting IP access through
    network policies.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API安全性**：保护Kubernetes API服务器（它充当集群的中央控制单元）至关重要。保护API访问包括使用SSL/TLS加密、API请求审计和通过网络策略限制IP访问。'
- en: '**Network security**: Enforcing policies that control the flow of traffic between
    pods and external networks helps prevent unauthorized access and limits the potential
    for lateral movement within the cluster.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络安全**：强制执行控制Pod与外部网络之间流量的政策，有助于防止未经授权的访问，并限制集群内横向移动的潜力。'
- en: '**Pod security admission**: This is a Kubernetes admission controller that
    enforces security settings on pods at creation time, using predefined security
    profiles (**privileged**, **baseline**, and **restricted**) to ensure compliance
    with best security practices and prevent privilege escalations.'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pod安全准入**：这是一个Kubernetes准入控制器，在Pod创建时强制执行安全设置，使用预定义的安全配置文件（**特权**、**基准**和**受限**）确保符合最佳安全实践并防止权限升级。'
- en: '**Secrets management**: Kubernetes manages sensitive data (such as passwords
    and tokens) using secrets. Proper handling and security of secrets, including
    encryption at rest and in transit, is vital to protect sensitive information.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**秘密管理**：Kubernetes使用秘密来管理敏感数据（如密码和令牌）。正确处理和保护这些秘密，包括静态和传输中的加密，对于保护敏感信息至关重要。'
- en: The importance of a layered security approach
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 分层安全方法的重要性
- en: Given the complexities of Kubernetes, a single security measure is often not
    enough. A layered security approach that includes network segmentation, threat
    detection, secure access controls, and ongoing vulnerability management is crucial
    for protecting Kubernetes environments from threats.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于Kubernetes的复杂性，单一的安全措施通常不足以应对威胁。一个包含网络分段、威胁检测、安全访问控制和持续漏洞管理的分层安全方法对于保护Kubernetes环境免受威胁至关重要。
- en: In the next section, we will see a practical example of how to manage access
    to the weather app’s resources within a specific namespace using RBAC.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将看到一个实际示例，展示如何使用 RBAC 管理对特定命名空间中天气应用资源的访问。
- en: Configuring Kubernetes RBAC for user and role management
  id: totrans-224
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置 Kubernetes RBAC 进行用户和角色管理
- en: 'Here is a step-by-step guide to configuring RBAC for the weather app:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 这是配置天气应用 RBAC 的逐步指南：
- en: 'Define a role that specifies the permissions for managing specific resources
    related to the weather app, such as deployments, services, and pods within a designated
    namespace. The following are the definitions for the `weather-app-manager` role:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义一个角色，指定管理与天气应用相关的特定资源（例如部署、服务和 Pod）所需的权限，范围是在指定命名空间内。以下是 `weather-app-manager`
    角色的定义：
- en: '[PRE24]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'apiVersion: rbac.authorization.k8s.io/v1'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'apiVersion: rbac.authorization.k8s.io/v1'
- en: 'kind: Role'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 类型：Role
- en: 'metadata:'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 元数据：
- en: 'namespace: weather-app-for-real'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 命名空间：weather-app-for-real
- en: 'name: weather-app-user'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 名称：weather-app-user
- en: 'rules:'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 规则：
- en: '- apiGroups: ["", "apps"]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '- apiGroups: ["", "apps"]'
- en: 'resources: ["pods", "services"]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 资源：["pods", "services"]
- en: 'verbs: [RoleBinding resource to grant the specified role to a user. This binding
    will apply the weather-app-manager role to a user named weather-app-user:'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 动作：[RoleBinding 资源将指定的角色授予用户。此绑定将 `weather-app-manager` 角色应用于名为 `weather-app-user`
    的用户：
- en: '[PRE25]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Create another `RoleBinding` resource to grant the `weather-app-user` role
    to a user named `weather-app-operator`:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建另一个 `RoleBinding` 资源，将 `weather-app-user` 角色授予名为 `weather-app-operator` 的用户：
- en: '[PRE27]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Move the YAML files to the `Step-01/deployment` folder, push the changes to
    GitHub, and synchronize the Argo CD app.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 YAML 文件移动到 `Step-01/deployment` 文件夹，推送更改到 GitHub，并同步 Argo CD 应用程序。
- en: 'Verify that the `weather-app-user` and `weather-app-operator` users have the
    necessary permissions using the `kubectl auth` `can-i` command:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `kubectl auth` `can-i` 命令，验证 `weather-app-user` 和 `weather-app-operator`
    用户是否具备必要的权限：
- en: '[PRE28]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The expected output should be as follows:'
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预期的输出应该如下所示：
- en: '[PRE29]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can list all roles and role bindings in the namespace, or cluster roles
    affecting the user, with commands such as the following:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令列出命名空间中的所有角色和角色绑定，或列出影响用户的集群角色：
- en: '[PRE30]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: For reference, the `Step-03-Security` directory in the repository accompanying
    this chapter contains the YAML files with the role and role-binding definitions
    described so far.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 作为参考，本章附带的代码库中的 `Step-03-Security` 目录包含了迄今为止所描述的角色和角色绑定定义的 YAML 文件。
- en: Beware!
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 小心！
- en: To avoid incurring unexpected expenses due to Azure resources, please remember
    to destroy any undesired Azure provisioned resources.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 为避免因 Azure 资源而产生意外费用，请记得销毁任何不需要的 Azure 提供的资源。
- en: This section concludes our journey through a real-world GitOps pipeline and
    deployment. While an entire book might not be enough to delve deeply into every
    aspect of GitOps with Kubernetes, security, and deployments, we believe that the
    sections covered so far provide a comprehensive overview. They offer valuable
    insights into setting up an effective GitOps pipeline for your future Kubernetes
    projects.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分结束了我们对实际 GitOps 流水线和部署的探讨。虽然一本书可能不足以深入探讨 GitOps 与 Kubernetes、安全性和部署的每个方面，但我们相信，到目前为止所覆盖的章节提供了一个全面的概述。它们为设置有效的
    GitOps 流水线并应用于未来的 Kubernetes 项目提供了宝贵的见解。
- en: Summary
  id: totrans-252
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter provided a comprehensive guide to deploying real-world projects
    on Kubernetes with GitOps. By following the detailed instructions and examples,
    you learned how to set up a GitOps and Kubernetes development environment, implement
    CI/CD processes, design for scalability and efficiency, manage resources, and
    secure your application. This practical knowledge equipped you with the skills
    needed to effectively implement these cutting-edge technologies in your projects,
    enhancing your organizational capabilities and personal technical expertise.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了一个关于如何在 Kubernetes 上使用 GitOps 部署真实世界项目的综合指南。通过遵循详细的指示和示例，你学会了如何设置 GitOps
    和 Kubernetes 开发环境、实现 CI/CD 流程、进行可扩展性和高效性的设计、管理资源并保护应用程序。这些实践知识使你掌握了在项目中有效应用这些前沿技术的技能，增强了你的组织能力和个人技术专长。
- en: As you now have a solid foundation in deploying and managing applications with
    GitOps on Kubernetes, the next chapter will delve into observability with GitOps,
    providing essential strategies to monitor and gain insights into your applications’
    performance and health.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你已经在 Kubernetes 上使用 GitOps 部署和管理应用程序打下了坚实的基础，下一章将深入探讨 GitOps 的可观察性，提供监控和深入了解应用程序性能与健康的关键策略。
- en: 'Part 4: Operational Excellence Through GitOps Best Practices'
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第四部分：通过GitOps最佳实践实现运营卓越
- en: In this part, you will focus on achieving operational excellence through best
    practices in GitOps. You will learn about integrating observability, enhancing
    security, managing financial operations, and preparing for future trends in GitOps.
    This section aims to provide a comprehensive guide to maintaining high standards
    of operational efficiency and security, while also addressing sustainability and
    financial considerations, thus ensuring that your GitOps practices are both cutting
    edge and sustainable.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在本部分中，你将专注于通过GitOps中的最佳实践实现运营卓越。你将学习集成可观察性、增强安全性、管理财务运营以及为GitOps中的未来趋势做好准备。本节旨在提供一份全面的指南，以保持高标准的运营效率和安全性，同时考虑到可持续性和财务因素，确保你的GitOps实践既前沿又可持续。
- en: 'This part includes the following chapters:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 12*](B22100_12.xhtml#_idTextAnchor231), Observability with GitOps'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第12章*](B22100_12.xhtml#_idTextAnchor231)，GitOps中的可观察性'
- en: '[*Chapter 13*](B22100_13.xhtml#_idTextAnchor257), Security with GitOps'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第13章*](B22100_13.xhtml#_idTextAnchor257)，GitOps中的安全性'
- en: '[*Chapter 13*](B22100_13.xhtml#_idTextAnchor257), FinOps, Sustainability, AI,
    and Future Trends for GitOps'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第13章*](B22100_13.xhtml#_idTextAnchor257)，FinOps、可持续性、AI和GitOps的未来趋势'
