- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: StatefulSet – Deploying Stateful Applications
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: StatefulSet – 部署有状态应用程序
- en: In the previous chapter, we explained how to use a Kubernetes cluster to run
    *stateless* workloads and applications and how to use Deployment objects for this
    purpose. Running stateless workloads in the cloud is generally easier to handle,
    as any container replica can handle the request without taking any dependencies
    on the results of previous operations by the end user. In other words, every container
    replica would handle the request in an identical way; all you need to care about
    is proper load balancing.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们解释了如何使用 Kubernetes 集群运行 *无状态* 工作负载和应用程序，以及如何为此目的使用 Deployment 对象。 在云中运行无状态工作负载通常更容易处理，因为任何容器副本都可以处理请求，而无需依赖于用户先前操作的结果。换句话说，每个容器副本都会以相同的方式处理请求；你需要关心的只是适当的负载均衡。
- en: 'However, the main complexity is in managing the *state* of applications. By
    *state,* we mean any stored *data* that the application or component needs to
    serve the requests, and it can be modified by these requests. The most common
    example of a stateful component in applications is a database – for example, it
    can be a **relational MySQL database** or a **NoSQL MongoDB database**. In Kubernetes,
    you can use a dedicated object to run *stateful* workloads and applications: StatefulSet.
    When managing StatefulSet objects, you will usually need to work with Persistent
    Volumes (PVs), which have been covered in *Chapter 9*, *Persistent Storage in
    Kubernetes*. This chapter will provide you with knowledge about the role of StatefulSet
    in Kubernetes and how to create and manage StatefulSet objects to release new
    versions of your stateful applications.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，主要的复杂性在于管理应用程序的 *状态*。这里的 *状态* 指的是应用程序或组件需要存储的 *数据*，这些数据用于服务请求，并且可以被这些请求修改。应用程序中最常见的有状态组件是数据库——例如，它可以是
    **关系型 MySQL 数据库** 或 **NoSQL MongoDB 数据库**。在 Kubernetes 中，你可以使用专门的对象来运行 *有状态* 工作负载和应用程序：StatefulSet。在管理
    StatefulSet 对象时，你通常需要与 Persistent Volumes (PVs) 一起工作，这部分内容已经在 *第 9 章*，*Kubernetes
    中的持久化存储* 中介绍过。本章将向你介绍 StatefulSet 在 Kubernetes 中的作用，以及如何创建和管理 StatefulSet 对象来发布你有状态应用程序的新版本。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Introducing the StatefulSet object
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 StatefulSet 对象
- en: Managing StatefulSet
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理 StatefulSet
- en: Releasing a new version of an app deployed as a StatefulSet
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发布作为 StatefulSet 部署的应用的新版本
- en: StatefulSet best practices
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: StatefulSet 最佳实践
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you will need the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章你需要以下内容：
- en: A deployed Kubernetes cluster is needed. You can use either a local or a cloud-based
    cluster, but to fully understand the concepts, we recommend using a **multi-node**,
    cloud-based Kubernetes cluster. The cluster must support the creation of PersistentVolumeClaims.
    Any cloud-based cluster, or local cluster, for example, `minikube` with a `k8s.io/minikube-hostpath`
    provisioner, will be sufficient.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要一个已部署的 Kubernetes 集群。你可以使用本地集群或云端集群，但为了更好地理解这些概念，建议使用 **多节点** 的云端 Kubernetes
    集群。该集群必须支持创建 PersistentVolumeClaims。任何云端集群或本地集群，例如使用 `k8s.io/minikube-hostpath`
    提供程序的 `minikube`，都足够了。
- en: A Kubernetes CLI (`kubectl`) must be installed on your local machine and configured
    to manage your Kubernetes cluster.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须在本地计算机上安装 Kubernetes CLI (`kubectl`)，并配置它来管理你的 Kubernetes 集群。
- en: Kubernetes cluster deployment (local and cloud-based) and `kubectl` installation
    have been covered in *Chapter 3*, *Installing Your First Kubernetes Cluster*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群的部署（本地和云端）和 `kubectl` 安装已在 *第 3 章*，*安装你的第一个 Kubernetes 集群* 中介绍过。
- en: You can download the latest code samples for this chapter from the official
    GitHub repository at [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter12](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter12).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从官方 GitHub 仓库下载本章的最新代码示例，地址是 [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter12](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter12)。
- en: Introducing the StatefulSet object
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 StatefulSet 对象
- en: You may wonder why running stateful workloads in the distributed cloud is generally
    considered **harder** than running stateless ones. In classic three-tier applications,
    all the states would be stored in a database (*data tier* or *persistence layer*)
    and there would be nothing special about it. For SQL servers, you would usually
    add a failover setup with data replication, and if you require superior performance,
    you would scale *vertically* by simply purchasing better hardware for hosting.
    Then, at some point, you might think about clustered SQL solutions, introducing
    *data sharding* (horizontal data partitions). But still, from the perspective
    of a web server running your application, the database would just be a single
    connection string to read and write the data. The database would be responsible
    for persisting a *mutable state*.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，为什么在分布式云中运行有状态工作负载通常被认为比运行无状态工作负载**更困难**。在经典的三层应用中，所有的状态都会存储在数据库中（*数据层*或*持久化层*），这没有什么特别的地方。对于
    SQL 服务器，你通常会添加一个故障转移设置和数据复制，如果需要更高的性能，你可以通过购买更好的硬件来进行*纵向*扩展。然后，某个时刻，你可能会考虑集群化的
    SQL 解决方案，引入*数据分片*（水平数据分区）。但即便如此，从运行你应用的 web 服务器的角度来看，数据库也只是一个用于读写数据的单一连接字符串。数据库将负责持久化一个*可变状态*。
- en: Remember that every application *as a whole* is, in some way, stateful unless
    it only serves static content or just transforms user input. However, this does
    not mean that *every* component in the application is stateful. A web server that
    runs the application logic can be a *stateless* component, but the database where
    this application stores user input and sessions will be a *stateful* component.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，除非应用程序仅提供静态内容或只是转换用户输入，否则每个应用程序*整体*上都是有状态的。然而，这并不意味着应用程序中的*每个*组件都是有状态的。运行应用程序逻辑的
    web 服务器可以是*无状态*组件，但这个应用程序存储用户输入和会话的数据库将是*有状态*组件。
- en: We will first explain how you approach managing state in containers and what
    we consider an application or system state.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先解释如何在容器中管理状态，并阐明我们认为的应用程序或系统状态。
- en: Managing state in containers
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在容器中管理状态
- en: Now, imagine how this could work if you deployed your SQL server (single instance)
    in a container. The first thing you would notice is that after restarting the
    container, you would lose the data stored in the database – each time it is restarted,
    you get a fresh instance of the SQL server. Containers are *ephemeral*. This doesn’t
    sound too useful for our use case. Fortunately, containers come with the option
    to mount data volumes. A volume can be, for example, a *host’s directory or an
    external disk volume*, which will be *mounted* to a specific path in the container’s
    filesystem. Whatever you store in this path will be kept in the volume even after
    the container is terminated or restarted. In a similar way, you can use NFS share
    or an external disk instance as a volume. Now, if you configure your SQL server
    to put its data files in the path where the volume is mounted, you achieve data
    persistence even if the container restarts. The container itself is still ephemeral,
    but the data (state) is *not*.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设你将 SQL 服务器（单实例）部署在容器中。你会注意到的第一件事是，每次重新启动容器后，数据库中存储的数据都会丢失——每次重新启动时，你得到的是
    SQL 服务器的一个全新实例。容器是*临时性的*。这对于我们的使用案例来说似乎不太有用。幸运的是，容器提供了挂载数据卷的选项。一个卷可以是，例如，一个*主机目录或外部磁盘卷*，它会被*挂载*到容器文件系统中的特定路径。你在这个路径中存储的任何东西，即使容器终止或重新启动，也会保存在卷中。类似地，你可以使用
    NFS 共享或外部磁盘实例作为卷。现在，如果你配置 SQL 服务器将其数据文件放在挂载卷的路径下，即使容器重新启动，你也能实现数据持久化。容器本身仍然是临时性的，但数据（状态）却*不是*。
- en: This is a high-level overview of how the state can be persisted for plain containers,
    without involving Kubernetes. But before we move on to Kubernetes, we need to
    clarify what we actually regard as a **state**.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这是关于如何在普通容器中持久化状态的高级概述，而不涉及 Kubernetes。但在我们进入 Kubernetes 之前，我们需要澄清我们实际认为的**状态**是什么。
- en: 'Assume that you have a web server that serves just simple *static* content
    (which means it is always the same, as a simple HTML web page). There is still
    some data that has persisted, for example, the HTML files. However, this is *not*
    a state: user requests cannot modify this data, so *previous* requests from the
    user will not influence the result of the *current* request. In the same way,
    configuration files for your web server are not their state or log files written
    on the disk (well, that is arguable, but from the end user’s perspective, it is
    not).'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个只提供简单 *静态* 内容的 Web 服务器（这意味着它始终是相同的，比如一个简单的 HTML 网页）。虽然仍然有一些数据是持久化的，例如
    HTML 文件，但这 *不是* 状态：用户请求无法修改这些数据，因此 *之前* 的请求不会影响 *当前* 请求的结果。同样，Web 服务器的配置文件也不是它的状态，磁盘上写入的日志文件也不是（嗯，这个可以争论，但从最终用户的角度来看，它不是）。
- en: 'Now, if you have a web server that keeps user sessions and stores information
    about whether the user is logged in, then this is indeed the state. Depending
    on this information, the web server will return different web pages (responses)
    based on whether the user is logged in. Let’s say that this web server runs in
    a container – there is a catch when it comes to whether it is *the* stateful component
    in your application. If the web server process stores user sessions as a file
    in the container (warning: this is probably quite a bad design), then the web
    server container is a *stateful* component. But if it stores user sessions in
    a database or a Redis cache running in separate containers, then the web server
    is *stateless*, and the database or Redis container becomes the stateful component.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你有一个 Web 服务器，用来保持用户会话并存储有关用户是否已登录的信息，那么这确实是状态。根据这些信息，Web 服务器将返回不同的网页（响应），以区分用户是否登录。假设这个
    Web 服务器运行在一个容器中 —— 当涉及到它是否是你应用程序中的 *有状态* 组件时，会有一些细节需要注意。如果 Web 服务器进程将用户会话存储为容器内的文件（警告：这可能是一个相当糟糕的设计），那么
    Web 服务器容器就是一个 *有状态* 组件。但如果它将用户会话存储在一个运行在独立容器中的数据库或 Redis 缓存中，那么 Web 服务器就是 *无状态*
    的，而数据库或 Redis 容器则成为有状态组件。
- en: This is briefly how it looks from a single container perspective. We need now
    to zoom out a bit and take a look at state management in **Kubernetes Pods**.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这从单个容器的角度来看大致是这样的。现在我们需要稍微放大一些，来看看在 **Kubernetes Pods** 中的状态管理。
- en: Managing state in Kubernetes Pods
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Kubernetes Pods 中管理状态
- en: In Kubernetes, the concept of container volumes is extended by **PersistentVolumes**
    (**PVs**), **PersistentVolumeClaims** (**PVCs**), and **StorageClasses** (**SCs**),
    which are dedicated, storage-related objects. PVC aims to *decouple* Pods from
    the actual storage. PVC is a Kubernetes object that models a request for the storage
    of a specific type, class, or size – think of saying *I would like 10 GB of read/write-once
    SSD storage*. To fulfill such a request, a PV object is required, which is a piece
    of real storage that has been provisioned by the cluster’s automation process
    – think of this as a directory on the host system or storage driver-managed disk.
    PV types are implemented as plugins, similar to volumes in Docker or Podman. Now,
    the whole process of provisioning PV can be *dynamic* – it requires the creation
    of an SC object and for this to be used when defining PVCs. When creating a new
    SC, you provide a *provisioner* (or plugin details) with specific parameters,
    and each PVC using the given SC will automatically create a PV using the selected
    provisioner. The provisioners may, for example, create cloud-managed disks to
    provide the backing storage. On top of that, containers of a given Pod can share
    data using the same PV and mount it to their filesystem.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，容器卷的概念通过 **持久卷**（**PVs**）、**持久卷声明**（**PVCs**）和 **存储类**（**SCs**）得到了扩展，这些都是专门用于存储的对象。PVC
    的目标是 *解耦* Pods 与实际存储之间的关系。PVC 是一个 Kubernetes 对象，用于表示对特定类型、类或大小存储的请求 —— 比如说 *我需要
    10 GB 的一次性读写 SSD 存储*。为了满足这样的请求，必须有一个 PV 对象，它是由集群的自动化过程提供的实际存储 —— 可以将其理解为主机系统上的一个目录或存储驱动程序管理的磁盘。PV
    类型通过插件实现，类似于 Docker 或 Podman 中的卷。现在，整个 PV 提供过程可以是 *动态的* —— 它需要创建一个 SC 对象，并在定义
    PVC 时使用该 SC。创建新的 SC 时，你提供一个 *提供者*（或插件细节）与特定参数，每个使用该 SC 的 PVC 会自动创建一个 PV，使用所选的提供者。例如，提供者可以创建云管理磁盘来提供后端存储。除此之外，给定
    Pod 的容器可以通过使用相同的 PV 来共享数据，并将其挂载到文件系统中。
- en: This is just a brief overview of what Kubernetes provides for state storage.
    We have covered this in more detail in *Chapter 9*, *Persistent Storage in Kubernetes*.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是Kubernetes提供的状态存储的简要概述。我们在*第9章*《Kubernetes中的持久存储》中对此进行了更详细的讲解。
- en: On top of the management of state in a single Pod and its containers, there
    is the management of state in *multiple replicas* of a Pod. Let’s think about
    what would happen if we used a Deployment object to run multiple Pods with MySQL
    Server. First, you would need to ensure that the state persisted on a volume in
    a container – for this, you can use PVs in Kubernetes. But then you actually get
    multiple, separate MySQL servers, which is not very useful if you would like to
    have high availability and fault tolerance. If you expose such a deployment using
    a service, it will also be useless because each time, you may hit a different
    MySQL Pod and get different data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 除了单个Pod及其容器的状态管理外，还有*多个副本*的Pod的状态管理。让我们考虑一下，如果我们使用Deployment对象来运行多个MySQL Server
    Pod会发生什么。首先，您需要确保在容器中的卷上持久化状态——为此，您可以在Kubernetes中使用PVs。但这样，您实际上会得到多个独立的MySQL服务器，如果您想要高可用性和容错性，这并不十分有用。如果您通过服务暴露这样的部署，它也将没有用处，因为每次您可能会连接到不同的MySQL
    Pod并获得不同的数据。
- en: So, you arrive either at designing a *multi-node failover setup* with replication
    between the master and replicas, or a complex *cluster with data sharding*. In
    any case, your individual MySQL Server Pod replicas need to have a *unique identity*
    and, preferably, *predictable network names* so that the Nodes and clients can
    communicate.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，您要么设计一个带有主从复制的*多节点故障转移设置*，要么设计一个复杂的*数据分片集群*。无论哪种情况，您的单个MySQL Server Pod副本都需要具有*唯一身份*，并且最好具有*可预测的网络名称*，以便节点和客户端可以进行通信。
- en: When designing your cloud-native application for the Kubernetes cluster, always
    analyze all the pros and cons of storing the state of the application as stateful
    components *running in Kubernetes*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在为Kubernetes集群设计云原生应用程序时，请始终分析将应用程序状态存储为有状态组件*在Kubernetes中运行*的所有优缺点。
- en: This is where StatefulSet comes in. Let’s take a closer look at this Kubernetes
    object.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是StatefulSet的作用。让我们更详细地看看这个Kubernetes对象。
- en: StatefulSet and how it differs from a Deployment object
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: StatefulSet及其与Deployment对象的区别
- en: Kubernetes StatefulSet is a similar concept to a Deployment object. It also
    provides a way of managing and scaling a set of Pods, but it provides guarantees
    about the *ordering and uniqueness* (unique identity) of the Pods. In the same
    way as Deployment, it uses a Pod template to define what each replica should look
    like. You can scale it up and down and perform rollouts of new versions. But now,
    in StatefulSet, the individual Pod replicas are *not interchangeable*. The unique,
    persistent identity for each Pod is maintained during any rescheduling or rollouts
    – this includes the **Pod name** and its **cluster DNS names**. This unique, persistent
    identity can be used to identify PVs assigned to each Pod, even if Pods are replaced
    following a failure. For this, StatefulSet provides another type of template in
    its specification named `volumeClaimTemplates`. This template can be used for
    the dynamic creation of the PVCs of a given SC. By doing this, the whole process
    of storage provisioning is fully dynamic – you just need to create a StatefulSet.
    The underlying storage objects are managed by the StatefulSet controller.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes StatefulSet是一个类似于Deployment对象的概念。它也提供了一种管理和扩展Pod集合的方式，但它提供了关于Pod的*顺序和唯一性*（唯一身份）的保证。与Deployment一样，它使用Pod模板来定义每个副本的样子。您可以进行扩展和缩减，并进行新版本的发布。但在StatefulSet中，单个Pod副本是*不可互换*的。每个Pod的唯一持久身份在任何重新调度或发布期间都得以保持——这包括**Pod名称**和其**集群DNS名称**。这个唯一的持久身份可以用于标识分配给每个Pod的PVs，即使Pods在故障后被替换。为此，StatefulSet在其规格中提供了另一种类型的模板，名为`volumeClaimTemplates`。该模板可以用于动态创建给定SC的PVC。通过这种方式，整个存储配置过程完全动态——您只需创建一个StatefulSet。底层存储对象由StatefulSet控制器管理。
- en: Cluster DNS names of individual Pods in StatefulSet remain the same, but their
    cluster IP addresses are not guaranteed to stay the same. This means that if you
    need to connect to individual Pods in the StatefulSet, you should use cluster
    DNS names.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSet中单个Pod的集群DNS名称保持不变，但其集群IP地址不保证保持不变。这意味着，如果您需要连接到StatefulSet中的单个Pod，应该使用集群DNS名称。
- en: 'Basically, you can use StatefulSet for applications that require the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 基本上，您可以将StatefulSet用于以下应用程序：
- en: Persistent storage managed by the Kubernetes cluster (this is the main use case,
    but not the only one)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由 Kubernetes 集群管理的持久化存储（这是主要使用场景，但不是唯一的）
- en: Stable and unique network identifiers (usually DNS names) for each Pod replica
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为每个 Pod 副本提供稳定且唯一的网络标识符（通常是 DNS 名称）
- en: Ordered deployment and scaling
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有序部署和扩展
- en: Ordered, rolling updates
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有序的滚动更新
- en: In the following diagram, you can see that StatefulSets can be seen as a more
    predictable version of a Deployment object, with the possibility to use persistent
    storage provided by PVCs.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下图示中，您可以看到 StatefulSets 可以视为 Deployment 对象的一个更具可预测性的版本，并且可以使用 PVC 提供的持久化存储。
- en: '![](img/B22019_12_01.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_12_01.png)'
- en: 'Figure 12.1: StatefulSet high-level view'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.1：StatefulSet 高层视图
- en: 'To summarize, the key differences between StatefulSet and Deployment are as
    follows:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，StatefulSet 和 Deployment 之间的主要区别如下：
- en: StatefulSet ensures a *deterministic* (sticky) name for Pods, which consists
    of `<statefulSetName>-<ordinal>`. For Deployments, you would have a *random* name
    consisting of `<deploymentName>-<podTemplateHash>-<randomHash>`.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: StatefulSet 确保为 Pod 提供 *确定性*（粘性）名称，名称由 `<statefulSetName>-<ordinal>` 组成。对于 Deployments，您将获得一个由
    `<deploymentName>-<podTemplateHash>-<randomHash>` 组成的 *随机* 名称。
- en: For StatefulSet objects, the Pods are started and terminated in a *specific*
    and *predictable* order that ensures consistency, stability, and coordination
    while scaling the ReplicaSet. Let us take the preceding example diagram of MySQL
    StatefulSet; the Pods will be created in sequential order (mysql-0, mysql-1, and
    mysql-2). When you scale down the StatefulSet, the Pods will be terminated in
    the reverse order – mysql-2, mysql-1, and mysql-0 at the end.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 StatefulSet 对象，Pod 是以 *特定* 和 *可预测* 的顺序启动和终止的，这确保了在扩展 ReplicaSet 时的一致性、稳定性和协调性。以前面提到的
    MySQL StatefulSet 示例为例，Pod 将按顺序创建（mysql-0、mysql-1 和 mysql-2）。当您缩小 StatefulSet
    时，Pod 将按相反的顺序终止 —— mysql-2、mysql-1，最后是 mysql-0。
- en: In terms of storage, Kubernetes creates PVCs based on `volumeClaimTemplates`
    of the StatefulSet specification for each Pod in the StatefulSet and always attaches
    this to the Pod with *the same* name. For Deployment, if you choose to use `persistentVolumeClaim`
    in the Pod template, Kubernetes will create a single PVC and attach the same to
    all the Pods in the deployment. This may be useful in certain scenarios but is
    not a common use case.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在存储方面，Kubernetes 会根据 StatefulSet 规范中的 `volumeClaimTemplates` 为 StatefulSet 中的每个
    Pod 创建 PVC，并始终将其附加到具有 *相同* 名称的 Pod。对于 Deployment，如果您选择在 Pod 模板中使用 `persistentVolumeClaim`，Kubernetes
    将创建一个单一的 PVC，并将其附加到 Deployment 中的所有 Pods。这在某些场景下可能有用，但并不是常见的使用场景。
- en: You need to create a `headless` Service object that is responsible for managing
    the *deterministic network identity* (cluster DNS names) for Pods. The headless
    Service allows us to return *all* Pods’ IP addresses behind the service as DNS
    A records instead of a single DNS A record with a `ClusterIP` Service. A headless
    Service is only required if you are not using a regular service. The specification
    of StatefulSet requires having the Service name provided in `.spec.serviceName`.
    Refer to *Understanding headless services* in *Chapter 8*, *Exposing Your Pods
    with Services*.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您需要创建一个 `headless` 服务对象，负责管理 Pod 的 *确定性网络标识*（集群 DNS 名称）。Headless 服务使我们能够将所有
    Pod 的 IP 地址作为 DNS A 记录返回，而不是将其作为带有 `ClusterIP` 服务的单一 DNS A 记录。只有在不使用常规服务时，才需要
    Headless 服务。StatefulSet 的规范要求在 `.spec.serviceName` 中提供服务名称。请参阅《第8章，*通过服务暴露您的 Pod*》中的
    *理解 Headless 服务*。
- en: Before we explore the StatefulSet, we need to understand some of the limitations
    of the StatefulSet objects, as explained in the following section.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探索 StatefulSet 之前，需要了解一些 StatefulSet 对象的局限性，具体内容将在以下部分中解释。
- en: Exploring the limitations of StatefulSet
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 StatefulSet 的局限性
- en: 'Here’s a breakdown of some specific things to keep in mind when using StatefulSets:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用 StatefulSets 时需要注意的具体事项：
- en: '**Storage setup**: StatefulSets don’t automatically create storage for your
    pods. You’ll need to either use a built-in tool (like PersistentVolume Provisioner)
    or manually set up the storage beforehand.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储设置**：StatefulSets 不会自动为您的 Pod 创建存储。您需要使用内建工具（如 PersistentVolume Provisioner）或事先手动设置存储。'
- en: '**Leftover storage**: When you scale down or remove a StatefulSet, the storage
    used by its pods sticks around. This is because your data is important and shouldn’t
    accidentally be deleted. You’ll need to clean up the storage yourself if needed.
    Otherwise, the leftover storage could become a concern because over time, all
    this unused storage can accumulate, leading to wasted resources and increased
    storage costs.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**残留存储**：当你缩减或删除一个 StatefulSet 时，其 Pod 使用的存储会保留下来。这是因为你的数据很重要，不应被意外删除。如果需要，你需要手动清理存储。否则，残留的存储可能会成为一个问题，因为随着时间的推移，所有这些未使用的存储会积累，导致资源浪费和存储成本增加。'
- en: '**Pod address**: You’ll need to set up a separate service (called a Headless
    Service) to give the Pod unique and stable network names.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pod 地址**：你需要设置一个单独的服务（称为无头服务），以为 Pod 提供唯一且稳定的网络名称。'
- en: '**Stopping StatefulSets**: There’s no guarantee that pods will shut down in
    a specific order when you delete a StatefulSet. To ensure a clean shutdown, it’s
    best to scale the StatefulSet down to zero Pods before removing it completely.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**停止 StatefulSets**：当你删除 StatefulSet 时，无法保证 Pod 会按特定顺序关闭。为了确保干净地关闭，最好在完全删除
    StatefulSet 之前，将其缩放为零个 Pod。'
- en: '**Updating StatefulSets**: Using the default update method with StatefulSets
    can sometimes lead to problems that require you to fix things manually. Be aware
    of this and consider alternative update strategies if needed.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更新 StatefulSets**：使用 StatefulSets 的默认更新方法有时会导致需要手动修复的问题。请注意这一点，并在需要时考虑替代的更新策略。'
- en: Before you start exercises with StatefulSet, read important information about
    the StatefulSets in the next section.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始使用 StatefulSet 进行练习之前，请阅读下一节关于 StatefulSets 的重要信息。
- en: Data management in Statefulset
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Statefulset 中的数据管理
- en: 'Kubernetes offers StatefulSets as a powerful tool for managing stateful applications.
    However, successfully deploying and maintaining stateful applications requires
    user involvement beyond simply defining the StatefulSet itself. Here’s a breakdown
    of key areas requiring your attention:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 提供了 StatefulSets 作为管理有状态应用程序的强大工具。然而，成功地部署和维护有状态应用程序需要用户的参与，远远不止是定义
    StatefulSet 本身。以下是需要你关注的关键领域：
- en: '**Data cloning and synchronization**: Unlike stateless applications, stateful
    applications rely on persistent data. While StatefulSets manage Pod ordering and
    identity, they don’t handle data replication between Pods. You’ll need to implement
    this functionality yourself. Common approaches include using init containers to
    copy data from a predefined source during Pod creation, leveraging built-in replication
    features within your application (like MySQL replication), or utilizing external
    scripts to manage data synchronization.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据克隆和同步**：与无状态应用程序不同，有状态应用程序依赖于持久化数据。虽然 StatefulSets 管理 Pod 的顺序和身份，但它们不处理
    Pods 之间的数据复制。你需要自己实现这一功能。常见的做法包括使用初始化容器在 Pod 创建时从预定义的源复制数据，利用应用程序内部的内建复制功能（例如
    MySQL 复制），或使用外部脚本来管理数据同步。'
- en: '**Remote storage accessibility**: StatefulSets ensure Pods can be rescheduled
    across available nodes in the cluster. To maintain data persistence during rescheduling,
    the storage provisioned by the PV needs to be accessible from all worker nodes.
    This means choosing a storage class that replicates data across nodes or using
    network-attached storage solutions accessible from all machines.'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**远程存储可访问性**：StatefulSets 确保 Pod 可以在集群中可用的节点之间重新调度。为了在重新调度期间保持数据持久性，PV 提供的存储需要能够从所有工作节点访问。这意味着选择一个跨节点复制数据的存储类，或使用所有机器都能访问的网络附加存储解决方案。'
- en: '**External backups**: StatefulSets are designed for managing Pod life cycles
    and data persistence within the cluster. However, they don’t handle external backups.
    To ensure disaster recovery in case of catastrophic events, implementing a separate
    external backup solution is crucial. This could involve backing up your PVs to
    a cloud storage service or a dedicated backup server outside the Kubernetes cluster.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部备份**：StatefulSets 旨在管理 Pod 生命周期和集群内的数据持久化。然而，它们不处理外部备份。为了确保在灾难性事件发生时的灾难恢复，实施一个单独的外部备份解决方案是至关重要的。这可能涉及将你的
    PV 备份到云存储服务或 Kubernetes 集群外的专用备份服务器。'
- en: There are best practices and recommended approaches for handling the data in
    StatefulSets. The following section will explain some of the replication management
    techniques for StatefulSets.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 有关于在 StatefulSets 中处理数据的最佳实践和推荐方法。下一节将解释一些 StatefulSets 的复制管理技术。
- en: Replication management
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复制管理
- en: 'As the name suggests, Stateful applications handling data often require data
    initialization or synchronization. You might need to implement these using methods
    like the following:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 正如名称所示，处理数据的有状态应用通常需要数据初始化或同步。你可能需要使用以下方法来实现这些功能：
- en: '**init containers**: Copy data from a source (like a config map) to the persistent
    storage before starting the application.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**初始化容器**：在启动应用程序之前，将数据从源（如配置映射）复制到持久化存储。'
- en: '**Application-level replication**: Leverage built-in replication features within
    your application to handle data updates across Pods.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用级别的复制**：利用应用内置的复制功能，在 Pods 之间处理数据更新。'
- en: '**External scripts**: Use external scripts or tools to manage data migration
    during the update process.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部脚本**：使用外部脚本或工具，在更新过程中管理数据迁移。'
- en: Now, let’s take a look at a concrete example of StatefulSet that deploys MySQL
    Pods with the backing of persistent storage.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一个具体的 StatefulSet 示例，它部署了 MySQL Pods，并且支持持久化存储。
- en: Managing StatefulSet
  id: totrans-69
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理 StatefulSet
- en: To demonstrate how StatefulSet objects work, we will modify our MySQL deployment
    and adapt it to be a StatefulSet. A significant part of the StatefulSet specification
    is the same as for Deployments. As we would like to demonstrate how the automatic
    management of PVCs works in StatefulSet objects, we will use `volumeClaimTemplates`
    in the specification to create PVCs and PVs, which the Pods will consume. Each
    Pod will internally mount its assigned PV under the `/var/lib/mysql` path in the
    container filesystem, which is the default location of MySQL data files. In this
    way, we can demonstrate how the *state* persists, even if we forcefully restart
    Pods.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示 StatefulSet 对象的工作原理，我们将修改 MySQL 部署并将其适配为 StatefulSet。StatefulSet 规格中的重要部分与部署（Deployments）相同。由于我们希望演示在
    StatefulSet 对象中 PVC 的自动管理如何工作，我们将在规格中使用 `volumeClaimTemplates` 来创建 PVC 和 PV，这些
    PVC 和 PV 会被 Pods 使用。每个 Pod 都会在容器文件系统中将其分配的 PV 挂载到 `/var/lib/mysql` 路径下，这里是 MySQL
    数据文件的默认位置。通过这种方式，即使我们强制重启 Pods，也能演示如何保持 *状态* 持久化。
- en: The example that we are going to use in this chapter is for demonstration purposes
    only and is meant to be as simple as possible. If you are interested in *complex*
    examples, such as deploying and managing distributed databases in StatefulSets,
    please take a look at the official Kubernetes blog post about deploying the Cassandra
    database at [https://kubernetes.io/docs/tutorials/stateful-application/cassandra/](https://kubernetes.io/docs/tutorials/stateful-application/cassandra/).
    Usually, the main source of complexity in such cases is handling the joining and
    removal of Pod replicas when scaling the StatefulSet.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将使用的示例仅用于演示，目的是尽可能简单。如果你对 *复杂* 的示例感兴趣，例如在 StatefulSets 中部署和管理分布式数据库，请查看官方
    Kubernetes 博文，关于部署 Cassandra 数据库的教程，网址是 [https://kubernetes.io/docs/tutorials/stateful-application/cassandra/](https://kubernetes.io/docs/tutorials/stateful-application/cassandra/)。通常，这类情况下的复杂性主要来自于在扩展
    StatefulSet 时处理 Pod 副本的加入与移除。
- en: We will now go through all the YAML manifests required to create our StatefulSet
    and apply them to the cluster.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将逐一查看创建 StatefulSet 所需的所有 YAML 清单，并将它们应用到集群中。
- en: Creating a StatefulSet
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 StatefulSet
- en: 'We have discussed the concepts of StatefulSet, and now it’s time to learn how
    to manage them. First, let’s take a look at the StatefulSet YAML manifest file
    named `mysql-statefulset.yaml`:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了 StatefulSet 的概念，现在是时候学习如何管理它们了。首先，让我们来看一下名为 `mysql-statefulset.yaml`
    的 StatefulSet YAML 清单文件：
- en: '[PRE0]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The first part of the preceding file is very similar to the Deployment object
    specification, where you need to provide the number of `replicas` and a `selector`
    for Pods. There is one new parameter, `serviceName`, which we will explain shortly.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 上述文件的第一部分与 Deployment 对象规格非常相似，你需要提供 `replicas` 数量以及 Pod 的 `selector`。有一个新参数
    `serviceName`，稍后我们会解释它。
- en: 'The next part of the file concerns the specification of the Pod template that
    is used by the StatefulSet:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 文件的下一部分涉及 StatefulSet 使用的 Pod 模板的规格：
- en: '[PRE1]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'If you look closely, you can observe that the structure is the same as for
    Deployments. Notice the environment variables we are providing via the Secret
    object, which needs to be created before creating the StatefulSet. Also, the last
    part of the file contains `volumeClaimTemplates`, which is used to define templates
    for PVC used by the Pod:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细观察，会发现其结构与部署（Deployments）是相同的。注意，我们通过 Secret 对象提供的环境变量，这些环境变量需要在创建 StatefulSet
    之前创建。此外，文件的最后部分包含了 `volumeClaimTemplates`，它用于定义 Pod 使用的 PVC 模板：
- en: '[PRE2]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As you can see, in general, the structure of the StatefulSet spec is similar
    to a Deployment, although it has a few extra parameters for configuring PVCs and
    associated Service objects. The specification has five main components:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，通常 StatefulSet 规范的结构与 Deployment 相似，尽管它有一些额外的参数用于配置 PVC 和相关的服务对象。该规范有五个主要组件：
- en: '`replicas`: Defines the number of Pod replicas that should run using the given
    `template` and the matching label `selector`. Pods may be created or deleted to
    maintain the required number.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`replicas`：定义应该使用给定的 `template` 和匹配的标签 `selector` 运行的 Pod 副本数。Pods 可能会被创建或删除，以维持所需的数量。'
- en: '`serviceName`: The name of the service that governs the StatefulSet and provides
    the network identity for the Pods. This Service must be created before the StatefulSet
    is created. We will create the `mysql-headless` Service in the next step.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`serviceName`：管理 StatefulSet 并为 Pod 提供网络身份的服务名称。此服务必须在创建 StatefulSet 之前创建。我们将在下一步中创建
    `mysql-headless` 服务。'
- en: '`selector`: A **label selector**, which defines how to identify Pods that the
    StatefulSet owns. This can include *set-based* and *equality-based* selectors.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`selector`：一个 **标签选择器**，定义如何识别 StatefulSet 所拥有的 Pods。这可以包括 *基于集合* 和 *基于相等*
    的选择器。'
- en: '`template`: Defines the template for Pod creation. Labels used in `metadata`
    must match the `selector`. Pod names are not random and follow the `<statefulSetName>-<ordinal>`
    convention. You can optionally use `.spec.ordinals` to control the starting number
    for the unique identification number assigned to each pod in your StatefulSet.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`template`：定义 Pod 创建的模板。`metadata` 中使用的标签必须与 `selector` 匹配。Pod 名称不是随机的，遵循 `<statefulSetName>-<ordinal>`
    的约定。你可以选择使用 `.spec.ordinals` 来控制分配给 StatefulSet 中每个 Pod 的唯一标识符的起始数字。'
- en: '`volumeClaimTemplates`: Defines the template for PVC that will be created for
    each of the Pods. Each Pod in the StatefulSet object will get its own PVC that
    is assigned to a given Pod name persistently. In our case, it is a 1 GB volume
    with the `ReadWriteOnce` access mode. This access mode allows the volume to be
    mounted for reads and writes by a *single* Node only. We did not specify `storageClassName`,
    so the PVCs will be provisioned using the default SC in the cluster. PVC names
    are not random and follow the `<volumeClaimTemplateName>-<statefulSetName>-<ordinal>`
    convention.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`volumeClaimTemplates`：定义为每个 Pod 创建的 PVC 模板。StatefulSet 对象中的每个 Pod 都将获得自己的
    PVC，并且该 PVC 始终与给定的 Pod 名称关联。在我们的示例中，这是一个 1 GB 的卷，访问模式为 `ReadWriteOnce`。此访问模式允许仅由
    *单个* 节点挂载该卷进行读写。我们没有指定 `storageClassName`，因此 PVC 将使用集群中的默认 SC 进行配置。PVC 名称不是随机的，遵循
    `<volumeClaimTemplateName>-<statefulSetName>-<ordinal>` 的约定。'
- en: The default SC in your cluster is marked with the `storageclass.kubernetes.io/is-default-class`
    annotation. Whether you have a default SC, and how it is defined, depends on your
    cluster deployment. For example, in the Azure Kubernetes Service cluster, it will
    be an SC named `default` that uses the `kubernetes.io/azure-disk` provisioner.
    In `minikube`, it will be an SC named `standard` that uses the `k8s.io/minikube-hostpath`
    provisioner.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 集群中的默认 SC 通过 `storageclass.kubernetes.io/is-default-class` 注解标记。是否有默认 SC 以及它如何定义，取决于你的集群部署。例如，在
    Azure Kubernetes Service 集群中，默认 SC 为名为 `default` 的 SC，使用 `kubernetes.io/azure-disk`
    提供者。在 `minikube` 中，默认 SC 为名为 `standard` 的 SC，使用 `k8s.io/minikube-hostpath` 提供者。
- en: The specification also contains other fields that are related to rolling out
    new revisions of StatefulSet – we will explain these in more detail in the next
    section.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 规范还包含与滚动发布 StatefulSet 新修订版相关的其他字段——我们将在下一部分中详细解释这些内容。
- en: 'Next, let’s have a look at our *headless* Service named `mysql-headless`. Create
    a `mysql-headless-service.yaml` file with the following content:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看一下我们名为 `mysql-headless` 的 *无头* 服务。创建一个 `mysql-headless-service.yaml`
    文件，内容如下：
- en: '[PRE3]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The specification is very similar to the normal Service that we created previously
    for the Deployment; the only difference is that it has the value `None` for the
    `clusterIP` field. This will result in the creation of a headless Service, `mysql-headless`.
    A headless Service allows us to return *all* Pods’ IP addresses behind the Service
    as DNS `A records` instead of a single DNS `A record` with a `clusterIP` Service.
    We will demonstrate what this means in practice in the next steps.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 该规范与我们之前为 Deployment 创建的普通服务非常相似；唯一的区别是它的 `clusterIP` 字段的值为 `None`。这将导致创建一个无头服务
    `mysql-headless`。无头服务允许我们将 *所有* Pods 的 IP 地址作为 DNS `A 记录` 返回，而不是使用带有 `clusterIP`
    服务的单个 DNS `A 记录`。我们将在接下来的步骤中演示这在实际中的意义。
- en: 'With all the YAML manifest files, we can start deploying our example StatefulSet!
    Perform the following steps:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 使用所有的 YAML 清单文件，我们可以开始部署我们的示例 StatefulSet！请执行以下步骤：
- en: 'Create a namespace called `mysql` (using `mysql-ns.yaml`):'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `mysql` 的命名空间（使用 `mysql-ns.yaml`）：
- en: '[PRE4]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Create a Secret to store MySQL environment variables:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 Secret 来存储 MySQL 环境变量：
- en: '[PRE5]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Please note that it is also possible to create the same secret using YAML and
    base64 encoded (e.g., `echo -n 'mysqlroot' | base64`) values inside (refer to
    `mysql-secret.yaml` in the repository to see the sample YAML file); we are using
    this imperative method to demonstrate the secret with actual values.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，也可以使用 YAML 和 base64 编码的值（例如，`echo -n 'mysqlroot' | base64`）在其中创建相同的 Secret（请参考仓库中的
    `mysql-secret.yaml` 查看示例 YAML 文件）；我们使用这种命令式方法来演示带有实际值的 Secret。
- en: 'Create a headless Service, `mysql-headless`, using the following command:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建一个无头服务 `mysql-headless`：
- en: '[PRE6]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Create a StatefulSet object, `mysql-stateful`, using the following command:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建一个名为 `mysql-stateful` 的 StatefulSet 对象：
- en: '[PRE7]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Now, you can use the `kubectl describe` command to observe the creation of
    the StatefulSet object (alternatively, you can use `sts` as an abbreviation for
    StatefulSet when using kubectl commands):'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您可以使用 `kubectl describe` 命令来观察 StatefulSet 对象的创建（或者，您也可以在使用 kubectl 命令时使用
    `sts` 作为 StatefulSet 的缩写）：
- en: '[PRE8]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Use the `kubectl get pods` command to see that the three desired Pod replicas
    have been created. Note that this can take a bit of time as the Pods have to get
    the PVs provisioned based on their PVCs:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `kubectl get pods` 命令查看是否已创建三个期望的 Pod 副本。请注意，这可能需要一些时间，因为 Pods 必须根据其 PVC
    获取已提供的 PV。
- en: '[PRE9]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Please note the ordered, deterministic Pod naming – this is the key to providing
    a unique identity to the Pods in the StatefulSet object.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意有序、确定性的 Pod 命名——这是为 StatefulSet 对象中的 Pods 提供唯一标识的关键。
- en: 'If you describe one of the Pods, you will see more details about the associated
    PV and PVC:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您描述其中一个 Pod，您将看到与之关联的 PV 和 PVC 的更多详细信息：
- en: '[PRE10]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'For the second Pod, you will see a similar output to the following, but with
    a different PVC:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个 Pod，您将看到类似以下的输出，但 PVC 会有所不同：
- en: '[PRE11]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: As you can see, the PVC used by this `mysql-stateful-0` Pod is named `mysql-data-mysql-stateful-0`
    and the PVC used by this `mysql-stateful-1` Pod is named `mysql-data-mysql-stateful-1`.
    Right after the Pod was scheduled on its target Node, the PVs are provisioned
    via the respective StorageClass and bound to the individual PVCs. After that,
    the actual container, which internally mounts this PV, has been created.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，这个 `mysql-stateful-0` Pod 使用的 PVC 名为 `mysql-data-mysql-stateful-0`，而这个
    `mysql-stateful-1` Pod 使用的 PVC 名为 `mysql-data-mysql-stateful-1`。在 Pod 被调度到其目标节点后，PV
    会通过各自的 StorageClass 被提供并绑定到各个 PVC。之后，实际的容器会被创建，并内部挂载这个 PV。
- en: 'Using the `kubectl get` command, we can reveal more details about the PVC:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `kubectl get` 命令，我们可以揭示更多关于 PVC 的详细信息：
- en: '[PRE12]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'And finally, let’s take a look at the PV that was provisioned:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们来看看被提供的 PV：
- en: '[PRE13]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Please note that, in our example, we are demonstrating this using the minikube
    `hostPath` type. If your Kubernetes cluster uses a different storage backend,
    you will see different outputs.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在我们的示例中，我们使用的是 minikube 的 `hostPath` 类型。如果您的 Kubernetes 集群使用了不同的存储后端，您将看到不同的输出。
- en: 'We have successfully created the StatefulSet object; now it is time to verify
    whether it works as expected in a basic scenario. To do this, let us use an updated
    `k8sutils` container image with the default MySQL client package installed. (Check
    `Chapter12/Containerfile` to see the details of the `k8sutils` image.) Create
    `k8sutils.yaml` as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功创建了 StatefulSet 对象，现在是时候验证它在基本场景中的工作情况了。为此，我们将使用一个更新的 `k8sutils` 容器镜像，里面安装了默认的
    MySQL 客户端包。（请查看 `Chapter12/Containerfile` 查看 `k8sutils` 镜像的详细信息。）按照以下方式创建 `k8sutils.yaml`：
- en: '[PRE14]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create the `k8sutils` Pod as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下方式创建 `k8sutils` Pod：
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Please note that we used `-n mysql` while applying the YAML so that the resource
    will be created inside the `mysql` namespace.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在应用 YAML 时我们使用了 `-n mysql`，这样资源将被创建在 `mysql` 命名空间中。
- en: 'Follow these steps to verify the content of different Pods in the StatefulSet:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤验证 StatefulSet 中不同 Pods 的内容：
- en: 'Jump into the `k8sutil` Pod to execute our test commands:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入 `k8sutil` Pod 执行我们的测试命令：
- en: '[PRE16]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Access the MySQL Stateful application using the default headless service we
    created earlier (remember the password you created using the Secret object earlier):'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们之前创建的默认无头服务访问 MySQL Stateful 应用（记得之前通过 Secret 对象创建的密码）：
- en: '[PRE17]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The basic MySQL connection is working, and we are able to access the MySQL server
    running as a StatefulSet application. We will now take a quick look at how the
    *headless* Service behaves.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 基本的 MySQL 连接已正常工作，我们能够访问作为 StatefulSet 应用程序运行的 MySQL 服务器。现在，我们将快速查看无头服务的行为。
- en: Using the headless Service and stable network identities
  id: totrans-128
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用无头服务和稳定的网络身份
- en: Previously, we learned about headless service in Kubernetes and how we can use
    it for accessing StatefulSet applications. (Refer to *Understanding headless services*
    section in *Chapter 8*, *Exposing Your Pods with Services*). In this section,
    let us go deep and explore the headless service mechanism in the backend of StatefulSet.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们了解了 Kubernetes 中的无头服务以及如何使用它来访问有状态集应用程序。（参考 *第 8 章* 中的 *理解无头服务* 部分，*通过服务暴露你的
    Pods*）。在本节中，让我们深入探讨 StatefulSet 后端中的无头服务机制。
- en: 'Let’s do an experiment that demonstrates how the `headless` Service is used
    to provide stable and predictable network identities for our Pods:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一个实验，演示如何使用 `headless` 服务为我们的 Pod 提供稳定且可预测的网络身份：
- en: Log in to the same k8sutils Pod that we used in the previous test.
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到我们在上一个测试中使用的相同 k8sutils Pod。
- en: 'Perform DNS check for the headless Service, `mysql-headless`:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对无头服务 `mysql-headless` 执行 DNS 检查：
- en: '[PRE18]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We have received three `A records` that point directly to Pod IP addresses.
    Additionally, they have `CNAME records` in the form of `<podName>-<ordinal-number>.<headless-serviceName>.<namespace>.svc.cluster.local`.
    So, the difference with default Service is that a Service that has `ClusterIP`
    will get load balancing to a *virtual IP* level (which, on Linux, is usually handled
    at a kernel level by `iptables` rules configured by `kube-proxy`), whereas in
    the case of the headless Service, the responsibility for load balancing or choosing
    the target Pod is on the *client* making the request.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们收到了三个 `A 记录`，它们直接指向 Pod 的 IP 地址。此外，它们有 `CNAME 记录`，形式为 `<podName>-<ordinal-number>.<headless-serviceName>.<namespace>.svc.cluster.local`。因此，与默认服务的不同之处在于，具有
    `ClusterIP` 的服务会进行负载均衡，达到 *虚拟 IP* 级别（在 Linux 中，通常通过 `iptables` 规则，由 `kube-proxy`
    配置在内核级别处理），而对于无头服务，负载均衡或选择目标 Pod 的责任由发起请求的 *客户端* 承担。
- en: 'Having *predictable* FQDNs for Pods in the StatefulSet gives us the option
    to send the requests directly to individual Pods, without guessing their IP addresses
    or names. Let’s try accessing the MySQL server served by the `mysql-stateful-0`
    using its short DNS name provided by the headless Service:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于 StatefulSet 中的 Pods，拥有 *可预测的* FQDN 给了我们直接向单个 Pods 发送请求的选项，而无需猜测它们的 IP 地址或名称。让我们尝试通过无头服务提供的短
    DNS 名称来访问由 `mysql-stateful-0` 提供的 MySQL 服务器：
- en: '[PRE19]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As expected, you have connected directly to the Pod and have been served by
    the proper Pod.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，你已经直接连接到 Pod，并由正确的 Pod 提供服务。
- en: 'Let us create a database inside the MySQL database server as follows:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们在 MySQL 数据库服务器中创建一个数据库，如下所示：
- en: '[PRE20]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, we will show that this DNS name remains unchanged even if a Pod is restarted.
    The IP of the Pod will change, but the DNS name will not. What is more, the PV
    that is mounted will also stay the same, but we will investigate this in the next
    paragraphs. In another shell window, outside of the container, execute the following
    command to force a restart of the `mysql-stateful-0` Pod:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将展示即使 Pod 重启，DNS 名称也保持不变。Pod 的 IP 地址会变化，但 DNS 名称不会变化。更重要的是，挂载的 PV 也会保持不变，但我们将在接下来的段落中调查这一点。在另一个
    shell 窗口中，容器外执行以下命令，强制重启 `mysql-stateful-0` Pod：
- en: '[PRE21]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Check the Pods and you will see that `mysql-stateful-0` has been recreated
    and mounted with the same `mysql-data-mysql-stateful-0` PVC:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 检查 Pods，你会看到 `mysql-stateful-0` 已被重新创建，并挂载了相同的 `mysql-data-mysql-stateful-0`
    PVC：
- en: '[PRE22]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'In the `k8sutils` shell, execute the MySQL client command to check the database
    server content:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `k8sutils` shell 中，执行 MySQL 客户端命令以检查数据库服务器内容：
- en: '[PRE23]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: You can see that the database `ststest` we created before the Pod deletion is
    still there, which means the data is persistent or stateful. Also, notice the
    IP address of the Pod changed but the DNS remained the same.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我们在 Pod 删除之前创建的数据库 `ststest` 仍然存在，这意味着数据是持久的或有状态的。同时，注意到 Pod 的 IP 地址发生了变化，但
    DNS 名称保持不变。
- en: 'This explains how the headless Services can be leveraged to get a stable and
    predictable network identity that will not change when a Pod is restarted or recreated.
    You may wonder what the actual use of this is and why it is important for StatefulSet
    objects. There are a couple of possible use cases:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 这解释了如何利用无头服务来获取一个稳定且可预测的网络标识符，该标识符在 Pod 被重启或重建时不会改变。你可能会想，这到底有什么实际用途，为什么它对 StatefulSet
    对象如此重要。这里有几个可能的使用案例：
- en: Deploying clustered databases, such as `etcd` or MongoDB, requires specifying
    the network addresses of other Nodes in the database cluster. This is especially
    necessary if there are no *automatic discovery* capabilities provided by the database.
    In such cases, stable DNS names provided by headless Services help to run such
    clusters on Kubernetes as StatefulSets. There is still the problem of changing
    the configuration when Pod replicas are added or removed from the StatefulSet
    during scaling. In some cases, this is solved by the *sidecar container pattern*,
    which monitors the Kubernetes API to dynamically change the database configuration.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署集群数据库，如 `etcd` 或 MongoDB，需要指定数据库集群中其他节点的网络地址。如果数据库没有提供*自动发现*功能，这一点尤其重要。在这种情况下，由无头服务提供的稳定
    DNS 名称可以帮助在 Kubernetes 上以 StatefulSets 的形式运行此类集群。仍然存在在扩展期间添加或删除 Pod 副本时更改配置的问题。在某些情况下，*sidecar
    容器模式*可以解决这个问题，它监控 Kubernetes API 以动态更改数据库配置。
- en: If you decide to implement your own storage solution running as StatefulSet
    with advanced data sharding, you will most likely need mappings of logical shards
    to physical Pod replicas in the cluster. Then, the stable DNS names can be used
    as part of this mapping. They will guarantee that queries for each logical shard
    are performed against a proper Pod, irrespective of whether it was rescheduled
    to another Node or restarted.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你决定实现自己的存储解决方案，并将其作为 StatefulSet 运行，具有高级数据分片功能，你很可能需要将逻辑分片映射到集群中的物理 Pod 副本。然后，稳定的
    DNS 名称可以作为映射的一部分使用。它们将确保每个逻辑分片的查询始终发送到正确的 Pod，无论该 Pod 是否被重新调度到另一个节点或重启。
- en: Finally, let’s take a look at the state persistence for Pods running in StatefulSet.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们看看运行在 StatefulSet 中的 Pods 的状态持久性。
- en: State persistence
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 状态持久性
- en: As we demonstrated earlier, the data is persistent inside the PV and will bound
    back to the newly created Pod with the same ordinal number.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前演示的，数据会在 PV 内持久化，并将绑定到具有相同顺序号的新创建的 Pod。
- en: 'In the following example, we are deleting all of the Pods in the StatefulSet:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下示例中，我们正在删除 StatefulSet 中的所有 Pods：
- en: '[PRE24]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Kubernetes will recreate all of the Pods in the same order as follows:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 会按以下顺序重新创建所有 Pods：
- en: '[PRE25]'
  id: totrans-156
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We can also verify the PVs mounted to ensure the Pod to PVC binding was successful:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以验证已挂载的 PV，以确保 Pod 到 PVC 的绑定成功：
- en: '[PRE26]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: As you have learned, the PV will not be removed by the StatefulSet controller
    as part of Pod or StatefulSet deletion. It is your responsibility to clean up
    the data by removing the PVs manually if you are removing the StatefulSet objects
    completely.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所学到的，StatefulSet 控制器不会在 Pod 或 StatefulSet 删除时删除 PV。若你完全删除 StatefulSet 对象，清理数据并手动删除
    PV 是你的责任。
- en: Next, we will take a look at scaling the StatefulSet object.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看看如何扩展 StatefulSet 对象。
- en: Scaling StatefulSet
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展 StatefulSet
- en: In the case of StatefulSets, you can do similar *scaling* operations as for
    Deployment objects by changing the number of `replicas` in the specification or
    using the `kubectl scale` imperative command. The new Pods will automatically
    be discovered as new Endpoints for the Service when you scale up, or automatically
    removed from the Endpoints list when you scale down.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在 StatefulSet 的情况下，你可以像操作 Deployment 对象一样执行类似的*扩展*操作，通过更改规格中的 `replicas` 数量或使用
    `kubectl scale` 命令。新 Pods 会在扩展时自动作为服务的新 Endpoints 被发现，或者在缩减时自动从 Endpoints 列表中移除。
- en: 'However, there are a few differences when compared to Deployment objects:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，与 Deployment 对象相比，仍然存在一些差异：
- en: When you deploy a StatefulSet object of `N` replicas, the Pods during deployment
    are created sequentially, in order from `0` to `N`-`1`. In our example, during
    the creation of a StatefulSet object of three replicas, the first `mysql-stateful-0`
    Pod is created, followed by `n mysql-stateful-1`, and finally `mysql-stateful-2`.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你部署一个有 `N` 个副本的 StatefulSet 对象时，部署过程中，Pods 是按顺序创建的，从 `0` 到 `N`-`1`。在我们的示例中，创建一个有三个副本的
    StatefulSet 对象时，第一个 `mysql-stateful-0` Pod 被创建，然后是 `mysql-stateful-1`，最后是 `mysql-stateful-2`。
- en: When you scale *up* the StatefulSet, the new Pods are also created sequentially
    and in an ordered fashion.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你*扩容*StatefulSet时，新的Pod也会按顺序创建，并且有序进行。
- en: When you scale *down* the StatefulSet, the Pods are terminated sequentially,
    in *reverse order*, from `N`*-*`1` to `0`. In our example, while scaling down
    the StatefulSet object to zero replicas, the `mysql-stateful-2` Pod is terminated,
    followed by `mysql-stateful-1`, and finally `mysql-stateful-0`.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你*缩容*StatefulSet时，Pod会按*反向顺序*依次终止，从`N`*-*`1`到`0`。在我们的例子中，当StatefulSet对象缩容至零副本时，`mysql-stateful-2`
    Pod首先被终止，然后是`mysql-stateful-1`，最后是`mysql-stateful-0`。
- en: During the scaling up of the StatefulSet object, before the next Pod is created
    in the sequence, all its predecessors must be *running* and *ready*.
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在StatefulSet对象进行扩容时，在按顺序创建下一个Pod之前，所有前一个Pod必须是*运行中*并且*就绪的*。
- en: During the scaling *down* of the StatefulSet object, before the next Pod is
    terminated in the reverse sequence, all its predecessors must be completely *terminated*
    and *deleted*.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在StatefulSet对象进行*缩容*时，在下一个Pod按反向顺序终止之前，所有前一个Pod必须完全*终止*并被*删除*。
- en: Also, in general, before *any* scaling operation is applied to a Pod in a StatefulSet
    object, all its predecessors must be running and ready. This means that if, during
    scaling down from four replicas to one replica, the `mysql-stateful-0` Pod were
    to suddenly fail, then no further scaling operation would be performed on the
    `mysql-stateful-1`, `mysql-stateful-2`, and `mysql-stateful-3` Pods. Scaling would
    resume when the `mysql-stateful-0` Pod becomes ready again.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，通常在对StatefulSet对象中的Pod执行*任何*扩展操作之前，所有前一个Pod必须处于运行并就绪状态。这意味着，如果在从四个副本缩容到一个副本时，`mysql-stateful-0`
    Pod突然失败，那么就不会对`mysql-stateful-1`、`mysql-stateful-2`和`mysql-stateful-3` Pod进行进一步的扩展操作。扩展操作将在`mysql-stateful-0`
    Pod重新就绪后恢复。
- en: This sequential behavior of scaling operations can be relaxed by changing the
    `.spec.podManagementPolicy` field in the specification. The default value is `OrderedReady`.
    If you change it to `Parallel`, the scaling operations will be performed on Pods
    in parallel, similar to what you know from Deployment objects. Note that this
    only affects scaling operations. The way of updating the StatefulSet object with
    `updateStrategy` of the `RollingUpdate` type does not change.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 通过更改规范中的`.spec.podManagementPolicy`字段，可以放宽扩展操作的顺序行为。默认值为`OrderedReady`。如果将其更改为`Parallel`，则扩展操作将在Pod上并行执行，类似于Deployment对象中的操作。请注意，这仅影响扩展操作。使用`RollingUpdate`类型的`updateStrategy`更新StatefulSet对象的方式不变。
- en: 'Equipped with this knowledge, let’s *scale up* our StatefulSet imperatively
    to demonstrate it quickly:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 具备了这些知识后，让我们*扩容*我们的StatefulSet对象，快速演示一下：
- en: 'Scale out the StatefulSet using the following command:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令扩展StatefulSet：
- en: '[PRE27]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'If you now check the Pods using the `kubectl get pods` command, you will see
    the sequential, ordered creation of new Pods:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你现在使用`kubectl get pods`命令检查Pod，你将看到新的Pod按顺序创建：
- en: '[PRE28]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Similarly, if you check the output of the `kubectl describe` command for the
    StatefulSet object, you will see the following in the events:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果你检查StatefulSet对象的`kubectl describe`命令输出，你会在事件中看到以下内容：
- en: '[PRE29]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You can see that the last two Pods – `mysql-stateful-3` and `mysql-stateful-2`
    – are deleted in an orderly way. Now, let us check the Pods in the `statefulset`
    as follows:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到最后两个Pod——`mysql-stateful-3`和`mysql-stateful-2`——已按顺序删除。现在，让我们检查`statefulset`中的Pod，如下所示：
- en: '[PRE30]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Check the PVCs now and you will see the PVCs are still there. This is an expected
    situation for StatefulSet, as we learned earlier:'
  id: totrans-180
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在检查PVC，你会发现PVC仍然存在。这是StatefulSet的预期情况，正如我们之前所学到的：
- en: '[PRE31]'
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: When managing StatefulSets with **Horizontal Pod Autoscaler** (**HPA**) or similar
    horizontal scaling tools, refrain from specifying a value for `.spec.replicas`
    in your manifest. Instead, leave it unset. The Kubernetes control plane will dynamically
    adjust the number of replicas as per resource requirements, facilitating efficient
    scaling of your application without the need for manual intervention.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用**水平Pod自动扩展器**（**HPA**）或类似的水平扩展工具管理StatefulSet时，避免在清单中为`.spec.replicas`指定值。相反，保持该字段为空。Kubernetes控制平面会根据资源需求动态调整副本数，从而有效地扩展你的应用程序，无需手动干预。
- en: Congratulations! We have learned how to deploy and scale StatefulSet objects.
    Next, we will demonstrate how you can delete a StatefulSet object.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！我们已经学会了如何部署和扩展StatefulSet对象。接下来，我们将演示如何删除StatefulSet对象。
- en: Deleting a StatefulSet
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除StatefulSet
- en: 'To delete a StatefulSet object, there are two possibilities:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 删除 StatefulSet 对象有两种可能性：
- en: Delete the StatefulSet together with Pods that it owns
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除 StatefulSet 及其拥有的 Pods
- en: Delete the StatefulSet and leave the Pods unaffected
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除 StatefulSet 并保持 Pods 不受影响
- en: In both cases, the PVCs and PVs that were created for the Pods using `volumeClaimTemplates`
    will *not* be deleted by default. This ensures that state data is not lost accidentally
    unless you explicitly clean up the PVCs and PVs.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，使用 `volumeClaimTemplates` 为 Pods 创建的 PVC 和 PV 默认*不会*被删除。这确保了状态数据不会意外丢失，除非你明确清理
    PVC 和 PV。
- en: 'But with the latest Kubernetes versions (from v1.27 onwards), you can use the
    `.spec.persistentVolumeClaimRetentionPolicy` field to control the deletion of
    PVCs as part of the StatefulSet life cycle:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 但是在最新的 Kubernetes 版本（从 v1.27 开始）中，你可以使用 `.spec.persistentVolumeClaimRetentionPolicy`
    字段来控制 PVC 在 StatefulSet 生命周期中的删除：
- en: '[PRE32]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Refer to the documentation to learn more about `persistentVolumeClaimRetentionPolicy`
    (https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention).
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅文档以了解更多关于 `persistentVolumeClaimRetentionPolicy` 的信息（https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention）。
- en: 'To delete the StatefulSet object together with Pods, you can use the regular
    `kubectl delete` command:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除 StatefulSet 对象及其 Pods，你可以使用常规的 `kubectl delete` 命令：
- en: '[PRE33]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: You will see that the Pods will be terminated first, followed by the StatefulSet
    object. Please note that this operation is different from *scaling down* the StatefulSet
    object to zero replicas and then deleting it. If you delete the StatefulSet object
    with existing Pods, there are no guarantees regarding the order of termination
    of the individual Pods. In most cases, they will be terminated at once.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到 Pods 会首先被终止，然后是 StatefulSet 对象。请注意，这一操作与将 StatefulSet 对象*缩容*至零副本并删除它的操作不同。如果你删除包含现有
    Pods 的 StatefulSet 对象，无法保证单个 Pods 的终止顺序。在大多数情况下，它们会被同时终止。
- en: 'Optionally, if you would like to delete just the StatefulSet object, you need
    to use the `--cascade=orphan` option for `kubectl delete`:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 可选地，如果你只想删除 StatefulSet 对象，你需要为 `kubectl delete` 命令使用 `--cascade=orphan` 选项：
- en: '[PRE34]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: After this command, if you inspect what Pods are in the cluster, you will still
    see all the Pods that were owned by the `mysql-stateful` StatefulSet.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此命令后，如果你检查集群中的 Pods，你仍然会看到所有由 `mysql-stateful` StatefulSet 所拥有的 Pods。
- en: 'Lastly, if you would like to clean up PVCs and PVs after deleting the StatefulSet
    object, you need to perform this step manually. Use the following command to delete
    the PVC’s created as part of the StatefulSet:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果你希望在删除 StatefulSet 对象后清理 PVC 和 PV，你需要手动执行此步骤。使用以下命令删除作为 StatefulSet 一部分创建的
    PVC：
- en: '[PRE35]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This command will delete PVCs and associated PVs.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将删除 PVC 及相关的 PV。
- en: IMPORTANT NOTE
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Please note that if you want to perform verifications of state persistence after
    exercising the new version rollout in the next section, you should not yet delete
    the PVCs. Otherwise, you will lose the MySQL files stored in the PVs.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果你想在下一部分的新版本发布过程中验证状态持久性，你不应该删除 PVC。否则，你将丢失存储在 PV 中的 MySQL 文件。
- en: With this section, we have completed our learning on basic operations with the
    StatefulSet objects in Kubernetes. Next, let’s take a look at releasing new versions
    of apps deployed as StatefulSets and how StatefulSet revisions are managed.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这一部分，我们完成了对 Kubernetes 中 StatefulSet 对象基本操作的学习。接下来，让我们看看如何发布作为 StatefulSet
    部署的应用的新版本，以及 StatefulSet 修订版是如何管理的。
- en: Releasing a new version of an app deployed as a StatefulSet
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发布作为 StatefulSet 部署的应用的新版本
- en: We have just covered the *scaling* of StatefulSets in the previous section by
    the `kubectl scale` command (or by making changes to the `.spec.replicas` number
    in the specification). Everything you have learned about sequential and ordered
    changes to the Pods plays an important role in rolling out a new revision of a
    StatefulSet object when using the `RollingUpdate` strategy. There are many similarities
    between StatefulSets and Deployment objects. We covered the details of Deployment
    updates in *Chapter 11*, *Using Kubernetes Deployments for Stateless Workloads*.
    Making changes to the StatefulSet Pod *template* (`.spec.template`) in the specification
    will also cause the rollout of a new revision for StatefulSet.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节中已经介绍了StatefulSet的*扩缩容*，通过`kubectl scale`命令（或通过修改规范中的`.spec.replicas`数量）。你所学到的关于Pod的顺序和有序变化的知识在使用`RollingUpdate`策略推出StatefulSet对象的新版本时发挥着重要作用。StatefulSet和Deployment对象之间有许多相似之处。我们在*第11章*《使用Kubernetes部署无状态工作负载》中详细讨论了Deployment更新的内容。对StatefulSet
    Pod *模板*（`spec.template`）的更改也会导致StatefulSet的新版本发布。
- en: 'StatefulSets support two types of *update strategies* that you define using
    the `.spec.updateStrategy.type` field in the specification:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSet支持两种*更新策略*，你可以通过规范中的`.spec.updateStrategy.type`字段来定义它们：
- en: '`RollingUpdate`: The default strategy, which allows you to roll out a new version
    of your application in a controlled way. This is slightly different from the `RollingUpdate`
    strategy known from Deployment objects. For StatefulSet, this strategy will terminate
    and recreate Pods in a sequential and ordered fashion and make sure that the Pod
    is recreated and in a ready state before proceeding to the next one.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RollingUpdate`：默认策略，允许你以可控的方式推出应用程序的新版本。这与Deployment对象中已知的`RollingUpdate`策略略有不同。对于StatefulSet，该策略会以顺序和有序的方式终止并重新创建Pod，并确保在继续处理下一个Pod之前，Pod已经重新创建并处于就绪状态。'
- en: '`OnDelete`: This strategy implements the legacy behavior of StatefulSet updates
    prior to Kubernetes 1.7\. However, it is still useful! In this type of strategy,
    StatefulSet will *not* automatically update the Pod replicas by recreating them.
    You need to manually delete a Pod replica to get the new Pod template applied.
    This is useful in scenarios when you need to perform additional manual actions
    or verifications before proceeding to the next Pod replica. For example, if you
    are running a *Cassandra cluster* or an *etcd cluster* in a StatefulSet, you may
    want to verify whether the new Pod has correctly joined the existing cluster following
    the removal of the previous version of the Pod. Of course, it is possible to perform
    similar checks using the Pod template life cycle `postStart` and `preStop` hooks
    while using the `RollingUpdate` strategy, but this requires more sophisticated
    error handling in the hooks.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OnDelete`：此策略实现了Kubernetes 1.7之前StatefulSet更新的传统行为。然而，它仍然非常有用！在这种策略下，StatefulSet
    *不会*通过重新创建Pod副本来自动更新Pod副本。你需要手动删除Pod副本，以便应用新的Pod模板。在需要在继续处理下一个Pod副本之前执行额外的手动操作或验证的场景中，这非常有用。例如，如果你在StatefulSet中运行一个*Cassandra集群*或*etcd集群*，你可能想要验证新的Pod在删除旧版本Pod之后，是否正确地加入了现有集群。当然，使用`RollingUpdate`策略时，也可以通过Pod模板生命周期中的`postStart`和`preStop`钩子来执行类似的检查，但这需要在钩子中处理更复杂的错误。'
- en: Let’s now take a closer look at the `RollingUpdate` strategy, which is the most
    important and commonly used update strategy for StatefulSets. The key thing about
    this is that the strategy respects all the StatefulSet guarantees, which we explained
    in the previous section regarding scaling. The rollout is done in reverse order;
    for example, the first Pod, `mysql-stateful-2`, is recreated with the new Pod
    template, followed by `mysql-stateful-1`, and finally `mysql-stateful-0`.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们仔细看看`RollingUpdate`策略，这是StatefulSet最重要和最常用的更新策略。关键在于，这个策略尊重我们在上一节中解释的关于扩缩容的StatefulSet保证。发布是按相反的顺序进行的；例如，第一个Pod
    `mysql-stateful-2` 会使用新的Pod模板重新创建，接着是`mysql-stateful-1`，最后是`mysql-stateful-0`。
- en: If the process of rollout fails (not necessarily the Pod that was currently
    recreated), the StatefulSet controller is going to restore any failed Pod to its
    *current version*. This means that the Pods that have already received a *successful*
    update to the current version will remain at the current version, whereas the
    Pods that have not yet received the update will remain at the previous version.
    In this way, the StatefulSet attempts to always keep applications healthy and
    consistent. However, this can also lead to *broken* rollouts of StatefulSets.
    If one of the Pod replicas *never* becomes running and ready, then the StatefulSet
    will stop the rollout and wait for *manual* intervention. Applying the template
    again to the previous revision of StatefulSet is not enough – this operation will
    not proceed as the StatefulSet will wait for the failed Pod to become ready. The
    only resolution is manual deletion of the failed Pod and then having the StatefulSet
    apply the previous revision of the Pod template.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 如果发布过程中失败（不一定是当前重新创建的Pod），StatefulSet控制器会将任何失败的Pod恢复到其*当前版本*。这意味着已经成功更新到当前版本的Pod将保持在当前版本，而尚未更新的Pod将保持在之前的版本。这样，StatefulSet会尽力保持应用的健康和一致性。然而，这也可能导致StatefulSet的*失败*发布。如果某个Pod副本*永远*没有变为运行并准备好，StatefulSet将停止发布并等待*手动*干预。仅仅再次应用模板到StatefulSet的先前版本是不够的——这个操作不会继续，因为StatefulSet会等待失败的Pod变为就绪。唯一的解决方法是手动删除失败的Pod，然后让StatefulSet应用Pod模板的先前版本。
- en: Lastly, the `RollingUpdate` strategy also provides the option to execute *staged*
    rollouts using the `.spec.updateStrategy.rollingUpdate.partition` field. This
    field defines a number for which all the Pod replicas that have a *lesser* *ordinal*
    number will not be updated, and, even if they are deleted, they will be recreated
    at the previous version. So, in our example, if the `partition` were to be set
    to `1`, this means that during the rollout, only `mysql-stateful-1` and `mysql-stateful-2`
    would be updated, whereas `mysql-stateful-0` would remain unchanged and run on
    the previous version. By controlling the `partition` field, you can easily roll
    out a single *canary* replica and perform *phased* rollouts. Please note that
    the default value is `0`, which means that all Pod replicas will be updated.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`RollingUpdate`策略还提供了使用`.spec.updateStrategy.rollingUpdate.partition`字段执行*分阶段*发布的选项。此字段定义了一个数字，所有*较小*的Pod副本序号将不会被更新，即使它们被删除，也会按之前的版本重新创建。因此，在我们的示例中，如果将`partition`设置为`1`，这意味着在发布过程中，只有`mysql-stateful-1`和`mysql-stateful-2`会被更新，而`mysql-stateful-0`将保持不变，并运行在之前的版本。通过控制`partition`字段，你可以轻松地发布单个*金丝雀*副本并执行*分阶段*发布。请注意，默认值为`0`，这意味着所有Pod副本都会被更新。
- en: Now, we will release a new version of our mysqlserver using the `RollingUpdate`
    strategy.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用`RollingUpdate`策略发布新的mysqlserver版本。
- en: Updating StatefulSet
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更新StatefulSet
- en: 'We will now demonstrate how to do a rollout of a new image version for a Pod
    container using the StatefulSet YAML manifest file that we created previously:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将演示如何使用之前创建的StatefulSet YAML清单文件，发布Pod容器的新镜像版本：
- en: 'Make a copy of the previous YAML manifest file:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制之前的YAML清单文件：
- en: '[PRE36]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Ensure that you have the `RollingUpdate` strategy type and `partition` set
    to `0`. Also note that if you have attempted to create the StatefulSet object
    with a different strategy first, you will not be able to modify it without deleting
    the StatefulSet beforehand:'
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你使用的是`RollingUpdate`策略类型，并将`partition`设置为`0`。同时请注意，如果你曾尝试先使用不同的策略创建StatefulSet对象，在删除StatefulSet之前无法修改它：
- en: '[PRE37]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: These values are the default ones, but it is worth specifying them explicitly
    to understand what is really happening.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值是默认值，但明确指定它们有助于理解实际发生了什么。
- en: 'Apply the manifest file to the cluster to create the `mysql-stateful` StatefulSet
    with new configurations:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将清单文件应用到集群中，以使用新配置创建`mysql-stateful` StatefulSet：
- en: '[PRE38]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Wait until the Pods are running before you continue the rolling update task.
    Let’s verify the pods created by StatefulSet using the `kubectl get pods` command
    as follows:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续滚动更新任务之前，等待Pod运行。我们可以通过以下`kubectl get pods`命令验证由StatefulSet创建的Pod：
- en: '[PRE39]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'When the StatefulSet is ready in the cluster, let’s create a new database inside
    the StatefulSet via the k8sutils Pod as follows:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 当StatefulSet在集群中准备好后，我们将通过k8sutils Pod在StatefulSet内部创建一个新数据库，如下所示：
- en: '[PRE40]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: Now, we have a new StatefulSet with `updateStrategy` and a new database created
    inside.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了一个新的StatefulSet，带有`updateStrategy`，并在其中创建了一个新的数据库。
- en: 'Next, we can roll out a new version of the MySQL container image for our StatefulSet
    object. To do that, perform the following steps:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以为我们的StatefulSet对象发布一个新的MySQL容器镜像版本。为此，执行以下步骤：
- en: 'Modify the container image used in the StatefulSet Pod template to `mysql:8.3.0`:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将StatefulSet Pod模板中使用的容器镜像修改为`mysql:8.3.0`：
- en: '[PRE41]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Apply the changes to the cluster using the following command:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将更改应用到集群中：
- en: '[PRE42]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Immediately after that, use the `kubectl rollout status` command to see the
    progress in real time. This process will be a bit longer than in the case of Deployment
    objects because the rollout is performed in a sequential and ordered fashion:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 紧接着，使用`kubectl rollout status`命令查看实时进度。由于发布是按顺序和有序的方式进行的，这个过程比Deployment对象要稍长一些：
- en: '[PRE43]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Similarly, using the `kubectl describe` command, you can see events for the
    StatefulSet that demonstrate precisely what the order of Pod replica recreation
    was:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似地，使用`kubectl describe`命令，你可以查看StatefulSet的事件，这些事件精确展示了Pod副本重建的顺序：
- en: '[PRE44]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: As expected, the rollout was done in *reverse* order. The first Pod to recreate
    was `mysql-stateful-2` followed by `mysql-stateful-1`, and finally `mysql-stateful-0`.
    Also, because we have used the default `partition` value of `0`, all the Pods
    were updated. This is because all ordinal numbers of Pod replicas are greater
    than or equal to `0`.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 如预期的那样，发布是按*相反*顺序完成的。第一个重建的Pod是`mysql-stateful-2`，然后是`mysql-stateful-1`，最后是`mysql-stateful-0`。此外，由于我们使用了默认的`partition`值`0`，所有的Pods都被更新了。这是因为所有Pod副本的顺序编号都大于或等于`0`。
- en: 'Now, we can verify that the Pods were recreated with the new image. Execute
    the following command to verify the first Pod replica in the StatefulSet object:'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们可以验证Pods是否使用新镜像进行了重建。执行以下命令来验证StatefulSet对象中的第一个Pod副本：
- en: '[PRE45]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'And finally, you can verify that the *state* persisted because the existing
    PVCs were used for the new Pods. Please note that this will only work properly
    if you haven’t deleted the PVCs for the StatefulSet manually in the previous section:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，你可以验证*状态*是否得以保持，因为新Pods使用了现有的PVC。请注意，只有在你没有在前一部分手动删除StatefulSet的PVC时，这一过程才能正常工作：
- en: '[PRE46]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: As you can see in the preceding output, the rollout of a new version of MySQL
    was completed successfully and the state has persisted even though the Pods were
    recreated; you can see the `stsrolling` database, which you created before the
    rolling update.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 如你在上面的输出中所看到的，MySQL新版本的发布已成功完成，状态得以保持，尽管Pods被重建了；你可以看到`stsrolling`数据库，这是你在滚动更新之前创建的。
- en: You can change the StatefulSet container image *imperatively* using the kubectl
    -n mysql set image sts `mysql-stateful mysql=mysql:8.3.0` command. This approach
    is only recommended for non-production and testing scenarios. In general, StatefulSets
    are much easier to manage declaratively than imperatively.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用`kubectl -n mysql set image sts mysql-stateful mysql=mysql:8.3.0`命令*命令式*地修改StatefulSet容器镜像。这种方法仅推荐用于非生产环境和测试场景。一般来说，StatefulSets比起命令式管理，更容易通过声明式方式进行管理。
- en: 'Now, let us learn how you can use the `partition` field to do a *phased* rollout
    with a *canary*. Assume that we would like to update the mysql image version to
    `8.4.0`. You would like to make sure that the change is working properly in your
    environment using a canary deployment, which is a single (or some) Pod replica
    updated to the new image (or another image) version. Please refer to the following
    steps:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们学习如何使用`partition`字段进行*分阶段*发布，并使用*金丝雀发布*。假设我们想要将mysql镜像版本更新为`8.4.0`。你希望通过金丝雀发布确保更改在你的环境中正常工作，这是一种将单个（或部分）Pod副本更新为新镜像（或其他镜像）版本的方法。请参考以下步骤：
- en: 'Modify the `mysql-statefulset-rolling-update.yaml` manifest file so that the
    `partition` number is equal to current `replicas`, in our case, `3`:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改`mysql-statefulset-rolling-update.yaml`清单文件，使`partition`数字等于当前`replicas`，在我们的案例中是`3`：
- en: '[PRE47]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: When the `partition` number is the same as the number of `replicas`, we can
    apply the YAML manifest to the cluster and no changes to the Pods will be introduced
    yet. This is called **staging a rollout**.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 当`partition`的数字与`replicas`的数量相同，我们可以将YAML清单文件应用到集群中，而Pods将不会立即发生变化。这称为**发布预演**。
- en: 'Apply the manifest file to the cluster:'
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将清单文件应用到集群中：
- en: '[PRE48]'
  id: totrans-248
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Now, let’s create a *canary* for our new version. Decrease the `partition`
    number by one to `2` in the manifest file. This means that all Pod replicas with
    an ordinal number of less than `2` will not be updated – in our case, that means
    updating the `mysql-stateful-2` Pod only. All others will remain unchanged:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们为新版本创建一个*金丝雀*。在清单文件中将`partition`数量减少 1 至`2`。这意味着所有序号小于`2`的 Pod 副本将不会更新——在我们的例子中，这仅意味着更新`mysql-stateful-2`
    Pod。其他 Pod 将保持不变：
- en: '[PRE49]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Apply the manifest file to the cluster again:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次将清单文件应用到集群中：
- en: '[PRE50]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Use the `kubectl rollout status` command to follow the process. As expected,
    only one Pod will be recreated:'
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl rollout status`命令来跟踪进程。如预期，只有一个 Pod 会被重新创建：
- en: '[PRE51]'
  id: totrans-254
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'If you describe the MySQL `mysql-stateful-0` and MySQL `mysql-stateful-2` Pods,
    you can see that the first one is using the old version of the image, whereas
    the second is using the new one:'
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你描述 MySQL `mysql-stateful-0` 和 MySQL `mysql-stateful-2` Pods，你会发现第一个 Pod 使用的是旧版本的镜像，而第二个
    Pod 则使用的是新版本：
- en: '[PRE52]'
  id: totrans-256
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'At this point, you can perform verifications and smoke tests on your canary.
    Log in to the k8sutils Pod and ensure the new Pod is running well with the new
    image (e.g., 8.4.0). The canary looks good, so we can continue with a *phased*
    rollout of our new version:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此时，你可以对金丝雀进行验证和冒烟测试。登录到 k8sutils Pod，并确保新的 Pod 使用新镜像（例如，8.4.0）运行正常。金丝雀看起来没有问题，所以我们可以继续进行新版本的*阶段性*发布：
- en: '[PRE53]'
  id: totrans-258
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'For a phased rollout, you may use any *lower* `partition` number in the manifest.
    You can do a few small, phased rollouts or just proceed with a full rollout. Let’s
    do a full rollout by decreasing `partition` to `0`:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于阶段性发布，你可以在清单中使用任何*较低*的`partition`值。你可以进行几个小的阶段性发布，或者直接进行完全发布。让我们通过将`partition`减少到`0`来进行完全发布：
- en: '[PRE54]'
  id: totrans-260
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Apply the manifest file to the cluster again:'
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次将清单文件应用到集群中：
- en: '[PRE55]'
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Observe the next phase of the rollout using the `kubectl rollout status` command:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl rollout status`命令观察发布的下一个阶段：
- en: '[PRE56]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: As you can see, the phased rollout to the `mysql:8.4.0` image version was completed
    successfully.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，`mysql:8.4.0` 镜像版本的阶段性发布已成功完成。
- en: It is possible to do phased rollouts *imperatively*. To do that, you need to
    control the `partition` number using the `kubectl patch` command, for example,
    `kubectl patch sts mysql-stateful -p '{"spec":{"updateStrategy":{"type":"RollingUpdate","rollingUpdate":{"partition":3}}}}'
    -n mysql`. However, this is much less readable and more error-prone than *declarative*
    changes.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过*命令式*的方式进行阶段性发布。为此，你需要使用`kubectl patch`命令来控制`partition`数量，例如，`kubectl patch
    sts mysql-stateful -p '{"spec":{"updateStrategy":{"type":"RollingUpdate","rollingUpdate":{"partition":3}}}}'
    -n mysql`。然而，这种方式的可读性较差，且比*声明式*变更更容易出错。
- en: We will now take a look at how you can do rollbacks of StatefulSets in the next
    section.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将看一下如何在下一部分执行 StatefulSets 的回滚操作。
- en: Rolling back StatefulSet
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回滚 StatefulSet
- en: In the previous *Chapter 11*, *Using Kubernetes Deployments for Stateless Workloads*,
    we have described how you can do *imperative* rollbacks to Deployments. For StatefulSets,
    you can do exactly the same operations. To do that, you need to use the `kubectl
    rollout undo` commands. However, especially for StatefulSets, we recommend using
    a *declarative* model for introducing changes to your Kubernetes cluster. In this
    model, you usually commit each change to the source code repository. Performing
    rollback is very simple and involves just reverting the commit and applying the
    configuration again. Usually, the process of applying changes (both deployment
    and updates) can be performed as part of the CI/CD pipeline for the source code
    repository, instead of manually applying the changes by an operator. This is the
    easiest way to manage StatefulSets, and is generally recommended in Infrastructure-as-Code
    and Configuration-as-Code paradigms.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的*第11章*《*使用 Kubernetes 部署无状态工作负载*》中，我们已经描述了如何对部署进行*命令式*回滚。对于 StatefulSets，你可以做完全相同的操作。为此，你需要使用`kubectl
    rollout undo`命令。然而，特别是对于 StatefulSets，我们建议使用*声明式*模型来引入更改到 Kubernetes 集群中。在这种模型下，通常会将每个更改提交到源代码仓库中。执行回滚非常简单，只需要恢复提交并再次应用配置即可。通常，应用更改（包括部署和更新）的过程可以作为源代码仓库的
    CI/CD 管道的一部分来执行，而不是由操作员手动应用更改。这是管理 StatefulSets 最简单的方法，在基础设施即代码（Infrastructure-as-Code）和配置即代码（Configuration-as-Code）范式中通常是推荐的方式。
- en: When performing rollbacks to StatefulSets, you must be fully aware of the consequences
    of operations such as *downgrading* to an earlier version of the container image
    while persisting the state. For example, if your rollout to a new version has
    introduced *data schema changes* to the state, then you will not be able to safely
    roll back to an earlier version unless you ensure that the *downward migration*
    of state data is implemented!
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行对 StatefulSets 的回滚操作时，你必须充分意识到一些操作的后果，例如在保持状态的同时将容器镜像降级到早期版本。例如，如果你在升级到新版本时引入了*数据模式变化*，那么除非确保实现了*数据状态的向下迁移*，否则你将无法安全地回滚到早期版本！
- en: In our example, if you would like to roll back to the mysql:8.3.0 image version
    for our StatefulSet, you would either modify the YAML manifest file manually or
    revert the commit in your source code repository if you use one. Then, all you
    would need to do is execute the `kubectl apply` command to the cluster.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，如果你想将 StatefulSet 回滚到 mysql:8.3.0 镜像版本，你可以手动修改 YAML 清单文件，或者如果你使用源代码仓库，可以恢复该提交。然后，你需要做的就是对集群执行
    `kubectl apply` 命令。
- en: Now, in the last section of this chapter, we will provide you with a set of
    best practices for managing StatefulSets in Kubernetes.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在本章的最后一节，我们将为你提供一套在 Kubernetes 中管理 StatefulSets 的最佳实践。
- en: StatefulSet best practices
  id: totrans-273
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: StatefulSet 最佳实践
- en: This section summarizes the known best practices when working with StatefulSet
    objects in Kubernetes. The list is by no means complete but is a good starting
    point for your journey with Kubernetes StatefulSet.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 本节总结了在使用 Kubernetes 中的 StatefulSet 对象时已知的最佳实践。这个列表并非完整，但为你与 Kubernetes StatefulSet
    的使用旅程提供了一个很好的起点。
- en: Use declarative object management for StatefulSets
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对 StatefulSets 使用声明式对象管理
- en: It is a good practice in the DevOps world to stick to declarative models for
    introducing updates to your infrastructure and applications. Using the declarative
    way of updates is the core concept for paradigms such as Infrastructure-as-Code
    and Configuration-as-Code. In Kubernetes, you can easily perform declarative updates
    using the `kubectl apply` command, which can be used on a single file or even
    a whole directory of YAML manifest files.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在 DevOps 领域，遵循声明式模型来引入基础设施和应用程序更新是一种良好的实践。使用声明式更新方式是像基础设施即代码（Infrastructure-as-Code）和配置即代码（Configuration-as-Code）这样的范式的核心概念。在
    Kubernetes 中，你可以通过 `kubectl apply` 命令轻松地执行声明式更新，这个命令可以用于单个文件甚至整个 YAML 清单文件目录。
- en: To delete objects, it is still better to use imperative commands. It is more
    predictable and less prone to errors. The declarative deletion of resources in
    the cluster is useful mostly in CI/CD scenarios, where the whole process is entirely
    automated.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 对于删除对象，仍然最好使用命令式操作。这样更具可预测性，且更不容易出错。声明式删除集群中的资源主要适用于 CI/CD 场景，在这些场景中，整个过程是完全自动化的。
- en: The same principle also applies to StatefulSets. Performing a rollout or rollback
    when your YAML manifest files are versioned and kept in a source control repository
    is easy and predictable. Using the `kubectl rollout undo` method and `kubectl
    set image deployment` commands is generally not practiced in production environments.
    Using these commands gets much more complicated when more than one person is working
    on operations in the cluster.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 同样的原则也适用于 StatefulSets。当你的 YAML 清单文件被版本化并保存在源代码控制库中时，执行升级或回滚是简单且可预测的。通常在生产环境中不会使用
    `kubectl rollout undo` 方法和 `kubectl set image deployment` 命令。当有多人在集群中进行操作时，使用这些命令会变得更加复杂。
- en: Do not use the TerminationGracePeriodSeconds Pod with a 0 value for StatefulSets
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不要在 StatefulSets 中使用 TerminationGracePeriodSeconds 值为 0 的 Pod
- en: The specification of Pod allows you to set `TerminationGracePeriodSeconds`,
    which informs `kubelet` how much time it should allow for a Pod to gracefully
    terminate when it attempts to terminate it. If you set `TerminationGracePeriodSeconds`
    to `0`, this will effectively make Pods terminate *immediately*, which is strongly
    discouraged for StatefulSets. StatefulSets often need graceful cleanup or `preStop`
    life cycle hooks to run before the container is removed. Otherwise, there is a
    risk that the state of StatefulSet will become inconsistent. Refer to the Container
    hooks documentation (https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks)
    to learn more.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 的规格允许你设置 `TerminationGracePeriodSeconds`，该参数告诉 `kubelet` 在尝试终止 Pod 时，它应该允许多少时间来优雅地终止该
    Pod。如果你将 `TerminationGracePeriodSeconds` 设置为 `0`，这将使 Pods *立即*终止，这对于 StatefulSets
    强烈不推荐。StatefulSets 通常需要优雅的清理，或者需要在容器被移除之前运行 `preStop` 生命周期钩子。否则，StatefulSet 的状态可能会变得不一致。请参考容器钩子文档
    (https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks)
    以了解更多信息。
- en: Scale down StatefulSets before deleting
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在删除 StatefulSets 之前缩减规模
- en: When you delete a StatefulSet and you intend to reuse the PVCs later, you need
    to ensure that the StatefulSet terminates gracefully, in an ordered manner, so
    that any subsequent redeployment will not fail because of an inconsistent state
    in PVCs. If you perform the `kubectl delete` operation on your StatefulSet, all
    the Pods will be terminated *at once*. This is often not desired, and you should
    first scale down the StatefulSet gracefully to zero replicas and then delete the
    StatefulSet itself.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 当你删除一个 StatefulSet 并打算稍后重新使用 PVC 时，你需要确保 StatefulSet 以有序的方式优雅终止，这样后续的重新部署就不会因为
    PVC 状态不一致而失败。如果你对 StatefulSet 执行 `kubectl delete` 操作，所有的 Pods 会*同时*终止。这通常是不可取的，你应该首先将
    StatefulSet 优雅地缩减到零副本，然后再删除 StatefulSet 本身。
- en: Ensure state compatibility during StatefulSet rollbacks
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 确保 StatefulSet 回滚期间的状态兼容性
- en: If you ever intend to use StatefulSet rollbacks, you need to be aware of the
    consequences of operations such as downgrading to an earlier version of the container
    image while persisting the state. For example, if your rollout to a new version
    has introduced data schema changes in the state, then you will not be able to
    safely roll back to an earlier version unless you ensure that the downward migration
    of state data is implemented. Otherwise, your rollback will just recreate Pods
    with the older versions of the container image, and they will fail to start properly
    because of incompatible state data.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打算使用 StatefulSet 回滚，你需要了解在持久化状态的同时，执行操作（例如降级到较早版本的容器镜像）所带来的后果。例如，如果你升级到新版本时引入了数据架构变化，那么除非你确保实现了状态数据的向下迁移，否则你将无法安全地回滚到早期版本。否则，你的回滚将仅重新创建具有旧版本容器镜像的
    Pods，而这些 Pods 将无法正常启动，因为状态数据不兼容。
- en: Do not create Pods that match an existing StatefulSet label selector
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 不要创建与现有 StatefulSet 标签选择器匹配的 Pods
- en: 'It is possible to create Pods with labels that match the label selector of
    some existing StatefulSet. This can be done using bare Pods or another Deployment
    or ReplicaSet. This leads to conflicts, which Kubernetes does not prevent, and
    makes the existing StatefulSet *believe* that it has created the other Pods. The
    results may be unpredictable and, in general, you need to pay attention to how
    you organize your labeling of resources in the cluster. It is advised to use semantic
    labeling. You can learn more about this approach in the official documentation:
    [https://kubernetes.io/docs/concepts/configuration/overview/#using-labels](https://kubernetes.io/docs/concepts/configuration/overview/#using-labels).'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 可以创建与某些现有 StatefulSet 标签选择器匹配的 Pods。这可以通过裸 Pods 或其他 Deployment 或 ReplicaSet
    来完成。这会导致冲突，Kubernetes 并不会阻止这种情况，并使现有的 StatefulSet *认为*它已经创建了其他 Pods。结果可能是不可预测的，通常来说，你需要注意如何在集群中组织资源的标签。建议使用语义化标签。你可以在官方文档中了解更多关于这种方法的信息：[https://kubernetes.io/docs/concepts/configuration/overview/#using-labels](https://kubernetes.io/docs/concepts/configuration/overview/#using-labels)。
- en: Use Remote Storage for the PV
  id: totrans-287
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用远程存储作为 PV
- en: When using StatefulSets, it’s important to ensure that you’re utilizing remote
    storage. This means storing your application’s data on a separate storage system,
    typically **Network-Attached Storage** (**NAS**), **Storage Area Network** (**SAN**),
    or a cloud storage service. By storing data remotely, you ensure that it’s accessible
    from any instance of your application (or any nodes in the cluster), even if the
    instance is replaced or moved. This provides data persistence and resilience,
    helping to prevent data loss in case of failures or updates to your StatefulSet.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 StatefulSets 时，确保使用远程存储非常重要。这意味着将应用程序的数据存储在一个单独的存储系统中，通常是**网络附加存储**（**NAS**）、**存储区域网络**（**SAN**）或云存储服务。通过远程存储数据，你可以确保从应用程序的任何实例（或集群中的任何节点）访问这些数据，即使该实例被替换或移动。这提供了数据持久性和弹性，帮助防止在
    StatefulSet 失败或更新时的数据丢失。
- en: Define liveness and readiness probes
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义活跃性和就绪性探针
- en: For stateful applications, a healthy Pod needs to not only be running but also
    be able to access and process its persistent state. Liveness probes help ensure
    this functionality. If a liveness probe fails consistently, it indicates a deeper
    issue with the Pod’s ability to handle its state. Restarting the Pod in this case
    can potentially trigger recovery mechanisms or allow the StatefulSet controller
    to orchestrate a failover to another healthy Pod with the same state.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 对于有状态的应用程序，一个健康的 Pod 需要不仅仅是运行，还要能够访问和处理其持久化的状态。活跃性探针有助于确保这一功能。如果活跃性探针持续失败，这意味着
    Pod 处理其状态的能力存在更深层次的问题。在这种情况下，重启 Pod 可能会触发恢复机制，或允许 StatefulSet 控制器将故障切换到另一个健康的、具有相同状态的
    Pod。
- en: StatefulSets often manage services that rely on specific data or configurations
    to be available before serving traffic. Readiness probes can be tailored to check
    if the Pod’s state is ready and operational. By preventing traffic from reaching
    unready Pods, you ensure a smooth user experience and avoid potential data inconsistencies.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSets 通常管理依赖于特定数据或配置在处理流量之前必须可用的服务。就绪探针可以根据 Pod 的状态来判断其是否准备就绪并且正常运行。通过防止流量进入未准备好的
    Pod，你可以确保平稳的用户体验，并避免潜在的数据不一致问题。
- en: Monitor your StatefulSets
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控你的 StatefulSets
- en: Keeping an eye on your StatefulSets’ health and performance is crucial. Utilize
    monitoring tools to track key metrics like Pod restarts, resource utilization,
    and application errors. This allows you to proactively identify and address potential
    issues before they impact your application’s functionality.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 监控你的 StatefulSets 的健康状态和性能至关重要。利用监控工具跟踪关键指标，如 Pod 重启、资源利用率和应用程序错误。这可以帮助你主动识别并解决潜在问题，以免影响应用程序的功能。
- en: Summary
  id: totrans-294
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter demonstrated how to work with *stateful* workloads and applications
    on Kubernetes using StatefulSets. We first learned what the approaches to persisting
    states in containers and Kubernetes Pods are, and, based on that, we described
    how a StatefulSet object can be used to persist the state. Next, we created an
    example StatefulSet, together with a *headless* Service. Based on that, you learned
    how PVCs and PVs are used in StatefulSets to ensure that the state is persisted
    between Pod restarts. Next, we learned how you can scale the StatefulSet and how
    to introduce updates using *canary* and *phased* rollouts. And finally, we provided
    a set of known best practices when working with StatefulSets.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 本章演示了如何使用 StatefulSets 在 Kubernetes 上处理*有状态*的工作负载和应用程序。我们首先了解了在容器和 Kubernetes
    Pods 中持久化状态的方法，并基于此描述了如何使用 StatefulSet 对象来持久化状态。接下来，我们创建了一个示例 StatefulSet，并与一个*无头*服务一起使用。在此基础上，你学习了如何在
    StatefulSets 中使用 PVCs 和 PVs 来确保 Pod 重启时状态得以持久化。然后，我们学习了如何扩展 StatefulSet，以及如何使用*金丝雀发布*和*阶段发布*来引入更新。最后，我们提供了一组处理
    StatefulSets 时的已知最佳实践。
- en: 'In the next chapter, you will learn more about managing special workloads where
    you need to maintain exactly one Pod per Node in Kubernetes. We will introduce
    a new Kubernetes object: DaemonSet.'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，你将学习如何管理需要在 Kubernetes 中每个节点上保持恰好一个 Pod 的特殊工作负载。我们将介绍一个新的 Kubernetes 对象：DaemonSet。
- en: Further reading
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'StatefulSets: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'StatefulSets: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/'
- en: 'Headless Services: https://kubernetes.io/docs/concepts/services-networking/service/#headless-services'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '无头服务: https://kubernetes.io/docs/concepts/services-networking/service/#headless-services'
- en: 'Container hooks: [https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks](https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks)'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器钩子： [https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks](https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks)
- en: Join our community on Discord
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们在Discord的社区
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的Discord空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
- en: '![](img/QR_Code119001106479081656.png)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code119001106479081656.png)'
