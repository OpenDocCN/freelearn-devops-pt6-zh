- en: '*Chapter 10*: Building, Deploying, and Monitoring Your Model'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 10 章*：构建、部署和监控你的模型'
- en: In the previous chapter, you built the data pipeline and created a basic flight
    dataset that can be used by your data science team. In this chapter, your data
    science team will use the flight dataset to build a **machine learning** (**ML**)
    model. The model will be used to predict the on-time performance of the flights.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章，你已经构建了数据管道，并创建了一个基础的航班数据集，供你的数据科学团队使用。在本章中，你的数据科学团队将使用该航班数据集来构建 **机器学习**
    (**ML**) 模型。该模型将用于预测航班的准点表现。
- en: In this chapter, you will see how the platform assists you in visualizing and
    experimenting with the data to build the right model. You will see how to tune
    hyperparameters and compare the results of different runs of model training. You
    will see how to register and version models using the components provided by the
    platform. You will deploy the model as a REST service and start monitoring the
    deployed model using the components provided by the platform.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章，你将看到平台如何帮助你可视化和实验数据，以构建正确的模型。你将学习如何调整超参数，并比较不同训练过程的结果。你还将看到如何使用平台提供的组件注册和管理模型版本。你将把模型作为
    REST 服务进行部署，并开始使用平台提供的组件来监控已部署的模型。
- en: Remember that this book is not about data science, instead, the focus is on
    enabling teams to work autonomously and efficiently. You may see some concepts
    and steps being repeated from earlier chapters. This is intentional to show you
    how the concepts provided in the previous chapters help you build a full life
    cycle.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，本书并不是关于数据科学的，重点在于使团队能够自主高效地工作。你可能会看到一些概念和步骤在前面的章节中被重复。这是故意的，目的是向你展示前面章节中提供的概念如何帮助你构建完整的生命周期。
- en: 'Keeping the goal in mind, you will learn about the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 保持目标清晰，你将学习以下内容：
- en: Visualizing and exploring data using JupyterHub
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 JupyterHub 可视化和探索数据
- en: Building and tuning your model using JupyterHub
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 JupyterHub 构建和调整你的模型
- en: Tracking model experiments and versioning using MLflow
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 MLflow 跟踪模型实验和版本管理
- en: Deploying your model as a service via Seldon and Airflow
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过 Seldon 和 Airflow 将你的模型部署为服务
- en: Monitoring your model using Prometheus and Grafana
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Prometheus 和 Grafana 监控你的模型
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter includes some hands-on setup and exercises. You will need a running
    Kubernetes cluster configured with the **Operator Lifecycle Manager** (**OLM**).
    Building such a Kubernetes environment is covered in [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040),
    *Exploring Kubernetes*. Before attempting the technical exercises in this chapter,
    please make sure that you have a working Kubernetes cluster and **Open Data Hub**
    (**ODH**) is installed on your Kubernetes cluster. Installing ODH is covered in
    [*Chapter 4*](B18332_04_ePub.xhtml#_idTextAnchor055), *The Anatomy of a Machine
    Learning Platform*.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含一些实践设置和练习。你需要一个已配置**Operator Lifecycle Manager**（**OLM**）的运行中的 Kubernetes
    集群。如何构建这样的 Kubernetes 环境，已在[*第 3 章*](B18332_03_ePub.xhtml#_idTextAnchor040)，*探索
    Kubernetes* 中进行了介绍。在尝试本章的技术练习之前，请确保你拥有一个工作中的 Kubernetes 集群，并且**Open Data Hub**（**ODH**）已安装在你的
    Kubernetes 集群上。ODH 的安装内容已在[*第 4 章*](B18332_04_ePub.xhtml#_idTextAnchor055)，*机器学习平台的构成*
    中进行了详细讲解。
- en: Visualizing and exploring data using JupyterHub
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 JupyterHub 可视化和探索数据
- en: Recall from [*Chapter 9*](B18332_09_ePub.xhtml#_idTextAnchor132), *Building
    Your Data Pipeline*, that the data engineer has worked with the SME of the business
    and prepared the flight data that can be used to predict the flights' on-time
    performance.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾一下[*第 9 章*](B18332_09_ePub.xhtml#_idTextAnchor132)，*构建你的数据管道*，数据工程师与业务领域专家（SME）合作，准备了可用于预测航班准点表现的航班数据。
- en: In this section, you will understand the data produced by the data engineering
    team. This is the role of the data scientist who is responsible for building the
    model. You will see how the platform enables your data science and data engineering
    teams to collaborate and how the data scientist can use the platform to build
    a model for the given problem.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将了解数据工程团队产生的数据。这是数据科学家的职责，他们负责构建模型。你将看到平台如何使数据科学团队和数据工程团队进行协作，以及数据科学家如何利用平台为给定问题构建模型。
- en: 'Let''s do some base data exploring using the platform. Keep in mind that the
    focus of this book is to enable your team to work efficiently. The focus is not
    on data science or data engineering but on building and using the platform:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用平台进行一些基础数据探索。请记住，本书的重点是帮助你的团队高效工作。重点不在于数据科学或数据工程，而是在于构建和使用平台：
- en: Launch JupyterHub, but this time select the image that is relative to the data
    science life cycle. SciKit is one such image available on the platform. Do not
    click on the **Start server** button just yet.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动 JupyterHub，但这次请选择与数据科学生命周期相关的图像。SciKit 是平台上可用的一个图像。现在不要点击 **启动服务器** 按钮。
- en: '![Figure 10.1 – JupyterHub landing page'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.1 – JupyterHub 登录页面'
- en: '](img/B18332_10_001.jpg)'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_001.jpg)'
- en: Figure 10.1 – JupyterHub landing page
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – JupyterHub 登录页面
- en: On the JupyterHub landing page, add an `AWS_SECRET_ACCESS_KEY` variable and
    populate it with the password for your S3 environment. The value for this key
    for this exercise would be `minio123`. Notice that we have used the **Medium**
    container size to accommodate the dataset. Now, hit the **Start server** button
    to start your JupyterHub IDE.
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 JupyterHub 登录页面，添加一个 `AWS_SECRET_ACCESS_KEY` 变量，并将其填入 S3 环境的密码。此练习中的密钥值为 `minio123`。请注意，我们使用了
    **中等** 容器大小以适应数据集。现在，点击 **启动服务器** 按钮来启动你的 JupyterHub IDE。
- en: '![Figure 10.2 – JupyterHub landing page'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.2 – JupyterHub 登录页面'
- en: '](img/B18332_10_002.jpg)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_002.jpg)'
- en: Figure 10.2 – JupyterHub landing page
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – JupyterHub 登录页面
- en: Open the `chapter10/visualize.ipynb` file notebook in your JupyterHub IDE.
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的 JupyterHub IDE 中打开 `chapter10/visualize.ipynb` 文件笔记本。
- en: 'The first step is to read the data provided by the data engineering team. Note
    that the data is available on the same platform, which improves the velocity of
    the teams. *Cell 2* in the notebook is using the `PyArrow` library to read the
    data as a pandas data frame. You will read the data from the `flights-data` bucket,
    where data is placed by the data team. You can see the data read code as follows:'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是读取数据工程团队提供的数据。请注意，数据已经在同一平台上可用，这提高了团队的工作效率。笔记本中的 *单元格 2* 使用了 `PyArrow` 库将数据读取为
    pandas 数据框。你将从数据团队放置数据的 `flights-data` 存储桶中读取数据。你可以看到数据读取代码如下：
- en: '![Figure 10.3 – Cell 2 for the chapter10/visualize notebook'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.3 – 第10章/可视化笔记本中的单元格 2'
- en: '](img/B18332_10_003.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_003.jpg)'
- en: Figure 10.3 – Cell 2 for the chapter10/visualize notebook
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – 第10章/可视化笔记本中的单元格 2
- en: 'The first thing you will do is to look at the data. Trying to make sense of
    it and familiarizing yourself with what is available can be the ideal take here.
    You can see in *Cell 3* that the DataFrame''s `head` function has been used to
    see the first few rows. You will notice the field names and the data in them and
    see whether you can understand one record. Notice that some fields are `NaN` and
    some are `None`. This gives you a clue that the dataset may not yet be ready for
    building models. The following screen captures partial output, and it is expected
    that you run this code in your environment to get the full picture:'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 第一步是查看数据。尝试理解它，并熟悉其中的内容是理想的做法。你可以在 *单元格 3* 中看到，已经使用了 DataFrame 的 `head` 函数来查看前几行。你会注意到字段名和其中的数据，看看是否能够理解一条记录。注意，有些字段是
    `NaN`，有些是 `None`。这提示数据集可能还未准备好用于构建模型。以下屏幕截图显示了部分输出，预计你需要在自己的环境中运行此代码以获取完整的结果：
- en: '![Figure 10.4 – Cell 3 for the chapter10/visualize notebook'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.4 – 第10章/可视化笔记本中的单元格 3'
- en: '](img/B18332_10_004.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_004.jpg)'
- en: Figure 10.4 – Cell 3 for the chapter10/visualize notebook
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 – 第10章/可视化笔记本中的单元格 3
- en: 'The next stage is to do a simple verification to see how much data is available
    for you and if you are reading all the records. You can see in *Cell 4* that the
    DataFrame''s `count` function has been used for this. The following screen captures
    partial output, and it is expected that you run this code in your environment
    to get the full picture:'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是进行简单的验证，看看有多少数据可用，是否能够读取所有记录。你可以在 *单元格 4* 中看到，已经使用了 DataFrame 的 `count`
    函数。以下屏幕截图显示了部分输出，预计你需要在自己的环境中运行此代码以获取完整的结果：
- en: '![Figure 10.5 – Cell 4 for the chapter10/visualize notebook'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.5 – 第10章/可视化笔记本中的单元格 4'
- en: '](img/B18332_10_005.jpg)'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_005.jpg)'
- en: Figure 10.5 – Cell 4 for the chapter10/visualize notebook
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5 – 第10章/可视化笔记本中的单元格 4
- en: '*Cells 5* and *6* are using the DataFrame''s shape and the columns'' functions
    are self-explanatory.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*单元格 5* 和 *单元格 6* 使用了 DataFrame 的形状功能，列的功能也一目了然。'
- en: '*Cell 7* is using the DataFrame''s `describe` function to generate some basic
    statistics for the dataset. You may use this to verify whether there is some data
    that may not make sense. An example could be an exceedingly high value as maximum
    for the `taxi_in` time. In such cases, you will work with your SME to clarify
    and adjust the records as needed. The following screen captures partial output,
    and it is expected that you run this code in your environment to get the full
    picture:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*第7单元格*使用了DataFrame的`describe`函数来生成数据集的一些基本统计信息。你可以使用这个方法验证是否有一些数据不合逻辑。例如，`taxi_in`时间的最大值可能过高。在这种情况下，你需要与主题专家（SME）合作，澄清并根据需要调整记录。以下截图显示了部分输出，建议你在自己的环境中运行这段代码以查看完整内容：'
- en: '![Figure 10.6 – Cell 7 for the chapter10/visualize notebook'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.6 – 第10章/可视化笔记本的第7单元格'
- en: '](img/B18332_10_006.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_006.jpg)'
- en: Figure 10.6 – Cell 7 for the chapter10/visualize notebook
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 – 第10章/可视化笔记本的第7单元格
- en: 'Next, you want to see whether the data has null values. You have seen in *Step
    3*, that there are some `NaN` and `None` values in the data. You have found out
    that there are many columns with missing data problems. The following screen captures
    partial output, and it is expected that you run this code in your environment
    to get the full picture:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你想查看数据是否有空值。你在*步骤3*中已经看到数据中存在一些`NaN`和`None`值，并发现有许多列存在缺失数据的问题。以下截图显示了部分输出，建议你在自己的环境中运行这段代码以查看完整内容：
- en: '![Figure 10.7 – Cell 8 for the chapter10/visualize notebook'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.7 – 第10章/可视化笔记本的第8单元格'
- en: '](img/B18332_10_007.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_007.jpg)'
- en: Figure 10.7 – Cell 8 for the chapter10/visualize notebook
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.7 – 第10章/可视化笔记本的第8单元格
- en: You will use the Dataframe's `isnull` function to find out how many records
    have this missing data. Using the output from the `df.isnull().sum().sort_values(ascending
    = False)` code, there are two different groups. The first six rows of the output
    show column names that have a very high missing data rate and for these columns,
    you may talk to data engineering and the SME to find resources from where you
    can fetch the data for them. For our example, we will just drop these columns.
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你将使用Dataframe的`isnull`函数来查找有多少记录缺失数据。通过运行`df.isnull().sum().sort_values(ascending
    = False)`代码输出，你会发现数据分为两组。输出的前六行显示了缺失数据率非常高的列，对于这些列，你可以与数据工程团队和主题专家（SME）沟通，找出可以从中获取数据的资源。对于本示例，我们将删除这些列。
- en: '![Figure 10.8 – Cell 9 for the chapter10/visualize notebook'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.8 – 第10章/可视化笔记本的第9单元格'
- en: '](img/B18332_10_008.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_008.jpg)'
- en: Figure 10.8 – Cell 9 for the chapter10/visualize notebook
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.8 – 第10章/可视化笔记本的第9单元格
- en: In the second group, starting from the `wheels_on` column, you may either choose
    to drop the rows containing no data or try to fill the data with a suitable statistics
    function. For example, the missing `taxi_in` columns could be the mean for the
    same airport and same time. The strategy must be discussed with the team. For
    this exercise, we will just drop the rows.
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在第二组数据中，从`wheels_on`列开始，你可以选择删除没有数据的行，或者尝试使用适当的统计函数填充数据。例如，缺失的`taxi_in`列可以用同一机场和相同时间的均值来填补。此策略需与团队讨论。对于本次练习，我们将直接删除这些行。
- en: '![Figure 10.9 – Cell 9 for the chapter10/visualize notebook'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.9 – 第10章/可视化笔记本的第9单元格'
- en: '](img/B18332_10_009.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_009.jpg)'
- en: Figure 10.9 – Cell 9 for the chapter10/visualize notebook
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.9 – 第10章/可视化笔记本的第9单元格
- en: 'Often, it is a good idea to investigate sample rows where a particular column
    has no data. You may find a pattern in the data that could be extremely useful
    in further understanding the data. You have chosen to see the rows where the `tail_number`
    field has no value and see whether you can find any patterns. The following screen
    captures partial output, and it is expected that you run this code in your environment
    to get the full picture:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通常，调查某一列缺失数据的示例行是一个不错的主意。你可能会在数据中发现某些模式，这对进一步理解数据可能非常有用。你选择查看`tail_number`字段没有值的行，并查看是否能发现任何模式。以下截图显示了部分输出，建议你在自己的环境中运行这段代码以查看完整内容：
- en: '![Figure 10.10 – Cell 10 for the chapter10/visualize notebook'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.10 – 第10章/可视化笔记本的第10单元格'
- en: '](img/B18332_10_010.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_010.jpg)'
- en: Figure 10.10 – Cell 10 for the chapter10/visualize notebook
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.10 – 第10章/可视化笔记本的第10单元格
- en: 'You will then run the Dataframe''s `info` function to find out the data types
    of the columns. A lot of times, the data types of columns are not the ones that
    you are expecting. You will then talk to the SME and data teams to improve the
    data quality. The following screen captures partial output, and it is expected
    that you run this code in your environment to get the full picture:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你将运行Dataframe的`info`函数，以找出列的数据类型。很多时候，列的数据类型并不是你所预期的。然后你将与SME和数据团队合作，改善数据质量。以下截图展示了部分输出，预计你会在自己的环境中运行这段代码以获取完整信息：
- en: '![Figure 10.11 – Cell 11 for the chapter10/visualize notebook'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.11 – 第10章/可视化笔记本中的单元格11](img/B18332_10_011.jpg)'
- en: '](img/B18332_10_011.jpg)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_011.jpg)'
- en: Figure 10.11 – Cell 11 for the chapter10/visualize notebook
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.11 – 第10章/可视化笔记本中的单元格11
- en: Visualization is one particularly important tool to understand data. You can
    use any of the libraries that you feel comfortable with. For example, in the last
    cell of this notebook, you build a graph to find out the data distribution for
    the `DELAYED` column. Imagine that 99% of the records are with the `DELAYED` column
    as `0`. If that is the case, the data may not be enough to predict the flights'
    on-time performance and you will need to engage the SME and data teams to get
    more data. For this exercise, we will use the existing data distribution.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可视化是理解数据的一个特别重要的工具。你可以使用任何你熟悉的库。例如，在这个笔记本的最后一个单元格中，你构建了一个图表来找出`DELAYED`列的数据分布。假设99%的记录中，`DELAYED`列为`0`。如果是这样，数据可能不足以预测航班的准点表现，你需要与SME和数据团队合作，获取更多的数据。对于这个练习，我们将使用现有的数据分布。
- en: '![Figure 10.12 – Cell 12 for the chapter10/visualize notebook'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.12 – 第10章/可视化笔记本中的单元格12](img/B18332_10_012.jpg)'
- en: '](img/B18332_10_012.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_012.jpg)'
- en: Figure 10.12 – Cell 12 for the chapter10/visualize notebook
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.12 – 第10章/可视化笔记本中的单元格12
- en: Now that we understand flight data a bit better, let's start building our model.
    In the real world, you would invest a lot more time to understand the data. The
    focus of this book is to show you how to execute the model development life cycle
    and so we kept the examples to a minimum.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对航班数据有了更好的理解，让我们开始构建模型。在现实世界中，你需要投入更多的时间来理解数据。本书的重点是展示如何执行模型开发生命周期，因此我们将示例保持在最低限度。
- en: Building and tuning your model using JupyterHub
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用JupyterHub构建和调优模型
- en: As a data scientist, you will want to try different models with different parameters
    to find the right fit. Before you start building the model, recall from [*Chapter
    8*](B18332_08_ePub.xhtml#_idTextAnchor116), *Building a Complete ML Project Using
    the Platform*, that you need to define the evaluation criteria, and that **accuracy**
    may be a misleading criterion for a lot of use cases.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一名数据科学家，你将希望尝试不同的模型和参数，以找到最合适的模型。在你开始构建模型之前，请回忆一下在[*第8章*](B18332_08_ePub.xhtml#_idTextAnchor116)《使用平台构建完整的机器学习项目》中提到的，你需要定义评估标准，而且**准确率（accuracy）**可能对于很多使用案例来说是一个具有误导性的标准。
- en: For the flight use case, let's assume that your team and the SME agree on the
    **PRECISION** metric. Note that precision measures the portion of correct positive
    identification in the provided dataset.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 对于航班使用案例，假设你的团队和SME（主题专家）一致同意使用**精准度（PRECISION）**指标。请注意，精准度衡量的是提供的数据集中正确正向识别的比例。
- en: 'Let''s start writing our model and see how the platform enables data scientists
    to perform their work efficiently:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始编写我们的模型，看看平台如何使数据科学家高效地完成工作：
- en: Open the `chapter10/experiments.ipynb` file notebook in your JupyterHub environment.
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你的JupyterHub环境中打开`chapter10/experiments.ipynb`文件笔记本。
- en: In *Cell 2*, add the connection information to MLflow. Recall that MLflow is
    the component in the platform that records the model experiments and works as
    the model registry. In the code, you will configure `EXPERIMENT_NAME`, which provides
    a name for your experiment runs. The last line of this cell mentions how MLflow
    will record the experiment run. The `autolog` feature enables MLflow to register
    automatic callbacks during training to record the parameters for later use.
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*单元格2*中，添加MLflow的连接信息。请回想一下，MLflow是平台中的组件，用于记录模型实验并充当模型注册中心。在代码中，你将配置`EXPERIMENT_NAME`，它为你的实验运行提供一个名称。该单元格的最后一行提到了MLflow如何记录实验运行。`autolog`功能使得MLflow在训练过程中注册自动回调，以记录参数以供以后使用。
- en: 'You also provide the configuration for the S3 bucket, which will be used by
    MLflow to store the artifacts of your experiments:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要提供S3桶的配置，该桶将由MLflow用于存储你的实验结果：
- en: '![Figure 10.13 – Cell 2 for the chapter10/experiments notebook'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.13 – 第 2 单元，位于第 10 章/实验笔记本中'
- en: '](img/B18332_10_013.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_013.jpg)'
- en: Figure 10.13 – Cell 2 for the chapter10/experiments notebook
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.13 – 第 2 单元，位于第 10 章/实验笔记本中
- en: '*Cell 3* reads the data available from the data engineering team, and *Cell
    4* is again providing the information on the missing data from multiple columns.
    In this notebook, you will use this information to drop the columns that you do
    not find useful. The following screen captures partial output, and it is expected
    that you run this code in your environment to get the full picture:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*第 3 单元* 从数据工程团队读取可用数据，*第 4 单元* 再次提供了多列缺失数据的信息。在这本笔记本中，你将使用这些信息来删除你认为不实用的列。以下是部分输出的屏幕截图，建议在你的环境中运行此代码以获取完整的图像：'
- en: '![Figure 10.14 – Cell 3 for the chapter10/experiments notebook'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.14 – 第 3 单元，位于第 10 章/实验笔记本中'
- en: '](img/B18332_10_014.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_014.jpg)'
- en: Figure 10.14 – Cell 3 for the chapter10/experiments notebook
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.14 – 第 3 单元，位于第 10 章/实验笔记本中
- en: '*Cell 5* is dropping two sets of columns. The first set drops the columns for
    which you do not have data in most of the rows. You selected these columns based
    on the previous step. We kept it simple here and dropped the columns; however,
    it is highly recommended that you work with data teams to find the reason for
    this anomaly and aim to get as much data as possible. The columns you are dropping
    are `"cancellation_reason"`, `"late_aircraft_delay"`, `"weather_delay"`, `"airline_delay"`,
    `"security_delay"`, and `"air_system_delay"`, and are shown in the following screenshot:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*第 5 单元* 删除了两组列。第一组是那些在大多数行中没有数据的列。你根据前一步骤选择了这些列。在这里，我们简单地删除了这些列；然而，强烈建议你与数据团队合作，找出这种异常的原因，并尽可能获取更多数据。你正在删除的列包括
    `"cancellation_reason"`, `"late_aircraft_delay"`, `"weather_delay"`, `"airline_delay"`,
    `"security_delay"`, 和 `"air_system_delay"`, 并显示在以下截图中：'
- en: '![Figure 10.15 – Cell 5 for the chapter10/experiments notebook'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.15 – 第 5 单元，位于第 10 章/实验笔记本中'
- en: '](img/B18332_10_015.jpg)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_015.jpg)'
- en: Figure 10.15 – Cell 5 for the chapter10/experiments notebook
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.15 – 第 5 单元，位于第 10 章/实验笔记本中
- en: 'The second `drop` statement is dropping the `tail_number` column. This column
    may not play any role in flights getting delayed. In a real-world scenario, you
    will need to discuss this with the SMEs:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个 `drop` 语句删除了 `tail_number` 列。在实际场景中，你需要与专家讨论这一列是否对航班延误起到任何作用。
- en: '![Figure 10.16 – Cell 5 for the chapter10/experiments notebook'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.16 – 第 5 单元，位于第 10 章/实验笔记本中'
- en: '](img/B18332_10_016.jpg)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_016.jpg)'
- en: Figure 10.16 – Cell 5 for the chapter10/experiments notebook
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.16 – 第 5 单元，位于第 10 章/实验笔记本中
- en: '*Cell 6* is dropping rows for which the data is not available using the Dataframe''s
    `dropna` function. Recall, from *Step 3*, that the number of rows where data is
    missing from these columns is less compared to the total rows available. `air_time`,
    `arrival_delay`, and `elapsed_time` are examples of such columns from *Step 5*.
    We have adopted this approach to keep things simple; a better way would be to
    find a way to get the missing data or to create this data from existing values.'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*第 6 单元* 使用 Dataframe 的 `dropna` 函数删除数据不可用的行。回想一下，从 *步骤 3* 中，与总行数相比，这些列缺失数据的行数较少。`air_time`,
    `arrival_delay` 和 `elapsed_time` 是 *步骤 5* 中的示例列。我们采用了这种方法来保持简单；更好的方法是找到获取缺失数据的途径或从现有值创建此数据。'
- en: '![Figure 10.17 – Cell 6 for the chapter10/experiments notebook'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.17 – 第 6 单元，位于第 10 章/实验笔记本中'
- en: '](img/B18332_10_017.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_017.jpg)'
- en: Figure 10.17 – Cell 6 for the chapter10/experiments notebook
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.17 – 第 6 单元，位于第 10 章/实验笔记本中
- en: In *Cell 7*, you are dropping columns for which you do not have data for future
    flights. Recall that the model aims to predict the future flight on-time performance.
    However, columns such as `departure_time` and `arrival_time` contain the actual
    departure and arrival times. For predicting future flights, you will not have
    such data available at the time of prediction, and so you need to drop these columns
    while training your model.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 *第 7 单元*，你正在删除那些未来航班没有数据的列。回想一下，该模型旨在预测未来航班的准时性。然而，诸如 `departure_time` 和 `arrival_time`
    这样的列包含实际的出发和到达时间。对于预测未来航班，你在预测时将无法使用这些数据，因此在训练模型时需要删除这些列。
- en: '![Figure 10.18 – Cell 7 for the chapter10/experiments notebook'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.18 – 第 7 单元，位于第 10 章/实验笔记本中'
- en: '](img/B18332_10_018.jpg)'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_018.jpg)'
- en: Figure 10.18 – Cell 7 for the chapter10/experiments notebook
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.18 – 第 7 单元，位于第 10 章/实验笔记本中
- en: In the dataset, the scheduled departure and arrival time is available in HHMM
    format, where HH is hours and MM is minutes. In *Cell 8*, as a data scientist,
    you may choose to split this data into two different columns where one column
    represents the hours and the other one represents the minutes. Doing this may
    simplify the dataset and improve the model performance if some correlation exists
    between the expected classification and split data. You may do it out of your
    intuition, or you may discuss this option with the SMEs.
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在数据集中，计划的出发和到达时间以 HHMM 格式表示，其中 HH 是小时，MM 是分钟。在 *第 8 单元格* 中，作为数据科学家，你可以选择将这个数据拆分成两列，一列表示小时，另一列表示分钟。这样做可能简化数据集，并提高模型性能，如果期望的分类与拆分数据之间存在某种相关性。你可以凭直觉做出这个选择，或者与领域专家讨论这个选项。
- en: 'You have chosen to split the `scheduled_departure` and `scheduled_arrival`
    columns:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你选择将 `scheduled_departure` 和 `scheduled_arrival` 列拆分：
- en: '![Figure 10.19 – Cell 8 for the chapter10/experiments notebook'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.19 – 第 8 单元格，章节 10/实验笔记本'
- en: '](img/B18332_10_019.jpg)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_019.jpg)'
- en: Figure 10.19 – Cell 8 for the chapter10/experiments notebook
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.19 – 第 8 单元格，章节 10/实验笔记本
- en: 'In *Cell 9*, you drop a few more columns. The first set contains columns for
    which we have to split the time into hours and minutes, such as `scheduled_arrival`:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 *第 9 单元格* 中，你删除了更多列。第一组包含需要将时间拆分为小时和分钟的列，例如 `scheduled_arrival`：
- en: '![Figure 10.20 – Cell 9 for the chapter10/experiments notebook'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.20 – 第 9 单元格，章节 10/实验笔记本'
- en: '](img/B18332_10_020.jpg)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_020.jpg)'
- en: Figure 10.20 – Cell 9 for the chapter10/experiments notebook
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.20 – 第 9 单元格，章节 10/实验笔记本
- en: 'The second set contains the columns that are represented in other columns.
    For example, the `origin_airport` column has a key for the airport, and the `ORIG_AIRPORT`
    column is a descriptive name. Both these columns represent the same information:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 第二组包含在其他列中表示的列。例如，`origin_airport` 列包含机场的键值，而 `ORIG_AIRPORT` 列则是一个描述性名称。这两列表示相同的信息：
- en: '![Figure 10.21 – Cell 9 for the chapter10/experiments notebook'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.21 – 第 9 单元格，章节 10/实验笔记本'
- en: '](img/B18332_10_021.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_021.jpg)'
- en: Figure 10.21 – Cell 9 for the chapter10/experiments notebook
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.21 – 第 9 单元格，章节 10/实验笔记本
- en: 'In *Cell 10*, you visually see the dataset again using the `head` statement.
    You have noticed that you have some data in string format, such as the `airline`
    column:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 *第 10 单元格* 中，你再次通过 `head` 语句查看数据集。你已经注意到某些数据是字符串格式，比如 `airline` 列：
- en: '![Figure 10.22 – Cell 10 for the chapter10/experiments notebook'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.22 – 第 10 单元格，章节 10/实验笔记本'
- en: '](img/B18332_10_022.jpg)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_022.jpg)'
- en: Figure 10.22 – Cell 10 for the chapter10/experiments notebook
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.22 – 第 10 单元格，章节 10/实验笔记本
- en: 'You choose to encode that data to convert it into numbers. There are many techniques
    available, such as `OrdinalEncoder`. This encoder encodes categorical values as
    an integer array. In *Cell 12*, you have applied the category encoding to the
    selected fields such as `airline` and `origin_airport`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 你选择对数据进行编码，将其转换为数字。有许多可用的技术，如 `OrdinalEncoder`。该编码器将分类值编码为整数数组。在 *第 12 单元格*
    中，你对选定的字段，如 `airline` 和 `origin_airport`，应用了类别编码：
- en: '![Figure 10.23 – Cell 12 for the chapter10/experiments notebook'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.23 – 第 12 单元格，章节 10/实验笔记本'
- en: '](img/B18332_10_023.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_023.jpg)'
- en: Figure 10.23 – Cell 12 for the chapter10/experiments notebook
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.23 – 第 12 单元格，章节 10/实验笔记本
- en: 'This means that the input string data for these fields will be converted into
    integers. This is good for training; however, at inferencing time, the caller
    may not know about this encoding that you have just performed. One way is to save
    this encoder and use it at inferencing time to convert the value from string to
    integers. So, your inferencing pipeline would consist of two steps. The first
    step is to apply the encoding and the second step is to predict the response using
    the saved mode. In the last four lines of *Cell 12*, you have saved the encoder
    and have to register it with MLflow:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着这些字段的输入字符串数据将被转换为整数。这对于训练是有益的；然而，在推理时，调用者可能并不知道你刚刚进行的编码。一种方法是保存这个编码器，并在推理时使用它将值从字符串转换为整数。因此，你的推理管道将包含两个步骤。第一步是应用编码，第二步是使用保存的模型预测响应。在
    *第 12 单元格* 的最后四行，你已经保存了编码器，并需要将其注册到 MLflow 中：
- en: '![Figure 10.24 – Cell 12 for the chapter10/experiments notebook'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.24 – 第 12 单元格，章节 10/实验笔记本'
- en: '](img/B18332_10_024.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_024.jpg)'
- en: Figure 10.24 – Cell 12 for the chapter10/experiments notebook
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.24 – 第 12 单元格，章节 10/实验笔记本
- en: 'In *Cell 13*, you validate the data using the `head` statement. Notice that
    the `airline` column (one of the columns that you have applied the category encoding
    to) has changed. For example, compare the value of the `airline` column from *Cell
    10* and *Cell 13* and notice that the value of `airline` column has been changed
    to `1`. This confirms that the encoding has been applied to the dataset successfully:'
  id: totrans-122
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*第 13 单元格*中，您使用`head`语句对数据进行了验证。请注意，`airline`列（您已对其应用类别编码的列之一）已发生变化。例如，比较*第
    10 单元格*和*第 13 单元格*中的`airline`列的值，可以发现`airline`列的值已更改为`1`。这确认了编码已成功应用到数据集：
- en: '![Figure 10.25 – Cell 13 for the chapter10/experiments notebook'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.25 – 第 13 单元格，chapter10/experiments 笔记本'
- en: '](img/B18332_10_025.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_025.jpg)'
- en: Figure 10.25 – Cell 13 for the chapter10/experiments notebook
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.25 – 第 13 单元格，chapter10/experiments 笔记本
- en: In *Cell 14*, you used the `dftype` statement to validate the data types of
    each column in the dataset. Many algorithms need data to be in a numerical format
    and, based on the available models, you may need to move all the fields to a numerical
    format.
  id: totrans-126
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*第 14 单元格*中，您使用`dftype`语句验证了数据集中每列的数据类型。许多算法需要数据以数值格式呈现，依据可用的模型，您可能需要将所有字段转换为数值格式。
- en: In *Cell 15*, you have split your data into training and testing sets. You will
    train the model using the `X_Train` and `y_train` set and use the `X_Test` and
    `y_test` for validation of your model performance. You can perform cross-validation
    to further assess the model performance on unseen data. We assume that you, as
    a data scientist, are aware of such concepts and, therefore, will not provide
    more details on this.
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*第 15 单元格*中，您将数据划分为训练集和测试集。您将使用`X_Train`和`y_train`集来训练模型，并使用`X_Test`和`y_test`来验证模型的性能。您可以执行交叉验证，进一步评估模型在未见数据上的表现。我们假设您作为数据科学家已经了解这些概念，因此不再提供更多细节。
- en: '![Figure 10.26 – Cell 15 for the chapter10/experiments notebook'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.26 – 第 15 单元格，chapter10/experiments 笔记本'
- en: '](img/B18332_10_026.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_026.jpg)'
- en: Figure 10.26 – Cell 15 for the chapter10/experiments notebook
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.26 – 第 15 单元格，chapter10/experiments 笔记本
- en: 'In *Cell 16*, you visualize the data distribution of the dataset. The following
    screenshot captures partial output, and it is expected that you run this code
    in your environment to get the full picture:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*第 16 单元格*中，您可视化了数据集的数据分布。以下截图捕获了部分输出，预计您将在自己的环境中运行此代码以获得完整的输出：
- en: '![Figure 10.27 – Cell 16 for the chapter10/experiments notebook'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.27 – 第 16 单元格，chapter10/experiments 笔记本'
- en: '](img/B18332_10_027.jpg)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_027.jpg)'
- en: Figure 10.27 – Cell 16 for the chapter10/experiments notebook
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.27 – 第 16 单元格，chapter10/experiments 笔记本
- en: You can see from the preceding chart that the data is biased towards the on-time
    flights. This may impact the performance of the model. Luckily, the `RandomForestClassifier`
    object of the `SciKit` library provides a `class_weight` parameter. It can take
    a Python `dictionary` object where we can provide the desired weights for respective
    labels. One such example would be to allocate less weight for a value of `0` in
    the `DELAYED` column, which represents the on-time flight. A different value for
    `class_weight` could be `balanced`, which will direct the algorithm to weigh the
    labels as per the inverse proportion to their occurrence frequency. Simply, for
    our case, the `balanced` value will put more weight on the value of `1` as compared
    to the value of `0` in the `DELAYED` column.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的图表中，您可以看到数据偏向准时航班。这可能会影响模型的表现。幸运的是，`SciKit`库中的`RandomForestClassifier`对象提供了一个`class_weight`参数。它可以接受一个Python
    `字典`对象，您可以在其中为各个标签提供所需的权重。例如，您可以为`DELAYED`列中表示准时航班的`0`值分配较小的权重。`class_weight`的另一种值可以是`balanced`，它将指导算法根据标签出现频率的逆比例对标签加权。简单来说，对于我们的情况，`balanced`值将比`0`更重视`DELAYED`列中的`1`值。
- en: In *Cell 19*, you define a random forest classification model and in *Cell 20*,
    you train the model. You have noticed that we have defined very minimal hyperparameters
    and then used `GridSearchCV` to find the best estimator for the given dataset.
    We have placed a separate set of hyperparameters in the comments of this cell.
    You are encouraged to try different combinations.
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*第 19 单元格*中，您定义了一个随机森林分类模型，在*第 20 单元格*中，您对该模型进行了训练。您会注意到，我们仅定义了最基本的超参数，并使用`GridSearchCV`来找到适合给定数据集的最佳估计器。我们在该单元格的注释中列出了另外一组超参数，建议您尝试不同的组合。
- en: '![Figure 10.28 – Cell 19 for the chapter10/experiments notebook'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.28 – 第 19 单元格，chapter10/experiments 笔记本'
- en: '](img/B18332_10_028.jpg)'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_028.jpg)'
- en: Figure 10.28 – Cell 19 for the chapter10/experiments notebook
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.28 – 第19单元格，来自chapter10/experiments笔记本
- en: '*Figure 10.29* shows how the model training is performed by executing the `model.fit()`
    function:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10.29*展示了通过执行`model.fit()`函数来进行模型训练：'
- en: '![Figure 10.29 – Cell 20 for the chapter10/experiments notebook'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.29 – 第20单元格，来自chapter10/experiments笔记本]'
- en: '](img/B18332_10_029.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_029.jpg)'
- en: Figure 10.29 – Cell 20 for the chapter10/experiments notebook
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.29 – 第20单元格，来自chapter10/experiments笔记本
- en: The training will take some time to complete, so for *Cell 20*, where you are
    training your model, be patient.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 训练将需要一些时间，因此对于*第20单元格*，即您正在训练模型的单元格，请耐心等待。
- en: 'In *Cell 21*, you have used the `predict` method to capture the model prediction
    for the test data. Note that the `rf_best_model` model is the output of the `GridSearchCV`
    object:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*第21单元格*中，您使用了`predict`方法来捕获模型对测试数据的预测。请注意，`rf_best_model`模型是`GridSearchCV`对象的输出：
- en: '![Figure 10.30 – Cell 21 for the chapter10/experiments notebook'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.30 – 第21单元格，来自chapter10/experiments笔记本]'
- en: '](img/B18332_10_030.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_030.jpg)'
- en: Figure 10.30 – Cell 21 for the chapter10/experiments notebook
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.30 – 第21单元格，来自chapter10/experiments笔记本
- en: 'In *Cell 22*, you have used the `confusion_matrix` function to calculate the
    matrix and validate the performance of your model:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*第22单元格*中，您使用了`confusion_matrix`函数来计算矩阵并验证模型的性能：
- en: '![Figure 10.31 – Cell 22 for the chapter10/experiments notebook'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.31 – 第22单元格，来自chapter10/experiments笔记本]'
- en: '](img/B18332_10_031.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_031.jpg)'
- en: Figure 10.31 – Cell 22 for the chapter10/experiments notebook
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.31 – 第22单元格，来自chapter10/experiments笔记本
- en: 'In *Cell 23*, you have used the `precision_score` function to calculate `recallscore`
    for your model on the test dataset. You can see that you have achieved 72% precision,
    which is good for the first experiment run. You can run more experiments and improve
    the metrics for your model using the platform:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在*第23单元格*中，您使用了`precision_score`函数来计算模型在测试数据集上的`recallscore`。您可以看到，您在第一次实验运行中达到了72%的精度，这对于第一次实验运行来说是不错的。您可以通过平台运行更多实验并提升模型的指标：
- en: '![Figure 10.32 – Cell 23 for the chapter10/experiments notebook'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.32 – 第23单元格，来自chapter10/experiments笔记本]'
- en: '](img/B18332_10_032.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_032.jpg)'
- en: Figure 10.32 – Cell 23 for the chapter10/experiments notebook
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.32 – 第23单元格，来自chapter10/experiments笔记本
- en: You have completed one experiment run with multiple parameters and the `RandomForestClassifier`
    model. At this stage, you may want to check MLflow and see all the runs the grid
    search has performed, captured parameters, and model performance data.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 您已经完成了一个带有多个参数的实验运行，并使用了`RandomForestClassifier`模型。在此阶段，您可能想检查MLflow，查看网格搜索执行的所有运行、捕获的参数以及模型性能数据。
- en: Typically, data scientists try multiple algorithms to find the right fit for
    the given problem. It is up to you to execute and enhance the code and use MLflow
    to compare different algorithms.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，数据科学家会尝试多种算法，以找到适合给定问题的最佳算法。您可以执行并优化代码，并使用MLflow比较不同的算法。
- en: Let's see what MLflow has recorded for us.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看MLflow为我们记录了什么。
- en: Tracking model experiments and versioning using MLflow
  id: totrans-160
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用MLflow跟踪模型实验和版本控制
- en: In this section, you will use MLflow to track your experiment and version your
    model. This small section is a review of the capabilities highlighted to you in
    [*Chapter 6*](B18332_06_ePub.xhtml#_idTextAnchor086), *Machine Learning Engineering*,
    where we discussed MLflow in detail.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将使用MLflow来跟踪您的实验并对您的模型进行版本控制。此小节是对[*第6章*](B18332_06_ePub.xhtml#_idTextAnchor086)的回顾，*机器学习工程*，我们在其中详细讨论了MLflow。
- en: Tracking model experiments
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟踪模型实验
- en: In this section, you will see the data recorded by MLflow for your experiment.
    Note that you have just registered the MLflow and called the `autolog` function,
    and MLflow automatically records all your data. This is a powerful capability
    in your platform through which you can compare multiple runs and share your findings
    with your team members.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将看到MLflow为您的实验记录的数据。请注意，您刚刚注册了MLflow并调用了`autolog`函数，MLflow会自动记录您的所有数据。这是您平台的一项强大功能，您可以通过它比较多个实验并与团队成员共享您的发现。
- en: 'The following steps shows you how experiment tracking is performed in MLflow:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤展示了如何在MLflow中执行实验跟踪：
- en: Log in to the MLflow UI of the platform.
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到平台的MLflow UI。
- en: 'On the left-hand side, you will see the **Experiments** section and it contains
    your experiment named **FlightsDelay-mluser**. Click on it and you will see the
    following screen. The right-hand side shows all the runs. Recall that we have
    used GridSearchCV so there will be multiple runs:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在左侧，你会看到 **Experiments** 部分，里面包含你名为 **FlightsDelay-mluser** 的实验。点击它，你将看到以下界面。右侧显示所有的运行。回想一下，我们使用了
    GridSearchCV，因此会有多个运行：
- en: '![Figure 10.33 – The model tracking details in MLflow'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.33 – MLflow 中的模型追踪详情'
- en: '](img/B18332_10_033.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_033.jpg)'
- en: Figure 10.33 – The model tracking details in MLflow
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.33 – MLflow 中的模型追踪详情
- en: Click on the `autolog` feature and MLflow will capture the bulk of the metrics
    automatically. Select all four runs and hit the **Compare** button.
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击`autolog`功能，MLflow 将自动捕获大部分指标。选择所有四个运行并点击**比较**按钮。
- en: '*Figure 10.34* shows the comparison of each run and the hyperparameters associated
    with the run:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10.34* 显示了每次运行的比较以及与运行相关的超参数：'
- en: '![Figure 10.34 – Comparing models in MLflow'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.34 – 在 MLflow 中比较模型'
- en: '](img/B18332_10_034.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_034.jpg)'
- en: Figure 10.34 – Comparing models in MLflow
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.34 – 在 MLflow 中比较模型
- en: 'Click on the run next to the `FlightsDelayOrdinalEncoder.pkl`:'
  id: totrans-175
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `FlightsDelayOrdinalEncoder.pkl` 旁边的运行：
- en: '![Figure 10.35 – Files and data captured by MLflow'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.35 – MLflow 捕获的文件和数据'
- en: '](img/B18332_10_035.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_035.jpg)'
- en: Figure 10.35 – Files and data captured by MLflow
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.35 – MLflow 捕获的文件和数据
- en: In this section, you have seen that MLflow captured all the metrics from your
    training run and assisted you in selecting the right model by providing a comparison
    function.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你已经看到 MLflow 捕获了训练运行的所有指标，并通过提供比较功能帮助你选择了合适的模型。
- en: The next stage is to version your model.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 下一阶段是对模型进行版本控制。
- en: Versioning models
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 对模型进行版本控制
- en: After giving some thought to the model performance and sharing the data with
    other team members, you have selected the model that can be used for this project.
    In this section, you will version your model to be used. Refer to [*Chapter 6*](B18332_06_ePub.xhtml#_idTextAnchor086),
    *Machine Learning Engineering*, where we discussed model versioning in detail.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在对模型性能进行一些思考并与其他团队成员共享数据后，你已经选择了可以用于此项目的模型。在本节中，你将对模型进行版本控制。请参考[*第 6 章*](B18332_06_ePub.xhtml#_idTextAnchor086)，*机器学习工程*，我们在其中详细讨论了模型版本控制。
- en: 'The following steps will guide you on how to version your model:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤将指导你如何对模型进行版本控制：
- en: Go to MLflow and click on the **FlightDelay-mluser** experiment on the left-hand
    side.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入 MLflow，点击左侧的 **FlightDelay-mluser** 实验。
- en: 'Then, on the right-hand side of the screen, click on the **+** icon for your
    run. You will see the following screen:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在屏幕右侧，点击你运行的**+**图标。你将看到以下界面：
- en: '![Figure 10.36 – Files and data captured by MLflow'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.36 – MLflow 捕获的文件和数据'
- en: '](img/B18332_10_036.jpg)'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_036.jpg)'
- en: Figure 10.36 – Files and data captured by MLflow
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.36 – MLflow 捕获的文件和数据
- en: 'Click on the **model** folder under artifacts and a blue button with the **Register
    Model** label will appear:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **model** 文件夹下的 artifacts，一个蓝色按钮将显示，按钮上标有 **注册模型**：
- en: '![Figure 10.37 – Versioning your models in MLflow'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.37 – 在 MLflow 中对模型进行版本控制'
- en: '](img/B18332_10_037.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_037.jpg)'
- en: Figure 10.37 – Versioning your models in MLflow
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.37 – 在 MLflow 中对模型进行版本控制
- en: 'Click on the `flights-ontime`:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 `flights-ontime`：
- en: '![Figure 10.38 – Model registration in MLflow'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.38 – 在 MLflow 中注册模型'
- en: '](img/B18332_10_038.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_038.jpg)'
- en: Figure 10.38 – Model registration in MLflow
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.38 – 在 MLflow 中注册模型
- en: As a data scientist, you have registered your model for predicting flight delays
    onto the model registry. The next step is to deploy your model.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 作为数据科学家，你已经将用于预测航班延误的模型注册到了模型注册表。下一步是部署你的模型。
- en: Deploying the model as a service
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将模型部署为服务
- en: In this section, you will deploy your model as a REST service. You will see
    that using the details mentioned in [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098),
    *Model Deployment and Automation*, the team can package and deploy the model as
    a service. This service will then be consumed by users of your model. We highly
    encourage you to refresh your knowledge from [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098),
    *Model Deployment and Automation* before proceeding to this section.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将把模型部署为一个 REST 服务。你将看到，使用[*第 7 章*](B18332_07_ePub.xhtml#_idTextAnchor098)中提到的详细信息，*模型部署与自动化*，团队可以将模型打包并作为服务部署。该服务将由你的模型用户使用。我们强烈建议你在继续本节之前，复习一下[*第
    7 章*](B18332_07_ePub.xhtml#_idTextAnchor098)中的知识，*模型部署与自动化*。
- en: In [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098), *Model Deployment and
    Automation*, you have deployed the model with a `Predictor` class, which exposes
    the model as a REST service. You will use the same class here, however, in the
    flight project, you applied categorical encoding to the data before it was used
    for model training. This means that you will need to apply the same encoding to
    the input data at the inferencing time. Recall that, earlier in this chapter,
    you saved the file as `FlightsDelayOrdinalEncoder.pkl` and it is available in
    the MLflow repository.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 7 章*](B18332_07_ePub.xhtml#_idTextAnchor098)《模型部署与自动化》中，你已经使用 `Predictor`
    类部署了模型，将模型暴露为 REST 服务。你将在这里使用相同的类，然而，在航班项目中，你在用于模型训练之前对数据应用了类别编码。这意味着你需要在推理时对输入数据应用相同的编码。回想一下，在本章早些时候，你将文件保存为`FlightsDelayOrdinalEncoder.pkl`，并且它可在
    MLflow 仓库中找到。
- en: The next step is to write a simple class that can apply the transformation to
    the input data. Once this class is defined, you will define your inference pipeline
    using Seldon and then package your model as a container. So, your inference pipeline
    will consist of two stages; the first stage is to apply the encoding and the second
    stage is to use the model to predict the class.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是编写一个简单的类，用于将转换应用到输入数据。一旦定义了这个类，你将使用 Seldon 定义推理管道，然后将模型打包为容器。因此，推理管道将包含两个阶段；第一阶段是应用编码，第二阶段是使用模型进行分类预测。
- en: Sounds difficult? You will see that the platform abstracts most of the details,
    and you will provide a few configuration parameters to package and deploy your
    model as a service.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来很难吗？你会看到平台已经抽象化了大部分细节，你只需要提供一些配置参数，就能将模型打包并作为服务部署。
- en: 'Let''s first see the `Transformer` class, which will load the `FlightsDelayOrdinalEncoder.pkl`
    file and apply the encoding to the input data. Open the `chapter10/model_deploy_pipeline/model_build_push/Transformer.py`
    file. You will see that the `__init__` function loads the encoder file and the
    `transform_input` function applies the transformation to the input data using
    the standard `transform` function. This is the same function you have used during
    the model training. *Figure 10.39* shows the code file:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先来看一下 `Transformer` 类，它将加载 `FlightsDelayOrdinalEncoder.pkl` 文件，并将编码应用到输入数据。打开
    `chapter10/model_deploy_pipeline/model_build_push/Transformer.py` 文件。你会看到 `__init__`
    函数加载编码器文件，`transform_input` 函数使用标准的 `transform` 函数对输入数据进行转换。这与模型训练时使用的函数相同。*图
    10.39* 显示了代码文件：
- en: '![Figure 10.39 – Transformer class'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.39 – Transformer 类'
- en: '](img/B18332_10_039.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_039.jpg)'
- en: Figure 10.39 – Transformer class
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.39 – Transformer 类
- en: The second artifact is to define the model inference graph. Recall from [*Chapter
    7*](B18332_07_ePub.xhtml#_idTextAnchor098), *Model Deployment and Automation*,
    that you have defined a container and one stage in your inference graph using
    the `SeldonDeploy.yaml` file. In this section, you will extend the inference graph
    to cater to the transformation and the prediction part of the inference pipeline.
    Naturally, when you define a new component in your graph, you will also need to
    define the corresponding container that will be the service for the graph node.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个工件是定义模型推理图。回顾[*第 7 章*](B18332_07_ePub.xhtml#_idTextAnchor098)《模型部署与自动化》，你已经使用`SeldonDeploy.yaml`文件定义了一个容器和推理图中的一个阶段。在本节中，你将扩展推理图，以适应推理管道中的转换和预测部分。自然地，当你在图中定义一个新组件时，你还需要定义相应的容器，作为图节点的服务。
- en: Note that you may choose to execute the transformation logic in `Predict.py`
    to keep things simple. However, we wanted to show how Seldon can build complicated
    graphs and each graph could be a separate instance of a container. This approach
    brings versatility to running your production models in an elastic fashion.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，你可以选择在`Predict.py`中执行转换逻辑，以保持简单。然而，我们希望展示 Seldon 如何构建复杂的图形，每个图形都可以是容器的一个单独实例。这种方法为以弹性方式运行生产模型带来了多样性。
- en: So, let's look into the `chapter10/model_deploy_pipeline/model_deploy/SeldonDeploy.yaml`
    file. This file has been copied from [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098),
    *Model Deployment and Automation*, and the following changes have been made to
    it.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下`chapter10/model_deploy_pipeline/model_deploy/SeldonDeploy.yaml`文件。该文件已从[*第
    7 章*](B18332_07_ePub.xhtml#_idTextAnchor098)《模型部署与自动化》中复制过来，并对其进行了以下修改。
- en: 'The first change is to build the inference graph. You need to apply the transformation
    first and then run the model prediction. *Figure 10.40* displays this graph. Note
    that the root element for the graph is of the `TRANSFORMER` type with the name
    `transformer`, and there is a `children` node in the graph. The `children` node
    will be executed after the root node. This setup allows you to have different
    graphs as per your model requirements. The child node in this example is the actual
    prediction:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个变化是构建推理图。你需要先应用转换操作，然后运行模型预测。*图10.40* 显示了这个图。注意，图的根元素是 `TRANSFORMER` 类型，名称为
    `transformer`，并且图中有一个 `children` 节点。`children` 节点将在根节点之后执行。这个设置允许你根据模型要求拥有不同的图。这个示例中的子节点是实际的预测：
- en: '![Figure 10.40 – Seldon deployment YAML'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.40 – Seldon 部署 YAML'
- en: '](img/B18332_10_040.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_040.jpg)'
- en: Figure 10.40 – Seldon deployment YAML
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.40 – Seldon 部署 YAML
- en: The second change to the `chapter10/model_deploy_pipeline/model_deploy/SeldonDeploy.yaml`
    file is registering the containers for both the root and the child node. The `name`
    field in the graph is the one that associates the container to the graph node.
    So, we will have two instances of a container, one for `transformer` and the second
    for `predictor`. The `transformer` instance will execute the `Transformer.py`
    file and the `predictor` instance will execute the `Predictor.py` file. What we
    have done is create a single container image with all these files, so our container
    image is the same. You can examine the `chapter10/model_deploy_pipeline/model_build_push/Dockerfile.py`
    file where you package all the files into a container image. *Figure 10.41* highlights
    the part of `SeldonDeploy.yaml` where the containers have been configured.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 对 `chapter10/model_deploy_pipeline/model_deploy/SeldonDeploy.yaml` 文件的第二个变化是为根节点和子节点注册容器。图中的
    `name` 字段是将容器与图节点关联的字段。因此，我们将有两个容器实例，一个是 `transformer`，另一个是 `predictor`。`transformer`
    实例将执行 `Transformer.py` 文件，而 `predictor` 实例将执行 `Predictor.py` 文件。我们所做的工作是创建一个包含所有这些文件的单一容器镜像，因此我们的容器镜像是相同的。你可以查看
    `chapter10/model_deploy_pipeline/model_build_push/Dockerfile.py` 文件，在其中将所有文件打包成容器镜像。*图10.41*
    突出了 `SeldonDeploy.yaml` 中配置容器的部分。
- en: 'Note that the first container is with the name `transformer`. The `MODEL_NAME`
    variable mentions the name of the Python file and the `SERVICE_TYPE` variable
    mentions the type of callback to call by Seldon. Recall that `Transformer.py`
    has a `transform_input` method, and `SERVICE_TYPE` guides the Seldon system to
    call the right function. The same is applied to the `predictor` container instance,
    and note how `MODEL_NAME` and `SERVICE_TYPE` are different for the `predictor`
    instance:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，第一个容器的名称是 `transformer`。`MODEL_NAME` 变量表示 Python 文件的名称，而 `SERVICE_TYPE` 变量表示
    Seldon 调用的回调类型。回想一下，`Transformer.py` 有一个 `transform_input` 方法，`SERVICE_TYPE` 引导
    Seldon 系统调用正确的函数。对 `predictor` 容器实例同样适用，注意 `MODEL_NAME` 和 `SERVICE_TYPE` 对于 `predictor`
    实例是不同的：
- en: '![Figure 10.41 – Seldon deployment YAML'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.41 – Seldon 部署 YAML'
- en: '](img/B18332_10_041.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_041.jpg)'
- en: Figure 10.41 – Seldon deployment YAML
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.41 – Seldon 部署 YAML
- en: That is it! For some of you, this may be a little overwhelming, but once you
    have defined the structure for your projects, these files can be standardized,
    and the data scientists will not need to change them for every project. You have
    seen how the ML platform allows you to be self-sufficient in not only building
    the models but also packaging them.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！对于你们中的一些人来说，这可能有些令人不知所措，但一旦你为项目定义了结构，这些文件就可以标准化，数据科学家将不需要为每个项目更改它们。你已经看到，ML平台不仅允许你构建模型，还能将它们打包，从而实现自给自足。
- en: The next step is to write a simple Airflow pipeline to deploy your model. Before
    you start this section, we recommend refreshing your knowledge of deploying the
    models using Airflow as detailed in [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098),
    *Model Deployment and Automation*. There is no change required in the pipeline
    that you have built, and you will just be changing a few configuration parameters
    to provide the right model name and version to the pipeline.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是编写一个简单的 Airflow 管道来部署你的模型。在开始这一部分之前，我们建议你复习一下使用 Airflow 部署模型的知识，详见[*第7章*](B18332_07_ePub.xhtml#_idTextAnchor098)，*模型部署与自动化*。你构建的管道无需更改，你只需更改几个配置参数，为管道提供正确的模型名称和版本。
- en: We have prebuilt this pipeline for you, so, open the `chapter10/model_deploy_pipeline/flights_model.pipeline`
    file. Open this file and validate that it has the same two stages as mentioned
    in [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098)*, Model Deployment and
    Automation*. The first stage builds and pushes the container image to a container
    registry and the second stage deploys the model using Seldon.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经为您预构建了此管道，因此，打开 `chapter10/model_deploy_pipeline/flights_model.pipeline`
    文件。打开此文件并验证它是否与 [*第7章*](B18332_07_ePub.xhtml#_idTextAnchor098)*，模型部署与自动化* 中提到的两个阶段相同。第一个阶段构建并推送容器镜像到容器注册表，第二个阶段使用
    Seldon 部署模型。
- en: '*Figure 10.42* displays the first stage with the parameters used for building
    and pushing the container image. **Runtime Image** and **File Dependencies** have
    the same values as shown earlier. Notice the **Environment Variables** section,
    where you have the same variable names but different values:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '*图10.42* 显示了构建和推送容器镜像时使用的参数的第一阶段。**运行时镜像**和**文件依赖项**与前面显示的值相同。请注意**环境变量**部分，您会看到相同的变量名，但值不同：'
- en: '![Figure 10.42 – Flights model deploy pipeline'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.42 – Flights模型部署管道'
- en: '](img/B18332_10_042.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_042.jpg)'
- en: Figure 10.42 – Flights model deploy pipeline
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.42 – Flights模型部署管道
- en: 'Let''s see each of them:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 我们来逐一看看它们：
- en: '`MODEL_NAME` has a value of `flights-ontime`. This is the name of the model
    you were given when you registered the model with MLflow.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MODEL_NAME` 的值为 `flights-ontime`。这是您在将模型注册到 MLflow 时分配给该模型的名称。'
- en: '`MODEL_VERSION` has a value of `1`. This is the version of the model you would
    like to deploy. This version is recorded in the MLflow system.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MODEL_VERSION` 的值为 `1`。这是您希望部署的模型版本。该版本会被记录在 MLflow 系统中。'
- en: '`CONTAINER_DETAILS` has a value of `flights-ontime`. This is the name of the
    model you were given when you registered the model with MLflow.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CONTAINER_DETAILS` 的值为 `flights-ontime`。这是您在将模型注册到 MLflow 时分配给该模型的名称。'
- en: '`CONTAINER_REGISTRY` is the container registry API endpoint. For DockerHub,
    this is at [https://index.docker.io/v1](https://index.docker.io/v1). Set the value
    of this variable to [https://index.docker.io/v1/](https://index.docker.io/v1/).
    In this example, we have used [quay.io](http://quay.io) as the registry. This
    is another free registry that you can use.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CONTAINER_REGISTRY` 是容器注册表 API 端点。对于 DockerHub，这个端点是 [https://index.docker.io/v1](https://index.docker.io/v1)。将此变量的值设置为
    [https://index.docker.io/v1/](https://index.docker.io/v1/)。在本示例中，我们使用了 [quay.io](http://quay.io)
    作为注册表。这是您可以使用的另一个免费的注册表。'
- en: '`CONTAINER_REGISTRY_USER` is the username of the user that will push images
    to the image registry. Set this to your DockerHub username or Quay username.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CONTAINER_REGISTRY_USER` 是将镜像推送到镜像注册表的用户的用户名。将此设置为您的 DockerHub 用户名或 Quay 用户名。'
- en: '`CONTAINER_REGISTRY_PASSWORD` is the password of your container registry user.
    In production, you do not want to do this. You may use secret management tools
    to serve your password.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`CONTAINER_REGISTRY_PASSWORD` 是容器注册表用户的密码。在生产环境中，您不应该这样做。您可以使用秘密管理工具来存储您的密码。'
- en: '`CONTAINER_DETAILS` is also the name of the repository to where the image will
    be pushed and the image name and image tag. *Figure 10.43* displays the second
    stage with the parameters used for deploying the container image using Seldon.
    `MODEL_NAME`, `MODEL_VERSION`, `CONTAINER_DETAILS`, and `CLUSTER_DOMAIN`. You
    have seen all the variables in the preceding paragraph, but `CLUSTER_DOMAIN` is
    the DNS name of your Kubernetes cluster. In this case, the IP address of minikube
    is `<Minikube IP>.nip.io`.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '`CONTAINER_DETAILS` 还是镜像将被推送到的仓库的名称，以及镜像名称和镜像标签。*图10.43* 显示了第二阶段，使用 Seldon
    部署容器镜像时使用的参数。`MODEL_NAME`，`MODEL_VERSION`，`CONTAINER_DETAILS` 和 `CLUSTER_DOMAIN`。您已经看到了前面一段中提到的所有变量，但
    `CLUSTER_DOMAIN` 是您 Kubernetes 集群的 DNS 名称。在本例中，minikube 的 IP 地址是 `<Minikube IP>.nip.io`。'
- en: '![Figure 10.43 – Flights model deploy pipeline'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '![图10.43 – Flights模型部署管道'
- en: '](img/B18332_10_043.jpg)'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_043.jpg)'
- en: Figure 10.43 – Flights model deploy pipeline
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 图10.43 – Flights模型部署管道
- en: Save and deploy this DAG to your Airflow environment and the model will be available
    for consumption when the Airflow DAG has finished execution. Validate that this
    DAG has been executed correctly by logging into Airflow and checking the status
    of the DAG. *Figure 10.44* shows the Airflow UI where you have validated the DAG's
    status. Notice that we have saved the DAG under the name `flights-model-deploy`;
    if you have chosen some other name, your DAG name will reflect accordingly.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 保存并部署此 DAG 到你的 Airflow 环境，当 Airflow DAG 执行完成时，模型将可供使用。通过登录 Airflow 并检查 DAG 的状态来验证此
    DAG 是否已正确执行。*图 10.44* 显示了你已验证 DAG 状态的 Airflow 用户界面。请注意，我们已将 DAG 保存为 `flights-model-deploy`；如果你选择了其他名称，DAG
    名称将相应地反映出来。
- en: '![Figure 10.44 – Airflow DAG for the flights pipeline'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.44 – 飞行管道的 Airflow DAG'
- en: '](img/B18332_10_044.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_044.jpg)'
- en: Figure 10.44 – Airflow DAG for the flights pipeline
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.44 – 飞行管道的 Airflow DAG
- en: Recall that MLflow associates a run ID for each of the experiments. You register
    one of these experiments in the model registry so it can be deployed. Refer to
    *Figure 10.34*, which shows a screenshot of the run ID for this model.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，MLflow 会为每个实验关联一个运行 ID。你将其中一个实验注册到模型注册表中，以便可以进行部署。参考*图 10.34*，该图展示了此模型的运行
    ID 截图。
- en: 'This model run will be associated with the deployed model, so your team can
    track the models running in the environment to an individual run. This capability
    provides a trace back on what version of the model is running in different environments.
    Run the following command to see the resources created by the model:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型运行将与已部署的模型相关联，因此你的团队可以将环境中运行的模型追踪到单个运行。这一功能提供了追溯不同环境中运行的模型版本的能力。运行以下命令查看模型创建的资源：
- en: '[PRE0]'
  id: totrans-243
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You should get the following response. As you can see, the Kubernetes service
    and ingress have a run ID that starts with `bf32` for this example. Note that
    it will have a different value for your case, and you will need to adjust the
    run ID in the preceding command:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该得到以下响应。如你所见，Kubernetes 服务和 Ingress 的运行 ID 在此示例中以 `bf32` 开头。请注意，在你的情况下，它将具有不同的值，你需要在前面的命令中调整运行
    ID：
- en: '![Figure 10.45 – Kubernetes objects created by the platform'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.45 – 平台创建的 Kubernetes 对象'
- en: '](img/B18332_10_045.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_045.jpg)'
- en: Figure 10.45 – Kubernetes objects created by the platform
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.45 – 平台创建的 Kubernetes 对象
- en: Now, the model is deployed; you now test the model by running a RESTful call
    to your model.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，模型已部署；你可以通过对模型进行 RESTful 调用来测试它。
- en: Calling your model
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调用你的模型
- en: 'Recall that the model is exposed via the Kubernetes Ingress, which is created
    by automation. In order to test whether the model is running properly as a RESTful
    API, follow these steps:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下，模型是通过 Kubernetes Ingress 暴露的，而 Ingress 是通过自动化创建的。为了测试模型是否作为 RESTful API
    正常运行，请按照以下步骤操作：
- en: 'Run the following command to get the `ingress` object. Note that the name of
    the `ingress` object will be different for your setup:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令以获取`ingress`对象。注意，`ingress`对象的名称将在你的设置中有所不同：
- en: '[PRE1]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Now, make an HTTP call to the location where your model is available for inference.
    Run the following commands. The `chapter10/inference` folder contains a payload
    for the flight data and in return, the model will predict the probability of the
    flight getting delayed.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，发起 HTTP 调用到你的模型可用于推理的位置。运行以下命令。`chapter10/inference` 文件夹包含航班数据的负载，模型将返回预测航班延误的概率。
- en: 'First, change the directory to the `chapter10/inference` folder:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，切换到 `chapter10/inference` 文件夹：
- en: '[PRE2]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Then, run a `curl` command to send the payload to the model. Note to change
    the HTTP address as per your setup:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，运行`curl`命令将负载发送到模型。请根据你的设置更改 HTTP 地址：
- en: '[PRE3]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Windows users may choose to use the excellent Postman application ([https://www.postman.com/](https://www.postman.com/))
    to make an HTTP call.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Windows 用户可以选择使用优秀的 Postman 应用程序（[https://www.postman.com/](https://www.postman.com/)）来发起
    HTTP 调用。
- en: 'Open the `chapter10/inference/data.json` file to see the payload that we are
    sending to the model. You will notice that there are two sections of the `json`
    payload. The first part is with the `names` key, which captures the feature columns
    that you have used to train the model. Notice that there is no `DELAYED` column
    here because the model will predict the probability of the `DELAYED` column. The
    second part is with the `ndarrray` key, which has the values for the feature columns.
    Note that the values for the categorical columns are in the original form and
    the inference pipeline will convert them into the categorical values before executing
    the model. *Figure 10.46* shows the following file:'
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 `chapter10/inference/data.json` 文件，查看我们发送给模型的有效载荷。你会注意到，`json` 有效载荷中有两个部分。第一部分是带有
    `names` 键的部分，用于捕获你在训练模型时使用的特征列。注意这里没有 `DELAYED` 列，因为模型将预测 `DELAYED` 列的概率。第二部分是带有
    `ndarrray` 键的部分，包含了特征列的值。需要注意的是，类别列的值是以原始形式存在的，推理管道会在执行模型之前将其转换为类别值。*图 10.46*
    显示了以下文件：
- en: '![Figure 10.46 – Sample payload for flights model inferencing'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.46 – 航班模型推理的示例有效载荷'
- en: '](img/B18332_10_046.jpg)'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_046.jpg)'
- en: Figure 10.46 – Sample payload for flights model inferencing
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.46 – 航班模型推理的示例有效载荷
- en: Now that you have successfully performed an inference call over HTTP, let's
    see how the information has been captured by the monitoring system.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经成功地通过 HTTP 进行推理调用，让我们看看监控系统是如何捕获这些信息的。
- en: Monitoring your model
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控你的模型
- en: In this last section, you will see how the platform automatically starts capturing
    the typical performance metrics of your model. The platform also helps you visualize
    the performance of the inference. The platform uses Seldon to package the model,
    and Seldon exposes default metrics to be captured. Seldon also allows you to write
    custom metrics for specific models; however, it is out of the scope of this book.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一节中，你将看到平台如何自动开始捕获模型的典型性能指标。平台还帮助你可视化推理的性能。平台使用 Seldon 打包模型，Seldon 会暴露默认的指标以供捕获。Seldon
    还允许你为特定模型编写自定义指标；不过这部分内容不在本书的范围之内。
- en: Let's start by understanding how the metrics capture and visualization work.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先理解一下指标捕获和可视化是如何工作的。
- en: Understanding monitoring components
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解监控组件
- en: The way metrics capture works is that your model is wrapped by Seldon. Seldon
    then exposes the metrics to a well-defined URL endpoint, which was detailed in
    [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098), *Model Deployment and Automation*.
    Prometheus harvests this information and stores it in its database. The platform's
    Grafana connects to Prometheus and helps you visualize the recorded metrics.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 指标捕获的工作方式是，模型由 Seldon 封装。然后 Seldon 将这些指标暴露到一个定义良好的 URL 端点，详细信息请参见 [*第 7 章*](B18332_07_ePub.xhtml#_idTextAnchor098)，*模型部署与自动化*。Prometheus
    收集这些信息并将其存储在其数据库中。平台的 Grafana 连接到 Prometheus，并帮助你可视化记录的指标。
- en: '*Figure 10.47* summarizes the relationship between the model and monitoring
    components:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 10.47* 总结了模型与监控组件之间的关系：'
- en: '![Figure 10.47 – ML platform monitoring components'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.47 – ML 平台监控组件'
- en: '](img/B18332_10_047.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_047.jpg)'
- en: Figure 10.47 – ML platform monitoring components
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.47 – ML 平台监控组件
- en: 'Let''s understand each component of this diagram:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们理解一下这个图中的每个组件：
- en: '**Open Data Hub (ODH) Operator**: This is the base operator for our platform.
    Its role is to provision all the different components for your platform. We have
    discussed this operator in various chapters of this book and so we do not describe
    it in this section.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开放数据中心（ODH）操作员**：这是我们平台的基础操作员。它的作用是为平台提供所有不同的组件。在本书的多个章节中，我们已经讨论过这个操作员，因此在本节中不再详细描述。'
- en: '`manifests/prometheus/base/subscription.yaml`. The following snippet shows
    that it uses the OLM mechanism to install the Prometheus operator:'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`manifests/prometheus/base/subscription.yaml`。以下代码片段展示了它如何使用 OLM 机制来安装 Prometheus
    操作员：'
- en: '![Figure 10.48 – Subscription for Prometheus operator'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.48 – Prometheus 操作员的订阅'
- en: '](img/B18332_10_048.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_048.jpg)'
- en: Figure 10.48 – Subscription for Prometheus operator
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.48 – Prometheus 操作员的订阅
- en: '`manifests/prometheus/base/prometheus.yaml`. The following snippet shows the
    file:'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`manifests/prometheus/base/prometheus.yaml`。以下代码片段展示了该文件：'
- en: '![Figure 10.49 – Prometheus server configuration'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.49 – Prometheus 服务器配置'
- en: '](img/B18332_10_049.jpg)'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_049.jpg)'
- en: Figure 10.49 – Prometheus server configuration
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.49 – Prometheus 服务器配置
- en: '`manifests/prometheus/base/prometheus.yaml`. The following snippet shows the
    file. Note that the configuration uses port `8000`, which is the port at which
    Seldon exposes the metrics information. The `selector` object defines the filter
    by which Prometheus will decide what pods to scrape data from:'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`manifests/prometheus/base/prometheus.yaml`。以下代码片段展示了该文件。请注意，配置使用了端口 `8000`，这是
    Seldon 用于暴露指标信息的端口。`selector` 对象定义了 Prometheus 用来决定从哪些 Pod 抓取数据的过滤器：'
- en: '![Figure 10.50 – Prometheus server monitors for Seldon pods'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.50 – Prometheus 服务器监控 Seldon Pod'
- en: '](img/B18332_10_050.jpg)'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_050.jpg)'
- en: Figure 10.50 – Prometheus server monitors for Seldon pods
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.50 – Prometheus 服务器监控 Seldon Pod
- en: '`manifests/grafana/base/deployment.yaml` file.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`manifests/grafana/base/deployment.yaml` 文件。'
- en: In this section, you have seen how the platform provides and wires different
    components to provide you with a visualization framework for your observability
    requirements.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你已经看到平台如何提供和连接不同的组件，为你提供一个可视化框架，以满足你的可观察性需求。
- en: Next is to configure Grafana.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是配置 Grafana。
- en: Configuring Grafana and a dashboard
  id: totrans-290
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置 Grafana 和仪表板
- en: In this section, you will configure Grafana to connect to Prometheus and build
    a dashboard to visualize the model's metrics. What is a dashboard? It is a set
    of graphs, tables, and other visualizations of your model. You will create a dashboard
    for the flight model.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将配置 Grafana 连接到 Prometheus，并构建一个仪表板来可视化模型的指标。什么是仪表板？它是你的模型的图表、表格和其他可视化元素的集合。你将为航班模型创建一个仪表板。
- en: Note that this is a one-time configuration, and it does not need to be repeated
    for every model. This means that once you have a dashboard, you can use it for
    multiple models. Your team may create a few standard dashboards and as soon as
    a new model is deployed, the platform will automatically find it and make it available
    for monitoring.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这只是一次性配置，不需要为每个模型重复此过程。这意味着一旦你有了仪表板，就可以在多个模型中使用它。你的团队可能会创建一些标准仪表板，一旦新的模型被部署，平台会自动找到它并将其用于监控。
- en: 'Let''s start with the configuration of the Grafana instance:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始配置 Grafana 实例：
- en: 'Log in to Grafana using https://grafna.192.128.36.219.nip.io. Notice that you
    will need to change the IP address as per your setup. On the login page, click
    the **Sign in With KeyCloak** button, which is at the bottom of the login window:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 https://grafna.192.128.36.219.nip.io 登录 Grafana。请注意，你需要根据你的设置更改 IP 地址。在登录页面，点击
    **使用 KeyCloak 登录** 按钮，它位于登录窗口的底部：
- en: '![Figure 10.51 – Grafana login page'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.51 – Grafana 登录页面'
- en: '](img/B18332_10_051.jpg)'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_051.jpg)'
- en: Figure 10.51 – Grafana login page
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.51 – Grafana 登录页面
- en: 'First, you will need to add a data source. A data source is a system that will
    provide the data that Grafana will help you visualize. The data provider in Prometheus
    scrapes the metrics data from your models. Select the **Configuration** | **Data
    sources** option from the left-hand menu:'
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，你需要添加一个数据源。数据源是一个系统，它将提供 Grafana 帮助你可视化的数据。Prometheus 是数据提供者，它从你的模型中抓取指标数据。选择左侧菜单中的
    **配置** | **数据源** 选项：
- en: '![Figure 10.52 – Grafana Data sources menu option'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.52 – Grafana 数据源菜单选项'
- en: '](img/B18332_10_052.jpg)'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_052.jpg)'
- en: Figure 10.52 – Grafana Data sources menu option
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.52 – Grafana 数据源菜单选项
- en: 'Click on the **Add data source** button, as shown in the following screenshot:'
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **添加数据源** 按钮，如下图所示：
- en: '![Figure 10.53 – Add new Grafana data source'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.53 – 添加新的 Grafana 数据源'
- en: '](img/B18332_10_053.jpg)'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_053.jpg)'
- en: Figure 10.53 – Add new Grafana data source
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.53 – 添加新的 Grafana 数据源
- en: Select the data source type, which will be Prometheus for your case. You may
    notice that Grafana can talk to a variety of data sources, including InfluxDB
    and YYYY, to name a couple.
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择数据源类型，在你的案例中为 Prometheus。你可能会注意到，Grafana 可以与多种数据源进行通信，包括 InfluxDB 和 YYYY 等。
- en: '![Figure 10.54 – Add new Prometheus Grafana data source'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.54 – 添加新的 Prometheus Grafana 数据源'
- en: '](img/B18332_10_054.jpg)'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_054.jpg)'
- en: Figure 10.54 – Add new Prometheus Grafana data source
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.54 – 添加新的 Prometheus Grafana 数据源
- en: 'Now, you need to add the details for the Prometheus server. Grafana will use
    these details to connect and fetch data from the Prometheus server. Add the following
    properties in the screen mentioned:'
  id: totrans-310
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你需要添加 Prometheus 服务器的详细信息。Grafana 将使用这些详细信息连接并从 Prometheus 服务器获取数据。在提到的屏幕中添加以下属性：
- en: '`Prometheus`'
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Prometheus`'
- en: '**URL**: http://prometheus-operated:9090'
  id: totrans-312
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**URL**: http://prometheus-operated:9090'
- en: 'Then click the **Save & test** button. The URL is the location of the Prometheus
    service created by the platform. Because the Grafana pod will talk to the Prometheus
    pod using the internal Kubernetes network, this URL will be the same for your
    setup too:'
  id: totrans-313
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后点击**保存并测试**按钮。URL 是由平台创建的 Prometheus 服务的地址。由于 Grafana pod 将通过 Kubernetes 内部网络与
    Prometheus pod 通信，因此这个 URL 对你的设置也是相同的：
- en: '![Figure 10.55 – Configuration for the Prometheus Grafana data source'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.55 – Prometheus Grafana 数据源的配置'
- en: '](img/B18332_10_055.jpg)'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_055.jpg)'
- en: Figure 10.55 – Configuration for the Prometheus Grafana data source
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.55 – Prometheus Grafana 数据源的配置
- en: 'You can find the `prometheus` service details by issuing the following command:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过执行以下命令来查看`prometheus`服务的详细信息：
- en: '[PRE4]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After you configure Grafana to connect to Prometheus, the next step is to build
    the dashboard. As mentioned earlier, a dashboard is a set of visualizations, and
    each visualization is backed by a query. Grafana runs those queries and plots
    the data for you. Building dashboards is out of the scope of this book, but we
    have provided a dashboard that you can use. Select the **Import** option from
    the left-hand menu:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在你配置 Grafana 连接到 Prometheus 后，下一步是构建仪表盘。如前所述，仪表盘是一组可视化内容，每个可视化内容都由查询支持。Grafana
    会运行这些查询并为你绘制数据。构建仪表盘超出了本书的范围，但我们提供了一个你可以使用的仪表盘。请从左侧菜单中选择**导入**选项：
- en: '![Figure 10.56 – Adding a new dashboard in Grafana'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.56 – 在 Grafana 中添加新仪表盘'
- en: '](img/B18332_10_056.jpg)'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_056.jpg)'
- en: Figure 10.56 – Adding a new dashboard in Grafana
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.56 – 在 Grafana 中添加新仪表盘
- en: 'On the `chapter10/grafana-dashboard/sample-seldon-dashboard.json` file and
    paste it into the **Import via panel json** textbox. Click on the **Load** button
    to import the dashboard:'
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开`chapter10/grafana-dashboard/sample-seldon-dashboard.json`文件，将其粘贴到**通过面板 JSON
    导入**文本框中。点击**加载**按钮导入仪表盘：
- en: '![Figure 10.57 – Importing a Seldon dashboard in Grafana'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.57 – 在 Grafana 中导入 Seldon 仪表盘'
- en: '](img/B18332_10_057.jpg)'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_057.jpg)'
- en: Figure 10.57 – Importing a Seldon dashboard in Grafana
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.57 – 在 Grafana 中导入 Seldon 仪表盘
- en: 'Set the name for your imported dashboard and click on the `Flights Prediction
    Analytics`, as you can see in the following screenshot:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置导入的仪表盘名称，并点击`Flights Prediction Analytics`，如下面的截图所示：
- en: '![Figure 10.58 – Importing Seldon dashboard in Grafana'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.58 – 在 Grafana 中导入 Seldon 仪表盘'
- en: '](img/B18332_10_058.jpg)'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_058.jpg)'
- en: Figure 10.58 – Importing Seldon dashboard in Grafana
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.58 – 在 Grafana 中导入 Seldon 仪表盘
- en: After you import the dashboard, Grafana will start displaying the dashboard
    immediately. You can see a few metrics such as response times, success rate, and
    other relative metrics for your deployed model. You may need to hit your model
    a few times to start populating this board. Refer to the *Calling your model*
    section earlier in this chapter on how to make calls to your deployed models.
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导入仪表盘后，Grafana 将立即开始显示仪表盘。你可以看到一些指标，比如响应时间、成功率以及其他与已部署模型相关的指标。你可能需要多次调用你的模型，才能开始填充这个仪表盘。请参考本章前面提到的*调用你的模型*部分，了解如何调用已部署的模型。
- en: '![Figure 10.59 – Dashboard for Seldon models'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.59 – Seldon 模型仪表盘'
- en: '](img/B18332_10_059.jpg)'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_10_059.jpg)'
- en: Figure 10.59 – Dashboard for Seldon models
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.59 – Seldon 模型仪表盘
- en: You can see that the board captures the metrics that have been emitted by your
    model wrapped in Seldon. As more models get deployed, they will be available in
    this dashboard, and you can filter the models through the filters provided in
    the top bar of the dashboard.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到仪表盘捕获了由你包装在 Seldon 中的模型所发出的指标。随着更多模型的部署，它们将出现在这个仪表盘中，你可以通过仪表盘顶部的过滤器来筛选模型。
- en: Your flights on-time prediction service is now available for consumption. You
    will now work with the product development team and the website team of your organization
    so that they can integrate this functionality and provide a better service for
    your customers. Your work does not finish here; you will need to continuously
    see how the model is performing and bring on improvements via new data and/or
    optimizing your models further. The platform will help you to perform this cycle
    with higher velocity and continuously improve the offerings to your customers.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你的航班准时预测服务已经可以使用。接下来，你将与产品开发团队和网站团队合作，帮助他们集成这个功能，为客户提供更好的服务。你的工作并不会在此结束；你需要持续监控模型的表现，并通过新的数据和/或进一步优化模型来提升服务。该平台将帮助你加速这个循环，并不断改进对客户的服务。
- en: Summary
  id: totrans-337
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This was another long chapter that covered the model development and deployment
    life cycle for the flights on-time performance project. You have seen how the
    platform enables you and your team to become autonomous in EDA, model experimentation
    and tracking, model registry, and model deployment.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个长章节，涵盖了航班准点率项目的模型开发和部署生命周期。你已经看到平台如何帮助你和你的团队在EDA、模型实验与追踪、模型注册以及模型部署方面实现自主。
- en: In the next chapter, we will take a step back and summarize our journey of the
    overall platform and how you can use it as your own solution that fits your vertical.
    You can use the concepts and tools to build a platform for your team and enable
    your business to realize the power of AI.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将退后一步，总结整体平台的旅程，并讲解如何将其作为适合你行业的解决方案。你可以利用这些概念和工具为你的团队构建一个平台，帮助你的业务实现AI的强大力量。
