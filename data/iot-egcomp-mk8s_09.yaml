- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Using Kubeflow to Run AI/MLOps Workloads
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kubeflow 运行 AI/MLOps 工作负载
- en: In the previous chapter, we looked at several logging, monitoring, and alerting
    options to gain comprehensive visibility into our container infrastructure and
    workloads. Regarding tools for setting up a monitoring and alerting stack, we
    looked at Prometheus, Grafana, and Alert Manager. We also looked at how to use
    the EFK toolset to set up a centralized, cluster-level logging stack that can
    handle large volumes of log data. Finally, we discussed the key indicators to
    keep a close eye on so that you can effectively manage your infrastructure and
    applications.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们讨论了几种日志记录、监控和警报选项，以便全面了解我们的容器基础设施和工作负载。关于设置监控和警报堆栈的工具，我们介绍了 Prometheus、Grafana
    和 Alert Manager。我们还讨论了如何使用 EFK 工具集设置一个集中式的集群级日志堆栈，以处理大量的日志数据。最后，我们探讨了应密切关注的关键指标，以便有效管理你的基础设施和应用程序。
- en: In this chapter, we will go through the steps for creating a **machine learning**
    (**ML**) pipeline that will build and deploy a sample ML model using the Kubeflow
    MLOps platform. ML is an AI subfield. The purpose of ML is to teach computers
    to learn from the data you provide. Instead of describing the action, the machine
    will take your code and provide an algorithm that adjusts, depending on samples
    of expected behavior. A trained model is the code that results from the combination
    of the algorithm and the learned parameters.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将介绍使用 Kubeflow MLOps 平台创建 **机器学习** (**ML**) 流水线的步骤，该流水线将构建并部署一个示例 ML
    模型。ML 是人工智能（AI）领域的一个子领域。ML 的目的是教会计算机从你提供的数据中学习。机器并不通过描述行为来进行操作，而是根据预期行为的样本来调整其算法。训练好的模型是算法与学习到的参数结合后所生成的代码。
- en: 'The following is a high-level overview of the stages in a typical ML workflow:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是典型 ML 工作流中各个阶段的高级概览：
- en: Source and prepare relevant data
  id: totrans-5
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取并准备相关数据
- en: Develop the ML model
  id: totrans-6
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开发 ML 模型
- en: Train the model, evaluate model accuracy, and tune the model
  id: totrans-7
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 训练模型、评估模型精度，并调整模型
- en: Deploy the trained model
  id: totrans-8
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署训练好的模型
- en: Get predictions from the model
  id: totrans-9
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从模型中获取预测结果
- en: Monitor the ongoing predictions
  id: totrans-10
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 监控正在进行的预测
- en: Manage the models and their versions
  id: totrans-11
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 管理模型及其版本
- en: These are iterative stages. At any time during the procedure, you may need to
    rethink and return to a prior phase.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是迭代阶段。在整个过程中，你可能需要重新思考并返回到之前的阶段。
- en: ML pipelines assist in automating the ML workflow and allowing sequence data
    to be converted and correlated together in a model so that it can be evaluated.
    It also allows outputs to be generated. The ML pipeline is designed to allow data
    to go from raw data format to meaningful information. It provides a way for constructing
    a multi-ML parallel pipeline system to investigate the outputs of various ML algorithms.
    There are various stages in a pipeline. Each stage of a pipeline receives data
    that’s been processed from the stage before it – for example, the output of a
    processing unit is fed into the next phase.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ML 流水线有助于自动化 ML 工作流，并允许将序列数据转换并相关联，以便在模型中进行评估。它还允许生成输出。ML 流水线旨在将数据从原始数据格式转换为有意义的信息。它提供了一种构建多
    ML 并行流水线系统的方法，用于调查各种 ML 算法的输出。流水线中有多个阶段。每个阶段接收来自前一阶段处理的数据 —— 例如，处理单元的输出会输入到下一阶段。
- en: Kubeflow is a platform for data scientists to build and experiment with ML pipelines.
    It allows you to deploy and build ML workflows. You can specify the ML tools required
    for your workflow using the Kubeflow configuration. The workflow can then be deployed
    to the cloud, local, and on-premises multiple platforms for testing and production
    use.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 是一个供数据科学家构建和实验 ML 流水线的平台。它允许你部署和构建 ML 工作流。你可以使用 Kubeflow 配置来指定工作流所需的
    ML 工具。然后，可以将工作流部署到云端、本地及本地部署的多个平台进行测试和生产使用。
- en: Data scientists and ML engineers use Kubeflow on MicroK8s to quickly prototype,
    construct, and deploy ML pipelines. Kubeflow makes MLOps more manageable by bridging
    the gap between AI workloads and Kubernetes.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学家和 ML 工程师使用 Kubeflow 在 MicroK8s 上快速原型开发、构建和部署 ML 流水线。Kubeflow 通过弥合 AI 工作负载与
    Kubernetes 之间的差距，使 MLOps 更加可管理。
- en: Furthermore, Kubeflow on MicroK8s is straightforward to set up and configure,
    as well as lightweight and capable of simulating production conditions for pipeline
    creation, migration, and deployment.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Kubeflow 在 MicroK8s 上的设置和配置非常简便，并且轻量级，能够模拟生产环境以进行流水线的创建、迁移和部署。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: Overview of the ML workflow
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习工作流概览
- en: Deploying Kubeflow
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署Kubeflow
- en: Accessing the Kubeflow dashboard
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问Kubeflow仪表板
- en: Creating a Kubeflow pipeline to build, train, and deploy a sample ML model
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建一个Kubeflow管道来构建、训练和部署一个示例机器学习模型
- en: Recommendations – running AL/ML workloads on Kubernetes
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐 — 在Kubernetes上运行AL/ML工作负载
- en: Overview of the ML workflow
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习工作流概览
- en: Kubeflow aims to be your Kubernetes ML toolkit. The ML tools that are required
    for your workflow can then be specified using the Kubeflow configurations and
    the workflow can be deployed to various platforms for testing and production use
    as required.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow旨在成为您的Kubernetes机器学习工具包。您可以使用Kubeflow配置来指定工作流所需的机器学习工具，然后将工作流部署到各种平台进行测试和生产使用。
- en: Let’s have a look at the Kubeflow components before we get into the intricacies
    of ML workflows.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解机器学习工作流的复杂性之前，让我们先来看看Kubeflow的各个组件。
- en: Introduction – Kubeflow and its components
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍 — Kubeflow及其组件
- en: Kubeflow is a system for deploying, scaling, and managing complex systems based
    on Kubernetes. For data scientists, Kubeflow is the go-to platform for building
    and testing ML pipelines. It is also for ML developers and operations teams who
    wish to deploy ML systems in a variety of contexts for development, testing, and
    production.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow是一个基于Kubernetes部署、扩展和管理复杂系统的系统。对于数据科学家来说，Kubeflow是构建和测试机器学习管道的首选平台。它也适用于希望在不同环境中部署机器学习系统的机器学习开发人员和运维团队，涵盖开发、测试和生产等各个环节。
- en: 'Kubeflow is a framework for establishing the components of your ML system on
    top of Kubernetes, as shown in the following diagram:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow是一个框架，用于在Kubernetes之上构建机器学习系统的各个组件，如下图所示：
- en: '![Figure 9.1 – Kubeflow components on top of Kubernetes ](img/Figure_9.1_B18115.jpg)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![图9.1 — Kubeflow组件在Kubernetes之上的布局](img/Figure_9.1_B18115.jpg)'
- en: Figure 9.1 – Kubeflow components on top of Kubernetes
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.1 — Kubeflow组件在Kubernetes之上的布局
- en: We can specify the ML tools required for our workflow by utilizing the Kubeflow
    configuration interfaces. The workflow can then be deployed to multiple clouds,
    local, and on-premises platforms for testing and production use.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过利用Kubeflow配置接口来指定工作流所需的机器学习工具。然后，工作流可以部署到多个云平台、本地和内部平台进行测试和生产使用。
- en: 'The following ML tools are supported by Kubeflow:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 以下机器学习工具由Kubeflow支持：
- en: '**Chainer**: Python-based deep learning framework.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Chainer**：基于Python的深度学习框架。'
- en: '**Jupyter**: Interactive development environment for notebooks, code, and data
    that is accessible through the web. Users can create and arrange workflows in
    data science, scientific computing, computational journalism, and ML using its
    versatile interface.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jupyter**：一个互动式开发环境，适用于笔记本、代码和数据，可以通过网页访问。用户可以通过其多功能的界面在数据科学、科学计算、计算新闻学和机器学习中创建和安排工作流。'
- en: '**MPI**: This is a message-passing standard that is standardized and portable
    and can be used on parallel computing platforms.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MPI**：这是一个标准化且可移植的消息传递标准，可用于并行计算平台。'
- en: '**MXNet**: This is an open source deep learning software framework that’s used
    to train and deploy deep neural networks.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MXNet**：这是一个开源深度学习软件框架，用于训练和部署深度神经网络。'
- en: '**PyTorch**: This is an open source ML framework based on the Torch library
    that’s used for applications such as computer vision and natural language processing.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PyTorch**：这是一个基于Torch库的开源机器学习框架，广泛应用于计算机视觉和自然语言处理等领域。'
- en: '**Scikit-learn**: This is an ML library for Python that includes support-vector
    machines, random forests, gradient boosting, k-means, and DBSCAN, among other
    classification, regression, and clustering techniques, and is designed to work
    with the Python numerical and scientific libraries known as NumPy and SciPy.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Scikit-learn**：这是一个Python机器学习库，支持支持向量机、随机森林、梯度提升、k-means和DBSCAN等分类、回归和聚类技术，并且设计上与Python的数值计算和科学计算库NumPy和SciPy兼容。'
- en: '**TensorFlow**: This is an ML and AI software library that is free and open
    source. It can be used for a variety of applications, but it focuses on deep neural
    network training and inference.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow**：这是一个开源的机器学习和人工智能软件库，适用于各种应用，特别是深度神经网络的训练和推理。'
- en: '**XGBoost**: This is an open source software library that provides a regularizing
    gradient boosting framework for C++, Java, Python, R, Julia, Perl, and Scala.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**XGBoost**：这是一个开源软件库，提供了一个正则化的梯度提升框架，支持C++、Java、Python、R、Julia、Perl和Scala等语言。'
- en: 'The following are the logical components that make up Kubeflow:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是构成 Kubeflow 的逻辑组件：
- en: '**Dashboard** allows you to quickly access the Kubeflow components installed
    in your cluster.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Dashboard** 允许你快速访问集群中安装的 Kubeflow 组件。'
- en: '**Kubeflow Notebooks** allows you to run web-based development environments
    within your Kubernetes cluster by encapsulating them in pods.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubeflow Notebooks** 允许你通过将其封装在 pods 中，在 Kubernetes 集群内运行基于 Web 的开发环境。'
- en: '**Kubeflow Pipelines** is a Docker-based platform for creating and deploying
    portable, scalable ML workflows.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubeflow Pipelines** 是一个基于 Docker 的平台，用于创建和部署可移植、可扩展的机器学习工作流。'
- en: '**KServing** provides performant, high abstraction interfaces for serving models
    using standard ML frameworks such as TensorFlow, XGBoost, scikit-learn, PyTorch,
    and ONNX to tackle production model serving use cases.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**KServing** 提供高性能、高抽象接口，用于使用标准机器学习框架（如 TensorFlow、XGBoost、scikit-learn、PyTorch
    和 ONNX）为生产模型提供服务，解决生产模型服务的应用场景。'
- en: '**TensorFlow Serving** takes care of serving functionality for TensorFlow models.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TensorFlow Serving** 负责为 TensorFlow 模型提供服务功能。'
- en: '**PyTorch Serving** takes care of serving functionality for the PyTorch model
    with Seldon.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PyTorch Serving** 负责与 Seldon 一起为 PyTorch 模型提供服务功能。'
- en: '**Seldon** manages, serves, and scales models in any language or framework
    on Kubernetes.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Seldon** 在 Kubernetes 上管理、提供和扩展任何语言或框架的模型。'
- en: '**Katib** is a scalable and flexible hyperparameter tuning framework that is
    tightly integrated with Kubernetes.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Katib** 是一个可扩展且灵活的超参数调优框架，紧密集成了 Kubernetes。'
- en: '**Training operators** train ML models through operators.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**训练操作符** 通过操作符训练机器学习模型。'
- en: '**Istio Integration** (for TF Serving) provides functionalities such as metrics,
    auth and quota, rollout and A/B testing, and more.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Istio 集成**（针对 TF Serving）提供了诸如指标、身份验证和配额、发布和 A/B 测试等功能。'
- en: '**Argo workflows** is a workflow engine that Kubeflow pipelines use to carry
    out various actions, such as monitoring pod logs, collecting artifacts, managing
    container life cycles, and more.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Argo workflows** 是一个工作流引擎，Kubeflow Pipelines 使用它来执行各种操作，如监控 pod 日志、收集工件、管理容器生命周期等。'
- en: '**Prometheus** takes care of logging and monitoring for Kubeflow metrics and
    Kubernetes components.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus** 负责 Kubeflow 指标和 Kubernetes 组件的日志记录和监控。'
- en: '**Multi-Tenancy** is self-served – a new user can self-register to create and
    own their workspace through the UI. It is currently built around *user namespaces*.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多租户** 是自服务的 – 新用户可以通过 UI 自行注册来创建和拥有他们的工作区。当前是围绕 *用户命名空间* 构建的。'
- en: Now that we’ve seen the various Kubeflow components and ML tools, let’s get
    into the specifics of understanding the ML workflow.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了各种 Kubeflow 组件和机器学习工具，让我们深入理解机器学习工作流的具体内容。
- en: Introduction to the ML workflow
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 机器学习工作流简介
- en: The ML workflow is typically comprised of multiple stages while developing and
    deploying an ML system. It is an iterative procedure for developing an ML system.
    To guarantee that the model continues to produce the results you require, you
    must review the output of various phases of the ML workflow and adjust the model
    and parameters as needed.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习工作流通常包含多个阶段，在开发和部署机器学习系统时，这是一个迭代过程。为了确保模型继续生成所需的结果，必须审查机器学习工作流各个阶段的输出，并根据需要调整模型和参数。
- en: 'The following diagram shows the experimental phase workflow stages in sequence:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了实验阶段工作流的各个阶段顺序：
- en: '![Figure 9.2 – Experimental phase workflow stages ](img/Figure_9.02_B18115.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.2 – 实验阶段工作流 ](img/Figure_9.02_B18115.jpg)'
- en: Figure 9.2 – Experimental phase workflow stages
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 – 实验阶段工作流
- en: 'In the experimental phase, the model would be built based on initial assumptions
    and tested and updated iteratively to achieve the desired results:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在实验阶段，模型会基于初始假设构建，并通过迭代测试和更新，以实现预期的结果：
- en: Determine the problem that needs to be solved by the ML system.
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确定需要由机器学习系统解决的问题。
- en: Collect and analyze the data required to train the ML model.
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 收集并分析训练机器学习模型所需的数据。
- en: Select an ML framework and algorithm, and then code the first version of the
    model.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择一个机器学习框架和算法，然后编写模型的第一个版本。
- en: Experiment with the data and model’s training.
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实验数据和模型的训练。
- en: Tune the model’s hyperparameters.
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调整模型的超参数。
- en: 'The following diagram shows the production phase workflow stages in sequence:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了生产阶段工作流的各个阶段顺序：
- en: '![Figure 9.3 – Production phase workflow stages ](img/Figure_9.03_B18115.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.3 – 生产阶段工作流 ](img/Figure_9.03_B18115.jpg)'
- en: Figure 9.3 – Production phase workflow stages
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.3 – 生产阶段工作流
- en: 'During the production phase, a system will be deployed that handles the following
    tasks:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在生产阶段，将部署一个处理以下任务的系统：
- en: Transform the data into the format required by the training system. To ensure
    that the model behaves consistently during training and prediction, the transformation
    process in the experimental and production phases must be the same.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据转化为训练系统所需的格式。为了确保模型在训练和预测过程中表现一致，实验阶段和生产阶段的转化过程必须相同。
- en: Develop the ML model.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发 ML 模型。
- en: Serve the model for online prediction or batch processing.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为在线预测或批处理提供模型服务。
- en: Monitor the model’s performance and feed the results into the model for tuning
    or retraining processes.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控模型的性能，并将结果反馈到模型中，以进行调优或重新训练过程。
- en: Now that we know what all the activities in the experimental and production
    stages involve, let’s look at the Kubeflow components that are involved in each
    phase.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了实验和生产阶段的各项活动，接下来看看每个阶段涉及的 Kubeflow 组件。
- en: Kubeflow components in each phase
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 每个阶段的 Kubeflow 组件
- en: 'The following diagram shows the experimental phase workflow stages and the
    Kubeflow components involved in each stage:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了实验阶段工作流的各个步骤以及每个阶段涉及的 Kubeflow 组件：
- en: '![Figure 9.4 – Experimental phase stages and Kubeflow components ](img/Figure_9.04_B18115.jpg)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.4 – 实验阶段步骤和 Kubeflow 组件](img/Figure_9.04_B18115.jpg)'
- en: Figure 9.4 – Experimental phase stages and Kubeflow components
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.4 – 实验阶段步骤和 Kubeflow 组件
- en: 'The following diagram shows the production phase workflow stages and the Kubeflow
    components involved in each stage:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了生产阶段工作流的各个步骤以及每个阶段涉及的 Kubeflow 组件：
- en: '![Figure 9.5 – Production phase stages and Kubeflow components ](img/Figure_9.05_B18115.jpg)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.5 – 生产阶段步骤和 Kubeflow 组件](img/Figure_9.05_B18115.jpg)'
- en: Figure 9.5 – Production phase stages and Kubeflow components
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.5 – 生产阶段步骤和 Kubeflow 组件
- en: 'Some of Kubeflow’s most important components are as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 中一些最重要的组件如下：
- en: Jupyter notebooks can be spawned and managed using Kubeflow’s services. Notebooks
    are used for interactive data science and ML workflow experiments.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可以使用 Kubeflow 的服务创建和管理 Jupyter 笔记本。笔记本用于交互式数据科学和 ML 工作流实验。
- en: Kubeflow Pipelines is a container-based platform for creating, deploying, and
    managing multi-step ML processes based on Docker containers.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubeflow Pipelines 是一个基于容器的平台，用于创建、部署和管理基于 Docker 容器的多步骤 ML 过程。
- en: Kubeflow has several components that can be used for ML training, hyperparameter
    tweaking, and workload serving across many platforms.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubeflow 拥有多个组件，可用于 ML 训练、超参数调整以及跨多个平台的工作负载服务。
- en: Now that we’ve looked at the various Kubeflow components and steps involved
    in the ML process stages, let’s look at Kubeflow Pipelines.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看过了涉及 ML 过程各个阶段的 Kubeflow 组件和步骤，接下来让我们来看一下 Kubeflow Pipelines。
- en: Kubeflow Pipelines
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubeflow Pipelines
- en: Kubeflow Pipelines are one of the most essential elements of Kubeflow that make
    AI/ML experiments reproducible, composable, scalable, and easily shareable. Each
    pipeline component, denoted by a block, is a self-contained piece of code that
    is packaged as a Docker image. It has inputs (arguments) and outputs, and it completes
    one stage in the pipeline.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow Pipelines 是 Kubeflow 中最重要的元素之一，使 AI/ML 实验具有可重现性、可组合性、可扩展性，并且易于共享。每个管道组件，表示为一个块，都是一个自包含的代码片段，打包为
    Docker 镜像。它具有输入（参数）和输出，并完成管道中的一个阶段。
- en: Finally, when the pipeline is run, each container will be executed across the
    cluster per Kubernetes scheduling, while dependencies are considered. This containerized
    architecture makes it easy to reuse, share, and swap out components as and when
    the workflow changes, which is common.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，当管道运行时，每个容器将根据 Kubernetes 调度在集群中执行，同时考虑依赖关系。这种容器化架构使得在工作流发生变化时，轻松重用、共享和替换组件，符合常见的需求。
- en: After running the pipeline, the results can be examined in the pipeline’s UI
    on the Kubeflow dashboard. Here, you can debug and tweak parameters and create
    additional “runs.”
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 运行管道后，结果可以在 Kubeflow 仪表板上的管道 UI 中查看。在这里，您可以调试和调整参数，并创建更多的“运行”。
- en: 'To recap, Kubeflow is your ML kit for Kubernetes that offers the following:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，Kubeflow 是为 Kubernetes 提供的 ML 工具包，提供以下功能：
- en: A platform for data scientists who want to build and experiment with ML pipelines
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为希望构建和实验 ML 管道的数据科学家提供的平台
- en: A platform for ML engineers and operational teams who want to deploy ML systems
    to various environments for development, testing, and production-level serving
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为希望将 ML 系统部署到各种环境中进行开发、测试和生产级服务的 ML 工程师和运维团队提供的平台。
- en: Services for spawning and managing Jupyter notebooks for interactive data science
    and experimenting with ML workflows
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于创建和管理 Jupyter notebook 的服务，支持交互式数据科学和 ML 工作流的实验。
- en: A platform for building, deploying, and managing multi-step ML workflows based
    on Docker containers
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个基于 Docker 容器的平台，用于构建、部署和管理多步骤的机器学习工作流。
- en: Several components that can be used to build your ML training, hyperparameter
    tuning, and serving workloads across multiple platforms
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些组件，可用于跨多个平台构建你的 ML 训练、超参数调优和服务工作负载。
- en: In the next section, we’ll go over the steps for deploying Kubeflow.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分中，我们将回顾部署 Kubeflow 的步骤。
- en: Deploying Kubeflow
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署 Kubeflow。
- en: Since MicroK8s version 1.22, Kubeflow is no longer available as an add-on; instead,
    Ubuntu has released Charmed Kubeflow ([https://charmed-kubeflow.io/](https://charmed-kubeflow.io/)),
    which is a complete collection of Kubernetes operators for delivering the 30+
    apps and services that make up the latest version of Kubeflow for easy operations
    anywhere, from desktops to on-premises, public cloud, and the edge.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 从 MicroK8s 版本 1.22 开始，Kubeflow 不再作为附加组件提供；相反，Ubuntu 发布了 Charmed Kubeflow ([https://charmed-kubeflow.io/](https://charmed-kubeflow.io/))，这是一整套
    Kubernetes 操作器，用于提供构成最新版本 Kubeflow 的 30 多个应用和服务，便于在任何地方进行简单操作，从桌面到本地、公共云和边缘设备。
- en: Kubeflow is available as a charm, which is a software package that contains
    a Kubernetes operator as well as information that allows you to integrate many
    operators into a unified system. This technology utilizes the Juju **Operator
    Lifecycle Manager** (**OLM**) to provide Kubeflow operations from day 0 to day
    2.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 作为 charm 提供，这是一个包含 Kubernetes 操作器的软件包，此外还包含允许你将多个操作器集成到统一系统中的信息。这项技术利用了
    Juju **操作生命周期管理器**（**OLM**）来提供从第 0 天到第 2 天的 Kubeflow 操作。
- en: To give an overview of Juju, it is an open source modeling tool for cloud-based
    software operations. It enables you to rapidly and efficiently deploy, set up,
    manage, maintain, and scale cloud applications on public clouds, as well as physical
    servers, OpenStack, and containers. More details can be found at [https://ubuntu.com/blog/what-is-juju-introduction-video](https://ubuntu.com/blog/what-is-juju-introduction-video).
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 为了概述 Juju，它是一个用于云软件操作的开源建模工具。它使你能够快速高效地在公共云、物理服务器、OpenStack 和容器上部署、设置、管理、维护和扩展云应用。更多细节请参阅
    [https://ubuntu.com/blog/what-is-juju-introduction-video](https://ubuntu.com/blog/what-is-juju-introduction-video)。
- en: Juju provides a centralized view of a deployment’s Kubernetes operators, including
    their configuration, scalability, and status, as well as the integration lines
    that connect them. It keeps track of prospective upgrades and updates for each
    operator, as well as coordinates the flow of events and communications between
    them.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Juju 提供了部署的 Kubernetes 操作器的集中视图，包括它们的配置、可扩展性和状态，以及连接它们的集成线。它跟踪每个操作器的潜在升级和更新，并协调它们之间事件和通信的流动。
- en: 'Charmed Kubeflow is available in two bundles:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Charmed Kubeflow 提供两种套件：
- en: '**Full** ([https://charmhub.io/kubeflow](https://charmhub.io/kubeflow)): Each
    Kubeflow service is included. At least 14 GB of RAM and 60 GB of storage space
    is required.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Full** ([https://charmhub.io/kubeflow](https://charmhub.io/kubeflow)): 包含所有
    Kubeflow 服务。需要至少 14 GB 内存和 60 GB 存储空间。'
- en: '**Lite** ([https://charmhub.io/kubeflow-lite](https://charmhub.io/kubeflow-lite)):
    Removes less frequently used services from the complete bundle while maintaining
    a user-friendly dashboard. This bundle is designed for environments with limited
    resources.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Lite** ([https://charmhub.io/kubeflow-lite](https://charmhub.io/kubeflow-lite)):
    移除了完整套件中较少使用的服务，同时保持了用户友好的仪表盘。此套件专为资源有限的环境设计。'
- en: Now that have a better grasp of Charmed Kubeflow, let's go over the deployment
    procedure for Kubeflow.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们对 Charmed Kubeflow 有了更好的了解，让我们来回顾一下 Kubeflow 的部署过程。
- en: What we are trying to achieve
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们想要实现的目标。
- en: 'We wish to do the following in this section:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们希望在这一部分中做以下事情：
- en: Install and configure Microk8s.
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装并配置 Microk8s。
- en: Install Juju Operator Lifecycle Manager.
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Juju 操作生命周期管理器。
- en: Deploy Kubeflow.
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署 Kubeflow。
- en: 'Now that we know what we want to do, let’s look at the prerequisites for setting
    up the Kubeflow platform:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了要做的事情，让我们看看设置 Kubeflow 平台的前提条件：
- en: A virtual machine with Ubuntu 20.04 (focal) or later
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台运行 Ubuntu 20.04（focal）或更高版本的虚拟机。
- en: At least 16 GB of free memory and 20 GB of disk space
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 至少需要 16 GB 的空闲内存和 20 GB 的磁盘空间
- en: Access to the internet for downloading the snaps and charms required
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问互联网以下载所需的 snaps 和 charms
- en: Now that we’ve established the prerequisites, let’s learn how to set up the
    Kubeflow platform.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经确定了前提条件，让我们学习如何设置 Kubeflow 平台。
- en: Step 1 – Installing and configuring MicroK8s
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 1 步 – 安装和配置 MicroK8s
- en: The following steps are similar to the ones we followed in [*Chapter 5*](B18115_05.xhtml#_idTextAnchor070)*,*
    *Creating and Implementing Updates on Multi-Node Raspberry Pi Kubernetes Clusters*
    for creating a MicroK8s cluster.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤与我们在[*第 5 章*](B18115_05.xhtml#_idTextAnchor070)中跟随的步骤类似，*创建并实施多节点 Raspberry
    Pi Kubernetes 集群的更新*，用于创建 MicroK8s 集群。
- en: We’ll set the snap to install the 1.21 release of Kubernetes since Kubeflow
    doesn’t support the newer 1.22 version yet.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将设置 snap 来安装 Kubernetes 的 1.21 版本，因为 Kubeflow 目前不支持更新的 1.22 版本。
- en: 'Use the following command to install MicroK8s:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令安装 MicroK8s：
- en: '[PRE0]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following output indicates MicroK8s has been installed successfully:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出表明 MicroK8s 已成功安装：
- en: '![Figure 9.6 – MicroK8s installation ](img/Figure_9.06_B18115.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.6 – MicroK8s 安装](img/Figure_9.06_B18115.jpg)'
- en: Figure 9.6 – MicroK8s installation
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.6 – MicroK8s 安装
- en: 'As we saw previously, MicroK8s creates a group called `microk8s` so that it
    can work without having to use `sudo` for every command. We will be adding the
    current user to this group to make it easier to run commands:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前看到的，MicroK8s 创建了一个名为 `microk8s` 的组，这样就可以在不使用 `sudo` 执行每个命令的情况下工作。我们将把当前用户添加到该组，以便更轻松地运行命令：
- en: '[PRE1]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Make sure there is proper access to kubectl configuration files as well:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 确保能够正确访问 kubectl 配置文件：
- en: '[PRE2]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As soon as MicroK8s is installed, it will start up. The Kubernetes cluster
    is now fully operational, as shown in the following screenshot:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 MicroK8s 安装完成，它将开始启动。Kubernetes 集群现在完全运行，如下图所示：
- en: '![Figure 9.7 – MicroK8s is fully operational ](img/Figure_9.07_B18115.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.7 – MicroK8s 完全运行中](img/Figure_9.07_B18115.jpg)'
- en: Figure 9.7 – MicroK8s is fully operational
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.7 – MicroK8s 完全运行中
- en: 'Before installing Kubeflow, let’s enable some add-ons. We’ll set up a DNS service
    so that the applications can discover one other, as well as storage, an ingress
    controller for accessing Kubeflow components, and the MetalLB load balancer application.
    All of these can be enabled at the same time using the following command:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 在安装 Kubeflow 之前，让我们先启用一些插件。我们将设置 DNS 服务，以便应用程序能够发现彼此，还包括存储、用于访问 Kubeflow 组件的入口控制器，以及
    MetalLB 负载均衡器应用程序。所有这些都可以通过以下命令同时启用：
- en: '[PRE3]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: With this command, we’ve instructed MetalLB to give out addresses in the `10.64.140.43
    - 10.64.140.49` range.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 通过此命令，我们已经指示 MetalLB 在 `10.64.140.43 - 10.64.140.49` 范围内分配地址。
- en: 'The following output shows that add-ons are being enabled:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示插件正在启用：
- en: '![Figure 9.8 – Add-ons enabled successfully ](img/Figure_9.08_B18115.jpg)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.8 – 插件成功启用](img/Figure_9.08_B18115.jpg)'
- en: Figure 9.8 – Add-ons enabled successfully
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.8 – 插件成功启用
- en: 'MicroK8s may take a few minutes to install and configure these extra features.
    Before we go any further, we should double-check that the add-ons have been correctly
    activated and that MicroK8s is ready to use. From the following output, we can
    infer that all the required add-ons are enabled:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: MicroK8s 可能需要几分钟时间来安装和配置这些额外的功能。在继续之前，我们应该再次检查插件是否已正确启用，以及 MicroK8s 是否已准备好使用。从以下输出可以推断，所有必需的插件都已启用：
- en: '![Figure 9.9 – Add-ons enabled successfully ](img/Figure_9.09_B18115.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.9 – 插件成功启用](img/Figure_9.09_B18115.jpg)'
- en: Figure 9.9 – Add-ons enabled successfully
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.9 – 插件成功启用
- en: We can achieve this by using the `microk8s status` command and specifying the
    `--wait-ready` option, which instructs MicroK8s to complete whatever processes
    it is currently working on before returning.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `microk8s status` 命令并指定 `--wait-ready` 选项来实现这一点，该选项指示 MicroK8s 在返回之前完成其当前正在进行的所有进程。
- en: Now that we have a running Kubernetes cluster, let’s install Juju.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经有了一个正在运行的 Kubernetes 集群，让我们来安装 Juju。
- en: Step 2 – Installing Juju Operator Lifecycle Manager
  id: totrans-144
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 2 步 – 安装 Juju 操作生命周期管理器
- en: As we discussed previously, Juju is an OLM for the cloud, bare metal, or Kubernetes.
    It can be used to deploy and manage the various components that make up Kubeflow.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前讨论的，Juju 是云端、裸机或 Kubernetes 的 OLM。它可以用于部署和管理构成 Kubeflow 的各种组件。
- en: 'Like MicroK8s, Juju can be installed from a snap package using the following
    command:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 与 MicroK8s 类似，Juju 也可以通过以下命令从 snap 包安装：
- en: '[PRE4]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following output shows that the Juju snap has been installed successfully:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示 Juju snap 已成功安装：
- en: '![Figure 9.10 – Juju installed ](img/Figure_9.10_B18115.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.10 – 已安装 Juju](img/Figure_9.10_B18115.jpg)'
- en: Figure 9.10 – Juju installed
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.10 – 已安装 Juju
- en: 'No further setup or configuration is required since the Juju OLM recognizes
    MicroK8s. To deploy a Juju controller to the Kubernetes session we put up with
    MicroK8s, all we must do is run the following command:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Juju OLM 可识别 MicroK8s，因此无需进一步设置或配置。要在我们使用 MicroK8s 架设的 Kubernetes 会话中部署 Juju
    控制器，我们只需运行以下命令：
- en: '[PRE5]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Note
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In the latest versions, you can just use `latest` instead of specifying the
    agent version.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在最新版本中，您可以只使用`latest`而不是指定代理版本。
- en: 'The following output shows that the Juju OLM bootstrap configuration has been
    successful:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示 Juju OLM 引导配置已成功：
- en: '![Figure 9.11 – Juju OLM bootstrap ](img/Figure_9.11_B18115.jpg)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.11 – 已引导 Juju OLM](img/Figure_9.11_B18115.jpg)'
- en: Figure 9.11 – Juju OLM bootstrap
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.11 – 已引导 Juju OLM
- en: 'The controller is Juju’s Kubernetes-based agent, which may be used to deploy
    and control Kubeflow components. The controller can work with a variety of models,
    which correspond to Kubernetes namespaces. Setting up a new model for Kubeflow
    is the recommended option:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器是 Juju 的基于 Kubernetes 的代理，可用于部署和控制 Kubeflow 组件。控制器可以与多种模型配合工作，这些模型对应 Kubernetes
    命名空间。建议为 Kubeflow 设置新模型：
- en: '[PRE6]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Note
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: At the time of writing, the model must be named `kubeflow`, but this is planned
    to be addressed in future versions.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，模型必须命名为`kubeflow`，但计划在未来版本中解决此问题。
- en: 'The following output shows that the `kubeflow` model was added successfully:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示`kubeflow`模型已成功添加：
- en: '![Figure 9.12 – Juju model addition ](img/Figure_9.12_B18115.jpg)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.12 – Juju 模型添加](img/Figure_9.12_B18115.jpg)'
- en: Figure 9.12 – Juju model addition
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.12 – Juju 模型添加
- en: Now that the Kubeflow model has been added, our next step is to deploy the Charmed
    Kubeflow bundle. Charmed Kubeflow is essentially a charm collection. Each charm
    deploys and controls a single application that makes up Kubeflow. You can just
    install the components that are required by deploying the charms individually
    and linking them together to create Kubeflow. However, three bundles are offered
    for your convenience. These bundles are essentially a recipe for a certain Kubeflow
    deployment, setting and connecting the applications in such a way that you end
    up with a working deployment with the least amount of effort.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 Kubeflow 模型已添加，我们的下一步是部署 Charmed Kubeflow bundle。Charmed Kubeflow 本质上是一个魅力收藏。每个魅力部署和控制一个单独的应用程序，这些应用程序组成
    Kubeflow。您可以通过逐个部署魅力并将它们连接在一起来创建 Kubeflow，仅安装所需的组件。但是，为方便起见，提供了三个捆绑包。这些捆绑包本质上是某种
    Kubeflow 部署的配方，以这种方式设置和连接应用程序，最终您将获得一个可工作的部署，而付出的努力最少。
- en: 'The full Kubeflow bundle will necessitate a lot of resources (at least 4 CPUs,
    14 GB of free RAM, and 60 GB of disk space), so starting with the `kubeflow-lite`
    bundle is the best alternative:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的 Kubeflow bundle 将需要大量资源（至少 4 个 CPU、14 GB 的空闲 RAM 和 60 GB 的磁盘空间），因此从`kubeflow-lite`
    bundle 开始是最佳选择：
- en: '[PRE7]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following output shows that Juju will start acquiring the apps and start
    deploying them to the MicroK8s Kubernetes cluster. This procedure can take quite
    some time but can vary based on your hardware configuration:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出显示 Juju 将开始获取应用程序并将它们部署到 MicroK8s Kubernetes 群集。这个过程可能需要相当长的时间，但根据您的硬件配置可能有所不同：
- en: '![Figure 9.13 – Juju deployment ](img/Figure_9.13_B18115.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.13 – Juju 部署](img/Figure_9.13_B18115.jpg)'
- en: Figure 9.13 – Juju deployment
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.13 – Juju 部署
- en: 'By running the `juju status` command, you can keep track of the deployment’s
    progress:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行`juju status`命令，您可以跟踪部署的进度：
- en: '![Figure 9.14 – Juju deployment successful ](img/Figure_9.14_B18115.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.14 – Juju 部署成功](img/Figure_9.14_B18115.jpg)'
- en: Figure 9.14 – Juju deployment successful
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.14 – Juju 部署成功
- en: There could be error messages since many of the components rely on the operation
    of others, so it may take some time before everything is up and running.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 由于许多组件依赖于其他操作的运行，可能会出现错误消息，因此在一切正常运行之前可能需要一些时间。
- en: Now the bundle has been deployed, let’s complete some of the post-installation
    configurations.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在捆绑已部署，让我们完成一些安装后的配置。
- en: Step 3 – Post-installation configurations
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3 – 安装后配置
- en: 'Some configuration needs to be set with the URL so that we have authentication
    and access to the dashboard service. This is dependent on the underlying network
    provider, but for this local deployment, we know what the URL will be for running
    on a local MicroK8s. The following commands can be used to configure it in Juju:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 需要设置一些配置项，包含 URL，这样我们就可以进行身份验证并访问仪表盘服务。具体配置依赖于底层网络提供者，但对于这个本地部署，我们知道在本地 MicroK8s
    上运行时的 URL。可以使用以下命令在 Juju 中配置：
- en: '[PRE8]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following output confirms that `dex-auth public-url` and `oidc-gatekeeper
    public-url` have been set successfully:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出确认 `dex-auth public-url` 和 `oidc-gatekeeper public-url` 已成功设置：
- en: '![Figure 9.15 – Setting public-url for the dashboard service ](img/Figure_9.15_B18115.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.15 – 设置仪表盘服务的 public-url ](img/Figure_9.15_B18115.jpg)'
- en: Figure 9.15 – Setting public-url for the dashboard service
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.15 – 设置仪表盘服务的 public-url
- en: 'Run the following commands to enable basic authentication and create a username
    and password for the Kubeflow deployment:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令以启用基本身份验证，并为 Kubeflow 部署创建用户名和密码：
- en: '[PRE9]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following output confirms that the username and password of the Kubeflow
    deployment have been set successfully:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出确认 Kubeflow 部署的用户名和密码已成功设置：
- en: '![Figure 9.16 – Setting the username and password for the Kubeflow deployment
    ](img/Figure_9.16_B18115.jpg)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.16 – 设置 Kubeflow 部署的用户名和密码 ](img/Figure_9.16_B18115.jpg)'
- en: Figure 9.16 – Setting the username and password for the Kubeflow deployment
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.16 – 设置 Kubeflow 部署的用户名和密码
- en: With that, we have installed and configured MicroK8s. We have also deployed
    the Juju Charmed Operator Framework to manage apps and automate operations and
    also integrated all the required Kubeflow components. Finally, we configured the
    Kubeflow dashboard service’s authentication. Now, let’s learn how to access the
    Kubeflow dashboard.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们已经安装并配置了 MicroK8s。我们还部署了 Juju Charmed Operator 框架来管理应用程序和自动化操作，并集成了所有所需的
    Kubeflow 组件。最后，我们配置了 Kubeflow 仪表盘服务的身份验证。现在，让我们来学习如何访问 Kubeflow 仪表盘。
- en: Accessing the Kubeflow dashboard
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 访问 Kubeflow 仪表盘
- en: The Kubeflow dashboard gives you easy access to all the Kubeflow components
    installed on the cluster. Point your browser to `http://10.64.140.43.nip.io` (the
    URL that we set earlier) to be taken to the login screen, where we can input `admin`
    as the username and `admin` as the password (we set these components up previously).
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 仪表盘让你可以轻松访问集群中安装的所有 Kubeflow 组件。将浏览器指向 `http://10.64.140.43.nip.io`（我们之前设置的
    URL），你将进入登录界面，在那里我们可以输入用户名 `admin` 和密码 `admin`（这些组件之前我们已经设置过）。
- en: 'The **Welcome** page should appear. Clicking **Start Setup** will lead you
    to the **Create namespace** screen. When you enter the namespace and click the
    **Finish** button, the dashboard will appear, as shown in the following screenshot:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '**欢迎** 页面应该会出现。点击 **开始设置** 将引导你进入 **创建命名空间** 页面。当你输入命名空间并点击 **完成** 按钮时，仪表盘将会出现，如下截图所示：'
- en: '![Figure 9.17 – Kubeflow dashboard ](img/Figure_9.17_B18115.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.17 – Kubeflow 仪表盘 ](img/Figure_9.17_B18115.jpg)'
- en: Figure 9.17 – Kubeflow dashboard
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.17 – Kubeflow 仪表盘
- en: Great! We have just installed Kubeflow.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 很棒！我们刚刚安装了 Kubeflow。
- en: Now that Kubeflow has been installed and is operational, let’s learn how to
    translate an ML model into a Kubeflow pipeline.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 既然 Kubeflow 已经安装并且可以运行，让我们来学习如何将 ML 模型转化为 Kubeflow 管道。
- en: Creating a Kubeflow pipeline to build, train, and deploy a sample ML model
  id: totrans-195
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建一个 Kubeflow 管道来构建、训练和部署一个示例 ML 模型
- en: In this section, we will be using the Fashion MNIST dataset and TensorFlow’s
    Basic classification to build the pipeline step by step and turn the example ML
    model into a Kubeflow pipeline.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 Fashion MNIST 数据集和 TensorFlow 的基础分类方法，逐步构建管道，并将示例 ML 模型转化为 Kubeflow
    管道。
- en: Before deploying Kubeflow, we will look at the dataset that we are going to
    use. Fashion-MNIST ([https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist))
    is a Zalando article image dataset that includes a training set of 60,000 samples
    and a test set of 10,000 examples. Each sample is a 28 x 28 grayscale image with
    a label from one of 10 categories.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署 Kubeflow 之前，我们先来看一下我们将要使用的数据集。Fashion-MNIST ([https://github.com/zalandoresearch/fashion-mnist](https://github.com/zalandoresearch/fashion-mnist))
    是一个 Zalando 文章图像数据集，包含 60,000 个训练样本和 10,000 个测试样本。每个样本都是一个 28 x 28 的灰度图像，标签来自
    10 个类别之一。
- en: 'Each training or test item in the dataset is assigned to one of the following
    labels:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中的每个训练或测试项都被分配到以下标签之一：
- en: '![Table 9.1 – Categories in the Fashion MNIST dataset ](img/B18115_Table_9.1a.jpg)![Table
    9.1 – Categories in the Fashion MNIST dataset ](img/B18115_Table_9.1b.jpg)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![表 9.1 – Fashion MNIST 数据集中的类别](img/B18115_Table_9.1a.jpg)![表 9.1 – Fashion
    MNIST 数据集中的类别](img/B18115_Table_9.1b.jpg)'
- en: Table 9.1 – Categories in the Fashion MNIST dataset
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9.1 – Fashion MNIST 数据集中的类别
- en: Now that our dataset is ready, we can launch a new notebook server via the Kubeflow
    dashboard.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的数据集已准备好，可以通过 Kubeflow 仪表板启动一个新的笔记本服务器。
- en: Step 1 – launching a new notebook server from the Kubeflow dashboard
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1 – 从 Kubeflow 仪表板启动新的笔记本服务器
- en: You can start a new notebook by clicking **New Server** on the **Notebook Servers**
    tab. Select a Docker **Image** for the notebook server and give it a **Name**.
    Choose the appropriate **CPU**, **RAM**, and **Workspace volume** values and click
    **Launch**.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过点击**新建服务器**按钮来启动一个新的笔记本。在**笔记本服务器**标签页中，选择一个 Docker **镜像**用于笔记本服务器，并为其命名**名称**。选择适当的**CPU**、**RAM**
    和 **工作空间卷**值，然后点击**启动**。
- en: 'To browse the web interface that’s been exposed by your server, click **CONNECT**:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 要浏览由服务器公开的 Web 界面，请点击**连接**：
- en: '![Figure 9.18 – Launch new notebook server ](img/Figure_9.18_B18115.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.18 – 启动新的笔记本服务器](img/Figure_9.18_B18115.jpg)'
- en: Figure 9.18 – Launch new notebook server
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.18 – 启动新的笔记本服务器
- en: 'Ensure that **Allow access to Kubeflow Pipelines** is enabled on the new notebook
    so that we can use the Kubeflow Pipelines SDK in the next step:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 确保新笔记本上启用了**允许访问 Kubeflow Pipelines**，这样我们才能在下一步中使用 Kubeflow Pipelines SDK：
- en: '![Figure 9.19 – New notebook configurations ](img/Figure_9.19_B18115.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.19 – 新的笔记本配置](img/Figure_9.19_B18115.jpg)'
- en: Figure 9.19 – New notebook configurations
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.19 – 新的笔记本配置
- en: 'Launch a new terminal from the right-hand menu (`git` command:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 从右侧菜单启动一个新的终端（`git`命令）：
- en: '[PRE10]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This will clone and open the `KF_Fashion_MNIST` notebook, as shown in the following
    screenshot:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 这将克隆并打开`KF_Fashion_MNIST`笔记本，如下图所示：
- en: '![Figure 9.20 – Fashion MNIST notebook ](img/Figure_9.20_B18115.jpg)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.20 – Fashion MNIST 笔记本](img/Figure_9.20_B18115.jpg)'
- en: Figure 9.20 – Fashion MNIST notebook
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.20 – Fashion MNIST 笔记本
- en: 'In **Section 1** of the notebook, we can familiarize ourselves with the dataset
    that we have; we’ll perform a quick analysis by exploring the data. Here’s a quick
    refresher on the dataset:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在笔记本的**第 1 节**中，我们可以熟悉我们拥有的数据集；我们将通过探索数据进行快速分析。以下是对数据集的简要回顾：
- en: There are 60,000 training labels and 10,000 test labels
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练标签有 60,000 个，测试标签有 10,000 个
- en: Each label corresponds to one of the 10 class names and is a number between
    0 and 9
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个标签对应 10 个类别名称中的一个，是一个介于 0 和 9 之间的数字
- en: Before starting any form of analysis, it’s always a good idea to comprehend
    the data. In `section 1.4` of the notebook, we will preprocess the data – that
    is, the data must be normalized so that each value falls between 0 and 1 to successfully
    train the model.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始任何形式的分析之前，理解数据总是一个好主意。在笔记本的`1.4节`中，我们将对数据进行预处理——即，数据必须进行归一化，使每个值都在 0 和 1
    之间，以便成功训练模型。
- en: 'The following screenshot shows that the values are between 0 and 255:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了值在 0 和 255 之间：
- en: '![Figure 9.21 – The first image from the dataset ](img/Figure_9.21_B18115.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.21 – 数据集中的第一张图片](img/Figure_9.21_B18115.jpg)'
- en: Figure 9.21 – The first image from the dataset
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.21 – 数据集中的第一张图片
- en: 'In the next step, we must divide the training and test values by `255` to scale
    the data. It’s critical that the training and testing sets are both preprocessed
    the same way:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一步，我们必须将训练集和测试集的值除以`255`来缩放数据。关键的是，训练集和测试集必须以相同的方式进行预处理：
- en: '![Figure 9.22 – Dividing the training and test values by 255 ](img/Figure_9.22_B18115.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.22 – 将训练集和测试集的值除以 255](img/Figure_9.22_B18115.jpg)'
- en: Figure 9.22 – Dividing the training and test values by 255
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.22 – 将训练集和测试集的值除以 255
- en: 'The following is the execution output from the Jupyter notebook for the preceding
    code:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Jupyter 笔记本执行前述代码的输出：
- en: '![Figure 9.23 – Preprocessing the data ](img/Figure_9.23_B18115.jpg)'
  id: totrans-226
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.23 – 数据预处理](img/Figure_9.23_B18115.jpg)'
- en: Figure 9.23 – Preprocessing the data
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.23 – 数据预处理
- en: 'Let’s inspect the first 25 images from the training set, together with the
    class name, to make sure the data is in the right format. Then, we will be ready
    to build and train the network:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查训练集中的前 25 张图片及其类别名称，确保数据格式正确。然后，我们就可以开始构建和训练网络了：
- en: '![Figure 9.24 – Plot for the first 25 images from the training set ](img/Figure_9.24_B18115.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.24 – 训练集前 25 张图片的图表](img/Figure_9.24_B18115.jpg)'
- en: Figure 9.24 – Plot for the first 25 images from the training set
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.24 – 训练集前 25 张图片的图示
- en: 'The following is the output from the Jupyter notebook for the preceding code:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前面代码的 Jupyter notebook 输出：
- en: '![Figure 9.25 – Inspecting 25 images from the training set ](img/Figure_9.25_B18115.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.25 – 检查训练集中的 25 张图片](img/Figure_9.25_B18115.jpg)'
- en: Figure 9.25 – Inspecting 25 images from the training set
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.25 – 检查训练集中的 25 张图片
- en: Now that the data has been preprocessed, we can build the model.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 现在数据已经预处理完毕，我们可以构建模型。
- en: The TensorFlow model we’re working on is an example of basic classification([https://www.tensorflow.org/tutorials/keras/classification](https://www.tensorflow.org/tutorials/keras/classification)).
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在处理的 TensorFlow 模型是一个基本分类示例([https://www.tensorflow.org/tutorials/keras/classification](https://www.tensorflow.org/tutorials/keras/classification))。
- en: Step 2 – creating a Kubeflow pipeline
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 2 – 创建一个 Kubeflow 管道
- en: We will be using the Kubeflow Pipelines SDK, which is a set of Python packages
    for specifying and running ML workflows. A pipeline is a description of an ML
    workflow that includes all the components that make up the steps in the workflow,
    as well as how they interact.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Kubeflow Pipelines SDK，它是一组用于指定和运行机器学习工作流的 Python 包。一个管道是机器学习工作流的描述，包含了工作流中各个步骤的所有组件，以及它们如何相互作用。
- en: 'Install the Kubeflow Pipelines SDK (`kfp`) in the current userspace to ensure
    that you have access to the necessary packages in your Jupyter notebook instance:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前用户空间中安装 Kubeflow Pipelines SDK（`kfp`），以确保您可以在 Jupyter notebook 实例中访问所需的包：
- en: '![Figure 9.26 – Installing the Kubeflow Pipelines SDK ](img/Figure_9.26_B18115.jpg)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.26 – 安装 Kubeflow Pipelines SDK](img/Figure_9.26_B18115.jpg)'
- en: Figure 9.26 – Installing the Kubeflow Pipelines SDK
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.26 – 安装 Kubeflow Pipelines SDK
- en: Now that we have installed the Kubeflow Pipelines SDK, the next step is to create
    Python scripts for Docker containers using `func_to_container_op`.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经安装了 Kubeflow Pipelines SDK，下一步是使用`func_to_container_op`为 Docker 容器创建 Python
    脚本。
- en: 'To package our Python code inside containers, we must create a standard Python
    function that contains a logical step in your pipeline. In this case, two functions
    have been defined: `train` and `predict.` Our model will be trained, evaluated,
    and saved by the train component (refer to `Section 2.2` in the notebook):'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将我们的 Python 代码打包到容器中，我们必须创建一个包含管道中逻辑步骤的标准 Python 函数。在这个例子中，已经定义了两个函数：`train`
    和 `predict`。我们的模型将通过训练组件进行训练、评估并保存（参考笔记本中的`第 2.2 节`）：
- en: '![Figure 9.27 – Model trained and saved ](img/Figure_9.27_B18115.jpg)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.27 – 训练并保存的模型](img/Figure_9.27_B18115.jpg)'
- en: Figure 9.27 – Model trained and saved
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.27 – 训练并保存的模型
- en: 'The layers of the neural network must be configured before the model can be
    compiled. The layers are the most fundamental components of a neural network.
    Data is put into layers, and then representations are extracted from it:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的层必须在模型编译之前进行配置。层是神经网络中最基本的组成部分。数据被输入到层中，然后从中提取表示：
- en: '![Figure 9.28 – Neural network layers to be configured ](img/Figure_9.28_B18115.jpg)'
  id: totrans-246
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.28 – 需要配置的神经网络层](img/Figure_9.28_B18115.jpg)'
- en: Figure 9.28 – Neural network layers to be configured
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.28 – 需要配置的神经网络层
- en: 'The predict component takes the model and applies it to an image from the test
    dataset to create a prediction:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 预测组件将模型应用于测试数据集中的一张图片，从而生成预测结果：
- en: '![Figure 9.29 – Predicting from the test dataset ](img/Figure_9.29_B18115.jpg)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.29 – 从测试数据集中进行预测](img/Figure_9.29_B18115.jpg)'
- en: Figure 9.29 – Predicting from the test dataset
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.29 – 从测试数据集中进行预测
- en: 'Our final step is to convert these functions into container components. The
    `func_to_container_op` method can be used to accomplish this:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的最终步骤是将这些函数转换为容器组件。可以使用`func_to_container_op`方法来实现这一点：
- en: '![Figure 9.30 – Converting Python scripts into Docker containers ](img/Figure_9.30_B18115.jpg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.30 – 将 Python 脚本转换为 Docker 容器](img/Figure_9.30_B18115.jpg)'
- en: Figure 9.30 – Converting Python scripts into Docker containers
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.30 – 将 Python 脚本转换为 Docker 容器
- en: After converting Python scripts into Docker containers, the next step is to
    define a Kubeflow pipeline.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在将 Python 脚本转换为 Docker 容器之后，下一步是定义一个 Kubeflow 管道。
- en: Kubeflow makes use of YAML templates to define Kubernetes resources. Without
    having to manually alter YAML files, the Kubeflow Pipelines SDK allows you to
    describe how our code is run. It generates a compressed YAML file that defines
    our pipeline at compile time. This file can then be reused or shared in the future,
    making the workflow scalable and repeatable.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Kubeflow 使用 YAML 模板来定义 Kubernetes 资源。通过 Kubeflow Pipelines SDK，无需手动修改 YAML 文件，您可以描述代码如何执行。它在编译时生成一个压缩的
    YAML 文件，定义我们的管道。这个文件可以在未来重用或共享，使工作流具有可扩展性和可重复性。
- en: 'Our first step is to launch a Kubeflow client, which includes client libraries
    for the Kubeflow Pipelines API, allowing us to construct more experiments and
    run within those experiments directly from the Jupyter notebook:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一步是启动一个 Kubeflow 客户端，它包含 Kubeflow Pipelines API 的客户端库，允许我们直接在 Jupyter notebook
    中构建更多实验并运行这些实验：
- en: '![Figure 9.31 – Launching the Kubeflow client ](img/Figure_9.31_B18115.jpg)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.31 – 启动 Kubeflow 客户端](img/Figure_9.31_B18115.jpg)'
- en: Figure 9.31 – Launching the Kubeflow client
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.31 – 启动 Kubeflow 客户端
- en: The preceding components build a client to communicate with the pipeline's API
    server. The next step will be to design the pipeline’s various components.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的组件构建了一个客户端来与管道的 API 服务器进行通信。下一步将是设计管道的各个组件。
- en: 'The pipeline function has been defined, and it contains several parameters
    that will be passed to our various components during execution. Kubeflow Pipelines
    are built declaratively. This means that the code will not be executed until the
    pipeline has been compiled:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 管道函数已经定义，并且包含一些在执行期间将传递给不同组件的参数。Kubeflow Pipelines 是声明式构建的。这意味着代码在管道编译之前不会执行：
- en: '![Figure 9.32 – Defining the pipeline ](img/Figure_9.32_B18115.jpg)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.32 – 定义管道](img/Figure_9.32_B18115.jpg)'
- en: Figure 9.32 – Defining the pipeline
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.32 – 定义管道
- en: To save and persist data between components, a Persistent Volume Claim can be
    quickly created using the `VolumeOp` method.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在组件之间保存和持久化数据，可以使用`VolumeOp`方法快速创建持久化卷声明。
- en: '`VolumeOp`’s parameters include the following:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '`VolumeOp`的参数包括以下内容：'
- en: '`name`: The name that’s displayed for the volume creation operation'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：在创建卷操作时显示的名称'
- en: '`resource_name`: The name that can be referenced by other resources'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`resource_name`：可以被其他资源引用的名称'
- en: '`size`: The size of the volume claim'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`size`：卷声明的大小'
- en: '`modes`: The access mode for the volume'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`modes`：卷的访问模式'
- en: 'It’s finally time to define our pipeline’s components and dependencies. This
    can be accomplished using `ContainerOp`, an object that defines a pipeline component
    from a container:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在终于是定义我们管道的组件和依赖关系的时候了。可以使用`ContainerOp`来完成这一任务，`ContainerOp`是一个从容器中定义管道组件的对象：
- en: '![Figure 9.33 – Creating the training and prediction components ](img/Figure_9.33_B18115.jpg)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.33 – 创建训练和预测组件](img/Figure_9.33_B18115.jpg)'
- en: Figure 9.33 – Creating the training and prediction components
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.33 – 创建训练和预测组件
- en: The `train_op` and `predict_op` components accept arguments from the original
    Python function. We attach our `VolumeOp` at the end of the function with a dictionary
    of paths and associated Persistent Volumes to be mounted to the container before
    execution.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '`train_op`和`predict_op`组件接受来自原始 Python 函数的参数。我们在函数末尾附加`VolumeOp`，并提供一个包含路径和与之关联的持久化卷的字典，这些卷将在执行前挂载到容器中。'
- en: 'While `train_op` is using the `pvolumes` dictionary’s `vop.volume` value, `<Container
    Op>`, the `pvolume` argument, which is used by the other components, ensures that
    the volume from the previous `ContainerOp` is used instead of creating a new one:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 当`train_op`使用`pvolumes`字典中的`vop.volume`值时，`<Container Op>`中的`pvolume`参数确保使用来自前一个`ContainerOp`的卷，而不是创建一个新的卷：
- en: '![Figure 9.34 – Attaching a volume to the container ](img/Figure_9.34_B18115.jpg)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.34 – 将卷附加到容器](img/Figure_9.34_B18115.jpg)'
- en: Figure 9.34 – Attaching a volume to the container
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.34 – 将卷附加到容器
- en: 'ContainerOp’s parameters include the following:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '`ContainerOp`的参数包括以下内容：'
- en: '`name`: The name displayed for the component’s execution during runtime'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`：在运行时显示的组件执行名称'
- en: '`image`: The image tag for the Docker container to be used'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image`：用于 Docker 容器的镜像标签'
- en: '`pvolumes`: A dictionary of paths and associated *Persistent Volumes* to be
    mounted to the container before execution'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pvolumes`：一个字典，包含路径和与之关联的*持久化卷*，将在执行前挂载到容器中'
- en: '`arguments`: The command to be run by the container at runtime'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`arguments`：容器在运行时执行的命令'
- en: Now that we’ve created separate components for training and prediction, we can
    start compiling and running the pipeline code in the notebook.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为训练和预测创建了独立的组件，我们可以开始在笔记本中编译和运行管道代码。
- en: Step 3 – compiling and running
  id: totrans-282
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 3 – 编译和运行
- en: 'Finally, it’s time to compile and run the pipeline code in the notebook. The
    notebook specifies the name of the run and the experiment (a group of runs), which
    is then displayed in the Kubeflow dashboard. By clicking on the notebook’s run
    link , you can see the pipeline running in the Kubeflow Pipelines UI:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，是时候在笔记本中编译和运行管道代码了。笔记本指定了运行名称和实验（多个运行的集合），然后在 Kubeflow 仪表板中显示。通过点击笔记本中的运行链接，你可以看到管道在
    Kubeflow Pipelines UI 中运行：
- en: '![Figure 9.35 – Compiling and running the pipeline ](img/Figure_9.35_B18115.jpg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.35 – 编译和运行管道](img/Figure_9.35_B18115.jpg)'
- en: Figure 9.35 – Compiling and running the pipeline
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.35 – 编译和运行管道
- en: 'Now that the pipeline has been created and set to run, we can look at its results.
    By clicking on the notebook’s run link, we can get to the Kubeflow Pipelines dashboard.
    The pipeline’s defined components will be displayed. The path of the data pipeline
    will be updated as they complete:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 现在管道已经创建并设置为运行，我们可以查看其结果。通过点击笔记本中的运行链接，我们可以进入 Kubeflow Pipelines 仪表板。管道定义的组件将显示出来。随着它们的完成，数据管道的路径会被更新：
- en: '![Figure 9.36 – Kubeflow Pipelines dashboard ](img/Figure_9.36_B18115.jpg)'
  id: totrans-287
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.36 – Kubeflow Pipelines 仪表板](img/Figure_9.36_B18115.jpg)'
- en: Figure 9.36 – Kubeflow Pipelines dashboard
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.36 – Kubeflow Pipelines 仪表板
- en: 'To view the details of a component, we can click on it directly and navigate
    through a few tabs. To view the logs that were generated while running the component,
    go to the **Logs** tab:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看组件的详细信息，我们可以直接点击它，并通过几个标签进行导航。要查看在运行组件时生成的日志，请前往**日志**标签：
- en: '![Figure 9.37 – Model training logs ](img/Figure_9.37_B18115.jpg)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.37 – 模型训练日志](img/Figure_9.37_B18115.jpg)'
- en: Figure 9.37 – Model training logs
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.37 – 模型训练日志
- en: The loss and accuracy metrics are displayed as the model trains. On the training
    data, the model achieves an accuracy of about 0.91 (or 91%), as shown in *Figure
    9.37*.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 随着模型训练的进行，损失和准确率指标会被显示。在训练数据上，模型的准确率约为 0.91（即 91%），如*图 9.37*所示。
- en: 'Once the `echo_result` component has finished executing, you can inspect the
    component’s logs to see what happened. It will show the class of the image being
    predicted, the model’s confidence in its prediction, and the image’s actual label:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦`echo_result`组件执行完毕，你可以检查该组件的日志，查看发生了什么。它将显示预测的图像类别、模型对预测的信心以及图像的实际标签：
- en: '![Figure 9.38 – Final prediction result from the pipeline ](img/Figure_9.38_B18115.jpg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.38 – 来自管道的最终预测结果](img/Figure_9.38_B18115.jpg)'
- en: Figure 9.38 – Final prediction result from the pipeline
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.38 – 来自管道的最终预测结果
- en: With that, we have made use of the Fashion MNIST dataset and TensorFlow’s Basic
    classification to turn the example model into a Kubeflow pipeline.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些，我们使用了 Fashion MNIST 数据集和 TensorFlow 的基础分类将示例模型转化为一个 Kubeflow 管道。
- en: Now, let’s look at the best practices for running AI/ML workloads on Kubernetes.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下在 Kubernetes 上运行 AI/ML 工作负载的最佳实践。
- en: Recommendations – running AL/ML workloads on Kubernetes
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 建议 – 在 Kubernetes 上运行 AL/ML 工作负载
- en: If you’re a data scientist or ML engineer, you’re probably thinking about how
    to deploy your ML models efficiently. You would essentially look for ways to scale
    models, distribute them across server clusters, and optimize model performance
    with a variety of techniques.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是数据科学家或 ML 工程师，你可能在思考如何高效地部署你的 ML 模型。你本质上会寻找方法来扩展模型，将其分布到服务器集群中，并利用各种技术优化模型性能。
- en: These are all tasks that Kubernetes is very good at. But Kubernetes was not
    designed to be an ML deployment platform. However, as more data scientists turn
    to Kubernetes to run their models, Kubernetes and ML are becoming popular stacks.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 这些都是 Kubernetes 非常擅长的任务。但 Kubernetes 并不是为了成为一个 ML 部署平台而设计的。然而，随着越来越多的数据科学家转向
    Kubernetes 来运行他们的模型，Kubernetes 和 ML 正成为流行的技术栈。
- en: 'As a platform for training and deploying ML models, Kubernetes provides several
    key advantages. To understand those benefits, let’s compare some of the major
    challenges and Kubernetes solution offerings:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个训练和部署 ML 模型的平台，Kubernetes 提供了几个关键的优势。为了理解这些好处，让我们比较一下 Kubernetes 解决方案提供的主要挑战和解决方案：
- en: '![Table 9.2 – Kubernetes solution offerings ](img/B18115_Table_9.2a.jpg)![Table
    9.2 – Kubernetes solution offerings ](img/B18115_Table_9.2b.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
  zh: '![表 9.2 – Kubernetes 解决方案提供](img/B18115_Table_9.2a.jpg)![表 9.2 – Kubernetes
    解决方案提供](img/B18115_Table_9.2b.jpg)'
- en: Table 9.2 – Kubernetes solution offerings
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.2 – Kubernetes解决方案
- en: Kubernetes helps offset some of the most significant challenges that data scientists
    face when running models at scale in each of these ways. Now, let’s look at some
    of the best practices for running AI/ML workloads.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes有助于抵消数据科学家在大规模运行模型时面临的一些最重要的挑战。现在，让我们来看一下运行AI/ML工作负载的一些最佳实践。
- en: Best practices for running AI/ML workloads
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 运行AI/ML工作负载的最佳实践
- en: As ML progresses from research to practical applications, we must improve the
    maturity of its operational processes. To crack these challenges, we’ll need to
    integrate DevOps and data engineering methods, as well as ones that are specific
    to ML.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 随着机器学习从研究走向实际应用，我们必须提升其运营过程的成熟度。为了解决这些挑战，我们需要结合DevOps和数据工程方法，以及一些专门针对机器学习的方法。
- en: 'MLOps blends ML, DevOps, and data engineering into a set of approaches. MLOps
    seeks to deploy and manage ML systems in production reliably and efficiently.
    The following are some of MLOps’s main practices:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: MLOps将机器学习、DevOps和数据工程结合成一套方法。MLOps旨在以可靠且高效的方式在生产环境中部署和管理机器学习系统。以下是一些MLOps的主要实践：
- en: '**Data Pipelines**: ML models always require some type of data transformation,
    which is typically accomplished through scripts or even cells in a notebook, making
    them difficult to manage and run consistently. Creating a separate data pipeline
    offers numerous benefits in terms of code reuse, runtime visibility, management,
    and scalability.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据管道**：机器学习模型始终需要某种类型的数据转换，通常通过脚本或甚至笔记本中的单元格来完成，这使得它们难以管理并保持一致运行。创建一个独立的数据管道在代码重用、运行时可见性、管理和可扩展性方面带来了许多好处。'
- en: '**Pipeline Versions**: Most ML models require two pipeline versions: one for
    training and one for serving. This is because data formats and the methods for
    accessing them are typically very different from each other, particularly for
    models that need to be served in real-time requests (as opposed to batch prediction
    runs). The ML pipeline should be a pure code artifact that is independent of any
    specific data. This means that it is possible to track its versions in source
    control and automate its deployment with a regular CI/CD pipeline. This would
    enable us to connect the code and data planes in a structured and automated manner.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管道版本**：大多数机器学习模型需要两种管道版本：一个用于训练，一个用于服务。这是因为数据格式和访问方法通常彼此非常不同，特别是对于需要在实时请求中提供服务的模型（与批处理预测不同）。机器学习管道应该是一个独立于任何特定数据的纯代码产物。这意味着可以在源代码控制中跟踪它的版本，并通过常规的CI/CD管道自动部署。这将使我们能够以结构化和自动化的方式连接代码和数据平面。'
- en: '**Multiple Pipelines**: At this point, it’s clear that there are two types
    of ML pipelines: training pipelines and serving pipelines. They have one thing
    in common: the data transformations that are performed must produce data in the
    same format, but their implementations can differ greatly. For example, the training
    pipeline typically runs over batch files containing all features, whereas the
    serving pipeline frequently runs online and receives only a portion of the features
    in the requests, retrieving the remainder from a database. It is critical, however,
    to ensure that these two pipelines are consistent, so code and data should be
    reused whenever possible.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多重管道**：此时，显而易见，机器学习管道有两种类型：训练管道和服务管道。它们有一个共同点：必须进行的数据转换必须产生相同格式的数据，但它们的实现可能大不相同。例如，训练管道通常运行在包含所有特征的批处理文件上，而服务管道则经常在线运行，并且仅接收请求中的部分特征，剩余部分从数据库中检索。然而，确保这两种管道的一致性至关重要，因此应尽可能重用代码和数据。'
- en: '**Model and Data Versioning**: Consistent version tracking is essential for
    reproducibility. In a traditional software world, versioning code is sufficient
    because it defines all behavior. In ML, we must also keep track of model versions,
    as well as the data used to train them and some meta information such as training
    hyperparameters. It’s also necessary to version the data and associate each trained
    model with the exact versions of code, data, and hyperparameters that we used.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型和数据版本控制**：一致的版本跟踪对于可重复性至关重要。在传统软件领域，版本控制代码就足够了，因为它定义了所有行为。而在机器学习中，我们还必须跟踪模型版本，以及用于训练它们的数据和一些元信息，如训练超参数。同时，还需要对数据进行版本控制，并将每个训练好的模型与我们所使用的代码、数据和超参数的确切版本相关联。'
- en: '**Model Validation**: To determine whether a model is suitable for deployment,
    the right metrics to track and the threshold of acceptable values must be determined,
    usually empirically and frequently compared to previous models or benchmarks.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型验证**：为了确定模型是否适合部署，必须确定正确的跟踪指标和可接受值的阈值，通常是通过经验并与之前的模型或基准进行对比。'
- en: '**Data Validation**: A good data pipeline will typically begin by validating
    the input data. File format and size, column types, null or empty values, and
    invalid values are all common validations. All of these are required for ML training
    and prediction; otherwise, you may have a misbehaving model. Higher-level statistical
    properties of the input should also be validated by ML pipelines. For example,
    if the average or standard deviation of a feature varies significantly from one
    training dataset to the next, the trained model and its predictions will most
    likely be affected.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据验证**：一个好的数据流水线通常会从验证输入数据开始。文件格式和大小、列类型、空值或无效值都是常见的验证内容。这些都是机器学习训练和预测所必需的，否则您可能会得到一个表现异常的模型。输入数据的更高层次统计特性也应由
    ML 流水线验证。例如，如果某一特征的平均值或标准差在不同训练数据集之间变化显著，训练出来的模型及其预测结果很可能会受到影响。'
- en: '**Monitoring**: Monitoring becomes important for ML systems because their performance
    is dependent not only on factors over which we have some control, such as infrastructure
    and our software, but also on data, over which we have much less control. In addition
    to standard metrics such as latency, traffic, errors, and saturation, we must
    also monitor model prediction performance. To detect problems that affect specific
    segments, we must monitor metrics across slices (rather than just globally), just
    as we do when validating the model.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控**：对于机器学习系统来说，监控变得至关重要，因为它们的性能不仅依赖于我们可以控制的因素，如基础设施和软件，还依赖于我们控制较少的数据。此外，除了标准的指标（如延迟、流量、错误和饱和度）外，我们还必须监控模型的预测性能。为了检测影响特定分段的问题，我们必须跨切片（而不仅仅是全局）监控指标，就像验证模型时一样。'
- en: To summarize, deploying ML in a production context entails more than just publishing
    the model as a prediction API. Rather, it entails establishing an ML pipeline
    capable of automating the retraining and deployment of new models. Setting up
    a CI/CD system allows you to test and release new pipeline implementations automatically.
    This system enables us to deal with quick data and business environment changes.
    MLOps, as a new area, is quickly gaining traction among data scientists, ML engineers,
    and AI enthusiasts.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，将机器学习（ML）应用于生产环境不仅仅是将模型发布为预测 API。实际上，它还包括建立一个能够自动化重新训练和部署新模型的 ML 流水线。设置
    CI/CD 系统可以让您自动测试和发布新的流水线实现。这个系统使我们能够应对快速变化的数据和商业环境。作为一个新兴领域，MLOps 正在迅速获得数据科学家、ML
    工程师和 AI 爱好者的关注。
- en: Summary
  id: totrans-316
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: To summarize, Kubeflow provides an easy-to-deploy, easy-to-use toolchain that
    will allow data scientists to integrate the various resources they will need to
    run models on Kubernetes, such as Jupyter Notebooks, Kubernetes deployment files,
    and ML libraries such as PyTorch and TensorFlow.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，Kubeflow 提供了一个易于部署和使用的工具链，允许数据科学家整合他们需要在 Kubernetes 上运行模型的各种资源，如 Jupyter
    Notebooks、Kubernetes 部署文件以及 PyTorch 和 TensorFlow 等 ML 库。
- en: Another popular ML task that Kubeflow considerably simplifies is working with
    Jupyter Notebooks. You can build notebooks and share them with your team or teams
    using Kubeflow’s built-in notebook services, which you can access via the UI.
    In this chapter, we learned how to set up an ML pipeline that will develop and
    deploy an example model using the Kubeflow ML platform. We also recognized that
    Kubeflow on MicroK8s is easy to set up and configure, as well as lightweight and
    capable of simulating real-world conditions while constructing, migrating, and
    deploying pipelines.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个 Kubeflow 显著简化的流行 ML 任务是与 Jupyter Notebooks 的工作。您可以使用 Kubeflow 内置的笔记本服务构建笔记本并与您的团队或多个团队分享，您可以通过
    UI 访问这些服务。在本章中，我们学习了如何设置一个 ML 流水线，该流水线将使用 Kubeflow ML 平台开发和部署示例模型。我们还意识到，Kubeflow
    在 MicroK8s 上的设置和配置既简单又轻量，同时能够在构建、迁移和部署流水线的过程中模拟现实世界的条件。
- en: In the next chapter, you will learn how to deploy and run serverless applications
    using the Knative and OpenFaaS frameworks.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，您将学习如何使用 Knative 和 OpenFaaS 框架部署和运行无服务器应用程序。
