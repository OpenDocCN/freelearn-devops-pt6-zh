- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Upgrading EKS Clusters
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级 EKS 集群
- en: The Kubernetes community will release a new version of Kubernetes approximately
    three times a year, as well as maintain release branches for the three most recent
    minor releases. In addition, AWS will maintain at least four production-ready
    versions of Kubernetes at any given time; at the time of writing, they are versions
    1.24, 1.23, 1.22, and 1.21\. Given these two different release schedules, at some
    point, you will need to upgrade your EKS clusters either because you want to use
    a new feature developed by the Kubernetes community or because AWS is no longer
    supporting the version you are using. The good news is that as EKS is a managed
    service, AWS does most of the upgrade work for you!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 社区每年大约发布三个新版本，并且会维护最近三个小版本的发布分支。此外，AWS 会在任何给定时刻维护至少四个生产就绪的 Kubernetes
    版本；目前这些版本为 1.24、1.23、1.22 和 1.21。鉴于这两种不同的发布计划，您最终需要升级 EKS 集群，原因可能是您希望使用 Kubernetes
    社区开发的新特性，或者因为 AWS 不再支持您正在使用的版本。好消息是，由于 EKS 是托管服务，AWS 会为您完成大部分升级工作！
- en: 'This chapter looks at the best way to do this and the impact it can have on
    running workloads. Specifically, we will cover the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨最佳的操作方式以及它对正在运行的工作负载可能产生的影响。具体来说，我们将涵盖以下内容：
- en: Reasons for upgrading EKS and key areas to focus on
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 升级 EKS 的原因及重点关注领域
- en: How to do in-place upgrades of the control plane
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何进行控制平面的就地升级
- en: Upgrading nodes and their critical components
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 升级节点及其关键组件
- en: Creating a new cluster and migrating workloads
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建新集群并迁移工作负载
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The reader should have a familiarity with YAML, basic networking, and EKS architecture.
    Before getting started with this chapter, please ensure you have the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 读者应对 YAML、基础网络和 EKS 架构有所了解。在开始本章之前，请确保您已具备以下内容：
- en: Network connectivity to your EKS API endpoint
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要与您的 EKS API 端点进行网络连接
- en: The AWS CLI and kubectl binary installed on your workstation
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 您的工作站上已安装 AWS CLI 和 kubectl 二进制文件
- en: A good understanding of VPC networking and how to create network objects such
    as ENIs
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对 VPC 网络和如何创建 ENI 等网络对象有较好的理解
- en: Reasons for upgrading EKS and key areas to focus on
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级 EKS 的原因及重点关注领域
- en: EKS is a community project and, as such, it is constantly evolving; big releases
    currently happen approximately three times per year and normally contain at least
    one major change. For example, 1.21, released in April 2021, deprecated Pod security
    policies in favor of external admission control. This means that you will need
    to take advantage of newer Kubernetes features at some point. In addition, the
    Kubernetes community only supports the most recent three minor releases (for example,
    1.25, 1.24, and 1.23), with older releases normally getting 1 year of patch releases,
    after which you are on your own!
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: EKS 是一个社区项目，因此它不断发展；目前大版本大约每年发布三次，并且通常包含至少一个重大变更。例如，2021 年 4 月发布的 1.21 版本废弃了
    Pod 安全策略，转而支持外部准入控制。这意味着您最终需要利用更新的 Kubernetes 特性。此外，Kubernetes 社区仅支持最近的三个小版本（例如
    1.25、1.24 和 1.23），较旧版本通常会得到 1 年的补丁更新，之后您就需要自行处理了！
- en: 'Amazon takes the upstream Kubernetes release, tests and validates it with the
    AWS platform and components such as the AWS VPC CNI, and so on, and packages and
    releases it as an EKS release. This process takes roughly 6 months after the Kubernetes
    community release and will normally be supported for 14 months. This is illustrated
    in the following diagram:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 亚马逊会从上游 Kubernetes 版本发布中获取代码，进行测试并与 AWS 平台及组件（如 AWS VPC CNI 等）验证，然后将其打包并发布为
    EKS 版本。这个过程大约需要 6 个月，通常支持 14 个月。以下图示说明了这一过程：
- en: '![Figure 10.1 – Example Kubernetes release schedule](img/B18129_10_01.jpg)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.1 – 示例 Kubernetes 发布计划](img/B18129_10_01.jpg)'
- en: Figure 10.1 – Example Kubernetes release schedule
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – 示例 Kubernetes 发布计划
- en: After 12 months, AWS will notify customers, using the console and AWS Health
    Dashboard, that a release is approaching the **end-of-life** (**EOL**)—sometimes
    called **end-of-support** (**EOS**)—date, and after 14 months they will automatically
    upgrade the control plane to the earliest supported version through a gradual
    deployment process after the EOS date.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 12 个月后，AWS 会通过控制台和 AWS 健康仪表板通知客户，某个版本即将达到 **生命周期结束**（**EOL**）日期——有时也称为 **支持结束**（**EOS**）日期，并且在
    EOS 日期后的 14 个月内，AWS 将通过渐进式部署过程自动将控制平面升级到最早支持的版本。
- en: As the cluster owner, you can choose to upgrade the control plane at any time
    before the EOS date, but you will always be responsible for upgrading worker nodes,
    add-ons, and any core components such as `kube-proxy`.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 作为集群拥有者，你可以在 EOS 日期之前随时选择升级控制平面，但你始终需要负责升级工作节点、插件以及任何核心组件，如`kube-proxy`。
- en: 'There are certain key areas to consider when upgrading as you cannot roll back
    a version. If you want to roll back, you must deploy a new cluster with a previous
    version. Key considerations are as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 升级时有一些关键领域需要考虑，因为你不能回滚版本。如果想回滚，必须重新部署一个先前版本的集群。关键考虑因素如下：
- en: Are Kubernetes APIs or key functionality being deprecated that may require changes
    to the deployment manifest or Kubernetes component upgrades such as replacing
    kubelet?
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes API 或关键功能是否已弃用，可能需要更改部署清单或进行 Kubernetes 组件升级，例如替换 kubelet？
- en: Do add-ons, third-party DaemonSets, and so on need upgrading to support the
    new release?
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 插件、第三方 DaemonSets 等是否需要升级以支持新版本？
- en: Is there a new functionality that needs designing, such as the use of **Open
    Policy Agent** (**OPA**) to replace Pod policies?
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有需要设计的新功能，例如使用**Open Policy Agent**（**OPA**）来替代 Pod 策略？
- en: Are there security patches that need to be applied?
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有需要应用的安全补丁？
- en: On the whole, there should be little impact on running workloads unless they
    are *aware* or interact with the Kubernetes control plane, but it is always worth
    reading the release notes and upgrading in lower environments first before you
    modify your production environment.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，除非工作负载与 Kubernetes 控制平面*相关*或交互，否则对运行中的工作负载几乎没有影响，但在修改生产环境之前，始终值得先阅读发布说明并在较低环境中进行升级。
- en: Now that we have discussed *why* you will need to upgrade, let’s discuss *how*
    you do a cluster upgrade.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经讨论了*为什么*需要升级，让我们来讨论*如何*进行集群升级。
- en: How to do in-place upgrades of the control plane
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何进行控制平面的就地升级
- en: If you do nothing, eventually, AWS will upgrade your control plane, but as discussed
    previously, this might have an impact on other components. It is, therefore, best
    to take a proactive approach. Upgrading the control plane is literally a *single-click*
    operation, and AWS will progressively upgrade the API and etcd servers. In most
    cases, this will be fine, but as discussed in the previous section, it can break
    *services*
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你什么都不做，AWS 最终会升级你的控制平面，但如前所述，这可能会影响其他组件。因此，采取主动的升级方法是最好的。升级控制平面实际上是一个*单击*操作，AWS
    将逐步升级 API 和 etcd 服务器。在大多数情况下，这样做是可以的，但正如前一部分所讨论的，它可能会导致*服务*中断。
- en: 'A structured approach is, therefore, recommended. In the following example,
    the team responsible for the `eksctl` configuration file, or it may be a more
    detailed development for add-ons such as Argo CD, Flux, and so on. In the following
    diagram, this is illustrated as the responsibility of a platform engineering team,
    but in smaller companies, this might be a DevOps or **site reliability engineering**
    (**SRE**) team’s or application development team’s responsibility:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，推荐采用结构化方法。在以下示例中，负责`eksctl`配置文件的团队，或者可能是更详细的插件开发团队，如 Argo CD、Flux 等。在以下图示中，这由平台工程团队负责，但在较小的公司中，这可能是
    DevOps 或**站点可靠性工程**（**SRE**）团队或应用开发团队的责任：
- en: '![Figure 10.2 – Structured upgrade approach](img/B18129_10_02.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.2 – 结构化升级方法](img/B18129_10_02.jpg)'
- en: Figure 10.2 – Structured upgrade approach
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – 结构化升级方法
- en: Once the master IaC template has been created, this can be used by the development
    teams to test their workloads in lower environments (testing/staging) and, ultimately,
    in production.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦主 IaC 模板创建完成，开发团队可以利用该模板在较低环境（测试/预生产）中测试工作负载，最终在生产环境中使用。
- en: 'Assuming you have used `eksctl` to create your cluster, you can upgrade the
    control plane with a simple one-line command. If we use the IPv4 cluster from
    the previous chapter, we can upgrade it using the following command:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你已经使用`eksctl`创建了集群，你可以通过一个简单的一行命令来升级控制平面。如果我们使用前一章中的 IPv4 集群，可以使用以下命令进行升级：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Important note
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: If you leave out the `--approve` keyword, `eksctl` will not make changes. It’s
    also worth noting that normally you can’t jump directly from a minor release such
    as 1.19 to 1.22 without upgrading to 1.20 and then 1.21 first!
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你省略了`--approve`关键字，`eksctl`将不会做任何更改。还值得注意的是，通常你不能直接从 1.19 这样的次要版本跳跃到 1.22，必须先升级到
    1.20，然后是 1.21！
- en: This process can take up to 20 minutes, so it’s worth planning a change window
    as Kubernetes API access may be intermittent during the upgrade (no existing workloads
    should be affected). Once the control plane has been upgraded, you should upgrade
    your worker nodes to match the cluster version prior to moving to the next version
    (`eksctl` enforces this requirement). Let’s look at how we do this upgrade next.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 该过程可能需要最多20分钟，因此值得规划一个变更窗口，因为在升级过程中，Kubernetes API访问可能会间歇性中断（现有工作负载不应受到影响）。一旦控制平面升级完成，您应升级工作节点以匹配集群版本，然后再进行下一个版本的升级（`eksctl`
    强制要求此步骤）。接下来我们来看看如何执行这个升级。
- en: Upgrading nodes and their critical components
  id: totrans-38
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 升级节点及其关键组件
- en: 'Simplifying the upgrade process is one of the key reasons for using managed
    node groups. If we want to upgrade a single worker node in an active cluster manually,
    we would need to perform the following actions:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 简化升级过程是使用托管节点组的关键原因之一。如果我们想手动升级活动集群中的单个工作节点，我们需要执行以下操作：
- en: Add a new worker that can run the Pods that will be evicted from the node running
    the old version of the Kubernetes agents (kubelet, and so on) we are upgrading,
    if we want to maintain the overall cluster capacity (the overall number of worker
    nodes that can run active Pods) during the upgrade.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果我们希望在升级过程中保持整体集群容量（能够运行活动Pods的工作节点总数），可以添加一台新工作节点来运行那些将从旧版Kubernetes代理（kubelet等）运行的节点中逐出的Pods。
- en: Drain the Pods from the node we are working on and remove them from the scheduling
    process so that no new Pods are allocated.
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从我们正在处理的节点中排出Pods，并将它们从调度过程中移除，以确保不会分配新的Pods。
- en: Upgrade the operating system binaries and apply patches if needed.
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 升级操作系统二进制文件并应用必要的补丁。
- en: Update and configure the Kubernetes agents (kubelet, and so on).
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新和配置Kubernetes代理（kubelet等）。
- en: Once the upgraded node has registered and is ready, add it back to the scheduler.
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦升级后的节点注册并准备就绪，将其重新添加到调度程序中。
- en: Update any critical components such as `kube-proxy`, `coreDNS`, and so on.
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新任何关键组件，如`kube-proxy`、`coreDNS`等。
- en: If we have node groups with 10 or 20 nodes, you will see how this can become
    painful very quickly.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们的节点组包含10个或20个节点，您将会看到这会变得非常麻烦。
- en: Let’s look at how we upgrade the worker nodes now that the cluster control plane
    is upgraded.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来看看，在集群控制平面升级后，我们如何升级工作节点。
- en: Upgrading managed node groups
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 升级托管节点组
- en: 'Once you have upgraded the cluster, if you look at the managed node groups
    for that cluster, you will see the **Update now** link. This can be used to automatically
    upgrade the node group using the autoscaling launch template process described
    in [*Chapter 8*](B18129_08.xhtml#_idTextAnchor123), *Managing Worker Nodes on
    EKS*. An example is shown next:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 升级集群后，如果查看该集群的托管节点组，您将看到**立即更新**链接。可以使用此链接，利用[*第 8 章*](B18129_08.xhtml#_idTextAnchor123)中描述的自动扩展启动模板过程自动升级节点组，*EKS中的工作节点管理*。下面显示了示例：
- en: '![Figure 10.3 – Node group updates](img/B18129_10_03.jpg)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.3 – 节点组更新](img/B18129_10_03.jpg)'
- en: Figure 10.3 – Node group updates
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – 节点组更新
- en: 'Using the link will automatically replace all EC2 workers in the node group;
    you will be presented with a pop-up window (an example is shown next) that provides
    a few more options:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 使用该链接将自动替换节点组中的所有EC2工作节点；您将看到一个弹出窗口（下面会显示示例），提供更多选项：
- en: '![Figure 10.4 – Node group update strategy](img/B18129_10_04.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.4 – 节点组更新策略](img/B18129_10_04.jpg)'
- en: Figure 10.4 – Node group update strategy
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.4 – 节点组更新策略
- en: 'The upgrade node dialog box shown previously allows you to do the following:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 前面显示的升级节点对话框允许您执行以下操作：
- en: Replace the nodes with the latest AMI by setting the **Update node group** **version**
    switch.
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过设置**更新节点组** **版本**切换，用最新的AMI替换节点。
- en: Replace the current autoscaling launch template with a different one using the
    **Change launch template** **version** switch.
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**更改启动模板** **版本**切换，替换当前的自动扩展启动模板为另一个模板。
- en: Use the **Rolling update** strategy (default) to drain the Pods from the running
    node. This strategy will respect any Pod disruption budgets defined, and so the
    update will fail if the Pods cannot be drained gracefully. Alternatively, the
    **Force update** strategy will try to drain the Pods as per a rolling update,
    but if it fails, it will simply terminate the node rather than fail the update.
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**滚动更新**策略（默认）从运行节点中排空 Pods。此策略会遵循定义的任何 Pod 中断预算，因此如果 Pods 无法平滑排空，更新将失败。另一种选择是**强制更新**策略，它将按滚动更新尝试排空
    Pods，但如果失败，将简单地终止节点而不是使更新失败。
- en: 'Clicking the `eksctl`:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 点击 `eksctl`：
- en: '[PRE1]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You can watch the status of the replacement using the following command. In
    the following example, you can see the older 1.19 AMI has `SchedulingDisabled`
    set:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令查看替换的状态。在以下示例中，可以看到较旧的 1.19 AMI 已设置为 `SchedulingDisabled`：
- en: '[PRE2]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Upgrading self-managed node groups
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 升级自管节点组
- en: Upgrading self-managed nodes will depend on how you want to perform the upgrade
    (draining Pods first, replacing nodes, or in-place upgrades), and which additional
    components are installed.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 升级自管节点将取决于你如何进行升级（先排空 Pods、替换节点或就地升级），以及安装了哪些额外组件。
- en: Generally, node groups should be viewed as immutable; so, as unmanaged node
    groups may be part of an autoscaling group, you can change the AMI and use a new
    launch template to force replacement, but as the operator you will be responsible
    for removing the nodes from the scheduler (`SchedulingDisabled`), draining the
    Pods, and then scaling out and scaling in (effectively, everything a managed group
    does for you).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，节点组应视为不可变的；因此，作为自动伸缩组的一部分的非托管节点组，您可以更改 AMI 并使用新的启动模板来强制替换，但作为操作员，你将负责将节点从调度器中移除（`SchedulingDisabled`），排空
    Pods，然后进行扩展和收缩（实际上，所有这些都是托管组为你完成的）。
- en: A simpler way may be to simply create a new node group, move the Pods onto the
    new node group, and delete the old one.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 更简单的方法可能是直接创建一个新的节点组，将 Pods 移动到新的节点组，并删除旧的节点组。
- en: Updating core components
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更新核心组件
- en: The node group will have an updated kubelet agent, but key components such as
    `kube-proxy`, `coreDNS`, and `vpc-cni` will typically need to be upgraded to work
    with a specific Kubernetes release.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 节点组将拥有更新后的 kubelet 代理，但像 `kube-proxy`、`coreDNS` 和 `vpc-cni` 等关键组件通常需要升级才能与特定的
    Kubernetes 版本配合使用。
- en: 'If you look at the current version of `kube-proxy` on the upgraded cluster
    and node groups using the following command, we can see this is still at the previous
    cluster’s versions (`v1.19.16`):'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用以下命令查看升级后的集群和节点组中当前版本的 `kube-proxy`，你会看到它仍然是之前集群的版本（`v1.19.16`）：
- en: '[PRE3]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can do an upgrade using `eksctl` or another IaC tool. The next example shows
    how to use `eksctl utils` to update `kube-proxy`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 `eksctl` 或其他 IaC 工具进行升级。下一个示例展示了如何使用 `eksctl utils` 更新 `kube-proxy`：
- en: '[PRE4]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To simplify this process, AWS introduced EKS add-ons, which allow the update
    of operational software such as `kube-proxy` or monitoring daemons such as **AWS
    Distro for** **OpenTelemetry** (**ADOT**).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为简化此过程，AWS 引入了 EKS 附加组件，允许更新如 `kube-proxy` 等操作软件或监控守护进程，例如**AWS Distro for**
    **OpenTelemetry** (**ADOT**)。
- en: 'If we use the AWS console and click on the `vpc-cni` add-on to upgrade the
    `aws-node` DaemonSet that implements the CNI:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们使用 AWS 控制台并点击 `vpc-cni` 附加组件来升级实现 CNI 的 `aws-node` DaemonSet：
- en: '![Figure 10.5 – Cluster add-ons](img/B18129_10_05.jpg)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.5 – 集群附加组件](img/B18129_10_05.jpg)'
- en: Figure 10.5 – Cluster add-ons
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.5 – 集群附加组件
- en: 'You can also do the operation programmatically using your IaC tool of choice.
    The next example shows how you can do the same operation with `eksctl`:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用你选择的 IaC 工具以编程方式执行此操作。下一个示例展示了如何使用 `eksctl` 执行相同操作：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Important note
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: The use of `--force` will force the configuration onto the cluster. These actions
    should all be tested on lower environments to ensure they don’t cause an outage
    prior to being run on production.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `--force` 会强制配置应用到集群。这些操作应该在低环境中进行测试，以确保在生产环境中执行时不会导致停机。
- en: Let’s look at using an alternative cluster and/or node group to provide a blue/green
    deployment approach at the cluster level.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下使用替代集群和/或节点组，在集群级别提供蓝绿部署方法。
- en: Creating a new cluster and migrating workloads
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建新集群并迁移工作负载
- en: 'As you can see, a typical upgrade will involve at least three steps:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，典型的升级通常涉及至少三个步骤：
- en: Upgrading the control plane
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 升级控制平面
- en: Upgrading/replacing the worker nodes with more up-to-date AMIs and the kubelet
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 升级/替换工作节点，使用更新的 AMI 和 kubelet
- en: At least upgrading the core components, `kube-proxy`, `coreDNS`, and `vpc-cni`
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 至少升级核心组件，`kube-proxy`，`coreDNS` 和 `vpc-cni`
- en: In this approach, the Pods must first be drained and reallocated to worker nodes
    as they are replaced. This can lead to interruptions if not managed well. An alternative
    is to deploy a new cluster and then migrate workloads; this is sometimes referred
    to as blue/green cluster deployment.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，Pod 必须首先被排空，并重新分配到工作节点，因为它们将被替换。如果管理不当，这可能会导致中断。另一种选择是部署新集群，然后迁移工作负载；这种方法有时被称为蓝绿集群部署。
- en: Important note
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: This will be the least cost-effective approach as you will be paying for two
    control planes but may be suitable if you want to try to minimize disruption.
    We will only discuss this approach at a high level in this book as the most common
    approach is to upgrade the EKS control plane and then the worker nodes using managed
    worker nodes, greatly reducing cost and complexity.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这是成本效益最差的方法，因为你将需要为两个控制平面付费，但如果你希望尽量减少中断，这种方法可能适合。我们在本书中只会在高层次上讨论这种方法，因为最常见的方法是升级
    EKS 控制平面，然后使用托管工作节点升级工作节点，这样可以大大降低成本和复杂性。
- en: 'A multi-cluster solution presents some different challenges: How do you move
    workloads? Have any manual changes been applied to the cluster? How do you provide
    ingress and egress connectivity? How do you manage state? The following diagram
    illustrates the solutions to these challenges:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 多集群解决方案提出了一些不同的挑战：如何迁移工作负载？集群上是否已应用任何手动更改？如何提供入口和出口连接性？如何管理状态？以下图示说明了这些挑战的解决方案：
- en: '![Figure 10.6 – Multi-cluster solution](img/B18129_10_06.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.6 – 多集群解决方案](img/B18129_10_06.jpg)'
- en: Figure 10.6 – Multi-cluster solution
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.6 – 多集群解决方案
- en: Now, to understand some of the challenges, let’s look at one approach to migrating
    workloads between two clusters.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，为了理解一些挑战，让我们看一下将工作负载迁移到两个集群之间的一个方法。
- en: How do you move workloads?
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你如何迁移工作负载？
- en: When using kubectl or Helm, the current context defines which cluster you will
    use. By switching context, the same manifest can be deployed on either cluster.
    In *Figure 10**.6*, a CI/CD pipeline can automate the provisioning of the service
    on either cluster. For example, **Cluster 1** (v1.19) is running **Service A**;
    **Cluster 2** can be created with v1.20, and this can trigger a deployment of
    **Service A** on **Cluster 2**.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 kubectl 或 Helm 时，当前上下文定义了你将使用哪个集群。通过切换上下文，可以在任一集群上部署相同的清单。在 *图 10.6* 中，CI/CD
    管道可以自动化在任一集群上部署服务。例如，**集群 1**（v1.19）正在运行 **Service A**；**集群 2** 可以使用 v1.20 创建，这可以触发在
    **集群 2** 上部署 **Service A**。
- en: How do you provide consistent ingress and egress network access?
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你如何提供一致的入口和出口网络访问？
- en: Egress (Pod initiating connections out) can use either an internal or external
    `VPC NAT` gateway to mask the IP address of the Pods from both clusters, masking
    any Pod IP address changes.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 出口（Pod 发起外部连接）可以使用内部或外部的 `VPC NAT` 网关来隐藏两个集群的 Pod 的 IP 地址，避免 Pod IP 地址发生变化。
- en: 'An `TargetGroupBinding` instance, which will reuse an existing ALB or NLB target
    group for both clusters configured outside the EKS cluster using IaC. An example
    is shown next and references the `testapp` service on port `80`:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`TargetGroupBinding` 实例，它将复用为两个集群配置的现有 ALB 或 NLB 目标组，这些集群使用基础设施即代码（IaC）在 EKS
    集群外配置。以下是一个示例，并引用了 `testapp` 服务，端口为 `80`：'
- en: '[PRE6]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, let’s look at how applications typically manage state.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看应用程序通常如何管理状态。
- en: How do you manage state?
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你如何管理状态？
- en: Your application may need to maintain state in a database or on a filesystem.
    As long as these services are configured outside the cluster using an AWS service
    such as **Relational Database Service** (**RDS**) or **Elastic File System** (**EFS**),
    they can be referenced by either cluster.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 你的应用程序可能需要在数据库或文件系统中维护状态。只要这些服务通过 AWS 服务（如 **关系型数据库服务** (**RDS**) 或 **弹性文件系统**
    (**EFS**)）配置在集群外部，它们就可以被任一集群引用。
- en: With these solutions in place, you can easily flip between clusters. By deploying
    to the new cluster first and making sure the service is registered with the ELB,
    you can make the transition almost seamless; however, you will pay more for this
    type of configuration.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些解决方案到位后，你可以轻松地在集群之间切换。通过先部署到新集群，并确保服务已注册到 ELB，你可以使过渡几乎无缝；然而，你将为这种配置支付更多费用。
- en: In this section, we have looked at how to upgrade key EKS components and the
    different approaches required for managed and unmanaged node groups. We’ll now
    revisit the key learning points from this chapter.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了如何升级关键的 EKS 组件以及托管和非托管节点组所需的不同方法。现在我们将回顾本章的关键学习点。
- en: Summary
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we explored why you will need to upgrade your cluster: either
    you want to use a new Kubernetes feature or a bug fix or AWS is deprecating the
    version you are using. We identified you will need to perform three actions for
    each cluster: upgrade the control plane, upgrade the worker nodes, and upgrade
    the core components such as `kube-proxy` and `coreDNS`.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探讨了为什么需要升级集群：要么是想使用新的 Kubernetes 特性，或者是修复一个 bug，或者是 AWS 正在弃用您使用的版本。我们确定了需要对每个集群执行三项操作：升级控制平面，升级工作节点，升级核心组件如
    `kube-proxy` 和 `coreDNS`。
- en: We also discussed how the control plane upgrade is pretty straightforward as
    it’s a managed service, but node group and component upgrades can be more challenging.
    Using managed node groups and add-ons simplifies this, but you could also use
    a second cluster and move the workload between them, upgrading the non-active
    cluster. This approach—sometimes referred to as blue/green cluster deployments—will
    add cost and complexity, so it is not recommended, but it can minimize application
    outages due to upgrades.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还讨论了控制平面升级相对简单，因为它是一个托管服务，但节点组和组件的升级可能更具挑战性。使用托管节点组和附加组件可以简化这一过程，但你也可以使用第二个集群，并在它们之间移动工作负载，升级非活动集群。这种方法——有时称为蓝绿集群部署——会增加成本和复杂性，因此不推荐使用，但它可以最小化因升级而导致的应用程序停机。
- en: In the next chapter, we will look at how you can use AWS **Elastic Container
    Repository** (**ECR**) as a source of your applications and Pods.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨如何使用 AWS **弹性容器仓库**（**ECR**）作为应用和 Pods 的源。
- en: Further reading
  id: totrans-109
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Pod disruption budgets: [https://kubernetes.io/docs/concepts/workloads/pods/disruptions/](https://kubernetes.io/docs/concepts/workloads/pods/disruptions/'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pod 中断预算: [https://kubernetes.io/docs/concepts/workloads/pods/disruptions/](https://kubernetes.io/docs/concepts/workloads/pods/disruptions/)'
- en: )
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'Managed node group update process: https://docs.aws.amazon.com/eks/latest/userguide/managed-node-update-behavior.html'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '托管节点组更新过程: [https://docs.aws.amazon.com/eks/latest/userguide/managed-node-update-behavior.html](https://docs.aws.amazon.com/eks/latest/userguide/managed-node-update-behavior.html)'
- en: 'AWS Load Balancer Controller TargetGroupBinding: [https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.1/guide/targetgroupbinding/targetgroupbinding/](https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.1/guide/targetgroupbinding/targetgroupbinding/'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'AWS 负载均衡器控制器 TargetGroupBinding: [https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.1/guide/targetgroupbinding/targetgroupbinding/](https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.1/guide/targetgroupbinding/targetgroupbinding/)'
- en: )
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'EKS add-ons: [https://docs.aws.amazon.com/eks/latest/userguide/eks-add-ons.html](https://docs.aws.amazon.com/eks/latest/userguide/eks-add-ons.html'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'EKS 附加组件: [https://docs.aws.amazon.com/eks/latest/userguide/eks-add-ons.html](https://docs.aws.amazon.com/eks/latest/userguide/eks-add-ons.html)'
- en: )
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'Kubernetes upgrades: [https://kubernetes.io/docs/tasks/administer-cluster/cluster-upgrade/](https://kubernetes.io/docs/tasks/administer-cluster/cluster-upgrade/)'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kubernetes 升级: [https://kubernetes.io/docs/tasks/administer-cluster/cluster-upgrade/](https://kubernetes.io/docs/tasks/administer-cluster/cluster-upgrade/)'
- en: 'Part 3: Deploying an Application on EKS'
  id: totrans-118
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第三部分：在 EKS 上部署应用
- en: This part will cover topics related to features that help you deploy your application
    on EKS. This section includes a complete guide for storing container images on
    Amazon ECR, providing persistent volumes for your application with AWS storage
    services such as EBS and EFS, defining the Pod security and granting permissions
    with IAM, and exposing and load balancing your Kubernetes application. In the
    last two chapters, we will look at more advanced topics such as using AWS Fargate,
    and how to use App Mesh to control and monitor our deployments
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分将涵盖与帮助您在 EKS 上部署应用相关的功能。本节包括如何将容器镜像存储在 Amazon ECR 上的完整指南，如何通过 AWS 存储服务（如
    EBS 和 EFS）为应用提供持久卷，如何定义 Pod 安全性并通过 IAM 授予权限，以及如何暴露和负载均衡您的 Kubernetes 应用。在接下来的两章中，我们将探讨更高级的主题，例如如何使用
    AWS Fargate，以及如何使用 App Mesh 来控制和监控我们的部署。
- en: 'This section contains the following chapters:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包含以下章节：
- en: '[*Chapter 11*](B18129_11.xhtml#_idTextAnchor162), *Building Applications and
    Pushing Them to Amazon ECR*'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第11章*](B18129_11.xhtml#_idTextAnchor162)，*构建应用并将其推送到 Amazon ECR*'
- en: '[*Chapter 12*](B18129_12.xhtml#_idTextAnchor175), *Deploying Pods with Amazon
    Storage*'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第12章*](B18129_12.xhtml#_idTextAnchor175)，*使用 Amazon 存储部署 Pods*'
- en: '[*Chapter 13*](B18129_13.xhtml#_idTextAnchor193), *Using IAM for Granting Access
    to Applications*'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第13章*](B18129_13.xhtml#_idTextAnchor193)，*使用IAM授予应用程序访问权限*'
- en: '[*Chapter 14*](B18129_14.xhtml#_idTextAnchor205), *Setting Load Balancing for
    Applications on EKS*'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第14章*](B18129_14.xhtml#_idTextAnchor205)，*在EKS上为应用程序设置负载均衡*'
- en: '[*Chapter 15*](B18129_15.xhtml#_idTextAnchor220), *Working with AWS Fargate*'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第15章*](B18129_15.xhtml#_idTextAnchor220)，*与AWS Fargate一起工作*'
- en: '[*Chapter 16*](B18129_16.xhtml#_idTextAnchor232), *Working with a Service Mesh*'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第16章*](B18129_16.xhtml#_idTextAnchor232)，*与服务网格一起工作*'
