- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Automation with Infrastructure as Code
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用基础设施即代码进行自动化
- en: This chapter will explore how to use **Infrastructure as Code** (**IaC**) tools
    to automate the management of the various components of the Grafana observability
    platform. We will focus on **Ansible**, **Terraform**, and **Helm**, which allow
    teams to manage many aspects of their systems repeatably and automatically. This
    chapter divides the platform into the *collection and processing* layer, the *storage*
    layer, and the *visualization* layer and will outline how to automate each of
    these components. This chapter will provide the technical tools to create an easy-to-manage
    and very scalable observability platform, and combined with the information in
    [*Chapter 11*](B18277_11.xhtml#_idTextAnchor218), you will be well placed to lead
    your organization in easily leveraging the power of observability.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨如何使用**基础设施即代码**（**IaC**）工具来自动化管理 Grafana 可观察性平台的各个组成部分。我们将重点介绍**Ansible**、**Terraform**和**Helm**，这些工具可以帮助团队以可重复和自动化的方式管理其系统的多个方面。本章将平台分为*收集和处理*层、*存储*层和*可视化*层，并概述如何自动化每个组件。本章将提供技术工具来创建一个易于管理且高度可扩展的可观察性平台，并结合[*第11章*](B18277_11.xhtml#_idTextAnchor218)中的信息，你将能够引领你的组织轻松地利用可观察性的强大功能。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: Benefits of automating Grafana
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化 Grafana 的好处
- en: Introducing the components of observability systems
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍可观察性系统的组成部分
- en: Automating collection infrastructure with Helm or Ansible
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Helm 或 Ansible 自动化收集基础设施
- en: Getting to grips with the Grafana API
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 掌握 Grafana API
- en: Managing dashboards and alerts with Terraform or Ansible
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Terraform 或 Ansible 管理仪表盘和警报
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter involves working with Ansible, Terraform, and Helm, and it is
    recommended that you install them before you start reading. The chapter will also
    discuss a couple of concepts that you should have at least a passing familiarity
    with:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涉及使用 Ansible、Terraform 和 Helm，建议在开始阅读之前先安装它们。本章还将讨论几个你应该至少有所了解的概念：
- en: Kubernetes objects
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 对象
- en: The Kubernetes operator pattern
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 操作员模式
- en: Benefits of automating Grafana
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自动化 Grafana 的好处
- en: 'Observability tooling combines the collection, storage, and visualization of
    telemetry from many applications, infrastructure services, and other components
    of systems. Automation offers us a way of providing a testable, repeatable way
    of delivering these needs. Using industry-standard tools such as Helm, Ansible,
    and Terraform helps us maintain these systems in the long term. There are a lot
    of benefits to using automation, including the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 可观察性工具结合了来自许多应用程序、基础设施服务和其他系统组件的遥测数据的收集、存储和可视化。自动化为我们提供了一种可测试、可重复的方式来满足这些需求。使用
    Helm、Ansible 和 Terraform 等行业标准工具有助于我们长期维护这些系统。使用自动化有很多好处，包括以下几点：
- en: It reduces the risks associated with manual processes.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它减少了与手动流程相关的风险。
- en: 'Domain experts can provide automation for systems that developers interact
    with. This gives development teams confidence that they are using unfamiliar systems
    correctly. This knowledge comes in the following forms:'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 领域专家可以为开发人员交互的系统提供自动化服务。这使得开发团队有信心正确使用这些不熟悉的系统。这些知识的形式如下：
- en: Data architecture for telemetry
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遥测数据架构
- en: Repeatable system architecture
  id: totrans-18
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可重复的系统架构
- en: Best practices for managing data visualizations
  id: totrans-19
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据可视化管理的最佳实践
- en: By providing automation, domain experts are able to focus on higher-value work
    by letting teams self-serve using more straightforward and user-friendly systems.
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供自动化，领域专家能够通过让团队使用更简单、更易用的系统自助服务，从而专注于更高价值的工作。
- en: It provides a golden path so development teams can adopt observability easily
    and quickly and spend more time focusing on value-adding activities.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它提供了一条黄金路径，使得开发团队能够轻松、快速地采用可观察性，并能将更多时间专注于增值活动。
- en: It allows for easy scaling of best practices and operational processes. This
    is especially important for organizations that are growing, where a process that
    may work with a handful of teams does not scale to dozens of teams.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使最佳实践和运营流程的扩展变得更加容易。这对于正在增长的组织尤为重要，因为一个可能适用于少数团队的流程无法扩展到数十个团队。
- en: It ensures that cost information is always attributable.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它确保成本信息始终可以追溯。
- en: Now that we’ve introduced why you would want to use automation, let’s have a
    look at the components that make up an observability platform so we can easily
    automate the different aspects of the system.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了为什么你想使用自动化，接下来让我们看看构成可观察性平台的组件，这样我们就能轻松地自动化系统的不同方面。
- en: Introducing the components of observability systems
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍可观察性系统的组件
- en: 'Observability systems consist of many components involved in producing, consuming,
    transforming, storing, and using data. Over the course of this chapter, we will
    split these components into four distinct systems to be clear about which aspect
    of observability platforms we are discussing. The different aspects of automation
    will be of interest to different audiences. The systems we will discuss are as
    follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 可观察性系统包含许多组件，涉及数据的生产、消费、转换、存储和使用。在本章中，我们将把这些组件分成四个不同的系统，以便明确我们在讨论可观察性平台的哪个方面。自动化的不同方面将吸引不同的受众。我们将讨论的系统如下：
- en: '**Data production systems**: These are the systems that generate data. The
    applications, infrastructure, and even components of the data collection system
    will produce data. Let’s look at the key features:'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据生产系统**：这些是生成数据的系统。应用程序、基础设施，甚至数据收集系统的组件都会产生数据。我们来看看其关键特性：'
- en: These systems are managed by developers such as *Diego*, or by operations experts
    such as *Ophelia* (refer to [*Chapter 1*](B18277_01.xhtml#_idTextAnchor018) for
    details on these personas).
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些系统由开发人员如*Diego*或运营专家如*Ophelia*管理（有关这些角色的详细信息，请参见[**第1章**](B18277_01.xhtml#_idTextAnchor018)）。
- en: These systems are tested as part of the application- or component-testing process.
    If a data schema is in use, this can be validated using a tool such as JSON Schema.
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些系统作为应用程序或组件测试过程的一部分进行测试。如果使用数据模式，则可以通过诸如JSON模式之类的工具进行验证。
- en: '**Data collection systems**: These systems collect the logs, metrics, and traces
    generated by data-producing systems. They typically offer tools for transforming
    data. Their key features are the following:'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据收集系统**：这些系统收集由数据生产系统生成的日志、度量和跟踪。它们通常提供用于转换数据的工具。它们的关键特性如下：'
- en: These systems are often run by specialist operations teams, observability engineers,
    site reliability engineers, or platform engineers
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些系统通常由专业的运营团队、可观察性工程师、站点可靠性工程师或平台工程师管理。
- en: These systems are provisioned infrastructure
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些系统是配置的基础设施。
- en: Automation involves the use of IaC tools and static analysis tools (where available)
    to validate the infrastructure
  id: totrans-33
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化涉及使用基础设施即代码（IaC）工具和静态分析工具（如可用）来验证基础设施。
- en: '**Data storage systems**: These are the systems that store data and make it
    searchable. If your observability platform leverages SaaS tools, these systems
    will be provided by your vendor. Loki, Prometheus, Mimir, and Tempo are all examples
    of storage systems. Some of the important features of these systems include the
    following:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据存储系统**：这些是用于存储数据并使其可搜索的系统。如果你的可观察性平台利用了SaaS工具，那么这些系统将由你的供应商提供。Loki、Prometheus、Mimir
    和 Tempo 都是存储系统的例子。这些系统的一些重要特性包括：'
- en: These systems are often managed by dedicated third parties, but when they are
    managed within an organization, they will typically be managed by the same team
    as the data collection system
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些系统通常由专门的第三方管理，但当它们在组织内部管理时，通常会由与数据收集系统相同的团队管理。
- en: These systems are provisioned infrastructure
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些系统是配置的基础设施。
- en: Automation involves the use of IaC to provision on-prem resources, or leverages
    SaaS tooling such as Grafana Labs with IaC configuration
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化涉及使用IaC来配置本地资源，或者利用SaaS工具，如使用Grafana Labs与IaC配置。
- en: '**Data visualization systems**: These are the systems that allow users to search
    the data stored in the storage systems and produce visualizations, alerts, and
    other methods of understanding the data. Grafana is an example of a visualization
    system. The following are some important features of such systems:'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**数据可视化系统**：这些是允许用户搜索存储在存储系统中的数据，并生成可视化、警报和其他理解数据的方法的系统。Grafana 是一个可视化系统的例子。以下是此类系统的一些重要特性：'
- en: The management of this layer is typically a shared responsibility. The developers
    and operators who manage a particular system should be empowered to take ownership
    of their dashboards. The team managing the collection and storage layers will
    typically be the team empowering the rest of the organization.
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这一层的管理通常是共享责任。管理特定系统的开发人员和运维人员应该被授权负责他们的仪表盘。管理数据收集和存储层的团队通常是赋能整个组织的团队。
- en: These systems are provisioned infrastructure.
  id: totrans-40
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这些系统是预配置的基础设施。
- en: Automation involves the use of IaC to provision on-prem resources, or leveraging
    SaaS tooling such as Grafana Labs, with IaC configuration.
  id: totrans-41
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化涉及使用基础设施即代码（IaC）来预配置本地资源，或者利用像 Grafana Labs 这样的 SaaS 工具，结合 IaC 配置。
- en: In this chapter, we will discuss systems *2*, *3*, and *4* in the preceding
    list. *System 1*, while important, is a very broad area and the automation strategies
    differ for different types of data producers. However, in most cases, teams can
    rely on the testing done by the libraries they consume, or the third-party systems
    they run.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论前面列表中的*系统 2*、*系统 3* 和 *系统 4*。虽然*系统 1*很重要，但它是一个非常广泛的领域，且自动化策略对于不同类型的数据生产者有所不同。然而，在大多数情况下，团队可以依赖他们所使用的库进行的测试，或者他们运行的第三方系统。
- en: Let’s start by looking at how we can use Terraform or Ansible to deploy data
    collection systems.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们先来看看如何使用 Terraform 或 Ansible 来部署数据收集系统。
- en: Automating collection infrastructure with Helm or Ansible
  id: totrans-44
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Helm 或 Ansible 自动化收集基础设施
- en: 'Automating the installation of the infrastructure used to collect telemetry
    is a critical piece of building a great observability platform. The tools to support
    this depend on the infrastructure you are deploying to. In this section, we will
    examine the installation of the **OpenTelemetry Collector** and **Grafana Agent**
    using the following tools:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化安装用于收集遥测数据的基础设施是构建一个优秀可观察性平台的关键部分。支持这些功能的工具取决于你部署的基础设施。在这一部分，我们将通过以下工具来研究如何安装**OpenTelemetry
    Collector**和**Grafana Agent**：
- en: '**Helm** is a tool for packaging and managing Kubernetes applications. A Helm
    chart contains all the configuration files for the various Kubernetes components
    needed for an application, and typically handles setting the variables for the
    application. We will be using Helm in a Kubernetes environment.'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Helm** 是一个用于打包和管理 Kubernetes 应用程序的工具。Helm 图表包含了应用程序所需的各种 Kubernetes 组件的所有配置文件，通常处理应用程序的变量设置。我们将在
    Kubernetes 环境中使用 Helm。'
- en: '**Ansible** is a tool for standardizing operations into repeatable playbooks.
    It uses simple YAML configuration files to define the actions to be taken and
    leverages OpenSSH to connect to the target servers on which the actions are to
    be taken. We’ll be using Ansible in a virtual or bare-metal environment, but it
    can be used to manage Kubernetes environments as well.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ansible** 是一个将操作标准化为可重复执行的剧本的工具。它使用简单的 YAML 配置文件来定义需要执行的操作，并利用 OpenSSH 连接到目标服务器以执行操作。我们将在虚拟或裸机环境中使用
    Ansible，但它也可以用来管理 Kubernetes 环境。'
- en: Important note
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: OpenTelemetry and Grafana both offer a Kubernetes operator, which can be installed
    using Helm. We will provide an overview of these tools as well.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 和 Grafana 都提供了 Kubernetes 操作符，可以通过 Helm 安装。我们也会概述这些工具。
- en: Now let’s look at how we can use Helm and Ansible to automate the installation
    of the OpenTelemetry Collector and Grafana Agent.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看如何使用 Helm 和 Ansible 来自动化安装 OpenTelemetry Collector 和 Grafana Agent。
- en: Automating the installation of the OpenTelemetry Collector
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动化安装 OpenTelemetry Collector
- en: In this book, we have been using the OpenTelemetry Collector to collect data
    from the OpenTelemetry demo application and send it into our Grafana instance.
    First, we’ll use the configuration we have already deployed to explore using the
    Helm chart made by OpenTelemetry to deploy the collector into a Kubernetes cluster.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们一直使用 OpenTelemetry Collector 从 OpenTelemetry 演示应用程序收集数据并将其发送到我们的 Grafana
    实例。首先，我们将使用已经部署的配置，探索使用 OpenTelemetry 提供的 Helm 图表将 Collector 部署到 Kubernetes 集群中。
- en: OpenTelemetry Collector Helm chart
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenTelemetry Collector Helm 图表
- en: We first installed the OpenTelemetry Helm chart in [*Chapter 3*](B18277_03.xhtml#_idTextAnchor063),
    and then updated the configuration in *Chapters 4*, *5*, and *6*. OpenTelemetry
    provides detailed information about the configuration options that are available
    in its Git repository at https://github.com/open-telemetry/opentelemetry-helm-charts/tree/main/charts/opentelemetry-collector.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在[*第3章*](B18277_03.xhtml#_idTextAnchor063)安装了OpenTelemetry Helm图表，然后在*第4章*、*第5章*和*第6章*中更新了配置。OpenTelemetry在其Git仓库中提供了关于可用配置选项的详细信息，地址为https://github.com/open-telemetry/opentelemetry-helm-charts/tree/main/charts/opentelemetry-collector。
- en: Let’s look at the final configuration that we applied in [*Chapter 6*](B18277_06.xhtml#_idTextAnchor134)
    and see how we configure the OTEL Helm chart. You can find this file in the Git
    repository at `/chapter6/OTEL-Collector.yaml`.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我们在[*第6章*](B18277_06.xhtml#_idTextAnchor134)中应用的最终配置，看看我们是如何配置OTEL Helm图表的。你可以在Git仓库中的`/chapter6/OTEL-Collector.yaml`文件中找到它。
- en: 'The first configuration block we’ll look at is `mode`, which describes how
    the collector is going to be deployed in Kubernetes. The options available are
    `deployment`, `daemonset`, and `statefulset`. Here, we use the `deployment` option:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先查看的配置块是`mode`，它描述了收集器将在Kubernetes中如何部署。可用的选项有`deployment`、`daemonset`和`statefulset`。在这里，我们使用`deployment`选项：
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Let’s explore the available options in some detail:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细探索一下可用选项：
- en: A `deployment` is deployed with a fixed number of Pods, which is the `replicaCount`
    in Kubernetes terms. For our reference system, we used this mode as we know the
    system will be deployed to a single-node Kubernetes cluster, and it allows us
    to combine presets that would usually be used independently in a multi-node cluster.
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`deployment`会以固定数量的Pod进行部署，这就是Kubernetes中的`replicaCount`。在我们的参考系统中，我们使用了这种模式，因为我们知道系统将部署到单节点Kubernetes集群，并且它允许我们将通常在多节点集群中独立使用的预设组合起来。'
- en: A `daemonset` is deployed with a collector to every node in a cluster.
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个`daemonset`会与一个收集器一起部署到集群中的每个节点。
- en: A `statefulset` is deployed with unique network interfaces and consistent deployments.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`statefulset`会以独特的网络接口和一致的部署进行部署。'
- en: We discuss selecting the appropriate mode in [*Chapter 11*](B18277_11.xhtml#_idTextAnchor218)
    when we discuss architecture. These deployment modes can also be combined to provide
    specific functionality in a Kubernetes cluster.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在讨论架构时会在[*第11章*](B18277_11.xhtml#_idTextAnchor218)中讨论如何选择适当的模式。这些部署模式也可以组合在一起，以在Kubernetes集群中提供特定功能。
- en: 'The next configuration block we’ll look at is `presets`:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将查看的配置块是`presets`：
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'As you can see, this configuration involves simply enabling or disabling different
    functions. Let’s look at the parameters in detail:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这个配置只涉及启用或禁用不同的功能。让我们详细看看这些参数：
- en: The `logsCollection` parameter tells the collector to collect logs from the
    standard output of Kubernetes containers. We are not including the collector logs
    as this can cause a logging cascade, where the collector reads its own log output
    and writes the collected logs to that output, which are then read again. In real-life
    setups, it is recommended to only use the `logsCollection` parameter in `daemonset`
    mode.
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`logsCollection`参数告诉收集器从Kubernetes容器的标准输出收集日志。我们没有包括收集器日志，因为这可能会导致日志级联现象，即收集器读取它自己的日志输出并将收集的日志写入该输出，然后再读取。这种设置下，建议仅在`daemonset`模式下使用`logsCollection`参数。'
- en: The `kubernetesAttributes` parameter collects Kubernetes metadata as the collector
    receives logs, metrics, and traces. This includes information such as `k8s.pod.name`,
    `k8s.namespace.name`, and `k8s.node.name`. The attribute collector is safe to
    use in all modes.
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubernetesAttributes`参数会在收集器接收日志、指标和追踪数据时收集Kubernetes元数据。这包括如`k8s.pod.name`、`k8s.namespace.name`和`k8s.node.name`等信息。属性收集器在所有模式中都是安全使用的。'
- en: The `kubernetesEvents` parameter collects the events that occur in the cluster
    and publishes them in the log pipeline. Effectively, every event that occurs in
    the cluster receives a log entry in Loki with this configuration. Cluster events
    include things such as Pod creations and deletions, among others. It’s best practice
    to use `kubernetesEvents` in the `deployment` or `statefulset` modes to prevent
    the duplication of events.
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubernetesEvents`参数会收集集群中发生的事件，并将它们发布到日志管道中。实际上，集群中发生的每个事件都会在Loki中收到一条日志条目，使用此配置。集群事件包括Pod创建和删除等。最佳实践是在`deployment`或`statefulset`模式下使用`kubernetesEvents`，以避免事件的重复。'
- en: 'The three metrics options collect metrics about the system:'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 三个指标选项会收集关于系统的指标：
- en: '`clusterMetrics` looks at the full cluster. This should be used in `deployment`
    or `statefulset` modes.'
  id: totrans-70
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`clusterMetrics` 查看整个集群。应该在 `deployment` 或 `statefulset` 模式下使用。'
- en: '`kubeletMetrics` collects metrics from the kubelet about the node, Pods, and
    containers it is managing. This should be used in `daemonset` mode.'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubeletMetrics` 收集来自 kubelet 的有关节点、Pod 和容器的指标。应在 `daemonset` 模式下使用。'
- en: '`hostMetrics` collects data directly from the host, such as CPU, memory, and
    disk usage. This should be used in `daemonset` mode.'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hostMetrics` 直接从主机收集数据，例如 CPU、内存和磁盘使用情况。应在 `daemonset` 模式下使用。'
- en: 'We’ll skip over a few blocks that are standard Kubernetes configurations and
    consider the `config` block next. The `config` block has a few subblocks:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将跳过一些标准的 Kubernetes 配置块，接下来考虑 `config` 块。`config` 块有几个子块：
- en: 'The telemetry pipeline includes the following:'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遥测管道包括以下内容：
- en: '`receivers`: Receivers are at the start of a pipeline. They receive data and
    translate it to add it to the pipeline for other components to use.'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`receivers`：接收器位于管道的开始部分。它们接收数据并进行转换，将数据添加到管道中，供其他组件使用。'
- en: '`processors`: Processors are used in a pipeline to carry out various functions.
    There are supported processors and contributed processors available.'
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`processors`：处理器用于管道中执行各种功能。有支持的处理器和贡献的处理器可供使用。'
- en: '`exporters`: Exporters come at the end of a pipeline. They receive data in
    the internal pipeline format and translate it to send the data onwards.'
  id: totrans-77
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`exporters`：出口器位于管道的末端。它们接收以内部管道格式传递的数据，并进行转换以将数据发送到下一阶段。'
- en: '`connectors`: These combine `receivers` and `exporters` to link pipelines together.
    `connectors` act as `exporters` to send the data from one pipeline onwards, and
    as `receivers` to take that data and add it to another pipeline.'
  id: totrans-78
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`connectors`：这些将 `receivers` 和 `exporters` 结合起来，连接管道。`connectors` 充当 `exporters`，将数据从一个管道发送到下一个管道，同时充当
    `receivers`，接收数据并将其添加到另一个管道中。'
- en: Separate to the pipeline are `extensions`, which add additional functionality
    to the collector, but do not need access to the telemetry data in the pipelines.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与管道分开的是 `extensions`，它们为收集器添加额外的功能，但不需要访问管道中的遥测数据。
- en: Finally, there is a `service` block, which is used to define the pipelines and
    extensions in use.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，还有一个 `service` 块，用于定义正在使用的管道和扩展。
- en: 'The only extension we are using in our `config` block is the `health_check`
    extension:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 `config` 块中使用的唯一扩展是 `health_check` 扩展：
- en: '[PRE2]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This enables an endpoint that can be used for a liveness and/or readiness probe
    in the Kubernetes cluster. This is helpful for you to be able to see easily whether
    the collector is working as expected.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这启用了一个端点，可用于 Kubernetes 集群中的存活性和/或就绪性探针。这对你来说非常有用，可以轻松查看收集器是否按预期工作。
- en: 'In our `receivers` block we have configured two receivers, `otlp` and `prometheus`:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 `receivers` 块中，我们配置了两个接收器：`otlp` 和 `prometheus`：
- en: '[PRE3]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Let’s look at these receivers more closely:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更仔细地看看这些接收器：
- en: The `OTLP` receiver configures our collector instance to expose port `4318`
    on `127.0.0.1` on the Kubernetes node, which allows the demo applications to submit
    telemetry easily.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OTLP` 接收器配置我们的收集器实例，在 Kubernetes 节点的 `127.0.0.1` 上暴露 `4318` 端口，这使得演示应用程序能够轻松地提交遥测数据。'
- en: The `Prometheus` receiver is used to collect metrics from the collector itself.
    This receiver config shows an example of relabeling, where we take `meta_kuberentes_pod_annotation_prometheus_io_port`
    and rename it with `__address__`, which is the standard used in OTLP.
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Prometheus` 接收器用于收集来自收集器本身的指标。此接收器配置显示了一个重新标记的示例，我们将 `meta_kuberentes_pod_annotation_prometheus_io_port`
    重新命名为 `__address__`，这是 OTLP 中使用的标准。'
- en: In our configuration, we have set up the `k8sattributes`, `resource`, and `attributes`
    processors. The `k8sattributes` processor extracts attributes from the kubelet
    and adds them to the telemetry in the pipelines. The `resource` and `attributes`
    processors will insert or modify the resource or attributes respectively. We’ll
    not discuss these concepts in detail, but resources are used to identify the source
    that is producing telemetry.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的配置中，我们设置了 `k8sattributes`、`resource` 和 `attributes` 处理器。`k8sattributes`
    处理器从 kubelet 中提取属性，并将其添加到管道中的遥测数据中。`resource` 和 `attributes` 处理器分别插入或修改资源或属性。我们不会详细讨论这些概念，但资源用于标识生产遥测数据的源。
- en: 'In our configuration, we are using both the `spanmetrics` and `servicegraph`
    connectors:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的配置中，我们使用了 `spanmetrics` 和 `servicegraph` 两个连接器：
- en: '[PRE4]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Both `connectors` are used to export the data from the `traces` pipeline and
    receive it in the `metrics` pipeline. `spanmetrics` collects the `servicegraph`
    generates metrics that describe the relationship between services, these metrics
    allow the service graphs to be shown in Tempo.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 两个`connectors`用于从`traces`管道导出数据并将其接收在`metrics`管道中。`spanmetrics`收集`servicegraph`生成的度量，这些度量描述了服务之间的关系，这些度量使得服务图能够在Tempo中显示。
- en: 'The final subblock in our `config` block is `services`. This subblock defines
    the extensions to be loaded and the configuration of the pipelines. Each pipeline
    (`logs`, `metrics`, and `traces`) defines the `receivers`, `processors`, and `exporters`
    used. Let’s look at the `metrics` pipeline as it is the most complex:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我们`config`块中的最后一个子块是`services`。这个子块定义了要加载的扩展和管道的配置。每个管道（`logs`、`metrics`和`traces`）定义了使用的`receivers`、`processors`和`exporters`。让我们来看一下`metrics`管道，因为它是最复杂的：
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The receivers are `OTLP`, `spanmetrics`, and `servicegraph` as discussed previously.
    We then instruct the pipeline to use the `memory_limiter`, `filter`, `transform`,
    and `batch` processors, in the order listed. You may notice that our filter is
    named `ottl` using the syntax of `processor/name`, which is useful when you need
    to use the same processor with different configurations. Finally, the pipeline
    uses the `prometheusremotewrite` exporters and logging to output data.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，receivers是`OTLP`、`spanmetrics`和`servicegraph`。我们接着指示管道按照列出的顺序使用`memory_limiter`、`filter`、`transform`和`batch`处理器。你可能会注意到我们的过滤器命名为`ottl`，采用`processor/name`的语法，这在需要使用相同的处理器并配置不同参数时非常有用。最后，管道使用`prometheusremotewrite`的exporters并通过日志输出数据。
- en: 'You may have noticed that the exporters are not defined in the `/chapter6/OTEL-Collector.yaml`
    file – this is because they are defined in `/OTEL-Creds.yaml`, and this highlights
    a very useful feature of Helm, which is the ability to separate out configuration
    files based on their function. When we install the Helm chart, we use a command
    such as the following:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，`/chapter6/OTEL-Collector.yaml`文件中没有定义exporters——这是因为它们在`/OTEL-Creds.yaml`中定义，这也突显了Helm的一个非常有用的功能，即能够根据功能分离配置文件。当我们安装Helm
    chart时，我们使用类似下面的命令：
- en: '[PRE6]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The `-f` or `--values` option can be used multiple times for multiple YAML files
    – if there are conflicts, then precedence is always given to the last file used.
    By structuring the YAML files in such a way, we can split the full configuration
    in ways that allow us to protect secret information, such as API keys, while still
    making our main configuration easily available. We can also use this feature for
    other purposes such as overriding a default configuration in a test environment.
    It’s important to be careful with precedence here as duplicate arrays will not
    be merged. Deploying the collector in this way is fantastic in a lot of situations.
    However, it has a limitation – any time there is a change to the configuration,
    or a new version of the collector is to be installed, a Helm `install` or `upgrade`
    operation needs to be carried out. This introduces the need for a system that
    has knowledge of and access to each cluster in which the collector will be deployed,
    which can introduce bottlenecks and security risks. Let’s look at the OpenTelemetry
    Operator, which offers solutions to these problems.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '`-f` 或 `--values` 选项可以对多个YAML文件使用多次——如果存在冲突，则始终优先使用最后一个文件。通过这种方式结构化YAML文件，我们可以将完整配置拆分成不同部分，以保护敏感信息（如API密钥），同时仍然使主配置易于访问。我们还可以将此功能用于其他目的，比如在测试环境中覆盖默认配置。这里需要小心优先级问题，因为重复的数组不会合并。以这种方式部署collector在很多情况下非常棒。然而，它有一个限制——每当配置发生变化，或需要安装新版本的collector时，都需要进行Helm的`install`或`upgrade`操作。这就需要一个了解并可以访问每个集群的系统，才能部署collector，这可能会带来瓶颈和安全风险。让我们来看看OpenTelemetry操作符，它提供了解决这些问题的方法。'
- en: OpenTelemetry Kubernetes Operator
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenTelemetry Kubernetes 操作符
- en: OpenTelemetry also offers a Kubernetes operator to manage both the OpenTelemetry
    Collector and allow for auto-instrumentation of workloads. This operator is still
    in active development and the feature set is expected to increase.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry还提供了一个Kubernetes操作符来管理OpenTelemetry Collector，并允许对工作负载进行自动化仪器化。这个操作符仍在积极开发中，预计功能集会增加。
- en: 'Kubernetes operators use **Custom Resource Definitions** (**CRDs**) to provide
    extensions to the Kubernetes API, which are used by the operators to manage the
    system. The advantages of using an operator include the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes Operator 使用 **自定义资源定义**（**CRDs**）为 Kubernetes API 提供扩展，这些扩展被 Operator
    用来管理系统。使用 Operator 的优势包括以下几点：
- en: The complex logic involved in managing the OpenTelemetry Operator or the auto-instrumentation
    system can be designed by the experts working on the OpenTelemetry projects. For
    the person responsible for managing an OpenTelemetry installation, the operator
    offers a defined CRD specification against which to validate the proposed configuration
    in a CI/CD pipeline.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理 OpenTelemetry Operator 或自动化仪器化系统所涉及的复杂逻辑可以由 OpenTelemetry 项目中的专家设计。对于负责管理
    OpenTelemetry 安装的人来说，Operator 提供了一个定义好的 CRD 规范，可以用来在 CI/CD 管道中验证提议的配置。
- en: The OpenTelemetry operator also allows for limited automated upgrades. Minor
    and major version updates still need to be applied via a Helm upgrade due to the
    possibility of breaking changes.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenTelemetry Operator 还允许有限的自动化升级。由于可能会有破坏性变更，次要和主要版本的更新仍需要通过 Helm 升级来应用。
- en: It can be combined with GitOps tooling to move from a solution where a central
    system must know each cluster and have the necessary credentials to deploy to
    them, to a solution where each cluster reads the desired configuration from a
    central version-controlled repository.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它可以与 GitOps 工具结合使用，将解决方案从一个必须知道每个集群并具有必要凭证来部署到这些集群的中央系统，转变为一个每个集群从中央版本控制的仓库中读取所需配置的解决方案。
- en: The operator really excels when it comes to making the OpenTelemetry auto-instrumentation
    easily accessible to applications by adding annotations. For the majority of use
    cases, auto-instrumentation will provide ample metric and trace telemetry to understand
    an application.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当涉及到通过添加注解使 OpenTelemetry 自动仪器化更容易被应用程序访问时，Operator 真正表现出色。对于大多数使用场景，自动仪器化将提供充足的度量和追踪遥测，以便了解应用程序。
- en: The OpenTelemetry Collector can also be installed on virtual or bare-metal servers,
    this process can be automated with tools such as Ansible. Let’s see how you might
    approach this.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry Collector 也可以安装在虚拟机或裸金属服务器上，这个过程可以通过如 Ansible 之类的工具来自动化。让我们来看看如何处理这个问题。
- en: OpenTelemetry and Ansible
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: OpenTelemetry 和 Ansible
- en: 'OpenTelemetry does not provide an official collection for Ansible. It provides
    packaged versions of the collector for Alpine-, Debian-, and Red Hat-based systems
    as `.apk`, `.deb`, and `.rpm` files respectively. Using `community.general.apk`,
    `ansible.builtin.apt`, or `ansible.builtin.yum`, the package can be installed
    with a configuration similar to the following:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry 不提供 Ansible 的官方集合。它分别为 Alpine、Debian 和 Red Hat 系统提供打包版本的 Collector，格式为
    `.apk`、`.deb` 和 `.rpm` 文件。使用 `community.general.apk`、`ansible.builtin.apt` 或 `ansible.builtin.yum`，可以用类似以下配置的方式安装此包：
- en: '[PRE7]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'With the package installed, the only other thing to do to configure the collector
    is to apply a configuration file. The default configuration file is located at
    `/etc/otelcol/config.yaml` and is used when systemd starts the collector. Ansible
    can overwrite this file or modify it in place. This could be done with the following
    configuration:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 安装好软件包后，配置收集器所需做的唯一其他事情是应用配置文件。默认配置文件位于 `/etc/otelcol/config.yaml`，并在 systemd
    启动收集器时使用。Ansible 可以覆盖此文件或直接修改它。可以使用以下配置来完成这项工作：
- en: '[PRE8]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: We have looked at the OpenTelemetry agent a lot during this book. One major
    reason for this is that OpenTelemetry also offers the Demo application we have
    used to produce realistic sample data. Next, let’s take a look at Grafana Agent.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们已经多次讨论了 OpenTelemetry 代理。这样做的一个主要原因是，OpenTelemetry 还提供了我们用来生成真实样本数据的
    Demo 应用程序。接下来，让我们来看看 Grafana Agent。
- en: Automating the installation of Grafana Agent
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 自动化安装 Grafana Agent
- en: Grafana produces its own agent, which is recommended by Grafana for use with
    its cloud platform. Grafana Agent also provides automation options, which we will
    introduce in this section.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana 生产了自己的代理，Grafana 推荐在其云平台中使用这个代理。Grafana Agent 还提供自动化选项，我们将在本节中介绍这些选项。
- en: Grafana Agent Helm charts
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Grafana Agent Helm charts
- en: Grafana offers two Helm charts, the `grafana-agent` chart and the configuration
    options, please check out the Helm chart documentation at https://github.com/grafana/agent/tree/main/operations/helm/charts/grafana-agent.
    Similarly, the documentation for the `agent-operator` chart can be found at [https://github.com/grafana/helm-charts/tree/main/charts/agent-operator#upgrading-an-existing-release-to-a-new-major-version](https://github.com/grafana/helm-charts/tree/main/charts/agent-operator#upgrading-an-existing-release-to-a-new-major-version).
    Details of the available CRDs are documented in the Operator architecture documentation
    at https://github.com/grafana/agent/blob/v0.36.2/docs/sources/operator/architecture.md.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana 提供了两个 Helm 图表，`grafana-agent` 图表和配置选项，请查看 Helm 图表文档 [https://github.com/grafana/agent/tree/main/operations/helm/charts/grafana-agent](https://github.com/grafana/agent/tree/main/operations/helm/charts/grafana-agent)。类似地，`agent-operator`
    图表的文档可以在 [https://github.com/grafana/helm-charts/tree/main/charts/agent-operator#upgrading-an-existing-release-to-a-new-major-version](https://github.com/grafana/helm-charts/tree/main/charts/agent-operator#upgrading-an-existing-release-to-a-new-major-version)
    找到。可用的 CRD 详细信息可以在操作员架构文档中找到 [https://github.com/grafana/agent/blob/v0.36.2/docs/sources/operator/architecture.md](https://github.com/grafana/agent/blob/v0.36.2/docs/sources/operator/architecture.md)。
- en: Grafana Agent and Ansible
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Grafana Agent 和 Ansible
- en: Unlike OpenTelemetry, Grafana maintains an Ansible collection (https://docs.ansible.com/ansible/latest/collections/grafana/grafana)
    that includes tools to manage collection, storage, and visualization systems,
    and we will revisit it in later sections.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 与 OpenTelemetry 不同，Grafana 维护着一个 Ansible 集合（[https://docs.ansible.com/ansible/latest/collections/grafana/grafana](https://docs.ansible.com/ansible/latest/collections/grafana/grafana)），其中包含管理收集、存储和可视化系统的工具，我们将在后续章节中重新访问它。
- en: 'The included `grafana_agent` role is used to manage data collection and will
    install the agent on Red Hat, Ubuntu, Debian, CentOS, and Fedora distributions.
    This role can be used as follows:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 包含的 `grafana_agent` 角色用于管理数据收集，并将代理安装在 Red Hat、Ubuntu、Debian、CentOS 和 Fedora
    发行版上。此角色可以按如下方式使用：
- en: '[PRE9]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The configuration for logs, metrics, and traces is specific to that telemetry
    type and the documentation available from Grafana covers using that configuration
    to manage the Agent.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 日志、指标和追踪的配置特定于该遥测类型，Grafana 提供的文档涵盖了使用该配置来管理代理的内容。
- en: Getting to grips with the Grafana API
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 熟悉 Grafana API
- en: Grafana offers a full-featured API for both Grafana Cloud and Grafana itself.
    This API is the same API used by the frontend, which means that we can also drive
    the functions of Grafana using either direct API calls in a script, or an IaC
    tool such as **Terraform**. We’ll start by having a high-level look at the APIs
    available in Grafana Cloud and Grafana, then we’ll look at the Grafana Terraform
    module and the Ansible collection, and see how to use them to manage a Grafana
    Cloud instance.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana 提供了一个功能齐全的 API，适用于 Grafana Cloud 和 Grafana 本身。这个 API 与前端使用的相同，这意味着我们也可以通过直接的
    API 调用或使用类似 **Terraform** 的 IaC 工具来操作 Grafana 的功能。我们将首先对 Grafana Cloud 和 Grafana
    中可用的 API 进行高层次的了解，然后我们将研究 Grafana 的 Terraform 模块和 Ansible 集合，看看如何使用它们来管理 Grafana
    Cloud 实例。
- en: Exploring the Grafana Cloud API
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 Grafana Cloud API
- en: 'The Grafana Cloud API is used to manage all aspects of a Grafana Cloud SaaS
    installation. Let’s have a high-level look at the functions provided by the Grafana
    Cloud API:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana Cloud API 用于管理 Grafana Cloud SaaS 安装的各个方面。让我们高层次地了解一下 Grafana Cloud
    API 提供的功能：
- en: '`accessPolicyId`, which is the unique ID for an access policy object.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`accessPolicyId`，即访问策略对象的唯一 ID。'
- en: '**Stacks**: These endpoints manage Grafana Cloud stacks. The following are
    their key functions:'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**堆栈**：这些端点管理 Grafana Cloud 堆栈。以下是它们的主要功能：'
- en: Create, read, update, and delete functions for stacks
  id: totrans-128
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 堆栈的创建、读取、更新和删除功能
- en: Restart Grafana on a specific stack
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重新启动特定堆栈上的 Grafana
- en: List data sources on a specific stack
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 列出特定堆栈上的数据源
- en: '**Grafana plugins**: These endpoints manage plugins installed on Grafana instances
    related to a stack. Their functions include creating, reading, updating, and deleting
    functions for Grafana plugins installed on a specific stack.'
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Grafana 插件**：这些端点管理与堆栈相关的 Grafana 实例上安装的插件。它们的功能包括创建、读取、更新和删除安装在特定堆栈上的 Grafana
    插件的功能。'
- en: '**Regions**: These API endpoints list the Grafana Cloud regions available.
    They are used to read functions for the available Grafana Cloud regions that can
    be used to host a stack.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**区域**：这些 API 端点列出了可用的 Grafana Cloud 区域。它们用于读取可以用来托管堆栈的可用 Grafana Cloud 区域的功能。'
- en: '**API keys**: These endpoints were for managing Cloud API keys and their major
    functions are the create, read, and delete functions for API keys. These endpoints
    are now deprecated as Grafana has moved to authentication techniques using access
    policies and tokens. API key endpoints will be removed in a future update.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**API 密钥**：这些端点用于管理云 API 密钥，其主要功能是创建、读取和删除 API 密钥。这些端点现已弃用，因为 Grafana 已转向使用基于访问策略和令牌的认证技术。API
    密钥端点将在未来的更新中被移除。'
- en: We will discuss access policies and tokens in more detail in [*Chapter 11*](B18277_11.xhtml#_idTextAnchor218)
    where we discuss **access levels** as part of architecting a great observability
    platform. All the Grafana Cloud endpoints have an associated access policy, and
    the token used must be authorized with that policy for a successful response.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在 [*第11章*](B18277_11.xhtml#_idTextAnchor218) 中更详细地讨论访问策略和令牌，其中我们会讨论 **访问级别**，作为构建一个优秀可观察性平台的一部分。所有
    Grafana Cloud 端点都有一个关联的访问策略，且所使用的令牌必须获得该策略的授权才能成功响应。
- en: More detailed information is available in Grafana’s documentation at https://grafana.com/docs/grafana-cloud/developer-resources/api-reference/cloud-api/,
    including information on the parameters and details needed in a request as well
    as example requests and responses.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 更详细的信息可以在 Grafana 的文档中找到，网址为 https://grafana.com/docs/grafana-cloud/developer-resources/api-reference/cloud-api/，其中包括请求中所需的参数和详细信息，以及示例请求和响应。
- en: We’ve now reviewed the API endpoints. Next, we'll discuss Grafana’s offerings
    of both a Terraform provider and the Ansible collection, which can be used to
    interact with the aforementioned APIs using IaC automation.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经回顾了 API 端点。接下来，我们将讨论 Grafana 提供的 Terraform 提供者和 Ansible 集合，这些工具可以用于通过基础设施即代码（IaC）自动化与上述
    API 进行交互。
- en: Using Terraform and Ansible for Grafana Cloud
  id: totrans-137
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Terraform 和 Ansible 管理 Grafana Cloud
- en: Grafana provides both a Terraform provider and an Ansible collection for use
    in managing organizations’ Cloud instances. Let’s explore how we can use these
    tools with the Grafana Cloud API to manage a Grafana Cloud instance.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana 提供了 Terraform 提供者和 Ansible 集合，用于管理组织的云实例。让我们来探讨如何利用这些工具通过 Grafana Cloud
    API 来管理 Grafana Cloud 实例。
- en: The Grafana Terraform provider
  id: totrans-139
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Grafana Terraform 提供者
- en: The **Grafana Terraform provider** has resources that match the Cloud API endpoints
    we have discussed. The provider also offers resources for other Grafana API endpoints,
    which we will cover when we discuss managing dashboards and alerts later in this
    chapter. The official documentation for the provider can be found on the Terraform
    Registry at [https://registry.terraform.io/providers/grafana/grafana/latest/docs](https://registry.terraform.io/providers/grafana/grafana/latest/docs).
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**Grafana Terraform 提供者**具有与我们讨论过的云 API 端点相对应的资源。该提供者还提供用于其他 Grafana API 端点的资源，我们将在本章后面讨论管理仪表板和警报时介绍这些资源。该提供者的官方文档可以在
    Terraform Registry 上找到，网址为 [https://registry.terraform.io/providers/grafana/grafana/latest/docs](https://registry.terraform.io/providers/grafana/grafana/latest/docs)。'
- en: Important note
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: This chapter was written with version 2.6.1 of the Grafana Terraform provider.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是基于 Grafana Terraform 提供者的 2.6.1 版本编写的。
- en: 'Here are some of the commonly used Terraform resources with examples of their
    use:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些常用的 Terraform 资源，并附有使用示例：
- en: 'First, let’s have a look at using the provider. The `grafana_cloud_stack` data
    provider is used to find a stack called `acme-preprod`, which we will use later
    to specify where our access policy is to be created:'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，让我们看一下如何使用提供者。`grafana_cloud_stack` 数据提供者用于查找一个名为 `acme-preprod` 的堆栈，我们稍后将使用它来指定我们的访问策略创建位置：
- en: '[PRE10]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `grafana_cloud_access_policy` resource allows us to create an access policy.
    Here, we set our `region` value to `us`, along with a name and a display name.
    Finally, we specify the scope of the policy – in this case, we want to be able
    to write logs, metrics, and traces. The `stack` ID we found earlier is then used
    to specify where to create this access policy:'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`grafana_cloud_access_policy` 资源允许我们创建一个访问策略。在这里，我们将 `region` 值设置为 `us`，并指定名称和显示名称。最后，我们指定策略的作用范围——在这种情况下，我们希望能够写入日志、指标和追踪。然后，我们之前找到的
    `stack` ID 将用于指定在哪里创建此访问策略：'
- en: '[PRE11]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Finally, the `grafana_cloud_access_policy_token` resource can be used to create
    a new token. We specify a region, the access policy to use, and a name. The token
    will then be able to be read from `grafana_cloud_access_policy_token.collector-token.token`:'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，`grafana_cloud_access_policy_token` 资源可用于创建一个新的令牌。我们指定区域、要使用的访问策略和名称。然后，令牌可以通过
    `grafana_cloud_access_policy_token.collector-token.token` 读取：
- en: '[PRE12]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'This isn’t the only thing we can do with the Grafana Terraform provider: we’ll
    consider another example later in this chapter when we examine managing dashboards
    and alerts. Typically, this would be combined with another provider to record
    this newly created token in a secrets management tool, such as **AWS Secrets Manager**
    or **HashiCorp Vault**, where it can be accessed whenever a collector is deployed.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是我们使用 Grafana Terraform 提供者能做的唯一事情：当我们讨论管理仪表盘和警报时，本章稍后会考虑另一个示例。通常，这会与另一个提供者结合使用，将新创建的令牌记录在秘密管理工具中，例如
    **AWS Secrets Manager** 或 **HashiCorp Vault**，以便在部署收集器时可以访问。
- en: Let’s look managing a Grafana Cloud system with another IaC tool provided by
    Grafana, the **Grafana** **Ansible collection**.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看如何使用 Grafana 提供的另一个 IaC 工具——**Grafana** **Ansible 集合**来管理 Grafana Cloud
    系统。
- en: The Grafana Ansible collection
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Grafana Ansible 集合
- en: The Grafana Ansible collection is not as feature rich as the Terraform provider
    for managing cloud instances. However, a lot of the functionality from the Grafana
    Cloud API can be accessed using the Ansible URI module. The official collection
    documentation is available on the Ansible site at [https://docs.ansible.com/ansible/latest/collections/grafana/grafana/](https://docs.ansible.com/ansible/latest/collections/grafana/grafana/).
    A community-provided collection is also available, but will not be discussed here.
    The relevant documentation is available at [https://docs.ansible.com/ansible/latest/collections/community/grafana/index.html](https://docs.ansible.com/ansible/latest/collections/community/grafana/index.html).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana Ansible 集合的功能不如 Terraform 提供者那样丰富，尤其是在管理云实例时。然而，可以通过 Ansible URI 模块访问许多来自
    Grafana Cloud API 的功能。官方集合文档可以在 Ansible 网站上找到，链接为：[https://docs.ansible.com/ansible/latest/collections/grafana/grafana/](https://docs.ansible.com/ansible/latest/collections/grafana/grafana/)。社区提供的集合也可用，但在此不做讨论。相关文档请参见：[https://docs.ansible.com/ansible/latest/collections/community/grafana/index.html](https://docs.ansible.com/ansible/latest/collections/community/grafana/index.html)。
- en: Important note
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: This chapter was written with version 2.2.3 of the Grafana Ansible collection.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 本章是在 Grafana Ansible 集合的 2.2.3 版本下编写的。
- en: 'We’ll look at managing a Grafana Cloud stack using Ansible. The `name` and
    `stack_slug` (this is the stack we are interacting with) values are set to the
    same string by convention. We then need to set the `region` value for the stack,
    along with the organization the stack will belong to using `org_slug`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将通过 Ansible 管理 Grafana Cloud 堆栈。`name` 和 `stack_slug`（这是我们正在交互的堆栈）值按照惯例被设置为相同的字符串。然后我们需要设置堆栈的
    `region` 值，以及使用 `org_slug` 设置堆栈将属于的组织：
- en: '[PRE13]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We’ve so far looked at the API for Grafana Cloud. This API is great for managing
    an observability platform in Grafana Cloud, but a lot of teams will be more interested
    in managing dashboards, alerts, and other items in the Grafana UI. Grafana provides
    another API to manage objects in the Grafana UI – let’s look at it now.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经看过了 Grafana Cloud 的 API。这个 API 非常适合管理 Grafana Cloud 中的可观察性平台，但许多团队可能更关注在
    Grafana UI 中管理仪表盘、警报和其他项目。Grafana 还提供了一个 API 来管理 Grafana UI 中的对象——让我们现在来看看。
- en: Exploring the Grafana API
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 Grafana API
- en: While the Grafana Cloud API is only used to manage Grafana Cloud SaaS instances,
    the **Grafana API** is very far reaching as Grafana has a lot of functionality.
    These APIs can be used on both Grafana Cloud and locally installed Grafana instances.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Grafana Cloud API 仅用于管理 Grafana Cloud SaaS 实例，但 **Grafana API** 的覆盖面非常广泛，因为
    Grafana 有很多功能。这些 API 可以用于 Grafana Cloud 和本地安装的 Grafana 实例。
- en: 'Similar to the Grafana Cloud API, all endpoints use role-based access control.
    However, the Grafana API offers an additional authentication option: service accounts.
    Service accounts should be used for any application that needs to interact with
    Grafana.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Grafana Cloud API 类似，所有端点都使用基于角色的访问控制。然而，Grafana API 提供了额外的认证选项：服务帐户。服务帐户应该用于任何需要与
    Grafana 交互的应用程序。
- en: 'As most teams will use a small subset of APIs frequently, we will only discuss
    a few APIs here. However, there are a lot of other APIs that can be used to automate
    the management of a Grafana instance. Let’s take a closer look at some commonly
    used APIs:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 由于大多数团队会频繁使用一小部分 API，因此我们这里只讨论一些常见的 API。然而，还有很多其他 API 可以用来自动化管理 Grafana 实例。让我们深入了解一些常用的
    API：
- en: '**Dashboard and Folder**: These endpoints manage dashboards and folders in
    Grafana. Their functions include the following:'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仪表盘和文件夹**：这些端点用于管理 Grafana 中的仪表盘和文件夹。它们的功能包括：'
- en: Create, read, update, and delete functions for dashboards or folders
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建、读取、更新和删除仪表盘或文件夹的功能
- en: Create, read, update, and delete the tags on a dashboard
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建、读取、更新和删除仪表盘上的标签
- en: Dashboards and folders have both an ID and a UID. The ID is only unique to a
    specific Grafana installation, while the UID is unique across installations.
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 仪表盘和文件夹都有 ID 和 UID。ID 仅在特定的 Grafana 安装中是唯一的，而 UID 在不同的安装中是唯一的。
- en: '`1` = `View`, `2` = `Edit`, `4` = `Admin`. Permissions can be set for user
    roles or `teamId` values.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`1` = `查看`，`2` = `编辑`，`4` = `管理员`。可以为用户角色或 `teamId` 值设置权限。'
- en: '**Folder/Dashboard Search**: This API allows users to search for dashboards
    and folders. This endpoint allows for complex searches using query parameters.
    The response is a list of matching objects including the UID of an object.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**文件夹/仪表盘搜索**：此 API 允许用户搜索仪表盘和文件夹。该端点允许通过查询参数进行复杂的搜索。响应是一个包含对象 UID 的匹配对象列表。'
- en: '**Teams**: These endpoints manage Teams in Grafana. They can be used to do
    the following:'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**团队**：这些端点管理 Grafana 中的团队。可以用来执行以下操作：'
- en: Create, read, update, and delete teams
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建、读取、更新和删除团队
- en: Get, add, and remove team members
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取、添加和移除团队成员
- en: Get and update team preferences
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取并更新团队偏好设置
- en: '**Alerting**: These complex APIs manage all of the aspects of alerts. This
    API manages everything to do with Grafana Alertmanager. It can be used to create,
    read, update, and delete alerts, alert rules, alert groups, silences, receivers,
    templates, and many more alerting objects.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**警报**：这些复杂的 API 管理警报的所有方面。此 API 管理与 Grafana Alertmanager 相关的所有内容。可以用来创建、读取、更新和删除警报、警报规则、警报组、静默、接收器、模板以及更多的警报对象。'
- en: These API endpoints are fantastic for managing Grafana. Grafana provides a detailed
    API reference at https://grafana.com/docs/grafana/latest/developers/http_api/.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 API 端点非常适合管理 Grafana。Grafana 提供了详细的 API 参考，链接为 [https://grafana.com/docs/grafana/latest/developers/http_api/](https://grafana.com/docs/grafana/latest/developers/http_api/)。
- en: Let’s now look at how these API endpoints allow us to use the IaC tools of Terraform
    and Ansible to manage dashboards and alerts.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看这些 API 端点如何允许我们使用 Terraform 和 Ansible 的基础设施即代码（IaC）工具来管理仪表盘和警报。
- en: Managing dashboards and alerts with Terraform or Ansible
  id: totrans-176
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Terraform 或 Ansible 管理仪表盘和警报
- en: As dashboards are typically managed by the teams responsible for a service or
    application, it is best practice to separate the tooling to deploy dashboards
    from the tooling to manage observability infrastructure. We will discuss the practicalities
    of this in [*Chapter 14*](B18277_14.xhtml#_idTextAnchor254).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 由于仪表盘通常由负责某个服务或应用程序的团队管理，因此最佳实践是将部署仪表盘的工具与管理可观察性基础设施的工具分开。我们将在 [*第14章*](B18277_14.xhtml#_idTextAnchor254)
    中讨论这个问题的实际操作。
- en: For managing dashboards, both Terraform and Ansible leverage the fact that Grafana
    dashboards are JSON objects, providing a mechanism to upload a JSON file with
    the dashboard configuration to the Grafana instance. Let’s look at how this works.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在管理仪表盘时，Terraform 和 Ansible 都利用 Grafana 仪表盘是 JSON 对象的事实，提供了一种将包含仪表盘配置的 JSON
    文件上传到 Grafana 实例的机制。让我们看看它是如何工作的。
- en: 'The **Terraform** code looks like this:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '**Terraform** 代码如下：'
- en: '[PRE14]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: A collection of dashboard JSON files can be iterated over using the Terraform
    `fileset` function with a `for_each` command. This makes it very easy for a team
    to manage all its dashboards in an automated manner by saving the correct dashboard
    to the relevant folder.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 一组仪表盘 JSON 文件可以通过 Terraform 的 `fileset` 函数和 `for_each` 命令进行迭代。这使得团队能够通过将正确的仪表盘保存到相关文件夹中，自动化地管理所有仪表盘。
- en: 'The **Ansible** collection works in a very similar fashion:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '**Ansible** 集合的工作方式非常相似：'
- en: '[PRE15]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Like the Terraform code, this could be iterated using the built-in `with_fileglob`
    function, allowing teams to manage all their dashboards in an automated fashion.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Terraform 代码类似，这也可以使用内置的 `with_fileglob` 函数进行迭代，使得团队能够以自动化的方式管理所有的仪表盘。
- en: 'Unfortunately, with the latest changes to alerting in Grafana, the Ansible
    collection has not been updated to allow for alert management. With Terraform,
    you can manage Grafana Alerts in a very similar way to dashboards. Consider the
    following example code block:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，由于 Grafana 在警报管理方面的最新变化，Ansible 集合尚未更新以支持警报管理。使用 Terraform，您可以以与仪表盘非常相似的方式管理
    Grafana 警报。请考虑以下示例代码块：
- en: '[PRE16]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: We’ve not included the full details of the two rules shown here as the required
    configuration block is too large. The Terraform documentation has a very clear
    example of a full alert at https://registry.terraform.io/providers/grafana/grafana/latest/docs/resources/rule_group.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们没有包含这里展示的两个规则的完整细节，因为所需的配置块过大。Terraform 文档中有一个非常清晰的完整警报示例，链接为 [https://registry.terraform.io/providers/grafana/grafana/latest/docs/resources/rule_group](https://registry.terraform.io/providers/grafana/grafana/latest/docs/resources/rule_group)。
- en: Similar to the `grafana_dashboard` resource, `grafana_rule_group` can be iterated
    over by using a `dynamic` block to populate each rule from another source, such
    as a JSON file, for example. This makes the management of these rules significantly
    more user-friendly.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 `grafana_dashboard` 资源，`grafana_rule_group` 可以通过使用 `dynamic` 块来遍历， 从其他源（例如
    JSON 文件）填充每个规则。这样，管理这些规则变得更加用户友好。
- en: Summary
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you were introduced to the benefits of automating the management
    of your observability platform, and saw how investing in good automation can allow
    subject-matter experts to shift repetitive and low-value work to others in the
    organization. We discussed the different aspects of observability platforms, being
    data production, collection, storage, and visualization. You also learned who
    is typically responsible for each aspect of the platform.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了自动化管理观察平台的好处，并看到投资于优秀的自动化可以让主题专家将重复性和低价值的工作交给组织中的其他人。我们讨论了观察平台的不同方面，包括数据生产、收集、存储和可视化。你还学习了通常由谁负责平台的每个方面。
- en: With the theory largely covered, we then went on to discuss how to manage the
    data collection layer, presenting an in-depth analysis of the OpenTelemetry Collector
    Helm configuration that has been used to collect data throughout this book. We
    contrasted the way Helm works with Ansible to deploy to a virtual or physical
    setup, and you gained valuable skills in understanding the structure of the management
    files used by each tool. We rounded out the automation of data collection systems
    by introducing the Helm chart and the Ansible collection for Grafana Agent. While
    we did not go into this in the same depth as the OpenTelemtry configuration, the
    skills required for managing the Grafana Agent are identical.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 理论部分大致讲解完后，我们继续讨论如何管理数据收集层，深入分析了用于收集本书中所有数据的 OpenTelemetry Collector Helm 配置。我们对比了
    Helm 与 Ansible 在虚拟或物理环境部署中的工作方式，并帮助你掌握了理解每个工具管理文件结构的宝贵技能。我们通过介绍 Helm 图表和用于 Grafana
    Agent 的 Ansible 集合，完善了数据收集系统的自动化。虽然我们没有像 OpenTelemetry 配置那样深入讲解，但管理 Grafana Agent
    所需的技能是相同的。
- en: Our next topic was the Grafana API, where you learned that there are two APIs,
    one to manage the SaaS Grafana Cloud solution, and one to manage Grafana instances
    (both cloud and local). You were then introduced to the Terraform provider for
    Grafana and learned through specific examples how to manage both their cloud stacks
    and their Grafana instances. We then also looked at the Grafana Ansible collection
    and saw how it can be used to manage cloud stacks and Grafana instances as well
    as the data collection layer.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来的主题是 Grafana API，在这里你了解到有两个 API，一个用于管理 SaaS Grafana Cloud 解决方案，另一个用于管理
    Grafana 实例（包括云端和本地）。然后，你学习了如何通过特定示例使用 Terraform 提供程序来管理云堆栈和 Grafana 实例。接着，我们也看了
    Grafana Ansible 集合，了解了它如何用来管理云堆栈和 Grafana 实例，以及数据收集层。
- en: In the next chapter of this book, we will discuss how to architect a full observability
    platform that scales to the needs of your organization.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的下一章中，我们将讨论如何架构一个完整的观察平台，能够根据组织的需求进行扩展。
