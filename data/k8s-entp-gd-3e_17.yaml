- en: '17'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '17'
- en: Building and Deploying Applications on Istio
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Istio上构建和部署应用程序
- en: 'In the previous chapter, we deployed Istio and Kiali into our cluster. We also
    deployed an example application to see how the pieces fit together. In this chapter,
    we’re going to look at what it takes to build applications that will run on Istio.
    We’ll start by examining the differences between microservices and monolithic
    applications. Then, we’ll deploy a monolithic application on Istio and move on
    to building microservices that will run on Istio. This chapter will cover the
    following main topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们将Istio和Kiali部署到了我们的集群中。我们还部署了一个示例应用程序，以查看各个部分如何组合。在本章中，我们将探讨构建能够在Istio上运行的应用程序所需要的内容。我们将从比较微服务和单体应用程序的区别开始。然后，我们将在Istio上部署一个单体应用程序，接着构建在Istio上运行的微服务。本章将涵盖以下主要内容：
- en: Comparing microservices and monoliths
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微服务与单体架构的比较
- en: Deploying a monolith
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署单体应用
- en: Building a microservice
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建微服务
- en: Do I need an API gateway?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我是否需要API网关？
- en: Once you have completed this chapter, you’ll have a practical understanding
    of the difference between a monolith and a microservice, along with the information
    you’ll need to determine which one is best for you, and you will also have deployed
    a secured microservice in Istio.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本章后，你将实际理解单体应用与微服务之间的区别，并掌握决定选择哪种架构的相关信息，你还将成功地在Istio中部署一个安全的微服务。
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To run the examples in this chapter, you’ll need:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行本章中的示例，你需要：
- en: A running cluster with Istio deployed, as outlined in *Chapter 16*, *An Introduction
    to Istio*.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个已部署Istio的运行集群，如*第16章*《Istio简介》中所述。
- en: Scripts from this book’s GitHub repository.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 来自本书GitHub仓库的脚本。
- en: 'You can access the code for this chapter by going to this book’s GitHub repository:
    [https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/tree/main/chapter17](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/tree/main/chapter17).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过访问本书的GitHub仓库来获取本章的代码：[https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/tree/main/chapter17](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/tree/main/chapter17)。
- en: Comparing microservices and monoliths
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 微服务与单体架构的比较
- en: Before we dive too deeply into code, we should spend some time discussing the
    differences between microservices and monolithic architecture. The microservices
    versus monolithic architecture debate is as old as computing itself (and the theory
    is probably even older). Understanding how these two approaches relate to each
    other and your problem set will help you decide which one to use.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入代码之前，我们应花一些时间讨论微服务和单体架构的区别。微服务与单体架构的争论几乎与计算机本身的历史一样久远（而且这一理论可能更久远）。理解这两种方法如何相互关联以及与问题集的关系，将帮助你决定使用哪种方法。
- en: My history with microservices versus monolithic architecture
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我与微服务与单体架构的历史
- en: Before we get into the microservices versus monoliths discussion, I wanted to
    share my own history. I doubt it’s unique, but it does frame my outlook on the
    discussion and adds some context to the recommendations in this chapter.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入讨论微服务与单体架构之前，我想分享一下我自己的历史。我怀疑这并不独特，但它确实为我对这一讨论的看法提供了框架，并为本章中的建议提供了一些背景。
- en: 'My introduction to this discussion was when I was a computer science student
    in college and had started using Linux and open source. One of my favorite books,
    *Open Sources: Voices from the Open Source Revolution*, had an appendix on the
    debate between Andrew Tanenbaum and Linus Torvalds on microkernels versus monolithic
    kernels. Tanenbaum was the inventor of Minix, and a proponent of a minimalist
    kernel, with most of the functionality in user space. Linux, instead, uses a monolithic
    kernel design, where much more is done in the kernel. If you’ve ever run `modprobe`
    to load a driver, you’re interacting with the kernel! The entire thread is available
    at [https://www.oreilly.com/openbook/opensources/book/appa.xhtml](https://www.oreilly.com/openbook/opensources/book/appa.xhtml).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我第一次接触这个讨论是当我还是一名计算机科学专业的大学生，并开始使用Linux和开源软件时。我最喜欢的书之一，《开放源代码：开源革命的声音》，书中附录讨论了Andrew
    Tanenbaum与Linus Torvalds关于微内核与单体内核的争论。Tanenbaum是Minix的发明者，他支持简约内核，大多数功能在用户空间中完成。而Linux则使用单体内核设计，更多的功能是在内核中完成的。如果你曾经运行过`modprobe`来加载驱动程序，那么你就是在与内核交互！完整的讨论可以在[https://www.oreilly.com/openbook/opensources/book/appa.xhtml](https://www.oreilly.com/openbook/opensources/book/appa.xhtml)查看。
- en: Linus’ core argument was that a well-managed monolith was much easier to maintain
    than a microkernel.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Linus的核心论点是，管理良好的单体架构比微内核更容易维护。
- en: Tanenbaum instead pointed to the idea that microkernels were easier to port
    and that most “modern” kernels were microkernels. Windows (at the time, Windows
    NT) is probably the most prevalent microkernel today. As a software developer,
    I’m constantly trying to find the smallest unit I can build. The microkernel architecture
    really appealed to that aspect of my talents.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Tanenbaum则指出，微内核更容易移植，而且大多数“现代”内核都是微内核。Windows（当时是Windows NT）今天可能是最普遍的微内核。作为软件开发者，我一直在努力找到我可以构建的最小单元。微内核架构真的很吸引我这一方面的才能。
- en: At the same time, I was starting my career in IT, primarily as a Windows developer
    in the data management and analysis space. I spent most of my time working with
    **ASP** (**Active Server Pages**, Microsoft’s version of PHP), Visual Basic, and
    SQL Server. I tried to convince my bosses that we should move off of a monolithic
    application design to use **MTS** (**Microsoft Transaction Server**). MTS was
    my first exposure to what we would call today a distributed application. My bosses
    and mentors all pointed out that our costs, and so our customers’ costs, would
    go through the roof if we injected the additional infrastructure for no benefit
    other than a cleaner code base. There was nothing we were working on that couldn’t
    be accomplished with our tightly bound trio of ASP, Visual Basic, and SQL Server
    at a much lower cost.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，我开始了我的IT职业生涯，主要作为数据管理和分析领域的Windows开发人员。我大部分时间都在使用**ASP**（**Active Server
    Pages**，微软版的PHP）、Visual Basic和SQL Server。我试图说服我的老板，我们应该从单体应用设计转向使用**MTS**（**Microsoft
    Transaction Server**）。MTS是我第一次接触到今天我们所称的分布式应用。我的老板和导师们都指出，如果我们为了更干净的代码库而注入额外的基础设施，那我们的成本，进而客户的成本，将会飙升。没有什么我们在做的事情是不能用我们紧密结合的ASP、Visual
    Basic和SQL Server三者组合以更低成本完成的。
- en: I later moved from data management to identity management. I also switched from
    Microsoft to Java. One of my first projects was to deploy an identity management
    vendor’s product that was built using a distributed architecture. At the time,
    I thought it was great, until I started trying to debug issues and trace down
    problems across dozens of log files. I quickly started using another vendor’s
    product that was built as a monolith. Deployments were slow, as they required
    a full recompile, but otherwise, management was much easier, and it scaled every
    bit as well. We found that a distributed architecture didn’t help because identity
    management was done by such a centralized team that having a monolith didn’t impact
    productivity or management. The benefits of distributing implementation just didn’t
    outweigh the additional complexity.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 后来，我从数据管理转到了身份管理。我也从微软技术转向了Java。我的第一个项目之一是部署一个基于分布式架构构建的身份管理厂商的产品。当时，我认为这很好，直到我开始尝试调试问题并在数十个日志文件中追踪问题。我很快开始使用另一家厂商的产品，它是一个单体架构。尽管部署速度较慢，因为需要完全重新编译，但除此之外，管理要容易得多，而且它的扩展性也同样很好。我们发现，分布式架构并没有带来帮助，因为身份管理是由一个高度集中的团队完成的，采用单体架构并不会影响生产力或管理。将实现分布的好处并不足以抵消额外的复杂性。
- en: Fast forward to the founding of Tremolo Security. This was in 2010, so it was
    before Kubernetes and Istio came along. At the time, virtual appliances were all
    the rage! We decided OpenUnison would take the monolithic approach because we
    wanted to make it easier to deploy and upgrade. In *Chapter 6*, *Integrating Authentication
    into Your Cluster*, we deployed OpenUnison with some Helm charts to layer on different
    configurations. How much harder would it have been had there been an authentication
    service to install, a directory service, a just-in-time provisioning service,
    etc.? It made for a much simpler deployment having one system.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 快进到Tremolo Security的成立。那是在2010年，也就是Kubernetes和Istio出现之前。那时，虚拟设备正风靡一时！我们决定OpenUnison采用单体架构，因为我们希望简化部署和升级。在*第六章*，*将身份认证集成到集群中*，我们使用一些Helm图表部署了OpenUnison，以便在不同配置上叠加。假如有一个身份认证服务需要安装，一个目录服务，一个即时配置服务等等，难度会增加多少呢？有一个系统来部署，简化了部署过程。
- en: With all that said, it’s not that I’m anti-microservice—I’m not! When used correctly,
    it’s an incredibly powerful architecture used by many of the world’s largest companies.
    I’ve learned through the years that if it’s not the right architecture for your
    system, it will considerably impact your ability to deliver. Now that I’ve filled
    you in on my own journey through architectures, let’s take a deeper look at the
    differences between microservices and monoliths.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 说到这里，并不是说我反对微服务——我并不反对！当正确使用时，它是一种非常强大的架构，许多世界上最大的公司都在使用它。多年来我学到的是，如果它不是你的系统的合适架构，它会显著影响你的交付能力。现在我已经跟你分享了我在架构方面的历程，让我们更深入地了解微服务和单体架构之间的区别。
- en: Comparing architectures in an application
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较应用中的架构
- en: First, let’s talk about what these two architecture approaches each do in a
    common example application, a storefront.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们谈谈这两种架构方法在一个常见示例应用——店面中的作用。
- en: Monolithic application design
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单体应用设计
- en: 'Let’s say you have an online store. Your store will likely need a product lookup
    service, a shopping cart, a payment system, and a shipping system. This is a vast
    oversimplification of a storefront application, but the point of the discussion
    is how to break up development and not how to build a storefront. There are two
    ways you could approach building this application. The first is you could build
    a monolithic application where all the code for each service is stored and managed
    in the same tree. Your application infrastructure would probably look something
    like this:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个在线商店。你的商店可能需要一个产品查找服务、一个购物车、一个支付系统和一个运输系统。这是一个对店面应用的极度简化，但讨论的重点是如何拆分开发，而不是如何构建一个店面。你可以通过两种方式来构建这个应用。第一种是构建一个单体应用，其中每个服务的所有代码都存储并管理在同一个树结构中。你的应用架构可能看起来像这样：
- en: '![A diagram of a storefront application  Description automatically generated](img/B21165_17_01.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![店面应用的示意图  描述自动生成](img/B21165_17_01.png)'
- en: 'Figure 17.1: Monolithic application architecture'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.1：单体应用架构
- en: In our application, we have a single system with multiple modules. Depending
    on your programming language of choice, these could be classes, structs, or other
    forms of code module. A central application manages the user’s interaction with
    this code. This would likely be a web frontend with the modules being server-side
    code, written up as web services or a post/response-style app.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的应用中，我们有一个单一的系统，包含多个模块。根据你选择的编程语言，这些模块可能是类、结构体或其他形式的代码模块。一个中央应用程序管理用户与这些代码的交互。这通常是一个网页前端，模块则是服务器端代码，编写为
    Web 服务或请求/响应风格的应用。
- en: Yes, web services can be used in a monolith! These modules likely need to store
    data, usually in some kind of a database. Whether it’s a relational database,
    a document database, or a series of databases isn’t really important.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，Web 服务可以在单体架构中使用！这些模块通常需要存储数据，通常是某种形式的数据库。无论是关系型数据库、文档型数据库，还是一系列数据库，其实并不重要。
- en: 'The biggest advantage to this monolithic architecture is it’s relatively simple
    to manage and have the systems interact with each other. If the user wants to
    do a product search, the storefront will likely just execute some code like the
    following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这种单体架构最大的优势是它相对容易管理，且系统之间可以互相交互。如果用户想进行产品搜索，店面可能只需执行以下类似的代码：
- en: '[PRE0]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The application code only needs to know the interface of the services it’s going
    to call. There’s no need to “authenticate” that call from the application controller
    to the product directory module. There’s no concern with creating rate-limiting
    systems or trying to work out which version of the service to use. Everything
    is tightly bound. If you make an update to any system, you know pretty quickly
    if you broke an interface, since you’re likely using a development tool that will
    tell you when module interfaces break. Finally, deployment is usually pretty simple.
    You upload your code to a deployment service (or create a container… this is a
    Kubernetes book!).
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 应用代码只需要知道它将要调用的服务的接口。无需“验证”从应用控制器到产品目录模块的调用。也无需担心创建速率限制系统或试图弄清楚使用哪个版本的服务。一切都紧密绑定。如果你对任何系统进行了更新，你很快就会知道是否破坏了接口，因为你可能使用了一个开发工具，当模块接口出现问题时，它会告诉你。最后，部署通常也非常简单。你只需要将代码上传到部署服务（或者创建容器……毕竟这是一本
    Kubernetes 书！）。
- en: What happens if you need to have one developer update your ordering system while
    another developer updates your payment system? They each have their own copies
    of the code that need to be merged. After merging, the changes from both branches
    need to be reconciled before deployment. This may be fine for a small system,
    but as your storefront grows, this can become cumbersome to the point of being
    unmanageable.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要一个开发者更新订单系统，而另一个开发者更新支付系统怎么办？他们各自有自己的代码副本，必须合并。在合并之后，两个分支的更改需要在部署之前进行对账。这对于一个小系统可能没问题，但随着你的商店前端不断扩展，这可能会变得繁琐，甚至无法管理。
- en: Another potential issue is, what if there’s a better language or system to build
    one of these services in than the overall application? I’ve been on multiple projects
    over the years where Java was a great choice for certain components, but C# had
    better APIs for others. Maybe one service team was built around Python and another
    on Ruby. Standardization is all well and good, but you wouldn’t use the butt end
    of a screwdriver to drive in a nail for the sake of standardization, would you?
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个潜在的问题是，如果有比整个应用程序更合适的语言或系统来构建其中的某个服务怎么办？多年来，我参与了多个项目，在一些组件上 Java 是一个不错的选择，而在其他组件上
    C# 提供了更好的 API。也许一个服务团队是基于 Python 构建的，另一个则是基于 Ruby 的。标准化本是好事，但为了标准化，你不会用螺丝刀的尾端来钉钉子吧？
- en: This argument doesn’t pertain to frontend versus backend. An application with
    a JavaScript frontend and a Golang backend can still be a monolithic application.
    Both the Kubernetes Dashboard and Kiali are examples of monolithic applications
    built on service APIs across different languages. Both have HTML and JavaScript
    frontends, while their backend APIs are written in Golang.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 这个论点与前端和后端无关。一个具有 JavaScript 前端和 Golang 后端的应用程序仍然可以是一个单体应用程序。Kubernetes Dashboard
    和 Kiali 都是构建在跨语言服务 API 上的单体应用程序示例。它们都有 HTML 和 JavaScript 前端，而后端 API 则是用 Golang
    编写的。
- en: Microservices design
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 微服务设计
- en: 'What if we broke these modules up into services? Instead of having one single
    source tree, we would break our application up into individual services like the
    following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将这些模块拆分成服务会怎样？我们不再有一个单一的源代码树，而是将应用程序拆分成如下所示的独立服务：
- en: '![A diagram of a storefront application  Description automatically generated](img/B21165_17_02.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![一个商店应用程序的图示  描述自动生成](img/B21165_17_02.png)'
- en: 'Figure 17.2: Simple microservices architecture'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.2：简单的微服务架构
- en: 'This doesn’t look that much more complex. Instead of a big box, there’s a bunch
    of lines. Let’s zoom in on the call from our frontend to our product lookup service:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这看起来并不复杂。与其说是一个大框框，不如说是一堆线条。让我们放大看一下前端到产品查询服务的调用：
- en: '![A picture containing text, screenshot, diagram, design  Description automatically
    generated](img/B21165_17_03.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
  zh: '![一张包含文本、截图、图表、设计的图片  描述自动生成](img/B21165_17_03.png)'
- en: 'Figure 17.3: Service call architecture'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.3：服务调用架构
- en: It’s no longer a simple function or method call. Now, our storefront controller
    needs to determine where to send the service call, and this will likely change
    in each environment. It also needs to inject some kind of authentication token,
    since you wouldn’t want just anyone calling your services. Since the remote service
    no longer has a local code representation, you’ll either need to build the call
    manually or use a schema language to describe your product listing service, combining
    it with a client binding. Once the call is made, the service needs to validate
    the call’s schema and apply security rules for authentication and authorization.
    Once the response is packaged and sent back to our storefront controller, the
    controller needs to validate the schema of the response. If there’s a failure,
    it needs to decide if it’s going to retry or not.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这不再是一个简单的函数或方法调用了。现在，我们的商店控制器需要确定将服务调用发送到哪里，这可能会在每个环境中有所不同。它还需要注入某种认证令牌，因为你不希望任何人都能调用你的服务。由于远程服务不再有本地代码表示，你要么需要手动构建调用，要么使用架构语言来描述你的产品列表服务，并将其与客户端绑定结合起来。一旦调用发出，服务需要验证调用的架构，并应用认证和授权的安全规则。响应被打包并发送回商店控制器后，控制器需要验证响应的架构。如果失败，它需要决定是否重试。
- en: Combine all this additional complexity with version management. Which version
    of the product lookup service should our storefront use? Are other services tightly
    coupled together? There are several benefits to the microservices approach, as
    we discussed earlier, in terms of version and deployment management. These advantages
    come with the cost of additional complexity.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有这些额外的复杂性与版本管理结合起来。我们的前端应该使用哪个版本的产品查找服务？其他服务是否紧密耦合在一起？正如我们之前讨论的，微服务方法在版本和部署管理方面有几个好处。这些优势伴随着额外复杂性的代价。
- en: Choosing between monoliths and microservices
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择单体架构还是微服务
- en: Which of these two approaches is right for you? That really depends. What does
    your team look like? What are your management needs? Do you need the flexibility
    that comes from microservices or will a monolith’s simpler design make for an
    easier-to-manage system?
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方法哪种适合你？这实际上取决于你的团队是什么样的？你的管理需求是什么？你是否需要微服务带来的灵活性，还是单体架构更简单的设计能够让系统更容易管理？
- en: One of the major benefits of a microservice architecture is that you can have
    multiple teams working on their own code without having to share the same source
    repository. Before assuming that breaking the services into their own source repositories
    will benefit your team, how closely tied are the services? If there are numerous
    interdependencies, then your microservices are really just a distributed monolith,
    and you may not get the benefits of different repositories. It may be easier to
    manage branches and merge them.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构的一个主要优点是，你可以让多个团队在自己的代码上工作，而无需共享同一个源代码仓库。在假设将服务拆分到各自的源代码仓库对你的团队有益之前，这些服务的耦合程度如何？如果服务之间有大量的相互依赖，那么你的微服务其实就是一个分布式的单体架构，你可能无法享受到不同仓库带来的好处。管理分支并将它们合并可能会更容易。
- en: Also, will your services need to be called by other systems? Look at the cluster
    we built in the last chapter. Kiali has its own services, but they’re not likely
    to be used by other applications. Jaeger and Prometheus, however, do have services
    that are used by Kiali, even if those systems have their own frontends too. In
    addition to these services, Kiali uses the Kubernetes API. All these components
    are deployed separately and are managed separately. They need to be upgraded on
    their own, monitored, and so on. This can be a management headache because each
    system is independently managed and maintained. That said, it wouldn’t make any
    sense for the Kiali team to re-implement Prometheus and Jaeger in their own project.
    It also wouldn’t make sense to just import the entire source tree for these projects
    and be forced to keep them up to date.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你的服务是否需要被其他系统调用？回顾我们在上一章构建的集群，Kiali 有自己的服务，但这些服务不太可能被其他应用程序使用。然而，Jaeger 和
    Prometheus 确实有被 Kiali 使用的服务，即使这些系统也有自己的前端。除了这些服务，Kiali 还使用了 Kubernetes API。所有这些组件都是单独部署和管理的，需要独立升级、监控等。这可能会带来管理上的头痛，因为每个系统都是独立管理和维护的。话虽如此，Kiali
    团队重新实现 Prometheus 和 Jaeger 并没有任何意义。将这些项目的整个源代码导入并强迫保持更新也没有意义。
- en: Using Istio to help manage microservices
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 Istio 来帮助管理微服务
- en: We’ve spent quite a bit of time talking about microservices and monoliths without
    talking about Istio. Earlier in this chapter, *Figure 17.3* pointed out decisions
    that were needed by our microservice before we could get to calling our code.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经花了相当多的时间讨论微服务和单体架构，但却没有提到 Istio。在本章前面，*图 17.3* 指出了在我们调用代码之前，微服务所需要做出的决策。
- en: These should look familiar because we covered objects from Istio that service
    most of these needs in the last chapter! Istio can remove our need to write code
    to authenticate and authorize clients, discover where services are running, and
    manage traffic routing. Throughout the rest of this chapter, we’re going to walk
    through building a small application off of a microservice, using Istio to leverage
    these common services without having to build them into our code.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这些应该很熟悉，因为我们在上一章已经讨论了 Istio 中的对象，它们可以满足大部分需求！Istio 可以消除我们编写代码来进行客户端身份验证和授权、发现服务运行位置以及管理流量路由的需求。在本章的其余部分，我们将通过构建一个小型应用程序来演示如何利用微服务，并使用
    Istio 来利用这些常见服务，而无需将它们构建到我们的代码中。
- en: So far, we’ve looked at the differences between monoliths and microservices,
    and how those differences interact with Istio at a conceptual level. Next, we’ll
    see how a monolith is deployed into Istio.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了单体应用和微服务之间的区别，以及这些区别如何在概念上与Istio进行交互。接下来，我们将看到如何将单体应用部署到Istio中。
- en: Deploying a monolith
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署单体应用
- en: This chapter is about microservices, so why are we starting with deploying monoliths
    in Istio? The first answer is, because we can! There’s no reason to not get the
    benefits of Istio’s built-in capabilities when working with monoliths in your
    cluster. Even though it’s not a “microservice,” it’s still good to be able to
    trace through application requests, manage deployments, and so on. The second
    answer is, because we need to. Our microservice will need to know which user in
    our enterprise is calling it. To do that, Istio will need a JWT to validate. We’ll
    use OpenUnison to generate JWTs first so that we can call our service manually,
    and then so we can authenticate users from a frontend and allow it to call our
    service securely.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容是关于微服务的，那么为什么我们从在Istio中部署单体应用开始呢？第一个答案是，因为我们可以！在集群中使用单体应用时，完全没有理由不享受Istio内置功能的好处。即使它不是“微服务”，但能够追踪应用请求、管理部署等依然很有用。第二个答案是，因为我们需要这么做。我们的微服务需要知道在我们的企业中是哪个用户在调用它。为了做到这一点，Istio需要一个JWT来验证。我们将首先使用OpenUnison生成JWT，以便我们可以手动调用服务，然后我们可以从前端进行用户身份验证，并确保安全地调用我们的服务。
- en: 'Starting with your cluster from *Chapter 16*, we’re now going to deploy OpenUnison.
    Go to the `chapter17/openunison-istio` directory and run `deploy_openunison_istio.sh`:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 从*第16章*开始，我们现在要部署OpenUnison。进入`chapter17/openunison-istio`目录，并运行`deploy_openunison_istio.sh`：
- en: '[PRE1]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This is going to take a while to run. This script does a few things:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这将需要一段时间来运行。这个脚本做了几件事：
- en: Deploys `cert-manager` with our enterprise CA.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用我们的企业CA部署`cert-manager`。
- en: Deploys all of the OpenUnison components (including our testing Active Directory)
    for impersonation, so we don’t need to worry about updating the API server for
    SSO to work.
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署所有OpenUnison组件（包括我们的测试Active Directory）用于模拟，因此我们不需要担心更新API服务器以使SSO工作。
- en: 'Labels the `openunison` namespace with `istio-injection: enabled`. This tells
    Istio to enable sidecar injection for all pods. You can do this manually by running
    `kubectl label ns openunison istio-injection=enabled`.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '给`openunison`命名空间打上`istio-injection: enabled`标签。这告诉Istio为所有Pod启用sidecar注入。你可以通过运行`kubectl
    label ns openunison istio-injection=enabled`手动完成此操作。'
- en: Creates all of our Istio objects for us (we’ll go into the details of these
    next).
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为我们创建所有的Istio对象（接下来我们将详细介绍这些对象）。
- en: Creates an `ou-tls-certificate` Certificate in the the `istio-system` namespace.
    Again, we’ll dive into the details as to why in the next section.
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`istio-system`命名空间中创建一个`ou-tls-certificate`证书。再次说明，为什么要这么做我们将在下一节详细探讨。
- en: Once the script is run, we’re able to now log in to our monolith! Just like
    in *Chapter 6*, *Integrating Authentication into Your Cluster*, go to `https://k8sou.apps.XX-XX-XX-XX.nip.io/`
    to log in, where `XX-XX-XX-XX` is your host’s IP address.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦脚本运行完毕，我们现在可以登录到我们的单体应用了！就像在*第6章*中提到的，*将身份验证集成到集群中*，访问`https://k8sou.apps.XX-XX-XX-XX.nip.io/`进行登录，其中`XX-XX-XX-XX`是你主机的IP地址。
- en: For instance, my host runs on `192.168.2.114`, so my URL is `https://k8sou.apps.192-168-2-114.nip.io/`.
    Again, as in *Chapter 6*, the username is `mmosley` and the password is `start123`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 比如说，我的主机的IP地址是`192.168.2.114`，因此我的URL是`https://k8sou.apps.192-168-2-114.nip.io/`。同样，正如在*第6章*中提到的，用户名是`mmosley`，密码是`start123`。
- en: Now that our monolith is deployed, let’s walk through the Istio-specific configuration
    as it relates to our deployment.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的单体应用已经部署好了，让我们一步一步地了解与部署相关的Istio特定配置。
- en: Exposing our monolith outside our cluster
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将我们的单体应用暴露到集群外部
- en: 'Our OpenUnison is running, so let’s look at the objects that expose it to our
    network. There are two main objects that do this work: `Gateway` and `VirtualService`.
    These objects were created when we installed OpenUnison. How these objects are
    configured was described in *Chapter 16*, *An Introduction to Istio*. Then, we’ll
    look at running instances to show how they grant access. First, let’s look at
    the important parts of our gateways. There are two. The first one, `openunison-gateway-orchestra`,
    handles access to the OpenUnison portal and the Kubernetes Dashboard:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的OpenUnison已经在运行，让我们来看看将它暴露到网络中的对象。完成这项工作的有两个主要对象：`Gateway`和`VirtualService`。这些对象是在我们安装OpenUnison时创建的。如何配置这些对象已经在*第16章*，*Istio简介*中描述过。接下来，我们将查看正在运行的实例，展示它们如何授予访问权限。首先，让我们来看一下网关的关键部分。有两个网关，第一个是`openunison-gateway-orchestra`，它负责访问OpenUnison门户和Kubernetes仪表板：
- en: '[PRE2]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The `selector` tells Istio which `ingress-ingressgateway` pod to work with.
    The default gateway deployed to `istio-system` has the label `istio: ingressgateway`,
    which will match this one. You could run multiple gateways, using this section
    to determine which one you want to expose your service to. This is useful if you
    have multiple networks with different traffic or if you want to separate traffic
    between applications on a cluster.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '`selector`告诉Istio要与哪个`ingress-ingressgateway` pod进行交互。部署到`istio-system`的默认网关具有标签`istio:
    ingressgateway`，它将与这个网关匹配。你可以运行多个网关，使用这个部分来确定你希望将服务暴露给哪一个。如果你有多个网络并且流量不同，或者你想要在集群中分隔应用之间的流量，这将非常有用。'
- en: The first entry in the `servers` list tells Istio that if a request comes on
    HTTP to port `80` for either of our hosts, then we want Istio to send a redirect
    to the HTTPS port. This is a good security practice, so folks, don’t try to bypass
    HTTPS. The second entry in `servers` tells Istio to accept HTTPS connections on
    port `443`, using the certificate in the `Secret` named `ou-tls-certificate`.
    This `Secret` must be a TLS `Secret` and be in the same namespace as the pod running
    the ingress gateway. For our cluster, this means that `ou-tls-certificate` *MUST*
    be in the `istio-system` namespace. That’s why our deployment script created the
    wild card certificate in the `istio-system` namespace. This is different from
    using an `Ingress` object with NGINX, where you keep the TLS `Secret` in the same
    namespace as your `Ingress` object.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '`servers`列表中的第一个条目告诉Istio，如果请求通过HTTP进入端口`80`，并且目标是我们的任一主机，那么我们希望Istio将请求重定向到HTTPS端口。这是一种良好的安全实践，因此大家不要试图绕过HTTPS。`servers`中的第二个条目告诉Istio接受端口`443`上的HTTPS连接，并使用名为`ou-tls-certificate`的`Secret`中的证书。这个`Secret`必须是TLS类型的`Secret`，并且必须与运行入口网关的pod位于同一命名空间。对于我们的集群，这意味着`ou-tls-certificate`*必须*位于`istio-system`命名空间中。这就是为什么我们的部署脚本在`istio-system`命名空间中创建了通配符证书。这与使用NGINX的`Ingress`对象不同，后者将TLS
    `Secret`保留在与`Ingress`对象相同的命名空间中。'
- en: If you don’t include your `Secret` in the correct namespace, it can be difficult
    to debug. The first thing you’ll notice is that when you try to connect to your
    host, your browser will report that the connection has been reset. This is because
    Istio doesn’t have a certificate to serve. Kiali won’t tell you there’s a configuration
    issue, but looking at the `istiod` pod in `istio-system`'s logs, you’ll find `failed
    to fetch key and certificate for kubernetes://secret-name`, where `secret-name`
    is the name of your `Secret`. Once you copy your `Secret` into the correct namespace,
    your app will start working on HTTPS.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有将你的`Secret`放在正确的命名空间中，可能会很难调试。你首先会注意到，当你尝试连接到主机时，浏览器会报告连接已被重置。这是因为Istio没有证书可以提供。Kiali不会告诉你有配置问题，但通过查看`istio-system`中`istiod`
    pod的日志，你会发现`failed to fetch key and certificate for kubernetes://secret-name`，其中`secret-name`是你的`Secret`的名称。一旦你将`Secret`复制到正确的命名空间中，应用程序就会开始在HTTPS上工作。
- en: 'The second Gateway, `openunison-api-gateway-orchestra`, is used to expose OpenUnison
    directly via HTTPS for the API server host. This bypasses most of Istio’s built-in
    functionality, so it’s not something we’ll want to do unless needed. The important
    difference in this Gateway versus our other Gateway is how we configure TLS:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个网关是`openunison-api-gateway-orchestra`，用于通过HTTPS直接暴露OpenUnison的API服务器主机。这绕过了Istio的内建功能，因此除非有必要，否则我们不希望这样做。这个网关与我们的另一个网关的主要区别在于我们如何配置TLS：
- en: '[PRE3]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: We use `PASSTHROUGH` as the `mode` instead of `SIMPLE`. This tells Istio to
    not bother trying to decrypt the HTTPS request and, instead, send it downstream.
    We have to do this for the Kubernetes API calls because Envoy doesn’t support
    the SPDY protocol used by kubectl for `exec`, `cp`, and `port-forward`, so we
    need to bypass it. This, of course, means that we lose much of Istio’s capabilities,
    so it’s not something we want to do if we can avoid it.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用`PASSTHROUGH`作为`mode`，而不是`SIMPLE`。这告诉Istio不要费力去解密HTTPS请求，而是直接将其下游传送。我们必须为Kubernetes
    API调用这样做，因为Envoy不支持kubectl用于`exec`、`cp`和`port-forward`的SPDY协议，因此我们需要绕过它。当然，这也意味着我们失去了Istio的许多功能，所以如果能避免，最好不要这样做。
- en: 'While the `Gateway` objects tell Istio how to listen for connections, the `VirtualService`
    objects tell Istio where to send the traffic to. Just like with the `Gateway`
    objects, there are two `VirtualService` objects. The first object handles traffic
    for both the OpenUnison portal and the Kubernetes Dashboard. Here are the important
    parts:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`Gateway`对象告诉Istio如何监听连接，而`VirtualService`对象则告诉Istio将流量发送到哪里。就像`Gateway`对象一样，这里有两个`VirtualService`对象。第一个对象处理OpenUnison门户和Kubernetes仪表盘的流量。以下是其中的重要部分：'
- en: '[PRE4]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The `gateways` section tells Istio which `Gateway` objects to link this to.
    You could, in theory, have multiple Gateways as sources for traffic. The `hosts`
    section tells Istio which hostnames to apply this configuration to, with the `match`
    section telling Istio what conditions to match requests on. This section can provide
    quite a bit of power for routing microservices, but for monoliths, just `/` is
    usually good enough.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '`gateways`部分告诉Istio要将这个配置链接到哪些`Gateway`对象。理论上，你可以有多个Gateway作为流量的来源。`hosts`部分告诉Istio将此配置应用于哪些主机名，而`match`部分则告诉Istio要根据什么条件匹配请求。对于微服务路由，这部分可以提供很大的灵活性，但对于单体应用，通常`/`就足够了。'
- en: Finally, the `route` section tells Istio where to send the traffic. `destination.host`
    is the name of the `Service` you want to send the traffic to. We’re sending all
    traffic to port `80` (sort of).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，`route`部分告诉Istio将流量发送到哪里。`destination.host`是你想要发送流量的`Service`名称。我们将所有流量发送到端口`80`（大致如此）。
- en: The NGINX `Ingress` version of this configuration sent all traffic to OpenUnison’s
    HTTPS port (`8443`). This meant that all data was encrypted over the wire from
    the user’s browser, all the way to the OpenUnison pod. We’re not doing that here
    because we’re going to rely on mTLS from Istio’s sidecar.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配置的NGINX `Ingress`版本将所有流量发送到OpenUnison的HTTPS端口（`8443`）。这意味着所有数据都会在用户浏览器和OpenUnison
    Pod之间的网络传输中被加密。我们在这里并没有这样做，因为我们将依赖Istio的sidecar来进行mTLS。
- en: Even though we’re sending traffic to port `80` using HTTP, the traffic will
    be encrypted from when it leaves the `ingressgateway` pod until it arrives at
    the sidecar on our OpenUnison pod that intercepts all of OpenUnison’s inbound
    network connections. There’s no need to configure TLS explicitly!
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 即使我们通过HTTP将流量发送到端口`80`，从流量离开`ingressgateway` Pod直到到达OpenUnison Pod上的sidecar并拦截所有OpenUnison的入站网络连接之前，这些流量都会被加密。无需显式配置TLS！
- en: 'Now that we’re routing traffic from our network to OpenUnison, let’s tackle
    a common requirement of monolithic applications: sticky sessions.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经将流量从我们的网络路由到OpenUnison，接下来我们来处理单体应用程序中的一个常见需求：粘性会话。
- en: Configuring sticky sessions
  id: totrans-84
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置粘性会话
- en: Most monolithic applications require sticky sessions. Enabling sticky sessions
    means that every request in a session is sent to the same pod. This is generally
    not needed in microservices because each API call is distinct. Web applications
    that users interact with generally need to manage state, usually via cookies.
    However, those cookies don’t generally store all of the session’s state because
    they would get too big and would likely have sensitive information. Instead, most
    web applications use a cookie that points to a session that’s saved on the server,
    usually in memory. While there are ways to make sure that this session is available
    to any instance of the application in a highly available way, it’s not very common
    to do so. These systems are expensive to maintain and are generally not worth
    the work.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数单体应用程序都需要粘性会话。启用粘性会话意味着每个会话中的每个请求都会发送到同一个 pod。在微服务中通常不需要这种设置，因为每个 API 调用都是独立的。用户交互的
    Web 应用程序通常需要管理状态，通常是通过 cookies。但这些 cookies 通常不会存储整个会话的状态，因为它们会变得太大，并且可能包含敏感信息。相反，大多数
    Web 应用程序使用指向服务器上保存的会话（通常在内存中）的 cookie。虽然有一些方法可以确保该会话对应用程序的任何实例都可用，且具有高可用性，但这样做并不常见。这些系统维护成本较高，通常不值得投入过多精力。
- en: 'OpenUnison is no different than most other web applications and needs to make
    sure that sessions are sticky to the pod they originated from. To tell Istio how
    we want sessions to be managed, we use `DestinationRule`. The `DestinationRule`
    objects tell Istio what to do about traffic routed to a host by a `VirtualService`.
    Here are the important parts of ours:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: OpenUnison 和大多数其他 Web 应用程序一样，需要确保会话与其来源的 pod 保持粘性。为了告诉 Istio 如何管理会话，我们使用 `DestinationRule`。`DestinationRule`
    对象告诉 Istio 在通过 `VirtualService` 路由到主机的流量中应该做什么。以下是我们规则中的重要部分：
- en: '[PRE5]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `host` in the rule refers to the target (`Service`) of the traffic, not
    the hostname in the original URL. `spec.trafficPolicy.loadBalancer.consistentHash`
    tells Istio how we want to manage stickiness. Most monolithic applications will
    want to use cookies. `ttl` is set to `0s`, so the cookie is considered a “session
    cookie.” This means that when the browser is closed, the cookie disappears from
    its cookie jar.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 规则中的 `host` 指的是流量的目标（`Service`），而不是原始 URL 中的主机名。`spec.trafficPolicy.loadBalancer.consistentHash`
    告诉 Istio 我们希望如何管理粘性。大多数单体应用程序会希望使用 cookies。`ttl` 设置为 `0s`，因此该 cookie 被视为“会话 cookie”。这意味着当浏览器关闭时，cookie
    会从浏览器的 cookie 存储中消失。
- en: You should avoid cookies with specific times to live. These cookies are persisted
    by the browser and can be treated as a security risk by your enterprise.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 应避免使用具有特定生存时间的 cookies。这些 cookies 会被浏览器持久化，并且可能被贵企业视为安全风险。
- en: With OpenUnison up and running and understanding how Istio is integrated, let’s
    take a look at what Kiali will tell us about our monolith.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: OpenUnison 启动并运行，且了解了 Istio 的集成方式后，让我们来看一下 Kiali 会如何向我们展示关于我们的单体应用的信息。
- en: Integrating Kiali and OpenUnison
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集成 Kiali 和 OpenUnison
- en: 'First, let’s integrate OpenUnison and Kiali. Kiali, like any other cluster
    management system, should be configured to require access. Kiali, just like the
    Kubernetes Dashboard, can integrate with Impersonation so that Kiali will interact
    with the API server, using the user’s own permissions. Doing this is pretty straight
    forward. We created a script in the `chapter17/kiali` folder called `integrate-kiali-openunison.sh`
    that:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们整合 OpenUnison 和 Kiali。Kiali 和其他集群管理系统一样，应当配置为需要访问权限。Kiali 和 Kubernetes
    Dashboard 一样，可以与 impersonation 集成，这样 Kiali 将使用用户自己的权限与 API 服务器进行交互。完成这个操作相当简单。我们在
    `chapter17/kiali` 文件夹中创建了一个名为 `integrate-kiali-openunison.sh` 的脚本，功能如下：
- en: Deletes the old Gateways and VirtualServices for Kiali, Prometheus, Jaeger,
    and Grafana.
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除 Kiali、Prometheus、Jaeger 和 Grafana 的旧网关和虚拟服务。
- en: Updates Grafana to accept a header for SSO from OpenUnison.
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新 Grafana，以便接受来自 OpenUnison 的 SSO 头部信息。
- en: Updates the Kiali Helm chart to use `header` for `auth.strategy` and restarts
    Kiali to pick up the changes.
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新 Kiali 的 Helm chart，使用 `header` 作为 `auth.strategy`，并重启 Kiali 以应用更改。
- en: Redeploys OpenUnison with Kiali, Prometheus, Jaeger, and Grafana integrated
    for SSO.
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 重新部署 OpenUnison，并集成 Kiali、Prometheus、Jaeger 和 Grafana 以实现单点登录（SSO）。
- en: The integration works the same way as the dashboard, but if you’re interested
    in the details, you can read about them at [https://openunison.github.io/applications/kiali/](https://openunison.github.io/applications/kiali/).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 该集成的工作方式与仪表盘相同，但如果你对细节感兴趣，可以在 [https://openunison.github.io/applications/kiali/](https://openunison.github.io/applications/kiali/)
    阅读相关内容。
- en: 'With the integration completed, let’s see what Kiali can tell us about our
    monolith. First, log in to OpenUnison. You’ll see new badges on the portal screen:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 集成完成后，让我们看看Kiali能告诉我们关于我们单体应用的哪些信息。首先，登录到OpenUnison。你会在门户屏幕上看到新的徽章：
- en: '![Graphical user interface, application, logo, company name  Description automatically
    generated](img/B21165_17_04.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面、应用程序、标志、公司名称 自动生成的描述](img/B21165_17_04.png)'
- en: 'Figure 17.4: OpenUnison portal with the Kiali, Prometheus, Grafana, and Jaeger
    badges'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.4：带有Kiali、Prometheus、Grafana和Jaeger徽章的OpenUnison门户
- en: 'Next, click on the **Kiali** badge to open Kiali, then click on **Graphs**,
    and choose the **openunison** namespace. You’ll see a graph similar to the following:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，点击**Kiali**徽章打开Kiali，然后点击**Graphs**，选择**openunison**命名空间。你将看到类似于以下的图表：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B21165_17_05.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图 自动生成的描述，具有中等信心](img/B21165_17_05.png)'
- en: 'Figure 17.5: OpenUnison graph in Kiali'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 图17.5：Kiali中的OpenUnison图表
- en: You can now view the connections between OpenUnison, `apacheds`, and other containers
    the same way you would with a microservice! Speaking of which, now that we’ve
    learned how to integrate a monolith into Istio, let’s build a microservice and
    learn how it integrates with Istio.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以像查看微服务一样查看OpenUnison、`apacheds`和其他容器之间的连接！说到这里，既然我们已经学习了如何将单体应用集成到Istio中，接下来让我们构建一个微服务，并学习它如何与Istio集成。
- en: Building a microservice
  id: totrans-105
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建一个微服务
- en: 'We spent quite a bit of time talking about monoliths. First, we discussed which
    is the best approach for you, then we spent some time showing how to deploy a
    monolith into Istio to get from it many of the benefits that microservices do.
    Now, let’s dive into building and deploying a microservice. Our microservice will
    be pretty simple. The goal is to show how a microservice is built and integrated
    into an application, rather than how to build a full-fledged application based
    on microservices. Our book is focused on enterprise, so we’re going to focus on
    a service that:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们花了不少时间讨论单体应用。首先，我们讨论了哪种方法最适合你，然后我们花了一些时间展示如何将单体应用部署到Istio中，以从中获得许多微服务的好处。现在，让我们深入探讨构建和部署一个微服务。我们的微服务将会很简单。目标是展示微服务是如何构建并集成到一个应用中的，而不是如何基于微服务构建一个完整的应用程序。我们的书聚焦于企业应用，因此我们将专注于一个服务：
- en: Requires authentication from a specific user
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要特定用户的身份验证
- en: Requires authorization for a specific user based on a group membership or attribute
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 需要基于组成员资格或属性的特定用户授权
- en: Does something very *important*
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 做了一些非常*重要*的事情
- en: Generates some log data about what happened
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 生成一些关于发生了什么的日志数据
- en: This is common in enterprise applications and the services they’re built on.
    Most enterprises need to be able to associate actions, or decisions, with a particular
    person in an organization. If an order is placed, who placed it? If a case is
    closed, who closed it? If a check is cut, who cut it? There are of course many
    instances where a user isn’t responsible for an action. Sometimes, it’s another
    service that is automated. A batch service that pulls in data to create a warehouse
    isn’t associated with a particular person. That is an **interactive** service,
    meaning that an end user is expected to interact with it, so we’re going to assume
    that the user is a person in the enterprise.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这是企业应用程序及其构建服务中的常见情况。大多数企业需要能够将某些操作或决策与组织中的特定人员关联起来。如果下了订单，是谁下的？如果案件被关闭，是谁关闭的？如果支票被开出，是谁开的？当然，也有很多情况下，用户并不对某个操作负责。有时是另一个自动化的服务。一个拉取数据来创建仓库的批处理服务并不与特定人员关联。这是一个**交互式**服务，意味着预期终端用户与其进行交互，因此我们假设用户是企业中的一个人。
- en: Once you know who is going to use the service, you’ll then need to know if the
    user is authorized to do so. In the previous paragraph, we identified that you
    need to know “who cut the check.” Another important question is, “Are they allowed
    to cut the check?” You really don’t want just anybody in your organization sending
    out checks, do you? Identifying who is authorized to perform an action could be
    the subject of multiple books, so to keep things simple, we’ll make our authorization
    decisions based on group membership, at least at a high level.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你知道了谁将使用这个服务，接下来你需要确认用户是否有权使用该服务。在前一段中，我们已经确定了你需要知道“谁开了支票”。另一个重要的问题是，“他们有权开这张支票吗？”你肯定不希望组织中的任何人都能随便开支票，对吧？确定谁有权执行某个操作可能是多本书的内容，因此为了简单起见，我们将基于组成员身份做出授权决策，至少在高级别上是这样。
- en: Having identified the user and authorized them, the next step is to do something
    *important*. It’s an enterprise, filled with important things that need doing!
    Since writing a check is something that we can all relate to and represents many
    of the challenges enterprise services face, we’re going to stick with this as
    our example. We’re going to write a check service that will let us send out checks.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定了用户并授权之后，下一步就是做一些*重要*的事情。这是一个充满需要完成的重要事务的企业！因为写支票是我们都能理解的，并且代表了企业服务面临的许多挑战，我们将继续以此为例。我们将编写一个支票服务，允许我们发出支票。
- en: Finally, having done something *important*, we need to make a record of it.
    We need to track who called our service, and once the service does the important
    parts, we need to make sure we record it somewhere. This can be recorded in a
    database or another service, or even sent to standard-out so that it can be collected
    by a log aggregator, like the OpenSearch we deployed in *Chapter 15*.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，做完一些*重要*的事情后，我们需要进行记录。我们需要跟踪是谁调用了我们的服务，一旦服务完成了重要部分，我们还需要确保将这些信息记录在某个地方。这些记录可以存储在数据库或其他服务中，甚至可以发送到标准输出，以便日志聚合工具（如我们在*第15章*中部署的
    OpenSearch）收集。
- en: 'Having identified all the things that our service will do, the next step is
    to identify which part of our infrastructure will be responsible for each decision
    and action. For our service:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 在确定了我们的服务将做什么之后，下一步是确定我们的基础设施中哪一部分将负责每个决策和行动。对于我们的服务：
- en: '| **Action** | **Component** | **Description** |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| **操作** | **组件** | **描述** |'
- en: '| User Authentication | OpenUnison | Our OpenUnison instance will authenticate
    users to our “Active Directory” |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 用户认证 | OpenUnison | 我们的 OpenUnison 实例将会验证用户的“Active Directory”身份 |'
- en: '| Service Routing | Istio | How we will expose our service to the world |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 服务路由 | Istio | 我们将如何向外界暴露我们的服务 |'
- en: '| Service Authentication | Istio | The `RequestAuthentication` object will
    describe how to validate the user for our service |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 服务认证 | Istio | `RequestAuthentication` 对象将描述如何验证我们服务的用户 |'
- en: '| Service Coarse Grained Authorization | Istio | `AuthorizationPolicy` will
    make sure users are members of a specific group to call our service |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 服务粗粒度授权 | Istio | `AuthorizationPolicy` 将确保用户是某个特定组的成员，从而能够调用我们的服务 |'
- en: '| Fine-Grained Authorization, or Entitlements | Service | Our service will
    determine which payees you’re able to write checks for |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 细粒度授权或权利 | 服务 | 我们的服务将决定你能为哪些收款人开支票 |'
- en: '| Writing a Check | Service | The point of writing this service! |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 写支票 | 服务 | 编写这个服务的目的！ |'
- en: '| Log who Wrote the Check and to whom it was Sent | Service | Write this data
    to standard-out |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 记录是谁写了支票以及支票发给了谁 | 服务 | 将这些数据写入标准输出 |'
- en: '| Log Aggregation | Kubernetes | In production – a tool like OpenSearch |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 日志聚合 | Kubernetes | 在生产环境中——使用像 OpenSearch 这样的工具 |'
- en: 'Table 17.1: Service responsibilities'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 表 17.1：服务职责
- en: We’ll build each of these components, layer by layer, in the following sections.
    Before we get into the service itself, we need to say hello to the world.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的部分中逐层构建这些组件。在深入讨论服务本身之前，我们需要先向世界打个招呼。
- en: Deploying Hello World
  id: totrans-127
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署 Hello World
- en: 'Our first service will be a simple Hello World service that will serve as the
    starting point for our check-writing service. Our service is built on Python using
    Flask. We’re using this because it’s pretty simple to use and deploy. Go to `chapter17/hello-world`
    and run the `deploy_helloworld.sh` script. This will create our `Namespace`, `Deployment`,
    `Service`, and `Istio` objects. Look at the code in the `service-source ConfigMap`.
    This is the main body of our code and the framework on which we will build our
    check service. The code itself doesn’t do much:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的第一个服务将是一个简单的 Hello World 服务，作为我们检查写入服务的起点。我们的服务是基于 Python 和 Flask 构建的。我们使用它是因为它相对简单，易于使用和部署。请进入
    `chapter17/hello-world` 目录并运行 `deploy_helloworld.sh` 脚本。这将创建我们的 `Namespace`、`Deployment`、`Service`
    和 `Istio` 对象。查看 `service-source ConfigMap` 中的代码。这是我们代码的主体，也是我们构建检查服务的框架。代码本身并不做太多的事情：
- en: '[PRE6]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This code accepts all requests to `/` and runs our function called `hello()`,
    which sends a simple response. We’re embedding our code as a `ConfigMap` for the
    sake of simplicity.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码接受所有对 `/` 的请求并运行我们的 `hello()` 函数，返回一个简单的响应。为了简化操作，我们将代码作为 `ConfigMap` 嵌入其中。
- en: If you’ve read all the previous chapters, you’ll notice that we’re violating
    some cardinal rules with this container from a security standpoint. It’s a Docker
    Hub container running as root. That’s OK for now. We didn’t want to get bogged
    down in the build processes for this chapter. In *Chapter 19**, Building a Developer
    Portal*, we’ll walk through using GitLab workflows to build out a more secure
    version of the container for this service.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经阅读了所有前面的章节，你会注意到从安全角度来看，我们的这个容器违反了一些基本规则。它是一个以 root 身份运行的 Docker Hub 容器。现在这样是可以的，我们并不想在这一章中深入探讨构建过程。在*第19章：构建开发者门户*中，我们将通过使用
    GitLab 工作流来构建该服务的更安全版本的容器。
- en: 'Once our service is deployed, we can test it out by using `curl`:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的服务部署完成，我们可以通过使用 `curl` 来测试它：
- en: '[PRE7]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This code isn’t terribly exciting, but next, we’ll add some security to our
    service.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 这段代码并不令人兴奋，但接下来我们将为我们的服务增加一些安全性。
- en: Integrating authentication into our service
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将身份验证集成到我们的服务中
- en: In *Chapter 16*, *An Introduction to Istio*, we introduced the `RequestAuthentication`
    object. Now, we will use this object to enforce authentication. We want to make
    sure that in order to access our service, you must have a valid JWT. In the previous
    example, we just called our service directly. Now, we want to only get a response
    if a valid JWT is embedded in the request. We need to make sure to pair our `RequestAuthentication`
    with an `AuthorizationPolicy` that forces Istio to require a JWT; otherwise, Istio
    will only reject JWTs that don’t conform to our `RequestAuthentication` but allow
    requests that have no JWT at all.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第16章：Istio简介* 中，我们介绍了 `RequestAuthentication` 对象。现在，我们将使用该对象来强制执行身份验证。我们希望确保访问我们的服务时，你必须拥有一个有效的
    JWT。在前面的示例中，我们直接调用了我们的服务。现在，我们希望只有在请求中嵌入有效的 JWT 时，才能收到响应。我们需要确保将我们的 `RequestAuthentication`
    与一个 `AuthorizationPolicy` 配对，这样 Istio 才会强制要求 JWT；否则，Istio 将只会拒绝不符合我们 `RequestAuthentication`
    的 JWT，而允许没有 JWT 的请求。
- en: 'Even before we configure our objects, we need to get a JWT from somewhere.
    We’re going to use OpenUnison. To work with our API, let’s deploy the pipeline
    token generation chart we deployed in *Chapter 6**, Integrating Authentication
    into Your Cluster*. Go to the `chapter6/pipelines` directory and run the Helm
    chart:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 即使在我们配置对象之前，我们也需要从某个地方获取 JWT。我们将使用 OpenUnison。为了与我们的 API 一起使用，让我们部署我们在 *第6章：将身份验证集成到集群中*
    中部署的管道令牌生成图表。进入 `chapter6/pipelines` 目录并运行 Helm 图表：
- en: '[PRE8]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This will give us a way to easily generate a JWT from our internal Active Directory.
    Next, we’ll deploy the actual policy objects. Go into the `chapter17/authentication`
    directory and run `deploy-auth.sh`. It will look like this:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为我们提供一个轻松从内部 Active Directory 生成 JWT 的方法。接下来，我们将部署实际的策略对象。进入 `chapter17/authentication`
    目录并运行 `deploy-auth.sh`。它将如下所示：
- en: '[PRE9]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'First, we created a `Secret` called `cacerts` to store our enterprise CA certificate
    and restart `istiod`. This will allow `istiod` to communicate with OpenUnison
    to pull `jwks` signature verification keys. Next, two objects are created. The
    first is the `RequestAuthentication` object and then a simple `AuthorizationPolicy`.
    First, we will walk through `RequestAuthentication`:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们创建了一个名为 `cacerts` 的 `Secret`，用于存储我们的企业 CA 证书，并重新启动 `istiod`。这将允许 `istiod`
    与 OpenUnison 通信，以拉取 `jwks` 签名验证密钥。接下来，创建了两个对象。第一个是 `RequestAuthentication` 对象，第二个是简单的
    `AuthorizationPolicy`。首先，我们将介绍 `RequestAuthentication`：
- en: '[PRE10]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'This object first specifies how the JWT needs to be formatted in order to be
    accepted. We’re cheating here a bit by just leveraging our Kubernetes JWT. Let’s
    compare this object to our JWT:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 这个对象首先指定了JWT需要如何格式化才能被接受。我们这里有点作弊，直接利用我们的Kubernetes JWT。让我们将这个对象与我们的JWT进行比较：
- en: '[PRE11]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The `aud` claim in our JWT lines up with the audiences in our `RequestAuthentication`.
    The `iss` claim lines up with `issuer` in our `RequestAuthentication`. If either
    of these claims doesn’t match, then Istio will return a `401` HTTP error code
    to tell you that the request is unauthorized.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们JWT中的`aud`声明与`RequestAuthentication`中的受众对齐。`iss`声明与`RequestAuthentication`中的`issuer`对齐。如果这两个声明中的任何一个不匹配，Istio将返回`401`
    HTTP错误代码，告诉你请求未经授权。
- en: 'We also specify `outputPayloadToHeader: User-Info` to tell Istio to pass the
    user info to the downstream service as a base64-encoded JSON header, with the
    name `User-Info`. This header can be used by our service to identify who called
    it. We’ll get into the details of this when we get into entitlement authorization.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '我们还指定了`outputPayloadToHeader: User-Info`，告诉Istio将用户信息作为base64编码的JSON头传递给下游服务，头部名称为`User-Info`。我们的服务可以使用这个头部来识别谁调用了它。当我们进入权限授权时，我们将详细介绍这一点。'
- en: Additionally, the `jwksUri` section specifies the URL that contains the RSA
    public keys used to verify the JWT. This can be obtained by first going to the
    issuer’s OIDC discovery URL and getting the URL from the `jwks` claim.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，`jwksUri`部分指定了包含用于验证JWT的RSA公钥的URL。这个URL可以通过首先访问发行者的OIDC发现URL并从`jwks`声明中获取。
- en: It’s important to note that the `RequestAuthentication` object will tell Istio
    what form the JWT needs to take, but not what data about the user needs to be
    present. We’ll cover that next, in the authorization section.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`RequestAuthentication`对象会告诉Istio JWT需要采取什么形式，但不会指定需要包含哪些用户数据。我们将在接下来的授权部分进行介绍。
- en: 'Speaking of authorization, we want to make sure to enforce the requirement
    for a JWT, so we will create this very simple `AuthorizationPolicy`:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 说到授权，我们希望确保强制要求JWT，因此我们将创建一个非常简单的`AuthorizationPolicy`：
- en: '[PRE12]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `from` section says that there must be a `requestPrincipal`. This tells
    Istio there must be a user (and in this case, anonymous is not a user). `requestPrincipal`
    comes from JWTs and represents users. There is also a `principal` configuration,
    but this represents the service calling our URL, which in this case would be `ingressgateway`.
    This tells Istio that a user must be authenticated via a JWT.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`from`部分表示必须有一个`requestPrincipal`。这告诉Istio必须有一个用户（在这种情况下，匿名用户不是用户）。`requestPrincipal`来自JWT，表示用户。还有一个`principal`配置，但它表示调用我们URL的服务，在这种情况下会是`ingressgateway`。这告诉Istio，用户必须通过JWT进行身份验证。'
- en: 'With our policy in place, we can now test it. First, with no user:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们有了策略之后，接下来可以进行测试。首先，测试没有用户的情况：
- en: '[PRE13]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We can see that the request was denied with a `403` HTTP code. We received
    `403` because Istio was expecting a JWT but there wasn’t one. Next, let’s generate
    a valid token the same way we did in *Chapter 6**, Integrating Authentication
    into Your Cluster*:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到请求被拒绝，并返回了`403` HTTP代码。收到`403`是因为Istio期望一个JWT，但请求中没有JWT。接下来，让我们按照*第6章*中的方式生成一个有效的令牌，《将身份验证集成到集群中》：
- en: '[PRE14]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now, we have success! Our hello world service now requires proper authentication.
    Next, we’ll update our authorization to require a specific group from Active Directory.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们成功了！我们的Hello World服务现在要求进行正确的身份验证。接下来，我们将更新授权，要求来自Active Directory的特定组。
- en: Authorizing access to our service
  id: totrans-157
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 授权访问我们的服务
- en: So far, we’ve built a service and made sure users have a valid JWT from our
    identity provider before they can access it.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经构建了一个服务，并确保用户在访问之前从身份提供者获得有效的JWT。
- en: Now, we want to apply what’s often referred to as “coarse-grained” authorization.
    This is application- or service-level access. It says, “You are generally able
    to use this service,” but it doesn’t say you’re able to perform the action you
    wish to take. For our check-writing service, you may be authorized to write a
    check, but there are likely more controls that limit who you can write a check
    for. If you’re responsible for the **Enterprise Resource Planning** (**ERP**)
    system in your enterprise, you probably shouldn’t be able to write checks for
    the facility vendors. We’ll get into how your service can manage these business-level
    decisions in the next section, but for now, we’ll focus on the service-level authorization.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们希望应用通常称为“粗粒度”授权的方式。这是应用层或服务级别的访问控制。它的意思是：“你通常可以使用此服务”，但并未说明你是否可以执行你希望进行的操作。对于我们的支票写作服务，你可能被授权写支票，但可能有更多的控制措施限制你可以为谁写支票。如果你负责企业中的**企业资源规划**（**ERP**）系统，你可能不应该能够为设施供应商写支票。我们将在下一部分讨论如何让服务管理这些业务级别的决策，但现在，我们将重点讨论服务级别的授权。
- en: 'It turns out we have everything we need. Earlier, we looked at our `mmosley`
    user’s JWT, which had multiple claims. One such claim was the `groups` claim.
    We used this claim in *Chapter 6*, *Integrating Authentication into Your Cluster*,
    and *Chapter 7*, *RBAC Policies and Auditing*, to manage access to our cluster.
    In a similar fashion, we’ll manage who can access our service based on our membership
    of a particular group. First, we’ll delete our existing policy:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 结果证明我们已经具备了所有需要的信息。之前，我们查看了`mmosley`用户的JWT，其中包含多个声明。其中一个声明是`groups`声明。我们在*第6章*、*将身份验证集成到集群中*和*第7章*、*RBAC策略与审计*中使用了该声明来管理对集群的访问。以类似的方式，我们将根据是否属于特定组来管理谁可以访问我们的服务。首先，我们将删除现有策略：
- en: '[PRE15]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: With the policy disabled, you can now access your service without a JWT. Next,
    we’ll create a policy that requires you to be a member of the group `cn=group2,ou=Groups,DC=domain,DC=com`
    in our Active Directory.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 禁用该策略后，你现在可以在没有JWT的情况下访问服务。接下来，我们将创建一个策略，要求你是Active Directory中`cn=group2,ou=Groups,DC=domain,DC=com`组的成员。
- en: 'Deploy the below policy (in `chapter17/coursed-grained-authorization/coursed-grained-az.yaml`):'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 部署以下策略（在`chapter17/coursed-grained-authorization/coursed-grained-az.yaml`中）：
- en: '[PRE16]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'This policy tells Istio that only users with a claim called `groups` that have
    the value `cn=group2,ou=Groups,DC=domain,DC=com` are able to access this service.
    With this policy deployed, you’ll see that you can still access the service as
    `mmosley`, and trying to access the service anonymously still fails. Next, try
    accessing the service as `jjackson`, with the same password:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 该策略告诉Istio，只有具有名为`groups`且值为`cn=group2,ou=Groups,DC=domain,DC=com`的声明的用户才能访问此服务。部署此策略后，你会发现你仍然可以以`mmosley`身份访问服务，匿名访问服务仍然失败。接下来，尝试以`jjackson`身份访问服务，使用相同的密码：
- en: '[PRE17]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'We’re not able to access this service as `jjackson`. If we look at `jjackson`''s
    `id_token`, we can see why:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 我们无法以`jjackson`身份访问该服务。如果我们查看`jjackson`的`id_token`，就能明白原因：
- en: '[PRE18]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Looking at the claims, `jjackson` isn’t a member of the group `cn=group2,ou=Groups,DC=domain,DC=com`.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 查看声明后，`jjackson`并不是`cn=group2,ou=Groups,DC=domain,DC=com`组的成员。
- en: Now that we’re able to tell Istio how to limit access to our service to valid
    users, the next step is to tell our service who the user is. We’ll then use this
    information to look up authorization data, log actions, and act on the user’s
    behalf.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们能够告诉Istio如何限制服务的访问权限，仅允许有效用户访问，下一步是告诉我们的服务用户是谁。然后，我们将使用这些信息查找授权数据、记录操作，并代表用户进行操作。
- en: Telling your service who’s using it
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 告诉你的服务谁在使用它
- en: 'When writing a service that does anything involving a user, the first thing
    you need to determine is, “Who is trying to use my service?” So far, we have told
    Istio how to determine who the user is, but how do we propagate that information
    down to our service? Our `RequestAuthentication` included the configuration option
    `outputPayloadToHeader: User-Info`, which injects the claims from our user’s authentication
    token as base64-encoded JSON into the HTTP request’s headers. This information
    can be pulled from that header and used by your service to look up additional
    authorization data.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '在编写涉及用户的服务时，首先需要确定的是：“谁在尝试使用我的服务？”到目前为止，我们已经告诉Istio如何确定用户身份，但我们如何将该信息传递给我们的服务呢？我们的`RequestAuthentication`包含了配置选项`outputPayloadToHeader:
    User-Info`，该选项将用户身份验证令牌中的声明作为base64编码的JSON注入到HTTP请求的头部。这些信息可以从该头部提取，并由你的服务用来查找额外的授权数据。'
- en: 'We can view this header with a service we built, called `/headers`. This service
    will just give us back all the headers that are passed to our service. Let’s take
    a look:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过我们构建的一个名为`/headers`的服务查看此头信息。该服务将返回传递给我们服务的所有头信息。让我们来看看：
- en: '[PRE19]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'There are several headers here. The one we care about is `User-Info`. This
    is the name of the header we specified in our `RequestAuthentication` object.
    If we decode from base64, we’ll get some JSON:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个头信息。我们关心的是`User-Info`。这是我们在`RequestAuthentication`对象中指定的头信息名称。如果我们从base64解码，我们会得到一些JSON：
- en: '[PRE20]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: We have all the same claims as if we had decoded the token ourselves. What we
    don’t have is the JWT. This is important from a security standpoint. Our service
    can’t leak a token it doesn’t possess.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们拥有的所有声明就像我们自己解码令牌时得到的一样。我们没有的是JWT。这从安全角度来看非常重要。我们的服务不能泄露它没有的令牌。
- en: 'Now that we know how to determine who the user is, let’s integrate that into
    a simple `who-am-i` service that just tells us who the user is. First, let’s look
    at our code:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何确定用户身份了，让我们将其集成到一个简单的`who-am-i`服务中，该服务只会告诉我们用户是谁。首先，让我们看看我们的代码：
- en: '[PRE21]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: This is pretty basic. We’re getting the header from our request. Next, we decode
    it from base64, and finally, we get the JSON and add it to a return. If this were
    a more complex service, this is where we might query a database to determine what
    entitlements our user has.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常基础。我们从请求中获取头信息。接下来，我们将其从base64解码，最后，我们得到JSON并将其添加到返回中。如果这是一个更复杂的服务，这时我们可能会查询数据库来确定用户拥有的权限。
- en: 'In addition to not requiring that our code knows how to verify the JWT, this
    also makes it easier for us to develop our code in isolation from Istio. Open
    a shell in your `run-service` pod and try accessing this service directly with
    any user:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 除了不要求我们的代码知道如何验证JWT外，这还使得我们更容易在与Istio隔离的情况下开发代码。打开`run-service` pod中的shell，尝试使用任何用户直接访问这个服务：
- en: '[PRE22]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: We were able to call our service without having to know anything about Istio,
    JWTs, or cryptography! Everything was offloaded to Istio so that we could focus
    on our service. While this does make for easier development, what are the impacts
    on security if there’s a way to inject any information we want into our service?
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们能够在不需要了解任何关于Istio、JWT或加密学的知识的情况下调用我们的服务！所有的工作都交给Istio处理，这样我们就可以专注于我们的服务。虽然这确实简化了开发，但如果存在一种方法可以将我们想要的任何信息注入到我们的服务中，这对安全性有什么影响呢？
- en: 'Let’s try this directly from a namespace that doesn’t have the Istio sidecar:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个没有Istio sidecar的命名空间直接尝试一下：
- en: '[PRE23]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Our `RequestAuthentication` and `AuthorizationPolicy` stop the request. While
    we’re not running the sidecar, our service is, and it redirects all traffic to
    Istio where our policies will be enforced. What about if we try to inject our
    own `User-Info` header from a valid request?
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的`RequestAuthentication`和`AuthorizationPolicy`阻止了请求。尽管我们没有运行sidecar，但我们的服务正在运行，它将所有流量重定向到Istio，在那里我们的策略将被执行。那么如果我们尝试从一个有效请求中注入自己的`User-Info`头信息呢？
- en: '[PRE24]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Once again, our attempt to override who the user is outside of a valid JWT has
    been foiled by Istio. We’ve shown how Istio injects a user’s identity into our
    service; now, we need to know how to authorize a user’s entitlements.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 再一次，我们试图覆盖用户身份的行为（在有效的JWT之外）被Istio阻止了。我们已经展示了Istio如何将用户身份注入到我们的服务中；现在，我们需要了解如何授权用户的权限。
- en: Authorizing user entitlements
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 授权用户权限
- en: So far, we’ve managed to add quite a bit of functionality to our service without
    having to write any code. We added token-based authentication and coarse-grained
    authorization. We know who the user is and have determined that, at the service
    level, they are authorized to call our service. Next, we need to decide if the
    user is allowed to do the specific action they’re trying to do. This is often
    called fine-grained authorization or entitlements. In this section, we’ll walk
    through multiple approaches you can take, discussing how you should choose an
    approach.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经在不编写任何代码的情况下为我们的服务添加了很多功能。我们增加了基于令牌的身份验证和粗粒度的授权。我们知道用户是谁，并且已经确定在服务层面，他们被授权调用我们的服务。接下来，我们需要决定用户是否被允许执行他们尝试做的特定操作。这通常被称为细粒度授权或权限。在这一部分，我们将讨论多种方法，并讨论你应该如何选择一种方法。
- en: Authorizing in service
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务中的授权
- en: Unlike coarse-grained authorizations and authentication, entitlements are generally
    not managed at the service mesh layer. That’s not to say it’s impossible. We’ll
    talk about ways you can do this in the service mesh, but in general, it’s not
    the best approach. Authorizations are generally tied to business data that’s usually
    locked up in a database. Sometimes, that database is a generic relational database,
    like MySQL or SQL Server, but it could really be anything. Since the data used
    to make the authorization decision is often owned by the service owner, not the
    cluster owner, it’s generally easier and more secure to make entitlement decisions
    directly in our code.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 与粗粒度的授权和身份验证不同，权限通常不在服务网格层面进行管理。但这并不意味着不可能做到。我们会讨论在服务网格中如何做，但一般来说，这不是最好的做法。授权通常与业务数据相关，这些数据通常存储在数据库中。有时，数据库是一个通用的关系型数据库，比如
    MySQL 或 SQL Server，但它也可以是任何类型的数据库。由于用于做出授权决策的数据通常由服务拥有者而非集群拥有者管理，因此在代码中直接做出权限决策通常更简单、更安全。
- en: Earlier, we discussed in our check-writing service that we don’t want someone
    responsible for the ERP to cut checks to the facilities vendor. Where is the data
    that determines that? Well, it’s probably in your enterprise’s ERP system. Depending
    on how big you are, this could be a homegrown application or a SAP or Oracle.
    Let’s say you wanted Istio to make the authorization decision for our check-writing
    service. How would it get that data? Do you think the people responsible for the
    ERP want you, as a cluster owner, to talk to their database directly? Do you,
    as a cluster owner, want that responsibility? What happens when something goes
    wrong with the ERP and someone points the finger at you for the problem? Do you
    have the resources to prove that you, and your team, were not responsible?
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们讨论过在我们的开支票服务中，我们不希望负责 ERP 的人向设施供应商开支票。那决定数据在哪里呢？很可能就在你企业的 ERP 系统中。根据你的企业规模，可能是自研的应用程序，也可能是
    SAP 或 Oracle。假设你希望 Istio 为我们的开支票服务做出授权决策。它如何获取这些数据？你认为负责 ERP 的人希望你，作为集群拥有者，直接访问他们的数据库吗？作为集群拥有者，你愿意承担这个责任吗？如果
    ERP 出现问题，且有人指责你造成了问题怎么办？你有足够的资源证明你和你的团队并不负责吗？
- en: It turns out that the silos in enterprises that benefit from the management
    aspects of microservice design also work against centralized authorization. In
    our example of determining who can write the check for a specific vendor, it’s
    probably just easiest to make this decision inside our service. This way, if there’s
    a problem, it’s not the Kubernetes team’s responsibility to determine the issue,
    and the people who are responsible are in control of their own destiny.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 事实证明，企业中那些受益于微服务设计管理方面的独立模块也会对集中式授权产生不利影响。在我们确定谁可以为特定供应商开支票的例子中，最简单的做法可能就是在我们的服务内部做出这个决定。这样，如果出现问题，Kubernetes
    团队就不需要负责确定问题所在，而负责的人可以掌控自己的命运。
- en: That’s not to say there isn’t an advantage to a more centralized approach to
    authorization. Having teams implement their own authorization code will lead to
    different standards being used and different approaches. Without careful controls,
    it can lead to a compliance nightmare. Let’s look at how Istio could provide a
    more robust framework for authorization.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这并不是说更集中式的授权方式就没有优势。让各个团队实现自己的授权代码会导致使用不同的标准和方法。如果没有严格的控制，可能会导致合规性问题。让我们看看 Istio
    如何提供一个更强大的授权框架。
- en: Using OPA with Istio
  id: totrans-196
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Istio 中使用 OPA
- en: 'Using the Envoy filters feature discussed in *Chapter 16*, *An Introduction
    to Istio*, you can integrate the **Open Policy Agent** (**OPA**) into your service
    mesh to make authorization decisions. We discussed OPA in *Chapter 11*, *Extending
    Security Using Open Policy Agent*. There are a few key points about OPA we need
    to review:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 使用在*第16章*《Istio简介》中讨论的 Envoy 过滤器功能，你可以将**开放策略代理**（**OPA**）集成到你的服务网格中来做出授权决策。我们在*第11章*《使用开放策略代理扩展安全性》中讨论了
    OPA。我们需要回顾一下关于 OPA 的几个关键点：
- en: OPA does not (typically) reach out to external data stores to make authorization
    decisions. Much of the benefit of OPA requires that it uses its own internal database.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OPA 通常不会向外部数据存储请求授权决策。OPA 的许多优势要求它使用自己的内部数据库。
- en: OPA’s database is not persistent. When an OPA instance dies, it must be repopulated
    with data.
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OPA 的数据库是非持久化的。当 OPA 实例终止时，必须重新填充数据。
- en: OPA’s databases are not clustered. If you have multiple OPA instances, each
    database must be updated independently.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OPA 的数据库没有集群功能。如果您有多个 OPA 实例，每个数据库必须独立更新。
- en: To use OPA to validate whether our user can write a check for a specific vendor,
    OPA would either need to be able to pull that data directly from the JWT or have
    the ERP data replicated in its own database. The former is unlikely to happen
    for multiple reasons. First, the issues with your cluster talking to your ERP
    will still exist when your identity provider tries to talk to your ERP. Second,
    the team that runs your identity provider would need to know to include the correct
    data, which is a difficult task and is unlikely something they’re interested in
    doing. Finally, there could be numerous folks, from security to the ERP team,
    who are not comfortable with this data being stored in a token that gets passed
    around. The latter option, syncing data into OPA, is more likely to be successful.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 OPA 验证我们的用户是否可以为特定供应商开具支票，OPA 要么需要能够直接从 JWT 中拉取数据，要么需要将 ERP 数据复制到其自己的数据库中。前者由于多种原因不太可能实现。首先，当您的身份提供者尝试与
    ERP 通信时，您的集群与 ERP 之间的问题仍然存在。其次，运行身份提供者的团队需要知道包括正确的数据，这是一个困难的任务，而且他们不太可能有兴趣去做。最后，可能会有许多人员（从安全到
    ERP 团队）不愿意将这些数据存储在一个被传递的令牌中。后者，即将数据同步到 OPA，更有可能成功。
- en: There are two ways you could sync your authorization data from your ERP into
    your OPA databases. The first is by pushing the data. A “bot” could push updates
    to each OPA instance. This way, the ERP owner is responsible for pushing the data,
    with your cluster just being a consumer. However, there’s no simple way to do
    this, and security would be a concern to make sure someone doesn’t push false
    data. The alternative is to write a pull “bot” that runs as a sidecar to your
    OPA pods. This is how GateKeeper works. The advantage here is that you have the
    responsibility of keeping your data synced without having to build a security
    framework to push data.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可以将您的授权数据从 ERP 同步到 OPA 数据库。第一种是通过推送数据。一个“机器人”可以将更新推送到每个 OPA 实例。这种方式下，ERP
    所有者负责推送数据，您的集群仅作为消费者。然而，这种方式没有简单的实现方法，安全性也会成为一个问题，必须确保没有人推送虚假数据。另一种选择是编写一个拉取“机器人”，作为
    OPA pod 的副车运行。这就是 GateKeeper 的工作方式。这里的优势是，您可以负责保持数据同步，而无需构建一个推送数据的安全框架。
- en: In either scenario, you’ll need to understand whether there are any compliance
    issues with the data you are storing. Now that you have the data, what’s the impact
    of losing it in a breach? Is that a responsibility you want?
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在这两种情况下，您都需要了解存储的数据是否存在任何合规性问题。现在您已经拥有数据，数据在泄露中丢失会带来什么影响？这是您想承担的责任吗？
- en: Centralized authorization services have been discussed for entitlements long
    before Kubernetes or even RESTful APIs existed. They even predate SOAP and XML!
    For enterprise applications, it’s never really worked because of the additional
    costs in data management, ownership, and bridging silos. If you own all of the
    data, this is a great approach. When one of the main goals of microservices is
    to allow silos to better manage their own development, forcing a centralized entitlements
    engine is not likely to succeed.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 集中化授权服务在 Kubernetes 或甚至 RESTful API 出现之前就已经被讨论过了。它们甚至比 SOAP 和 XML 还要早！对于企业应用而言，这种方式从未真正成功，因为数据管理、所有权以及打破孤岛所带来的额外成本。如果您拥有所有数据，这种方式非常合适。而当微服务的主要目标之一是让各个孤岛能够更好地管理自己的开发时，强迫使用集中化的授权引擎很可能无法成功。
- en: 'With all that said, there has been a move towards centralizing authorization
    services. This movement has spawned several commercial companies and projects
    outside of OPA:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，已经出现了集中化授权服务的趋势。这个趋势催生了许多商业公司和项目，这些项目位于 OPA 之外：
- en: '**Cedar**: An open source project from Amazon Web Services that creates a new
    policy language. Amazon has also created a service built on this language: [https://github.com/cedar-policy](https://github.com/cedar-policy).'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cedar**：亚马逊网络服务（Amazon Web Services）推出的一个开源项目，旨在创建一种新的策略语言。亚马逊还基于这种语言创建了一个服务：[https://github.com/cedar-policy](https://github.com/cedar-policy)。'
- en: '**Topaz**: Built on OPA and Zanzibar, Topaz provides the OPA authorization
    engine with relationship-based authorizations from Zanzibar. There’s also a commercial
    offering: [https://github.com/aserto-dev/topaz](https://github.com/aserto-dev/topaz).'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Topaz**：基于 OPA 和 Zanzibar 构建，Topaz 为 OPA 授权引擎提供了来自 Zanzibar 的基于关系的授权。此外，还有一个商业产品：[https://github.com/aserto-dev/topaz](https://github.com/aserto-dev/topaz)。'
- en: '**OpenFGA**: Another engine built on Zanzibar’s relationship-based authorization
    system, built by Auth0/Okta: [https://github.com/openfga](https://github.com/openfga).'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenFGA**：另一个基于 Zanzibar 关系授权系统构建的引擎，由 Auth0/Okta 构建：[https://github.com/openfga](https://github.com/openfga)。'
- en: We’re not going to dive into any of these solutions in detail; the point is
    that there has been a clear movement toward building authorization solutions,
    similar to how externalized authentication has been a product and project category
    for multiple decades.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入探讨这些解决方案的细节；关键在于，已经有了一个明确的趋势，即构建授权解决方案，类似于外部身份验证已经成为一个产品和项目类别，历时数十年。
- en: Now that we know some of the issues involved in creating a centralized authorization,
    let’s build out an authorization rule with OPA for Istio.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了创建集中式授权的一些问题，让我们为 Istio 使用 OPA 构建一个授权规则。
- en: Creating an OPA Authorization Rule
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建 OPA 授权规则
- en: Earlier in this section, we discussed writing checks. A common rule for writing
    checks is that the person who writes the check is now also allowed to sign the
    check. This rule is called a “separation of duties.” It’s designed to build checkpoints
    for potentially harmful and costly processes. For instance, if an employee were
    allowed to both write the check and sign it, there’s no chance for someone to
    ask if the check is being written for a valid reason.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节前面，我们讨论了编写检查的规则。编写检查的常见规则是，编写支票的人也允许签署支票。这个规则称为“职责分离”。它旨在为潜在的有害和高成本的过程构建检查点。例如，如果允许一个员工既编写支票又签署支票，就没有机会有人询问支票是否用于有效的理由。
- en: We’ve already implemented an AuthorizationPolicy that validates group membership,
    but for separation of duties, what we want is to implement a rule that validates
    that a user is a member of one group while NOT a member of another group. This
    sort of complex decision isn’t possible with a generic AuthorizationPolicy, so
    we’re going to need to build our own. We can use OPA as our authorization engine
    while instructing Istio to use our policy.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经实现了一个验证用户组成员资格的 AuthorizationPolicy，但为了职责分离，我们需要实现一个规则来验证用户属于某个组，同时**不**属于另一个组。这样的复杂决策是通用
    AuthorizationPolicy 无法实现的，因此我们需要构建我们自己的策略。我们可以使用 OPA 作为我们的授权引擎，同时指示 Istio 使用我们的策略。
- en: 'Before we deploy our policy, let’s review it. The full policy is in `chapter17/opa/rego`
    and includes test cases:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们部署策略之前，让我们复查一下它。完整的策略位于 `chapter17/opa/rego` 中，并包含测试用例：
- en: '[PRE25]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We removed the comments to make the code more compact. The basics of this policy
    are that we:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 我们移除了注释，以使代码更加简洁。该策略的基本内容是：
- en: Verify that there’s an `authorization` header.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证是否存在 `authorization` 头部。
- en: Verify that the `authorization` header is a `Bearer` token.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证 `authorization` 头部是否为 `Bearer` 令牌。
- en: Verify that the bearer token is a JWT.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证承载令牌是否为 JWT。
- en: Parse the JWT and verify that there is a `groups` claim.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解析 JWT 并验证是否包含 `groups` 声明。
- en: If the `groups` claim is a list, make sure that it contains the `k8s-cluster-admins`
    group, but NOT the `group2` group.
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果 `groups` 声明是一个列表，确保它包含 `k8s-cluster-admins` 组，但**不**包含 `group2` 组。
- en: If the `groups` claim is not a list, only validate that it’s the `k8s-cluster-admins`
    group.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果 `groups` 声明不是列表，仅验证它是否为 `k8s-cluster-admins` 组。
- en: We are validating that the authorization header is present and properly formatted
    because Istio does not require a token to be present to pass authentication. This
    was done by our previous `AuthorizationPolicy`, either explicitly by requiring
    that a principal be present or implicitly by requiring that a specific claim has
    a specific value.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在验证授权头是否存在且格式正确，因为 Istio 不要求必须提供令牌才能通过身份验证。这是通过我们之前的 `AuthorizationPolicy`
    实现的，无论是通过显式要求存在某个主体，还是通过隐式要求某个特定声明具有特定值。
- en: Once we have validated that the authorization header is properly formatted,
    we parse it for a payload. We’re not validating the JWT based on its public key,
    validity, or issuer because our `RequestAuthentication` object is doing that for
    us. We just need to make sure that the token is there.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们验证了授权头的格式正确，我们就会解析其负载。我们不会基于公钥、有效性或颁发者来验证 JWT，因为我们的 `RequestAuthentication`
    对象会为我们完成这部分验证。我们只需要确保令牌存在。
- en: Finally, we have two potential `allow` policies. The first is if the `groups`
    claim is a list, so we need to apply array logic to see if the correct group is
    present and that the forbidden group is not present. The second `allow` policy
    will trigger if the `groups` claim is not a list but only a single value. In this
    case, we only care that the group’s value is our admin group.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有两个潜在的 `allow` 策略。第一个是当 `groups` 声明是一个列表时，我们需要应用数组逻辑来检查是否存在正确的组，并且不存在被禁止的组。第二个
    `allow` 策略会在 `groups` 声明不是列表，而只是一个单一值时触发。在这种情况下，我们只关心该组的值是否是我们的管理员组。
- en: 'To deploy this policy, go to the `chapter17/opa` directory and run `deploy_opa_istio.sh`.
    The script will enable authorization and deploy our policy:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署此策略，请进入 `chapter17/opa` 目录并运行 `deploy_opa_istio.sh`。该脚本将启用授权并部署我们的策略：
- en: '**Configure istiod**: Updates the `istio` `ConfigMap` that stores the mesh
    configuration to enable the `envoyExtAuthzGrpc` extension provider.'
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**配置 istiod**：更新存储网格配置的 `istio` `ConfigMap`，以启用 `envoyExtAuthzGrpc` 扩展提供程序。'
- en: '**Deploy an OPA mutating admission controller**: A mutating admission controller
    is deployed to automate the creation of an OPA instance on pods that runs alongside
    your services.'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**部署 OPA 变异准入控制器**：部署一个变异准入控制器，自动在 pod 上创建 OPA 实例，与服务一起运行。'
- en: '**Deploys our policy**: The policy we created earlier is created as a `ConfigMap`.'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**部署我们的策略**：我们之前创建的策略被作为 `ConfigMap` 创建。'
- en: '**Redeploy our service**: Deletes the pod so that it is recreated with our
    authorization policy.'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**重新部署我们的服务**：删除 pod，使其根据我们的授权策略重新创建。'
- en: 'Once everything is deployed, we can now verify that our policy is being enforced
    using a `curl` command. If we try to call our headers service now with our `mmosley`
    user, it will fail because `mmosley` is a member of both the `k8s-cluster-admin`
    group and the `group2` group:'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦所有内容都部署完成，我们现在可以使用 `curl` 命令验证我们的策略是否生效。如果我们现在尝试使用 `mmosley` 用户调用我们的头信息服务，它将失败，因为
    `mmosley` 是 `k8s-cluster-admin` 组和 `group2` 组的成员：
- en: '[PRE26]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'However, if we use our `pipeline_svc_account` user, it succeeds because this
    user is only a member of the `k8s-cluster-admin` group:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果我们使用 `pipeline_svc_account` 用户，它会成功，因为该用户仅是 `k8s-cluster-admin` 组的成员：
- en: '[PRE27]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Now, we can build more complex policies than what’s possible with Istio’s `AuthorizationPolicy`'s
    built-in authorization capabilities.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以构建比 Istio 的 `AuthorizationPolicy` 内置授权功能更复杂的策略。
- en: Having determined how to integrate entitlements into our services, the next
    question we need to answer is, how do we securely call other services?
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 确定了如何将授权集成到我们的服务中之后，我们需要回答的下一个问题是，如何安全地调用其他服务？
- en: Calling other services
  id: totrans-237
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调用其他服务
- en: We’ve written services that do simple things, but what about when your service
    needs to talk to another service? Just like with almost every other set of choices
    in your cluster rollout, you have multiple options to authenticate to other services.
    Which choice you make will depend on your needs. We’ll first cover the OAuth2
    standard way of getting new tokens for service calls and how Istio works with
    it. We’ll then cover some alternatives that should be considered anti-patterns
    but that you may choose to use anyway.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们编写了执行简单任务的服务，但当你的服务需要与另一个服务通信时怎么办？就像集群部署中的几乎所有其他选择一样，你有多种方式来验证对其他服务的身份。你选择哪种方式取决于你的需求。我们将首先介绍
    OAuth2 标准的获取新令牌的方式及其如何与 Istio 配合使用。然后，我们将介绍一些应被视为反模式的替代方法，但你可能仍然选择使用它们。
- en: Using OAuth2 Token Exchange
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 OAuth2 令牌交换
- en: Your service knows who your user is but needs to call another service. How do
    you identify yourself to the second service? The OAuth2 specification, which OpenID
    Connect is built on, has RFC 8693 – OAuth2 Token Exchange for this purpose. The
    basic idea is that your service will get a fresh token from your identity provider
    for the service call, based on the existing user. By getting a fresh token for
    your own call to a remote service, you’re making it easier to lock down where
    tokens can be used and who can use them, allowing yourself to more easily track
    a call’s authentication and authorization flow. The following diagram gives a
    high-level overview.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 你的服务知道你的用户是谁，但需要调用另一个服务。你如何向第二个服务证明你的身份？OAuth2 规范（OpenID Connect 就是基于它）有 RFC
    8693 – OAuth2 令牌交换用于此目的。基本思路是，你的服务将根据现有的用户，从身份提供商处获取新的令牌来进行服务调用。通过为你的远程服务调用获取新的令牌，你可以更容易地控制令牌的使用范围和使用者，从而更轻松地跟踪调用的身份验证和授权流程。以下图表提供了一个高层次的概述。
- en: '![A picture containing text, screenshot, line, diagram  Description automatically
    generated](img/B21165_17_06.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![包含文本的图片，截图，线条，图示  说明自动生成](img/B21165_17_06.png)'
- en: 'Figure 17.6: OAuth2 Token Exchange sequence'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17.6：OAuth2 令牌交换序列
- en: 'There are some details we’ll walk through that depend on your use case:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的使用场景，有一些细节我们需要逐一说明：
- en: The user requests an `id_token` from the identity provider. How the user gets
    their token doesn’t really matter for this part of the sequence. We’ll use a utility
    in OpenUnison for our lab.
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户向身份提供者请求 `id_token`。在这一部分的序列中，用户如何获得令牌并不重要。我们将在实验中使用 OpenUnison 中的工具。
- en: Assuming you’re authenticated and authorized, your identity provider will give
    you an `id_token` with an `aud` claim that will be accepted by Service-X.
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设你已通过身份验证并获得授权，身份提供者将为你提供一个带有 `aud` 声明的 `id_token`，该声明将被 Service-X 接受。
- en: The user uses the `id_token` as a bearer token to call Service-X. It goes without
    saying that Istio will validate this token.
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 用户将 `id_token` 作为持有令牌（bearer token）来调用 Service-X。不言而喻，Istio 将验证此令牌。
- en: Service-X requests a token for Service-Y from the identity provider on behalf
    of the user. There are two potential methods to do this. One is impersonation;
    the other is delegation. We’ll cover both in detail later in this section. You’ll
    send your identity provider your original `id_token` and something to identify
    the service to the identity provider.
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Service-X 代表用户向身份提供者请求 Service-Y 的令牌。执行此操作有两种可能的方法，一种是模拟身份，另一种是委托身份。我们将在本节稍后详细讨论这两种方法。你将向身份提供者发送原始的
    `id_token`，以及一些用于识别服务的内容。
- en: Assuming Service-X is authorized, the identity provider sends a new `id_token`
    to Service-X with the original user’s attributes and an `aud` scoped to Service-Y.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 假设 Service-X 已获得授权，身份提供者将把一个新的 `id_token` 发送给 Service-X，该 `id_token` 包含原始用户的属性，并且
    `aud` 作用域限定为 Service-Y。
- en: Service-X uses the new `id_token` as the `Authorization` header when calling
    Service-Y. Again, Istio validates the `id_token`.
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Service-X 在调用 Service-Y 时，将新的 `id_token` 作为 `Authorization` 头部传递。再次强调，Istio
    会验证 `id_token`。
- en: Steps 7 and 8 in the previous diagram aren’t really important here.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 前面图示中的第 7 步和第 8 步在此并不重要。
- en: 'If you think this seems like quite a bit of work to make a service call, you’re
    right. There are several authorization steps going on here:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你认为进行服务调用需要很多工作，那你是对的。这里有多个授权步骤在进行：
- en: The identity provider authorizes the user to generate a token scoped to Service-X.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 身份提供者授权用户生成一个作用域限定为 Service-X 的令牌。
- en: Istio validates the token and that it’s properly scoped to Service-X.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Istio 验证该令牌，并确认其作用域正确，限定为 Service-X。
- en: The identity provider authorizes Service-X to get a token for Service-Y and
    to do so for our user.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 身份提供者授权 Service-X 为 Service-Y 获取令牌，并为我们的用户执行此操作。
- en: Istio validates that the token used by Service-X for Service-Y is properly scoped.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Istio 验证 Service-X 为 Service-Y 使用的令牌是否具有正确的作用域。
- en: These authorization points provide a chance for an improper token to be stopped,
    allowing you to create very short-lived tokens that are harder to abuse and are
    more narrowly scoped. For instance, if the token used to call Service-X was leaked,
    it couldn’t be used to call Service-Y on its own. You’d still need Service-X’s
    own token before you could get a token for Service-Y. That’s an additional step
    an attacker would need to take in order to get control of Service-Y. It also means
    breaching more than one service, providing multiple layers of security. This lines
    up with our discussion of defense in depth from *Chapter 11*, *Extending Security
    Using Open Policy Agent*. With a high-level understanding of how OAuth2 Token
    Exchange works, the next question we need to answer is, how will your services
    authenticate themselves to your identity provider?
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 这些授权点提供了拦截不正当令牌的机会，允许你创建短生命周期的令牌，这些令牌更难滥用且作用域更窄。例如，如果用于调用 Service-X 的令牌被泄露，它就无法单独用于调用
    Service-Y。你仍然需要 Service-X 自己的令牌，才能获得用于 Service-Y 的令牌。这是攻击者需要额外采取的一步，才能控制 Service-Y。这也意味着需要突破多个服务，从而提供多层安全防护。这与我们在*第
    11 章* *使用 Open Policy Agent 扩展安全性* 中讨论的深度防御相一致。了解了 OAuth2 令牌交换的高层次工作原理后，接下来的问题是，你的服务将如何向身份提供者进行身份验证？
- en: Authenticating your service
  id: totrans-257
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 验证你的服务
- en: In order for the token exchange to work, your identity provider needs to know
    who the original user is and which service wants to exchange the token on behalf
    of the user. In the check-writing service example we’ve discussed, you wouldn’t
    want the service that provides today’s lunch menu to be able to generate a token
    for issuing a check! You accomplish this by making sure your identity provider
    knows the difference between your check-writing services and your lunch menu service
    by authenticating each service individually.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使令牌交换起作用，您的身份提供者需要知道原始用户是谁以及哪个服务想要代表用户交换令牌。在我们讨论的撰写支票服务示例中，您不希望提供今天午餐菜单的服务能够生成用于发放支票的令牌！通过确保您的身份提供者知道您的支票撰写服务与午餐菜单服务之间的区别，通过逐个验证每个服务来实现这一点。
- en: 'There are three ways a service running in Kubernetes can authenticate itself
    to the identity provider:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 中运行的服务可以用三种方式进行身份验证：
- en: Use the Pod’s `ServiceAccount` token
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Pod 的 `ServiceAccount` 令牌
- en: Use Istio’s mTLS capabilities
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Istio 的 mTLS 能力
- en: Use a pre-shared “client secret”
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用预共享的“客户端密钥”
- en: 'Throughout the rest of this section, we’re going to focus on option #1, using
    the Pod’s built-in `ServiceAccount` token. This token is provided by default for
    each running pod. This token can be validated by either submitting it to the API
    server’s `TokenReview` service or by treating it as a JWT, validating it against
    the public key published by the API server.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节的其余部分，我们将专注于选项 #1，即使用 Pod 的内置 `ServiceAccount` 令牌。该令牌默认为每个运行中的 Pod 提供。您可以通过将其提交给
    API 服务器的 `TokenReview` 服务或将其视为 JWT 并根据 API 服务器发布的公钥进行验证来验证该令牌。'
- en: In our examples, we’re going to use the `TokenReview` API to test the passed-in
    `ServiceAccount` token against the API server. This is the most backward-compatible
    approach and supports any kind of token integrated into your cluster. For instance,
    if you’re deployed in a managed cloud with its own IAM system that mounts tokens,
    you could use that as well. This could generate a considerable amount of load
    on your API server, since every time a token needs to be validated, it gets sent
    to the API server.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们将使用 `TokenReview` API 来测试传入的 `ServiceAccount` 令牌是否与 API 服务器匹配。这是最具向后兼容性的方法，并支持集成到您的集群中的任何类型的令牌。例如，如果您部署在具有自己
    IAM 系统的托管云中，该系统挂载令牌，您也可以使用它。每次需要验证令牌时，都会将其发送到 API 服务器，这可能会对您的 API 服务器产生相当大的负载。
- en: 'The `TokenRequest` API discussed in *Chapter 6*, *Integrating Authentication
    into Your Cluster*, can be used to cut down on this additional load. Instead of
    using the `TokenReview` API, we can call the API server’s issuer endpoint to get
    the appropriate token verification public key and use that key to validate the
    token’s JWT. While this is convenient and scales better, it does have some drawbacks:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在 *第 6 章*，*将认证集成到您的集群中*中讨论的 `TokenRequest` API 可以用来减少这种额外的负载。而不是使用 `TokenReview`
    API，我们可以调用 API 服务器的发行者端点来获取适当的令牌验证公钥，并使用该密钥验证令牌的 JWT。虽然这很方便且扩展性更好，但它确实有一些缺点：
- en: Starting in 1.21, `ServiceAccount` tokens are mounted using the `TokenRequest`
    API but with lifespans of a year or more. You can manually change this to be as
    short as 10 minutes.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 1.21 开始，`ServiceAccount` 令牌使用 `TokenRequest` API 进行挂载，但生存期长达一年或更长时间。您可以手动将其更改为短至
    10 分钟。
- en: Validating the JWT directly against a public key won’t tell you if the pod is
    still running. The `TokenReview` API will fail if a `ServiceAcount` token is associated
    with a deleted pod, adding an additional layer of security.
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 直接使用公钥对 JWT 进行验证不会告诉您 Pod 是否仍在运行。如果与已删除 Pod 关联了 `ServiceAccount` 令牌，则 `TokenReview`
    API 将失败，从而增加了额外的安全层。
- en: Enabling this feature requires enabling anonymous authentication in your cluster,
    which can be leveraged to elevate privileges with misconfigured RBAC or potential
    bugs.
  id: totrans-268
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用此功能需要在您的集群中启用匿名身份验证，这可以用来通过错误配置的 RBAC 或潜在的错误提升权限。
- en: We’re not going to use Istio’s mTLS capabilities because it’s not as flexible
    as tokens. It’s primarily meant for intra-cluster communications, so if our identity
    provider were outside of the cluster, it would be much harder to use. Also, since
    mTLS requires a point-to-point connection, any TLS termination points would break
    its use. Since it’s rare for an enterprise system to host its own certificate,
    even outside of Kubernetes, it would be very difficult to implement mTLS between
    your cluster’s services and your identity provider.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会使用 Istio 的 mTLS 功能，因为它不像令牌那样灵活。mTLS 主要用于集群内部通信，因此如果我们的身份提供者位于集群外部，使用起来会更为困难。此外，由于
    mTLS 需要点对点连接，任何 TLS 终止点都会破坏其使用。由于企业系统托管自己的证书是很罕见的，即使在 Kubernetes 外部，也很难实现集群服务与身份提供者之间的
    mTLS。
- en: Finally, we’re not going to use a shared secret between our services and our
    identity provider because we don’t need to. Shared secrets are only needed when
    you have no other way to give a workload an identity. Since Kubernetes gives every
    pod its own identity, there’s no need to use a client secret to identify our service.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们不会在服务和身份提供者之间使用共享密钥，因为我们不需要这样做。共享密钥只在没有其他方式为工作负载赋予身份时才需要。由于 Kubernetes
    为每个 Pod 提供自己的身份，因此我们不需要使用客户端密钥来识别我们的服务。
- en: Now that we know how our services will identify themselves to our identity provider,
    let’s walk through an example of using OAuth2 Token Exchange to securely call
    one service from another.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道我们的服务将如何向身份提供者进行身份验证，接下来让我们通过一个使用 OAuth2 令牌交换的示例，来安全地从一个服务调用另一个服务。
- en: Deploying and running the check-writing service
  id: totrans-272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 部署和运行支票写入服务
- en: 'Having walked through much of the theory of using a token exchange to securely
    call services, let’s deploy an example check-writing service. When we call this
    service, it will call two other services. The first service, `check-funds`, will
    use the impersonation profile of OAuth2 Token Exchange, while the second service,
    `pull-funds`, will use delegation. We’ll walk through each of these individually.
    First, use Helm to deploy an identity provider. Go into the `chapter17` directory
    and run:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在讲解了使用令牌交换安全调用服务的理论之后，让我们部署一个示例的支票写入服务。当我们调用这个服务时，它将调用另外两个服务。第一个服务 `check-funds`
    将使用 OAuth2 令牌交换的假冒配置，而第二个服务 `pull-funds` 将使用委托。我们将分别讲解每一个。首先，使用 Helm 部署一个身份提供者。进入
    `chapter17` 目录并运行：
- en: '[PRE28]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'We’re not going to go into the details of OpenUnison’s configuration. Suffice
    it to say, this will set up an identity provider for our services and a way to
    get an initial token. Next, deploy the `write-checks` service:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入讨论 OpenUnison 的配置。可以简单地说，这将为我们的服务设置一个身份提供者，并提供获取初始令牌的方式。接下来，部署 `write-checks`
    服务：
- en: '[PRE29]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'This should look pretty familiar after the first set of examples in this chapter.
    We deployed our service as Python in a `ConfigMap` and the same Istio objects
    we created in the previous service. The only major difference is in our `RequestAuthentication`
    object:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的第一个示例之后，这应该看起来非常熟悉。我们将我们的服务部署为 Python 并放入 `ConfigMap`，以及在之前的服务中创建的相同 Istio
    对象。唯一的主要区别是在我们的 `RequestAuthentication` 对象中：
- en: '[PRE30]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: There’s an additional setting, `forwardOriginalToken`, that tells Istio to send
    the service the original JWT used to authenticate the call. We’ll need this token
    in order to prove to the identity provider that we should even attempt to perform
    a token exchange. You can’t ask for a new token if you can’t provide the original.
    This keeps someone with access to your service’s pod from requesting a token on
    your behalf with just the service’s `ServiceAccount`.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一个额外的设置，`forwardOriginalToken`，它告诉 Istio 将用于认证调用的原始 JWT 发送给服务。我们需要这个令牌来证明我们应该尝试执行令牌交换。如果无法提供原始令牌，你就无法请求新令牌。这可以防止拥有服务
    Pod 访问权限的人仅凭服务的 `ServiceAccount` 请求令牌。
- en: Earlier in the chapter, we said we couldn’t leak a token we didn’t have, so
    we shouldn’t have access to the original token. This would be true if we didn’t
    need it to get a token for another service. Following the concept of least privilege,
    we shouldn’t forward the token if we don’t need to. In this case, we need it for
    a token exchange, so it’s worth the increased risk to have more secure service-to-service
    calls.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章前面，我们提到过如果我们没有令牌，就不应该泄露它，因此我们不应该访问原始令牌。如果我们不需要它来为另一个服务获取令牌，那这是正确的。遵循最小权限原则，如果不需要，我们不应该转发令牌。在这种情况下，我们需要它进行令牌交换，因此为了实现更安全的服务间调用，增加的风险是值得的。
- en: 'With our example check-writing service deployed, let’s run it and work backward.
    Just like with our earlier examples, we’ll use `curl` to get the token and call
    our service. In `chapter17/write-checks`, run `call_service.sh`:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们部署了示例的支票写入服务后，接下来让我们运行它并倒推。和之前的示例一样，我们将使用`curl`来获取令牌并调用我们的服务。在`chapter17/write-checks`中，运行`call_service.sh`：
- en: '[PRE31]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The output you see is the result of the calls to `/write-check`, which then
    calls `/check-funds` and `/pull-funds`. Let’s walk through each call, the tokens
    that are generated, and the code that generates them.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到的输出是调用`/write-check`后的结果，接着调用了`/check-funds`和`/pull-funds`。让我们逐步讲解每个调用、生成的令牌以及生成它们的代码。
- en: Using Impersonation
  id: totrans-284
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用模拟认证
- en: 'We’re not talking about the same Impersonation you used in *Chapter 6*, *Integrating
    Authentication into Your Cluster*. It’s a similar concept, but this is specific
    to token exchange. When `/write-check` needs to get a token to call `/check-funds`,
    it asks OpenUnison for a token on behalf of our user, `mmosley`. The important
    aspect of Impersonation is that there’s no reference to the requesting client
    in the generated token. The `/check-funds` service does not know that the token
    it’s received wasn’t retrieved by the user themselves. Working backward, the `impersonated_jwt`
    in the response to our service call is what `/write-check` uses to call `/check-funds`.
    Here’s the payload after dropping the result into `jwt.io`:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 我们这里说的模拟认证不同于*第六章*中你在*将身份认证集成到集群中*时使用的模拟认证。虽然概念类似，但这次是针对令牌交换的。当`/write-check`需要获取令牌来调用`/check-funds`时，它会代表我们的用户`mmosley`向OpenUnison请求一个令牌。模拟认证的关键在于，生成的令牌中没有包含请求客户端的任何引用。`/check-funds`服务并不知道它接收到的令牌并不是用户自己获取的。从倒推的角度看，`impersonated_jwt`是我们服务调用响应中返回的内容，它是`/write-check`用来调用`/check-funds`的令牌。以下是将结果粘贴到`jwt.io`后的载荷：
- en: '[PRE32]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The two important fields here are `sub` and `aud`. The `sub` field tells `/check-funds`
    who the user is and the `aud` field tells Istio which services can consume this
    token. Compare this to the payload from the original token in the `user_jwt` response:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两个重要的字段是`sub`和`aud`。`sub`字段告诉`/check-funds`用户是谁，而`aud`字段则告诉Istio哪些服务可以使用此令牌。将其与`user_jwt`响应中的原始令牌载荷进行对比：
- en: '[PRE33]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The original `sub` is the same, but the `aud` is different. The original `aud`
    is for users, while the impersonated `aud` is for `checkfunds`. This is what differentiates
    the impersonated token from the original one. While our Istio deployment is configured
    to accept both audiences for the same service, that’s not a guarantee in most
    production clusters. When we call `/check-funds`, you’ll see that, in the output,
    we echo the user of our token, `mmosley`.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的`sub`是相同的，但`aud`不同。原始的`aud`是针对用户的，而模拟的`aud`是针对`checkfunds`的。这就是模拟的令牌与原始令牌之间的区别。尽管我们的Istio部署配置为接受同一服务的两种audience，但在大多数生产集群中，这并不是一个保证。当我们调用`/check-funds`时，你会看到在输出中，我们回显了令牌的用户`mmosley`。
- en: 'Now that we’ve seen the end product, let’s see how we get it. First, we get
    the original JWT that was used to call `/write-check`:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看到了最终产品，接下来我们来看一下如何获得它。首先，我们获取用于调用`/write-check`的原始JWT：
- en: '[PRE34]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Once we have the original JWT, we need the Pod’s `ServiceAccount` token:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们拥有了原始的JWT，我们还需要Pod的`ServiceAccount`令牌：
- en: '[PRE35]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'We now have everything we need to get an impersonation token. We’ll create
    a POST body and an `Authorization` header to authenticate us to OpenUnison to
    get our token:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们拥有了获取模拟令牌所需的一切。我们将创建一个POST主体和一个`Authorization`头部，以便向OpenUnison认证我们并获取令牌：
- en: '[PRE36]'
  id: totrans-295
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The first data structure we created is the body of an HTTP POST that will tell
    OpenUnison to generate an impersonation token for the `clientfunds aud`, using
    our existing user (`user_jwt`). OpenUnison will authenticate our service by verifying
    the JWT sent in the `Authorization` header as a `Bearer` token, using the `TokenReview`
    API.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 我们创建的第一个数据结构是一个HTTP POST的主体，它将告诉OpenUnison为`clientfunds aud`生成一个模拟令牌，使用我们现有的用户（`user_jwt`）。OpenUnison将通过验证在`Authorization`头部作为`Bearer`令牌发送的JWT来认证我们的服务，使用的是`TokenReview`
    API。
- en: 'OpenUnison will then apply its internal policy to verify that our service is
    able to generate a token for `mmosley` for the `clientfunds` audience, and then
    generate an `access_token`, `id_token`, and `refresh_token`. We’ll use the `id_token`
    to call `/check-funds`:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: OpenUnison将应用其内部策略，验证我们的服务是否能够为`mmosley`生成`clientfunds`受众的令牌，然后生成`access_token`、`id_token`和`refresh_token`。我们将使用`id_token`来调用`/check-funds`：
- en: '[PRE37]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Since the final JWT makes no mention of the impersonation, how do we track
    a request back to our service? Hopefully, you’re piping your logs into a centralized
    logging system. If we look at the `jti` claim of our impersonation token, we can
    find the impersonation call in the OpenUnison logs:'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 由于最终的 JWT 并未提及模拟身份，我们如何将请求追溯到我们的服务呢？希望你已经将日志发送到一个集中式日志系统。如果我们查看模拟令牌的 `jti` 声明，就可以在
    OpenUnison 的日志中找到模拟调用：
- en: '[PRE38]'
  id: totrans-300
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: So, we at least have a way of tying them together. We can see that our Pod’s
    service account was authorized to create the impersonation token for `mmosley`.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们至少有一种方式将它们联系起来。我们可以看到，我们的 Pod 服务账户被授权为 `mmosley` 创建了模拟令牌。
- en: Having worked through an example of impersonation, let’s cover token delegation
    next.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在通过模拟身份的示例后，让我们接下来讲解令牌委托。
- en: Using delegation
  id: totrans-303
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用委托
- en: In the last example, we used impersonation to generate a new token on behalf
    of our user, but our downstream service had no knowledge that the impersonation
    happened. Delegation is different in that the token carries information about
    both the original user and the service, or actor, that requested it.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一个示例中，我们使用模拟身份为用户生成了一个新令牌，但我们的下游服务并未意识到模拟身份的发生。委托不同之处在于，令牌携带了关于原始用户和请求它的服务或演员的信息。
- en: 'This means that the service being called knows both the originator of the call
    and the service that makes the call. We can see this in the `pull_funds_text`
    value from the response of our `call_service.sh` run. It contains both our original
    user, `mmosley`, and the `ServiceAccount` for the service that made the call,
    `system:serviceaccount:write-checks:default`. Just as with impersonation, let’s
    look at the generated token:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着被调用的服务既知道调用者的来源，也知道发起调用的服务。我们可以在 `call_service.sh` 执行结果的响应中的 `pull_funds_text`
    值中看到这一点。它包含了我们原始的用户 `mmosley` 和发起调用的服务的 `ServiceAccount`，`system:serviceaccount:write-checks:default`。就像模拟身份一样，让我们看看生成的令牌：
- en: '[PRE39]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: In addition to the claims that identify the user as `mmosley`, there’s an `act`
    claim that identifies the `ServiceAccount` that’s used by `/write-checks`. Our
    service can make additional authorization decisions based on this claim or simply
    log it, noting that the token it received was delegated to a different service.
    In order to generate this token, we start by getting the original subject’s JWT
    and the Pod’s `ServiceAccount` token.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 除了标识用户为 `mmosley` 的声明外，还有一个 `act` 声明，用来标识 `/write-checks` 使用的 `ServiceAccount`。我们的服务可以根据这个声明做出额外的授权决策，或者仅仅记录下来，表明它接收到的令牌是委托给了另一个服务。为了生成这个令牌，我们首先获取原始主体的
    JWT 和 Pod 的 `ServiceAccount` 令牌。
- en: 'Instead of calling OpenUnison for a delegated token, our client first has to
    get an actor token by using the `client_credentials` grant. This will get us the
    token that will eventually go into the `act` claim:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 客户端在调用 OpenUnison 获取委托令牌之前，首先需要通过使用 `client_credentials` 授权方式获取一个演员令牌。这将为我们获取一个最终会进入
    `act` 声明的令牌：
- en: '[PRE40]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'We authenticate to OpenUnison using our Pod’s native identity. OpenUnison returns
    an `access_token` and an `id_token`, but we only need the `id_token`. With our
    actor token in hand, we can now get our delegation token:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 Pod 的原生身份对 OpenUnison 进行身份验证。OpenUnison 返回一个 `access_token` 和一个 `id_token`，但我们只需要
    `id_token`。拿到我们的演员令牌后，现在可以获取我们的委托令牌：
- en: '[PRE41]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Similarly to impersonation, in this call, we not only send the original user’s
    token (`user_jwt`) but also the `actor_token` we just received from OpenUnison.
    We also don’t send an Authorization header. The `actor_token` authenticates us
    already. Finally, we’re able to use our returned token to call `/pull-funds`.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于模拟身份，在这个调用中，我们不仅发送了原始用户的令牌（`user_jwt`），还发送了我们刚从 OpenUnison 获得的 `actor_token`。我们同样不会发送
    Authorization 头，因为 `actor_token` 已经完成了我们的身份验证。最终，我们能够使用返回的令牌来调用 `/pull-funds`。
- en: Now that we’ve looked at the most correct way to call services, using both impersonation
    and delegation, let’s take a look at some anti-patterns and why you shouldn’t
    use them.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经看过了使用模拟身份和委托的最正确调用服务的方式，让我们来看一些反模式，以及为什么你不应该使用它们。
- en: Passing tokens between services
  id: totrans-314
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在服务之间传递令牌
- en: Whereas, in the previous section, we used an identity provider to generate either
    impersonation or delegation tokens, this method skips that and just passes the
    original token from service to service. This is a simple approach that’s easy
    to implement. It also creates a larger blast radius. If the token gets leaked
    (and given that it’s now being passed to multiple services, the likelihood of
    it leaking goes up quite a bit), you’ve now not only exposed one service; you’ve
    also exposed all the services that trust that token.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们使用了身份提供者生成冒充或委托令牌，而这种方法跳过了这些步骤，直接从服务传递原始令牌到另一个服务。这是一种简单的实现方法，也带来了更大的暴露范围。如果令牌泄露了（而且由于现在它被传递到多个服务，泄露的可能性大大增加），那么不仅仅是一个服务暴露了，你还暴露了所有信任该令牌的服务。
- en: While using OAuth2 Token Exchange does require more work, it will limit your
    blast radius should a token be leaked. Next, we’ll look at how you can simply
    tell a downstream service who’s calling it.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然使用 OAuth2 令牌交换需要更多的工作，但如果令牌泄露，它将限制你的影响范围。接下来，我们将看看如何简单地告诉下游服务是谁在调用它。
- en: Using simple impersonation
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用简单的冒充
- en: 'Where the previous examples of service-to-service calls rely on a third party
    to generate a token for a user, direct impersonation is where your service’s code
    uses a service account (in the generic sense, not the Kubernetes version) to call
    the second service and just tells the service who the user is as an input to the
    call. For instance, instead of calling OpenUnison to get a new token, `/write-check`
    could have just used the Pod’s `ServiceAccount` token to call `/check-funds`,
    with a parameter containing the user’s ID. Something like the following would
    work:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的服务到服务调用示例依赖第三方为用户生成令牌，而直接冒充则是你的服务代码使用服务账户（广义上的服务账户，而非 Kubernetes 版本）来调用第二个服务，并且只是告诉该服务用户是谁，作为调用的输入。例如，`/write-check`
    可以直接使用 Pod 的 `ServiceAccount` 令牌来调用 `/check-funds`，并带上包含用户 ID 的参数。像下面这样就能工作：
- en: '[PRE42]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: This is, again, very simple. You can tell Istio to authenticate a Kubernetes
    `ServiceAccount`. This takes two lines of code to do something that took 15 to
    20 lines using a token service. Just like with passing tokens between services,
    this approach leaves you exposed in multiple ways. First, if anyone gets the `ServiceAccount`
    used by our service, they can impersonate anyone they want without checks. Using
    the token service ensures that a compromised service account doesn’t lead to it
    being used to impersonate anyone.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 这再次是一个非常简单的问题。你可以告诉 Istio 认证一个 Kubernetes `ServiceAccount`。只需两行代码，就能完成之前需要 15
    到 20 行代码才能实现的功能。就像服务之间传递令牌一样，这种方法在多个方面仍然存在暴露的风险。首先，如果有人获取了我们服务使用的 `ServiceAccount`，他们可以不受检查地冒充任何人。使用令牌服务可以确保即便服务账户被泄露，也不会被用来冒充其他人。
- en: You might find this method very similar to the impersonation we used in *Chapter
    6*, *Integrating Authentication into Your Cluster*. You’re correct. While this
    uses the same mechanism, a `ServiceAccount` and some parameters to specify who
    the user is, the type of impersonation Kubernetes uses for the API server is often
    referred to as a **protocol transition**. This is used when you are moving from
    one protocol (OpenID Connect) to another (a Kubernetes service account). As we
    discussed in *Chapter 5*, there are several controls you can put in place with
    Kubernetes impersonation, including using `NetworkPolicies`, `RBAC`, and the `TokenRequest`
    API. It’s also a much more isolated use case than a generic service.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会发现这种方法与我们在*第六章*《将身份认证集成到集群》中使用的冒充非常相似。你没错。虽然这使用了相同的机制，即 `ServiceAccount`
    和一些参数来指定用户是谁，但 Kubernetes 用于 API 服务器的冒充方式通常被称为**协议转换**。当你从一种协议（如 OpenID Connect）转换到另一种协议（如
    Kubernetes 服务账户）时，会使用这种方式。正如我们在*第五章*中讨论的，Kubernetes 冒充可以通过多种控制机制来实现，包括使用 `NetworkPolicies`、`RBAC`
    和 `TokenRequest` API。这也是一个比通用服务更加孤立的用例。
- en: We’ve walked through multiple ways for services to call and authenticate each
    other. While it may not be the simplest way to secure access between services,
    it will limit the impact of a leaked token. Now that we know how our services
    will talk to each other, the last topic we need to cover is the relationship between
    Istio and API gateways.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经走过了多种服务间相互调用和认证的方式。虽然这可能不是最简单的方式来确保服务间的访问安全，但它会限制令牌泄露的影响。现在我们知道了服务间的通信方式，最后一个我们需要讨论的话题是
    Istio 和 API 网关之间的关系。
- en: Do I need an API gateway?
  id: totrans-323
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 我需要 API 网关吗？
- en: If you’re using Istio, do you still need an API gateway? In the past, Istio
    was primarily concerned with routing traffic for services. It got traffic into
    the cluster and figured out where to route it to. API gateways have typically
    focused more on application-level functionality such as authentication, authorization,
    input validation, and logging.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用Istio，是否还需要API网关？过去，Istio主要关注为服务路由流量。它将流量引入集群并决定将其路由到哪里。API网关则通常更多关注应用级功能，如身份验证、授权、输入验证和日志记录。
- en: For example, earlier in this chapter, we identified schema input validation
    as a process that needs to be repeated for each call and shouldn’t need to be
    done manually. This is important to protect against attacks that can leverage
    unexpected input, and it also makes for a better developer experience, providing
    feedback to developers sooner in the integration process. This is a common function
    for API gateways but is not available in Istio.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在本章前面，我们将模式输入验证确定为一个需要在每次调用时重复执行的过程，而且不应该需要手动执行。这一点非常重要，因为它可以防止利用意外输入进行攻击，同时也能为开发者提供更好的体验，在集成过程中更早地向开发者提供反馈。这是API网关中的常见功能，但在Istio中并不可用。
- en: Another example of a function that is not built into Istio but is common for
    API gateways is logging authentication and authorization decisions and information.
    Throughout this chapter, we leveraged Istio’s built-in authentication and authorization
    to validate service access, but Istio makes no record of that decision, other
    than that a decision was made. It doesn’t record who accessed a particular URL,
    only where it was accessed from. Logging who accessed a service, from an identity
    standpoint, is left to each individual service. This is a common function for
    API gateways.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个Istio没有内建，但在API网关中常见的功能是记录身份验证和授权的决策和信息。在本章中，我们利用Istio内建的身份验证和授权来验证服务访问，但Istio并未记录这些决策，仅仅记录了是否做出了决策。它不会记录谁访问了特定的URL，只会记录从哪里访问。记录谁从身份角度访问了服务，则交由每个独立的服务来处理。这是API网关的常见功能。
- en: Finally, API gateways are able to handle more complex transformations. Gateways
    will typically provide functionality for mapping inputs and outputs, or even integrating
    with legacy systems.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，API网关能够处理更复杂的转换。网关通常会提供映射输入和输出的功能，甚至可以与遗留系统进行集成。
- en: These functions could all be integrated into Istio, either directly or via Envoy
    filters. We saw an example of this when we looked at using OPA to make more complex
    authorization decisions than what the `AuthorizationPolicy` object provides. However,
    over the last few releases, Istio has moved further into the realm of traditional
    API gateways, and API gateways have begun taking on more service mesh capabilities.
    I suspect there will be considerable overlap between these systems in the future,
    but at the time of writing, Istio isn’t yet capable of fulfilling all the functions
    of an API gateway.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这些功能都可以通过Istio进行集成，无论是直接集成还是通过Envoy过滤器。我们在查看使用OPA来做出比`AuthorizationPolicy`对象提供的更复杂的授权决策时就看到过一个例子。然而，在过去的几个版本中，Istio进一步进入了传统API网关的领域，而API网关也开始承担更多服务网格的功能。我猜想，未来这些系统之间会有相当大的重叠，但在写这篇文章时，Istio尚未具备实现所有API网关功能的能力。
- en: We’ve had quite the journey building out the services for our Istio service
    mesh. You should now have the tools you need to begin building services in your
    own cluster.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在构建Istio服务网格的服务过程中经历了一段不小的旅程。现在，你应该已经掌握了开始在你自己的集群中构建服务所需的工具。
- en: Summary
  id: totrans-330
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned how both monoliths and microservices run in Istio.
    We explored why and when to use each approach. We deployed a monolith, taking
    care to ensure our monolith’s session management worked. We then moved into deploying
    microservices, authenticating requests, authorizing requests, and finally, how
    services can securely communicate. To wrap things up, we discussed whether an
    API gateway is still necessary when using Istio.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了单体应用和微服务在Istio中的运行方式。我们探讨了何时以及为何使用这两种方法。我们部署了一个单体应用，并确保单体应用的会话管理正常工作。然后我们开始部署微服务，进行请求身份验证、授权请求，最后讨论了服务如何安全地进行通信。最后，我们讨论了在使用Istio时，API网关是否仍然必要。
- en: Istio can be complex, but when used properly, it can provide considerable power.
    What we didn’t cover in this chapter is how to build containers and manage the
    deployment of our services. We’re going to tackle that next, in *Chapter 18*,
    *Provisioning a Multitenant Platform*.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: Istio 可能比较复杂，但如果使用得当，它可以提供相当强大的功能。本章未涉及的是如何构建容器并管理服务的部署。我们将在下一章，*第18章*，*提供多租户平台*中讨论这个问题。
- en: Questions
  id: totrans-333
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'True or false: Istio is an API Gateway.'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对错：Istio 是一个 API 网关。
- en: 'True'
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对
- en: 'False'
  id: totrans-336
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错
- en: 'Answer: b – False. Istio is a service mesh, and while it has many of the functions
    of a gateway, it doesn’t have all of them (such as schema checking).'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：b – 错。Istio 是一个服务网格，虽然它具有网关的许多功能，但并不包含所有功能（例如，模式检查）。
- en: Should I always build applications as microservices?
  id: totrans-338
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我是否应该始终将应用程序构建为微服务？
- en: Obviously – this is the right way.
  id: totrans-339
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 显然——这是正确的方式。
- en: Only if a microservices architecture aligns with your organization’s structure
    and needs.
  id: totrans-340
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只有当微服务架构与你组织的结构和需求相匹配时，才应考虑使用微服务。
- en: No. Microservices are more trouble than they’re worth.
  id: totrans-341
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不是。微服务带来的麻烦远大于它们的价值。
- en: What’s a microservice?
  id: totrans-342
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是微服务？
- en: 'Answer: b – Microservices are great when you have a team that is able to make
    use of the granularity they provide.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：b – 微服务在你的团队能够充分利用其粒度时非常有用。
- en: What is a monolith?
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么是单体应用？
- en: A large object that appears to be made from a single piece by an unknown maker
  id: totrans-345
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个看起来像由一个未知制造者用一块材料做成的大物件
- en: An application that is self-contained
  id: totrans-346
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个自包含的应用程序
- en: A system that won’t run on Kubernetes
  id: totrans-347
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个无法在 Kubernetes 上运行的系统
- en: A product from a new start-up
  id: totrans-348
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一家新创公司的产品
- en: 'Answer: b – A monolith is a self-contained application that can run quite well
    on Kubernetes.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：b – 单体应用是一个自包含的应用程序，可以在 Kubernetes 上运行得很好。
- en: How should you authorize access to your services in Istio?
  id: totrans-350
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如何在 Istio 中授权访问你的服务？
- en: You can write a rule that limits access in Istio by a claim in the token.
  id: totrans-351
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以在 Istio 中编写规则，通过令牌中的声明限制访问。
- en: You can integrate OPA with Istio for more complex authorization decisions.
  id: totrans-352
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以将 OPA 与 Istio 集成，以做出更复杂的授权决策。
- en: You can embed complex authorization decisions in your code.
  id: totrans-353
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以在代码中嵌入复杂的授权决策。
- en: All of the above.
  id: totrans-354
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上述所有。
- en: 'Answer: d – These are all valid strategies from a technical standpoint. Each
    situation is different, so look at each one to determine which one is best for
    you!'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：d – 从技术角度来看，这些都是有效的策略。每种情况不同，因此需要查看每个选项，判断哪个最适合你！
- en: 'True or false: Calling services on behalf of a user without token exchange
    is a secure approach.'
  id: totrans-356
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对错：代表用户调用服务而不进行令牌交换是一种安全的方法。
- en: 'True'
  id: totrans-357
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对
- en: 'False'
  id: totrans-358
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错
- en: 'Answer: b. False – Without using token exchange to get a new token for when
    the user uses the next service, you leave yourself open to various attacks because
    you can’t limit calls or track them.'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：b. 错 – 如果不使用令牌交换来获取新令牌以便用户使用下一个服务时，你会让自己面临各种攻击，因为你无法限制或追踪调用。
- en: 'True or false: Istio supports sticky sessions.'
  id: totrans-360
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对错：Istio 支持粘性会话。
- en: 'True'
  id: totrans-361
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对
- en: 'False'
  id: totrans-362
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错
- en: 'Answer: a. True – They are not a default, but they are supported.'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：a. 对 – 它们不是默认的，但支持它们。
- en: Join our book’s Discord space
  id: totrans-364
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们本书的 Discord 空间
- en: 'Join the book’s Discord workspace for a monthly *Ask Me Anything* session with
    the authors:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 加入本书的 Discord 工作空间，参与每月一次的 *提问与解答* 会话，与作者互动：
- en: '[https://packt.link/K8EntGuide](https://packt.link/K8EntGuide)'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/K8EntGuide](https://packt.link/K8EntGuide)'
- en: '![](img/QR_Code965214276169525265.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code965214276169525265.png)'
