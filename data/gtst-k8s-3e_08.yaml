- en: Monitoring and Logging
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控与日志记录
- en: This chapter will cover the use and customization of both built-in and third-party
    monitoring tools on our Kubernetes cluster. We will cover how to use the tools
    to monitor the health and performance of our cluster. In addition, we will look
    at built-in logging, the Google Cloud Logging service, and Sysdig.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍在我们的 Kubernetes 集群中使用和定制内置及第三方监控工具。我们将讨论如何使用这些工具来监控集群的健康状态和性能。此外，我们还将了解内置日志、Google
    Cloud Logging 服务以及 Sysdig。
- en: 'The following topics will be covered in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: How Kuberentes uses cAdvisor, Heapster, InfluxDB, and Grafana
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 如何使用 cAdvisor、Heapster、InfluxDB 和 Grafana
- en: Customizing the default Grafana dashboard
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义默认的 Grafana 仪表板
- en: Using Fluentd and Grafana
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Fluentd 和 Grafana
- en: Installing and using logging tools
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装和使用日志工具
- en: Working with popular third-party tools, such as Stackdriver and Sysdig, to extend
    our monitoring capabilities
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用流行的第三方工具，如 Stackdriver 和 Sysdig，来扩展我们的监控能力
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You''ll need to have your Google Cloud Platform account enabled and logged
    in to it, or you can use a local Minikube instance of Kubernetes. You can also
    use Play with Kubernetes over the web: [https://labs.play-with-k8s.com/](https://labs.play-with-k8s.com/).'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要启用并登录到你的 Google Cloud Platform 账户，或者使用本地的 Minikube 实例来运行 Kubernetes。你也可以通过
    Web 使用 Play with Kubernetes：[https://labs.play-with-k8s.com/](https://labs.play-with-k8s.com/)。
- en: Monitoring operations
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 监控操作
- en: Real-world monitoring goes far beyond checking whether a system is up and running.
    Although health checks like those you learned in [Chapter 2](f8b73a87-79ed-4db9-b3b2-46ade1342892.xhtml),
    *Building a Foundation with Core Kubernetes Constructs*, in the *Health checks*
    section can help us isolate problem applications, operations teams can best serve
    the business when they can anticipate the issues and mitigate them before a system
    goes offline.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 真实世界中的监控远不止于检查系统是否正常运行。尽管像你在[第 2 章](f8b73a87-79ed-4db9-b3b2-46ade1342892.xhtml)《基于核心
    Kubernetes 构件建立基础》中的*健康检查*部分学到的健康检查可以帮助我们隔离问题应用程序，但运营团队能够在系统停机前预见问题并加以缓解，才能更好地为业务服务。
- en: The best practices in monitoring are to measure the performance and usage of
    core resources and watch for trends that stray from the normal baseline. Containers
    are not different here, and a key component to managing our Kubernetes cluster
    is having a clear view of the performance and availability of the OS, network,
    system (CPU and memory), and storage resources across all nodes.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 监控的最佳实践是衡量核心资源的性能和使用情况，并观察偏离正常基线的趋势。容器在这方面并不例外，管理 Kubernetes 集群的关键组成部分是能够清晰地查看所有节点的操作系统、网络、系统（CPU
    和内存）以及存储资源的性能和可用性。
- en: In this chapter, we will examine several options to monitor and measure the
    performance and availability of all our cluster resources. In addition, we will
    look at a few options for alerting and notifications when irregular trends start
    to emerge.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨几种监控和衡量集群资源的性能与可用性的方法。此外，我们还将研究当出现不规则趋势时，如何进行告警和通知。
- en: Built-in monitoring
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 内置监控
- en: 'If you recall from [Chapter 1](446f901d-70fa-4ebe-be8a-0de14248f99c.xhtml),
    *Introduction to Kubernetes*, we noted that our nodes were already running a number
    of monitoring services. We can see these once again by running the `get pods`
    command with the `kube-system` namespace specified as follows:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还记得[第 1 章](446f901d-70fa-4ebe-be8a-0de14248f99c.xhtml)《Kubernetes 简介》，我们提到我们的节点已经运行了多个监控服务。我们可以通过如下命令，指定
    `kube-system` 命名空间，再次查看这些服务：
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following screenshot is the result of the preceding command:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前面命令的结果：
- en: '![](img/e1c1b51d-e031-4ef2-825f-4ae59c000c90.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e1c1b51d-e031-4ef2-825f-4ae59c000c90.png)'
- en: System pod listing
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 系统 pod 列表
- en: Again, we see a variety of services, but how does this all fit together? If
    you recall, the node (formerly minions) section from [Chapter 2](f8b73a87-79ed-4db9-b3b2-46ade1342892.xhtml),
    *Building a Foundation with Core Kubernetes Constructs*, each node is running
    a `kubelet`. The `kubelet` is the main interface for nodes to interact with and
    update the API server. One such update is the metrics of the node resources. The
    actual reporting of the resource usage is performed by a program named cAdvisor.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们看到多种服务，但这些是如何协同工作的呢？如果你还记得，第2章中关于节点（以前称为minions）的部分[Chapter 2](f8b73a87-79ed-4db9-b3b2-46ade1342892.xhtml)，*构建核心Kubernetes结构的基础*，每个节点都在运行`kubelet`。`kubelet`是节点与API服务器交互并进行更新的主要接口。此类更新之一是节点资源的指标。资源使用的实际报告是由名为cAdvisor的程序执行的。
- en: The cAdvisor program is another open source project from Google, which provides
    various metrics on container resource use. Metrics include CPU, memory, and network
    statistics. There is no need to tell cAdvisor about individual containers; it
    collects the metrics for all containers on a node and reports this back to the
    `kubelet`, which in turn reports to Heapster.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: cAdvisor程序是Google的另一个开源项目，它提供关于容器资源使用的各种指标。指标包括CPU、内存和网络统计信息。无需为单独的容器配置cAdvisor，它会收集节点上所有容器的指标并将其报告给`kubelet`，然后`kubelet`将这些数据报告给Heapster。
- en: Google's open source projects: Google has a variety of open source projects
    related to Kubernetes. Check them out, use them, and even contribute your own
    code!
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: Google's open source projects：Google有很多与Kubernetes相关的开源项目。查看它们，使用它们，甚至贡献你自己的代码！
- en: 'Both cAdvisor and Heapster are mentioned in the following sections of GitHub:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: cAdvisor和Heapster都在以下GitHub部分中提到：
- en: '**cAdvisor**: [https://github.com/google/cadvisor](https://github.com/google/cadvisor)'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**cAdvisor**: [https://github.com/google/cadvisor](https://github.com/google/cadvisor)'
- en: '**Heapster**: [https://github.com/kubernetes/heapster](https://github.com/kubernetes/heapster)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Heapster**: [https://github.com/kubernetes/heapster](https://github.com/kubernetes/heapster)'
- en: Contrib is a catch-all term for a variety of components that are not part of
    core Kubernetes. It can be found at [https://github.com/kubernetes/contrib](https://github.com/kubernetes/contrib). LevelDB
    is a key store library that was used in the creation of InfluxDB. It can be found
    at [https://github.com/google/leveldb](https://github.com/google/leveldb).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Contrib是一个包含各种组件的统称，这些组件并非Kubernetes核心的一部分。它可以在[https://github.com/kubernetes/contrib](https://github.com/kubernetes/contrib)找到。LevelDB是一个键值存储库，它在InfluxDB的创建中被使用。你可以在[https://github.com/google/leveldb](https://github.com/google/leveldb)找到它。
- en: Heapster is yet another open source project from Google; you may start to see
    a theme emerging here (see the preceding information box). Heapster runs in a
    container on one of the minion nodes and aggregates the data from a `kubelet`.
    A simple REST interface is provided to query the data.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Heapster是Google的另一个开源项目；你可能开始看到一些模式（参见前面的信息框）。Heapster运行在一个minion节点上的容器中，汇总来自`kubelet`的数据。提供了一个简单的REST接口来查询数据。
- en: When using the GCE setup, a few additional packages are set up for us, which
    saves us time and gives us a complete package to monitor our container workloads.
    As we can see from the preceding *System pod listing* screenshot, there is another
    pod with `influx-grafana` in the title.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用GCE设置时，我们会为我们安装一些额外的软件包，这样可以节省时间，并提供一个完整的包来监控我们的容器工作负载。正如我们从前面的*系统Pod列表*截图中看到的，标题中还有一个包含`influx-grafana`的Pod。
- en: 'InfluxDB is described on its official website as follows:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: InfluxDB在其官方网站上的描述如下：
- en: An open-source distributed time series database with no external dependencies.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一个开源的分布式时间序列数据库，没有外部依赖。
- en: InfluxDB is based on a key store package (refer to the previous *Google's open
    source projects* information box) and is perfect to store and query event- or
    time-based statistics such as those provided by Heapster.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: InfluxDB基于一个键值存储包（参见前面的*Google的开源项目*信息框），非常适合存储和查询基于事件或时间的统计数据，比如Heapster提供的数据。
- en: Finally, we have Grafana, which provides a dashboard and graphing interface
    for the data stored in InfluxDB. Using Grafana, users can create a custom monitoring
    dashboard and get immediate visibility into the health of their Kubernetes cluster,
    and therefore their entire container infrastructure.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们有Grafana，它提供了一个仪表板和图表界面，用于显示存储在InfluxDB中的数据。使用Grafana，用户可以创建自定义监控仪表板，并立即查看Kubernetes集群的健康状况，从而了解整个容器基础设施的运行情况。
- en: Exploring Heapster
  id: totrans-33
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索Heapster
- en: 'Let''s quickly look at the REST interface by running SSH to the node that is
    running the Heapster pod. First, we can list the pods to find the one that is running
    Heapster, as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 快速查看 REST 接口，我们可以通过 SSH 连接到正在运行 Heapster Pod 的节点。首先，我们可以列出 Pod，找到正在运行 Heapster
    的 Pod，命令如下：
- en: '[PRE1]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The name of the pod should start with `monitoring-heapster`. Run a `describe`
    command to see which node it is running on, as follows:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 的名称应以 `monitoring-heapster` 开头。运行 `describe` 命令查看它运行在哪个节点，命令如下：
- en: '[PRE2]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'From the output in the following screenshot, we can see that the pod is running
    in `kubernetes-minion-merd`. Also note the IP for the pod, a few lines down, as
    we will need that in a moment:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从下面截图的输出中，我们可以看到 Pod 正在 `kubernetes-minion-merd` 中运行。还请注意稍后会用到的 Pod 的 IP 地址，见下几行：
- en: '![](img/c7283a40-8d51-461e-8d11-8a42c2284317.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c7283a40-8d51-461e-8d11-8a42c2284317.png)'
- en: Heapster pod details
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Heapster Pod 详细信息
- en: 'Next, we can SSH to this box with the familiar `gcloud ssh` command, as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用熟悉的 `gcloud ssh` 命令 SSH 连接到此主机，命令如下：
- en: '[PRE3]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: From here, we can access the Heapster REST API directly using the pod's IP address.
    Remember that pod IPs are routable not only in the containers but also on the
    nodes themselves. The `Heapster` API is listening on port `8082`, and we can get
    a full list of metrics at `/api/v1/metric-export-schema/`.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 从这里，我们可以直接通过 Pod 的 IP 地址访问 Heapster REST API。记住，Pod 的 IP 地址不仅在容器内部可路由，而且在节点本身也能路由。`Heapster`
    API 正在监听 `8082` 端口，我们可以在 `/api/v1/metric-export-schema/` 路径下获取完整的指标列表。
- en: 'Let''s look at the list now by issuing a `curl` command to the pod IP address
    we saved from the `describe` command, as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们通过执行 `curl` 命令查询我们从 `describe` 命令中保存的 Pod IP 地址，命令如下：
- en: '[PRE4]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We will see a listing that is quite long. The first section shows all the metrics
    available. The last two sections list fields by which we can filter and group.
    For your convenience, I''ve added the following tables which are a little bit
    easier to read:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到一个非常长的列表。第一部分展示了所有可用的指标，最后两部分列出了可以用来过滤和分组的字段。为了方便阅读，我已经添加了以下表格：
- en: '| **Metric** | **Description** | **Unit** | **Type** |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| **Metric** | **描述** | **单位** | **类型** |'
- en: '| `uptime` | The number of milliseconds since the container was started | ms
    | Cumulative |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| `uptime` | 容器启动以来经过的毫秒数 | 毫秒 | 累计 |'
- en: '| `cpu/usage` | The cumulative CPU usage on all cores | ns | Cumulative |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| `cpu/usage` | 所有核心的累计 CPU 使用情况 | 纳秒 | 累计 |'
- en: '| `cpu/limit` | The CPU limit in millicores | - | Gauge |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| `cpu/limit` | CPU 限制（以毫核为单位） | - | 测量 |'
- en: '| `memory/usage` | Total memory usage | Bytes | Gauge |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| `memory/usage` | 总内存使用量 | 字节 | 测量 |'
- en: '| `memory/working_set` | Total working set usage; the working set is the memory
    that is being used, and is not easily dropped by the kernel | Bytes | Gauge |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| `memory/working_set` | 总的工作集使用情况；工作集是当前使用的内存，且不容易被内核丢弃 | 字节 | 测量 |'
- en: '| `memory/limit` | The memory limit | Bytes | Gauge |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| `memory/limit` | 内存限制 | 字节 | 测量 |'
- en: '| `memory/page_faults` | The number of page faults | - | Cumulative |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| `memory/page_faults` | 页面错误的数量 | - | 累计 |'
- en: '| `memory/major_page_faults` | The number of major page faults | - | Cumulative
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| `memory/major_page_faults` | 主要页面错误的数量 | - | 累计 |'
- en: '| `network/rx` | The cumulative number of bytes received over the network |
    Bytes | Cumulative |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| `network/rx` | 网络接收的累计字节数 | 字节 | 累计 |'
- en: '| `network/rx_errors` | The cumulative number of errors while receiving over
    the network | - | Cumulative |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| `network/rx_errors` | 网络接收过程中累计的错误数 | - | 累计 |'
- en: '| `network/tx` | The cumulative number of bytes sent over the network | Bytes
    | Cumulative |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| `network/tx` | 网络发送的累计字节数 | 字节 | 累计 |'
- en: '| `network/tx_errors` | The cumulative number of errors while sending over
    the network | - | Cumulative |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| `network/tx_errors` | 网络发送过程中累计的错误数 | - | 累计 |'
- en: '| `filesystem/usage` | The total number of bytes consumed on a filesystem |
    Bytes | Gauge |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| `filesystem/usage` | 文件系统消耗的总字节数 | 字节 | 测量 |'
- en: '| `filesystem/limit` | The total size of filesystem in bytes | Bytes | Gauge
    |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| `filesystem/limit` | 文件系统的总大小（字节数） | 字节 | 测量 |'
- en: '| `filesystem/available` | The number of available bytes remaining in a the
    filesystem | Bytes | Gauge |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| `filesystem/available` | 文件系统中剩余的可用字节数 | 字节 | 测量 |'
- en: Table 6.1\. Available Heapster metrics
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6.1：可用的 Heapster 指标
- en: '| **Field** | **Description** | **Label type** |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| **字段** | **描述** | **标签类型** |'
- en: '| `nodename` | The node name where the container ran | Common |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| `nodename` | 容器运行所在的节点名称 | 常见 |'
- en: '| `hostname` | The host name where the container ran | Common |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| `hostname` | 容器运行的主机名 | 常见 |'
- en: '| `host_id` | An identifier specific to a host, which is set by the cloud provider
    or user | Common |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| `host_id` | 特定于主机的标识符，由云提供商或用户设置 | Common |'
- en: '| `container_base_image` | The user-defined image name that is run inside the
    container | Common |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| `container_base_image` | 用户定义的容器内运行的镜像名称 | Common |'
- en: '| `container_name` | The user-provided name of the container or full container
    name for system containers | Common |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| `container_name` | 用户提供的容器名称或系统容器的完整名称 | Common |'
- en: '| `pod_name` | The name of the pod | Pod |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| `pod_name` | Pod 的名称 | Pod |'
- en: '| `pod_id` | The unique ID of the pod | Pod |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| `pod_id` | Pod 的唯一 ID | Pod |'
- en: '| `pod_namespace` | The namespace of the pod | Pod |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| `pod_namespace` | Pod 的命名空间 | Pod |'
- en: '| `namespace_id` | The unique ID of the namespace of the pod | Pod |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| `namespace_id` | Pod 命名空间的唯一 ID | Pod |'
- en: '| `labels` | A comma-separated list of user-provided labels | Pod |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| `labels` | 用户提供的标签，以逗号分隔 | Pod |'
- en: Table 6.2\. Available Heapster fields
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6.2\. 可用的 Heapster 字段
- en: Customizing our dashboards
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义仪表盘
- en: Now that we have the fields, we can have some fun. Recall the Grafana page that
    we looked at in [Chapter 1](446f901d-70fa-4ebe-be8a-0de14248f99c.xhtml), *Introduction to Kubernetes*.
    Let's pull that up again by going to our cluster's monitoring URL. Note that you
    may need to log in with your cluster credentials. Refer to the following format
    of the link you need to use: `https://<your master IP>/api/v1/proxy/namespaces/kube-system/services/monitoring-grafana`
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了字段，可以开始有些有趣的操作了。回想一下我们在[第 1 章](446f901d-70fa-4ebe-be8a-0de14248f99c.xhtml)中看到的
    Grafana 页面，*Kubernetes 入门*。让我们再次打开它，方法是访问我们集群的监控 URL。注意，你可能需要用集群凭据登录。请参照以下链接格式：`https://<your
    master IP>/api/v1/proxy/namespaces/kube-system/services/monitoring-grafana`
- en: We'll see the default Home dashboard. Click on the down arrow next to Home and
    select Cluster. This shows the Kubernetes cluster dashboard, and now we can add
    our own statistics to the board. Scroll all the way to the bottom and click on
    Add a Row. This should create a space for a new row and present a green tab on
    the left-hand side of the screen.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们会看到默认的主页仪表盘。点击主页旁边的向下箭头，选择集群。这会显示 Kubernetes 集群仪表盘，现在我们可以将自己的统计数据添加到仪表盘上。滚动到页面底部，点击添加一行。这会为新的一行创建一个空间，并在屏幕的左侧显示一个绿色标签。
- en: Let's start by adding a view into the filesystem usage for each node (minion).
    Click on the green tab to expand, and then select Add Panel and then Graph. An
    empty graph should appear on the screen, along with a query panel for our custom
    graph.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先添加每个节点（minion）的文件系统使用情况视图。点击绿色标签以展开，然后选择添加面板，再选择图形。屏幕上应该会出现一个空白图形，并伴有一个查询面板用于我们的自定义图形。
- en: The first field in this panel should show a query that starts with SELECT mean("value")
    FROM. Click on the A character next to this field to expand it. Leave the first
    field next to FROM as default and then click on the next field with the select
    measurement value. A drop-down menu will appear with the Heapster metrics we saw
    in the previous tables. Select `filesystem/usage_bytes_gauge`. Now, in the SELECT
    row, click on mean() and then on the x symbol to remove it. Next, click on the
    + symbol on the end of the row and add selectors and max. Then, you'll see a GROUP
    BY row with time($interval) and fill(none). Carefully click on fill and not on
    the (none) portion, and again on x to remove it.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 此面板中的第一个字段应该显示一个查询，查询以 SELECT mean("value") FROM 开头。点击此字段旁边的 A 字符以展开它。将 FROM
    后面的第一个字段保持默认值，然后点击下一个包含选择度量值的字段。将出现一个下拉菜单，其中列出了我们在前面表格中看到的 Heapster 指标。选择 `filesystem/usage_bytes_gauge`。现在，在
    SELECT 行中，点击 mean()，然后点击 x 符号将其移除。接下来，点击行末的 + 符号，添加选择器和 max。然后，你将看到一个 GROUP BY
    行，包含 time($interval) 和 fill(none)。仔细点击 fill，而不是 (none) 部分，然后再次点击 x 以移除它。
- en: 'Then, click on the + symbol at the end of the row and select tag(hostname).Finally,
    at the bottom of the screen we should see a Group by time interval. Enter `5s` there
    and you should have something similar to the following screenshot:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，点击行末的 + 符号，选择标签（hostname）。最后，在屏幕底部我们应该能看到按时间间隔分组的选项。在那里输入`5s`，然后你应该能看到类似以下截图的内容：
- en: '![](img/07fee65f-a7e2-4905-8ae3-8b883ea681d5.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/07fee65f-a7e2-4905-8ae3-8b883ea681d5.png)'
- en: Heapster pod details
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Heapster Pod 详情
- en: Next, let's click on the Axes tab, so that we can set the units and legend.
    Under Left Y Axis, click on the field next to Unit and set it to data | bytes
    and Label to Disk Space Used. Under Right Y Axis, set Unit to none | none. Next,
    on the Legend tab, make sure to check Show in Options and Max in Values.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，点击“坐标轴”标签，以便设置单位和图例。在左侧Y轴下，点击单位旁边的字段并将其设置为数据 | 字节，标签设置为“磁盘空间使用”。在右侧Y轴下，将单位设置为无
    | 无。接下来，在“图例”标签下，确保勾选“选项中的显示”和“值中的最大值”。
- en: Now, let's quickly go to the General tab and choose a title. In my case, I named
    mine `Filesystem Disk Usage by Node (max)`.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们快速进入“常规”标签页并选择一个标题。在我的例子中，我将其命名为`Filesystem Disk Usage by Node (max)`。
- en: We don't want to lose this nice new graph we've created, so let's click on the
    save icon in the top-right corner. It looks like a floppy disk (you can do a Google
    image search if you don't know what this is).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不想丢失我们刚刚创建的漂亮新图表，因此让我们点击右上角的保存图标。它看起来像一个软盘（如果你不知道它是什么，可以用Google图片搜索）。
- en: After we click on the save icon, we will see a green dialog box that verifies
    that the dashboard was saved. We can now click the x symbol above the graph details
    panel and below the graph itself.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 点击保存图标后，我们会看到一个绿色的对话框，确认仪表板已保存。现在我们可以点击图表详情面板上方、图表本身下方的x符号。
- en: This will return us to the dashboard page. If we scroll all the way down, we
    will see our new graph. Let's add another panel to this row. Again, use the *green*
    tab and then select Add Panel | singlestat. Once again, an empty panel will appear
    with a setting form below it.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回到仪表板页面。如果我们向下滚动，应该能看到我们的新图表。让我们再向这一行添加一个面板。同样使用*绿色*标签，然后选择“添加面板 | 单一统计”。再次，一个空白面板将出现，下面是一个设置表单。
- en: Let's say we want to watch a particular node and monitor network usage. We can
    easily do this by first going to the Metrics tab. Then, expand the query field
    and set the second value in the FROM field to network/rx. Now, we can specify
    the WHERE clause by clicking the + symbol at the end of the row and choosing hostname
    from the drop-down. After hostname =, click on select tag value and choose one
    of the minion nodes from the list.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们想监控一个特定节点的网络使用情况。我们可以通过首先进入“度量”标签页轻松实现。然后，展开查询字段并将FROM字段中的第二个值设置为network/rx。现在，我们可以通过点击行末的+符号并从下拉菜单中选择hostname来指定WHERE子句。在hostname
    =之后，点击选择标签值并从列表中选择一个从节点。
- en: 'Finally, leave mean() for the second SELECT field shown as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，保留`mean()`作为第二个SELECT字段，示例如下：
- en: '![](img/828b8fbe-c59b-4863-8ab3-eda8f82f0518.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![](img/828b8fbe-c59b-4863-8ab3-eda8f82f0518.png)'
- en: Singlestat options
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 单一统计选项
- en: In the Options tab, make sure that Unit format is set to data | bytes and check
    the Show box next to Spark lines. The spark line gives us a quick historical view
    of the recent variations in the value. We can use Background mode to take up the
    entire background; by default, it uses the area below the value.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在“选项”标签页中，确保将单位格式设置为数据 | 字节，并勾选“火花线”旁边的框。火花线为我们提供了近期数值变化的快速历史视图。我们可以使用背景模式来填充整个背景；默认情况下，它使用数值下方的区域。
- en: In Coloring, we can optionally check the Value or Background box and choose
    Thresholds and Colors. This will allow us to choose different colors for the value
    based on the threshold tier we specify. Note that an unformatted version of the
    number must be used for threshold values.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在“着色”中，我们可以选择性地勾选“值”或“背景”框，并选择阈值和颜色。这将允许我们根据指定的阈值层次为值选择不同的颜色。请注意，阈值值必须使用未格式化的数字版本。
- en: Now, let's go back to the General tab and set the title as `Network bytes received
    (Node35ao)`. Use the identifier for your minion node.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们返回到“常规”标签页，并将标题设置为`Network bytes received (Node35ao)`。使用你的从节点标识符。
- en: 'Once again, let''s save our work and return to the dashboard. We should now
    have a row that looks like the following screenshot:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 再次保存我们的工作并返回到仪表板。现在，我们应该看到如下所示的行：
- en: '![](img/d10e2ae7-5b49-4772-a1a5-b340e7db65dd.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![](img/d10e2ae7-5b49-4772-a1a5-b340e7db65dd.png)'
- en: Custom dashboard panels
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 自定义仪表板面板
- en: Grafana has a number of other panel types that you can play with, such as Dashboard
    list, Plugin list, Table, and Text.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana还有许多其他面板类型，您可以尝试，比如仪表板列表、插件列表、表格和文本。
- en: As we can see, it is pretty easy to build a custom dashboard and monitor the
    health of our cluster at a glance.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所看到的，创建一个自定义仪表板并一眼监控集群健康状态其实是很简单的。
- en: FluentD and Google Cloud Logging
  id: totrans-101
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FluentD 和 Google Cloud Logging
- en: Looking back at the *System pod listing* screenshot at the beginning of the
    chapter, you may have noted a number of pods starting with the words `fluentd-cloud-logging-kubernetes`.
    These pods appear when using the GCE provider for your K8s cluster.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾本章开始时的*系统 Pod 列表*截图，你可能注意到有一些 Pod 以 `fluentd-cloud-logging-kubernetes` 开头。这些
    Pod 在使用 GCE 提供程序进行 K8s 集群配置时会出现。
- en: A pod like this exists on every node in our cluster, and its sole purpose is
    to handle the processing of Kubernetes logs. If we log in to our Google Cloud
    Platform account, we can see some of the logs processed there. Simply use the
    left side, and under Stackdriver, select Logging. This will take us to a log listing
    page with a number of drop-down menus on the top. If this is your first time visiting
    the page, the first drop-down will likely be set to Cloud HTTP Load Balancer.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点上都有这样的 Pod，它的唯一目的是处理 Kubernetes 日志。如果我们登录到 Google Cloud Platform 帐户，我们可以查看在那里处理的一些日志。只需使用左侧菜单，在
    Stackdriver 下选择 Logging。这样我们将进入一个日志列表页面，页面顶部有多个下拉菜单。如果这是你第一次访问该页面，第一个下拉菜单很可能会被设置为
    Cloud HTTP Load Balancer。
- en: 'In this drop-down menu, we''ll see a number of GCE types of entries. Select GCE
    VM instances and then the Kubernetes master or one of the nodes. In the second
    drop-down, we can choose various log groups, including kubelet. We can also filter
    by the event log level and date. Additionally, we can use the play button to watch
    events stream in live shown as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在此下拉菜单中，我们将看到多个 GCE 类型的条目。选择 GCE VM 实例，然后选择 Kubernetes 主节点或其中一个节点。在第二个下拉菜单中，我们可以选择不同的日志组，包括
    kubelet。我们还可以按事件日志级别和日期进行筛选。此外，我们可以使用播放按钮观看实时流入的事件，如下所示：
- en: '![](img/2e48780f-e898-4f43-a83a-f8555566e79b.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2e48780f-e898-4f43-a83a-f8555566e79b.png)'
- en: The Google Cloud Logging filter
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud 日志过滤器
- en: FluentD
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FluentD
- en: Now we know that the `fluentd-cloud-logging-kubernetes` pods are sending the
    data to the Google Cloud, but why do we need FluentD? Simply put, FluentD is a
    collector.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道 `fluentd-cloud-logging-kubernetes` Pods 正在将数据发送到 Google Cloud，但为什么我们需要
    FluentD 呢？简而言之，FluentD 是一个收集器。
- en: It can be configured to have multiple sources to collect and tag logs, which
    are then sent to various output points for analysis, alerting, or archiving. We
    can even transform data using plugins before it is passed on to its destination.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以配置多个来源来收集和标记日志，然后将其发送到不同的输出点进行分析、告警或归档。我们甚至可以在数据传输到目的地之前，通过插件对数据进行转换。
- en: Not all provider setups have FluentD installed by default, but it is one of
    the recommended approaches to give us greater flexibility for future monitoring
    operations. The AWS Kubernetes setup also uses FluentD, but instead forwards events
    to Elasticsearch.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 不是所有的提供程序设置都会默认安装 FluentD，但它是推荐的方式之一，能为我们未来的监控操作提供更大的灵活性。AWS Kubernetes 设置也使用
    FluentD，但它将事件转发到 Elasticsearch。
- en: '**Exploring FluentD**: If you are curious about the inner workings of the FluentD
    setup or just want to customize the log collection, we can explore quite easily
    using the `kubectl exec` command and one of the pod names from the command we
    ran earlier in the chapter. First, let''s see if we can find the FluentD `config`
    file: `**$ kubectl exec fluentd-cloud-logging-kubernetes-minion-group-r4qt --namespace=kube-system
    -- ls /etc/td-agent**`.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '**探索 FluentD**：如果你对 FluentD 配置的内部工作原理感兴趣，或者只是想自定义日志收集，我们可以很容易地通过 `kubectl exec`
    命令和本章前面运行的命令中的某个 Pod 名称进行探索。首先，让我们看看能否找到 FluentD 的 `config` 文件：`**$ kubectl exec
    fluentd-cloud-logging-kubernetes-minion-group-r4qt --namespace=kube-system --
    ls /etc/td-agent**`。'
- en: We will look in the `etc` folder and then `td-agent`, which is the `fluent`
    sub folder. While searching in this directory, we should see a `td-agent.conf`
    file. We can view that file with a simple `cat` command, as follows: `**$ kubectl
    exec fluentd-cloud-logging-kubernetes-minion-group-r4qt --namespace=kube-system
    -- cat /etc/td-agent/td-agent.conf**`.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将查看 `etc` 文件夹中的 `td-agent` 文件夹，它是 `fluent` 的子文件夹。在这个目录中搜索时，我们应该能看到一个 `td-agent.conf`
    文件。我们可以通过一个简单的 `cat` 命令查看该文件，如下所示：`**$ kubectl exec fluentd-cloud-logging-kubernetes-minion-group-r4qt
    --namespace=kube-system -- cat /etc/td-agent/td-agent.conf**`。
- en: We should see a number of sources, including the various Kubernetes components,
    Docker, and some GCP elements. While we can make changes here, remember that it
    is a running container and our changes won't be saved if the pod dies or is restarted.
    If we really want to customize, it's best to use this container as a base and
    build a new container, which we can push to a repository for later use.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该查看多个来源，包括各种 Kubernetes 组件、Docker 和一些 GCP 元素。虽然我们可以在这里进行更改，但请记住，这是一个正在运行的容器，如果
    Pod 死亡或重启，我们的更改将不会保存。如果我们真的想要定制，最好将此容器作为基础并构建一个新的容器，之后可以将其推送到仓库以供以后使用。
- en: Maturing our monitoring operations
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 发展我们的监控操作
- en: While Grafana gives us a great start to monitoring our container operations,
    it is still a work in progress. In the real world of operations, having a complete
    dashboard view is great once we know there is a problem. However, in everyday
    scenarios, we'd prefer to be proactive and actually receive notifications when
    issues arise. This kind of alerting capability is a must to keep the operations
    team ahead of the curve and out of reactive mode.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Grafana 为我们提供了监控容器操作的良好起点，但它仍在不断发展中。在实际操作环境中，拥有一个完整的仪表板视图在发现问题时非常有用。然而，在日常场景中，我们更倾向于主动并且希望在问题出现时就收到通知。这种告警能力对于确保运营团队处于领先地位、避免被动反应模式至关重要。
- en: 'There are many solutions available in this space, and we will take a look at
    two in particular: GCE monitoring (Stackdriver) and Sysdig.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域有许多可用的解决方案，我们将特别查看其中的两个：GCE 监控（Stackdriver）和 Sysdig。
- en: GCE (Stackdriver)
  id: totrans-117
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GCE（Stackdriver）
- en: Stackdriver is a great place to start for infrastructure in the public cloud.
    It is actually owned by Google, so it's integrated as the Google Cloud Platform
    monitoring service. Before your lock-in alarm bells start ringing, Stackdriver
    also has solid integration with AWS. In addition, Stackdriver has alerting capability
    with support for notification to a variety of platforms and webhooks for anything
    else.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Stackdriver 是一个很好的公共云基础设施监控起点。它实际上是由 Google 所拥有，因此被集成作为 Google Cloud Platform
    的监控服务。在你开始担心锁定问题之前，Stackdriver 也与 AWS 有良好的集成。此外，Stackdriver 提供告警功能，支持将通知发送到各种平台，并支持
    Webhooks 用于其他用途。
- en: Signing up for GCE monitoring
  id: totrans-119
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 注册 GCE 监控
- en: In the GCE console, in the Stackdriver section, click on Monitoring. This will
    open a new window, where we can sign up for a free trial of Stackdriver. We can
    then add our GCP project and optionally an AWS account as well. This requires
    a few more steps, but instructions are included on the page. Finally, we'll be
    given instructions on how to install the agents on our cluster nodes. We can skip
    this for now, but will come back to it in a minute.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GCE 控制台的 Stackdriver 部分，点击“监控”。这将打开一个新窗口，在这里我们可以注册 Stackdriver 的免费试用。接下来，我们可以添加我们的
    GCP 项目，并可选地添加一个 AWS 账户。这需要更多的步骤，但页面中已提供说明。最后，我们将获得关于如何在集群节点上安装代理的说明。我们可以暂时跳过这一步，但稍后会回来处理。
- en: Click on Continue, set up your daily alerts, and click on Continue again.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“继续”，设置每日告警，然后再次点击“继续”。
- en: Click on Launch Monitoring to proceed. We'll be taken to the main dashboard
    page, where we will see some basic statistics on our node in the cluster. If we
    select Resources from the side menu and then Instances, we'll be taken to a page
    with all our nodes listed. By clicking on the individual node, we can again see
    some basic information even without an agent installed.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“启动监控”继续。我们将被带到主仪表板页面，在这里我们可以看到集群中节点的一些基本统计信息。如果从侧边菜单选择“资源”，然后选择“实例”，我们将进入一个页面，列出所有节点。通过点击单个节点，即使没有安装代理，我们也能看到一些基本信息。
- en: Stackdriver also offers monitoring and logging agents that can be installed
    on the nodes. However, it currently does not support the container OS that is
    used by default in the GCE `kube-up` script. You can still see the basic metrics
    for any nodes in GCE or AWS, but will need to use another OS if you want a detailed
    agent installation.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Stackdriver 还提供可以安装在节点上的监控和日志代理。然而，它目前不支持 GCE `kube-up` 脚本中默认使用的容器操作系统。如果你想要更详细的代理安装，你仍然可以看到
    GCE 或 AWS 中任何节点的基本指标，但需要使用另一个操作系统。
- en: Alerts
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 警报
- en: Next, we can look at the alerting policies available as part of the monitoring
    service. From the instance details page, click on the Create Alerting Policy button
    in the Incidents section at the top of the page.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以查看作为监控服务一部分的告警策略。从实例详情页，点击页面顶部“事件”部分中的“创建告警策略”按钮。
- en: We will click on Add Condition and select a Metric Threshold. In the Target section,
    set RESOURCE TYPE to Instance (GCE). Then, set APPLIES TO to Group and kubernetes.
    Leave CONDITION TRIGGERS IF set to Any Member Violates.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将点击添加条件并选择一个指标阈值。在目标部分，将 RESOURCE TYPE 设置为实例（GCE）。然后，将 APPLIES TO 设置为组和 kubernetes。将
    CONDITION TRIGGERS IF 保持为任何成员违反时触发。
- en: In the Configuration section, leave IF METRIC as CPU Usage (GCE Monitoring)
    and CONDITION as above. Now, set THRESHOLD to `80` and set the time in FOR to
    5 minutes.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置部分，将 IF METRIC 保持为 CPU 使用率（GCE 监控），并将 CONDITION 设置为如上所示。现在，将 THRESHOLD 设置为`80`，并将
    FOR 中的时间设置为 5 分钟。
- en: 'Then click on Save Condition:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 然后点击保存条件：
- en: '![](img/44c131d0-a5f8-4760-9288-36fb3056debb.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![](img/44c131d0-a5f8-4760-9288-36fb3056debb.png)'
- en: Google Cloud Monitoring alert policy
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud 监控警报策略
- en: Next, we will add a notification. In the Notification section, leave Method
    as Email and enter your email address.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将添加一个通知。在通知部分，将方法保持为电子邮件，并输入你的电子邮件地址。
- en: We can skip the Documentation section, but this is where we can add text and
    formatting to alert messages.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以跳过文档部分，但在这里我们可以为警报消息添加文本和格式。
- en: Finally, name the policy `Excessive CPU Load` and click on Save Policy.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将策略命名为 `过高的 CPU 负载`，并点击保存策略。
- en: Now, whenever the CPU from one of our instances goes above 80 percent, we will
    receive an email notification. If we ever need to review our policies, we can
    find them in the Alerting drop-down and then in Policies Overview in the menu
    on the left-hand side of the screen.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，每当我们某个实例的 CPU 使用率超过 80%，我们就会收到电子邮件通知。如果我们需要查看我们的策略，可以在警报下拉菜单中找到它们，然后在屏幕左侧的菜单中选择策略概览。
- en: Beyond system monitoring with Sysdig
  id: totrans-135
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 超越使用 Sysdig 进行系统监控
- en: Monitoring our cloud systems is a great start, but what about the visibility
    of the containers themselves? Although there are a variety of cloud monitoring
    and visibility tools, Sysdig stands out for its ability to dive deep, not only
    into system operations, but specifically containers.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 监控我们的云系统是一个很好的开始，但容器本身的可视化呢？虽然有许多云监控和可视化工具，但 Sysdig 以其能够深入挖掘，不仅限于系统操作，还专门针对容器的能力而脱颖而出。
- en: Sysdig is open source and is billed as a universal system visibility tool with
    native support for containers. It is a command line tool that provides insight
    into the areas we looked at earlier, such as storage, network, and system processes.
    What sets it apart is the level of detail and visibility it offers for these process
    and system activities. Furthermore, it has native support for containers, which
    gives us a full picture of our container operations. This is a highly recommended
    tool for your container operations arsenal. The main website of Sysdig is [http://www.sysdig.org/](http://www.sysdig.org/).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Sysdig 是开源软件，被誉为一款通用的系统可视化工具，原生支持容器。它是一个命令行工具，可以提供对我们之前查看过的各个领域的深入了解，如存储、网络和系统进程。它的独特之处在于提供的细节级别和对这些进程和系统活动的可视化。此外，Sysdig
    还原生支持容器，为我们提供了容器操作的全面视图。这是一个非常推荐的工具，适合你的容器操作工具库。Sysdig 的官方网站是 [http://www.sysdig.org/](http://www.sysdig.org/)。
- en: Sysdig Cloud
  id: totrans-138
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sysdig Cloud
- en: We will take a look at the Sysdig tool and some of the useful command line-based
    UIs in a moment. However, the team at Sysdig has also built a commercial product,
    named **Sysdig Cloud**, which provides the advanced dashboard, alerting, and notification
    services we discussed earlier in the chapter. Also, the differentiator here has
    high visibility into containers, including some nice visualizations of our application
    topology.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们稍后将看看 Sysdig 工具及其一些有用的命令行 UI。然而，Sysdig 团队还开发了一款商业产品，名为 **Sysdig Cloud**，它提供了我们在本章前面讨论过的高级仪表盘、警报和通知服务。此外，Sysdig
    Cloud 的区别在于对容器的高可视化，包括我们应用拓扑的一些漂亮的可视化效果。
- en: If you'd rather skip the *Sysdig Cloud* section and just try out the command-line
    tool, simply skip to *The* S*ysdig command line* section later in this chapter.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你更愿意跳过 *Sysdig Cloud* 部分并直接尝试命令行工具，只需跳到本章后面的 *Sysdig 命令行* 部分。
- en: If you have not done so already, sign up for Sysdig Cloud at [http://www.sysdigcloud.com](http://www.sysdigcloud.com).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有注册，快去 [http://www.sysdigcloud.com](http://www.sysdigcloud.com) 注册 Sysdig
    Cloud。
- en: After activating and logging in for the first time, we'll be taken to a welcome
    page. Clicking on Next, we are shown a page with various options to install the
    Sysdig agents. For our example environment, we will use the Kubernetes setup.
    Selecting Kubernetes will give you a page with your API key and a link to instructions.
    The instructions will walk you through how to create a Sysdig agent DaemonSet
    on your cluster. Don't forget to add the API key from the install page.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在首次激活并登录后，我们将进入欢迎页面。点击“下一步”，会显示一个页面，提供各种选项来安装Sysdig代理。在我们的示例环境中，我们将使用Kubernetes设置。选择Kubernetes后，会显示一个页面，提供API密钥和安装说明的链接。安装说明会指导你如何在集群中创建Sysdig代理DaemonSet。别忘了在安装页面添加API密钥。
- en: We will not be able to continue on the install page until the agents connect.
    After creating the DaemonSet and waiting a moment, the page should continue to
    the AWS integration page. You can fill this out if you like, but for this walk-through,
    we will click on Skip. Then, click on Let's Get Started.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在代理连接之前，我们将无法继续安装页面。在创建DaemonSet并等待片刻后，页面应该会继续到AWS集成页面。你可以填写这些信息，但在本次操作中，我们将点击“跳过”。然后，点击“开始使用”。
- en: As of this writing, Sysdig and Sysdig Cloud were not fully compatible with the
    latest container OS deployed by default in the GCE `kube-up` script, Container-optimized
    OS from Google: [https://cloud.google.com/container-optimized-os/docs](https://cloud.google.com/container-optimized-os/docs).
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 截至本文撰写时，Sysdig和Sysdig Cloud尚未完全兼容GCE `kube-up`脚本中默认部署的最新容器操作系统——Google的容器优化操作系统：[https://cloud.google.com/container-optimized-os/docs](https://cloud.google.com/container-optimized-os/docs)。
- en: 'We''ll be taken to the main Sysdig Cloud dashboard screen. We should see at
    least two minion nodes appear under the Explore tab. We should see something similar
    to the following screenshot with our minion nodes:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将被带到Sysdig Cloud的主仪表盘屏幕。我们应该在“探索”标签下看到至少两个从属节点。我们应该看到类似下面截图的内容，显示我们的从属节点：
- en: '![](img/e1e97e90-8387-4488-aab6-cc3d56c93599.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/e1e97e90-8387-4488-aab6-cc3d56c93599.png)'
- en: Sysdig Cloud Explore page
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Sysdig Cloud探索页面
- en: This page shows us a table view, and the links on the left let us explore some
    key metrics for CPU, memory, networking, and so on. Although this is a great start,
    the detailed views will give us a much deeper look at each node.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 该页面展示了一个表格视图，左侧的链接让我们可以查看一些关键指标，例如CPU、内存、网络等。虽然这是一个很好的开始，但详细视图将为我们提供每个节点的更深入的视图。
- en: Detailed views
  id: totrans-149
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 详细视图
- en: 'Let''s take a look at these views. Select one of the minion nodes and then
    scroll down to the detail section that appears below. By default, we should see
    the System: Overview by Process view (if it''s not selected, just click on it
    from the list on the left-hand side). If the chart is hard to read, simply use
    the maximize icon in the top-left corner of each graph for a larger view.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看这些视图。选择一个从属节点，然后向下滚动到下面显示的详细信息部分。默认情况下，我们应该看到“按进程概览”视图（如果没有选中，只需从左侧列表中点击它）。如果图表难以阅读，只需使用每个图表左上角的最大化图标来放大视图。
- en: There are a variety of interesting views to explore. Just to call out a few
    others, Services | HTTP Overview and Hosts & Containers | Overview by Container
    give us some great charts for inspection. In the latter view, we can see stats
    for CPU, memory, network, and file usage by container.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种有趣的视图可以探索。这里只列出其他几个，服务|HTTP概览和主机与容器|按容器概览为我们提供了一些很好的图表供检查。在后者的视图中，我们可以看到每个容器的CPU、内存、网络和文件使用情况的统计数据。
- en: Topology views
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 拓扑视图
- en: 'In addition, there are three topology views at the bottom. These views are
    perfect for helping us understand how our application is communicating. Click
    on Topology | Network Traffic and wait a few seconds for the view to fully populate.
    It should look similar to the following screenshot:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，底部还有三个拓扑视图。这些视图非常适合帮助我们理解应用程序如何进行通信。点击拓扑|网络流量，并等待几秒钟，直到视图完全加载。它应该与以下截图相似：
- en: '![](img/2c6efa2b-a243-4682-bf29-58f1b88d0859.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2c6efa2b-a243-4682-bf29-58f1b88d0859.png)'
- en: Sysdig Cloud network topology view
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: Sysdig Cloud网络拓扑视图
- en: 'Note that the view maps out the flow of communication between the minion nodes
    and the master in the cluster. You may also note a + symbol in the top corner
    of the node boxes. Click on that in one of the minion nodes and use the zoom tools
    at the top of the view area to zoom into the details, as shown in the following
    screenshot:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，该视图绘制了从属节点与集群中主节点之间的通信流动。你还可能会在节点框的右上角看到一个加号（+）符号。点击其中一个从属节点上的加号，并使用视图区域顶部的缩放工具来放大查看详细信息，如下图所示：
- en: '![](img/1f120057-ed85-45db-b377-2ced1e76790f.png)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1f120057-ed85-45db-b377-2ced1e76790f.png)'
- en: The Sysdig Cloud network topology detailed view
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: Sysdig Cloud网络拓扑详细视图
- en: Note that we can now see all the components of Kubernetes running inside the
    master. We can see how the various components work together. We can see `kube-proxy` and
    the `kubelet` process running, as well as a number of boxes with the Docker whale,
    which indicate that they are containers. If we zoom in and use the plus icon,
    we can see that these are the containers for our pods and core Kubernetes processes,
    as we saw in the services running on the master section in [Chapter 1](446f901d-70fa-4ebe-be8a-0de14248f99c.xhtml),
    *Introduction to* *Kubernetes*.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们现在可以看到所有在主节点内运行的Kubernetes组件。我们可以看到各个组件如何协同工作。我们可以看到`kube-proxy`和`kubelet`进程在运行，还有一些带有Docker鲸鱼标志的框，这些表示它们是容器。如果我们放大并使用加号图标，我们可以看到这些是我们的Pod和核心Kubernetes进程的容器，正如我们在[第1章](446f901d-70fa-4ebe-be8a-0de14248f99c.xhtml)的主节点上运行的服务中看到的，*Kubernetes简介*部分。
- en: Also, if you have the master included in your monitored nodes, you can watch
    `kubelet` initiate communication from a minion and follow it all the way through
    the `kube-apiserver` container in the master.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，如果你在监控的节点中包括了主节点，你可以看到`kubelet`从某个从节点发起通信，并一路跟踪到主节点的`kube-apiserver`容器。
- en: We can even sometimes see the instance communicating with the GCE infrastructure
    to update metadata. This view is great in order to get a mental picture of how
    our infrastructure and underlying containers are talking to one another.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们甚至有时能看到实例与GCE基础设施进行通信，更新元数据。这个视图非常适合帮助我们形成一个大致的思路，了解我们的基础设施和底层容器是如何相互通信的。
- en: Metrics
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 指标
- en: Next, let's switch over to the Metrics tab in the left-hand menu next to Views.
    Here, there are also a variety of helpful views.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们切换到左侧菜单中“视图”（Views）旁的“指标”（Metrics）选项卡。在这里，还有各种有用的视图。
- en: 'Let''s look at capacity.estimated.request.total.count in System. This view
    shows us an estimate of how many requests a node is capable of handling when fully
    loaded. This can be really useful for infrastructure planning:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下System中的capacity.estimated.request.total.count。这个视图展示了节点在完全负载时能够处理多少请求的估计值。这对于基础设施规划非常有用：
- en: '![](img/9f48657a-fe91-40d8-aeb9-a40410ef95f6.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9f48657a-fe91-40d8-aeb9-a40410ef95f6.png)'
- en: Sysdig Cloud capacity estimate view
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Sysdig Cloud容量估算视图
- en: Alerting
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 警报
- en: Now that we have all this great information, let's create some notifications.
    Scroll back up to the top of the page and find the bell icon next to one of your
    minion entries. This will open a Create Alert dialog. Here, we can set manual
    alerts similar to what we did earlier in the chapter. However, there is also the
    option to use BASELINE and HOST COMPARISON.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们拥有了这么多有用的信息，让我们创建一些通知。向上滚动到页面顶部，找到一个从节点条目旁边的铃铛图标。点击它会打开一个创建警报的对话框。在这里，我们可以设置类似于本章前面部分手动设置的警报。不过，这里还有使用基准线（BASELINE）和主机比较（HOST
    COMPARISON）选项的功能。
- en: 'Using the BASELINE option is extremely helpful, as Sysdig will watch the historical
    patterns of the node and alert us whenever one of the metrics strays outside the
    expected metric thresholds. No manual settings are required, so this can really
    save time for the notification setup and help our operations team to be proactive
    before issues arise. Refer to the following screenshot:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 使用基准线（BASELINE）选项非常有帮助，因为Sysdig会监视节点的历史模式，并在某个指标超出预期的阈值时发出警报。无需手动设置，这样可以大大节省通知设置的时间，并帮助我们的运维团队在问题出现之前采取主动。请参见以下截图：
- en: '![](img/9c4b11bc-0918-4bfa-adfe-32be7f016b56.png)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![](img/9c4b11bc-0918-4bfa-adfe-32be7f016b56.png)'
- en: Sysdig Cloud new alert
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Sysdig Cloud新警报
- en: The HOST COMPARISON option is also a great help as it allows us to compare metrics
    with other hosts and alert whenever one host has a metric that differs significantly
    from the group. A great use case for this is monitoring resource usage across
    minion nodes to ensure that our scheduling constraints are not creating a bottleneck
    somewhere in the cluster.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 主机比较（HOST COMPARISON）选项也非常有帮助，因为它可以让我们与其他主机比较指标，并在某个主机的指标与其他主机显著不同时发出警报。一个典型的使用场景是监控从节点的资源使用情况，确保我们的调度约束不会在集群中某个地方造成瓶颈。
- en: You can choose whichever option you like and give it a name and warning level.
    Enable the notification method. Sysdig supports email, **SNS** (short for **Simple
    Notification Service**), and **PagerDuty** as notification methods. You can optionally
    enable **Sysdig Capture** to gain deeper insight into issues. Once you have everything
    set, just click on Create and you will start to receive alerts as issues come
    up.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以选择任何你喜欢的选项，为其命名并设置警告级别。启用通知方法。Sysdig 支持电子邮件、**SNS**（即 **简单通知服务**）和 **PagerDuty**
    作为通知方法。你还可以选择启用 **Sysdig Capture**，以便更深入地了解问题。设置完成后，只需点击创建，你就会在问题出现时开始收到警报。
- en: The Sysdig command line
  id: totrans-174
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Sysdig 命令行
- en: Whether you only use the open source tool or you are trying out the full Sysdig
    Cloud package, the command line utility is a great companion to have to track
    down issues or get a deeper understanding of your system.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你是仅使用开源工具，还是尝试完整的 Sysdig Cloud 套件，命令行工具都是一个很好的伙伴，可以帮助你追踪问题或更深入地了解你的系统。
- en: In the core tool, there is the main `sysdig` utility and also a command line-style
    UI named `csysdig`. Let's take a look at a few useful commands.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在核心工具中，除了主要的 `sysdig` 工具外，还有一个命令行风格的 UI，名为 `csysdig`。让我们看一些有用的命令。
- en: Find the relevant installation instructions for your OS here: [http://www.sysdig.org/install/](http://www.sysdig.org/install/).
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 查找适合你操作系统的安装说明：[http://www.sysdig.org/install/](http://www.sysdig.org/install/)。
- en: 'Once installed, let''s first look at the process with the most network activity
    by issuing the following command:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 安装完成后，首先通过以下命令查看网络活动最多的进程：
- en: '[PRE5]'
  id: totrans-179
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following screenshot is the result of the preceding command:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前述命令的结果：
- en: '![](img/cc33a877-6d2d-475c-9e22-dc4c87e1b15b.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![](img/cc33a877-6d2d-475c-9e22-dc4c87e1b15b.png)'
- en: A Sysdig top process by network activity
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 按网络活动排序的 Sysdig 顶级进程
- en: 'This is an interactive view that will show us a top process in terms of network
    activity. Also, there are a plethora of commands to use with `sysdig`. A few other
    useful commands to try out include the following:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个交互式视图，将显示按网络活动排序的顶级进程。此外，还有许多可以与 `sysdig` 一起使用的命令。以下是一些其他有用的命令：
- en: '[PRE6]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: More examples can be found at [http://www.sysdig.org/wiki/sysdig-examples/](http://www.sysdig.org/wiki/sysdig-examples/).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 更多示例可以在 [http://www.sysdig.org/wiki/sysdig-examples/](http://www.sysdig.org/wiki/sysdig-examples/)
    找到。
- en: The Csysdig command-line UI
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Csysdig 命令行 UI
- en: 'Just because we are in a shell on one of our nodes doesn''t mean we can''t
    have a UI. Csysdig is a customizable UI for exploring all the metrics and insight
    that Sysdig provides. Simply type `csysdig` in the prompt:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 仅仅因为我们在某个节点的 shell 中，并不意味着我们不能使用 UI。Csysdig 是一个可定制的 UI，用于探索 Sysdig 提供的所有指标和洞察。只需在提示符中输入`csysdig`：
- en: '[PRE7]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: After entering `csysdig`, we will see a real-time listing of all processes on
    the machine. At the bottom of the screen, you'll note a menu with various options.
    Click on Views or press *F2* if you love to use your keyboard. In the left-hand
    menu, there are a variety of options, but we'll look at threads. Double-click
    on Threads.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 输入 `csysdig` 后，我们将看到机器上所有进程的实时列表。在屏幕底部，你会看到一个包含各种选项的菜单。如果你喜欢使用键盘，可以点击 Views
    或按 *F2*。在左侧菜单中有各种选项，我们将查看线程。双击线程（Threads）。
- en: On some operating systems and with some SSH clients, you may have issues with
    the function keys. Check the settings on your terminal and make sure that the
    function keys are using the VT100+ sequences.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些操作系统和 SSH 客户端上，你可能会遇到功能键的问题。检查你的终端设置，确保功能键使用的是 VT100+ 序列。
- en: We can see all the threads currently running on the system and some information
    about the resource usage. By default, we see a big list that is updated often.
    If we click on the Filter, *F4* for the mouse-challenged, we can slim down the
    list.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到系统上当前运行的所有线程以及一些资源使用信息。默认情况下，我们会看到一个更新频繁的大列表。如果点击筛选器，*F4*（对于不擅长使用鼠标的用户），我们可以缩小列表范围。
- en: 'Type `kube-apiserver`, if you are on the master, or `kube-proxy`, if you are
    on a node (minion), in the filter box and press *Enter*. The view now filters
    for only the threads in that command:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在筛选框中输入 `kube-apiserver`，如果你在主节点上；或输入 `kube-proxy`，如果你在一个节点（minion）上，然后按 *Enter*。现在视图会过滤出该命令下的所有线程：
- en: '![](img/1c9f7d33-45a0-4d07-8710-782388d176a3.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![](img/1c9f7d33-45a0-4d07-8710-782388d176a3.png)'
- en: Csysdig threads
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Csysdig 线程
- en: If we want to inspect this a little further, we can simply select one of the
    threads in the list and click on Dig or press *F6*. Now, we see a detailed listing
    of system calls from the command in real time. This can be a really useful tool
    to gain deep insight into the containers and processes running on our cluster.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们想进一步检查，可以简单地选择列表中的一个线程，点击“Dig”或按 *F6* 键。现在，我们可以看到命令的系统调用的详细列表，实时显示。这是一个非常有用的工具，可以深入了解在我们集群上运行的容器和进程。
- en: Click on Back or press the *Backspace* key to go back to the previous screen.
    Then, go to Views once more. This time, we will look at the Containers view. Once
    again, we can filter and also use the Dig view to get more in-depth visibility
    into what is happening at the system call level.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 点击“Back”或按 *Backspace* 键返回到上一个屏幕。然后，再次进入“Views”视图。这一次，我们将查看 Containers 视图。同样，我们可以进行过滤，并使用
    Dig 视图深入了解系统调用级别的情况。
- en: Another menu item you might note here is Actions, which is available in the
    newest release. These features allow us to go from process monitoring to action
    and response. It gives us the ability to perform a variety of actions from the
    various process views in Csysdig. For example, the container view has actions
    to drop into a Bash shell, kill containers, inspect logs, and more. It's worth
    getting to know the various actions and hotkeys, and even add your own custom
    hotkeys for common operations.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个你可能会注意到的菜单项是“Actions”，它在最新版本中提供。这些功能允许我们从进程监控到操作和响应。它使我们能够从 Csysdig 的各种进程视图中执行各种操作。例如，容器视图中有操作可以进入
    Bash shell、杀死容器、检查日志等。值得了解各种操作和快捷键，甚至为常见操作添加你自己的自定义快捷键。
- en: Prometheus
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus
- en: A newcomer to the monitoring scene is an open source tool called Prometheus.
    Prometheus is an open source monitoring tool that was built by a team at SoundCloud.
    You can find more about the project at [https://prometheus.io](https://prometheus.io).
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 一个新兴的监控工具是名为 Prometheus 的开源工具。Prometheus 是一个由 SoundCloud 团队开发的开源监控工具。你可以在 [https://prometheus.io](https://prometheus.io)
    上找到更多关于该项目的信息。
- en: 'Their website offers the following features:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 他们的网站提供以下功能：
- en: A multi-dimensional data model ([https://prometheus.io/docs/concepts/data_model/](https://prometheus.io/docs/concepts/data_model/))
    (the time series are identified by their metric name and key/value pairs)
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多维数据模型 ([https://prometheus.io/docs/concepts/data_model/](https://prometheus.io/docs/concepts/data_model/))（时间序列通过其度量名称和键/值对来标识）
- en: A flexible query language ([https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/))
    to leverage this dimensionality
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个灵活的查询语言 ([https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/))
    来利用这种多维度数据
- en: No reliance on distributed storage; single-server nodes are autonomous
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不依赖分布式存储；单服务器节点是自主的
- en: Time series collection happens via a pull model over HTTP
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间序列收集通过 HTTP 的拉取模型进行
- en: Pushing time series ([https://prometheus.io/docs/instrumenting/pushing/](https://prometheus.io/docs/instrumenting/pushing/))
    is supported via an intermediary gateway
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推送时间序列 ([https://prometheus.io/docs/instrumenting/pushing/](https://prometheus.io/docs/instrumenting/pushing/))
    通过中介网关进行支持
- en: Targets are discovered via service discovery or static configuration
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目标通过服务发现或静态配置进行发现
- en: Multiple modes of graphing and dashboard support
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持多种图形和仪表盘模式
- en: Prometheus summary
  id: totrans-208
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus 总结
- en: 'Prometheus offers a lot of value to the operators of a Kubernetes cluster.
    Let''s look at some of the more important dimensions of the software:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 为 Kubernetes 集群的操作员提供了许多价值。让我们来看一下软件的一些重要维度：
- en: '**Simple to operate**: It was built to run as individual servers using local
    storage for reliability'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**操作简单**：它被设计为使用本地存储作为可靠性的独立服务器运行'
- en: '**It''s precise**: You can use a query language similar to JQL, DDL, DCL, or
    SQL queries to define alerts and provide a multi-dimensional view of status'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**它很精准**：你可以使用类似 JQL、DDL、DCL 或 SQL 查询的查询语言来定义告警，并提供多维度的状态视图'
- en: '**Lots of libraries**: You can use more than ten languages and numerous client
    libraries in order to introspect your services and software'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大量的库**：你可以使用十多种语言和众多客户端库来检查你的服务和软件'
- en: '**Efficient**: With data stored in an efficient, custom format both in memory
    and on disk, you can scale out easily with sharding and federation, creating a
    strong platform from which to issue powerful queries that can construct powerful
    data models and ad hoc tables, graphs, and alerts'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高效**：通过内存和磁盘上的高效自定义格式存储数据，你可以轻松通过分片和联合来进行扩展，创建一个强大的平台，从中发出强有力的查询，构建强大的数据模型、临时表格、图表和警报。'
- en: Also, Promethus is 100% open source and is (as of July 2018) currently an incubating
    project in the CNCF. You can install it with Helm as we did with other software,
    or do a manual installation as we'll detail here. Part of the reason that we're
    going to look at Prometheus today is due to the overall complexity of the Kubernetes
    system. With lots of moving parts, many servers, and potentially differing geographic
    regions, we need a system that can cope with all of that complexity.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Prometheus 是 100% 开源的，并且（截至 2018 年 7 月）目前是 CNCF 的一个孵化项目。你可以像安装其他软件一样使用 Helm
    安装它，或者按照我们将在这里详细介绍的手动安装方法进行安装。我们今天要讨论 Prometheus 的原因之一是由于 Kubernetes 系统的整体复杂性。由于有大量的活动组件、多个服务器以及可能的不同地理区域，我们需要一个能够应对所有这些复杂性的系统。
- en: A nice part about Prometheus is the pull nature, which allows you to focus on
    exposing metrics on your nodes as plain text via HTTP, which Prometheus can then
    pull back to a central monitoring and logging location. It's also written in Go
    and inspired by the closed source Borgmon system, which makes it a perfect match
    for our Kubernetes cluster. Let's get started with an install!
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 的一个好处是它的拉取机制，这使得你可以专注于通过 HTTP 将节点的度量标准作为纯文本暴露出来，Prometheus 然后可以将这些数据拉取到一个集中监控和日志记录的位置。它也是用
    Go 编写的，并受到封闭源 Borgmon 系统的启发，这使得它与我们的 Kubernetes 集群完美契合。让我们开始安装吧！
- en: Prometheus installation choices
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus 安装选项
- en: 'As with previous examples, we''ll need to either use our local Minikube install
    or the GCP cluster that we''ve spun up. Log in to your cluster of choice, and
    then let''s get Prometheus set up. There''s actually lots of options for installing
    Prometheus due to the fast moving nature of the software:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的例子一样，我们需要使用本地的 Minikube 安装或我们已经创建的 GCP 集群。登录到你选择的集群，然后让我们开始设置 Prometheus。由于软件的快速发展，实际上有很多安装
    Prometheus 的选择：
- en: The simplest, manual method; if you'd like to build the software from the getting
    started documents, you can jump in with [https://prometheus.io/docs/prometheus/latest/getting_started/](https://prometheus.io/docs/prometheus/latest/getting_started/)
    and get Prometheus monitoring itself.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最简单的手动方法；如果你想根据入门文档从头开始构建软件，你可以访问[https://prometheus.io/docs/prometheus/latest/getting_started/](https://prometheus.io/docs/prometheus/latest/getting_started/)并启动
    Prometheus 自身的监控。
- en: The middle ground, with Helm; if you'd like to take the middle road, you can
    install Prometheus on your cluster with Helm ([https://github.com/helm/charts/tree/master/stable/prometheus](https://github.com/helm/charts/tree/master/stable/prometheus)).
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中间道路，使用 Helm；如果你想采取中间路线，你可以通过 Helm 在你的集群上安装 Prometheus（[https://github.com/helm/charts/tree/master/stable/prometheus](https://github.com/helm/charts/tree/master/stable/prometheus)）。
- en: The advanced `Operator` method; if you want to use the latest and greatest,
    let's take a look at the Kubernetes `Operator` class of software, and use it to
    install Prometheus. The `Operator` was created by CoreOS, who have recently been
    acquired by Red Hat. That should mean interesting things for Project Atomic and
    Container Linux. We'll talk more about that later, however! We'll use the Operator
    model here.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级的 `Operator` 方法；如果你想使用最新最强的技术，让我们来看看 Kubernetes 的 `Operator` 软件类，并使用它来安装 Prometheus。`Operator`
    是由 CoreOS 创建的，CoreOS 最近被 Red Hat 收购了。这应该意味着 Project Atomic 和 Container Linux 会有一些有趣的变化。不过，我们稍后会详细讨论！我们在这里将使用
    Operator 模式。
- en: 'The Operator is designed to build upon the Helm-style management of software
    in order to build additional human operational knowledge into the installation,
    maintenance, and recovery of applications. You can think of the Operator software
    just like an SRE Operator: someone who''s an expert in running a piece of software.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: Operator 旨在构建在 Helm 风格的软件管理之上，目的是将额外的人类操作知识融入到应用程序的安装、维护和恢复中。你可以将 Operator 软件视为一个
    SRE Operator：一个在运行软件方面的专家。
- en: An Operator is an application-specific controller that extends the Kubernetes
    API in order to manage complex stateful applications such as caches, monitoring
    systems, and relational or non-relational databases. The Operator uses the API
    in order to create, configure, and manage these stateful systems on behalf of
    the user. While Deployments are excellent in dealing with seamless management
    of stateless web applications, the Deployment object in Kubernetes struggles to
    orchestrate all of the moving pieces in a stateful application when it comes to
    scaling, upgrading, recovering from failure, and reconfiguring these systems.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Operator是一个特定于应用的控制器，扩展了Kubernetes API，以便管理复杂的有状态应用，如缓存、监控系统和关系型或非关系型数据库。Operator利用API来创建、配置和管理这些有状态系统，代表用户执行操作。虽然Deployments在处理无状态Web应用的无缝管理方面非常出色，但Kubernetes中的Deployment对象在扩展、升级、故障恢复和重新配置这些有状态系统时，面临着协调所有移动部件的挑战。
- en: You can read more about extending the Kubernetes API here: [https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里阅读更多关于扩展Kubernetes API的内容：[https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/)。
- en: Operators leverage some core Kubernetes concepts that we've discussed in other
    chapters. Resources (ReplicaSets) and Controllers (for example Deployments, Services,
    and DaemonSets) are leverage with additional operational knowledge of the manual
    steps that are encoded in the Operator software. For example, when you scale up
    an etcd cluster manually, one of the key steps in the process is to create a DNS
    name for the new etcd member that can be used to route to the new member once
    it's been added to the cluster. With the Operator pattern being used, that systematized
    knowledge is built into the `Operator` class to provide the cluster administrator
    with seamless updates to the etcd software.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: Operator利用了我们在其他章节中讨论的一些Kubernetes核心概念。资源（如ReplicaSets）和控制器（例如Deployments、Services和DaemonSets）与编码在Operator软件中的手动操作步骤的附加操作知识一起使用。例如，当你手动扩展一个etcd集群时，过程中的关键步骤之一是为新的etcd成员创建一个DNS名称，这个名称可以在将其添加到集群后用来路由到新的成员。使用Operator模式时，这些系统化的知识被构建到`Operator`类中，为集群管理员提供对etcd软件的无缝更新。
- en: The difficulty in creating operators is understanding the underlying functionality
    of the stateful software in question, and then encoding that into a resource configuration
    and control loop. Keep in mind that Kubernetes can be thought of as simply being
    a large distributed messaging queue, with messages that exist in the form of a
    YAML blob of declarative state that the cluster operator defines, which the Kubernetes
    system puts into place.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 创建Operator的难点在于理解相关有状态软件的底层功能，并将其编码到资源配置和控制循环中。请记住，Kubernetes可以被看作是一个大型的分布式消息队列，消息以YAML格式的声明性状态存在，集群操作员定义这些状态，Kubernetes系统负责将其落实。
- en: Tips for creating an Operator
  id: totrans-226
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建Operator的提示
- en: If you want to create your own `Operator` in the future, you can keep the following
    tips from CoreOS in mind. Given the nature of their application-specific domain,
    you'll need to keep a few things in mind when managing complex applications. First,
    you'll have a set of system flow activities that your `Operator` should be able
    to perform. This will be actions such as creating a user, creating a database,
    modifying user permissions and passwords, and deleting users (such as the default
    user installed when creating many systems).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在未来创建自己的`Operator`，可以记住CoreOS提供的以下提示。鉴于它们的应用特定领域，在管理复杂应用时需要注意几点。首先，你会有一组系统流程活动，`Operator`应该能够执行这些操作。这些操作包括创建用户、创建数据库、修改用户权限和密码、删除用户（例如创建许多系统时默认安装的用户）。
- en: 'You''ll also need to manage your installation dependencies, which are the items
    that need to be present and configured for your system to work in the first place.
    CoreOS also recommends the following principles be followed when creating an `Operator`:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 你还需要管理你的安装依赖项，即那些在系统正常运行之前必须存在并配置的项。CoreOS还建议在创建`Operator`时遵循以下原则：
- en: '**Single step to deploy**: Make sure your `Operator` can be initialized and
    run with a single command that takes no additional work to get running.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署的单步操作**：确保你的`Operator`可以通过一个不需要额外操作的命令来初始化并运行。'
- en: '**New third-party type**: Your `Operator` should leverage the third-party API
    types, which users will take advantage of when creating applications that use
    your software.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新的第三方类型**：你的`Operator`应该利用第三方API类型，用户在创建使用你软件的应用程序时会使用这些类型。'
- en: '**Use the basics**: Make sure that your `Operator` uses the core Kubernetes
    objects such as ReplicaSets, Services, and StatefulSets, in order to leverage
    all of the hard work being poured into the open source Kubernetes project.'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用基础功能**：确保你的`Operator`使用核心的Kubernetes对象，如ReplicaSets、Services和StatefulSets，以便充分利用Kubernetes开源项目中所投入的大量工作。'
- en: '**Compatible and default working**: Make sure you build your `Operators` so
    that they exist in harmony with older versions, and design your system so that
    it still continues to run unaffected if the `Operator` is stopped or accidentally
    deleted from your cluster.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**兼容且默认工作**：确保你构建的`Operators`与旧版本兼容，并设计你的系统，使得即使`Operator`被停止或意外从集群中删除，系统仍能继续运行且不受影响。'
- en: '**Version**: Make sure to facilitate the ability to version instances of your
    `Operator`, so cluster administrators don''t shy away from updating your software.'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**版本**：确保你的`Operator`支持版本控制，以便集群管理员不会回避更新你的软件。'
- en: '**Test**: Also, make sure to test your `Operator` against a destructive force
    such as a Chaos Monkey! Your `Operator` should be able to survive the failure
    of nodes, pods, storage, configuration, and networking outages.'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**测试**：同样，确保将`Operator`进行抗破坏性测试，例如使用混沌猴（Chaos Monkey）进行测试！你的`Operator`应该能够承受节点、pods、存储、配置和网络故障的影响。'
- en: Installing Prometheus
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安装Prometheus
- en: Let's run through an install of Prometheus using the new pattern that we've
    discovered. First, let's use the Prometheus definition file to create the deployment.
    We'll use Helm here to install the Operator!
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过我们发现的新模式来安装Prometheus。首先，使用Prometheus定义文件来创建部署。我们将在这里使用Helm来安装Operator！
- en: 'Make sure you have Helm installed, and then make sure you''ve initialized it:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你已经安装了Helm，并确保你已经初始化了它：
- en: '[PRE8]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Next, we can install the various `Operator` packages required for this demo:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以安装此演示所需的各种`Operator`包：
- en: '[PRE9]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, install the `Operator`:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，安装`Operator`：
- en: '[PRE10]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can see that it''s installed and running by first checking the installation:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以先检查安装情况来确认它已经安装并在运行：
- en: '[PRE11]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Then, look at the pods:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，查看pods：
- en: '[PRE12]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, we can install `kube-prometheus` to get all of our dependencies up and
    running:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以安装`kube-prometheus`，让所有依赖项开始运行：
- en: '[PRE13]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'We''ve truncated the output here as there''s a lot of information. Let''s look
    at the pods again:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在这里截断了输出，因为有大量信息。让我们再次查看pods：
- en: '[PRE14]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Nicely done!
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 干得不错！
- en: If you forward the port for `prometheus-kube-prometheus-0` to `8448`, you should
    be able to see the Prometheus dashboard, which we'll revisit in later chapters
    as we explore high availability and the productionalization of your Kubernetes
    cluster. You can check this out at `http://localhost:8449/alerts`.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将`prometheus-kube-prometheus-0`的端口转发到`8448`，你应该能够看到Prometheus仪表板，我们将在后续章节中重新访问它，探索Kubernetes集群的高可用性和生产化。你可以通过`http://localhost:8449/alerts`查看。
- en: Summary
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: We took a quick look at monitoring and logging with Kubernetes. You should now
    be familiar with how Kubernetes uses cAdvisor and Heapster to collect metrics
    on all the resources in a given cluster. Furthermore, we saw how Kubernetes saves
    us time by providing InfluxDB and Grafana set up and configured out of the box.
    Dashboards are easily customizable for our everyday operational needs.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简要了解了Kubernetes的监控和日志记录。你现在应该熟悉Kubernetes如何使用cAdvisor和Heapster收集集群中所有资源的指标。此外，我们看到Kubernetes通过提供预配置好的InfluxDB和Grafana，帮助我们节省了时间。仪表板可以根据我们的日常操作需求轻松定制。
- en: In addition, we looked at the built-in logging capabilities with FluentD and
    the Google Cloud Logging service. Also, Kubernetes gives us great time savings
    by setting up the basics for us.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还了解了使用FluentD和Google Cloud Logging服务的内置日志记录功能。另外，Kubernetes通过为我们设置基本配置，节省了大量时间。
- en: Finally, you learned about the various third-party options available to monitor
    our containers and clusters. Using these tools will allow us to gain even more
    insight into the health and status of our applications. All these tools combine
    to give us a solid toolset to manage day-to-day operations. Lastly, we explored
    different methods of installing Prometheus, with an eye on building more robust
    production systems.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你了解了各种可用于监控容器和集群的第三方选项。使用这些工具将帮助我们更深入地了解应用程序的健康状况和状态。所有这些工具结合在一起，提供了一个强大的工具集来管理日常操作。最后，我们探讨了不同的
    Prometheus 安装方法，旨在构建更强大的生产系统。
- en: In the next chapter, we will explore the new cluster federation capabilities.
    Still mostly in beta, this functionality will allow us to run multiple clusters
    in different data centers and even clouds, but manage and distribute applications
    from a single control plane.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将探讨新的集群联邦功能。尽管仍然处于测试阶段，但这一功能将允许我们在不同的数据中心甚至云中运行多个集群，同时从单一控制平面管理和分发应用程序。
- en: Questions
  id: totrans-258
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Name two of the built-in monitoring tools for Kubernetes
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 列出 Kubernetes 内置的两种监控工具
- en: What namespace do the built-in monitoring tools run in?
  id: totrans-260
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 内置监控工具运行在哪个命名空间？
- en: What graphing software is used by most of the monitoring tools?
  id: totrans-261
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 大多数监控工具使用的图表软件是什么？
- en: What is FluentD referred to as?
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: FluentD 被称为什么？
- en: What's Google's native monitoring system?
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Google 的原生监控系统是什么？
- en: What are two good reasons to use Prometheus?
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Prometheus 的两个好理由是什么？
- en: Further reading
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: If you'd like to read more about the Kubernetes Operator Framework, check out
    this blog post: [https://coreos.com/blog/introducing-operator-framework](https://coreos.com/blog/introducing-operator-framework).
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于 Kubernetes 操作符框架的内容，请查看这篇博客文章：[https://coreos.com/blog/introducing-operator-framework](https://coreos.com/blog/introducing-operator-framework)。
- en: If you'd like to check out a video on Kubernetes monitoring from Packt, see
    this video: [https://www.packtpub.com/mapt/video/virtualization_and_cloud/9781789130003/65553/65558/monitoring-your-infrastructure](https://www.packtpub.com/mapt/video/virtualization_and_cloud/9781789130003/65553/65558/monitoring-your-infrastructure).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看一段关于 Kubernetes 监控的视频，请访问这个视频：[https://www.packtpub.com/mapt/video/virtualization_and_cloud/9781789130003/65553/65558/monitoring-your-infrastructure](https://www.packtpub.com/mapt/video/virtualization_and_cloud/9781789130003/65553/65558/monitoring-your-infrastructure)。
