- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Using Kubernetes Resources in Practice
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在实践中使用 Kubernetes 资源
- en: In this chapter, we will design a fictional massive-scale platform that will
    challenge Kubernetes’ capabilities and scalability. The Hue platform is all about
    creating an omniscient and omnipotent digital assistant. Hue is a digital extension
    of you. Hue will help you do anything, find anything, and, in many cases, will
    do a lot on your behalf. It will obviously need to store a lot of information,
    integrate with many external services, respond to notifications and events, and
    be smart about interacting with you.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将设计一个虚构的大规模平台，挑战 Kubernetes 的能力和可扩展性。Hue 平台旨在创造一个全知全能的数字助手。Hue 是你的数字延伸。Hue
    会帮助你做任何事情，找到任何东西，并且在许多情况下，会代表你做很多事情。显然，它需要存储大量信息，集成许多外部服务，响应通知和事件，并在与你互动时非常智能。
- en: We will take the opportunity in this chapter to get to know kubectl and related
    tools a little better and explore in detail familiar resources we’ve seen before,
    such as pods, as well as new resources, such as jobs. We will explore advanced
    scheduling and resource management.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将借此机会让我们更好地了解 kubectl 及相关工具，深入探讨我们之前见过的熟悉资源（如 Pods），以及一些新资源（如 Jobs）。我们将探讨高级调度和资源管理。
- en: 'This chapter will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涉及以下主题：
- en: Designing the Hue platform
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计 Hue 平台
- en: Using Kubernetes to build the Hue platform
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 构建 Hue 平台
- en: Separating internal and external services
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分离内部和外部服务
- en: Advanced scheduling
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级调度
- en: Using namespaces to limit access
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用命名空间限制访问
- en: Using Kustomization for hierarchical cluster structures
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Kustomization 构建层次化集群结构
- en: Launching jobs
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动任务
- en: Mixing non-cluster components
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 混合非集群组件
- en: Managing the Hue platform with Kubernetes
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 管理 Hue 平台
- en: Evolving the Hue platform with Kubernetes
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 发展 Hue 平台
- en: Just to be clear, this is a design exercise! We are not actually going to build
    the Hue platform. The motivation behind this exercise is to showcase the vast
    range of capabilities available with Kubernetes in the context of a large system
    with multiple moving parts.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 为了明确，这只是一个设计练习！我们并不打算真正构建 Hue 平台。这个练习的目的是展示 Kubernetes 在大规模系统中，处理多个活动部分时所能提供的广泛功能。
- en: At the end of this chapter, you will have a clear picture of how impressive
    Kubernetes is and how it can be used as the foundation for hugely complex systems.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，你将清楚地看到 Kubernetes 的强大，并了解它如何作为构建复杂系统的基础。
- en: Designing the Hue platform
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设计 Hue 平台
- en: In this section, we will set the stage and define the scope of the amazing Hue
    platform. Hue is not Big Brother; Hue is Little Brother! Hue will do whatever
    you allow it to do. Hue will be able to do a lot, which might concern some people,
    but you get to pick how much or how little Hue can help you with. Get ready for
    a wild ride!
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将为令人惊叹的 Hue 平台奠定基础，并定义其范围。Hue 不是“大哥”；Hue 是“小弟”！Hue 会做你允许它做的任何事情。Hue 能做很多事，这可能会让一些人感到担忧，但你可以选择让
    Hue 帮助你多少。准备好迎接一场疯狂的旅程吧！
- en: Defining the scope of Hue
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义 Hue 的范围
- en: 'Hue will manage your digital persona. It will know you better than you know
    yourself. Here is a list of some of the services Hue can manage and help you with:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: Hue 将管理你的数字身份。它会比你更了解你自己。以下是 Hue 可以管理和帮助你的部分服务列表：
- en: Search and content aggregation
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 搜索和内容聚合
- en: Medical – electronic heath records, DNA sequencing
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 医疗 – 电子健康记录，DNA 测序
- en: Smart homes
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 智能家居
- en: Finance – banking, savings, retirement, investing
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 财务 – 银行业务，储蓄，退休，投资
- en: Office
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 办公室
- en: Social
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社交
- en: Travel
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 旅行
- en: Wellbeing
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 健康
- en: Family
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 家庭
- en: Let’s look at some of the capabilities of the Hue platform, such as smart reminders
    and notifications, security, identity, and privacy.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看 Hue 平台的一些功能，例如智能提醒和通知、安全、身份和隐私。
- en: Smart reminders and notifications
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 智能提醒和通知
- en: Let’s think of the possibilities. Hue will know you, but also know your friends
    and the aggregate of other users across all domains. Hue will update its models
    in real time. It will not be confused by stale data. It will act on your behalf,
    present relevant information, and learn your preferences continuously. It can
    recommend new shows or books that you may like, make restaurant reservations based
    on your schedule and that of your family or friends, and control your house’s
    automation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们想象一下各种可能性。Hue 会了解你，也了解你的朋友，以及所有领域中其他用户的集合。Hue 会实时更新其模型。它不会被过时的数据所困扰。它会代表你行动，呈现相关信息，并不断学习你的偏好。它可以推荐你可能喜欢的新节目或书籍，根据你和你家人或朋友的日程安排预订餐厅，甚至控制你家的自动化系统。
- en: Security, identity, and privacy
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安全性、身份和隐私
- en: 'Hue is your proxy online. The ramifications of someone stealing your Hue identity,
    or even just eavesdropping on your Hue interactions, are devastating. Potential
    users may even be reluctant to trust the Hue organization with their identity.
    Let’s devise a non-trust system where users have the power to pull the plug on
    Hue at any time. Here are a few ideas:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Hue 是你的在线代理。有人窃取你的 Hue 身份，甚至只是窃听你与 Hue 的互动，将带来灾难性后果。潜在用户可能甚至不愿意将他们的身份交给 Hue
    组织。让我们设计一个无信任系统，使用户随时拥有切断 Hue 的权力。以下是一些想法：
- en: Strong identity via a dedicated device with multi-factor authorization, including
    multiple biometric factors
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过专用设备实现强身份验证，采用多因素授权，包括多个生物识别因素
- en: Frequently rotating credentials
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期更换凭证
- en: Quick service pause and identity verification of all external services (will
    require original proof of identity for each provider)
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 快速暂停服务并验证所有外部服务的身份（将要求每个服务提供商提供原始身份凭证）
- en: The Hue backend will interact with all external services via short-lived tokens
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hue 后端将通过短生命周期令牌与所有外部服务进行交互
- en: Architecting Hue as a collection of loosely coupled microservices with strong
    compartmentalization
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Hue 架构设计为松耦合微服务的集合，并确保强大的隔离性
- en: GDPR compliance
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GDPR 合规性
- en: End-to-end encryption
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端到端加密
- en: Avoid owning critical data (let external providers manage it)
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 避免拥有关键数据（让外部服务提供商来管理）
- en: Hue’s architecture will need to support enormous variation and flexibility.
    It will also need to be very extensible where existing capabilities and external
    services are constantly upgraded, and new capabilities and external services are
    integrated into the platform. That level of scale calls for microservices, where
    each capability or service is totally independent of other services except for
    well-defined interfaces via standard and/or discoverable APIs.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: Hue 的架构需要支持巨大的变化和灵活性。它还需要非常具有扩展性，因为现有功能和外部服务会不断升级，新的功能和外部服务也会不断集成到平台中。这种规模要求使用微服务架构，每个功能或服务都与其他服务完全独立，除非通过标准和/或可发现的
    API 定义了良好的接口。
- en: Hue components
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hue 组件
- en: Before embarking on our microservice journey, let’s review the types of components
    we need to construct for Hue.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始我们的微服务之旅之前，让我们回顾一下我们需要为 Hue 构建的组件类型。
- en: User profile
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用户档案
- en: The user profile is a major component, with lots of sub-components. It is the
    essence of the user, their preferences, their history across every area, and everything
    that Hue knows about them. The benefit you can get from Hue is affected strongly
    by the richness of the profile. But the more information is managed by the profile,
    the more damage you can suffer if the data (or part of it) is compromised.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 用户档案是一个主要组件，包含许多子组件。它代表用户的本质、他们的偏好、他们在各个领域的历史记录，以及 Hue 所知道的所有信息。你能从 Hue 获取的收益在很大程度上取决于档案的丰富程度。但档案管理的信息越多，若数据（或部分数据）被泄露，将带来越大的损害。
- en: A big piece of managing the user profile is the reports and insights that Hue
    will provide to the user. Hue will employ sophisticated machine learning to better
    understand the user and their interactions with other users and external service
    providers.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 管理用户档案的一个重要部分是 Hue 为用户提供的报告和洞察。Hue 将采用先进的机器学习技术，更好地了解用户及其与其他用户和外部服务提供商的互动。
- en: User graph
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用户图谱
- en: 'The user graph component models networks of interactions between users across
    multiple domains. Each user participates in multiple networks: social networks
    such as Facebook, Instagram, and Twitter; professional networks; hobby networks;
    and volunteer communities. Some of these networks are ad hoc and Hue will be able
    to structure them to benefit users. Hue can take advantage of the rich profiles
    it has of user connections to improve interactions even without exposing private
    information.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 用户图组件建模了跨多个领域用户之间的交互网络。每个用户都参与多个网络：如 Facebook、Instagram 和 Twitter 等社交网络；专业网络；兴趣爱好网络；以及志愿者社区。这些网络中的一些是临时性的，Hue
    将能够结构化它们以造福用户。即使不暴露私密信息，Hue 也能利用其对用户连接的丰富资料来改善交互。
- en: Identity
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 身份
- en: Identity management is critical, as mentioned previously, so it merits a separate
    component. A user may prefer to manage multiple mutually exclusive profiles with
    separate identities. For example, maybe users are not comfortable with mixing
    their health profile with their social profile at the risk of inadvertently exposing
    personal health information to their friends. While Hue can find useful connections
    for you, you may prefer to trade off capabilities for more privacy.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，身份管理至关重要，因此需要一个单独的组件。用户可能希望管理多个相互排斥的个人档案，并拥有不同的身份。例如，用户可能不愿将自己的健康档案与社交档案混合，担心无意间将个人健康信息暴露给朋友。虽然
    Hue 可以为你找到有用的连接，但你可能更倾向于在更多隐私和更高能力之间做出权衡。
- en: Authorizer
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 授权器
- en: The authorizer is a critical component where the user explicitly authorizes
    Hue to perform certain actions or collect various data on their behalf. This involves
    access to physical devices, accounts of external services, and levels of initiative.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 授权器是一个关键组件，用户明确授权 Hue 执行某些操作或代表其收集各种数据。这涉及到访问物理设备、外部服务账户和操作权限等方面。
- en: External services
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 外部服务
- en: Hue is an aggregator of external services. It is not designed to replace your
    bank, your health provider, or your social network. It will keep a lot of metadata
    about your activities, but the content will remain with your external services.
    Each external service will require a dedicated component to interact with the
    external service API and policies. When no API is available, Hue emulates the
    user by automating the browser or native apps.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Hue 是外部服务的聚合器。它并不是用来替代你的银行、健康服务提供者或社交网络的。它将保留大量关于你活动的元数据，但内容仍将保留在外部服务中。每个外部服务都需要一个专门的组件来与外部服务
    API 和政策进行交互。当没有可用 API 时，Hue 会通过自动化浏览器或本地应用程序来模拟用户行为。
- en: Generic sensor
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通用传感器
- en: A big part of Hue’s value proposition is to act on the user’s behalf. In order
    to do that effectively, Hue needs to be aware of various events. For example,
    if Hue reserved a vacation for you but it senses that a cheaper flight is available,
    it can either automatically change your flight or ask you for confirmation. There
    is an infinite number of things to sense. To reign in sensing, a generic sensor
    is needed. The generic sensor will be extensible but exposes a generic interface
    that the other parts of Hue can utilize uniformly even as more and more sensors
    are added.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Hue 的一个重要价值 proposition 是代表用户执行操作。为了有效执行此操作，Hue 需要了解各种事件。例如，如果 Hue 为你预订了假期，但它检测到有更便宜的航班，它可以自动更改你的航班或要求你确认。有无数的事件需要感知。为了控制感知范围，需要一个通用传感器。通用传感器将是可扩展的，但它暴露出一个通用接口，其他
    Hue 组件即使在添加更多传感器时，也可以统一使用该接口。
- en: Generic actuator
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通用执行器
- en: This is the counterpart of the generic sensor. Hue needs to perform actions
    on your behalf; for example, reserving a flight or a doctor’s appointment. To
    do that, Hue needs a generic actuator that can be extended to support particular
    functions but can interact with other components, such as the identity manager
    and the authorizer, in a uniform fashion.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是通用传感器的对应组件。Hue 需要代表你执行某些操作；例如，预订航班或预约医生。为了做到这一点，Hue 需要一个通用执行器，该执行器可以扩展以支持特定功能，但能以统一的方式与其他组件（如身份管理器和授权器）进行交互。
- en: User learner
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用户学习者
- en: This is the brain of Hue. It will constantly monitor all your interactions (that
    you authorize) and update its model of you and other users in your networks. This
    will allow Hue to become more and more useful over time, predict what you need
    and what will interest you, provide better choices, surface more relevant information
    at the right time, and avoid being annoying and overbearing.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Hue 的大脑。它将持续监控你所有授权的互动，并更新其对你和你网络中其他用户的模型。这将使 Hue 随着时间的推移变得越来越有用，能够预测你的需求和兴趣，提供更好的选择，在合适的时间展示更相关的信息，避免令人烦恼和过于强势。
- en: Hue microservices
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Hue 微服务
- en: The complexity of each of the components is enormous. Some of the components,
    such as the external service, the generic sensor, and the generic actuator, will
    need to operate across hundreds, thousands, or even more external services that
    constantly change outside the control of Hue. Even the user learner needs to learn
    the user’s preferences across many areas and domains. Microservices address this
    need by allowing Hue to evolve gradually and grow more isolated capabilities without
    collapsing under its own complexity. Each microservice interacts with generic
    Hue infrastructure services through standard interfaces and, optionally, with
    a few other services through well-defined and versioned interfaces. The surface
    area of each microservice is manageable and the orchestration between microservices
    is based on standard best practices.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 每个组件的复杂性都非常庞大。一些组件，比如外部服务、通用传感器和通用执行器，将需要跨越数百、数千甚至更多的外部服务，这些服务会不断变化，超出 Hue 的控制范围。即使是用户学习系统，也需要在多个领域和范畴中学习用户的偏好。微服务通过允许
    Hue 渐进式发展并在不因其自身复杂性而崩溃的情况下，增长出更多独立的功能来解决这一需求。每个微服务通过标准接口与通用的 Hue 基础设施服务进行交互，并且可以通过明确定义且版本化的接口与少数其他服务进行交互。每个微服务的表面面积是可管理的，微服务之间的编排遵循标准的最佳实践。
- en: Plugins
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 插件
- en: Plugins are the key to extending Hue without a proliferation of interfaces.
    The thing about plugins is that often, you need plugin chains that cross multiple
    abstraction layers. For example, if you want to add a new integration for Hue
    with YouTube, then you can collect a lot of YouTube-specific information – your
    channels, favorite videos, recommendations, and videos you have watched. To display
    this information to users and allow them to act on it, you need plugins across
    multiple components and, eventually, in the user interface as well. Smart design
    will help by aggregating categories of actions such as recommendations, selections,
    and delayed notifications to many services.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 插件是扩展 Hue 的关键，而无需大量界面。关于插件的一个特点是，你通常需要跨越多个抽象层的插件链。例如，如果你想为 Hue 添加 YouTube 集成功能，那么你可以收集大量特定于
    YouTube 的信息——你的频道、收藏的视频、推荐内容以及你观看过的视频。为了向用户展示这些信息并允许他们进行操作，你需要跨多个组件的插件，并最终出现在用户界面中。智能设计将通过汇总推荐、选择和延迟通知等行为类别，来帮助许多服务进行聚合。
- en: The great thing about plugins is that they can be developed by anyone. Initially,
    the Hue development team will have to develop the plugins, but as Hue becomes
    more popular, external services will want to integrate with Hue and build Hue
    plugins to enable their service. That will lead, of course, to a whole ecosystem
    of plugin registration, approval, and curation.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 插件的一个重要优点是它们可以由任何人开发。最初，Hue 开发团队将需要开发这些插件，但随着 Hue 的流行，外部服务将希望与 Hue 集成并构建 Hue
    插件以启用他们的服务。当然，这将导致一个完整的插件注册、审批和管理生态系统。
- en: Data stores
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据存储
- en: 'Hue will need several types of data stores, and multiple instances of each
    type, to manage its data and metadata:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Hue 将需要几种类型的数据存储，每种类型还需要多个实例，以管理其数据和元数据：
- en: Relational database
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关系型数据库
- en: Graph database
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图形数据库
- en: Time-series database
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时序数据库
- en: In-memory caching
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存缓存
- en: Blob storage
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blob 存储
- en: Due to the scope of Hue, each one of these databases will have to be clustered,
    scalable, and distributed. In addition, Hue will use local storage on edge devices.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Hue 的规模，每个数据库都必须进行集群化、可扩展性和分布式处理。此外，Hue 还将使用边缘设备上的本地存储。
- en: Stateless microservices
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无状态微服务
- en: The microservices should be mostly stateless. This will allow specific instances
    to be started and killed quickly and migrated across the infrastructure as necessary.
    The state will be managed by the stores and accessed by the microservices with
    short-lived access tokens. Hue will store frequently accessed data in easily hydrated
    fast caches when appropriate.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务应该大多是无状态的。这将允许特定实例快速启动和终止，并根据需要在基础设施中迁移。状态将由存储管理，微服务通过短期访问令牌访问这些状态。Hue 将在适当的时候将频繁访问的数据存储在易于加速的缓存中。
- en: Serverless functions
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无服务器函数
- en: A big part of Hue’s functionality per user will involve relatively short interactions
    with external services or other Hue services. For those activities, it may not
    be necessary to run a full-fledged persistent microservice that needs to be scaled
    and managed. A more appropriate solution may be to use a serverless function that
    is more lightweight.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 每个用户的 Hue 功能的大部分将涉及与外部服务或其他 Hue 服务的相对较短的交互。对于这些活动，可能无需运行一个完整的持久性微服务，也不需要扩展和管理它。更合适的解决方案可能是使用更轻量的无服务器函数。
- en: Event-driven interactions
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事件驱动交互
- en: All these microservices need to talk to each other. Users will ask Hue to perform
    tasks on their behalf. External services will notify Hue of various events. Queues
    coupled with stateless microservices provide the perfect solution.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些微服务需要相互通信。用户将请求 Hue 代表他们执行任务。外部服务将通知 Hue 各种事件。队列与无状态微服务的结合提供了完美的解决方案。
- en: Multiple instances of each microservice will listen to various queues and respond
    when relevant events or requests are popped from the queue. Serverless functions
    may be triggered as a result of particular events too. This arrangement is very
    robust and easy to scale. Every component can be redundant and highly available.
    While each component is fallible, the system is very fault-tolerant.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 每个微服务的多个实例将监听不同的队列，并在相关事件或请求从队列中弹出时作出响应。特定事件也可能触发无服务器函数。这种安排非常健壮且易于扩展。每个组件都可以是冗余的并且具有高可用性。虽然每个组件都有可能发生故障，但系统本身非常容错。
- en: A queue can be used for asynchronous RPC or request-response style interactions
    too, where the calling instance provides a private queue name and the response
    is posted to the private queue.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 队列也可以用于异步的 RPC 或请求-响应风格的交互，其中调用实例提供一个私有队列名，响应将被发布到该私有队列。
- en: That said, sometimes direct service-to-service interaction (or serverless function-to-service
    interaction) through a well-defined interface makes more sense and simplifies
    the architecture.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 也就是说，有时候通过一个明确界定的接口进行直接的服务对服务交互（或无服务器函数对服务交互）更为合适，并能简化架构。
- en: Planning workflows
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 规划工作流
- en: Hue often needs to support workflows. A typical workflow will take a high-level
    task, such as making a dentist appointment. It will extract the user’s dentist’s
    details and schedule, match it with the user’s schedule, choose between multiple
    options, potentially confirm with the user, make the appointment, and set up a
    reminder. We can classify workflows into fully automatic workflows and human workflows
    where humans are involved. Then there are workflows that involve spending money
    and might require an additional level of approval.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Hue 经常需要支持工作流。一个典型的工作流会处理一个高层次的任务，比如预约看牙医。它会提取用户的牙医信息和日程安排，匹配用户的日程，选择多个选项中的一个，可能需要与用户确认，完成预约并设置提醒。我们可以将工作流分为完全自动化工作流和涉及人类的人工工作流。还有一些工作流涉及花费金钱，可能需要额外的审批层级。
- en: Automatic workflows
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动化工作流
- en: Automatic workflows don’t require human intervention. Hue has full authority
    to execute all the steps from start to finish. The more autonomy the user allocates
    to Hue, the more effective it will be. The user will be able to view and audit
    all workflows, past and present.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化工作流无需人工干预。Hue 具有从头到尾执行所有步骤的完全权限。用户分配给 Hue 的自主权越大，Hue 的效果就越好。用户将能够查看并审计所有的工作流，无论是过去的还是当前的。
- en: Human workflows
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工工作流
- en: Human workflows require interaction with a human. Most often it will be the
    user that needs to make a choice from multiple options or approve an action. But
    it may involve a person on another service. For example, to make an appointment
    with a dentist, Hue may have to get a list of available times from the secretary.
    In the future, Hue will be able to handle conversations with humans and possibly
    automate some of these workflows too.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 人类工作流需要与人类互动。最常见的是用户需要从多个选项中做出选择或批准某个操作。但它也可能涉及其他服务中的人。例如，要与牙医预约，Hue 可能需要从秘书那里获取可用时间列表。在未来，Hue
    将能够处理与人类的对话，并可能自动化一些这些工作流。
- en: Budget-aware workflows
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 预算感知工作流
- en: Some workflows, such as paying bills or purchasing a gift, require spending
    money. While, in theory, Hue can be granted unlimited access to the user’s bank
    account, most users will probably be more comfortable setting budgets for different
    workflows or just making spending a human-approved activity. Potentially, the
    user could grant Hue access to a dedicated account or set of accounts and, based
    on reminders and reports, allocate more or fewer funds to Hue as needed.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一些工作流，如支付账单或购买礼物，涉及花费金钱。虽然理论上可以给 Hue 授权访问用户的银行账户，但大多数用户可能会更愿意为不同的工作流设置预算，或者仅将支出作为一个人类批准的活动。用户可能会授予
    Hue 访问一个专用账户或一组账户的权限，并根据提醒和报告，按需为 Hue 分配更多或更少的资金。
- en: At this point, we have covered a lot of ground and looked at the different components
    that comprise the Hue platform and its design. Now is a good time to see how Kubernetes
    can help with building a platform like Hue.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经覆盖了很多内容，查看了构成 Hue 平台及其设计的不同组件。现在是时候看看 Kubernetes 如何帮助构建像 Hue 这样的平台了。
- en: Using Kubernetes to build the Hue platform
  id: totrans-94
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 构建 Hue 平台
- en: 'In this section, we will look at various Kubernetes resources and how they
    can help us build Hue. First, we’ll get to know the versatile kubectl a little
    better, then we will look at how to run long-running processes in Kubernetes,
    exposing services internally and externally, using namespaces to limit access,
    launching ad hoc jobs, and mixing in non-cluster components. Obviously, Hue is
    a huge project, so we will demonstrate the ideas on a local cluster and not actually
    build a real Hue Kubernetes cluster. Consider it primarily a thought experiment.
    If you wish to explore building a real microservice-based distributed system on
    Kubernetes, check out *Hands-On Microservices with Kubernetes*: [https://www.packtpub.com/product/hands-on-microservices-with-kubernetes/9781789805468](https://www.packtpub.com/product/hands-on-microservices-with-kubernetes/9781789805468).'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将查看各种 Kubernetes 资源以及它们如何帮助我们构建 Hue。首先，我们将更好地了解多功能的 kubectl，然后我们将了解如何在
    Kubernetes 中运行长时间运行的进程，如何内部和外部暴露服务，如何使用命名空间限制访问，如何启动临时作业，以及如何混合非集群组件。显然，Hue 是一个庞大的项目，因此我们将在本地集群上演示这些想法，而不实际构建一个真正的
    Hue Kubernetes 集群。将其视为一种思维实验。如果你希望探索如何在 Kubernetes 上构建一个真正的微服务分布式系统，可以查看 *Hands-On
    Microservices with Kubernetes*：[https://www.packtpub.com/product/hands-on-microservices-with-kubernetes/9781789805468](https://www.packtpub.com/product/hands-on-microservices-with-kubernetes/9781789805468)。
- en: Using kubectl effectively
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高效使用 kubectl
- en: 'kubectl is your Swiss Army knife. It can do pretty much anything around a cluster.
    Under the hood, kubectl connects to your cluster via the API. It reads your `~/.kube/config`
    file (by default, this can be overridden with the `KUBECONFIG` environment variable
    or the `--kubeconfig` command-line argument), which contains the information necessary
    to connect to your cluster or clusters. The commands are divided into multiple
    categories:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: kubectl 是你的瑞士军刀。它几乎可以完成集群中的任何任务。在后台，kubectl 通过 API 连接到你的集群。它读取你的 `~/.kube/config`
    文件（默认情况下，这可以通过 `KUBECONFIG` 环境变量或 `--kubeconfig` 命令行参数来覆盖），该文件包含连接到你的集群或多个集群所需的信息。命令被分为多个类别：
- en: '**Generic commands**: Deal with resources in a generic way: `create`, `get`,
    `delete`, `run`, `apply`, `patch`, `replace`, and so on'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通用命令**：以通用方式处理资源：`create`、`get`、`delete`、`run`、`apply`、`patch`、`replace`
    等'
- en: '**Cluster management commands**: Deal with nodes and the cluster at large:
    `cluster-info`, `certificate`, `drain`, and so on'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群管理命令**：处理节点和整个集群的任务：`cluster-info`、`certificate`、`drain` 等'
- en: '**Troubleshooting commands**: `describe`, `logs`, `attach`, `exec`, and so
    on'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**故障排除命令**：`describe`、`logs`、`attach`、`exec` 等'
- en: '**Deployment commands**: Deal with deployment and scaling: `rollout`, `scale`,
    `auto-scale`, and so on'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署命令**：处理部署和扩展的任务：`rollout`、`scale`、`auto-scale` 等'
- en: '**Settings commands**: Deal with labels and annotations: `label`, `annotate`,
    and so on'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**设置命令**: 处理标签和注释：`label`、`annotate` 等'
- en: '**Misc commands**: `help`, `config`, and `version`'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**杂项命令**: `help`、`config` 和 `version`'
- en: '**Customization commands**: Integrate the kustomize.io capabilities into kubectl'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自定义命令**: 将 kustomize.io 的功能集成到 kubectl 中'
- en: '**Configuration commands:** Deal with contexts, switch between clusters and
    namespaces, set current context and namespace, and so on'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**配置命令**: 处理上下文，切换集群和命名空间，设置当前上下文和命名空间，等等'
- en: You can view the configuration with Kubernetes’ `config view` command.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 Kubernetes 的 `config view` 命令查看配置。
- en: 'Here is the configuration for my local KinD cluster:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我本地 KinD 集群的配置：
- en: '[PRE0]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Your `kubeconfig` file may or may not be similar to the code sample above, but
    as long as it points to a running Kubernetes cluster, you will be able to follow
    along. Let’s take an in-depth look into the kubectl manifest files.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 `kubeconfig` 文件可能与上面的代码示例相似，也可能不同，只要它指向一个正在运行的 Kubernetes 集群，你就可以跟随学习。让我们深入了解
    kubectl 清单文件。
- en: Understanding kubectl manifest files
  id: totrans-110
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 kubectl 清单文件
- en: 'Many kubectl operations, such as `create`, require a complicated hierarchical
    structure (since the API requires this structure). kubectl uses YAML or JSON manifest
    files. YAML is more concise and human-readable so we will use YAML mostly. Here
    is a YAML manifest file for creating a pod:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 许多 kubectl 操作，例如 `create`，需要一个复杂的层级结构（因为 API 要求此结构）。kubectl 使用 YAML 或 JSON 清单文件。YAML
    更简洁且易于人类阅读，所以我们大多使用 YAML。下面是一个用于创建 pod 的 YAML 清单文件：
- en: '[PRE1]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Let’s examine the various fields of the manifest.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看清单中的各个字段。
- en: apiVersion
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: apiVersion
- en: The very important Kubernetes API keeps evolving and can support different versions
    of the same resource via different versions of the API.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 非常重要的 Kubernetes API 持续发展，可以通过不同版本的 API 支持同一资源的不同版本。
- en: kind
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: kind
- en: '`kind` tells Kubernetes what type of resource it is dealing with; in this case,
    `Pod`. This is always required.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`kind` 告诉 Kubernetes 它正在处理的资源类型；在这种情况下是 `Pod`。这是必需的。'
- en: metadata
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: metadata
- en: '`metadata` contains a lot of information that describes the pod and where it
    operates:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '`metadata` 包含了描述 pod 及其操作位置的大量信息：'
- en: '`name`: Identifies the pod uniquely within its namespace'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`name`: 在命名空间中唯一标识 pod'
- en: '`labels`: Multiple labels can be applied'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`: 可以应用多个标签'
- en: '`namespace`: The namespace the pod belongs to'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`namespace`: pod 所属的命名空间'
- en: '`annotations`: A list of annotations available for query'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`annotations`: 可查询的注释列表'
- en: spec
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: spec
- en: '`spec` is a pod template that contains all the information necessary to launch
    a pod. It can be quite elaborate, so we’ll explore it in multiple parts:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`spec` 是一个 pod 模板，包含启动 pod 所需的所有信息。它可能相当复杂，因此我们将分多个部分来探讨：'
- en: '[PRE2]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Container spec
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 容器规格
- en: 'The pod spec’s `containers` section is a list of container specs. Each container
    spec has the following structure:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: pod spec 的 `containers` 部分是一个容器规格列表。每个容器规格具有以下结构：
- en: '[PRE3]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Each container has an `image`, a command that, if specified, replaces the Docker
    image command. It also has arguments and environment variables. Then, there are
    of course the image pull policy, ports, and resource limits. We covered those
    in earlier chapters.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 每个容器都有一个 `image`，一个命令，如果指定的话，将替代 Docker 镜像命令。它还可以有参数和环境变量。当然，还有镜像拉取策略、端口和资源限制。我们在前面的章节中已经介绍过这些内容。
- en: 'If you want to explore the pod resource, or other Kubernetes resources, further,
    then the following command can be very useful: `kubectl explain`.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想深入探索 pod 资源或其他 Kubernetes 资源，那么以下命令将非常有用：`kubectl explain`。
- en: It can explore resources as well as specific sub-resources and fields.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以探索资源以及特定的子资源和字段。
- en: 'Try the following commands:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试以下命令：
- en: '[PRE4]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Deploying long-running microservices in pods
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 pods 中部署长时间运行的微服务
- en: Long-running microservices should run in pods and be stateless. Let’s look at
    how to create pods for one of Hue’s microservices – the Hue learner – which is
    responsible for learning the user’s preferences across different domains. Later,
    we will raise the level of abstraction and use a deployment.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 长时间运行的微服务应该运行在 pods 中，并且是无状态的。让我们看看如何为 Hue 的一个微服务——Hue 学习器——创建 pods，Hue 学习器负责学习用户在不同领域的偏好。稍后，我们将提高抽象级别，使用部署（deployment）。
- en: Creating pods
  id: totrans-137
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建 pods
- en: Let’s start with a regular pod configuration file for creating a Hue learner
    internal service. This service doesn’t need to be exposed as a public service
    and it will listen to a queue for notifications and store its insights in some
    persistent storage.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个普通的 Pod 配置文件开始，来创建一个 Hue 学习器内部服务。该服务不需要公开暴露，它将监听一个队列以接收通知，并将其见解存储在持久存储中。
- en: 'We need a simple container that will run in the pod. Here is possibly the simplest
    Docker file ever, which will simulate the Hue learner:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要一个简单的容器来在 Pod 中运行。以下是可能是最简单的 Docker 文件，它将模拟 Hue 学习器：
- en: '[PRE5]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: It uses the `busybox` base image, prints to standard output `Started...`, and
    then goes into an infinite loop, which is, by all accounts, long-running.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 它使用 `busybox` 基础镜像，打印 `Started...` 到标准输出，然后进入无限循环，这在所有情况下都是长期运行的。
- en: 'I have built two Docker images tagged as `g1g1/hue-learn:0.3` and `g1g1/hue-learn:0.4`
    and pushed them to the Docker Hub registry (`g1g1` is my username):'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我已经构建了两个 Docker 镜像，标签为 `g1g1/hue-learn:0.3` 和 `g1g1/hue-learn:0.4`，并将它们推送到 Docker
    Hub 注册表（`g1g1` 是我的用户名）：
- en: '[PRE6]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now these images are available to be pulled into containers inside of Hue’s
    pods.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 现在这些镜像可以拉取到 Hue 的 Pod 中的容器里。
- en: 'We’ll use YAML here because it’s more concise and human-readable. Here are
    the boilerplate and metadata labels:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在这里使用 YAML，因为它更加简洁和易读。以下是模板和元数据标签：
- en: '[PRE7]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Next comes the important `containers` spec, which defines for each container
    the mandatory name and image:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是重要的 `containers` 规格，它为每个容器定义了必需的名称和镜像：
- en: '[PRE8]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `resources` section tells Kubernetes the resource requirements of the container,
    which allows for more efficient and compact scheduling and allocations. Here,
    the container requests 200 milli-cpu units (0.2 core) and 256 MiB (2 to the power
    of 28 bytes):'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '`resources` 部分告诉 Kubernetes 容器的资源需求，从而实现更高效、更紧凑的调度和分配。在这里，容器请求 200 毫 CPU 单位（0.2
    核）和 256 MiB（2 的 28 次方字节）：'
- en: '[PRE9]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The environment section allows the cluster administrator to provide environment
    variables that will be available to the container. Here it tells it to discover
    the queue and the store via DNS. In a testing environment, it may use a different
    discovery method:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '`environment` 部分允许集群管理员提供将可用于容器的环境变量。在这里，它告诉容器通过 DNS 查找队列和存储。在测试环境中，可能使用不同的发现方法：'
- en: '[PRE10]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Decorating pods with labels
  id: totrans-153
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 给 Pod 添加标签
- en: Labeling pods wisely is key for flexible operations. It lets you evolve your
    cluster live, organize your microservices into groups you can operate on uniformly,
    and drill down on the fly to observe different subsets.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 明智地标记 Pod 对灵活操作至关重要。它让你可以实时演进集群，将微服务组织成可以统一操作的组，并且可以快速深入观察不同的子集。
- en: 'For example, our Hue learner pod has the following labels (and a few others):'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们的 Hue 学习器 Pod 具有以下标签（以及其他一些标签）：
- en: '`runtime-environment : production`'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`runtime-environment : production`'
- en: '`tier : internal-service`'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tier : internal-service`'
- en: The `runtime-environment` label allows performing global operations on all pods
    that belong to a certain environment. The `tier` label can be used to query all
    pods that belong to a particular tier. These are just examples; your imagination
    is the limit here.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`runtime-environment` 标签允许对属于特定环境的所有 Pod 执行全局操作。`tier` 标签可以用于查询属于特定层级的所有 Pod。这些仅仅是示例，你的想象力才是限制。'
- en: 'Here is how to list the labels with the `get pods` command:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是如何使用 `get pods` 命令列出标签的方法：
- en: '[PRE11]'
  id: totrans-160
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, if you want to filter and list only the **kube-dns** pods, type the following:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你想过滤并仅列出 **kube-dns** Pod，可以输入以下命令：
- en: '[PRE12]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Deploying long-running processes with deployments
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用部署部署长期运行的进程
- en: In a large-scale system, pods should never be just created and let loose. If
    a pod dies unexpectedly for whatever reason, you want another one to replace it
    to maintain overall capacity. You can create replication controllers or replica
    sets yourself, but that leaves the door open to mistakes, as well as the possibility
    of partial failure. It makes much more sense to specify how many replicas you
    want when you launch your pods in a declarative manner. This is what Kubernetes
    deployments are for.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在大规模系统中，Pod 不应只是被创建后任其自由。如果 Pod 因为某种原因意外死亡，你希望有另一个 Pod 来替代它，以维持整体容量。你可以自己创建副本控制器或副本集，但这样会留下错误的隐患，并且有部分失败的可能性。以声明的方式指定你希望启动多少个副本，这样显得更加合理。这正是
    Kubernetes 部署的用途。
- en: 'Let’s deploy three instances of our Hue learner microservice with a Kubernetes
    deployment resource:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过 Kubernetes 部署资源来部署三个实例的 Hue 学习器微服务：
- en: '[PRE13]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The pod spec is identical to the `spec` section from the pod configuration file
    previously.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 规格与之前的 pod 配置文件中的 `spec` 部分完全相同。
- en: 'Let’s create the deployment and check its status:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建这个部署并检查其状态：
- en: '[PRE14]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You can get a lot more information about the deployment using the `kubectl
    describe` command:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `kubectl describe` 命令获取有关部署的更多信息：
- en: '[PRE15]'
  id: totrans-171
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Updating a deployment
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 更新一个部署
- en: 'The Hue platform is a large and ever-evolving system. You need to upgrade constantly.
    Deployments can be updated to roll out updates in a painless manner. You change
    the pod template to trigger a rolling update fully managed by Kubernetes. Currently,
    all the pods are running with version 0.3:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Hue 平台是一个庞大且不断发展的系统。你需要不断地进行升级。部署可以进行更新，以便以一种无痛的方式推出更新。你只需要更改 pod 模板，从而触发一个完全由
    Kubernetes 管理的滚动更新。目前，所有 pods 都在运行 0.3 版本：
- en: '[PRE16]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Let’s update the deployment to upgrade to version 0.4\. Modify the image version
    in the deployment file. Don’t modify labels; it will cause an error. Save it to
    `hue-learn-deployment-0.4.yaml`. Then we can use the `kubectl apply` command to
    upgrade the version and verify that the pods now run 0.4:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更新部署，升级到 0.4 版本。在部署文件中修改镜像版本，不要修改标签，否则会导致错误。将其保存为 `hue-learn-deployment-0.4.yaml`。然后我们可以使用
    `kubectl apply` 命令来升级版本，并验证 pods 是否现在运行 0.4 版本：
- en: '[PRE17]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note that new pods are created and the original 0.3 pods are terminated in a
    rolling update manner.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，新的 pods 会被创建，而原来的 0.3 版本的 pods 会以滚动更新的方式终止。
- en: '[PRE18]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We’ve covered how kubectl manifest files are structured and how they can be
    applied to deploy and update workloads on our cluster. Let’s see how these workloads
    can discover and call each other via internal services as well as be called from
    outside the cluster via externally exposed services.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讲解了 `kubectl` 清单文件的结构，以及如何应用这些文件来部署和更新集群中的工作负载。接下来，我们将看看这些工作负载如何通过内部服务发现并相互调用，以及如何通过外部暴露的服务从集群外部进行访问。
- en: Separating internal and external services
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 分离内部服务和外部服务
- en: Internal services are services that are accessed directly only by other services
    or jobs in the cluster (or administrators that log in and run ad hoc tools). There
    are also workloads that are not accessed at all. These workloads may watch for
    some events and perform their function without exposing any API.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 内部服务是只允许集群中其他服务或作业（或登录并运行临时工具的管理员）直接访问的服务。也有一些工作负载完全不被访问。这些工作负载可能会监听某些事件并执行其功能，而不暴露任何
    API。
- en: 'But some services need to be exposed to users or external programs. Let’s look
    at a fake Hue service that manages a list of reminders for a user. It doesn’t
    really do much – just returns a fixed list of reminders – but we’ll use it to
    illustrate how to expose services. I already pushed a `hue-reminders` image to
    Docker Hub:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 但有些服务需要对用户或外部程序进行暴露。让我们看一个虚拟的 Hue 服务，它管理用户的提醒列表。它实际上做的事情并不多——只返回一个固定的提醒列表——但我们将用它来说明如何暴露服务。我已经将
    `hue-reminders` 镜像推送到 Docker Hub：
- en: '[PRE19]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Deploying an internal service
  id: totrans-184
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署一个内部服务
- en: 'Here is the deployment, which is very similar to the `hue-learner` deployment,
    except that I dropped the annotations, `env`, and `resources` sections, kept just
    one or two labels to save space, and added a `ports` section to the container.
    That’s crucial because a service must expose a port through which other services
    can access it:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 这是该部署文件，它与 `hue-learner` 部署非常相似，除了我去掉了注释、`env` 和 `resources` 部分，保留了一个或两个标签以节省空间，并且添加了一个
    `ports` 部分到容器中。这是至关重要的，因为一个服务必须通过某个端口进行暴露，其他服务才能访问它：
- en: '[PRE20]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'When we run the deployment, two `hue-reminders` pods are added to the cluster:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行这个部署时，会有两个 `hue-reminders` pods 被添加到集群中：
- en: '[PRE21]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'OK. The pods are running. In theory, other services can look up or be configured
    with their internal IP address and just access them directly because they are
    all in the same network address space. But this doesn’t scale. Every time a reminder’s
    pod dies and is replaced by a new one, or when we just scale up the number of
    pods, all the services that access these pods must know about it. Kubernetes services
    solve this issue by providing a single stable access point to all the pods that
    share a set of selector labels. Here is the service definition:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，Pods 已经在运行。从理论上讲，其他服务可以查找或通过它们的内部 IP 地址进行配置，并直接访问它们，因为它们都在同一个网络地址空间中。但这样并不具有可扩展性。每次提醒的
    pod 终止并被新的 pod 替换，或者当我们只是增加 pod 的数量时，所有访问这些 pods 的服务都必须了解这些变更。Kubernetes 服务通过提供一个稳定的单一访问点来解决这个问题，所有共享一组选择器标签的
    pods 都可以通过它来访问。这里是服务定义：
- en: '[PRE22]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: The service has a `selector` that determines the backing pods by their matching
    labels. It also exposes a port, which other services will use to access it. It
    doesn’t have to be the same port as the container’s port. You can define a `targetPort`.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 服务有一个 `selector`，通过匹配标签来确定支持的 Pods。它还暴露一个端口，其他服务将通过该端口访问它。这个端口不需要和容器的端口相同。你可以定义一个
    `targetPort`。
- en: 'The `protocol` field can be one of the following: k’TCP, UDP, or (since Kubernetes
    1.12) SCTP.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '`protocol` 字段可以是以下之一：TCP、UDP，或者（从 Kubernetes 1.12 开始）SCTP。'
- en: Creating the hue-reminders service
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 hue-reminders 服务
- en: 'Let’s create the service and explore it:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建服务并进行探索：
- en: '[PRE23]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The service is up and running. Other pods can find it through environment variables
    or DNS. The environment variables for all services are set at pod creation time.
    That means that if a pod is already running when you create your service, you’ll
    have to kill it and let Kubernetes recreate it with the environment variables
    for the new service.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 服务已经启动并运行。其他 Pods 可以通过环境变量或 DNS 找到它。所有服务的环境变量在 Pod 创建时设置。这意味着如果你在创建服务时一个 Pod
    已经在运行，你必须杀掉它并让 Kubernetes 使用新的服务环境变量重新创建它。
- en: 'For example, the pod `hue-learn-68d74fd4b7-bxxnm` was created before the `hue-reminders`
    service was created, so it doesn’t have the environment variable for `HUE_REMINDERS_SERVICE`.
    Printing the environment for the pod shows the environment variable doesn’t exist:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Pod `hue-learn-68d74fd4b7-bxxnm` 在创建 `hue-reminders` 服务之前就已经创建，因此它没有 `HUE_REMINDERS_SERVICE`
    的环境变量。打印该 Pod 的环境变量显示该环境变量不存在：
- en: '[PRE24]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Let’s kill the pod and, when a new pod replaces it, let’s try again:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们杀掉该 Pod，当一个新的 Pod 替代它时，我们再试一次：
- en: '[PRE25]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let’s check the `hue-learn` pods again:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次检查 `hue-learn` Pods：
- en: '[PRE26]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Great. We have a new fresh pod – `hue-learn-68d74fd4b7-rw4qr`. Let’s see if
    it has the environment variable for the `HUE_REMINDERS_SERVICE` service:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 很好，我们有一个新的 Pod —— `hue-learn-68d74fd4b7-rw4qr`。让我们看看它是否有 `HUE_REMINDERS_SERVICE`
    服务的环境变量：
- en: '[PRE27]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Yes, it does! But using DNS is much simpler. Kubernetes assigns an internal
    DNS name to every service. The service DNS name is:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，它有！不过使用 DNS 要简单得多。Kubernetes 会为每个服务分配一个内部 DNS 名称。服务的 DNS 名称是：
- en: '[PRE28]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now, every pod in the cluster can access the `hue-reminders` service through
    its service endpoint and port `8080`:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，集群中的每个 Pod 都可以通过其服务端点和端口 `8080` 访问 `hue-reminders` 服务：
- en: '[PRE29]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Yes, at the moment `hue-reminders` always returns the same two reminders:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，目前 `hue-reminders` 总是返回相同的两条提醒：
- en: '[PRE30]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: This is for demonstration purposes only. If `hue-reminders` was a real system
    it would return live and dynamic reminders.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 这里只是为了演示目的。如果 `hue-reminders` 是一个真实的系统，它会返回实时和动态的提醒。
- en: Now that we’ve covered internal services and how to access them, let’s look
    at external services.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了内部服务及其访问方式，接下来我们来看一下外部服务。
- en: Exposing a service externally
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 暴露服务到外部
- en: 'The service is accessible inside the cluster. If you want to expose it to the
    world, Kubernetes provides several ways to do it:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 服务可以在集群内部访问。如果你想将其暴露给外界，Kubernetes 提供了几种方法：
- en: Configure `NodePort` for direct access
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置 `NodePort` 以便直接访问
- en: Configure a cloud load balancer if you run it in a cloud environment
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你在云环境中运行，配置一个云负载均衡器
- en: Configure your own load balancer if you run on bare metal
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你在裸金属上运行，配置你自己的负载均衡器
- en: 'Before you configure a service for external access, you should make sure it
    is secure. We’ve already covered the principles of this in *Chapter 4*, *Securing
    Kubernetes*. The Kubernetes documentation has a good example that covers all the
    gory details here: [https://github.com/kubernetes/examples/blob/master/staging/https-nginx/README.md](https://github.com/kubernetes/examples/blob/master/staging/https-nginx/README.md).'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置外部访问服务之前，你应该确保它是安全的。我们在*第 4 章*《Kubernetes 安全性》中已经讲解了这方面的原则。Kubernetes 文档中有一个很好的示例，涵盖了所有细节：[https://github.com/kubernetes/examples/blob/master/staging/https-nginx/README.md](https://github.com/kubernetes/examples/blob/master/staging/https-nginx/README.md)。
- en: 'Here is the `spec` section of the `hue-reminders` service when exposed to the
    world through `NodePort`:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 这是暴露到外部通过 `NodePort` 的 `hue-reminders` 服务的 `spec` 部分：
- en: '[PRE31]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The main downside of exposing services though `NodePort` is that the port numbers
    are shared across all services. You must coordinate them globally across your
    entire cluster to avoid conflicts. This is not trivial at scale for large clusters
    with lots of developers deploying services.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 `NodePort` 暴露服务的主要缺点是端口号在所有服务之间共享。你必须在整个集群中进行全局协调，以避免冲突。对于大规模集群和有大量开发者部署服务的情况，这并不简单。
- en: But there are other reasons that you may want to avoid exposing a Kubernetes
    service directly, such as security and lack of abstraction, and you may prefer
    to use an Ingress resource in front of the service.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 但你可能有其他原因不希望直接暴露 Kubernetes 服务，例如安全性问题和缺乏抽象，可能更倾向于在服务前使用 Ingress 资源。
- en: Ingress
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Ingress
- en: 'Ingress is a Kubernetes configuration object that lets you expose a service
    to the outside world and takes care of a lot of details. It can do the following:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress 是一个 Kubernetes 配置对象，允许你将服务暴露到外部世界，并处理许多细节。它可以做以下事情：
- en: Provide an externally visible URL to your service
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为你的服务提供一个对外可见的 URL
- en: Load balance traffic
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负载均衡流量
- en: Terminate SSL
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 终止 SSL
- en: Provide name-based virtual hosting
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提供基于名称的虚拟主机
- en: To use Ingress, you must have an Ingress controller running in your cluster.
    Ingress was introduced in Kubernetes 1.1, and became stable in Kubernetes 1.19\.
    One of the current limitations of the Ingress controller is that it isn’t built
    for scale. As such, it is not a good option for the Hue platform yet. We’ll cover
    the Ingress controller in greater detail in *Chapter 10*, *Exploring Kubernetes
    Networking*.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Ingress，你必须在集群中运行一个 Ingress 控制器。Ingress 是在 Kubernetes 1.1 中引入的，并在 Kubernetes
    1.19 中稳定。Ingress 控制器的一个当前限制是它并不适合大规模使用。因此，它目前不适合 Hue 平台。我们将在 *第10章*，*探索 Kubernetes
    网络* 中更详细地讨论 Ingress 控制器。
- en: 'Here is what an Ingress resource looks like:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个 Ingress 资源的样子：
- en: '[PRE32]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Note the annotation, which hints that it is an Ingress object that works with
    the Nginx Ingress controller. There are many other Ingress controllers and they
    typically use annotations to encode information they need that is not captured
    by the Ingress object itself and its rules.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 注意这个注解，它提示这是一个与 Nginx Ingress 控制器配合使用的 Ingress 对象。还有许多其他 Ingress 控制器，它们通常使用注解来编码它们需要的信息，这些信息是
    Ingress 对象及其规则本身无法捕获的。
- en: 'Other Ingress controllers include:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 其他 Ingress 控制器包括：
- en: Traefik
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Traefik
- en: Gloo
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gloo
- en: Contour
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Contour
- en: AWS ALB Ingress controller
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS ALB Ingress 控制器
- en: HAProxy Ingress
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HAProxy Ingress
- en: Voyager
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Voyager
- en: An `IngressClass` resource can be created and specified in the `Ingress` resource.
    If it is not specified, then the default `IngressClass` is used.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 可以创建 `IngressClass` 资源并在 `Ingress` 资源中指定它。如果未指定，则使用默认的 `IngressClass`。
- en: In this section, we looked at how the different components of the Hue platform
    can discover and talk to each other via services as well as exposing public-facing
    services to the outside world. In the next section, we will look at how Hue workloads
    can be scheduled efficiently and cost-effectively on Kubernetes.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们查看了 Hue 平台的不同组件如何通过服务发现并相互通信，以及如何将面向公众的服务暴露给外部世界。在下一节中，我们将探讨如何在 Kubernetes
    上高效且具成本效益地调度 Hue 工作负载。
- en: Advanced scheduling
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 高级调度
- en: One of the strongest suits of Kubernetes is its powerful yet flexible scheduler.
    The job of the scheduler, put simply, is to choose nodes to run newly created
    pods. In theory, the scheduler could even move existing pods around between nodes,
    but in practice, it doesn’t do that at the moment and instead leaves this functionality
    for other components.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 最强大的特点之一就是其强大而灵活的调度器。简而言之，调度器的工作就是选择节点来运行新创建的 Pod。理论上，调度器甚至可以将现有的
    Pod 在节点之间移动，但实际上它目前并不这样做，而是将这一功能交给其他组件。
- en: 'By default, the scheduler follows several guiding principles, including:'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，调度器遵循几个指导原则，包括：
- en: Split pods from the same replica set or stateful set across nodes
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将来自同一副本集或有状态集的 Pod 分布到不同节点
- en: Schedule pods to nodes that have enough resources to satisfy the pod requests
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将 Pod 调度到具有足够资源以满足 Pod 请求的节点上
- en: Balance out the overall resource utilization of nodes
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 平衡节点的整体资源利用率
- en: This is pretty good default behavior, but sometimes you may want better control
    over specific pod placement. Kubernetes 1.6 introduced several advanced scheduling
    options that give you fine-grained control over which pods are scheduled or not
    scheduled on which nodes as well as which pods are to be scheduled together or
    separately.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个相当不错的默认行为，但有时你可能希望对特定的 Pod 放置进行更好的控制。Kubernetes 1.6 引入了几个高级调度选项，使你可以精细地控制哪些
    Pod 在哪些节点上调度，哪些 Pod 不调度，以及哪些 Pod 要一起调度或分开调度。
- en: Let’s review these mechanisms in the context of Hue.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 Hue 的背景下回顾这些机制。
- en: 'First, let’s create a k3d cluster with two worker nodes:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个包含两个工作节点的 k3d 集群：
- en: '[PRE33]'
  id: totrans-251
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Let’s look at the various ways that pods can be scheduled to nodes and when
    each method is appropriate.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 Pod 可以如何调度到节点的各种方式，以及每种方法适用的场景。
- en: Node selector
  id: totrans-253
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 节点选择器
- en: 'The node selector is pretty simple. A pod can specify which nodes it wants
    to be scheduled on in its spec. For example, the `trouble-shooter` pod has a `nodeSelector`
    that specifies the `kubernetes.io/hostname` label of the `worker-2` node:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 节点选择器非常简单。Pod 可以在其规格中指定它希望调度到的节点。例如，`trouble-shooter` Pod 有一个`nodeSelector`，它指定了`worker-2`节点的`kubernetes.io/hostname`标签：
- en: '[PRE34]'
  id: totrans-255
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'When creating this pod, it is indeed scheduled to the `k3d-k3s-default-agent-1`
    node:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 创建这个 Pod 时，它确实被调度到了`k3d-k3s-default-agent-1`节点：
- en: '[PRE35]'
  id: totrans-257
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Taints and tolerations
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 污点与容忍度
- en: 'You can taint a node in order to prevent pods from being scheduled on the node.
    This can be useful, for example, if you don’t want pods to be scheduled on your
    control plane nodes. Tolerations allow pods to declare that they can “tolerate”
    a specific node taint and then these pods can be scheduled on the tainted node.
    A node can have multiple taints and a pod can have multiple tolerations. A taint
    is a triplet: key, value, effect. The key and value are used to identify the taint.
    The effect is one of:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以对一个节点添加污点，防止 Pods 被调度到该节点。例如，如果你不希望 Pods 被调度到你的控制平面节点，可以使用这种方法。容忍度允许 Pods
    声明它们可以“忍受”特定的节点污点，之后这些 Pods 可以调度到被污染的节点。一个节点可以有多个污点，一个 Pod 可以有多个容忍度。污点是一个三元组：键（key）、值（value）、效果（effect）。键和值用于识别污点，效果包括以下几种：
- en: '`NoSchedule` (no pods will be scheduled to the node unless they tolerate the
    taint)'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NoSchedule`（除非 Pods 忍受污点，否则不会调度到该节点）'
- en: '`PreferNoSchedule` (soft version of `NoSchedule`; the scheduler will attempt
    to not schedule pods that don’t tolerate the taint)'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PreferNoSchedule`（`NoSchedule`的软版本；调度器将尽量避免调度那些不忍受污点的 Pods）'
- en: '`NoExecute` (no new pods will be scheduled, but also existing pods that don’t
    tolerate the taint will be evicted)'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NoExecute`（不会调度新的 Pod，但也会驱逐那些不忍受污点的现有 Pod）'
- en: 'Let’s deploy `hue-learn` and `hue-reminders` on our k3d cluster:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在我们的 k3d 集群上部署`hue-learn`和`hue-reminders`：
- en: '[PRE36]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Currently, there is a `hue-learn` pod that runs on the control plane node (`k3d-k3s-default-server-0`):'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 当前，在控制平面节点（`k3d-k3s-default-server-0`）上运行着一个`hue-learn` Pod：
- en: '[PRE37]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Let’s taint our control plane node:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们给控制平面节点加上污点：
- en: '[PRE38]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'We can now review the taint:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以查看污点（taint）：
- en: '[PRE39]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Yeah, it worked! There are now no pods scheduled on the master node. The `hue-learn`
    pod on `k3d-k3s-default-server-0` was evicted and a new pod (`hue-learn-67d4649b58-bl8cn`)
    is now running on `k3d-k3s-default-agent-0`:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，成功了！现在没有 Pods 被调度到主节点上。`k3d-k3s-default-server-0`上的`hue-learn` Pod 被驱逐，并且一个新的
    Pod（`hue-learn-67d4649b58-bl8cn`）现在在`k3d-k3s-default-agent-0`上运行：
- en: '[PRE40]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'To allow pods to tolerate the taint, add a toleration to their spec such as:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 若要允许 Pod 忍受污点，可以在其规格中添加一个容忍度（toleration），例如：
- en: '[PRE41]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: Node affinity and anti-affinity
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 节点亲和性与反亲和性
- en: 'Node affinity is a more sophisticated form of the `nodeSelector`. It has three
    main advantages:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 节点亲和性（node affinity）是比`nodeSelector`更复杂的一种形式。它有三个主要优点：
- en: Rich selection criteria (`nodeSelector` is just `AND` of exact matches on the
    labels)
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 丰富的选择标准（`nodeSelector`只是标签精确匹配的`AND`运算）
- en: Rules can be soft
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规则可以是软性（soft）
- en: You can achieve anti-affinity using operators like `NotIn` and `DoesNotExist`
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使用`NotIn`和`DoesNotExist`等运算符实现反亲和性（anti-affinity）
- en: Note that if you specify both `nodeSelector` and `nodeAffinity`, then the pod
    will be scheduled only to a node that satisfies both requirements.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果你同时指定了`nodeSelector`和`nodeAffinity`，那么该 Pod 只会调度到满足两个要求的节点上。
- en: 'For example, if we add the following section to our `trouble-shooter` pod,
    it will not be able to run on any node because it conflicts with the `nodeSelector`:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果我们将以下部分添加到我们的`trouble-shooter` Pod，它将无法在任何节点上运行，因为它与`nodeSelector`发生冲突：
- en: '[PRE42]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Pod affinity and anti-affinity
  id: totrans-283
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pod 亲和性与反亲和性
- en: 'Pod affinity and anti-affinity provide yet another avenue for managing where
    your workloads run. All the methods we discussed so far – node selectors, taints/tolerations,
    node affinity/anti-affinity – were about assigning pods to nodes. But pod affinity
    is about the relationships between different pods. Pod affinity has several other
    concepts associated with it: namespacing (since pods are namespaced), topology
    zone (node, rack, cloud provider zone, cloud provider region), and weight (for
    preferred scheduling). A simple example is if you want `hue-reminders` to always
    be scheduled with a `trouble-shooter` pod. Let’s see how to define it in the pod
    template spec of the `hue-reminders` deployment:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: Pod亲和性和反亲和性提供了另一种管理工作负载运行位置的方式。到目前为止，我们讨论的所有方法——节点选择器、污点/容忍、节点亲和性/反亲和性——都是关于将pod分配给节点的。但pod亲和性是关于不同pod之间的关系。pod亲和性还涉及几个其他概念：命名空间（因为pod是有命名空间的）、拓扑区域（节点、机架、云提供商区域、云提供商区域）、权重（用于首选调度）。一个简单的例子是，如果你希望`hue-reminders`总是与`trouble-shooter`
    pod一起调度。让我们看看如何在`hue-reminders`部署的pod模板规格中定义它：
- en: '[PRE43]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: The topology key is a node label that Kubernetes will treat as identical for
    scheduling purposes. On cloud providers, it is recommended to use `topology.kubernetes.io/zone`
    when workloads should run in proximity to each other. In the cloud, a zone is
    the equivalent of a data center.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑键是一个节点标签，Kubernetes会将其视为在调度时相同。在云提供商中，当工作负载应该彼此靠近时，建议使用`topology.kubernetes.io/zone`。在云环境中，区域相当于数据中心。
- en: 'Then, after re-deploying `hue-reminders`, all the `hue-reminders` pods are
    scheduled to run on `k3d-k3s-default-agent-1` next to the `trouble-shooter` pod:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，在重新部署`hue-reminders`之后，所有的`hue-reminders` pod都被调度到`k3d-k3s-default-agent-1`上，紧邻`trouble-shooter`
    pod：
- en: '[PRE44]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Pod topology spread constraints
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pod拓扑分布约束
- en: Node affinity/anti-affinity and pod affinity/anti-affinity are sometimes too
    strict. You may want to spread your pods – it’s okay if some pods of the same
    deployment end up on the same node. Pod topology spread constraints give you this
    flexibility. You can specify the max skew, which is how far you can be from the
    optimal spread, as well as the behavior when the constraint can’t be satisfied
    (`DoNotSchedule` or `ScheduleAnyway`).
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 节点亲和性/反亲和性和pod亲和性/反亲和性有时过于严格。你可能希望分散你的pod——如果同一部署的某些pod最终部署在同一节点上也是可以的。pod拓扑分布约束为你提供了这种灵活性。你可以指定最大偏差，即你能接受的最优分布偏差，同时也可以指定当约束无法满足时的行为（`DoNotSchedule`或`ScheduleAnyway`）。
- en: 'Here is our `hue-reminders` deployment with pod topology spread constraints:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的`hue-reminders`部署，带有pod拓扑分布约束：
- en: '[PRE45]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'We can see that after applying the manifest, the three pods were spread across
    the two agent nodes (the server node has a taint as you recall):'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，在应用清单之后，三个pod被分布在两个代理节点上（服务器节点如你所记得，有一个污点）：
- en: '[PRE46]'
  id: totrans-294
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: The descheduler
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 反调度器
- en: 'Kubernetes is great at scheduling pods to nodes according to sophisticated
    placement rules. But, once a pod is scheduled, Kubernetes will not move it to
    another node if the original conditions changed. Here are some use cases that
    would benefit from moving workloads around:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes在根据复杂的放置规则将pod调度到节点方面表现出色。但是，一旦pod被调度，Kubernetes就不会在原始条件发生变化时将其移动到另一个节点。以下是一些可以从工作负载迁移中受益的用例：
- en: Certain nodes are experiencing under-utilization or over-utilization.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 某些节点出现了资源利用不足或过度利用的情况。
- en: The initial scheduling decision is no longer valid when taints or labels are
    modified on nodes, causing pod/node affinity requirements to no longer be met.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当节点上的污点或标签被修改时，初始调度决策不再有效，导致pod/node亲和性要求不再满足。
- en: Certain nodes have encountered failures, resulting in the migration of their
    pods to other nodes.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 某些节点发生了故障，导致它们的pod迁移到其他节点。
- en: Additional nodes are introduced to the clusters.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 向集群中引入了额外的节点。
- en: This is where the descheduler comes into play. The descheduler is not part of
    vanilla Kubernetes. You need to install it and define policies that determine
    which running pods may be evicted. It can run as a `Job`, `CronJob`, or `Deployment`.
    The descheduler will periodically check the current placement of pods and will
    evict pods that violate some policy. The pods will get rescheduled and then the
    standard Kubernetes scheduler will take care of scheduling them according to the
    current conditions.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 这时，反调度器就发挥作用了。反调度器并不是Kubernetes的原生功能。你需要安装它并定义策略，决定哪些正在运行的pod可能被驱逐。它可以作为`Job`、`CronJob`或`Deployment`运行。反调度器会定期检查当前pod的分布情况，并会驱逐违反某些策略的pod。这些pod会被重新调度，标准的Kubernetes调度器会根据当前的条件重新安排它们。
- en: 'Check it out here: [https://github.com/kubernetes-sigs/descheduler](https://github.com/kubernetes-sigs/descheduler).'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里查看：[https://github.com/kubernetes-sigs/descheduler](https://github.com/kubernetes-sigs/descheduler)。
- en: In this section, we saw how the advanced scheduling mechanisms Kubernetes provides,
    as well as projects like the descheduler, can help Hue schedule its workload in
    an optimal way across the available infrastructure. In the next section, we will
    look at how to divide Hue workloads to a namespace to manage access to different
    resources.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分中，我们看到了 Kubernetes 提供的高级调度机制，以及像 descheduler 这样的项目，如何帮助 Hue 在可用的基础设施上以最优方式调度其工作负载。在下一部分中，我们将研究如何将
    Hue 的工作负载划分到命名空间中，以便更好地管理对不同资源的访问。
- en: Using namespaces to limit access
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用命名空间来限制访问
- en: The Hue project is moving along nicely, and we have a few hundred microservices
    and about 100 developers and DevOps engineers working on it. Groups of related
    microservices emerge, and you notice that many of these groups are pretty autonomous.
    They are completely oblivious to the other groups. Also, there are some sensitive
    areas such as health and finance that you want to control access to more effectively.
    Enter namespaces.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: Hue 项目进展顺利，我们有几百个微服务和大约100名开发人员以及 DevOps 工程师在参与其中。相关微服务的组逐渐形成，你会发现这些组相当自治，它们完全忽略了其他组。此外，像健康和财务等敏感区域，你希望更有效地控制访问。于是，命名空间应运而生。
- en: Let’s create a new service, `hue-finance`, and put it in a new namespace called
    `restricted`.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个新的服务`hue-finance`，并将其放入一个名为`restricted`的新命名空间中。
- en: 'Here is the YAML file for the new `restricted` namespace:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 这是新`restricted`命名空间的 YAML 文件：
- en: '[PRE47]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'We can create it as usual:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以像往常一样创建它：
- en: '[PRE48]'
  id: totrans-310
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Once the namespace has been created, we can configure a context for the namespace:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦命名空间创建完成，我们可以为该命名空间配置一个上下文：
- en: '[PRE49]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Let’s check our cluster configuration:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下我们的集群配置：
- en: '[PRE50]'
  id: totrans-314
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: As you can see, there are two contexts now and the current context is `restricted`.
    If we wanted to, we could even create dedicated users with their own credentials
    that are allowed to operate in the restricted namespace. Depending on the environment
    this can be easy or difficult and may involve creating certificates via Kubernetes
    certificate authorities. Cloud providers offer integration with their IAM systems.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，现在有两个上下文，当前的上下文是`restricted`。如果需要，我们甚至可以创建专用用户，并为他们分配允许在受限命名空间中操作的凭证。根据环境的不同，这可能很简单也可能很复杂，并且可能涉及通过
    Kubernetes 证书颁发机构创建证书。云服务提供商提供与其身份和访问管理（IAM）系统的集成。
- en: 'To move along, I’ll use the `admin@k3d-k3s-default` user’s credentials and
    create a user named `restricted@k3d-k3s-default` directly in the `kubeconfig`
    file of the cluster:'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 为了继续进行，我将使用`admin@k3d-k3s-default`用户的凭证，并直接在集群的`kubeconfig`文件中创建一个名为`restricted@k3d-k3s-default`的用户：
- en: '[PRE51]'
  id: totrans-317
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Now, in this empty namespace, we can create our `hue-finance` service, and
    it will be separate from the other services in the default namespace:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在这个空的命名空间中，我们可以创建我们的 `hue-finance` 服务，它将与默认命名空间中的其他服务分开：
- en: '[PRE52]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: You don’t have to switch contexts. You can also use the `--namespace=<namespace>`
    and `--all-namespaces` command-line switches, but when operating for a while in
    the same non-default namespace, it’s nice to set the context to that namespace.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 你不需要切换上下文。你还可以使用`--namespace=<namespace>`和`--all-namespaces`命令行选项，但当长时间在同一个非默认命名空间中操作时，将上下文设置为该命名空间会更加方便。
- en: Using Kustomization for hierarchical cluster structures
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kustomization 进行分层集群结构
- en: This is not a typo. Kubectl recently incorporated the functionality of Kustomize
    ([https://kustomize.io/](https://kustomize.io/)). It is a way to configure Kubernetes
    without templates. There was a lot of drama about the way the Kustomize functionality
    was integrated into kubectl itself, since there are other options and it was an
    open question if kubectl should be that opinionated. But, that’s all in the past.
    The bottom line is that `kubectl apply -k` unlocks a treasure trove of configuration
    options. Let’s understand what problem it helps us to solve and take advantage
    of it to help us manage Hue.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 这不是打字错误。Kubectl 最近集成了 Kustomize 的功能（[https://kustomize.io/](https://kustomize.io/)）。它是一种无需模板即可配置
    Kubernetes 的方式。关于 Kustomize 功能如何集成到 kubectl 本身中曾有过很多争议，因为还有其他选择，是否应该让 kubectl
    具有这么强的偏好也曾是一个开放的问题。不过，这些都已经过去了。最终结论是，`kubectl apply -k` 解锁了大量的配置选项。让我们理解它帮助我们解决了什么问题，并利用它来帮助我们管理
    Hue。
- en: Understanding the basics of Kustomize
  id: totrans-323
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 Kustomize 的基础
- en: Kustomize was created as a response to template-heavy approaches like Helm to
    configure and customize Kubernetes clusters. It is designed around the principle
    of declarative application management. It takes a valid Kubernetes YAML manifest
    (base) and specializes it or extends it by overlaying additional YAML patches
    (overlays). Overlays depend on their bases. All files are valid YAML files. There
    are no placeholders.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: Kustomize 是响应像 Helm 这样的模板驱动方法而创建的，用于配置和定制 Kubernetes 集群。它围绕声明式应用管理的原则设计。它接受一个有效的
    Kubernetes YAML 清单（基础配置），并通过覆盖额外的 YAML 补丁（覆盖层）来专门化或扩展它。覆盖层依赖于它们的基础配置。所有文件都是有效的
    YAML 文件。没有占位符。
- en: 'A `kustomization.yaml` file controls the process. Any directory that contains
    a `kustomization.yaml` file is called a root. For example:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '`kustomization.yaml` 文件控制该过程。任何包含 `kustomization.yaml` 文件的目录都称为根目录。例如：'
- en: '[PRE53]'
  id: totrans-326
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Kustomize can work well in a GitOps environment where different Kustomizations
    live in a Git repo and changes to the bases, overlays, or `kustomization.yaml`
    files trigger a deployment.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: Kustomize 在 GitOps 环境中表现良好，其中不同的 Kustomizations 存储在 Git 仓库中，并且对基础配置、覆盖层或 `kustomization.yaml`
    文件的更改会触发部署。
- en: One of the best use cases for Kustomize is organizing your system into multiple
    namespaces such as staging and production. Let’s restructure the Hue platform
    deployment manifests.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: Kustomize 的最佳使用场景之一是将你的系统组织成多个命名空间，如 staging 和 production。让我们重构 Hue 平台部署清单。
- en: Configuring the directory structure
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置目录结构
- en: 'First, we need a base directory that will contain the commonalities of all
    the manifests. Then we will have an `overlays` directory that contains `staging`
    and `production` sub-directories:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们需要一个基础目录，其中包含所有清单的共性。然后我们将拥有一个 `overlays` 目录，该目录包含 `staging` 和 `production`
    子目录：
- en: '[PRE54]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The `hue-learn.yaml` file in the base directory is just an example. There may
    be many files there. Let’s review it quickly:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 基础目录中的 `hue-learn.yaml` 文件只是一个示例。那里可能有许多文件。让我们快速查看它：
- en: '[PRE55]'
  id: totrans-333
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'It is very similar to the manifest we created earlier, but it doesn’t have
    the `app: hue` label. It is not necessary because the label is provided by the
    `kustomization.yaml` file as a common label for all the listed resources:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '它与我们之前创建的清单非常相似，但没有 `app: hue` 标签。这个标签并不是必需的，因为标签是由 `kustomization.yaml` 文件提供的，作为所有列出资源的通用标签：'
- en: '[PRE56]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: Applying Kustomizations
  id: totrans-336
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用 Kustomizations
- en: 'We can observe the results by running the `kubectl kustomize` command on the
    base directory. You can see that the common label `app: hue` was added:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '我们可以通过在基础目录上运行 `kubectl kustomize` 命令来查看结果。你可以看到，通用标签 `app: hue` 被添加了：'
- en: '[PRE57]'
  id: totrans-338
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: In order to actually deploy the Kustomization, we can run `kubectl -k apply`.
    But, the base is not supposed to be deployed on its own. Let’s dive into the `overlays/staging`
    directory and examine it.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实际部署 Kustomization，我们可以运行 `kubectl -k apply`。但是，基础配置不应该单独部署。让我们深入到 `overlays/staging`
    目录并查看它。
- en: 'The `namespace.yaml` file just creates the `staging` namespace. It will also
    benefit from all the Kustomizations as we’ll soon see:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '`namespace.yaml` 文件仅创建 `staging` 命名空间。正如我们即将看到的，它将受益于所有的 Kustomizations：'
- en: '[PRE58]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'The `kustomization.yaml` file adds the common label `environment: staging`.
    It depends on the base directory and adds the `namespace.yaml` file to the resources
    list (which already includes `hue-learn.yaml` from the base):'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '`kustomization.yaml` 文件添加了通用标签 `environment: staging`。它依赖于基础目录，并将 `namespace.yaml`
    文件添加到资源列表中（该列表已包括基础目录中的 `hue-learn.yaml`）：'
- en: '[PRE59]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: But, that’s not all. The most interesting part of Kustomizations is patching.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 但这还不是全部。Kustomizations 最有趣的部分是补丁。
- en: Patching
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 补丁
- en: 'Patches add or replace parts of manifests. They never remove existing resources
    or parts of resources. The `hue-learn-patch.yaml` updates the image from `g1g1/hue-learn:0.3`
    to `g1g1/hue-learn:0.4`:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 补丁添加或替换清单的部分内容。它们从不删除现有的资源或资源的部分内容。`hue-learn-patch.yaml` 将镜像从 `g1g1/hue-learn:0.3`
    更新为 `g1g1/hue-learn:0.4`：
- en: '[PRE60]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: This is a strategic merge. Kustomize supports another type of patch called `JsonPatches6902`.
    It is based on RFC 6902 ([https://tools.ietf.org/html/rfc6902](https://tools.ietf.org/html/rfc6902)).
    It is often more concise than a strategic merge. We can use YAML syntax for JSON
    6902 patches. Here is the same patch of changing the image version to version
    0.4 using `JsonPatches6902` syntax`:`
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个战略合并。Kustomize 支持另一种补丁类型，称为 `JsonPatches6902`。它基于 RFC 6902 ([https://tools.ietf.org/html/rfc6902](https://tools.ietf.org/html/rfc6902))。通常，它比战略合并更简洁。我们可以使用
    YAML 语法为 JSON 6902 补丁编写。这里是使用 `JsonPatches6902` 语法将镜像版本更改为 0.4 的相同补丁：
- en: '[PRE61]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: Kustomizing the entire staging namespace
  id: totrans-350
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 对整个 staging 命名空间进行 Kustomize 操作
- en: 'Here is what Kustomize generates when running it on the `overlays/staging`
    directory:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 这是在`overlays/staging`目录上运行Kustomize时生成的内容：
- en: '[PRE62]'
  id: totrans-352
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Note that the namespace didn’t inherit the `app: hue` label from the base,
    but only the `environment: staging` label from its local Kustomization file. The
    `hue-learn` pod, on the other hand, got all labels as well the namespace designation.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '请注意，命名空间没有继承基础中的`app: hue`标签，而只继承了其本地Kustomization文件中的`environment: staging`标签。另一方面，`hue-learn`
    pod则得到了所有标签以及命名空间指定。'
- en: 'It’s time to deploy it to the cluster:'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候将其部署到集群中了：
- en: '[PRE63]'
  id: totrans-355
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Now, we can review the pod in the newly created `staging` namespace:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以查看在新创建的`staging`命名空间中的pod：
- en: '[PRE64]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: 'Let’s check that the overlay worked and the image version is indeed 0.4:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查overlay是否生效，并且镜像版本确实是0.4：
- en: '[PRE65]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: In this section, we covered the powerful structuring and reusability afforded
    by the Kustomize option. This is very important for a large-scale system like
    the Hue platform where a lot of workloads can benefit from a uniform structure
    and consistent foundation. In the next section, we will look at launching short-term
    jobs.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了Kustomize选项所提供的强大结构化和可重用性。这对像Hue平台这样的大规模系统非常重要，因为许多工作负载可以从统一的结构和一致的基础中受益。在下一节中，我们将介绍如何启动短期作业。
- en: Launching jobs
  id: totrans-361
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动作业
- en: Hue has evolved and has a lot of long-running processes deployed as microservices,
    but it also has a lot of tasks that run, accomplish some goal, and exit. Kubernetes
    supports this functionality via the `Job` resource. A Kubernetes job manages one
    or more pods and ensures that they run until success or failure. If one of the
    pods managed by the job fails or is deleted, then the job will run a new pod until
    it succeeds.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: Hue已经发展起来，并且部署了许多长时间运行的微服务进程，但它也有许多任务会运行、完成某些目标然后退出。Kubernetes通过`Job`资源支持这种功能。Kubernetes作业管理一个或多个pod，并确保它们在成功或失败之前一直运行。如果作业管理的pod之一失败或被删除，那么作业会启动一个新的pod，直到成功为止。
- en: There are also many serverless or function-as-a-service solutions for Kubernetes,
    but they are built-on top of native Kubernetes. We will cover serverless computing
    in depth in *Chapter 12*, *Serverless Computing on Kubernetes*.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 也有许多适用于Kubernetes的无服务器或函数即服务解决方案，但它们是建立在原生Kubernetes之上的。我们将在*第12章*中深入讨论无服务器计算，*Kubernetes上的无服务器计算*。
- en: 'Here is a job that runs a Python process to compute the factorial of 5 (hint:
    it’s 120):'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个运行Python进程计算5的阶乘（提示：结果是120）的作业：
- en: '[PRE66]'
  id: totrans-365
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: Note that the `restartPolicy` must be either `Never` or `OnFailure`. The default
    value – `Always` – is invalid because a job doesn’t restart after successful completion.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`restartPolicy`必须是`Never`或`OnFailure`。默认值`Always`无效，因为作业在成功完成后不会重启。
- en: 'Let’s start the job and check its status:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们启动作业并检查其状态：
- en: '[PRE67]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The pods of completed tasks are displayed with a status of `Completed`. Note
    that job pods have a label called `job-name` with the name of the job, so it’s
    easy to filter just the job pods:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 完成任务的pod显示为`Completed`状态。请注意，作业pod有一个名为`job-name`的标签，标签值为作业的名称，因此很容易过滤出作业pod：
- en: '[PRE68]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'Let’s check out its output in the logs:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看日志中的输出：
- en: '[PRE69]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE69]'
- en: Launching jobs one after another is fine for some use cases, but it is often
    useful to run jobs in parallel. In addition, it’s important to clean up jobs after
    they are done as well as to run jobs periodically. Let’s see how it’s done.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 按顺序启动作业对于某些用例是可以的，但通常运行并行作业会更有用。此外，完成后清理作业并定期运行作业也很重要。让我们看看这是怎么做到的。
- en: Running jobs in parallel
  id: totrans-374
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 并行运行作业
- en: You can also run a job with parallelism. There are two fields in the spec called
    `completions` and `parallelism`. The completions are set to 1 by default. If you
    want more than one successful completion, then increase this value. Parallelism
    determines how many pods to launch. A job will not launch more pods than needed
    for successful completions, even if the parallelism number is greater.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以运行带有并行度的作业。在spec中有两个字段，分别是`completions`和`parallelism`。默认情况下，completions设置为1。如果你想要多个成功的完成次数，可以增加这个值。并行度决定了要启动多少个pod。作业不会启动超过成功完成所需的pod，即使并行度数大于该值。
- en: 'Let’s run another job that just sleeps for 20 seconds until it has three successful
    completions. We’ll use a parallelism factor of six, but only three pods will be
    launched:'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行另一个作业，它只会休眠20秒，直到完成三次成功。我们将使用并行因子为六，但只会启动三个pod：
- en: '[PRE70]'
  id: totrans-377
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Let’s run the job and wait for all the pods to complete:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行作业并等待所有pod完成：
- en: '[PRE71]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'We can now see that all three pods completed and the pods are not ready because
    they already did their work:'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以看到，所有三个 pods 都已完成，并且这些 pods 现在没有准备好，因为它们已经完成了工作：
- en: '[PRE72]'
  id: totrans-381
  prefs: []
  type: TYPE_PRE
  zh: '[PRE72]'
- en: Completed pods don’t take up resources on the node, so other pods can get scheduled
    there.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 已完成的 pods 不会占用节点上的资源，因此其他 pods 可以在该节点上被调度。
- en: Cleaning up completed jobs
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 清理已完成的作业
- en: When a job completes, it sticks around – and its pods, too. This is by design,
    so you can look at logs or connect to pods and explore. But normally, when a job
    has completed successfully, it is not needed anymore. It’s your responsibility
    to clean up completed jobs and their pods.
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 当一个作业完成时，它会保留 – 其 pods 也会保留。这是设计使然，目的是让你查看日志或连接到 pods 进行探查。但通常情况下，当一个作业成功完成后，它就不再需要了。清理已完成的作业及其
    pods 是你的责任。
- en: 'The easiest way is to simply delete the `job` object, which will delete all
    the pods too:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 最简单的方法是直接删除 `job` 对象，这样也会删除所有的 pods：
- en: '[PRE73]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Scheduling cron jobs
  id: totrans-387
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调度 cron 作业
- en: Kubernetes cron jobs are jobs that run at a specified time, once or repeatedly.
    They behave as regular Unix cron jobs specified in the `/etc/crontab` file.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes cron 作业是按指定时间运行的作业，可以是一次性运行或重复运行。它们的行为与在 `/etc/crontab` 文件中指定的普通
    Unix cron 作业一样。
- en: 'The `CronJob` resource became stable with Kubernetes 1.21\. Here is the configuration
    to launch a cron job every minute to remind you to stretch. In the schedule, you
    may replace the ‘`*`'' with ‘`?`'':'
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: '`CronJob` 资源在 Kubernetes 1.21 版本中变得稳定。这里是每分钟启动一个 cron 作业的配置，用来提醒你做伸展运动。在调度中，你可以将
    ‘`*`'' 替换为 ‘`?`''：'
- en: '[PRE74]'
  id: totrans-390
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: 'In the pod `spec`, under the job template, I added the label `cronjob-name:
    cron-demo`. The reason is that cron jobs and their pods are assigned names with
    a random prefix by Kubernetes. The label allows you to easily discover all the
    pods of a particular cron job. The pods will also have the `job-name` label because
    a cron job creates a `job` object for each invocation. However, the job name itself
    has a random prefix, so it doesn’t help us discover the pods.'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: '在 pod 的 `spec` 中，在作业模板下，我添加了标签 `cronjob-name: cron-demo`。原因是，cron 作业及其 pods
    会由 Kubernetes 分配一个随机前缀的名称。这个标签允许你轻松发现某个特定 cron 作业的所有 pods。Pods 还会有 `job-name`
    标签，因为一个 cron 作业会为每次执行创建一个 `job` 对象。然而，作业名称本身带有随机前缀，因此它不能帮助我们发现 pods。'
- en: 'Let’s run the cron job and observe the results after a minute:'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们运行 cron 作业并在一分钟后观察结果：
- en: '[PRE75]'
  id: totrans-393
  prefs: []
  type: TYPE_PRE
  zh: '[PRE75]'
- en: As you can see, every minute the cron job creates a new job with a different
    name. The pod of each job is labeled with its job name, but also with the cron
    job name – `cronjob-demo` – for easily aggregating all pods originating from this
    cron job.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，每分钟 cron 作业都会创建一个新的作业，并且每个作业的 pod 都会被标记上不同的名称。每个作业的 pod 都被标记上其作业名称，并且还会标记上
    cron 作业名称 —— `cronjob-demo` —— 以便于汇总所有来自该 cron 作业的 pods。
- en: 'As usual, you can check the output of a completed job’s pod using the `logs`
    command:'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 像往常一样，你可以使用 `logs` 命令查看已完成作业的 pod 输出：
- en: '[PRE76]'
  id: totrans-396
  prefs: []
  type: TYPE_PRE
  zh: '[PRE76]'
- en: When you delete a cron job it stops scheduling new jobs and deletes all the
    existing `job` objects and all the pods it created.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 当你删除一个 cron 作业时，它会停止调度新的作业，并删除所有现有的 `job` 对象以及它创建的所有 pods。
- en: 'You can use the designated label (`name=cron-demo` in this case) to locate
    all the `job` objects launched by the cron job:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用指定的标签（在这个例子中是 `name=cron-demo`）来定位 cron 作业启动的所有 `job` 对象：
- en: '[PRE77]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE77]'
- en: 'You can also suspend a cron job so it doesn’t create more jobs without deleting
    completed jobs and pods. You can also manage how many jobs stick around by setting
    it in the spec history limits: `.spec.successfulJobsHistoryLimit` and `.spec.failedJobsHistoryLimit`.'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以暂停一个 cron 作业，这样它就不会创建更多作业，但不会删除已完成的作业和 pods。你还可以通过在 spec 中设置历史限制来管理作业的保留数量：`.spec.successfulJobsHistoryLimit`
    和 `.spec.failedJobsHistoryLimit`。
- en: In this section, we covered the important topics of launching jobs and controlling
    them. This is a critical aspect of the Hue platform, which needs to react to real-time
    events and handle them by launching jobs as well as periodically performing short
    tasks.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了启动作业和控制作业的关键主题。这是 Hue 平台的一个关键方面，它需要响应实时事件并通过启动作业以及定期执行短期任务来处理它们。
- en: Mixing non-cluster components
  id: totrans-402
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 混合非集群组件
- en: Most real-time system components in the Kubernetes cluster will communicate
    with out-of-cluster components. Those could be completely external third-party
    services accessible through some API, but can also be internal services running
    in the same local network that, for various reasons, are not part of the Kubernetes
    cluster.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群中的大多数实时系统组件将与集群外的组件通信。那些组件可以是通过某些 API 访问的完全外部的第三方服务，也可以是运行在同一局域网中的内部服务，由于各种原因，它们不属于
    Kubernetes 集群的一部分。
- en: 'There are two categories here: inside the cluster network and outside the cluster
    network.'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有两类：集群内网络和集群外网络。
- en: Outside-the-cluster-network components
  id: totrans-405
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集群外网络组件
- en: These components have no direct access to the cluster. They can only access
    it through APIs, externally visible URLs, and exposed services. These components
    are treated just like any external user. Often, cluster components will just use
    external services, which pose no security issue. For example, in a previous company,
    we had a Kubernetes cluster that reported exceptions to a third-party service
    called Sentry ([https://sentry.io/welcome/](https://sentry.io/welcome/)). It was
    one-way communication from the Kubernetes cluster to the third-party service.
    The Kubernetes cluster had the credentials to access Sentry and that was the extent
    of this one-way communication.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件无法直接访问集群。它们只能通过 API、外部可见的 URL 和暴露的服务访问集群。这些组件被视为任何外部用户。通常，集群组件会使用外部服务，这不会造成安全问题。例如，在以前的公司里，我们有一个
    Kubernetes 集群，它将异常报告给名为 Sentry 的第三方服务（[https://sentry.io/welcome/](https://sentry.io/welcome/)）。这是
    Kubernetes 集群到第三方服务的单向通信。Kubernetes 集群拥有访问 Sentry 的凭据，这就是这单向通信的全部。
- en: Inside-the-cluster-network components
  id: totrans-407
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集群内网络组件
- en: These are components that run inside the network but are not managed by Kubernetes.
    There are many reasons to run such components. They could be legacy applications
    that have not been “kubernetized” yet, or some distributed data store that is
    not easy to run inside Kubernetes. The reason to run these components inside the
    network is for performance, and to have isolation from the outside world so traffic
    between these components and pods can be more secure. Being part of the same network
    ensures low latency, and the reduced need for opening up the network for communication
    is both convenient and can be more secure.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是运行在网络内部但不由 Kubernetes 管理的组件。运行这些组件有多种原因。它们可能是尚未“容器化”的遗留应用程序，或者是一些不易在 Kubernetes
    内部运行的分布式数据存储。将这些组件运行在网络内部的原因是为了性能，并且与外界隔离，以便这些组件和 Pod 之间的流量更加安全。作为同一网络的一部分可以确保低延迟，并且减少需要为通信打开网络的需求，这不仅方便，而且可以提高安全性。
- en: Managing the Hue platform with Kubernetes
  id: totrans-409
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 管理 Hue 平台
- en: 'In this section, we will look at how Kubernetes can help operate a huge platform
    such as Hue. Kubernetes itself provides a lot of capabilities to orchestrate pods
    and manage quotas and limits, detecting and recovering from certain types of generic
    failures (hardware malfunctions, process crashes, and unreachable services). But,
    in a complicated system such as Hue, pods and services may be up and running but
    in an invalid state or waiting for other dependencies in order to perform their
    duties. This is tricky because if a service or pod is not ready yet but is already
    receiving requests, then you need to manage it somehow: fail (puts responsibility
    on the caller), retry (how many times? for how long? how often?), and queue for
    later (who will manage this queue?).'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将探讨 Kubernetes 如何帮助运营像 Hue 这样的巨大平台。Kubernetes 本身提供了很多能力来编排 Pod 并管理配额和限制，检测和恢复某些类型的通用故障（硬件故障、进程崩溃和无法访问的服务）。但是，在像
    Hue 这样的复杂系统中，Pod 和服务可能已经启动并运行，但处于无效状态，或者正在等待其他依赖项才能执行其职能。这很棘手，因为如果一个服务或 Pod 尚未准备好，但已经在接收请求，那么你需要以某种方式进行管理：失败（责任转移给调用者）、重试（重试多少次？多长时间？多频繁？），以及稍后排队（谁来管理这个队列？）。
- en: It is often better if the system at large can be aware of the readiness state
    of different components, or if components are visible only when they are truly
    ready. Kubernetes doesn’t know Hue, but it provides several mechanisms such as
    liveness probes, readiness probes, startup probes, and init containers to support
    application-specific management of your cluster.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 如果整个系统能够了解不同组件的就绪状态，或者仅当组件真正就绪时才对外可见，这通常会更好。Kubernetes 不了解 Hue，但它提供了几种机制，如活性探针、就绪探针、启动探针和初始化容器，以支持针对应用程序的集群管理。
- en: Using liveness probes to ensure your containers are alive
  id: totrans-412
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用活性探针确保容器存活
- en: 'The kubelet watches over your containers. If a container process crashes, the
    kubelet will take care of it based on the restart policy. But this is not enough
    in many cases. Your process may not crash but instead run into an infinite loop
    or a deadlock. The restart policy might not be nuanced enough. With a liveness
    probe, you get to decide when a container is considered alive. If a liveness probe
    fails, Kubernetes will restart your container. Here is a pod template for the
    Hue music service. It has a `livenessProbe` section, which uses the `httpGet`
    probe. An HTTP probe requires a scheme (`http` or `https`, default to `http`),
    a host (default to `PodIp`), a path, and a port. The probe is considered successful
    if the HTTP status is between `200` and `399`. Your container may need some time
    to initialize, so you can specify an `initialDelayInSeconds`. The kubelet will
    not hit the liveness check during this period:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: kubelet 负责监控你的容器。如果容器进程崩溃，kubelet 会根据重启策略处理它。但在许多情况下，这还不够。你的进程可能不会崩溃，而是陷入死循环或死锁中。重启策略可能不够精细。通过存活探针，你可以决定容器何时被视为存活的。如果存活探针失败，Kubernetes
    会重启你的容器。这里是一个 Hue 音乐服务的 pod 模板。它有一个 `livenessProbe` 部分，使用 `httpGet` 探针。HTTP 探针需要一个方案（`http`
    或 `https`，默认是 `http`）、一个主机（默认是 `PodIp`）、一个路径和一个端口。如果 HTTP 状态码在 `200` 到 `399` 之间，则认为探针成功。你的容器可能需要一些时间来初始化，因此你可以指定
    `initialDelayInSeconds`。在此期间，kubelet 不会进行存活检查：
- en: '[PRE78]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE78]'
- en: If a liveness probe fails for any container, then the pod’s restart policy goes
    into effect. Make sure your restart policy is not `Never`, because that will make
    the probe useless.
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 如果任何容器的存活探针失败，那么 pod 的重启策略将生效。确保你的重启策略不是 `Never`，因为那样会使探针失效。
- en: 'There are three other types of liveness probes:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 还有三种其他类型的存活探针：
- en: '`TcpSocket` – Just checks that a port is open'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`TcpSocket` – 只是检查端口是否打开'
- en: '`Exec` – Runs a command that returns 0 for success'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Exec` – 运行一个返回 0 表示成功的命令'
- en: '`gRPC` – Follows the gRPC health-checking protocol ([https://github.com/grpc/grpc/blob/master/doc/health-checking.md](https://github.com/grpc/grpc/blob/master/doc/health-checking.md))'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gRPC` – 遵循 gRPC 健康检查协议 ([https://github.com/grpc/grpc/blob/master/doc/health-checking.md](https://github.com/grpc/grpc/blob/master/doc/health-checking.md))'
- en: Using readiness probes to manage dependencies
  id: totrans-420
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用就绪探针来管理依赖关系
- en: Readiness probes are used for a different purpose. Your container may be up
    and running and pass its liveness probe, but it may depend on other services that
    are unavailable at the moment. For example, `hue-music` may depend on access to
    a data service that contains your listening history. Without access, it is unable
    to perform its duties. In this case, other services or external clients should
    not send requests to the `hue-music` service, but there is no need to restart
    it. Readiness probes address this use case. When a readiness probe fails for a
    container, the container’s pod will be removed from any service endpoint it is
    registered with. This ensures that requests don’t flood services that can’t process
    them. Note that you can also use readiness probes to temporarily remove pods that
    are overbooked until they drain some internal queue.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪探针用于不同的目的。你的容器可能已经启动并运行，并通过了存活探针，但它可能依赖于当前不可用的其他服务。例如，`hue-music` 可能依赖于访问包含你听歌历史的数据服务。如果没有访问权限，它将无法履行职责。在这种情况下，其他服务或外部客户端不应向
    `hue-music` 服务发送请求，但无需重启它。就绪探针解决了这一用例。当容器的就绪探针失败时，该容器的 pod 会从它注册的任何服务端点中移除。这确保了不会向无法处理请求的服务发送请求。请注意，你还可以使用就绪探针暂时移除过度预订的
    pods，直到它们清空一些内部队列。
- en: 'Here is a sample readiness probe. I use the `exec` probe here to execute a
    custom command. If the command exits a non-zero exit code, the container will
    be torn down:'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个示例就绪探针。我在这里使用 `exec` 探针来执行一个自定义命令。如果命令退出时返回非零的退出码，容器将被销毁：
- en: '[PRE79]'
  id: totrans-423
  prefs: []
  type: TYPE_PRE
  zh: '[PRE79]'
- en: It is fine to have both a readiness probe and a liveness probe on the same container
    as they serve different purposes.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一个容器上同时使用就绪探针和存活探针是可以的，因为它们有不同的目的。
- en: Using startup probes
  id: totrans-425
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用启动探针
- en: Some applications (mostly legacy) may have long initialization periods. In this
    case, liveness probes may fail and cause the container to restart before it finishes
    initialization. This is where startup probes come in. If a startup probe is configured,
    liveness and readiness checks are skipped until the startup is completed. At this
    point, the startup probe is not invoked anymore and normal liveness and readiness
    probes take over.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 一些应用程序（主要是遗留应用程序）可能具有较长的初始化周期。在这种情况下，活跃性探针可能会失败，并导致容器在完成初始化之前重新启动。这就是启动探针发挥作用的地方。如果配置了启动探针，则会跳过活跃性和就绪性检查，直到启动完成。此时，启动探针不再被调用，正常的活跃性和就绪性探针接管。
- en: 'For example, in the following configuration snippet, the startup probe will
    check for 5 minutes every 10 seconds if the container has started (using the same
    liveness check as the liveness probe). If the startup probe fails 30 times (300
    seconds = 5 minutes) then the container will be restarted and get 5 more minutes
    to try and initialize itself. But, if it passes the startup probe check within
    5 minutes, then the liveness probe is in effect and any failure of the liveness
    check will result in a restart:'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，在以下配置片段中，启动探针每10秒检查5分钟，以确定容器是否已启动（使用与活跃探针相同的检查）。如果启动探针失败30次（300秒 = 5分钟），则容器将被重新启动，并获得额外的5分钟来尝试初始化自身。但是，如果在5分钟内通过了启动探针的检查，则活跃探针生效，任何活跃检查失败将导致重新启动：
- en: '[PRE80]'
  id: totrans-428
  prefs: []
  type: TYPE_PRE
  zh: '[PRE80]'
- en: Employing init containers for orderly pod bring-up
  id: totrans-429
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用初始化容器有序地启动Pod
- en: Liveness, readiness, and startup probes are great. They recognize that, at startup,
    there may be a period where the container is not ready yet, but shouldn’t be considered
    failed. To accommodate that, there is the `initialDelayInSeconds` setting where
    containers will not be considered failed. But, what if this initial delay is potentially
    very long? Maybe, in most cases, a container is ready after a couple of seconds
    and ready to process requests, but because the initial delay is set to 5 minutes
    just in case, we waste a lot of time when the container is idle. If the container
    is part of a high-traffic service, then many instances can all sit idle for five
    minutes after each upgrade and pretty much make the service unavailable.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 活跃性、就绪性和启动探针非常重要。它们认识到，在启动过程中，容器可能尚未就绪，但不应视为失败。为了适应这一点，有一个`initialDelayInSeconds`设置，容器在此期间不会被视为失败。但是，如果这个初始延迟可能非常长怎么办？也许在大多数情况下，容器几秒钟后即可准备好并且可以处理请求，但由于初始延迟设置为5分钟以防万一，我们在容器空闲时浪费了大量时间。如果容器是高流量服务的一部分，那么每次升级后许多实例都可能在空闲5分钟后坐等，几乎使服务不可用。
- en: Init containers address this problem. A pod may have a set of init containers
    that run to completion before other containers are started. An init container
    can take care of all the non-deterministic initialization and let application
    containers with their readiness probe have a minimal delay.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化容器解决了这个问题。一个Pod可以有一组初始化容器在其他容器启动之前运行完成。初始化容器可以处理所有非确定性初始化，并让带有其就绪探针的应用容器具有最小的延迟。
- en: Init containers are especially useful for pod-level initialization purposes
    like waiting for volumes to be ready. There is some overlap between init containers
    and startup probes and the choice depends on the specific use case.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化容器特别适用于Pod级别的初始化任务，例如等待卷准备就绪。初始化容器和启动探针之间有些重叠，选择取决于具体的用例。
- en: 'Init containers came out of beta in Kubernetes 1.6\. You specify them in the
    pod spec as the `initContainers` field, which is very similar to the `containers`
    field. Here is an example:'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 初始化容器在Kubernetes 1.6中退出了beta版。您可以在Pod规范中指定它们作为`initContainers`字段，这与`containers`字段非常相似。以下是一个示例：
- en: '[PRE81]'
  id: totrans-434
  prefs: []
  type: TYPE_PRE
  zh: '[PRE81]'
- en: Pod readiness and readiness gates
  id: totrans-435
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pod的就绪性和就绪性门
- en: Pod readiness was introduced in Kubernetes 1.11 and became stable in Kubernetes
    1.14\. While readiness probes allow you to determine at the container level if
    it’s ready to serve requests, the overall infrastructure that supports delivering
    traffic to the pod might not be ready yet. For example, the service, network policy,
    and load balancer might take some extra time. This can be a problem, especially
    during rolling deployments where Kubernetes might terminate the old pods before
    the new pods are really ready, which will cause degradation in service capacity
    and even cause a service outage in extreme cases (all old pods were terminated
    and no new pod is fully ready).
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 就绪性是在 Kubernetes 1.11 中引入的，并在 Kubernetes 1.14 中变得稳定。尽管就绪探针允许你在容器级别判断其是否准备好处理请求，但支持将流量传递到
    pod 的整体基础设施可能尚未准备好。例如，服务、网络策略和负载均衡器可能需要一些额外的时间。这可能会成为一个问题，尤其是在滚动部署期间，Kubernetes
    可能在新 pod 真的准备好之前就终止旧 pod，这将导致服务容量下降，甚至在极端情况下引发服务中断（所有旧 pod 被终止且没有新的 pod 完全准备好）。
- en: 'This is the problem that the pod readiness gates address. The idea is to extend
    the concept of pod readiness to check additional conditions in addition to making
    sure all the containers are ready. This is done by adding a new field to the `PodSpec`
    called `readinessGates`. You can specify a set of conditions that must be satisfied
    for the pod to be considered ready. In the following example, the pod is not ready
    because the `www.example.com/feature-1` condition has the `status: False`:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '这就是 pod 就绪性门控所解决的问题。其思路是将 pod 就绪性的概念扩展到检查额外的条件，而不仅仅是确保所有容器都已就绪。这是通过在 `PodSpec`
    中添加一个新的字段 `readinessGates` 来实现的。你可以指定一组必须满足的条件，才能将 pod 视为已准备好。在以下示例中，由于 `www.example.com/feature-1`
    条件的 `status: False`，该 pod 还未就绪：'
- en: '[PRE82]'
  id: totrans-438
  prefs: []
  type: TYPE_PRE
  zh: '[PRE82]'
- en: Sharing with DaemonSet pods
  id: totrans-439
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 与 DaemonSet pod 共享
- en: DaemonSet pods are pods that are deployed automatically, one per node (or a
    designated subset of the nodes). They are typically used for keeping an eye on
    nodes and ensuring they are operational. This is a very important function, which
    we will cover in *Chapter 13*, *Monitoring Kubernetes Clusters*. But they can
    be used for much more. The nature of the default Kubernetes scheduler is that
    it schedules pods based on resource availability and requests. If you have lots
    of pods that don’t require a lot of resources, similarly many pods will be scheduled
    on the same node.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: DaemonSet pod 是自动部署的 pod，每个节点（或指定的节点子集）上部署一个。它们通常用于监视节点并确保它们处于正常工作状态。这是一个非常重要的功能，我们将在*第13章*，*Kubernetes
    集群监控*中详细讨论。但它们也可以用于更多其他功能。默认的 Kubernetes 调度器的特点是，它根据资源可用性和请求来调度 pod。如果你有很多不需要大量资源的
    pod，那么这些 pod 很可能会被调度到同一个节点上。
- en: Let’s consider a pod that performs a small task and then, every second, sends
    a summary of all its activities to a remote service. Now, imagine that, on average,
    50 of these pods are scheduled on the same node. This means that, every second,
    50 pods make 50 network requests with very little data. How about we cut it down
    by 50× to just a single network request? With a `DaemonSet` pod, all the other
    50 pods can communicate with it instead of talking directly to the remote service.
    The `DaemonSet` pod will collect all the data from the 50 pods and, once a second,
    will report it in aggregate to the remote service. Of course, that requires the
    remote service API to support aggregate reporting. The nice thing is that the
    pods themselves don’t have to be modified; they will just be configured to talk
    to the `DaemonSet` pod on `localhost` instead of the remote service. The `DaemonSet`
    pod serves as an aggregating proxy. It can also implement retry and other similar
    functions.
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 假设有一个 pod 执行一个小任务，然后每秒将所有活动的总结发送到一个远程服务。现在，假设平均来说，50 个这样的 pod 会被调度到同一个节点上。这意味着每秒钟，50
    个 pod 会发起 50 次网络请求，每次请求的数据量非常小。如何将其减少 50 倍，仅发送一个网络请求呢？通过使用 `DaemonSet` pod，其他
    50 个 pod 可以与它通信，而不是直接与远程服务进行通信。`DaemonSet` pod 将从这 50 个 pod 收集所有数据，并每秒将其汇总报告到远程服务。当然，这要求远程服务的
    API 支持汇总报告。好的一点是，这些 pod 本身无需修改；它们只需配置为与 `DaemonSet` pod 在 `localhost` 上通信，而不是直接与远程服务通信。`DaemonSet`
    pod 充当了一个聚合代理。它还可以实现重试和其他类似功能。
- en: 'The interesting part about this configuration file is that the `hostNetwork`,
    `hostPID`, and `hostIPC` options are set to `true`. This enables the pods to communicate
    efficiently with the proxy, utilizing the fact they are running on the same physical
    host:'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: 这个配置文件的有趣之处在于，`hostNetwork`、`hostPID` 和 `hostIPC` 选项被设置为 `true`。这使得 pods 可以高效地与代理进行通信，利用它们运行在同一个物理主机上的事实：
- en: '[PRE83]'
  id: totrans-443
  prefs: []
  type: TYPE_PRE
  zh: '[PRE83]'
- en: In this section, we looked at how to manage the Hue platform on Kubernetes and
    ensure that Hue components are deployed reliably and accessed when they are ready
    using capabilities such as init containers, readiness gates, and DaemonSets. In
    the next section, we’ll see where the Hue platform could potentially go in the
    future.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了如何在 Kubernetes 上管理 Hue 平台，并确保 Hue 组件在准备好时能够可靠地部署和访问，利用诸如初始化容器、就绪门和
    DaemonSets 等功能。在接下来的章节中，我们将讨论 Hue 平台未来可能的发展方向。
- en: Evolving the Hue platform with Kubernetes
  id: totrans-445
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 用 Kubernetes 发展 Hue 平台
- en: In this section, we’ll discuss other ways to extend the Hue platform and service
    additional markets and communities. The question is always, what Kubernetes features
    and capabilities can we use to address new challenges or requirements?
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论扩展 Hue 平台并服务于其他市场和社区的其他方式。问题总是，哪些 Kubernetes 功能和能力可以帮助我们应对新的挑战或需求？
- en: This is a hypothetical section for thinking big and using Hue as an example
    of a massively complicated system.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个假设性章节，旨在从宏观角度思考，使用 Hue 作为一个复杂系统的例子。
- en: Utilizing Hue in an enterprise
  id: totrans-448
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在企业中使用 Hue
- en: An enterprise often can’t run in the cloud, either due to security and compliance
    reasons or for performance reasons because the system has to work with data and
    legacy systems that are not cost-effective to move to the cloud. Either way, Hue
    for enterprise must support on-premises clusters and/or bare-metal clusters.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: 企业通常无法在云端运行，可能是出于安全性和合规性原因，或是由于性能原因，因为系统必须与不适合迁移到云端的数据和遗留系统进行协作。无论如何，企业版的 Hue
    必须支持本地集群和/或裸金属集群。
- en: While Kubernetes is most often deployed in the cloud and even has a special
    cloud-provider interface, it doesn’t depend on the cloud and can be deployed anywhere.
    It does require more expertise, but enterprise organizations that already run
    systems on their own data centers may have that expertise or develop it.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Kubernetes 最常在云端部署，并且拥有专门的云服务提供商接口，但它并不依赖于云环境，可以在任何地方部署。它确实需要更多的专业知识，但那些已经在自己数据中心运行系统的企业组织，可能拥有这样的专业知识或能培养出来。
- en: Advancing science with Hue
  id: totrans-451
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用 Hue 推动科学进步
- en: Hue is so great at integrating information from multiple sources that it would
    be a boon for the scientific community. Consider how Hue can help with multi-disciplinary
    collaboration between scientists from different disciplines.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: Hue 在集成来自多个来源的信息方面非常出色，对科学界来说将是一个巨大的福音。试想一下，Hue 如何帮助不同学科的科学家之间进行多学科的协作。
- en: A network of scientific communities might require deployment across multiple
    geographically distributed clusters. Enter multi-cluster Kubernetes. Kubernetes
    has this use case in mind and evolves its support. We will discuss it at length
    in *Chapter 11*, *Running Kubernetes on Multiple Clusters*.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 一个科学社区的网络可能需要在多个地理位置分布的集群之间进行部署。这时，便引入了多集群 Kubernetes。Kubernetes 考虑到了这一使用场景并不断发展其支持。我们将在*第十一章*，《在多个集群上运行
    Kubernetes》中详细讨论这一话题。
- en: Educating the kids of the future with Hue
  id: totrans-454
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 用 Hue 教育未来的孩子
- en: Hue can be utilized for education and provide many services to online education
    systems. But, privacy concerns may prevent deploying Hue for kids as a single,
    centralized system. One possibility is to have a single cluster, with namespaces
    for different schools. Another deployment option is that each school or county
    has its own Hue Kubernetes cluster. In the second case, Hue for education must
    be extremely easy to operate to cater to schools without a lot of technical expertise.
    Kubernetes can help a lot by providing self-healing and auto-scaling features
    and capabilities for Hue, to be as close to zero-administration as possible.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: Hue 可以用于教育，并为在线教育系统提供多种服务。然而，隐私问题可能会阻止将 Hue 部署为一个单一的集中式系统来服务于孩子们。一个可能的方案是设置一个集群，并为不同的学校配置命名空间。另一个部署选项是每个学校或县拥有自己的
    Hue Kubernetes 集群。在第二种情况下，Hue 在教育领域的应用必须非常易于操作，以适应那些没有太多技术专长的学校。Kubernetes 可以通过提供自愈和自动扩展的功能和能力，帮助
    Hue 尽可能接近零管理。
- en: Summary
  id: totrans-456
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we designed and planned the development, deployment, and management
    of the Hue platform – an imaginary omniscient and omnipotent system – built on
    microservice architecture. We used Kubernetes as the underlying orchestration
    platform, of course, and delved into many of its concepts and resources. In particular,
    we focused on deploying pods for long-running services as opposed to jobs for
    launching short-term or cron jobs, explored internal services versus external
    services, and also used namespaces to segment a Kubernetes cluster. We looked
    into the various workload scheduling mechanisms of Kubernetes. Then, we looked
    at the management of a large system such as Hue with liveness probes, readiness
    probes, startup probes, init containers, and daemon sets.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们设计并规划了Hue平台的开发、部署和管理——这是一个基于微服务架构构建的虚拟全知全能系统。我们使用Kubernetes作为底层编排平台，当然，并深入探讨了它的许多概念和资源。特别地，我们专注于为长期运行的服务部署pods，而不是为短期任务或定时任务部署jobs，探索了内部服务与外部服务的区别，还使用了命名空间来划分Kubernetes集群。我们研究了Kubernetes的各种工作负载调度机制。接着，我们探讨了如何通过存活探针、就绪探针、启动探针、初始化容器和守护进程集来管理像Hue这样的庞大系统。
- en: You should now feel comfortable architecting web-scale systems composed of microservices
    and understand how to deploy and manage them in a Kubernetes cluster.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该能够熟练地设计由微服务组成的Web规模系统，并理解如何在Kubernetes集群中部署和管理它们。
- en: In the next chapter, we will look into the super-important area of storage.
    Data is king, but it is often the least flexible element of the system. Kubernetes
    provides a storage model and many options for integrating with various storage
    solutions.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将探讨一个至关重要的领域——存储。数据是王者，但它通常是系统中最不灵活的部分。Kubernetes提供了一个存储模型，并提供了多种与各种存储解决方案集成的选项。
