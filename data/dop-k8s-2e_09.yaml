- en: Continuous Delivery
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持续交付
- en: 'At the beginning of this book, we started by containerizing our applications,
    orchestrating them with Kubernetes, persisting their data, and exposing our service
    to the outside world. Later, we gained more confidence in our services by setting
    up monitoring and logging, and we made them scale in and out in a fully automatic
    manner. We''d now like to set our service on course by delivering our latest features
    and improvements to our services continuously in Kubernetes. We''ll learn about
    the following topics in this chapter:'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的开头，我们通过容器化我们的应用程序，使用 Kubernetes 进行编排，持久化数据，并将服务暴露给外界。后来，我们通过设置监控和日志记录来增强对服务的信心，并使它们能够完全自动地进行扩展和缩减。现在，我们希望通过在
    Kubernetes 中持续交付最新的功能和改进来推动我们的服务。我们将在本章学习以下内容：
- en: Updating Kubernetes resources
  id: totrans-2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新 Kubernetes 资源
- en: Setting up a delivery pipeline
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置交付管道
- en: How to improve the deployment process
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何改进部署过程
- en: Updating resources
  id: totrans-5
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新资源
- en: '**Continuous Delivery** (**CD**), as we described in [Chapter 1](43698ec3-b595-4aa0-811a-111010763585.xhtml),
    *Introduction to DevOps*, is a set of operations including **Continuous Integration**
    (**CI**) and the ensuing deployment tasks. The CI flow is made up of elements
    such as version control systems, buildings, and different levels of validation,
    which aim to eliminate the effort to integrate every change in the main release
    line. Tools to implement functions are usually at the application layer, which
    might be independent to the underlying infrastructure. Even so, when it comes
    to the deployment part, understanding and dealing with infrastructure is still
    inevitable. Deployment tasks are tightly coupled with the platform our application
    is running on, no matter which practice, continuous delivery or continuous deployment,
    we''re implementing. For instance, in an environment where the software runs on
    baremetal or virtual machines, we''d utilize configuration management tools, orchestrators,
    and scripts to deploy our software. However, if we''re running our service on
    an application platform such as Heroku, or even in the serverless pattern, designing
    the deployment pipeline would be a totally different story. All in all, the goal
    of deployment tasks is about making sure our software works properly in the right
    places. In Kubernetes, it''s about knowing how to correctly update resources,
    in particular pods.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**持续交付**（**CD**），正如我们在[第1章](43698ec3-b595-4aa0-811a-111010763585.xhtml)《*DevOps简介*》中所描述的，是一组操作流程，包括**持续集成**（**CI**）和随后的部署任务。CI
    流程由版本控制系统、构建、不同级别的验证等元素组成，旨在消除将每个更改集成到主发布线中的工作量。实现这些功能的工具通常位于应用层，可能独立于底层基础设施。尽管如此，谈到部署部分时，理解和处理基础设施仍然是不可避免的。部署任务与我们的应用程序运行平台紧密耦合，无论我们实现的是持续交付还是持续部署。例如，在软件运行在裸机或虚拟机的环境中时，我们会利用配置管理工具、调度器和脚本来部署软件。然而，如果我们将服务运行在像
    Heroku 这样的应用平台，甚至是在无服务器模式下，设计部署管道将是完全不同的故事。总的来说，部署任务的目标是确保我们的软件在正确的地方正常运行。在 Kubernetes
    中，这意味着知道如何正确更新资源，特别是 Pods。'
- en: Triggering updates
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 触发更新
- en: 'In [Chapter 3](a5cf080a-372a-406e-bb48-019af313c676.xhtml), *Getting Started
    with Kubernetes*, we discussed the rolling update mechanism of the pods in a deployment.
    Let''s recap what happens after the update process is triggered:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第3章](a5cf080a-372a-406e-bb48-019af313c676.xhtml)《*Kubernetes入门*》中，我们讨论了部署中
    Pods 的滚动更新机制。让我们回顾一下更新过程触发后的发生情况：
- en: The deployment creates a new `ReplicaSet` with `0` pods, according to the updated
    manifest
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署会根据更新后的清单创建一个新的 `ReplicaSet`，其初始状态为 `0` 个 Pods
- en: The new `ReplicaSet` is scaled up gradually while the previous `ReplicaSet`
    keeps shrinking
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 新的 `ReplicaSet` 会逐渐扩展，而之前的 `ReplicaSet` 会逐渐缩小
- en: The process ends after all of the old pods are replaced
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该过程在所有旧的 Pods 被替换后结束
- en: 'This mechanism is implemented automatically by Kubernetes, meaning we don''t
    have to supervise the updating process. To trigger it, all we need to do is inform
    Kubernetes that the pod specification of a deployment is updated; that is to say,
    we modify the manifest of a resource in Kubernetes. Suppose we have a deployment, `my-app`
    (see `ex-deployment.yml` under the example directory for this section), we can
    modify the manifest with the sub–commands of `kubectl` as follows:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这一机制由 Kubernetes 自动实现，这意味着我们不需要监督更新过程。触发它所需做的只是通知 Kubernetes 部署的 pod 规格已更新；也就是说，我们修改
    Kubernetes 资源的清单。例如，假设我们有一个名为 `my-app` 的部署（可以参见本节示例目录下的 `ex-deployment.yml`），我们可以通过
    `kubectl` 的子命令来修改清单，如下所示：
- en: '`kubectl patch`: This patches a manifest of an object partially according to
    the input JSON parameter. If we''d like to update the image of `my-app` from `alpine:3.7` to
    `alpine:3.8`, it''d be as follows:'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl patch`：这会根据输入的 JSON 参数部分地更新对象的清单。如果我们想将 `my-app` 的镜像从 `alpine:3.7`
    更新到 `alpine:3.8`，可以按如下方式操作：'
- en: '[PRE0]'
  id: totrans-14
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '`kubectl set`: This makes changes to certain properties of an object. This
    is a shortcut to change some properties directly. The image of `deployment` is
    one of the properties it supports:'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl set`：此命令修改对象的某些属性。这是直接更改某些属性的快捷方式。`deployment` 的镜像就是它支持的属性之一：'
- en: '[PRE1]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`kubectl edit`: This opens an editor and dumps the current manifest so that
    we can edit it interactively. The modified manifest will take effect immediately
    after being saved. To change the default editor for this command, use the `EDITOR` environment
    variable. For example, `EDITOR`="`code --wait`" kubectl edit deployments my-app
    opens Visual Studio Code.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl edit`：此命令打开编辑器并显示当前的清单，以便我们可以交互式地进行编辑。修改后的清单将在保存后立即生效。要更改此命令的默认编辑器，可以使用
    `EDITOR` 环境变量。例如，`EDITOR="`code --wait`" kubectl edit deployments my-app` 会打开
    Visual Studio Code。'
- en: '`kubectl replace`: This replaces one manifest with another submitted template
    file. If a resource isn''t created yet or contains properties that can''t be changed,
    it yields errors. For instance, there are two resources in our example template, `ex-deployment.yml`,
    namely the deployment, `my-app`, and its `Service`, `my-app-svc`. Let''s replace
    them with a new specification file:'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl replace`：此命令用另一个提交的模板文件替换一个清单。如果资源尚未创建，或者包含无法更改的属性，则会报错。例如，在我们的示例模板
    `ex-deployment.yml` 中有两个资源，分别是部署 `my-app` 和其 `Service` `my-app-svc`。我们可以用新的规范文件来替换它们：'
- en: '[PRE2]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: After they're replaced, we see that the error code is `1` as expected, so we
    are updating `deployment` rather than `Service`. This behavior is particularly
    important when composing automation scripts for the CI/CD flow.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 替换后，我们看到错误代码是 `1`，符合预期，因此我们正在更新的是 `deployment` 而不是 `Service`。这种行为在编写 CI/CD 流程的自动化脚本时尤为重要。
- en: '`kubectl apply`: This applies the manifest file anyway. In other words, if
    a resource exists in Kubernetes, it''d be updated; otherwise, it''d be created.
    When `kubectl apply` is used to create resources, it is roughly equal to `kubectl
    create --save-config` in terms of functionality. The applied specification file
    would be saved to the annotation field, `kubectl.kubernetes.io/last-applied- configuration`,
    accordingly, and we can manipulate it with the sub-commands `edit-last-applied`, `set-last-applied`,
    and `view-last-applied`. For example, we can view the template we submitted previously
    with the following:'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl apply`：此命令会应用清单文件。换句话说，如果资源已存在于 Kubernetes 中，它将被更新；否则，将会创建资源。当 `kubectl
    apply` 用来创建资源时，它在功能上大致等同于 `kubectl create --save-config`。应用的规格文件会被保存到注释字段 `kubectl.kubernetes.io/last-applied-configuration`
    中，我们可以通过子命令 `edit-last-applied`、`set-last-applied` 和 `view-last-applied` 对其进行操作。例如，我们可以通过以下命令查看之前提交的模板：'
- en: '[PRE3]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The saved manifest information will be exactly the same as what we've sent,
    unlike the information we retrieve via `kubectl get <resource> -o <yaml or json>`,
    which contains an object's live status, in addition to specifications.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 保存的清单信息将与我们发送的完全相同，区别在于通过 `kubectl get <resource> -o <yaml or json>` 获取的信息包含对象的实时状态，而不仅仅是规格。
- en: Although in this section we are only focusing on manipulating a deployment,
    the commands here also work for updating all other Kubernetes resources, such
    as `service` and `role`.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在本节中我们仅关注操作部署，但这些命令同样适用于更新其他所有 Kubernetes 资源，如 `service` 和 `role`。
- en: Depending on the convergence speed of `etcd`, changes to `ConfigMap` and `secret`
    usually take a couple of seconds to propagate to pods.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 `etcd` 的汇聚速度，`ConfigMap` 和 `secret` 的更改通常需要几秒钟才能传播到 pods。
- en: 'The recommended way to interact with a Kubernetes API server is by using `kubectl`.
    If you''re in a confined environment or you want to implement your own operator
    controllers, there are also RESTful APIs for manipulating resources in Kubernetes.
    For instance, the `kubectl patch` command we used before would look as follows:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 与Kubernetes API服务器交互的推荐方式是使用`kubectl`。如果你处于受限环境中，或者想实现自己的操作控制器，也可以使用Kubernetes的RESTful
    API来操作资源。例如，我们之前使用的`kubectl patch`命令如下所示：
- en: '[PRE4]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Here, the `$KUBEAPI` variable is the endpoint of the API server. See the API
    reference material for more information: [https://kubernetes.io/docs/reference/kubernetes-api/](https://kubernetes.io/docs/reference/kubernetes-api/).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，`$KUBEAPI`变量是API服务器的端点。更多信息请参见API参考资料：[https://kubernetes.io/docs/reference/kubernetes-api/](https://kubernetes.io/docs/reference/kubernetes-api/)。
- en: Managing rollouts
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理滚动更新
- en: 'Once the rollout process is triggered, Kubernetes silently completes all tasks
    in the background. Let''s try some hands-on experiments. Again, the rolling update
    process won''t be triggered even if we''ve modified something with the commands
    mentioned earlier, unless the associated pod''s specification is changed. The
    example we prepared is a simple script that will respond to any request with its
    hostname and the Alpine version it runs on. First, we create `deployment` and
    check its response in another Terminal:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦触发部署过程，Kubernetes会在后台默默完成所有任务。让我们进行一些动手实验。再次提醒，即使我们用之前提到的命令修改了某些内容，滚动更新过程也不会被触发，除非相关Pod的规格发生变化。我们准备的示例是一个简单的脚本，它会用其主机名和运行的Alpine版本响应任何请求。首先，我们创建`deployment`并在另一个终端中检查其响应：
- en: '[PRE5]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, we change its image to another version and see what the responses are:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将其镜像更改为另一个版本，并查看响应：
- en: '[PRE6]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Messages from version 3.7 and 3.8 are interleaved until the updating process
    ends. In order to immediately determine the status of updating processes from
    Kubernetes, rather than polling the service endpoint, we can use `kubectl rollout`
    to manage the rolling update process, including inspecting the progress of ongoing
    updates. Let''s see the acting `rollout` with the `status` sub-command:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 版本3.7和3.8的消息交替显示，直到更新过程结束。为了立即确定Kubernetes中的更新进程状态，而不是轮询服务端点，我们可以使用`kubectl
    rollout`来管理滚动更新过程，包括检查正在进行的更新进度。让我们使用`status`子命令查看当前的`rollout`状态：
- en: '[PRE7]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'At this moment, the output at `terminal#2` should be from version 3.6\. The `history`
    sub-command allows us to review previous changes to `deployment`:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，`terminal#2`的输出应该来自版本3.6。`history`子命令允许我们查看之前对`deployment`所做的更改：
- en: '[PRE8]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: However, the `CHANGE-CAUSE` field doesn't show any useful information that helps
    us to see the details of the revision. To profit from the rollout history feature,
    add a `--record` flag after each command that leads to a change, such as `apply` or
    `patch`. `kubectl create` also supports the `record` flag.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，`CHANGE-CAUSE`字段并没有显示出任何有助于我们查看修订详情的有用信息。为了利用滚动更新历史功能，在每个导致更改的命令后添加`--record`标志，如`apply`或`patch`。`kubectl
    create`也支持`record`标志。
- en: 'Let''s make some changes to the `deployment`, such as modifying the `DEMO`
    environment variable on pods in `my-app`. As this causes a change in the pod''s
    specification, `rollout` will start right away. This sort of behavior allows us
    to trigger an update without building a new image. For simplicity, we use `patch`
    to modify the variable:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们对`deployment`做一些更改，例如修改`my-app`中Pod的`DEMO`环境变量。由于这会导致Pod规格发生变化，`rollout`将立即启动。这种行为使我们能够在不构建新镜像的情况下触发更新。为了简化，我们使用`patch`来修改变量：
- en: '[PRE9]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`CHANGE-CAUSE` of `REVISION 3` notes the committed command clearly. Only the
    command will be recorded, which means that any modification inside `edit`/`apply`/`replace`
    won''t be marked down explicitly. If we want to get the manifest of the former
    revisions, we could retrieve the saved configuration, as long as our changes are
    made with `apply`.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`REVISION 3`的`CHANGE-CAUSE`清楚地记录了提交的命令。只有命令会被记录，这意味着任何在`edit`/`apply`/`replace`中的修改不会被明确标记。如果我们想获取之前版本的清单，可以检索已保存的配置，只要我们的更改是通过`apply`完成的。'
- en: The `CHANGE-CAUSE` field is actually stored in the `kubernetes.io/change-cause`
    annotation of an object.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`CHANGE-CAUSE`字段实际上存储在对象的`kubernetes.io/change-cause`注释中。'
- en: 'For various reasons, we sometimes want to roll back our application even if
    the `rollout` is successful to a certain extent. This can be achieved with the
    `undo` sub-command :'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 出于各种原因，我们有时希望即使`rollout`已经成功到一定程度，也能回滚我们的应用。这可以通过`undo`子命令实现：
- en: '[PRE10]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The whole process is basically identical to updating—that is, applying the previous
    manifest—and performing a rolling update. We can also utilize the `--to-revision=<REVISION#>`
    flag to roll back to a specific version, but only retained revisions are able
    to be rolled back. Kubernetes determines how many revisions it keeps according
    to the `revisionHistoryLimit` parameter in the `deployment` object.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 整个过程基本上与更新相同——也就是应用之前的清单——并执行滚动更新。我们还可以使用`--to-revision=<REVISION#>`标志回滚到特定版本，但只有保留的修订版本才能回滚。Kubernetes根据`deployment`对象中的`revisionHistoryLimit`参数来确定保留多少个修订版本。
- en: The progress of an update is controlled by `kubectl rollout pause` and `kubectl
    rollout resume`. As their names indicate, they should be used in pairs. Pausing
    a deployment involves not only stopping an ongoing `rollout`, but also freezing
    any triggering of updates even if the specification is modified, unless it's resumed.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 更新的进度由`kubectl rollout pause`和`kubectl rollout resume`控制。顾名思义，它们应该成对使用。暂停一个部署不仅仅是停止正在进行的`rollout`，还包括冻结任何更新触发，即使规格被修改，除非被恢复。
- en: Updating DaemonSet and StatefulSet
  id: totrans-47
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新DaemonSet和StatefulSet
- en: Kubernetes supports various ways to orchestrate pods for different types of
    workloads. In addition to deployments, we also have `DaemonSet` and `StatefulSet`
    for long-running and non-batch workloads. As pods spawned by these have more constraints
    than the ones from deployments, there are a few caveats that we need to be aware
    of in order to handle their updates.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes支持多种方式来编排不同类型工作负载的pods。除了部署外，我们还可以使用`DaemonSet`和`StatefulSet`来处理长期运行和非批量工作负载。由于这些pods相对于部署的pods有更多的约束，因此我们需要注意一些事项，以便正确处理它们的更新。
- en: DaemonSet
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DaemonSet
- en: '`DaemonSet` is a controller designed for system daemons, as its name suggests.
    Consequently, a `DaemonSet` controller launches and maintains exactly one pod
    per node; the total number of pods launched by a `DaemonSet` controller adheres to
    the number of nodes in a cluster. Due to this limitation, updating `DaemonSet`
    isn''t as straightforward as updating a deployment. For instance, `deployment`
    has a `maxSurge` parameter (`.spec.strategy.rollingUpdate.maxSurge`) that controls
    how many redundant pods over the desired number can be created during updates,
    but we can''t employ the same strategy for pods managed by `DaemonSet`. Because
    daemon pods usually come with special concerns that might occupy a host''s resources,
    such as ports, it could result in errors if we have two or more system pods simultaneously
    on a node. As such, the update is in the form that a new pod is created after
    the old pod is terminated on a host.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`DaemonSet`是为系统守护进程设计的控制器，正如其名称所示。因此，`DaemonSet`控制器在每个节点上启动并维护一个pod；`DaemonSet`控制器启动的pod总数等于集群中的节点数。由于这个限制，更新`DaemonSet`不像更新部署那样直接。例如，`deployment`有一个`maxSurge`参数（`.spec.strategy.rollingUpdate.maxSurge`），用于控制更新过程中可以创建的超过期望数量的冗余pod数量，但我们不能对`DaemonSet`管理的pods使用相同的策略。因为守护进程pod通常涉及一些特殊问题，可能会占用主机资源，如端口，如果同一节点上有两个或多个系统pod同时存在，可能会导致错误。因此，更新的方式是先在主机上终止旧pod，再创建新pod。'
- en: 'Kubernetes implements two update strategies for `DaemonSet`:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes为`DaemonSet`实现了两种更新策略：
- en: '`OnDelete`: Pods are only updated after they are deleted manually.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OnDelete`：Pods只有在手动删除后才会更新。'
- en: '`RollingUpdate`: This works like `OnDelete`, but the deletion of pods is performed
    by Kubernetes automatically. There is one optional parameter, `.spec.updateStrategy.rollingUpdate.maxUnavailable`,
    which is similar to the one in `deployment`. Its default value is `1`, which means
    Kubernetes replaces one pod at a time, node by node.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RollingUpdate`：这与`OnDelete`类似，但pod的删除由Kubernetes自动执行。有一个可选参数`.spec.updateStrategy.rollingUpdate.maxUnavailable`，类似于`deployment`中的参数。默认值为`1`，意味着Kubernetes每次替换一个pod，逐节点进行。'
- en: You can find an example that demonstrates how to write a template of `DaemonSet` at [https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-1_updates/ex-daemonset.yml](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-1_updates/ex-daemonset.yml).
    The update strategy is set at the `.spec.updateStrategy.type` path, and its default
    is `RollingUpdate`. The way to trigger the rolling update is identical to the
    way in which we trigger a deployment. We can also utilize `kubectl rollout` to
    manage rollouts of our `DaemonSet` controller, but `pause` and `resume` aren't
    supported.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-1_updates/ex-daemonset.yml](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-1_updates/ex-daemonset.yml)找到一个示例，展示了如何编写`DaemonSet`模板。更新策略设置在`.spec.updateStrategy.type`路径下，其默认值是`RollingUpdate`。触发滚动更新的方式与触发部署的方式相同。我们还可以使用`kubectl
    rollout`来管理`DaemonSet`控制器的滚动更新，但`pause`和`resume`不受支持。
- en: StatefulSet
  id: totrans-55
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: StatefulSet
- en: 'The updating of `StatefulSet` and `DaemonSet` are pretty much the same; they
    don''t create redundant pods during an update and their update strategies also
    behave in a similar way. There''s a template file at `9-1_updates/ex-statefulset.yml` that
    you can use for practice. The options of the update strategy are set at the `.spec.updateStrategy.type` path:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`StatefulSet`和`DaemonSet`的更新过程基本相同；它们在更新过程中不会创建冗余的Pod，且更新策略的行为也类似。你可以在`9-1_updates/ex-statefulset.yml`文件中找到一个用于练习的模板。更新策略的选项设置在`.spec.updateStrategy.type`路径下：'
- en: '`OnDelete`: Pods are only updated after they''re manually deleted.'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OnDelete`：Pod只有在被手动删除后才会更新。'
- en: '`RollingUpdate`: Like rolling updates for other controllers, Kubernetes deletes
    and creates pods in a managed fashion. Kubernetes knows the order matters in `StatefulSet`,
    so it replaces pods in reverse order. Say we have three pods in `StatefulSet`: `my-ss-0`,
    `my-ss-1`, and `my-ss-2`. The update order will start at `my-ss-2` and run to
    `my-ss-0`. The deletion process doesn''t respect the pod management policy of `StatefulSet`;
    even if we set the pod management policies to `Parallel`, the updates would still
    be performed one by one.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RollingUpdate`：像其他控制器的滚动更新一样，Kubernetes以受控的方式删除和创建Pod。Kubernetes知道`StatefulSet`中的顺序很重要，因此它会逆序替换Pod。假设我们有三个Pod：`my-ss-0`、`my-ss-1`和`my-ss-2`，更新顺序将从`my-ss-2`开始，直到`my-ss-0`。删除过程不会遵循`StatefulSet`的Pod管理策略；即使我们将Pod管理策略设置为`Parallel`，更新仍然会按顺序一个一个地执行。'
- en: The only parameter for the `RollingUpdate` type is `partition` (`.spec.updateStrategy.rollingUpdate.partition`).
    If this is specified, any pod with an ordinal less than the partition number will
    keep its current version and won't be updated. For instance, if we set `partition`
    to `1` in a `StatefulSet` with three pods, only pod-1 and pod-2 would be updated
    after a rollout. This parameter allows us to control the progress to a certain
    extent and it's particularly handy for scenarios such as waiting for data synchronization,
    carrying out a canary test, or staging an update.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`RollingUpdate`类型的唯一参数是`partition`（`.spec.updateStrategy.rollingUpdate.partition`）。如果指定了该参数，则任何顺序编号小于分区号的Pod将保持当前版本，并不会更新。例如，如果我们在具有三个Pod的`StatefulSet`中将`partition`设置为`1`，那么在滚动更新后，只有pod-1和pod-2会被更新。这个参数允许我们在一定程度上控制进度，尤其适用于等待数据同步、执行金丝雀测试或进行分阶段更新等场景。'
- en: Building a delivery pipeline
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 构建交付管道
- en: 'Implementing a CD pipeline for containerized applications is quite simple.
    Let''s recall what practices we learned about Docker and Kubernetes so far and
    organize those practices into the CD pipeline. Suppose we''ve finished our code,
    Dockerfile, and corresponding Kubernetes templates. To deploy these to our cluster,
    we''d go through the following steps:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为容器化应用实现CD管道是非常简单的。让我们回顾一下到目前为止学到的关于Docker和Kubernetes的实践，并将这些实践组织成CD管道。假设我们已经完成了代码、Dockerfile和相应的Kubernetes模板。要将这些内容部署到集群中，我们需要按照以下步骤操作：
- en: '`docker build`: Produces an executable and immutable artifact'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`docker build`：生成一个可执行且不可变的构件'
- en: '`docker run`: Verifies whether the build works with a simple test'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`docker run`：通过简单的测试验证构建是否有效'
- en: '`docker tag`: Tags the build with meaningful versions if it''s good'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`docker tag`：如果构建正常，将其标记为具有有意义的版本'
- en: '`docker push`: Moves the build to the `artifacts` repository for distribution'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`docker push`：将构建移动到`artifacts`仓库以供分发'
- en: '`kubectl apply`: Deploys the build to a desired environment'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubectl apply`：将构建部署到目标环境'
- en: '`kubectl rollout status`: Tracks the progress of deployment tasks'
  id: totrans-67
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubectl rollout status`：跟踪部署任务的进度'
- en: This is all we need for a simple but viable delivery pipeline.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们所需的一个简单而可行的交付流水线。
- en: Here, we use the term continuous delivery instead of continuous deployment because
    there are still gaps between the steps described previously, which can be implemented
    as either human-controlled or fully automatic deployments. The consideration may
    differ from team to team.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们使用“持续交付”而不是“持续部署”这个术语，因为之前描述的步骤之间仍然存在一些差距，可以实现为人工控制或完全自动化的部署。这一考虑可能因团队而异。
- en: Choosing tools
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择工具
- en: The steps we're going to implement are quite simple. However, when it comes
    to chaining them as a pipeline, there's no generic pipeline that suits all scenarios.
    It might differ by factors such as the form of an organization, the development
    workflow a team is running, or the interaction between the pipeline and other
    systems in the existing infrastructure. In light of this, setting a goal and choosing
    tools are the first things we have to think about.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要实现的步骤非常简单。然而，当把它们作为流水线串联起来时，并没有一个适用于所有场景的通用流水线。它可能因组织形式、团队运行的开发工作流或流水线与现有基础设施中其他系统的交互等因素而有所不同。因此，设定目标并选择工具是我们必须考虑的首要事项。
- en: 'Generally speaking, to make the pipeline ship builds continuously, we''ll need
    at least three kinds of tools: version control systems, build servers, and a repository
    for storing container artifacts. In this section, we will set a reference CD pipeline
    based on the SaaS tools we introduced in previous chapters:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，为了让流水线持续发布构建，我们至少需要三类工具：版本控制系统、构建服务器和用于存储容器工件的代码库。在本节中，我们将基于之前章节中介绍的SaaS工具设置一个参考CD流水线：
- en: GitHub ([https://github.com](https://github.com))
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GitHub ([https://github.com](https://github.com))
- en: Travis CI ([https://travis-ci.com](https://travis-ci.com))
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Travis CI ([https://travis-ci.com](https://travis-ci.com))
- en: Docker Hub ([https://hub.docker.com](https://hub.docker.com))
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Hub ([https://hub.docker.com](https://hub.docker.com))
- en: All of these are free for open source projects. Certainly, there are numerous
    alternatives for each tool we used here, such as GitLab for VCS, hosting Jenkins
    for CI, or even dedicated deployment tools such as Spinnaker ([https://www.spinnaker.io/](https://www.spinnaker.io/)).
    In addition to these large building blocks, we can also benefit from tools such
    as Helm ([https://github.com/kubernetes/helm](https://github.com/kubernetes/helm))
    to help us to organize templates and their instantialized releases. All in all,
    it's up to you to choose the tools that best suit your needs. We'll focus on how
    these fundamental components interact with our deployments in Kubernetes.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些工具对于开源项目都是免费的。当然，每个工具都有很多替代方案，例如，GitLab用于版本控制系统（VCS），Jenkins托管用于CI，甚至专门的部署工具如Spinnaker ([https://www.spinnaker.io/](https://www.spinnaker.io/))。除了这些大型构建模块外，我们还可以借助Helm
    ([https://github.com/kubernetes/helm](https://github.com/kubernetes/helm))等工具来帮助我们组织模板及其实例化的发布。总而言之，选择最适合您需求的工具由您自己决定。我们将重点讨论这些基础组件如何与Kubernetes中的部署进行交互。
- en: End-to-end walk-through of the delivery pipeline
  id: totrans-77
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 交付流水线的端到端演练
- en: 'The following diagram is our CD flow based on the three services mentioned
    earlier:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了我们基于前述三个服务的CD流程：
- en: '![](img/964506b1-8d43-4d17-99bd-0af7675bde57.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![](img/964506b1-8d43-4d17-99bd-0af7675bde57.png)'
- en: 'The workflow for code integration is as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 代码集成的工作流程如下：
- en: Code is committed to a repository on GitHub.
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码被提交到GitHub上的一个代码库。
- en: 'The commit triggers a build job on Travis CI:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交触发Travis CI上的构建任务：
- en: A Docker image will be built.
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个Docker镜像将被构建。
- en: To ensure that the quality of the build is solid and ready to be integrated,
    different levels of tests are usually performed at this stage on the CI server.
    Furthermore, as running an application stack with Docker Compose or Kubernetes
    is easier than ever, running tests involving many components in a build job is
    also possible.
  id: totrans-84
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为确保构建质量稳固且准备好进行集成，通常在CI服务器上执行不同层次的测试。此外，由于使用Docker Compose或Kubernetes运行应用程序堆栈比以往任何时候都更加简便，因此在构建任务中运行涉及多个组件的测试也是可行的。
- en: The verified image is tagged with identifiers and pushed to Docker Hub.
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 经验证的镜像会被标记上标识符，并推送到Docker Hub。
- en: As for the deployment in Kubernetes, this can be as simple as updating the image
    path in a template and then applying the template to a production cluster, or
    as complex as a series of operations including traffic distribution and canary
    deployment. In our example, a rollout starts from manually publishing a new Git
    SemVer tag, and the CI script repeats the same flow as in the integration part
    until the image pushing step. As a CI server sometimes may not be able to touch
    the production environment, we put an agent inside our cluster to watch and apply
    the changes in the configuration branch.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 至于 Kubernetes 中的部署，这可以像在模板中更新镜像路径，然后将模板应用于生产集群那样简单，也可以像一系列操作，包括流量分配和金丝雀发布那样复杂。在我们的例子中，发布过程从手动发布一个新的
    Git SemVer 标签开始，CI 脚本重复与集成部分相同的流程，直到镜像推送步骤。由于 CI 服务器有时无法触及生产环境，我们在集群内放置了一个代理，来观察并应用配置分支中的更改。
- en: A dedicated config repository is a popular pattern for segregating an application
    and its infrastructure. There are many **Infrastructure as Code** (**IaC**) tools
    that help us to express infrastructure and their states in a way that can be recorded
    in a version control system. Additionally, by tracking everything in a version
    control system, we can translate every change made to the infrastructure into
    Git operations. For the sake of simplicity, we use another branch in the same
    repository for the config changes.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 专用的配置仓库是一种常见的模式，用于将应用程序及其基础设施分开。有许多**基础设施即代码**（**IaC**）工具帮助我们以可记录在版本控制系统中的方式表达基础设施及其状态。此外，通过在版本控制系统中追踪所有内容，我们可以将对基础设施所做的每个更改转化为
    Git 操作。为了简化起见，我们在同一个仓库中使用另一个分支来进行配置更改。
- en: Once the agent observes the change, it pulls the new template and updates the
    corresponding controller accordingly. Finally, the delivery is finished after
    the rolling update process of Kubernetes ends.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦代理检测到更改，它会拉取新的模板并相应地更新对应的控制器。最后，在 Kubernetes 滚动更新过程结束后，交付工作就完成了。
- en: The steps explained
  id: totrans-89
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解释步骤
- en: 'Our example, `okeydokey`, is a web service that always echoes `OK` to every
    request, and the code as well as the files for deployment are committed in our
    repository over in GitHub: [https://github.com/DevOps-with-Kubernetes/okeydokey](https://github.com/DevOps-with-Kubernetes/okeydokey).'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的例子 `okeydokey` 是一个始终对每个请求回显 `OK` 的 Web 服务，代码和部署文件已提交到 GitHub 上的仓库：[https://github.com/DevOps-with-Kubernetes/okeydokey](https://github.com/DevOps-with-Kubernetes/okeydokey)。
- en: Before configuring our builds on Travis CI, let's create an image repository
    in Docker Hub first for later use. After signing in to Docker Hub, press the huge
    Create Repository button at the top right, and then follow the steps onscreen
    to create one. The image repository of `okeydokey` is at `devopswithkubernetes/okeydokey` ([https://hub.docker.com/r/devopswithkubernetes/okeydokey/](https://hub.docker.com/r/devopswithkubernetes/okeydokey/)[)](https://hub.docker.com/r/devopswithkubernetes/my-app/).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在配置 Travis CI 构建之前，让我们先在 Docker Hub 上创建一个镜像仓库以供后续使用。在登录到 Docker Hub 后，点击右上角的“Create
    Repository”按钮，然后按照屏幕上的步骤创建一个仓库。`okeydokey` 的镜像仓库地址是 `devopswithkubernetes/okeydokey`（[https://hub.docker.com/r/devopswithkubernetes/okeydokey/](https://hub.docker.com/r/devopswithkubernetes/okeydokey/)）。
- en: Connecting Travis CI with a GitHub repository is quite simple; all we need to
    do is authorize Travis CI to access our GitHub repositories and enable it to build
    the repository in the settings page ([https://travis-ci.com/account/repositories](https://travis-ci.com/account/repositories)). Another
    thing we'll need is a GitHub access token or a deploy key that has write permission
    to our repository. This will be put on the Travis CI so that the CI script can
    update the built image back into the config branch. Please refer to the GitHub
    official documentation ([https://developer.github.com/v3/guides/managing-deploy-keys/#deploy-keys](https://developer.github.com/v3/guides/managing-deploy-keys/#deploy-keys))
    to obtain a deploy key.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 将 Travis CI 与 GitHub 仓库连接是非常简单的；我们需要做的就是授权 Travis CI 访问我们的 GitHub 仓库，并在设置页面启用其构建该仓库的功能（[https://travis-ci.com/account/repositories](https://travis-ci.com/account/repositories)）。另一个我们需要的东西是一个
    GitHub 访问令牌或具有写权限的部署密钥。这个密钥将被放置在 Travis CI 上，以便 CI 脚本能够将构建好的镜像更新到配置分支。请参考 GitHub
    官方文档（[https://developer.github.com/v3/guides/managing-deploy-keys/#deploy-keys](https://developer.github.com/v3/guides/managing-deploy-keys/#deploy-keys)）获取部署密钥。
- en: The definition of a job in Travis CI is configured in a file, `.travis.yml`,
    placed under the same repository. The definition is a YAML format template consisting
    of blocks of shell scripts that tell us what Travis CI should do during a build.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Travis CI 中作业的定义是在一个文件 `.travis.yml` 中配置的，该文件位于同一个仓库下。这个定义是一个 YAML 格式的模板，包含了一些
    Shell 脚本块，指示 Travis CI 在构建过程中应该执行什么操作。
- en: 'The full Travis CI document can be found here: [https://docs.travis-ci.com/user/tutorial/](https://docs.travis-ci.com/user/tutorial/).'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的 Travis CI 文档可以在这里找到：[https://docs.travis-ci.com/user/tutorial/](https://docs.travis-ci.com/user/tutorial/)。
- en: You can find explanations for the blocks of our `.travis.yml` file at the following
    URL: [https://github.com/DevOps-with-Kubernetes/okeydokey/blob/master/.travis.yml](https://github.com/DevOps-with-Kubernetes/okeydokey/blob/master/.travis.yml).
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下网址找到我们 `.travis.yml` 文件块的解释：[https://github.com/DevOps-with-Kubernetes/okeydokey/blob/master/.travis.yml](https://github.com/DevOps-with-Kubernetes/okeydokey/blob/master/.travis.yml)。
- en: env
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: env
- en: 'This section defines environment variables that are visible throughout a build:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 本节定义了在整个构建过程中可见的环境变量：
- en: '[PRE11]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Here, we set some variables that might be changed, such as the Docker registry
    path where the built image is heading. There''s also metadata about a build passed
    from Travis CI in the form of environment variables, which is documented here:
    [https://docs.travis-ci.com/user/environment-variables/#default-environment-variables](https://docs.travis-ci.com/user/environment-variables/#default-environment-variables).
    For example, `TRAVIS_COMMIT` represents the hash of the current commit, and we
    use it as an identifier to distinguish our images across builds.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们设置了一些可能会更改的变量，例如构建的镜像将要存储的 Docker 注册表路径。此外，还有从 Travis CI 传递过来的构建元数据，以环境变量的形式存在，具体文档可参考：[https://docs.travis-ci.com/user/environment-variables/#default-environment-variables](https://docs.travis-ci.com/user/environment-variables/#default-environment-variables)。例如，`TRAVIS_COMMIT`
    代表当前提交的哈希值，我们使用它作为标识符来区分不同构建的镜像。
- en: 'The other source of environment variables is configured manually on Travis
    CI. Because the variables configured there would be hidden from public view, we
    stored some sensitive data such as credentials for Docker Hub and our GitHub repository
    there:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个环境变量的来源是手动在 Travis CI 上配置的。由于这些变量在配置后会被隐藏，因此我们把一些敏感数据，如 Docker Hub 和 GitHub
    仓库的凭证，存储在这里：
- en: '![](img/0cb129a6-81d7-4e69-a05c-7a15663db0c8.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/0cb129a6-81d7-4e69-a05c-7a15663db0c8.png)'
- en: Every CI tool has its own best practices to deal with secrets. For instance,
    some CI tools also allow us to save variables in the CI server, but these are
    still printed in the building logs, so we're unlikely to save secrets there in
    such cases.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 CI 工具都有其处理机密信息的最佳实践。例如，一些 CI 工具还允许我们将变量保存在 CI 服务器中，但这些变量仍然会打印在构建日志中，因此在这种情况下我们不太可能将机密信息存储在这里。
- en: Key management systems such as Vault ([https://www.vaultproject.io/](https://www.vaultproject.io/)) or
    similar services by cloud providers such as GCP KMS ([https://cloud.google.com/kms/](https://cloud.google.com/kms/)),
    AWS KMS ([https://aws.amazon.com/kms/](https://aws.amazon.com/kms/)), and Azure
    Key Vault ([https://azure.microsoft.com/en-us/services/key-vault/](https://azure.microsoft.com/en-us/services/key-vault/)),
    are recommended for storing sensitive credentials.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 像 Vault（[https://www.vaultproject.io/](https://www.vaultproject.io/)）这样的密钥管理系统，或云服务商提供的类似服务，如
    GCP KMS（[https://cloud.google.com/kms/](https://cloud.google.com/kms/)）、AWS KMS（[https://aws.amazon.com/kms/](https://aws.amazon.com/kms/)）和
    Azure Key Vault（[https://azure.microsoft.com/en-us/services/key-vault/](https://azure.microsoft.com/en-us/services/key-vault/)）都推荐用于存储敏感凭证。
- en: script
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: script
- en: 'This section is where we run builds and tests:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 本节是我们运行构建和测试的地方：
- en: '[PRE12]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: As we're on Docker, the build only takes up one line of script. Our test is
    quite simple; it involves launching a container with the built image and making
    some requests to determine its integrity. We can do everything, including adding
    unit tests or running an automated integration test to improve the resultant artifacts,
    in this stage.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们使用的是 Docker，构建过程只需要一行脚本。我们的测试非常简单，主要是启动一个容器并使用构建的镜像，发出一些请求来确定其完整性。在这一阶段，我们可以完成所有操作，包括添加单元测试或运行自动化集成测试，以改进生成的构建成果。
- en: after_success
  id: totrans-108
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: after_success
- en: 'This block is executed only if the previous stage ends without any error. Once
    the block is executed, we are ready to publish our image:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这个块仅在前一个阶段无错误结束时执行。一旦执行了这个块，我们就准备发布我们的镜像了：
- en: '[PRE13]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Our image tag uses the commit hash for ordinary builds and uses a manually tagged version
    for releases. There's no absolute rule for tagging an image, but using the default `latest` tag for
    your business service is strongly discouraged as it could result in version confusion,
    such as running two different images that have the same name. The last conditional
    block is used to publish the image on certain branch tags, and we want to keep
    building and releasing on separate tracks. Remember to authenticate to Docker
    Hub before pushing an image.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的镜像标签使用提交的哈希值用于普通构建，并使用手动标记的版本用于发布。没有绝对的镜像标记规则，但强烈不建议将`latest`作为业务服务的标签，因为这可能导致版本混乱，例如运行两个名称相同但不同的镜像。最后的条件块用于在特定分支标签上发布镜像，我们希望将构建和发布保持在不同的轨道上。记得在推送镜像之前进行Docker
    Hub身份验证。
- en: 'Kubernetes decides whether the image should be pulled using `imagePullPolicy`,
    which defaults to `IfNotPresent`:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes通过`imagePullPolicy`决定是否拉取镜像，默认值为`IfNotPresent`：
- en: '`IfNotPresent`: kubelet pulls images if they aren''t present on the node. If
    the image tag is `:latest` and the policy isn''t `Never`, then kubelet falls back
    to `Always`.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '`IfNotPresent`：kubelet在节点上没有镜像时会拉取镜像。如果镜像标签是`:latest`且策略不是`Never`，那么kubelet将回退到`Always`。'
- en: '`Always`: kubelet always pulls images.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '`Always`：kubelet始终拉取镜像。'
- en: '`Never`: kubelet never pulls images; it will find out whether the desired image
    is on the node or not.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`Never`：kubelet永远不会拉取镜像；它会检查目标镜像是否已经存在于节点上。'
- en: 'Because we set our project deployments to actual machines only on a release,
    a build may stop and be returned at that moment. Let''s have a look into the log
    of this build: [https://travis-ci.com/DevOps-with-Kubernetes/okeydokey/builds/93296022](https://travis-ci.com/DevOps-with-Kubernetes/okeydokey/builds/93296022).
    The log retains the executed scripts and outputs from every line of the script
    during a CI build:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们将项目部署设置为仅在发布时部署到实际机器上，所以构建可能会在此时停止并被返回。我们来看一下该构建的日志：[https://travis-ci.com/DevOps-with-Kubernetes/okeydokey/builds/93296022](https://travis-ci.com/DevOps-with-Kubernetes/okeydokey/builds/93296022)。日志保留了执行的脚本和在CI构建过程中每一行脚本的输出：
- en: '![](img/c735c0d7-b93c-4b31-aa0d-21ad62a98269.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c735c0d7-b93c-4b31-aa0d-21ad62a98269.png)'
- en: 'As we can see, our build is successful, so the image is then published here: [https://hub.docker.com/r/devopswithkubernetes/okeydokey/tags/](https://hub.docker.com/r/devopswithkubernetes/okeydokey/tags/). The
    build refers to the `build-842eb66b2fa612598add8e19769af5c56b922532` tag and we
    can now run it outside the CI server:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，我们的构建已经成功，所以镜像被发布在这里：[https://hub.docker.com/r/devopswithkubernetes/okeydokey/tags/](https://hub.docker.com/r/devopswithkubernetes/okeydokey/tags/)。该构建使用的是`build-842eb66b2fa612598add8e19769af5c56b922532`标签，我们现在可以在CI服务器之外运行它：
- en: '[PRE14]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: deploy
  id: totrans-120
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署
- en: Although we can achieve a fully automated pipeline from end to end, we often
    encounter situations that hold up the deployment of a new build due to business
    concerns. Consequently, we tell Travis CI to run deployment scripts only when
    we want to release a new version.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们可以实现从端到端的完全自动化流水线，但由于业务原因，我们经常遇到阻碍新构建部署的情况。因此，我们告诉Travis CI仅在我们想要发布新版本时才运行部署脚本。
- en: 'As we stated earlier, the deployment in this example on Travis CI is merely to
    write the built image back to the template to be deployed. Here, we utilize the
    script provider to make Travis CI run our deployment script ([deployment/update-config.sh](https://github.com/DevOps-with-Kubernetes/okeydokey/blob/master/deployment/update-config.sh))
    and the script does the following:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所述，本例中在Travis CI上的部署仅仅是将构建好的镜像写回模板以便进行部署。在这里，我们使用脚本提供程序使Travis CI运行我们的部署脚本([deployment/update-config.sh](https://github.com/DevOps-with-Kubernetes/okeydokey/blob/master/deployment/update-config.sh))，该脚本执行以下操作：
- en: Locates the config repository and corresponding branch
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定位配置仓库及其相应分支
- en: Updates the image tag
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新了镜像标签
- en: Commits the updated template back
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提交更新后的模板
- en: After the updated image tag is committed into the repository, the job on Travis
    CI is done.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在更新后的镜像标签提交到仓库后，Travis CI上的任务完成。
- en: 'The other end of the pipeline is our agent inside the cluster. It is responsible
    for the following tasks:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 流水线的另一端是我们集群内部的代理。它负责以下任务：
- en: Periodically monitoring the change of our configs on GitHub
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定期监控我们在GitHub上配置的变化
- en: Pulling and applying the updated image to our pod controller
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拉取并应用更新后的镜像到我们的pod控制器
- en: The former is quite simple, but for the latter, we have to grant the agent sufficient
    permissions so that it can manipulate resources inside the cluster. Our example
    uses a service account, `cd-agent`, under a dedicated namespace, `cd`, to create
    and update our deployments, and the related RBAC configurations can be found under [chapter9/9-2_service-account-for-ci-tool/cd-agent](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter9/9-2_service-account-for-ci-tool/cd-agent)
    in the repository for this book.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 前者非常简单，但对于后者，我们必须授予代理足够的权限，以便它能够操作集群内的资源。我们的示例使用一个服务账户`cd-agent`，位于一个专用的命名空间`cd`下，用于创建和更新我们的部署，相关的RBAC配置可以在本书的[chapter9/9-2_service-account-for-ci-tool/cd-agent](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter9/9-2_service-account-for-ci-tool/cd-agent)中找到。
- en: Here, we grant the service account the permission to read and modify resources
    across namespaces, including the secrets of the whole cluster. Due to security
    concerns, it's always encouraged to restrict the permissions of a service account
    to the resources that the account actually uses, or it could be a potential vulnerability.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们授予服务账户跨命名空间读取和修改资源的权限，包括整个集群的秘密。由于安全问题，通常建议将服务账户的权限限制在实际使用的资源上，否则可能成为潜在的漏洞。
- en: 'The agent itself is merely a long-running script at [chapter9/9-2_service-account-for-ci-tool/utils/watcher/watcher.sh](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-2_service-account-for-ci-tool/utils/watcher/watcher.sh).
    To carry out updates, it uses `apply` and `rollout`:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 该代理本身仅是一个长期运行的脚本，位于[chapter9/9-2_service-account-for-ci-tool/utils/watcher/watcher.sh](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-2_service-account-for-ci-tool/utils/watcher/watcher.sh)。为了执行更新，它使用`apply`和`rollout`：
- en: '[PRE15]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Let''s deploy `agent` and its related `config` before rolling out our application:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署应用之前，让我们先部署`agent`及其相关的`config`：
- en: '[PRE16]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The `state-watcher` deployment is our `agent`, and it has been configured to
    monitor our config repository for environment variables:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`state-watcher`部署就是我们的`agent`，它已配置为监控我们的配置仓库中的环境变量：'
- en: '[PRE17]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Everything is ready. Let's see the entire flow in action.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 一切准备就绪。让我们看看整个流程是如何运行的。
- en: 'We publish a release with a `v0.0.3` tag at GitHub ([https://github.com/DevOps-with-Kubernetes/okeydokey/releases/tag/v0.0.3](https://github.com/DevOps-with-Kubernetes/okeydokey/releases/tag/v0.0.3)):'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在GitHub上发布了一个带有`v0.0.3`标签的版本（[https://github.com/DevOps-with-Kubernetes/okeydokey/releases/tag/v0.0.3](https://github.com/DevOps-with-Kubernetes/okeydokey/releases/tag/v0.0.3)）：
- en: '![](img/fc6593f4-845b-4b80-b3ac-55b4cd3596d1.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fc6593f4-845b-4b80-b3ac-55b4cd3596d1.png)'
- en: 'Travis CI starts to build our job right after being triggered by the new tag:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Travis CI在新标签触发后开始构建我们的作业：
- en: '![](img/2499ae7a-fae7-4c92-8a34-111eaec87856.png)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/2499ae7a-fae7-4c92-8a34-111eaec87856.png)'
- en: 'If it fails, we can check the build log to see what went wrong: [https://travis-ci.com/DevOps-with-Kubernetes/okeydokey/jobs/162862675](https://travis-ci.com/DevOps-with-Kubernetes/okeydokey/jobs/162862675).
    Fortunately, we get a green flag, so the built image will be pushed onto Docker
    Hub after a while:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 如果失败了，我们可以查看构建日志，看看哪里出了问题：[https://travis-ci.com/DevOps-with-Kubernetes/okeydokey/jobs/162862675](https://travis-ci.com/DevOps-with-Kubernetes/okeydokey/jobs/162862675)。幸运的是，我们获得了绿色标志，因此构建的镜像将在稍后推送到Docker
    Hub：
- en: '![](img/aa75bd53-c20f-485d-a454-5228e6ac5ca6.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![](img/aa75bd53-c20f-485d-a454-5228e6ac5ca6.png)'
- en: 'At this moment, our `agent` should also notice the change in `config` and act
    upon it:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，我们的`agent`也应该注意到`config`的变化并做出相应的处理：
- en: '[PRE18]'
  id: totrans-146
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'As we can see, our application has rolled out successfully, and it should start
    to welcome everyone with `OK`:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们所见，我们的应用已成功部署，应该开始向所有人显示`OK`：
- en: '[PRE19]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The pipeline we built and demonstrated in this section is a classic flow to
    deliver code continuously in Kubernetes. However, as the work style and culture
    varies from team to team, designing a tailor-made continuous delivery pipeline
    for your team can improve efficiency. For example, the built-in update strategy
    of a deployment is the rolling update. Teams that prefer other types of deployment
    strategies such as blue/green or canary have to change the pipeline to fit their
    needs. Fortunately, Kubernetes is extremely flexible, and we can implement various
    strategies by compositing `Deployment`, `Service`, `Ingress`, and so on.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本节中构建并演示的流水线是一个经典的 Kubernetes 持续交付流程。然而，随着团队工作方式和文化的不同，为你的团队量身定制一个持续交付流水线可以提高效率。例如，部署的内置更新策略是滚动更新。那些更倾向于使用其他类型部署策略（如蓝绿部署或金丝雀发布）的团队需要调整流水线以满足他们的需求。幸运的是，Kubernetes
    非常灵活，我们可以通过组合 `Deployment`、`Service`、`Ingress` 等来实现各种策略。
- en: In the previous edition of this book, we demonstrated a similar flow but applied
    the configuration from the CI server directly. Both approaches have their pros
    and cons. If you don't have any security concerns related to putting cluster information
    on the CI server and just need a really easy CD flow, then the push-based pipeline
    is still an option. You can find a script for exporting the tokens of a service
    account and another script for applying configuration to Kubernetes here: [https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter9/9-2_service-account-for-ci-tool/utils/push-cd](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter9/9-2_service-account-for-ci-tool/utils/push-cd).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的上一版中，我们演示了一个类似的流程，但直接从 CI 服务器应用配置。这两种方法各有优缺点。如果你对将集群信息放在 CI 服务器上没有安全顾虑，并且只需要一个非常简单的持续交付流程，那么基于推送的流水线仍然是一个选择。你可以在这里找到导出服务账户令牌的脚本和应用
    Kubernetes 配置的另一个脚本：[https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter9/9-2_service-account-for-ci-tool/utils/push-cd](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter9/9-2_service-account-for-ci-tool/utils/push-cd)。
- en: Gaining a deeper understanding of pods
  id: totrans-151
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入理解 Pod
- en: Although birth and death are merely a blink during a pod's lifetime, they're
    also the most fragile points of a service. We want to avoid common situations
    such as routing requests to an unready box or brutally cutting all in-flight connections
    to a terminating machine. As a consequence, even if Kubernetes takes care of most
    things for us, we should know how to configure our service properly to make sure
    every feature is delivered perfectly.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Pod 的生命周期中的出生与死亡不过是瞬息之间，但它们也是服务最脆弱的点。我们希望避免常见的情况，比如将请求路由到一个尚未就绪的 Pod，或是强制切断与终止中的机器的所有连接。因此，即使
    Kubernetes 为我们处理了大多数事务，我们仍然应该知道如何正确配置服务，确保每个功能都能完美交付。
- en: Starting a pod
  id: totrans-153
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 启动 Pod
- en: By default, Kubernetes moves a pod's state to Running as soon as a pod launches.
    If the pod is behind a service, the endpoint controller registers an endpoint
    to Kubernetes immediately. Later on, `kube-proxy` observes the change of endpoints
    and configures the host's `ipvs` or `iptables` accordingly. Requests from the
    outside world now go to pods. These operations happen very quickly, so it's quite
    possible that requests arrive at a pod before the application is ready, especially
    with bulky software. If a pod fails while running, we should remove it from the
    pool of a service instantly to make sure no requests reach a bad endpoint.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Kubernetes 在 Pod 启动后立即将其状态设置为 Running。如果 Pod 后面有服务，端点控制器会立即向 Kubernetes
    注册一个端点。之后，`kube-proxy` 会观察端点的变化，并相应地配置主机的 `ipvs` 或 `iptables`。来自外部世界的请求现在会发送到
    Pod。这些操作发生得非常迅速，因此很有可能请求在应用程序准备就绪之前就到达了 Pod，特别是对于大型软件。如果 Pod 在运行时失败，我们应立即将其从服务的池中移除，以确保没有请求到达坏的端点。
- en: The `minReadySeconds` field of deployment and other controllers doesn't postpone
    a pod from becoming ready. Instead, it delays a pod from becoming available. A
    rollout is only successful if all pods are available.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 部署和其他控制器的 `minReadySeconds` 字段不会延迟 Pod 变为就绪，而是延迟 Pod 变为可用。只有当所有 Pod 都可用时，部署才算成功。
- en: Liveness and readiness probes
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 存活性和就绪性探针
- en: 'A probe is an indicator of a container''s health. It judges health through
    periodically performing diagnostic actions against a container via kubelet. There
    are two kinds of probes for determining the state of a container:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 探测是容器健康状况的指示器。它通过定期执行诊断操作来判断容器健康状态，操作由kubelet发起。判断容器状态有两种探测方法：
- en: '**Liveness** **probe**: This indicates whether or not a container is alive.
    If a container fails on this probe, kubelet kills it and may restart it based
    on the `restartPolicy` of a pod.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存活** **探测**：这表示容器是否存活。如果容器在此探测失败，kubelet 会杀死它，并根据Pod的`restartPolicy`决定是否重启它。'
- en: '**Readiness probe**: This indicates whether a container is ready for incoming
    traffic. If a pod behind a service isn''t ready, its endpoint won''t be created
    until the pod is ready.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**就绪探测**：这表示容器是否已准备好接收流量。如果服务后面的Pod没有准备好，其端点不会被创建，直到Pod准备好。'
- en: 'The `restartPolicy` tells us how Kubernetes treats a pod on failures or terminations.
    It has three modes: `Always`, `OnFailure`, or `Never`. The default is set to `Always`.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '`restartPolicy`告诉我们Kubernetes如何处理Pod的失败或终止情况。它有三种模式：`Always`、`OnFailure` 或
    `Never`。默认设置为 `Always`。'
- en: 'Three kinds of action handlers can be configured to diagnose a container:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 可以配置三种操作处理程序来诊断容器：
- en: '`exec`: This executes a defined command inside the container. It''s considered
    to be successful if the exit code is `0`.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`exec`：此命令会在容器内执行定义的命令。如果退出码为`0`，则视为执行成功。'
- en: '`tcpSocket`: This tests a given port via TCP and is successful if the port
    is opened.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tcpSocket`：此操作通过TCP测试指定端口，如果端口打开，则操作成功。'
- en: '`httpGet`: This performs `HTTP GET` on the IP address of the target container.
    Headers in the request to be sent are customizable. This check is considered to
    be healthy if the status code satisfies `400 > CODE >= 200`.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`httpGet`：这会对目标容器的IP地址执行`HTTP GET`请求。请求中的头部可以自定义。如果状态码满足`400 > CODE >= 200`，则此探测被认为是健康的。'
- en: 'Additionally, there are five parameters that define a probe''s behavior:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有五个参数定义了探测的行为：
- en: '`initialDelaySeconds`: How long kubelet should wait for before the first probing'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initialDelaySeconds`：Kubelet在首次探测前需要等待的时间。'
- en: '`successThreshold`: A container is considered to be healthy only if it got
    consecutive times of probing successes over this threshold'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`successThreshold`：只有当容器连续多次探测成功超过此阈值时，才认为容器健康。'
- en: '`failureThreshold`: The same as the previous one, but defines the negative
    side instead'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`failureThreshold`：与之前相同，但定义了失败的条件。'
- en: '`timeoutSeconds`: The time limitation of a single probe action'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timeoutSeconds`：单次探测操作的时间限制。'
- en: '`periodSeconds`: Intervals between probe actions'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`periodSeconds`：探测操作之间的时间间隔。'
- en: 'The following code snippet demonstrates the use of a readiness probe. The full
    template can be found at [https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-3_on_pods/probe.yml](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-3_on_pods/probe.yml):'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段演示了如何使用就绪探测。完整模板可以在[https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-3_on_pods/probe.yml](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-3_on_pods/probe.yml)找到：
- en: '[PRE20]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In this example, we used some tricks with our main application, which set the
    starting time of the application to around six seconds and replace the application after
    20 seconds with another one that echoes `HTTP 500`. The application''s interaction
    with the readiness probe is illustrated in the following diagram:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们在主应用程序中做了一些处理，设置应用程序的启动时间约为六秒，并在20秒后用另一个返回`HTTP 500`的应用程序替换它。应用程序与就绪探测的交互如下图所示：
- en: '![](img/eb1f7b10-2da5-418b-88a8-889ef9528d93.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![](img/eb1f7b10-2da5-418b-88a8-889ef9528d93.png)'
- en: 'The upper timeline is a pod''s real readiness, and the other one is its readiness
    from Kubernetes'' perspective. The first probe executes 10 seconds after the pod
    is created, and the pod is regarded as ready after two probing successes. A few
    seconds later, the pod goes out of service due to the termination of our application,
    and it becomes unready after the next three failures. Try to deploy the preceding
    example and observe its output:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的时间线表示Pod的实际就绪状态，另一个则是Kubernetes视角下的就绪状态。第一次探测在Pod创建后10秒执行，Pod在连续两次探测成功后被视为就绪。几秒钟后，由于应用程序的终止，Pod变为不可用，接下来的三次探测失败后，Pod变为不可就绪。尝试部署前述示例并观察输出：
- en: '[PRE21]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In our example file, there is another pod, `tester`, which is constantly making
    requests to our service and the log entries. `/from-tester` in our service represents
    the requests from the tester. From the tester''s activity logs, we can observe
    that the traffic from `tester` is stopped after our service becomes unready (notice
    the activities of two pods around the time `1544137180`):'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例文件中，还有另一个 pod，`tester`，它不断向我们的服务发起请求，并记录日志。`/from-tester`代表来自测试者的请求。从测试者的活动日志中，我们可以看到，当我们的服务变得不可用时，来自`tester`的流量停止了（注意时间点`1544137180`前后两个
    pod 的活动）：
- en: '[PRE22]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Since we didn't configure the liveness probe in our service, the unhealthy container
    won't be restarted unless we kill it manually. In general, we would use both probes
    together to automate the healing process.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有在服务中配置存活探针，因此不健康的容器不会自动重启，除非我们手动杀死它。通常，我们会同时使用两个探针来自动化修复过程。
- en: Custom readiness gate
  id: totrans-180
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 自定义就绪门控
- en: The testing targets of the readiness probe are always containers, which means
    that it can't be used to disable a pod from a service by using external states.
    Since a service selects pods by their labels, we can control the traffic to pods
    by manipulating pod labels to a certain extent. However, pod labels are also read
    by other components inside Kubernetes, so building complex toggles with labels could
    lead to unexpected results.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪探针的测试目标始终是容器，这意味着它不能用来通过外部状态禁用 pod 访问服务。由于服务是通过 pod 的标签来选择 pod 的，我们可以通过操作
    pod 标签来在一定程度上控制流量。然而，pod 标签也会被 Kubernetes 内部的其他组件读取，因此构建复杂的标签开关可能会导致意想不到的结果。
- en: 'The pod readiness gate is the feature that allows us to mark whether a pod
    is ready or not, based on the conditions we defined. With the pod readiness gates
    defined, a pod is regarded as ready only if its readiness probe passes and the
    status of all readiness gates associated with the pod is `True`. We can define
    the readiness gate as shown in the following snippet:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: pod 就绪门控是一个允许我们根据定义的条件标记 pod 是否准备就绪的功能。定义了 pod 就绪门控后，只有当 pod 的就绪探针通过并且与 pod
    关联的所有就绪门控状态为`True`时，pod 才被视为就绪。我们可以通过以下代码片段来定义就绪门控：
- en: '[PRE23]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The value must follow the format of a label key such as `feature_1` or `myorg.com/fg-2`.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 值必须遵循标签键的格式，例如`feature_1`或`myorg.com/fg-2`。
- en: 'When a pod starts, a condition type we defined will be populated as a condition
    under a pod''s `.status.conditions[]` path, and we have to explicitly set the
    condition to `True` to mark a pod ready. As for Kubernetes 1.13, the only way
    to edit the condition is with the `patch` API. Let''s see an example at [https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-3_on_pods/readiness_gates.yml](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-3_on_pods/readiness_gates.yml):'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 当 pod 启动时，我们定义的条件类型会作为条件填充到 pod 的`.status.conditions[]`路径下，并且我们必须显式地将条件设置为`True`，以标记
    pod 为就绪。对于 Kubernetes 1.13，编辑条件的唯一方式是使用`patch` API。我们来看一下在[https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-3_on_pods/readiness_gates.yml](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/blob/master/chapter9/9-3_on_pods/readiness_gates.yml)中的示例：
- en: '[PRE24]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Here, our custom condition is called `MY-GATE-1` and the application is the
    one that we have used throughout this chapter. As we can see, even if the pod
    has started, its address is still listed in `NotReadyAddresses`. This means that
    the pod isn''t taking any traffic. We can verify its status with `describe` (or
    `wide`/`json`/`yaml`):'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们自定义的条件被称为`MY-GATE-1`，而应用程序是我们在本章中一直使用的那个。正如我们所见，即使 pod 已启动，其地址仍列在`NotReadyAddresses`中。这意味着该
    pod 没有承接任何流量。我们可以使用`describe`（或`wide`/`json`/`yaml`）命令来验证其状态：
- en: '[PRE25]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The container in the pod is ready, but the pod itself isn''t ready due to the
    readiness gates. To toggle it on, we''ll need to make a request to the API server
    with a **JSON Patch** payload to `/api/v1/namespaces/<namespace>/pods/<pod_name>/status`:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: pod 中的容器已就绪，但由于就绪门控的原因，pod 本身并没有就绪。要开启它，我们需要向 API 服务器发送一个**JSON Patch**负载，目标路径为`/api/v1/namespaces/<namespace>/pods/<pod_name>/status`：
- en: '[PRE26]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We''ll see that an entry will be inserted into the `.status.conditions` list.
    Now, if we check the endpoints of the service, we can see that the pod has started
    to serve requests:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将看到一条条目被插入到`.status.conditions`列表中。现在，如果我们检查服务的端点，就可以看到 pod 已经开始提供请求服务：
- en: '[PRE27]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'To put the pod in the other way around, we could use the `replace` or `remove`
    operation of JSON Patch to set the condition''s status to `False` or `<none>`:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 要将 pod 调转过来，我们可以使用 JSON Patch 的`replace`或`remove`操作，将条件状态设置为`False`或`<none>`：
- en: '[PRE28]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The pod now becomes unready again. With the readiness gate, we can nicely separate
    the logic of toggling business features and managing labels.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 pod 再次变为未就绪状态。通过就绪门控，我们可以很好地区分切换业务功能和管理标签的逻辑。
- en: init containers
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: init 容器
- en: At times we'll need to initialize our application before it actually runs, such
    as by preparing schema for the main application or loading data from another place.
    As it's difficult to predict how long the initialization could take, we can't
    simply rely on `initialDelaySeconds` to create a buffer for this preparation,
    so `init` containers come in handy here.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 有时我们需要在应用程序实际运行之前进行初始化，例如为主应用程序准备架构或从其他地方加载数据。由于很难预测初始化可能需要多长时间，我们不能仅仅依赖 `initialDelaySeconds`
    来为此准备工作创建缓冲区，因此 `init` 容器在这里非常有用。
- en: '`init` containers are one or more containers that start prior to application
    containers and run one by one to completion in order. If any container fails,
    it''s subject to the `restartPolicy` of a pod and starts over again until all
    containers are exited with code `0`. Defining `init` containers is similar to
    defining regular containers:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`init` 容器是一个或多个在应用容器之前启动并依次运行到完成的容器。如果任何容器失败，它将根据 pod 的 `restartPolicy` 重新启动，直到所有容器退出并返回代码
    `0`。定义 `init` 容器与定义常规容器类似：'
- en: '[PRE29]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'They only differ in the following respects:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 它们仅在以下几个方面有所不同：
- en: '`init` containers don''t have readiness probes as they run to completion.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`init` 容器没有就绪探针，因为它们运行到完成为止。'
- en: The port defined in `init` containers won't be captured by the service in front
    of the pod.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 `init` 容器中定义的端口不会被 pod 前面的服务捕获。
- en: The request limit of resources are calculated with `max(sum(regular containers)`,
    and `max(init containers))`, which means if one of the `init` containers sets
    a higher resource limit than other `init` containers, as well as the sum of the
    resource limits of all regular containers, Kubernetes schedules the pod according
    to the `init` container's resource limit.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 资源请求限制是通过计算 `max(sum(regular containers))` 和 `max(init containers))` 来得出的，这意味着如果其中一个
    `init` 容器设置的资源限制高于其他 `init` 容器的限制以及所有常规容器资源限制的总和，Kubernetes 会根据该 `init` 容器的资源限制来调度
    pod。
- en: The usefulness of `init` containers is more than blocking the application containers.
    For instance, we can utilize an `init` container to configure an image by sharing
    an `emptyDir` volume with `init` containers and application containers, instead
    of building another image that only runs `awk`/`sed` on the base image. Also,
    it grants us the flexibility to use different images for initialization tasks
    and the main application.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`init` 容器的作用不仅仅是阻塞应用容器。例如，我们可以利用 `init` 容器通过与 `init` 容器和应用容器共享 `emptyDir` 卷来配置一个镜像，而不是构建另一个只对基础镜像执行
    `awk` / `sed` 的镜像。此外，它还使我们能够灵活地为初始化任务和主要应用程序使用不同的镜像。'
- en: Terminating a pod
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 终止一个 pod
- en: The sequence of shutdown events is similar to events while starting a pod. After
    receiving a deletion invocation, Kubernetes sends `SIGTERM` to the pod that is
    going to be deleted, and the pod's state becomes terminating. Meanwhile, Kubernetes
    removes the endpoint of that pod to stop further requests if the pod is backing
    a service. Occasionally, there are pods that don't quit at all. It could be that
    the pods don't honor `SIGTERM`, or simply because their tasks aren't completed.
    Under such circumstances, Kubernetes will send `SIGKILL` to forcibly kill those
    pods after the termination period. The period length is set at `.spec.terminationGracePeriodSeconds`
    under the pod specification. Even though Kubernetes has mechanisms to reclaim
    such pods anyway, we still should make sure our pods can be closed properly.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 关闭事件的顺序与启动 pod 时的事件类似。在收到删除请求后，Kubernetes 会向即将被删除的 pod 发送 `SIGTERM`，并且该 pod
    的状态变为终止。与此同时，如果该 pod 支持服务，Kubernetes 会移除该 pod 的端点，以停止进一步的请求。偶尔，某些 pod 可能永远不会退出。可能是这些
    pod 不遵循 `SIGTERM`，或者只是因为它们的任务尚未完成。在这种情况下，Kubernetes 会在终止期过后发送 `SIGKILL` 强制终止这些
    pod。终止期的长度在 pod 规格中的 `.spec.terminationGracePeriodSeconds` 设置。尽管 Kubernetes 仍然有机制回收这些
    pod，但我们仍应确保我们的 pod 能够正确关闭。
- en: Handling SIGTERM
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理 SIGTERM
- en: Graceful termination isn't a new idea; it is a common practice in programming.
    Killing a pod forcibly while it's still working is like suddenly unplugging the
    power cord of a running computer, which could harm the data.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 优雅终止并不是一个新概念；它是编程中的常见做法。强行终止一个正在工作的 pod 就像突然拔掉正在运行的计算机的电源线，这可能会损坏数据。
- en: 'The implementation principally includes three steps:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 实现主要包括三个步骤：
- en: Register a handler to capture termination signals.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 注册处理程序来捕获终止信号。
- en: Do everything required in the handler, such as freeing resources, writing data
    to external persistent layers, releasing distribution locks, or closing connections.
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在处理程序中完成所有必要的操作，例如释放资源、将数据写入外部持久化层、释放分布式锁或关闭连接。
- en: 'Perform a program shutdown. Our previous example demonstrates the idea: closing
    the controller thread on `SIGTERM` in the `graceful_exit_handler` handler. The
    code can be found here: [https://github.com/DevOps-with-Kubernetes/okeydokey/blob/master/app.py](https://github.com/DevOps-with-Kubernetes/okeydokey/blob/master/app.py).'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行程序关闭。我们之前的示例展示了这一思路：在 `graceful_exit_handler` 处理程序中，接收到 `SIGTERM` 信号时关闭控制器线程。代码可以在这里找到：[https://github.com/DevOps-with-Kubernetes/okeydokey/blob/master/app.py](https://github.com/DevOps-with-Kubernetes/okeydokey/blob/master/app.py)。
- en: Due to the fact that Kubernetes can only send signals to the `PID 1` process
    in a container, there are some common pitfalls that could fail the graceful handler
    in our program.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Kubernetes 只能向容器中的 `PID 1` 进程发送信号，所以有一些常见的陷阱可能会导致我们程序中的优雅处理程序失败。
- en: SIGTERM isn't sent to the application process
  id: totrans-214
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`SIGTERM` 没有发送到应用程序进程'
- en: 'In [Chapter 2](05e2d0b4-0e70-4480-b5a0-f3860ddb24f2.xhtml), *DevOps with Containers*,
    we learned there are two forms to invoke our program when writing a Dockerfile:
    the shell form and the exec form. The shell to run the shell form commands defaults
    to `/bin/sh -c` on Linux containers. Hence, there are a few questions related
    to whether `SIGTERM` can be received by our applications:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第 2 章](05e2d0b4-0e70-4480-b5a0-f3860ddb24f2.xhtml)，*容器化 DevOps* 中，我们学习了在编写
    Dockerfile 时，有两种方式调用程序：Shell 表达式和 exec 表达式。在 Linux 容器中，执行 Shell 表达式命令的 Shell 默认是
    `/bin/sh -c`。因此，关于 `SIGTERM` 是否能被我们的应用程序接收，存在一些相关问题：
- en: How is our application invoked?
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们的应用程序是如何被调用的？
- en: What shell implementation is used in the image?
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 镜像中使用的是哪种 Shell 实现？
- en: How does the shell implementation deal with the `-c` parameter?
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shell 实现是如何处理 `-c` 参数的？
- en: 'Let''s approach these questions one by one. The Dockerfile used in the following
    example can be found here: [https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter9/9-3_on_pods/graceful_docker](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter9/9-3_on_pods/graceful_docker).'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 我们逐一分析这些问题。以下示例中使用的 Dockerfile 可以在这里找到：[https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter9/9-3_on_pods/graceful_docker](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter9/9-3_on_pods/graceful_docker)。
- en: 'Say we''re using the shell form command, `CMD python -u app.py`, in our Dockerfile
    to execute our application. The starting command of the container would be `/bin/sh
    -c "python3 -u app.py"`. When the container starts, the structure of the processes
    inside it is as follows:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们在 Dockerfile 中使用的是 Shell 表达式命令，`CMD python -u app.py`，用于执行我们的应用程序。容器的启动命令将是
    `/bin/sh -c "python3 -u app.py"`。当容器启动时，容器内进程的结构如下：
- en: '[PRE30]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'We can see that the `PID 1` process isn''t our application with handlers; it''s
    the shell instead. When we try to kill the pod, `SIGTERM` will be sent to the
    shell rather than to our application, and the pod will be terminated after the
    grace period expires. We can check the log in our application when deleting it
    to see whether it received `SIGTERM`:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，`PID 1` 进程不是我们的应用程序和处理程序，而是 Shell。当我们尝试终止 Pod 时，`SIGTERM` 会发送到 Shell
    而不是我们的应用程序，Pod 会在宽限期结束后被终止。我们可以在删除应用程序时检查日志，看看它是否收到了 `SIGTERM`：
- en: '[PRE31]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Our application exited without going to the stop handler in the code. There
    are a couple of ways to properly promote our application to `PID 1`. For example,
    we can explicitly call `exec` in the shell form, such as `CMD exec python3 -u
    app.py`, so that our program will inherit `PID 1`. Or, we can choose the `exec`
    form, `CMD [ "python3", "-u", "app.py" ]`, to execute our program directly:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的应用程序在没有进入代码中的停止处理程序的情况下退出了。正确提升应用程序为 `PID 1` 的方法有几种。例如，我们可以在 Shell 表达式中显式调用
    `exec`，如 `CMD exec python3 -u app.py`，这样我们的程序就会继承 `PID 1`。或者，我们可以选择 `exec` 表达式，`CMD
    [ "python3", "-u", "app.py" ]`，直接执行我们的程序：
- en: '[PRE32]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The program, executed in either way, can now receive `SIGTERM` properly. Besides,
    if we need to set up the environment with a shell script for our program, we should
    either trap signals in the script to propagate them to our program, or use the
    exec call to invoke our program so that the handler in our application is able
    to work as desired.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 无论以哪种方式执行，程序现在都可以正确地接收`SIGTERM`信号。此外，如果我们需要通过shell脚本为程序设置环境，我们应该在脚本中捕获信号并将其传播给程序，或者使用exec调用来启动程序，以便应用程序中的信号处理器能够按预期工作。
- en: 'The second and the third questions are about the shell implication: how could
    it affect our graceful handler? Again, the default command of a Docker container
    in Linux is `/bin/sh -c`. As `sh` differs among popular Docker images, the way
    it handles `-c` could also affect the signals if we''re using the shell form.
    For example, Alpine Linux links `ash` to `/bin/sh`, and the Debian family of distributions
    use `dash`. Before Alpine 3.8 (or BusyBox 1.28.0), `ash` forks a new process when
    using `sh -c`, and it uses `exec` in 3.8\. We can observe the difference with
    `ps`, where we can see the one in 3.7 gets `PID 6` while it''s `PID 1` in 3.8:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个和第三个问题是关于shell的影响：它如何影响我们优雅的处理程序？同样，Linux中Docker容器的默认命令是`/bin/sh -c`。由于`sh`在流行的Docker镜像中有所不同，因此它处理`-c`的方式也可能影响信号，特别是在使用shell形式时。例如，Alpine
    Linux将`ash`链接到`/bin/sh`，而Debian系列的发行版使用`dash`。在Alpine 3.8之前（或BusyBox 1.28.0），`ash`在使用`sh
    -c`时会派生出一个新进程，而在3.8版本中，它使用`exec`。我们可以通过`ps`观察到这一差异，在3.7版本中，它会获得`PID 6`，而在3.8版本中则为`PID
    1`：
- en: '[PRE33]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'How do `dash` and `bash` handle these cases? Let''s take a look:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '`dash`和`bash`如何处理这些情况？让我们来看看：'
- en: '[PRE34]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: As we can see, their results are different as well. Our application can now
    respond to the terminating event appropriately. There is one more thing, however,
    that could potentially harm our system if our application is run as `PID 1` and
    it uses more than one process inside the container.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所见，它们的结果也不同。我们的应用程序现在可以正确地响应终止事件。然而，还有一件事，如果我们的应用程序以`PID 1`运行，并且在容器内使用多个进程，这可能会对系统造成潜在的危害。
- en: 'On Linux, a child process becomes a zombie if its parent doesn''t wait for
    its execution. If the parent dies before its child process ends, the `init` process
    should adopt those orphaned processes and reap processes that become zombies.
    System programs know how to deal with orphaned processes, so zombie processes
    are not a problem most of the time. However, in a containerized context, the process
    that holds `PID 1` is our application, and the operating system would expect our
    application to reap zombie processes. Because our application isn''t designed
    to act as a proper `init` process, however, handling the state of child processes
    is unrealistic. If we just ignore it, at worst the process table of the node will
    be filled with zombie processes and we won''t be able to launch new programs on
    the node anymore. In Kubernetes, if a pod with zombie processes is gone, then
    all zombie processes inside will be cleaned. Another possible scenario is if our
    application performs some tasks frequently through scripts in the background,
    which could potentially fork lots of processes. Let''s consider the following
    simple example:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在Linux系统中，如果子进程的父进程没有等待其执行，子进程将变成僵尸进程。如果父进程在子进程结束之前死亡，那么`init`进程应该收养这些孤儿进程，并清理变成僵尸的进程。系统程序知道如何处理孤儿进程，因此僵尸进程通常不会成为问题。然而，在容器化的环境中，持有`PID
    1`的进程是我们的应用程序，操作系统期望我们的应用程序去清理僵尸进程。由于我们的应用程序并没有被设计成一个合适的`init`进程，因此处理子进程的状态是不现实的。如果我们忽略这一点，最糟糕的情况是节点的进程表会被僵尸进程填满，我们将无法在节点上启动新的程序。在Kubernetes中，如果包含僵尸进程的Pod被销毁，那么Pod内部的所有僵尸进程将会被清理。另一个可能的场景是，如果我们的应用程序通过脚本频繁在后台执行某些任务，这可能会派生出大量的进程。让我们考虑以下这个简单的例子：
- en: '[PRE35]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '`sleep 30` is now a zombie in our pod. In [Chapter 2](05e2d0b4-0e70-4480-b5a0-f3860ddb24f2.xhtml), *DevOps
    with Containers*, we mentioned that the `docker run --init` parameter can set
    a simple `init` process for our container. In Kubernetes, we can make the `pause`
    container, a special container that deals with those chores silently for us, be
    present in our pod by specifying `.spec.shareProcessNamespace` in the pod specification:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '`sleep 30`现在是我们Pod中的一个僵尸进程。在[第2章](05e2d0b4-0e70-4480-b5a0-f3860ddb24f2.xhtml)《与容器的DevOps》中，我们提到过`docker
    run --init`参数可以为我们的容器设置一个简单的`init`进程。在Kubernetes中，我们可以通过在Pod的规格中指定`.spec.shareProcessNamespace`，使`pause`容器（一个特殊容器，默默地为我们处理这些事务）出现在Pod中：'
- en: '[PRE36]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The `pause` process ensures that zombies are reaped and `SIGTERM` goes to our
    application process. Notice that by enabling process namespace sharing, aside
    from our application no longer having `PID 1`, there are two other key differences:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`pause`进程确保丧尸进程被清理，`SIGTERM`会发送到我们的应用程序进程。请注意，通过启用进程命名空间共享，除了我们的应用程序不再具有`PID
    1`，还有两个关键的区别：'
- en: All containers in the same pod share process information with each other, which
    means a container can send signals to another container
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一 pod 中的所有容器共享进程信息，这意味着一个容器可以向另一个容器发送信号。
- en: The filesystem of containers can be accessed via the `/proc/$PID/root` path
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器的文件系统可以通过`/proc/$PID/root`路径进行访问。
- en: If the described behaviors aren't feasible to your application while an `init`
    process is still needed, you can opt for Tini ([https://github.com/krallin/tini](https://github.com/krallin/tini)),
    or dump-init ([https://github.com/Yelp/dumb-init](https://github.com/Yelp/dumb-init)),
    or even write a wrapper script to resolve the zombie reaping problem.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在`init`进程仍然需要的情况下，所描述的行为不适合你的应用程序，你可以选择Tini（[https://github.com/krallin/tini](https://github.com/krallin/tini)），或者dump-init（[https://github.com/Yelp/dumb-init](https://github.com/Yelp/dumb-init)），甚至编写一个包装脚本来解决丧尸进程清理问题。
- en: SIGTERM doesn't invoke the termination handler
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '`SIGTERM`不会触发终止处理程序。'
- en: In some cases, the termination handler of a process isn't triggered by `SIGTERM`.
    For instance, sending `SIGTERM` to `nginx` actually causes a fast shutdown. To
    gracefully close an `nginx` controller, we have to send `SIGQUIT` with `nginx
    -s quit` instead.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，进程的终止处理程序不会被`SIGTERM`触发。例如，向`nginx`发送`SIGTERM`实际上会导致快速关闭。要优雅地关闭`nginx`控制器，我们必须通过`nginx
    -s quit`发送`SIGQUIT`。
- en: 'The full list of supported actions on the signal of `nginx` is listed here:
    [http://nginx.org/en/docs/control.html](http://nginx.org/en/docs/control.html).'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`nginx`信号支持的完整操作列表请查看此处：[http://nginx.org/en/docs/control.html](http://nginx.org/en/docs/control.html)。'
- en: 'Now, another problem arises: how do we send signals other than `SIGTERM` to
    a container when deleting a pod? We can modify the behavior of our program to
    trap `SIGTERM`, but there''s nothing we can do about popular tools such as `nginx`.
    For such a situation, we can use life cycle hooks.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，出现了另一个问题：在删除 pod 时，如何向容器发送除了`SIGTERM`以外的信号？我们可以修改程序的行为来捕获`SIGTERM`，但对于像`nginx`这样的流行工具，我们无法做出任何处理。对于这种情况，我们可以使用生命周期钩子。
- en: Container life cycle hooks
  id: totrans-244
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 容器生命周期钩子
- en: 'Life cycle hooks are actions triggered on certain events and performed against
    containers. They work like a single Kubernetes probing action, but they''ll be
    fired at least once per event during a container''s lifetime. Currently, two events
    are supported:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 生命周期钩子是某些事件触发的操作，并在容器上执行。它们的工作方式类似于单一的 Kubernetes 探针操作，但在容器生命周期中的每个事件至少会触发一次。目前，支持两个事件：
- en: '`PostStart`: This executes right after a container is created. Since this hook
    and the entry point of a container are fired asynchronously, there''s no guarantee
    that the hook will be executed before the container starts. As such, we''re unlikely
    to use it to initialize resources for a container.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PostStart`：在容器创建后执行。由于这个钩子和容器的入口点是异步触发的，所以无法保证钩子会在容器启动之前执行。因此，我们不太可能使用它来初始化容器的资源。'
- en: '`PreStop`: This executes right before sending `SIGTERM` to a container. One
    difference from the `PostStart` hook is that the `PreStop` hook is a synchronous
    call; in other words, `SIGTERM` is only sent after a `PreStop` hook exited.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PreStop`：在发送`SIGTERM`到容器之前执行。与`PostStart`钩子的一个区别是，`PreStop`钩子是同步调用；换句话说，只有在`PreStop`钩子执行完毕后，`SIGTERM`才会被发送。'
- en: 'We can easily solve our `nginx` shutdown problem with a `PreStop` hook:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过`PreStop`钩子轻松解决`nginx`的关闭问题：
- en: '[PRE37]'
  id: totrans-249
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'An important property of hooks is they can affect the state of a pod in certain
    ways: a pod won''t be running unless its `PostStart` hook exits successfully.
    A pod is set to terminate immediately on deletion, but `SIGTERM` won''t be sent
    unless the `PreStop` hook exits successfully. Therefore, we can resolve a situation
    that a pod quits before its proxy rules are removed on the node by the `PreStop`
    hook.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 钩子的一个重要特性是它们可以以某种方式影响 pod 的状态：只有当`PostStart`钩子成功退出时，pod 才会运行；pod 在删除时会立即终止，但只有在`PreStop`钩子成功退出后，`SIGTERM`才会被发送。因此，我们可以通过`PreStop`钩子解决
    pod 在其代理规则在节点上被移除之前退出的问题。
- en: 'The following diagram illustrates how to use the hook to eliminate the unwanted
    gap:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了如何使用钩子来消除不必要的间隙：
- en: '![](img/956a3c06-c7c9-488d-8c63-66b7fde1d620.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![](img/956a3c06-c7c9-488d-8c63-66b7fde1d620.png)'
- en: 'The implementation is to just add a hook that sleeps for a few seconds:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 其实现方式只是添加一个挂钩，让它休眠几秒钟：
- en: '[PRE38]'
  id: totrans-254
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Tackling pod disruptions
  id: totrans-255
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 处理Pod中断
- en: Ideally, we'd like to keep the availability of our service as high as we can.
    However, there're always lots of events that cause the pods that are backing our
    service to go up and down, either voluntarily or involuntarily. Voluntary disruptions
    include `Deployment` rollouts, planned node maintenance, or the accidental killing
    of a pod with the API. On the whole, every operation that goes through the Kubernetes
    master counts. On the other hand, any unexpected outage that leads to the termination
    of our service belongs to the category of involuntary disruptions.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，我们希望尽可能保持服务的可用性。然而，总是有许多事件导致支持我们服务的Pod出现上下波动，无论是自愿的还是非自愿的。自愿中断包括`Deployment`的推出、计划中的节点维护，或者通过API意外终止Pod。总体而言，任何经过Kubernetes主控的操作都会算作一个事件。另一方面，任何导致服务终止的意外停机都属于**非自愿中断**的范畴。
- en: In previous chapters, we discussed how to prevent involuntary disruptions by
    replicating pods with `Deployment` and `StatefulSet`, appropriately configuring
    resource requests and limits, scaling an application's capacity with the autoscaler,
    and distributing pods to multiple locations with affinities and anti-affinities. Since
    we've already put a lot of effort into our service, what could go wrong when it
    comes to these expected voluntary disruptions? In fact, because they're events
    that are likely to happen, we ought to pay more attention to them.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们讨论了如何通过使用`Deployment`和`StatefulSet`复制Pod，适当配置资源请求和限制，通过自动扩展器调整应用程序的容量，并使用亲和性和反亲和性将Pod分布到多个位置，从而防止**非自愿的中断**。既然我们已经在服务上付出了很多努力，那在面对这些预期中的**自愿中断**时，可能会出现什么问题呢？事实上，由于这些事件很可能发生，我们应该更加关注它们。
- en: In `Deployment` and other similar objects, we can use the `maxUnavailable` and
    `maxSurge` fields that help us roll out our updates in a controlled manner. As
    for other cases, such as node maintenance tasks performed by cluster administrators
    who don't have domain knowledge about all the applications run in the cluster,
    the service owner can utilize `PodDisruptionBudget` to tell Kubernetes how many
    pods are required for a service to meet its service level.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 在`Deployment`和其他类似对象中，我们可以使用`maxUnavailable`和`maxSurge`字段，这些字段帮助我们以受控的方式推出更新。至于其他情况，比如由集群管理员执行的节点维护任务，这些管理员并不了解集群中运行的所有应用程序，服务所有者可以利用`PodDisruptionBudget`来告知Kubernetes，服务需要多少Pod才能达到服务水平。
- en: 'A pod disruption budget has the following syntax:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 一个Pod中断预算的语法如下：
- en: '[PRE39]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: There are two configurable fields in a pod disruption budget, but they can't
    be used together. The selector is identical to the one in `Deployment` or other
    places. Note that a pod disruption budget is immutable, which means it can't be
    updated after its creation. The `minAvailable` and `maxUnavailable` fields are
    mutually exclusive, but they're the same in some ways. For example, `maxUnavailable:0`
    means zero tolerance of any pod losses, and it's roughly equivalent to `minAvailable:100%`,
    which means that all pods should be available.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: Pod中断预算中有两个可配置的字段，但它们不能一起使用。选择器与`Deployment`或其他地方的选择器相同。需要注意的是，Pod中断预算是不可变的，这意味着它在创建后无法更新。`minAvailable`和`maxUnavailable`字段是互斥的，但在某些方面它们是相同的。例如，`maxUnavailable:0`意味着对任何Pod丢失的零容忍，基本上等同于`minAvailable:100%`，即所有Pod必须保持可用。
- en: Pod disruption budgets work by evicting events such as draining nodes or pod
    preemption. They don't interfere with the rolling update process performed by
    controllers such as `Deployment` or `StatefulSet`. Suppose that we want to temporarily
    remove one node from the cluster with `kubectl drain`, but this would violate
    certain pod disruption budgets of running applications. In this case, the draining
    operation would be blocked unless all pod disruption budgets can be satisfied.
    However, if the Kubernetes scheduler is going to evict a victim pod to fulfill high
    priority pods, the scheduler would only try to meet all of the pod disruption
    budgets if possible. If the scheduler can't find a target without breaking any
    pod disruption budgets, it would still pick a pod with the lowest priority.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 中断预算通过驱逐事件来工作，如节点排空或 Pod 优先级抢占。它们不会干扰由控制器如`Deployment`或`StatefulSet`执行的滚动更新过程。假设我们想用`kubectl
    drain`暂时从集群中移除一个节点，但这会违反某些正在运行的应用程序的 Pod 中断预算。在这种情况下，除非所有的 Pod 中断预算都能得到满足，否则排空操作会被阻止。然而，如果
    Kubernetes 调度器将驱逐一个受害 Pod 以满足高优先级的 Pods，调度器只会在可能的情况下尝试满足所有的 Pod 中断预算。如果调度器找不到不违反任何
    Pod 中断预算的目标，它仍然会选择优先级最低的 Pod。
- en: Summary
  id: totrans-263
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we've discussed topics related to building a continuous delivery
    pipeline and how to strengthen our deployment tasks. The rolling update of a pod
    is a powerful tool that allows us to perform updates in a controlled fashion.
    To trigger a rolling update, what we need to do is change the pod's specification
    in a controller that supports that rolling update. Additionally, although the
    update is managed by Kubernetes, we can still control it with `kubectl rollout` to
    a certain extent.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了与构建持续交付流水线相关的主题，以及如何加强我们的部署任务。Pod 的滚动更新是一个强大的工具，它使我们能够以受控的方式进行更新。为了触发滚动更新，我们需要做的就是在支持该滚动更新的控制器中更改
    Pod 的规格。此外，尽管更新由 Kubernetes 管理，我们仍然可以通过`kubectl rollout`在一定程度上控制它。
- en: Later on, we fabricated an extensible continuous delivery pipeline using `GitHub`/`DockerHub`/`Travis-CI`.
    We then moved on to learn more about the life cycle of pods to prevent any possible
    failures, including using the readiness and liveness probes to protect a pod;
    initializing a pod with `init` containers; handling `SIGTERM` properly by picking
    the right composition of invocation commands of the entry point of our program
    and the shell to run it; using life cycle hooks to stall a pod's readiness, as
    well as its termination for the pod to be removed from a service at the right
    time; and assigning pod disruption budgets to ensure the availability of our pods.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 随后，我们构建了一个可扩展的持续交付流水线，使用了`GitHub`/`DockerHub`/`Travis-CI`。然后，我们继续学习了更多关于 Pod
    生命周期的内容，以防止可能的失败，包括使用就绪探针和存活探针来保护 Pod；用`init`容器初始化 Pod；通过选择合适的入口程序命令和运行它的 Shell
    组合来正确处理`SIGTERM`；使用生命周期钩子来延迟 Pod 的就绪状态，以及其终止，以便 Pod 在正确的时间从服务中移除；以及分配 Pod 中断预算以确保
    Pod 的可用性。
- en: In [Chapter 10](f55d3fa8-e791-4473-83ba-ed8c4f848a90.xhtml), *Kubernetes on
    AWS*, we'll move on to learn the essentials of how to deploy the cluster on AWS,
    the major player among all public cloud providers.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在[第10章](f55d3fa8-e791-4473-83ba-ed8c4f848a90.xhtml)，*Kubernetes on AWS*，我们将继续学习如何在
    AWS（所有公共云提供商中的重要角色）上部署集群的基本要点。
