- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Getting Started with Kubernetes in the Cloud
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在云中使用Kubernetes入门
- en: Cloud computing has revolutionized how organizations access scalable IT resources,
    enabling the fast deployment of compute, storage, and networking services. For
    teams adopting containerized applications, **Kubernetes** (**K8s**) has become
    the de facto platform. Cloud providers offer managed K8s services, such as **Amazon**
    **Elastic Kubernetes Service** (**EKS**), **Google Kubernetes Engine** (**GKE**),
    and **Azure Kubernetes Service** (**AKS**), which makes it easier to run and deploy
    GenAI models.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 云计算彻底改变了组织访问可扩展IT资源的方式，使得计算、存储和网络服务的快速部署成为可能。对于采用容器化应用程序的团队，**Kubernetes**（**K8s**）已经成为事实上的平台。云服务提供商提供托管的K8s服务，如**Amazon**
    **Elastic Kubernetes Service**（**EKS**）、**Google Kubernetes Engine**（**GKE**）和**Azure
    Kubernetes Service**（**AKS**），使得在云中运行和部署GenAI模型变得更加容易。
- en: In this chapter, we’ll discuss how the cloud can help simplify the management
    of production-grade K8s clusters by offloading some of their complexities. Then,
    we’ll guide you in creating your first cluster using infrastructure automation.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论云计算如何通过减轻一些复杂性，简化生产级K8s集群的管理。然后，我们将指导你通过基础设施自动化创建你的第一个集群。
- en: 'Let’s explore the following key topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索以下关键主题：
- en: Advantages of running K8s in the cloud
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在云中运行K8s的优势
- en: Setting up a K8s cluster in the cloud
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在云中设置K8s集群
- en: Deploying our first GenAI model in the K8s cluster
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在K8s集群中部署我们的第一个GenAI模型
- en: Advantages of running K8s in the cloud
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在云中运行K8s的优势
- en: 'A report published in 2023, *Kubernetes in the wild report 2023* ([https://www.dynatrace.com/news/blog/kubernetes-in-the-wild-2023/](https://www.dynatrace.com/news/blog/kubernetes-in-the-wild-2023/)),
    states that the number of K8s clusters in the cloud grew about five times as fast
    as the clusters hosted on-premises at the same time. This is primarily attributed
    to the following factors:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 一份2023年发布的报告，《Kubernetes in the wild report 2023》([https://www.dynatrace.com/news/blog/kubernetes-in-the-wild-2023/](https://www.dynatrace.com/news/blog/kubernetes-in-the-wild-2023/))指出，云中K8s集群的数量增长速度大约是同时期本地托管集群的五倍。这主要归因于以下几个因素：
- en: '**Managed services**: Operating a production-grade K8s cluster typically involves
    ensuring there’s a highly available control plane, cluster management activities
    such as creating, upgrading, and patching all K8s control plane and data plane
    components, resource management, security, monitoring, and more. Many of these
    activities add significant operational overhead, which is undifferentiated and
    takes time and resources away from core business operations. Due to this, many
    K8s consumers have chosen to offload the undifferentiated heavy lifting of managing
    K8s clusters by choosing one of the managed offerings that’s available. Some of
    the notable managed K8s offerings are as follows:'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**托管服务**：运营一个生产级的K8s集群通常需要确保控制平面高可用，集群管理活动（如创建、升级和修补所有K8s控制平面和数据平面组件）、资源管理、安全性、监控等。许多这些活动增加了显著的运营开销，而这些开销是没有差异化的，且会占用核心业务运营的时间和资源。因此，许多K8s用户选择通过选择现有的托管服务之一来将管理K8s集群的繁重任务外包。一些著名的托管K8s服务如下：'
- en: '**Amazon EKS**: This is a managed service that’s used to run K8s in the AWS
    cloud and on-premises data centers. With Amazon EKS, you can take advantage of
    all the performance, scale, reliability, and security aspects of AWS infrastructure,
    as well as implement deeper integrations with other AWS-managed services. To learn
    more, visit [https://aws.amazon.com/eks/](https://aws.amazon.com/eks/).'
  id: totrans-11
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon EKS**：这是一项托管服务，用于在AWS云和本地数据中心运行K8s。使用Amazon EKS，你可以利用AWS基础设施的所有性能、规模、可靠性和安全性，并且能够与其他AWS托管服务进行更深入的集成。欲了解更多信息，请访问[https://aws.amazon.com/eks/](https://aws.amazon.com/eks/)。'
- en: '**GKE**: This is a managed K8s service from **Google Cloud Platform** (**GCP**)
    that you can use to deploy and operate containerized applications using Google’s
    infrastructure. It is available in Standard and Enterprise editions, where the
    former provides fully automated cluster life cycle management and the latter provides
    powerful features for governing, managing, and operating containerized workloads
    at enterprise scale. To learn more, go to [https://cloud.google.com/kubernetes-engine](https://cloud.google.com/kubernetes-engine).'
  id: totrans-12
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GKE**：这是一个来自**谷歌云平台**（**GCP**）的托管 K8s 服务，你可以利用它在谷歌的基础设施上部署和操作容器化应用程序。它提供标准版和企业版，其中标准版提供完全自动化的集群生命周期管理，企业版则提供强大的功能来治理、管理和操作大规模企业容器化工作负载。如需了解更多信息，请访问
    [https://cloud.google.com/kubernetes-engine](https://cloud.google.com/kubernetes-engine)。'
- en: '**AKS**: This is a managed service from Azure that simplifies deploying, managing,
    and scaling K8s clusters. AKS automates critical tasks such as monitoring, upgrades,
    and scaling while integrating with other Azure services such as Active Directory,
    Load Balancer, and Virtual Network. To learn more, go to [https://azure.microsoft.com/en-us/products/kubernetes-service](https://azure.microsoft.com/en-us/products/kubernetes-service).'
  id: totrans-13
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AKS**：这是 Azure 提供的一个托管服务，用于简化 K8s 集群的部署、管理和扩展。AKS 自动化了关键任务，如监控、升级和扩展，同时与其他
    Azure 服务（如 Active Directory、负载均衡器和虚拟网络）集成。如需了解更多信息，请访问 [https://azure.microsoft.com/en-us/products/kubernetes-service](https://azure.microsoft.com/en-us/products/kubernetes-service)。'
- en: Apart from these, there are many other managed K8s offerings from companies
    such as Red Hat, Oracle Cloud Infrastructure (OCI), Alibaba Cloud, and others.
    The goal of these offerings is to simplify K8s cluster operations and provide
    deeper integrations with the respective cloud provider infrastructure.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 除此之外，还有许多其他由公司提供的托管 K8s 服务，如 Red Hat、Oracle Cloud Infrastructure (OCI)、阿里云等。这些服务的目标是简化
    K8s 集群操作，并提供与相应云服务提供商基础设施的更深层次集成。
- en: '**Scalability and efficiency**: Cloud providers offer seamless scalability
    for running K8s clusters by providing access to on-demand infrastructure and a
    pay-as-you-go pricing model. As the clusters grow in size, they automatically
    scale the K8s control plane components to match their usage.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性与效率**：云服务提供商通过提供按需基础设施和按量计费的定价模式，提供无缝的 K8s 集群可扩展性。随着集群规模的增长，它们会自动扩展 K8s
    控制平面组件，以适应其使用需求。'
- en: '**Availability and Global expansion**: All managed K8s offerings provide strict
    uptime **service-level agreements** (**SLAs**) – for example, Amazon EKS offers
    99.95%. To achieve this, they often deploy multiple instances of an API server
    with etcd database components spread across multiple **Availability Zones** (**AZs**),
    automatically monitor the health of those components, and recover/replace any
    unhealthy components. Cloud providers also operate in multiple geographical areas
    called **Regions**; note that their definition may vary between cloud providers.
    For example, an AWS Region consists of multiple physically separated and isolated
    AZs that are connected with low-latency, high throughput, highly redundant networks.
    We can utilize these regions to deploy the workload for global users or to implement
    disaster recovery mechanisms.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可用性与全球扩展**：所有托管的 K8s 服务都提供严格的正常运行时间**服务级别协议**（**SLA**）—例如，Amazon EKS 提供 99.95%
    的正常运行时间。为了实现这一目标，它们通常会部署多个 API 服务器实例，且其 etcd 数据库组件分布在多个**可用区**（**AZ**）之间，自动监控这些组件的健康状况，并恢复或替换任何不健康的组件。云服务提供商还在多个地理区域运营，这些区域被称为**区域**；注意，不同的云服务提供商对区域的定义可能有所不同。例如，AWS
    的一个区域由多个物理上分离且相互隔离的 AZ 组成，这些 AZ 通过低延迟、高吞吐量、高冗余的网络连接。我们可以利用这些区域为全球用户部署工作负载或实施灾难恢复机制。'
- en: '**Security and compliance**: There’s always a shared responsibility between
    cloud providers and consumers. Providers are responsible for the security and
    compliance of the cloud while you, as a consumer, are responsible for security
    and compliance in the cloud. This means that the cloud provider ensures the managed
    components of K8s offerings such as the **control plane** are secured and meet
    various compliance standards such as **PCI DSS**, **HIPPA**, **GDPR**, **SOC**,
    and others. You, as a consumer, are responsible for securing the applications
    and self-managed K8s add-ons in the cluster. Additionally, the cloud provider
    takes care of automatically patching the control plane components to keep them
    secure.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性和合规性**：云服务提供商和消费者之间始终存在共享责任。提供商负责云的安全性和合规性，而作为消费者，你负责云中的安全性和合规性。这意味着云服务提供商确保K8s产品的托管组件（如**控制平面**）是安全的，并符合各种合规标准，如**PCI
    DSS**、**HIPPA**、**GDPR**、**SOC**等。作为消费者，你需要负责保障集群中应用程序和自管K8s插件的安全。此外，云服务提供商还负责自动修补控制平面组件，以确保其安全。'
- en: '**Native integration**: To operate a production-ready K8s cluster, we need
    to integrate with many external components, such as storage systems, databases,
    load balancers, and monitoring and security tools. Cloud providers often provide
    managed services for those components and create seamless integrations with their
    managed K8s offerings. This makes it easier to build end-to-end solutions and
    takes away the pain of performing compatibility testing for various components.
    It also provides seamless integrations with various **third-party** (**3P**) tools
    such as **Splunk** ([https://www.splunk.com/](https://www.splunk.com/)), **Datadog**
    ([https://www.datadoghq.com/](https://www.datadoghq.com/)), **New Relic** ([https://newrelic.com/](https://newrelic.com/)),
    **Aqua Security** ([https://www.aquasec.com/](https://www.aquasec.com/)), **Sysdig**
    ([https://sysdig.com/](https://sysdig.com/)), **Kubecost** ([https://www.kubecost.com/](https://www.kubecost.com/)),
    and others for monitoring and security purposes, as well as to allocate and optimize
    the cost of K8s workloads.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**原生集成**：要操作一个生产就绪的K8s集群，我们需要与许多外部组件进行集成，如存储系统、数据库、负载均衡器以及监控和安全工具。云服务提供商通常为这些组件提供托管服务，并与他们的托管K8s产品创建无缝集成。这使得构建端到端解决方案变得更容易，并消除了对各种组件进行兼容性测试的痛苦。它还提供与各种**第三方**（**3P**）工具的无缝集成，如**Splunk**（[https://www.splunk.com/](https://www.splunk.com/)）、**Datadog**（[https://www.datadoghq.com/](https://www.datadoghq.com/)）、**New
    Relic**（[https://newrelic.com/](https://newrelic.com/)）、**Aqua Security**（[https://www.aquasec.com/](https://www.aquasec.com/)）、**Sysdig**（[https://sysdig.com/](https://sysdig.com/)）、**Kubecost**（[https://www.kubecost.com/](https://www.kubecost.com/)）等，用于监控和安全目的，并为K8s工作负载分配和优化成本。'
- en: '**Extended support**: At the time of writing, the K8s community releases a
    new K8s version approximately three times a year. As depicted in *Figure 3**.1*,
    each version is supported for 12 months. During this time, the community provides
    patch releases that include bug fixes, security patches, and more. Performing
    multiple K8s version upgrades often adds significant overhead to the platform
    engineering teams as each version upgrade involves verifying and remediating any
    usage of deprecated APIs, as well as upgrading the control plane, data plane,
    and operational add-ons while ensuring application availability. Cloud providers
    offer extended support for up to 26 months from the release date so that customers
    can plan and execute their cluster upgrades. It’s always recommended to stay on
    the latest K8s releases so that you can leverage the latest innovations from the
    community, so it’s crucial to automate cluster life cycle operations using **Infrastructure
    as** **Code** (**IaC**):'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩展支持**：截至目前，K8s社区大约每年发布三个新的K8s版本。如*图3.1*所示，每个版本的支持期限为12个月。在此期间，社区会提供补丁发布，包括错误修复、安全补丁等。执行多个K8s版本的升级通常会为平台工程团队带来较大负担，因为每次版本升级都涉及验证并修复任何已弃用的API的使用，以及升级控制平面、数据平面和操作插件，同时确保应用程序的可用性。云服务提供商提供最长26个月的扩展支持，帮助客户规划和执行集群升级。始终建议使用最新的K8s版本，以便能够利用社区的最新创新，因此，自动化集群生命周期操作使用**基础设施即代码**（**IaC**）是至关重要的。'
- en: '![Figure 3.1 – K8s release cycle](img/B31108_03_1.jpg)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图3.1 – K8s发布周期](img/B31108_03_1.jpg)'
- en: Figure 3.1 – K8s release cycle
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1 – K8s发布周期
- en: In this section, we learned about the advantages of using managed K8s offerings
    from various cloud providers. These let us utilize the seamless scalability of
    the cloud, ease of management, and global expansion so that we can cater to various
    geographical customers and meet and exceed security and compliance requirements
    while operating cost-efficiently. Next, we will set up our first K8s cluster in
    the AWS cloud using IaC and deploy the `my-llama` model in it.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解了使用各大云服务提供商的托管 K8s 服务的优势。这些服务使我们能够利用云的无缝扩展性、简便的管理和全球扩展，以便满足不同地域客户的需求，同时在运营中高效控制成本并达到甚至超越安全性和合规性要求。接下来，我们将使用基础设施即代码（IaC）在
    AWS 云中设置我们的第一个 K8s 集群，并将 `my-llama` 模型部署到其中。
- en: Setting up a K8s cluster in the cloud
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在云中设置 K8s 集群
- en: Managed K8s offerings are generally upstream and K8s-compliant, which means
    we can seamlessly migrate the workloads from one offering to another without changing
    the application code. You may still need to use cloud-provider-specific add-ons
    to integrate with respective cloud services. Due to this, throughout the rest
    of this book, we will be using the AWS cloud and Amazon EKS. You can replicate
    a similar setup using other cloud provider offerings.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 托管 K8s 服务通常是上游的并符合 K8s 标准，这意味着我们可以在不修改应用代码的情况下，无缝地将工作负载从一个服务迁移到另一个服务。你可能仍然需要使用云服务商特定的附加组件，以便与相应的云服务进行集成。由于这一点，在本书的其余部分，我们将使用
    AWS 云和 Amazon EKS。你也可以使用其他云服务商的产品进行类似的设置。
- en: 'Amazon EKS is a regional AWS service that eliminates the need to install, operate,
    and maintain a K8s control plane on AWS. An Amazon EKS cluster provides a single-tenant,
    highly available K8s control plane that is spread across three AZs to withstand
    AZ-wide failures. For the data plane, you can choose from the options shown in
    *Figure 3**.2*:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon EKS 是一项区域性的 AWS 服务，消除了在 AWS 上安装、操作和维护 K8s 控制平面的需要。一个 Amazon EKS 集群提供一个单租户、高可用的
    K8s 控制平面，分布在三个可用区（AZ）中，以应对可用区范围内的故障。对于数据平面，你可以从 *图 3.2* 中展示的选项中进行选择：
- en: '![Figure 3.2 – Amazon EKS data plane options](img/B31108_03_2.jpg)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![图 3.2 – 亚马逊 EKS 数据平面选项](img/B31108_03_2.jpg)'
- en: Figure 3.2 – Amazon EKS data plane options
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.2 – 亚马逊 EKS 数据平面选项
- en: 'Let’s learn about these options in detail:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细了解这些选项：
- en: '**Self-managed nodes**: This is a group of **Amazon EC2** ([https://aws.amazon.com/ec2/](https://aws.amazon.com/ec2/))
    instances that are manually managed by the users. Amazon EC2 is a managed service
    that provides resizable compute capacity in the AWS cloud. Customers are responsible
    for bootstrapping the worker nodes so that they can join the cluster and managing
    their life cycle operations (provisioning, updating, and destroying). This option
    provides fine-grained control over node configuration, setup, and management and
    also adds operational overhead.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自管理节点**：这是由用户手动管理的一组 **Amazon EC2** ([https://aws.amazon.com/ec2/](https://aws.amazon.com/ec2/))
    实例。Amazon EC2 是一项托管服务，提供可扩展的计算能力，用于 AWS 云中。客户负责启动工作节点，使其能够加入集群，并管理其生命周期操作（如配置、更新和销毁）。此选项提供了对节点配置、设置和管理的精细控制，但也增加了操作开销。'
- en: '**EKS-managed node group**: This is the most popular choice for EKS users.
    It provides APIs to automate the process of provisioning and managing the life
    cycle of the worker nodes. Every managed node group is provisioned as part of
    an Amazon EC2 **Auto Scaling group** (**ASG**) ([https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html)),
    which is managed by Amazon EKS. An ASG automatically manages the scaling of EC2
    instances, ensuring the appropriate number of instances are running to handle
    the load. To learn more, go to [https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html](https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html).'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**EKS 托管节点组**：这是 EKS 用户中最受欢迎的选择。它提供了自动化的 API，用于配置和管理工作节点的生命周期。每个托管节点组都作为 Amazon
    EC2 **自动扩展组** (**ASG**) ([https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html](https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html))
    的一部分进行配置，并由 Amazon EKS 管理。ASG 会自动管理 EC2 实例的扩展，确保运行适当数量的实例来处理负载。欲了解更多信息，请访问 [https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html](https://docs.aws.amazon.com/eks/latest/userguide/managed-node-groups.html)。'
- en: '**AWS Fargate**: This is a serverless compute engine for running containerized
    workloads. With AWS Fargate, you don’t have to manage the underlying compute infrastructure
    that runs the K8s Pods. AWS handles how the worker nodes are provisioned, configured,
    patched, and scaled. It automatically provisions the compute capacity that matches
    your Pod resource requirements and provides higher-level security isolation by
    providing a dedicated kernel for each Pod. Visit [https://docs.aws.amazon.com/eks/latest/userguide/fargate.html](https://docs.aws.amazon.com/eks/latest/userguide/fargate.html)
    to learn more.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS Fargate**：这是一种无服务器计算引擎，用于运行容器化工作负载。使用AWS Fargate，您无需管理运行K8s Pods的底层计算基础设施。AWS负责管理工作节点的配置、补丁和扩展。它会自动配置与您的Pod资源要求匹配的计算容量，并通过为每个Pod提供专用内核来提供更高级别的安全隔离。访问[https://docs.aws.amazon.com/eks/latest/userguide/fargate.html](https://docs.aws.amazon.com/eks/latest/userguide/fargate.html)了解更多信息。'
- en: '**Karpenter managed nodes**: Karpenter is a high-performance cluster autoscaling
    solution that automatically launches the right amount of compute resources to
    handle the cluster workloads available. It observes the aggregate resource requirements
    of unscheduled Pods and makes decisions to launch and terminate the worker nodes.
    We will explore this in detail in [*Chapter 6*](B31108_06.xhtml#_idTextAnchor075)*.*
    Go to [https://karpenter.sh/](https://karpenter.sh/) to learn more.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Karpenter管理节点**：Karpenter是一个高性能的集群自动扩展解决方案，它会自动启动合适数量的计算资源来处理集群的工作负载。它会观察未调度Pod的聚合资源需求，并做出启动和终止工作节点的决策。我们将在[*第6章*](B31108_06.xhtml#_idTextAnchor075)中详细探讨这个问题。访问[https://karpenter.sh/](https://karpenter.sh/)了解更多信息。'
- en: For a detailed comparison of these data plane options, you can refer to the
    EKS documentation at [https://docs.aws.amazon.com/eks/latest/userguide/eks-compute.html](https://docs.aws.amazon.com/eks/latest/userguide/eks-compute.html).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 关于这些数据平面选项的详细比较，您可以参考EKS文档：[https://docs.aws.amazon.com/eks/latest/userguide/eks-compute.html](https://docs.aws.amazon.com/eks/latest/userguide/eks-compute.html)。
- en: 'We will be using an IaC tool to automate the process of provisioning the necessary
    AWS infrastructure. **Terraform** ([https://www.hashicorp.com/products/terraform](https://www.hashicorp.com/products/terraform))
    is the most popular and cloud-agnostic IaC tool available and is developed by
    HashiCorp ([https://www.hashicorp.com/](https://www.hashicorp.com/)). It is used
    to automatically provision and manage resources in any cloud or data center. Terraform
    uses a domain-specific language called **HashiCorp Configuration Language** (**HCL**)
    ([https://github.com/hashicorp/hcl](https://github.com/hashicorp/hcl)) to define
    the infrastructure while providing support for input and output variables so that
    the configuration can be customized. To learn more about Terraform, follow the
    Get Started - AWS tutorial on the HashiCorp website: [https://developer.hashicorp.com/terraform/tutorials/aws-get-started](https://developer.hashicorp.com/terraform/tutorials/aws-get-started).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用一个IaC工具来自动化配置所需AWS基础设施的过程。**Terraform**([https://www.hashicorp.com/products/terraform](https://www.hashicorp.com/products/terraform))是最流行的云无关的IaC工具，由HashiCorp公司开发([https://www.hashicorp.com/](https://www.hashicorp.com/))。它被用来自动配置和管理任何云或数据中心中的资源。Terraform使用一种称为**HashiCorp配置语言**(**HCL**)([https://github.com/hashicorp/hcl](https://github.com/hashicorp/hcl))的领域特定语言来定义基础设施，并支持输入和输出变量，从而使得配置可以定制化。要了解更多关于Terraform的信息，请参阅HashiCorp网站上的AWS入门教程：[https://developer.hashicorp.com/terraform/tutorials/aws-get-started](https://developer.hashicorp.com/terraform/tutorials/aws-get-started)。
- en: 'To promote modularity, multiple configuration files can be organized into a
    Terraform module to encapsulate a set of related resources. There is a large Terraform
    community that maintains the registry of open source modules at [https://registry.terraform.io/](https://registry.terraform.io/)
    that’s available for public use. We will be using the following community modules
    to provision the necessary infrastructure in this walkthrough:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 为了促进模块化，多个配置文件可以组织成一个Terraform模块，以封装一组相关的资源。Terraform有一个庞大的社区，维护着一个开源模块的注册表，您可以在[https://registry.terraform.io/](https://registry.terraform.io/)中找到供公众使用的模块。在本教程中，我们将使用以下社区模块来配置所需的基础设施：
- en: The **AWS VPC Terraform** module ([https://registry.terraform.io/modules/terraform-aws-modules/vpc/aws/latest](https://registry.terraform.io/modules/terraform-aws-modules/vpc/aws/latest))
    will be used to create Amazon VPC resources
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS VPC Terraform**模块([https://registry.terraform.io/modules/terraform-aws-modules/vpc/aws/latest](https://registry.terraform.io/modules/terraform-aws-modules/vpc/aws/latest))将用于创建Amazon
    VPC资源。'
- en: The **AWS EKS Terraform** module ([https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/latest](https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/latest))
    will be used to create an Amazon EKS cluster, node groups, AWS Fargate profiles,
    and more
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS EKS Terraform** 模块（[https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/latest](https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/latest)）将用于创建
    Amazon EKS 集群、节点组、AWS Fargate 配置文件等。'
- en: The **Amazon EKS Blueprints Addons** module ([https://registry.terraform.io/modules/aws-ia/eks-blueprints-addons/aws/latest](https://registry.terraform.io/modules/aws-ia/eks-blueprints-addons/aws/latest))
    will be used to deploy K8s add-ons on Amazon EKS clusters
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon EKS 蓝图插件**模块（[https://registry.terraform.io/modules/aws-ia/eks-blueprints-addons/aws/latest](https://registry.terraform.io/modules/aws-ia/eks-blueprints-addons/aws/latest)）将用于在
    Amazon EKS 集群上部署 K8s 插件。'
- en: Let’s start by setting up our environment so that we can provision the EKS cluster
    using Terraform.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从设置环境开始，以便使用 Terraform 配置 EKS 集群。
- en: Important note
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: In this walkthrough, we will be creating AWS resources that are not part of
    the AWS free tier, so you will incur charges. Please refer to AWS Pricing Calculator
    at [https://calculator.aws/#/](https://calculator.aws/#/) for a cost estimate.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，我们将创建一些不属于 AWS 免费套餐的 AWS 资源，因此你会产生费用。请参考 AWS 定价计算器 [https://calculator.aws/#/](https://calculator.aws/#/)
    获取费用估算。
- en: Prerequisites
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前提条件
- en: 'Here are the prerequisites for setting up a K8s cluster in the cloud:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是在云中设置 K8s 集群的前提条件：
- en: Create a free **AWS account** at [https://aws.amazon.com/free/](https://aws.amazon.com/free/)
    if you haven’t got one already. AWS provides generous free tiers across many of
    its services. Amazon EKS is *not* part of the free tier, so any resources that
    are provisioned in this walkthrough will incur some charges.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你还没有 AWS 账户，可以在 [https://aws.amazon.com/free/](https://aws.amazon.com/free/)
    创建一个免费的 **AWS 账户**。AWS 提供了许多服务的慷慨免费套餐。Amazon EKS *不*属于免费套餐，因此本教程中配置的任何资源都会产生费用。
- en: Create an **IAM user** with administrator privileges by following the instructions
    at [https://docs.aws.amazon.com/streams/latest/dev/setting-up.html#setting-up-iam](https://docs.aws.amazon.com/streams/latest/dev/setting-up.html#setting-up-iam)
    and generate programmatic access credentials.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 按照 [https://docs.aws.amazon.com/streams/latest/dev/setting-up.html#setting-up-iam](https://docs.aws.amazon.com/streams/latest/dev/setting-up.html#setting-up-iam)
    中的说明创建一个具有管理员权限的 **IAM 用户**，并生成编程访问凭证。
- en: Install the **AWS CLI** by going to [https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)
    and configure it with the AWS access credentials of an administrator user.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过访问 [https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)
    安装 **AWS CLI**，并使用管理员用户的 AWS 访问凭证进行配置。
- en: Install the **Terraform CLI** by going to [https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli](https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli).
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过访问 [https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli](https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli)
    安装 **Terraform CLI**。
- en: Install **kubectl**, the official CLI tool for interacting with K8s clusters,
    by going to [https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html](https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html).
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过访问 [https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html](https://docs.aws.amazon.com/eks/latest/userguide/install-kubectl.html)
    安装 **kubectl**，这是与 K8s 集群交互的官方 CLI 工具。
- en: Provisioning the Amazon EKS cluster
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置 Amazon EKS 集群
- en: Important note
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Terraform providers and modules are frequently updated with new features and
    fixes. We’ve used the latest compatible versions that were available at the time
    of writing. You can update those to their latest versions by going to the Terraform
    Registry at [https://registry.terraform.io/](https://registry.terraform.io/).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform 提供者和模块经常更新，带来新的功能和修复。在编写时，我们使用了可用的最新兼容版本。你可以通过访问 Terraform 注册表 [https://registry.terraform.io/](https://registry.terraform.io/)
    来更新到最新版本。
- en: 'Let’s start by setting up the Terraform project:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从设置 Terraform 项目开始：
- en: 'Create a new project directory called `genai-eks-demo`:'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为 `genai-eks-demo` 的新项目目录：
- en: '[PRE0]'
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: terraform {
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: terraform {
- en: required_version = ">= 1.11"
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: required_version = ">= 1.11"
- en: required_providers {
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: required_providers {
- en: aws = {
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: aws = {
- en: source = "hashicorp/aws"
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: source = "hashicorp/aws"
- en: version = ">= 5.96"
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: version = ">= 5.96"
- en: '}'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '}'
- en: helm = {
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: helm = {
- en: source = "hashicorp/helm"
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: source = "hashicorp/helm"
- en: version = ">= 2.17"
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: version = ">= 2.17"
- en: '}'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '}'
- en: kubernetes = {
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: kubernetes = {
- en: source = "hashicorp/kubernetes"
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: source = "hashicorp/kubernetes"
- en: version = ">= 2.36"
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: version = ">= 2.36"
- en: '}'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '}'
- en: '}'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '}'
- en: 'locals.tf file for storing local variables such as name, AWS Region, and VPC
    azs to fetch the AWS AZs in the given AWS Region (us-west-2) and filtering them
    by opt-in-status. You can download the locals.tf file from our GitHub repository
    at https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/locals.tf:'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`locals.tf` 文件用于存储本地变量，如名称、AWS区域和VPC可用区（azs），用于获取给定AWS区域（us-west-2）中的AWS可用区（AZs），并按opt-in状态进行过滤。你可以从我们的GitHub仓库下载
    `locals.tf` 文件，链接地址为 [https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/locals.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/locals.tf)：'
- en: '[PRE1]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Create a `providers.tf` file for configuring the Terraform providers. Here,
    we are initializing K8s and Helm providers with the EKS cluster credentials provided
    to interact with the cluster. You can download the `providers.tf` file from our
    GitHub repository at [https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/providers.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/providers.tf):'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `providers.tf` 文件，用于配置Terraform提供程序。在这里，我们使用EKS集群凭证初始化K8s和Helm提供程序，以便与集群进行交互。你可以从我们的GitHub仓库下载
    `providers.tf` 文件，链接地址为 [https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/providers.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/providers.tf)：
- en: '[PRE3]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Create a `vpc.tf` file that will define the Amazon VPC, public and private
    subnets, internet gateway, NAT gateway, and other networking resources required
    for the EKS cluster. Refer to the AWS documentation at [https://docs.aws.amazon.com/vpc/latest/userguide/how-it-works.html](https://docs.aws.amazon.com/vpc/latest/userguide/how-it-works.html)
    to learn more about these concepts. You can download the `vpc.tf` file from our
    GitHub repository at [https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/vpc.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/vpc.tf):'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `vpc.tf` 文件，用于定义Amazon VPC、公共和私有子网、互联网网关、NAT网关以及EKS集群所需的其他网络资源。你可以参考AWS文档
    [https://docs.aws.amazon.com/vpc/latest/userguide/how-it-works.html](https://docs.aws.amazon.com/vpc/latest/userguide/how-it-works.html)
    来了解更多关于这些概念的信息。你可以从我们的GitHub仓库下载 `vpc.tf` 文件，链接地址为 [https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/vpc.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/vpc.tf)：
- en: '[PRE4]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: To deploy the Amazon VPC resources using Terraform, start by running `terraform
    init` ([https://developer.hashicorp.com/terraform/cli/commands/init](https://developer.hashicorp.com/terraform/cli/commands/init)).
    This command initializes your working directory by downloading the required Terraform
    provider plugins and configuring the backend for storing Terraform’s state. It
    ensures that your environment has been set up properly before making any changes.
    Next, run `terraform plan` ([https://developer.hashicorp.com/terraform/cli/commands/plan](https://developer.hashicorp.com/terraform/cli/commands/plan))
    to generate an execution plan, which allows you to preview the actions Terraform
    will take, such as which resources will be created, modified, or destroyed, without
    actually making any changes. Reviewing the plan helps catch potential misconfigurations
    early. Finally, run `terraform apply` ([https://developer.hashicorp.com/terraform/cli/commands/apply](https://developer.hashicorp.com/terraform/cli/commands/apply))
    to apply the changes to your infrastructure.
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要使用Terraform部署Amazon VPC资源，首先运行 `terraform init` （[https://developer.hashicorp.com/terraform/cli/commands/init](https://developer.hashicorp.com/terraform/cli/commands/init)）。此命令将初始化你的工作目录，下载所需的Terraform提供程序插件，并配置后端来存储Terraform的状态。它确保你的环境已正确设置，才能进行任何更改。接下来，运行
    `terraform plan` （[https://developer.hashicorp.com/terraform/cli/commands/plan](https://developer.hashicorp.com/terraform/cli/commands/plan)）生成执行计划，让你预览Terraform将采取的操作，比如哪些资源将被创建、修改或销毁，而不会实际进行更改。审查计划有助于及早发现潜在的配置错误。最后，运行
    `terraform apply` （[https://developer.hashicorp.com/terraform/cli/commands/apply](https://developer.hashicorp.com/terraform/cli/commands/apply)）将更改应用到你的基础设施上。
- en: 'This command provisions the defined VPC resources and prompts for confirmation
    before making any changes:'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此命令将配置定义的VPC资源，并在进行任何更改之前提示确认：
- en: '[PRE5]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'After completion, you will notice the VPC ID in the output:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，你将在输出中看到VPC ID：
- en: '[PRE6]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'In the `eks.tf` file, we must define the EKS cluster using the `terraform-aws-modules/eks`
    ([https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/latest](https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/latest))
    module. This module simplifies EKS provisioning by abstracting away low-level
    AWS API calls. Here, we must specify the desired cluster version, VPC subnets,
    and managed node groups. We are defining one managed node group with a minimum
    of two EC2 worker nodes from the `General Purpose (m)` instance family. Feel free
    to modify the `instance_types` attribute value if you encounter an `InsufficientInstanceCapacity`
    ([https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html#troubleshooting-launch-capacity](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html#troubleshooting-launch-capacity))
    error from AWS. You can choose `General Purpose` instance types from this page:
    [https://aws.amazon.com/ec2/instance-types/](https://aws.amazon.com/ec2/instance-types/).'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`eks.tf`文件中，我们必须使用`terraform-aws-modules/eks`（[https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/latest](https://registry.terraform.io/modules/terraform-aws-modules/eks/aws/latest)）模块来定义EKS集群。这个模块通过抽象化底层的AWS
    API调用，简化了EKS的配置。在这里，我们需要指定所需的集群版本、VPC子网和托管节点组。我们定义了一个托管节点组，至少包含两台来自`通用目的（m）`实例系列的EC2工作节点。如果遇到`InsufficientInstanceCapacity`（[https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html#troubleshooting-launch-capacity](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/troubleshooting-launch.html#troubleshooting-launch-capacity)）错误，可以随时修改`instance_types`属性的值。你可以从此页面选择`通用目的`实例类型：[https://aws.amazon.com/ec2/instance-types/](https://aws.amazon.com/ec2/instance-types/)。
- en: 'In this example, we are defining a managed node group (`eks-mng`) for an EKS
    cluster. This node group is a group of EC2 instances that will serve as worker
    nodes in the cluster. In the `m5.large`, `m6i.large`, `m6a.large`, and others.
    EKS will attempt to use one of these instances based on availability. This enables
    instance-type flexibility, which improves resiliency and may reduce costs by taking
    advantage of Spot Instance pools or regional availability. You can download the
    `eks.tf` file from our GitHub repository at [https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/eks.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/eks.tf):'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个示例中，我们为EKS集群定义了一个托管节点组（`eks-mng`）。这个节点组是一组EC2实例，将作为集群中的工作节点。在`m5.large`、`m6i.large`、`m6a.large`等实例类型中，EKS将根据可用性尝试使用这些实例之一。这使得实例类型更加灵活，有助于提高弹性，并可能通过利用Spot实例池或区域可用性来降低成本。你可以从我们的GitHub仓库下载`eks.tf`文件：[https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/eks.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/eks.tf)。
- en: '[PRE7]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Apply the Terraform code to deploy the EKS cluster and the managed node group
    resources. EKS also deploys default networking add-ons such as `vpc-cni`, `kube-proxy`,
    and CoreDNS in the cluster:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用Terraform代码以部署EKS集群和托管节点组资源。EKS还会在集群中部署默认的网络附加组件，如`vpc-cni`、`kube-proxy`和CoreDNS。
- en: '[PRE8]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'After successful deployment, you will notice the following output. You can
    use this to configure your `kubectl` CLI so that it can interact with the EKS
    cluster:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 部署成功后，你将看到以下输出。你可以使用它来配置`kubectl` CLI，以便它与EKS集群进行交互。
- en: '[PRE9]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Copy and run the following command in your terminal to point the `kubectl`
    CLI to the `eks-demo` cluster:'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 复制并在终端中运行以下命令，将`kubectl` CLI指向`eks-demo`集群：
- en: '[PRE10]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Next, we will install the required operational add-on software to make our
    EKS cluster production-ready. This includes add-ons such as `addons.tf` from our
    GitHub repository at [https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/addons.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/addons.tf).
    We are using the **eks-blueprints-addons** ([https://github.com/aws-ia/terraform-aws-eks-blueprints-addons](https://github.com/aws-ia/terraform-aws-eks-blueprints-addons))
    Terraform module to deploy these add-ons on the EKS cluster:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将安装所需的操作附加软件，使我们的EKS集群准备好投入生产使用。这包括来自我们GitHub仓库的`addons.tf`等附加组件：[https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/addons.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/addons.tf)。我们正在使用**eks-blueprints-addons**（[https://github.com/aws-ia/terraform-aws-eks-blueprints-addons](https://github.com/aws-ia/terraform-aws-eks-blueprints-addons)）Terraform模块，将这些附加组件部署到EKS集群中。
- en: '[PRE11]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Apply the Terraform code to deploy the add-on software on the cluster:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用Terraform代码以在集群上部署附加软件：
- en: '[PRE12]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Verify the installation by running the following `kubectl` commands. You will
    notice that there are two worker nodes and 10 K8s Pods running in the cluster:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下`kubectl`命令验证安装。你会注意到集群中有两个工作节点和10个K8s Pod在运行：
- en: '[PRE13]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'This wraps up the initial setup of the EKS cluster. The process is depicted
    in *Figure 3**.3*:'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这就完成了EKS集群的初始设置。该过程如*图3.3*所示：
- en: '![Figure 3.3 – High-level architecture of our EKS cluster](img/B31108_03_3.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图3.3 – 我们EKS集群的高级架构](img/B31108_03_3.jpg)'
- en: Figure 3.3 – High-level architecture of our EKS cluster
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.3 – 我们EKS集群的高级架构
- en: We started by setting up the required tools, which include Terraform, the AWS
    CLI, kubectl, and others, and created a Terraform project to provision various
    AWS network components, such as Amazon VPCs, subnets, and internet gateways, before
    deploying an Amazon EKS cluster alongside AWS Load Balancer and Karpenter add-ons.
    We will build on top of this setup throughout this book and create a production-ready
    system for deploying and operating GenAI workloads.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们从设置所需的工具开始，这些工具包括Terraform、AWS CLI、kubectl等，并创建了一个Terraform项目来配置各种AWS网络组件，如Amazon
    VPC、子网和互联网网关，然后在此基础上部署了Amazon EKS集群，并添加了AWS负载均衡器和Karpenter插件。我们将在本书中继续构建这个设置，并创建一个生产就绪的系统，用于部署和运营生成型AI工作负载。
- en: Deploying our first GenAI model in the K8s cluster
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在K8s集群中部署我们的第一个生成型AI模型
- en: 'In this section, we will deploy the Llama model we built in [*Chapter 2*](B31108_02.xhtml#_idTextAnchor027)
    on the EKS cluster and expose it to our end users using an AWS `nginx-pod` using
    the latest `nginx` container image running on port `80`. You can download this
    manifest file from our GitHub repository at [https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/nginx-pod.yaml](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/nginx-pod.yaml):'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将在EKS集群上部署我们在[*第2章*](B31108_02.xhtml#_idTextAnchor027)中构建的Llama模型，并使用最新的`nginx`容器镜像，通过AWS的`nginx-pod`暴露给终端用户，该容器运行在`80`端口。你可以从我们的GitHub仓库下载此清单文件：[https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/nginx-pod.yaml](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/nginx-pod.yaml)：
- en: '[PRE14]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'K8s also provides high-level abstracted constructs so that we can manage our
    workloads declaratively:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: K8s还提供了高级抽象构件，使我们可以声明性地管理我们的工作负载：
- en: '**Deployments** ([https://kubernetes.io/docs/concepts/workloads/controllers/deployment/](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/))'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署** ([https://kubernetes.io/docs/concepts/workloads/controllers/deployment/](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/))'
- en: '**ReplicaSets** ([https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/))'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**副本集** ([https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/))'
- en: '**StatefulSets** ([https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/))'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有状态副本集** ([https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/))'
- en: '**Jobs** ([https://kubernetes.io/docs/concepts/workloads/controllers/job/](https://kubernetes.io/docs/concepts/workloads/controllers/job/))'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**作业** ([https://kubernetes.io/docs/concepts/workloads/controllers/job/](https://kubernetes.io/docs/concepts/workloads/controllers/job/))'
- en: '**DaemonSets** ([https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/))'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**守护进程集** ([https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/))'
- en: Each workload or component of the workload runs as a container inside Pods,
    and managing these Pods often takes a lot of effort. For example, if a Pod fails,
    a new replacement Pod needs to be created or a new version of the workload has
    to be rolled out. These high-level constructs help to abstract these complexities.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 每个工作负载或工作负载的组件都作为容器在Pod内运行，而管理这些Pod通常需要大量的工作。例如，如果一个Pod失败，则需要创建一个新的替代Pod，或者必须推出工作负载的新版本。这些高级构件有助于抽象这些复杂性。
- en: Deployment is the most common way to deploy a workload on a K8s cluster. It
    automates the process of rolling updates, ensuring that new versions of the workload
    can be released without downtime. We can also apply scaling policies to easily
    increase or decrease the number of Pods based on demand. Furthermore, deployments
    use **ReplicaSets** to ensure high availability by automatically restarting failed
    Pods and maintaining the desired state of the application, which is critical for
    resilience in production environments.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 部署是最常见的K8s集群工作负载部署方式。它自动化了滚动更新过程，确保可以在不中断的情况下发布工作负载的新版本。我们还可以应用扩展策略，轻松地根据需求增加或减少Pod的数量。此外，部署使用**副本集（ReplicaSets）**确保高可用性，自动重启失败的Pod并保持应用程序的期望状态，这对于生产环境的弹性至关重要。
- en: 'In K8s, a **Service** is an abstraction that enables you to expose one or more
    Pods over a network. It defines a logical group of endpoints, typically consisting
    of Pods, and includes a policy that governs their accessibility. There are many
    different types of K8s Service objects:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在K8s中，**服务（Service）**是一种抽象，允许您通过网络暴露一个或多个Pod。它定义了一组逻辑上的端点，通常由Pod组成，并包含一个管理其可访问性的策略。K8s服务对象有多种类型：
- en: '**ClusterIP** ([https://kubernetes.io/docs/concepts/services-networking/service/#type-clusterip](https://kubernetes.io/docs/concepts/services-networking/service/#type-clusterip))'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ClusterIP** ([https://kubernetes.io/docs/concepts/services-networking/service/#type-clusterip](https://kubernetes.io/docs/concepts/services-networking/service/#type-clusterip))'
- en: '**LoadBalancer** ([https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer))'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载均衡器（LoadBalancer）** ([https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer](https://kubernetes.io/docs/concepts/services-networking/service/#loadbalancer))'
- en: '**NodePort** ([https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport))'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NodePort** ([https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport))'
- en: '**ExternalName** ([https://kubernetes.io/docs/concepts/services-networking/service/#externalname](https://kubernetes.io/docs/concepts/services-networking/service/#externalname)).'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ExternalName** ([https://kubernetes.io/docs/concepts/services-networking/service/#externalname](https://kubernetes.io/docs/concepts/services-networking/service/#externalname))。'
- en: In this walkthrough, we will be exposing our application using the **LoadBalancer**
    Service type, which, in turn, will provision our NLB in the AWS cloud.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次操作指南中，我们将使用**负载均衡器（LoadBalancer）**服务类型来暴露我们的应用程序，进而在AWS云中配置我们的NLB。
- en: 'Let’s create a deployment specification for the `my-llama` container we created
    in [*Chapter 2*](B31108_02.xhtml#_idTextAnchor027). To do this, we need to upload
    the local container image to a container registry so that it can be downloaded
    by EKS. `ecr.tf` that contains the following Terraform code to create an Amazon
    ECR repository and enable image tag immutability to prevent image tags from being
    overwritten. You can download the `ecr.tf` file from our GitHub repository at
    [https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/ecr.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/ecr.tf):'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为在[*第二章*](B31108_02.xhtml#_idTextAnchor027)中创建的`my-llama`容器创建一个部署规范。为此，我们需要将本地容器镜像上传到容器注册表，以便EKS可以下载。`ecr.tf`文件包含以下Terraform代码，用于创建一个Amazon
    ECR仓库并启用镜像标签不可变性，以防止镜像标签被覆盖。您可以从我们的GitHub仓库下载`ecr.tf`文件：[https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/ecr.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/ecr.tf)。
- en: '[PRE15]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Run the following commands to create the ECR repository:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令来创建ECR仓库：
- en: '[PRE16]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Run the `terraform output` command to list the ECR upload commands. Copy and
    paste those output commands in your terminal to push the `my-llama` container
    image to the ECR repository:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 运行`terraform output`命令以列出ECR上传命令。复制并粘贴这些输出命令到终端中，将`my-llama`容器镜像推送到ECR仓库：
- en: '[PRE17]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Create the K8s deployment resource using the `my-llama` ECR image:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`my-llama` ECR镜像创建K8s部署资源：
- en: '[PRE18]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'It may take a couple of minutes for the K8s deployment to get into the `Ready`
    state. You can verify this by running the following command and looking for the
    `Ready` status:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: K8s部署可能需要几分钟才能进入`Ready`状态。您可以通过运行以下命令并查看`Ready`状态来验证：
- en: '[PRE19]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Now that the `my-llama` model is being deployed to the EKS cluster, the next
    step is to expose it outside the cluster using an AWS NLB. We will be using the
    `my-llama-svc.yaml` that contains the following content. This will create a K8s
    service of the `LoadBalancer` type on port `80` and forward the traffic to port
    `5000` on the `my-llama` container. Here, we’re also adding annotations to make
    it an internet-facing NLB.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 `my-llama` 模型正在部署到 EKS 集群中，下一步是通过 AWS NLB 将其暴露到集群外部。我们将使用包含以下内容的 `my-llama-svc.yaml`。这将在端口
    `80` 上创建一个 `LoadBalancer` 类型的 K8s 服务，并将流量转发到 `my-llama` 容器的端口 `5000`。在这里，我们还添加了注释，使其成为面向互联网的
    NLB。
- en: 'You can download the `my-llama-svc.yaml` file from our GitHub repository at
    [https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/my-llama-svc.yaml](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/my-llama-svc.yaml):'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从我们的 GitHub 仓库下载 `my-llama-svc.yaml` 文件：[https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/my-llama-svc.yaml](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch3/my-llama-svc.yaml)
- en: Important note
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: We are creating a public-facing NLB for testing purposes. Feel free to restrict
    access to your IP address by updating the inbound rules of the NLB security group.
    Please refer to the AWS NLB documentation at [https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-security-groups.html](https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-security-groups.html)
    for more details.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 我们正在为测试目的创建一个面向公众的 NLB。请随时通过更新 NLB 安全组的入站规则来限制访问您的 IP 地址。有关详细信息，请参阅 AWS NLB
    文档：[https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-security-groups.html](https://docs.aws.amazon.com/elasticloadbalancing/latest/network/load-balancer-security-groups.html)。
- en: '[PRE20]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Deploy the K8s service and fetch the NLB hostname by running the following
    commands:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行以下命令部署 K8s 服务并获取 NLB 主机名：
- en: '[PRE21]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'It may take up to 5 minutes for the K8s Pod endpoints to be registered to the
    AWS NLB and become healthy. You can run the following commands to look at the
    K8s Pod logs, events, and service status:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: K8s Pod 端点注册到 AWS NLB 并变为健康状态可能需要最多 5 分钟。您可以运行以下命令查看 K8s Pod 日志、事件和服务状态：
- en: '[PRE22]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Now, we can invoke the Llama model by using this NLB endpoint. Run the following
    `curl` command to send a test prompt to the `my-llama` service. It will generate
    a response by forwarding the prompt to the Llama model:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以通过该 NLB 端点调用 Llama 模型。运行以下 `curl` 命令将测试提示发送到 `my-llama` 服务。它将把提示转发给 Llama
    模型以生成响应：
- en: '[PRE23]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: In this section, we deployed our `my-llama` container image as a K8s deployment
    in an EKS cluster and exposed it to the internet using an AWS NLB by creating
    the K8s LoadBalancer Service. Finally, we ran inference on our LLM by using the
    `curl` utility against the AWS NLB endpoint’s URL. Similarly, you can containerize
    other publicly available models such as **Mistral** ([https://huggingface.co/mistralai](https://huggingface.co/mistralai)),
    **Falcon** ([https://huggingface.co/tiiuae](https://huggingface.co/tiiuae)), and
    **DeepSeek** ([https://huggingface.co/deepseek-ai](https://huggingface.co/deepseek-ai))
    and deploy them in your EKS cluster.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将 `my-llama` 容器映像作为 K8s 部署部署在 EKS 集群中，并通过创建 K8s LoadBalancer 服务将其暴露到互联网。最后，我们使用
    `curl` 实用程序针对 AWS NLB 端点的 URL 对我们的 LLM 进行推理。类似地，您可以将其他公开可用模型如 **Mistral** ([https://huggingface.co/mistralai](https://huggingface.co/mistralai)),
    **Falcon** ([https://huggingface.co/tiiuae](https://huggingface.co/tiiuae)), 和
    **DeepSeek** ([https://huggingface.co/deepseek-ai](https://huggingface.co/deepseek-ai))
    容器化，并部署到您的 EKS 集群中。
- en: Summary
  id: totrans-141
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, we discussed how cloud computing has fundamentally changed
    how we access and utilize compute resources, offering scalability, accessibility,
    and cost-efficiency through pay-as-you-go models. Managed K8s services provided
    by major cloud providers simplify the deployment and management of K8s clusters,
    which is particularly beneficial for running GenAI models. We used Amazon EKS,
    a managed, upstream K8s-compliant service as an example and covered how to automate
    the process of setting up an EKS cluster. Then, we utilized Terraform for cluster
    provisioning, set up a Terraform project with the required providers, and used
    community modules to create AWS resources such as VPCs, EKS clusters, EKS-managed
    node groups, and cluster add-ons. After, we deployed our `my-llama` model as a
    K8s deployment on the EKS cluster and exposed it to the internet using the K8s
    LoadBalancer Service.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了云计算如何从根本上改变我们访问和利用计算资源的方式，通过按需付费模型提供了可扩展性、可访问性和成本效益。主要云服务提供商提供的托管K8s服务简化了K8s集群的部署和管理，这对于运行GenAI模型尤其有利。我们以Amazon
    EKS为例，介绍了如何自动化设置EKS集群的过程。接着，我们使用Terraform进行集群配置，设置了一个包含所需提供程序的Terraform项目，并利用社区模块创建了AWS资源，如VPC、EKS集群、EKS管理的节点组和集群附加组件。之后，我们将`my-llama`模型作为K8s部署应用在EKS集群上，并通过K8s
    LoadBalancer服务将其暴露到互联网上。
- en: In the next chapter, we will discuss techniques for optimizing a general-purpose
    foundational model for domain-specific use cases, such as chatbots. We will cover
    some specific techniques such as Retrieval-Augmented Generation (RAG) and fine-tuning
    methods while providing an in-depth exploration of how to implement them.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将讨论如何优化通用基础模型，以便用于特定领域的用例，如聊天机器人。我们将介绍一些特定的技术，如检索增强生成（RAG）和微调方法，并深入探讨如何实现这些技术。
- en: Join the CloudPro Newsletter with 44000+ Subscribers
  id: totrans-144
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入拥有44000+订阅者的CloudPro时事通讯
- en: Want to know what’s happening in cloud computing, DevOps, IT administration,
    networking, and more? Scan the QR code to subscribe to **CloudPro**, our weekly
    newsletter for 44,000+ tech professionals who want to stay informed and ahead
    of the curve.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解云计算、DevOps、IT管理、网络等领域的最新动态吗？扫描二维码订阅**CloudPro**，我们每周发布的时事通讯，已有44,000+名技术专业人士订阅，帮助他们保持信息领先。
- en: '![](img/NL_Part1.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![](img/NL_Part1.jpg)'
- en: '[https://packt.link/cloudpro](https://packt.link/cloudpro)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/cloudpro](https://packt.link/cloudpro)'
- en: 'Part 2: Productionalizing GenAI Workloads Using K8s'
  id: totrans-148
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第2部分：使用K8s将GenAI工作负载投入生产
- en: This section offers a comprehensive guide for deploying, scaling, and optimizing
    GenAI applications in production K8s environments. Through real-world examples,
    such as an e-commerce chatbot, this section covers essential techniques for model
    optimization, cost and resource management, networking and security best practices,
    and GPU resource optimization, enabling a smooth transition from experimentation
    to production-ready solutions.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分提供了一个全面的指南，帮助您在生产K8s环境中部署、扩展和优化GenAI应用。通过实际案例（例如电商聊天机器人），本部分涵盖了模型优化、成本和资源管理、网络与安全最佳实践以及GPU资源优化等关键技术，帮助实现从实验阶段到生产就绪解决方案的平稳过渡。
- en: 'This part has the following chapters:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包括以下章节：
- en: '[*Chapter 4*](B31108_04.xhtml#_idTextAnchor049), *GenAI Model Optimization
    for Domain-Specific Use Cases*'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第4章*](B31108_04.xhtml#_idTextAnchor049)，*针对特定领域用例优化GenAI模型*'
- en: '[*Chapter 5*](B31108_05.xhtml#_idTextAnchor062), *Working with GenAI on K8s:
    Chatbot Example*'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第5章*](B31108_05.xhtml#_idTextAnchor062)，*在K8s上使用GenAI：聊天机器人示例*'
- en: '[*Chapter 6*](B31108_06.xhtml#_idTextAnchor075), *Scaling GenAI Applications
    on Kubernetes*'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第6章*](B31108_06.xhtml#_idTextAnchor075)，*在Kubernetes上扩展GenAI应用*'
- en: '[*Chapter 7*](B31108_07.xhtml#_idTextAnchor087), *Cost Optimization of GenAI
    Applications on Kubernetes*'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第7章*](B31108_07.xhtml#_idTextAnchor087)，*在Kubernetes中优化GenAI应用的成本*'
- en: '[*Chapter 8*](B31108_08.xhtml#_idTextAnchor097), *Networking Best Practices
    for Deploying GenAI on K8s*'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B31108_08.xhtml#_idTextAnchor097)，*在Kubernetes中部署GenAI的网络最佳实践*'
- en: '[*Chapter 9*](B31108_09.xhtml#_idTextAnchor113), *Security Best Practices for
    Deploying GenAI on Kubernetes*'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B31108_09.xhtml#_idTextAnchor113)，*在Kubernetes中部署GenAI的安全最佳实践*'
- en: '[*Chapter 10*](B31108_10.xhtml#_idTextAnchor128), *Optimizing GPU Resources
    for GenAI Applications in Kubernetes*'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B31108_10.xhtml#_idTextAnchor128)，*在Kubernetes中优化GPU资源以支持GenAI应用*'
