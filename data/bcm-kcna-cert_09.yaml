- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Understanding Cloud Native Architectures
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解云原生架构
- en: With this chapter, we are moving on to explore further aspects of Cloud Native
    in more detail. We will see which concepts are a part of Cloud Native and what
    is the architecture of Cloud Native, talk about **resiliency** and **autoscaling**,
    and get to know some of the best practices. This chapter covers further requirements
    of the *Cloud Native Architecture* domain of the **Kubernetes and Cloud Native
    Associate** (**KCNA**) exam, which makes up a total of 16% of questions.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将继续深入探讨云原生的各个方面。我们将看到哪些概念属于云原生，云原生的架构是什么，讨论**韧性**和**自动扩展**，并了解一些最佳实践。本章涵盖了*云原生架构*领域的进一步要求，这部分内容占**Kubernetes和云原生认证工程师**（**KCNA**）考试问题的16%。
- en: 'This chapter has no practical part, so we won’t perform any hands-on exercises,
    but it is still very important to understand it in order to pass the KCNA exam
    and advance in the field. We will focus on the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章没有实践部分，因此我们不会进行动手练习，但它仍然非常重要，因为它是通过 KCNA 考试并在该领域进一步发展的基础。我们将关注以下主题：
- en: Cloud Native architectures
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云原生架构
- en: Resiliency and autoscaling
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 韧性与自动扩展
- en: Serverless
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无服务器
- en: Cloud Native best practices
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云原生最佳实践
- en: If you’ve skipped the first two chapters of the book and you find some terms
    discussed here unclear, please go back and read *Chapters 1* and *2* to cover
    the gaps first.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你跳过了本书的前两章，发现这里讨论的一些术语不清楚，请返回并阅读*第1章*和*第2章*，以弥补知识空白。
- en: Cloud Native architectures
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云原生架构
- en: In the first two chapters, we’ve already covered the definition of Cloud Native.
    Let’s check it one more time for a quick recap.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在前两章中，我们已经介绍了云原生的定义。让我们再检查一次，以便快速回顾。
- en: Cloud Native
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生
- en: This is an approach to building and running applications on modern, dynamic
    infrastructures such as clouds. It emphasizes application workloads with high
    resiliency, scalability, a high degree of automation, ease of management, and
    observability.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种在现代动态基础设施上构建和运行应用程序的方法，例如云计算。它强调高韧性、可扩展性、高度自动化、易于管理和可观察性的应用程序工作负载。
- en: Yet, despite the presence of the word *cloud*, a Cloud Native application is
    not strictly required to run in the cloud. It’s an approach that can be followed
    when building and running applications also on-premises. And yes—you can also
    build resilient, scalable, highly automated applications on-premises that are
    Cloud Native, albeit not running in the cloud.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有“云”这个词，云原生应用程序并不严格要求运行在云中。它是一种可以在本地构建和运行应用程序时也能采用的方法。没错——你也可以在本地构建具有韧性、可扩展性、高度自动化的云原生应用程序，尽管它们并不运行在云中。
- en: It is important to understand that simply picking a well-known public cloud
    provider and building on top of its service offerings (whether IaaS, PaaS, SaaS,
    or FaaS) does not mean your application automatically becomes Cloud Native. For
    example, if your application requires manual intervention to start then it cannot
    scale automatically, and it won’t be possible to restart it automatically in case
    of failure, so it’s not Cloud Native.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要理解，仅仅选择一个知名的公共云服务提供商，并在其服务基础上构建应用程序（无论是 IaaS、PaaS、SaaS 还是 FaaS），并不意味着你的应用程序自动成为云原生。例如，如果你的应用程序启动时需要人工干预，那么它就无法自动扩展，也无法在发生故障时自动重启，因此它就不是云原生的。
- en: 'Another example: you have a web application consisting of a few microservices,
    but it is deployed and configured manually without any automation and thus cannot
    be easily updated. This is not a Cloud Native approach. If you forgot about microservices
    in the meantime, here is a definition one more time .'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个例子：你有一个由若干微服务组成的 Web 应用程序，但它是手动部署和配置的，没有任何自动化，因此无法轻松更新。这不是一种云原生方法。如果你此时忘记了微服务的概念，下面再给你一个定义。
- en: Microservices
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务
- en: These are small applications that work together as a part of a larger application
    or service. Each microservice could be responsible for a single feature of a big
    application and communicate with other microservices over the network. This is
    the opposite of monolithic applications, which bundle all functionality and logic
    in one big deployable piece (tightly coupled).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务是作为大型应用或服务的一部分协同工作的较小应用程序。每个微服务可能负责大型应用中的单一功能，并通过网络与其他微服务进行通信。这与单体应用程序相反，后者将所有功能和逻辑打包成一个大的可部署单元（紧耦合）。
- en: In practice, to implement a Cloud Native application, you’ll most likely turn
    to microservices. Microservices are loosely coupled, which makes it possible to
    scale, develop, and update them independently from each other. Microservices solve
    many problems but they also add operational overhead as their number grows, and
    that is why many of the Cloud Native technologies such as Kubernetes and Helm
    aim to make microservices easy to deploy, manage, and scale.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，为了实现一个云原生应用程序，你很可能会采用微服务。微服务是松耦合的，这使得它们可以独立扩展、开发和更新。微服务解决了许多问题，但随着数量的增加，也带来了更多的操作开销，这就是为什么许多云原生技术，如
    Kubernetes 和 Helm，旨在使微服务的部署、管理和扩展变得更加简单。
- en: Again, strictly speaking, you are not required to run microservices managed
    by Kubernetes to have Cloud Native architecture. But this combination of containerized,
    small, loosely coupled applications orchestrated by Kubernetes works very well
    and paves the way toward Cloud Native. It is much, much easier to implement resiliency,
    autoscaling, controllable rolling updates, and observability with Kubernetes and
    containers than doing so with many **virtual machines** (**VMs**) and homegrown
    shell scripts. Kubernetes is also infrastructure-agnostic, which makes it very
    attractive for many environments and use cases. It can run on bare-metal servers,
    on VMs, in public and private clouds, and could be consumed as a managed service
    or run in a hybrid environment consisting of cloud resources and on-premises data
    centers.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 再次严格来说，运行由 Kubernetes 管理的微服务并不是实现云原生架构的必要条件。但这种由 Kubernetes 协调的容器化、小型、松耦合的应用程序组合非常有效，并为云原生铺平了道路。相比于使用许多**虚拟机**（**VMs**）和自制的
    Shell 脚本，通过 Kubernetes 和容器来实现弹性、自动扩展、可控的滚动更新和可观测性要容易得多。Kubernetes 还具有与基础设施无关的特点，这使得它在许多环境和用例中都具有很大的吸引力。它可以运行在裸金属服务器上、虚拟机中、公共云和私有云中，且可以作为托管服务使用，或者运行在由云资源和本地数据中心组成的混合环境中。
- en: 'Now, before diving deeper into some of the aspects, let’s see at a high level
    the benefits Cloud Native provides:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在深入探讨一些方面之前，让我们高层次地看一下云原生带来的好处：
- en: '**Reduced time to market (TTM)** – A high degree of automation and easy updates
    make it possible to deliver new Cloud Native application features rapidly, which
    offers a competitive advantage for many businesses.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**缩短市场时间（TTM）** – 高度的自动化和简便的更新使得新功能能够迅速交付，从而为许多企业提供了竞争优势。'
- en: '**Cost efficiency** – Cloud Native applications scale based on demand, which
    means paying only for resources required and eliminating waste.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本效益** – 云原生应用程序根据需求扩展，这意味着只需为实际需要的资源付费，避免了浪费。'
- en: '**Higher reliability** – Cloud Native applications can self-heal and automatically
    recover from failures. This means reduced system downtime, resulting in a better
    user experience.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更高的可靠性** – 云原生应用程序能够自我修复并自动从故障中恢复。这意味着减少了系统的停机时间，从而改善了用户体验。'
- en: '**Scalability and flexibility** – Microservices can be scaled, developed, and
    updated individually allowing us to handle various scenarios and provide more
    flexibility for development teams.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可扩展性和灵活性** – 微服务可以单独扩展、开发和更新，这使我们能够处理各种场景，并为开发团队提供更多灵活性。'
- en: '**No vendor lock-in** – With the right approach and use of open source technologies,
    a Cloud Native application could be shifted between different infrastructures
    or cloud providers with minimum effort.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无供应商锁定** – 通过正确的方法和开源技术的使用，云原生应用程序可以在不同的基础设施或云提供商之间迁移，且几乎不需要任何努力。'
- en: The list can be continued, but it should be enough to give you an idea of why
    most modern applications follow Cloud Native approaches and practices. Moving
    on, we will focus on some of the most important aspects of Cloud Native, such
    as resiliency and autoscaling.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表还可以继续，但应该足以让你了解为什么大多数现代应用程序遵循云原生方法和实践。接下来，我们将重点讨论云原生的一些重要方面，比如弹性和自动扩展。
- en: Resiliency and autoscaling
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 弹性和自动扩展
- en: As funny as it may sound, in order to design and build resilient systems, we
    need to expect things to fail and break apart. In other words, in order to engineer
    resilient systems, we need to engineer for failure and provide ways for applications
    and infrastructure to recover from failures automatically.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来可能有些好笑，但为了设计和构建弹性系统，我们需要预期事物会失败并分崩离析。换句话说，为了打造弹性系统，我们需要为故障设计，并提供让应用程序和基础设施能够自动从故障中恢复的方法。
- en: Resiliency
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 弹性
- en: This characterizes an application and infrastructure that can automatically
    recover from failures. The ability to recover without manual intervention is often
    called *self-healing*.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明应用程序和基础设施能够在故障发生时自动恢复。无需人工干预的恢复能力通常称为*自我修复*。
- en: We’ve already seen self-healing in action in [*Chapter 6*](B18970_06.xhtml#_idTextAnchor068)
    when Kubernetes detected that the *desired state* and the *current state* were
    different and quickly spawned additional application replicas. This is possible
    thanks to the Kubernetes *reconciliation loop*.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[*第六章*](B18970_06.xhtml#_idTextAnchor068)中看到过自我修复的实际应用，当时 Kubernetes 检测到*期望状态*和*当前状态*不一致，并迅速启动了额外的应用程序副本。这要归功于
    Kubernetes 的*协调循环*。
- en: 'There are, of course, ways to build resilient applications and infrastructure
    without Kubernetes. For example, the **Amazon Web Services** (**AWS**) public
    cloud offers **Autoscaling Groups**, which allow you to run a desired number of
    VMs in a group or increase and decrease the number automatically based on the
    load. In case of VM failure, it will be detected and reacted upon with the creation
    of a new VM. In case CPU utilization in the group reaches a certain, pre-defined
    threshold, new VMs can be provisioned to share the load. And this brings us to
    another important concept: autoscaling.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，也有方法在没有 Kubernetes 的情况下构建具有韧性的应用程序和基础设施。例如，**Amazon Web Services** (**AWS**)
    公有云提供了 **自动伸缩组**，允许您在一个组内运行所需数量的虚拟机（VM），并根据负载自动增加或减少虚拟机的数量。如果虚拟机发生故障，系统会检测到并通过创建新的虚拟机来做出响应。当组内的
    CPU 利用率达到某个预定义的阈值时，可以创建新的虚拟机来分担负载。这引出了另一个重要的概念：自动伸缩。
- en: Autoscaling
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 自动伸缩
- en: This is an ability to add or reduce computing resources automatically to meet
    the current demand.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种能够自动增加或减少计算资源以满足当前需求的能力。
- en: Needless to say, different cloud providers offer many options for configuring
    autoscaling today. It can be based on various metrics and conditions, where CPU
    or RAM utilization are just common examples.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 不用多说，如今不同的云服务提供商提供了多种配置自动伸缩的选项。这些选项可以基于各种指标和条件，其中 CPU 或内存利用率仅仅是常见的例子。
- en: Previously, in the times of traditional IT, applications and infrastructure
    were designed to account for peak system usage, and this resulted in highly underutilized
    hardware and high running costs. Autoscaling has been a huge improvement, and
    it became one of the most important features of Cloud Native.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 过去，在传统 IT 时代，应用程序和基础设施是根据系统的峰值使用情况来设计的，这导致了硬件的高度低效利用和高昂的运行成本。自动伸缩是一个巨大的改进，它已成为云原生的最重要特性之一。
- en: 'When we talk about autoscaling, it applies to *both the application and the
    infrastructure it runs on*, because scaling one without another won’t be sufficient.
    Let’s consider the following example to explain—you manage multiple microservice
    applications running in a Kubernetes cluster that under typical load require 10
    worker nodes to operate. If additional worker nodes are created and joined into
    the K8s cluster, there won’t be any pods running on those new nodes until one
    of the following happens:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论自动伸缩时，它适用于*应用程序及其运行的基础设施*，因为仅仅伸缩其中一个是远远不够的。让我们通过以下例子来解释——你管理着多个微服务应用程序，这些应用在典型负载下需要
    10 个工作节点才能运行。如果创建了额外的工作节点并将其加入到 K8s 集群中，那么在以下情况之一发生之前，这些新节点上将不会有任何 Pod 运行：
- en: The number of replicas of applications is increased so that new pods are created
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序的副本数量增加，以便创建新的 Pod。
- en: Some of the existing pods exit and get recreated by a controller (such as Deployment,
    StatefulSet, and so on)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些现有的 Pod 会退出并由控制器（如 Deployment、StatefulSet 等）重新创建。
- en: That is because Kubernetes won’t reschedule already running pods when a new
    node joins the cluster. So, it would be required to increase the number of microservice
    replicas besides adding new nodes. *Why won’t simply adding more replicas be enough?*
    Doing so will eventually max out the CPU/RAM utilization and make Kubernetes nodes
    unresponsive as the payloads will be *fighting* for resources.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为 Kubernetes 不会在新节点加入集群时重新调度已经运行的 Pod。所以，除了增加新节点外，还需要增加微服务副本的数量。*为什么仅仅增加副本数就不够？*
    这样做最终会使 CPU/内存利用率达到上限，导致 Kubernetes 节点无法响应，因为负载将会为资源而*争斗*。
- en: 'Scaling in general can also be distinguished into two types, as shown in *Figure
    9**.1*:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，伸缩可以分为两种类型，如*图 9.1*所示：
- en: '![Figure 9.1 – Comparison of horizontal and vertical scaling](img/B18970_09_01.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.1 – 横向与纵向伸缩比较](img/B18970_09_01.jpg)'
- en: Figure 9.1 – Comparison of horizontal and vertical scaling
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1 – 水平扩展与垂直扩展的比较
- en: 'Let’s look at this in more detail:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地了解一下：
- en: '**Horizontal**—When we add or reduce the number of instances (VMs or nodes),
    as in the preceding example. Horizontal scaling is also known as **scaling out**
    (adding new VMs) and **scaling in** (terminating VMs).'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**水平扩展**—当我们增加或减少实例（虚拟机或节点）的数量时，就像前面的例子那样。水平扩展也称为**向外扩展**（添加新的虚拟机）和**向内扩展**（终止虚拟机）。'
- en: '**Vertical**—When we keep the number of instances the same but change their
    configuration (such as the number of vCPUs, GB of RAM, size of the disks, and
    so on). Vertical scaling is also known as **scaling up** (adding CPU/RAM capacity)
    and **scaling down** (reducing CPU/RAM capacity).'
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垂直扩展**—当我们保持实例数量不变，但更改其配置（如 vCPU 数量、内存 GB、磁盘大小等）时。垂直扩展也称为**向上扩展**（增加 CPU/RAM
    容量）和**向下扩展**（减少 CPU/RAM 容量）。'
- en: To keep it simple, you can memorize horizontal autoscaling as an automatic increase
    (or decrease) in numbers and vertical autoscaling as an increase (or decrease)
    in size. Cloud Native microservice architectures commonly apply horizontal autoscaling,
    whereas old monolithic applications were scaled vertically most of the time. Vertical
    autoscaling is also more restricting because even the largest flavors of VMs and
    bare-metal servers available today cannot go beyond certain technological limits.
    Therefore, scaling horizontally is the preferred way.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化记忆，你可以将水平自动扩展记作数字的自动增加（或减少），而将垂直自动扩展记作大小的增加（或减少）。云原生微服务架构通常采用水平自动扩展，而传统的单体应用程序通常采用垂直扩展。垂直自动扩展也更具限制性，因为即使是今天可用的最大虚拟机和裸机服务器，也无法突破某些技术限制。因此，水平扩展是更为推荐的方式。
- en: 'From the previous chapters, we already know that we can change the number of
    Deployment replicas with Kubernetes in just one simple command; however, that
    is not automatic, but a manual scaling. Apart from that, there are three mechanisms
    in Kubernetes that allow us to implement automatic scaling:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的章节中，我们已经知道可以通过 Kubernetes 在一个简单的命令中更改部署副本的数量；然而，这不是自动的，而是手动扩展。除此之外，Kubernetes
    中有三种机制可以实现自动扩展：
- en: '**Horizontal Pod Autoscaler (HPA)**—This updates the workload resource (such
    as Deployment, StatefulSet) to add more pods when the load goes up and removes
    pods when the load goes down to match demand. HPA requires configuration of lower
    and upper bounds of replicas (for example, 3 replicas minimum and 10 maximum).'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**水平 Pod 自动扩展器（HPA）**—当负载上升时，它会更新工作负载资源（如 Deployment、StatefulSet），以添加更多 Pods，而当负载下降时，它会移除
    Pods 以匹配需求。HPA 需要配置副本的上下限（例如，最少 3 个副本，最多 10 个副本）。'
- en: '**Vertical Pod Autoscaler (VPA)**—This updates the workload resource requests
    and limits for containers (CPU, memory, huge page size). It can reduce requests
    and limits of containers *over-requesting* resources and scale up requests and
    limits for *under-requesting* workloads based on historical usage over time. VPA
    does not change the number of replicas like HPA does, as shown in *Figure 9**.2*.
    VPA also optionally allows us to define minimum and maximum request boundaries.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**垂直 Pod 自动扩展器（VPA）**—它会更新工作负载资源的请求和限制（如 CPU、内存、大页面大小）。它可以减少资源请求过多的容器的请求和限制，并根据历史使用情况扩展资源请求和限制，适用于资源请求过少的工作负载。与
    HPA 不同，VPA 不会更改副本数量，如在*图 9.2*中所示。VPA 还可以选择性地允许我们定义请求的最小和最大边界。'
- en: '**Cluster Autoscaler**—This adjusts the size of the Kubernetes cluster by adding
    or removing worker nodes when either there are pods that fail to run due to insufficient
    resources or there are underutilized nodes for an extended period of time and
    their pods can be placed on other nodes in the cluster. It is recommendable to
    limit the maximum number of nodes in the cluster to protect against making the
    cluster too large. Cluster Autoscaler also requires integration with your cloud
    provider to operate:'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群自动扩展器**—它通过增加或移除工作节点来调整 Kubernetes 集群的大小，适用于当因资源不足而导致某些 Pods 无法运行，或者存在长时间未使用的节点且这些节点上的
    Pods 可以迁移到集群中的其他节点时。建议限制集群中节点的最大数量，以防止集群过大。集群自动扩展器还需要与您的云服务提供商集成才能正常工作：'
- en: '![Figure 9.2 – Comparison of Kubernetes HPA and VPA](img/B18970_09_02.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 9.2 – Kubernetes HPA 和 VPA 的比较](img/B18970_09_02.jpg)'
- en: Figure 9.2 – Comparison of Kubernetes HPA and VPA
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.2 – Kubernetes HPA 和 VPA 的比较
- en: Those mechanisms are especially powerful as they get combined. As you remember,
    we need to scale both application and the infrastructure where it runs, so using
    only HPA or only using Cluster Autoscaler won’t be sufficient. In fact, all three
    mechanisms can be used together, but this is a complex topic that you should not
    approach without getting enough K8s experience first. For the scope of KCNA, you
    only need to know what autoscaling is and which autoscaling mechanisms Kubernetes
    has to offer.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 这些机制尤其在结合使用时非常强大。如你所记得，我们需要同时扩展应用程序和运行它的基础设施，因此仅使用HPA或仅使用Cluster Autoscaler是不够的。实际上，所有三种机制可以一起使用，但这是一个复杂的主题，你在没有足够K8s经验之前不应该轻易接触。就KCNA的范围而言，你只需要了解什么是自动扩展以及Kubernetes提供了哪些自动扩展机制。
- en: At the end of the day, autoscaling is a crucial part of Cloud Native that is
    required to strike a balance between workload performance and infrastructure size
    and costs.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 到头来，自动扩展是云原生的重要组成部分，它有助于在工作负载性能、基础设施规模和成本之间找到平衡。
- en: Moving on, we are going to learn more about Serverless—an evolution of computing
    that gained adoption over the last years.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将进一步了解Serverless——一种近年来获得广泛应用的计算演进模式。
- en: Serverless
  id: totrans-57
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Serverless
- en: In the very first chapter, we briefly touched on a definition of Serverless—a
    newer cloud delivery model that appeared around 2010 and is known as *Function
    as a Service* or *FaaS*.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在第一章中，我们简要介绍了Serverless的定义——一种在2010年左右出现的较新云交付模型，通常被称为*功能即服务*或*FaaS*。
- en: Serverless
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: Serverless
- en: This is a computing model where code is written as small functions that are
    built and run without the need to manage any servers. Those functions are triggered
    by events (for example, the user clicked a button on the web page, uploaded a
    file, and so on).
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一种计算模型，代码以小函数的形式编写，这些函数在不需要管理任何服务器的情况下构建和运行。这些函数由事件触发（例如，用户在网页上点击按钮、上传文件等）。
- en: 'Despite the name, the truth is that Serverless computing still relies on real
    hardware servers underneath. However, servers running the functions **are completely
    abstracted away** from the application development. In this model, the provider
    handles all operations that are required to run the code: provisioning, scaling,
    maintenance, security patching, and so on. Since you don’t need to take care of
    servers ever, the model is called Serverless.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管名字中有“Serverless”，但事实上，Serverless计算仍然依赖于底层的真实硬件服务器。然而，运行这些函数的服务器**完全抽象**与应用开发分离。在这种模式下，提供商负责运行代码所需的所有操作：配置、扩展、维护、安全补丁等。由于你无需关心服务器，因此这种模式被称为Serverless。
- en: Serverless brings in several advantages besides a lack of routine server operations.
    The development team can simply upload code to the Serverless platform, and once
    deployed, the application and infrastructure it runs on will be scaled automatically
    as needed based on demand.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 除了不需要例行的服务器操作外，Serverless还带来了一些优势。开发团队可以简单地将代码上传到Serverless平台，一旦部署，应用程序及其运行的基础设施将根据需求自动扩展。
- en: 'When a Serverless function idles, most cloud providers won’t charge anything
    as with no events, there are no executions of the functions and thus no costs
    are incurred. If there are 10,000 events that trigger 10,000 function executions,
    then in most cases, their *exact execution times* will be billed by the provider.
    This is different from a typical *pay-as-you-go* VM in the cloud where you pay
    for all time the VM is running, regardless of the actual CPU/RAM utilization.
    A sample Serverless architecture is shown in *Figure 9**.3*:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 当Serverless函数处于空闲状态时，大多数云提供商不会收费，因为没有事件触发函数执行，因此没有产生费用。如果有10,000个事件触发10,000次函数执行，那么在大多数情况下，提供商会按*精确执行时间*计费。这与典型的*按需付费*云虚拟机不同，后者不管实际的CPU/RAM利用率如何，只要虚拟机在运行，你就需要支付所有运行时间。一个示例Serverless架构如*图9.3*所示：
- en: '![Figure 9.3 – Serverless architecture example](img/B18970_09_03.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
  zh: '![图9.3 – Serverless架构示例](img/B18970_09_03.jpg)'
- en: Figure 9.3 – Serverless architecture example
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.3 – Serverless架构示例
- en: Note
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: An API Gateway is a part of Serverless that allows us to define endpoints for
    the REST API of an application and connect those endpoints with corresponding
    functions implementing the actual logic. API Gateway typically handles user authentication
    and access control and often provides additional features for observability.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: API网关是Serverless的一部分，允许我们为应用程序的REST API定义端点，并将这些端点与实现实际逻辑的函数连接起来。API网关通常处理用户认证和访问控制，并且经常提供额外的可观察性功能。
- en: It’s worth mentioning that many popular programming languages (Java, Golang,
    Python, and Ruby, to name a few) are supported by the cloud providers offering
    Serverless today, yet not all providers allow the use of our own container images.
    In fact, most public cloud providers offering Serverless today rely on their own
    proprietary technology. So, if you develop a Serverless application for **AWS
    Lambda** (the Serverless offering of AWS) then migrating it to **Google Cloud
    Functions** (the Serverless offering of Google Cloud) will require considerable
    effort.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，许多流行的编程语言（如 Java、Golang、Python 和 Ruby 等）都得到了提供 Serverless 服务的云服务商的支持，但并不是所有供应商都允许使用我们自己的容器镜像。事实上，目前提供
    Serverless 服务的大多数公共云服务商都依赖于其自有的技术。因此，如果你为 **AWS Lambda**（AWS 提供的 Serverless 服务）开发了一个
    Serverless 应用，那么将其迁移到 **Google Cloud Functions**（Google Cloud 提供的 Serverless 服务）将需要付出相当大的努力。
- en: 'Besides fully managed cloud Serverless platforms, there are a few open source
    alternatives available today that reduce the risk of vendor lock-in. For example,
    the following Serverless frameworks can be installed on top of Kubernetes with
    functions code packaged and run as containers:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 除了完全托管的云 Serverless 平台，今天还有一些开源替代方案可供选择，这些方案减少了供应商锁定的风险。例如，以下 Serverless 框架可以安装在
    Kubernetes 上，并将函数代码打包成容器运行：
- en: '**OpenFaaS**'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OpenFaaS**'
- en: '**CloudEvents**'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CloudEvents**'
- en: '**Knative**'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Knative**'
- en: '**Fn**'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Fn**'
- en: Knative and CloudEvents are currently curated **Cloud Native Computing Foundation**
    (**CNCF**) projects.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: Knative 和 CloudEvents 目前是由 **Cloud Native Computing Foundation**（**CNCF**）策划的项目。
- en: 'To wrap it up, FaaS can be seen as an evolution of cloud computing models (IaaS,
    PaaS, and SaaS) that fits well for Cloud Native architectures. While the Serverless
    market share is still growing, it has become apparent that it will not replace
    common VMs and managed platform offerings due to limitations that we briefly cover
    here:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，FaaS 可以看作是云计算模型（IaaS、PaaS 和 SaaS）的进化，适用于 Cloud Native 架构。虽然 Serverless
    的市场份额仍在增长，但显然它不会取代常见的虚拟机和托管平台服务，因为我们在这里简要提到的一些限制：
- en: To persist data, Serverless applications must interact with other stateful components.
    So, unless you never need to keep the state, you’ll have to involve databases
    and other storage options.
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为了持久化数据，Serverless 应用必须与其他有状态组件进行交互。因此，除非你完全不需要保持状态，否则你将不得不涉及数据库和其他存储选项。
- en: In most cases, there is little to no control over runtime configuration. For
    instance, you won’t be able to change OS or **Java Virtual Machine** (**JVM**)
    parameters when using FaaS offered by a cloud provider.
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在大多数情况下，对运行时配置的控制非常有限。举例来说，当使用云服务提供商的 FaaS 时，你将无法更改操作系统或 **Java 虚拟机**（**JVM**）的参数。
- en: '**Cold start**—Initialization of container or infrastructure where the function
    code will execute takes some time (typically in the range of tens of seconds).
    If a particular function has not been invoked for a while, the next invocation
    will suffer from a cold-start delay. The way to go around it is to call the functions
    periodically to keep them *pre-warmed*.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Cold start**——容器或基础设施初始化以执行函数代码需要一些时间（通常在几十秒的范围内）。如果某个函数长时间未被调用，下次调用时将遭遇冷启动延迟。解决办法是定期调用函数以保持其
    *预热*。'
- en: Monitoring, logging, and debugging Serverless applications is often harder.
    While you don’t need to take care of servers and metrics such as CPU or disk utilization,
    the ways to debug functions at runtime are limited. You won’t be able to run code
    line by line as you would do locally in an IDE.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 监控、日志记录和调试 Serverless 应用通常更加困难。虽然你不需要关心服务器以及 CPU 或磁盘利用率等指标，但在运行时调试函数的方式有限。你将无法像在本地
    IDE 中那样逐行运行代码。
- en: Risk of vendor lock-in. As already mentioned, FaaS offerings are not standardized,
    and thus migrating from one provider to another would require significant work.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 供应商锁定的风险。正如前面提到的，FaaS 服务尚未标准化，因此从一个供应商迁移到另一个供应商需要大量的工作。
- en: The list is not exhaustive, but hopefully, it gives you an idea of why you should
    not necessarily rush your development team to move completely to Serverless. Both
    cloud provider and open source FaaS offerings have improved a lot in the recent
    years, so there is a chance that many of the limitations will be resolved in the
    near future.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表并不详尽，但希望它能让你明白为什么你不应该急于让开发团队完全迁移到 Serverless。无论是云服务提供商还是开源 FaaS 服务，近年来都已经有了很大的改进，因此许多限制可能会在不久的将来得到解决。
- en: Again, we are diving deeper here than required to pass KCNA. You’ll not be questioned
    about the limitations of Serverless, but you need to understand the concept of
    the billing model and be able to name a few projects that let you operate your
    own FaaS on top of Kubernetes.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，我们在这里探讨的内容比 KCNA 认证所要求的要深入一些。你不会被问及无服务器架构的局限性，但你需要理解计费模型的概念，并能列举几个允许你在
    Kubernetes 上运行自己的 FaaS 项目。
- en: In the last section of the chapter, we’re going to summarize some key points
    we’ve learned about Cloud Native.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的最后部分，我们将总结一些关于云原生的关键点。
- en: Cloud Native best practices
  id: totrans-84
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云原生最佳实践
- en: As the world is changing fast, users get more and more demanding, and the IT
    landscape has to change in order to meet expectations. Today, not many people
    tolerate waiting for a web page to open if it takes 30 seconds and people complain
    if online banking is not working for a whole hour long.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 随着世界变化的加速，用户的需求越来越高，IT 领域也必须做出相应的变化以满足这些期望。如今，如果一个网页打开需要 30 秒钟，很多人都无法忍受，而且如果网上银行系统停运一个小时，人们会抱怨。
- en: Cloud Native has signified major improvements in the field by bringing a new
    approach to building and running applications. Cloud Native applications are designed
    to expect failures and automatically recover from most of them. A lot of focus
    is put on making **both the application and the infrastructure resilient**. This
    can be achieved in many ways with or without Kubernetes. If using Kubernetes,
    make sure to run multiple control plane and worker nodes spread across different
    failure domains such as your cloud provider **availability zones** (**AZs**).
    Always run at least two replicas (pods) of an application using a controller such
    as Deployment and make sure to spread them across the topology of your cluster.
    In the case of pod failure, the K8s reconciliation loop will kick in and self-heal
    the application.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 云原生通过引入全新的应用构建和运行方式，显著改善了该领域的情况。云原生应用程序设计时考虑到了故障，并能够从大多数故障中自动恢复。大量的重点放在了让**应用程序和基础设施都具备弹性**上。这可以通过多种方式实现，不论是否使用
    Kubernetes。如果使用 Kubernetes，请确保运行多个控制平面和工作节点，并将它们分布在不同的故障域中，例如云服务提供商的**可用区**（**AZs**）。始终使用如
    Deployment 等控制器运行应用的至少两个副本（pod），并确保它们分布在集群的拓扑结构中。若 pod 发生故障，K8s 的调和循环将启动，并自动修复应用。
- en: Some companies have taken further steps to improve resiliency by introducing
    random failures across the infrastructure, allowing them to detect weak spots
    that need improvement or system redesign. For example, Netflix has become known
    for its **Chaos Monkey** tool that randomly terminates VMs and containers in order
    to incentivize engineers to build highly resilient services.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 一些公司通过在基础设施中引入随机故障，采取了更进一步的措施来提高弹性，使它们能够检测到需要改进或重设计的薄弱环节。例如，Netflix 就以其**混沌猴子**工具而闻名，这个工具会随机终止虚拟机和容器，促使工程师构建高度弹性的服务。
- en: Next on the list is autoscaling—a crucial element for both performance and cost
    efficiency. Again, autoscaling must be implemented for **both the application
    and the infrastructure**. If running Kubernetes, make sure to set up at least
    HPA and Cluster Autoscaler. And don’t forget to configure resource requests and
    limits for all workloads, as it helps K8s to schedule pods in an optimal way.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 排在下一个重点的是自动扩展——这对于性能和成本效率都是至关重要的。自动扩展必须为**应用程序和基础设施**同时实现。如果使用 Kubernetes，请确保至少设置
    HPA 和集群自动扩展器。并且不要忘记为所有工作负载配置资源请求和限制，因为它有助于 K8s 以最优方式调度 pod。
- en: When it comes to application architecture, apply the principle of *loose coupling*—develop
    microservices performing small tasks working together as a part of a larger application.
    Consider event-driven Serverless architecture if that fits your scenarios. In
    many cases, Serverless might be more cost-efficient and require almost zero operations.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在应用架构方面，应用*松耦合*原则——开发执行小任务的微服务，并让它们作为更大应用的一部分协同工作。如果场景适合，考虑使用事件驱动的无服务器架构。在许多情况下，无服务器架构可能更具成本效益，且几乎不需要运维。
- en: When it comes to roles, we’ve already learned in [*Chapter 2*](B18970_02.xhtml#_idTextAnchor026)
    that organizations need to hire the right people for the job. This is not only
    about hiring DevOps and site reliability engineers to handle infrastructure, but
    it is also about team collaboration and corporate culture supporting constant
    change and experimentation. Learnings that come along provide valuable insights
    and lead to improvements in architecture and system design.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 关于角色方面，我们在[*第2章*](B18970_02.xhtml#_idTextAnchor026)中已经了解到，组织需要为合适的岗位聘用合适的人才。这不仅仅是聘请DevOps和站点可靠性工程师来处理基础设施，还涉及团队协作和企业文化的支持，促进不断变化和实验。通过不断学习，能获得宝贵的见解，并促进架构和系统设计的改进。
- en: Furthermore, we briefly mentioned before that Cloud Native applications should
    feature a high degree of automation and ease of management. In [*Chapter 11*](B18970_11.xhtml#_idTextAnchor112),
    we’ll see in detail how automation helps shipping software faster and more reliably.
    And in the upcoming [*Chapter 10*](B18970_10.xhtml#_idTextAnchor104), we’ll discuss
    telemetry and observability.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们之前简要提到过，云原生应用应该具备高度的自动化和易于管理的特点。在[*第11章*](B18970_11.xhtml#_idTextAnchor112)中，我们将详细探讨自动化如何帮助更快速、更可靠地交付软件。在接下来的[*第10章*](B18970_10.xhtml#_idTextAnchor104)中，我们将讨论遥测和可观测性。
- en: Summary
  id: totrans-92
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, we’ve learned about Cloud Native architectures, applications,
    and their features. Not every application that runs in the cloud automatically
    becomes Cloud Native. In fact, Cloud Native principles can be successfully applied
    also on-premises and not just in the cloud. We’ve briefly discussed the benefits
    of Cloud Native and in-depth about two core features—**resiliency** and **autoscaling**.
    While Cloud Native applications do not strictly require Kubernetes to run them,
    K8s makes things much easier with its *self-healing* capabilities and multiple
    autoscaling mechanisms: **HPA**, **VPA**, and **Cluster Autoscaler**.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了云原生架构、应用及其特性。并非所有在云中运行的应用都自动变为云原生应用。实际上，云原生原则也可以成功地应用于本地部署，而不仅仅是云中。我们简要讨论了云原生的好处，并深入探讨了两个核心特性——**弹性**和**自动扩展**。虽然云原生应用并不严格要求必须使用Kubernetes来运行，但K8s凭借其*自愈*能力和多种自动扩展机制，使得实现更加轻松：**HPA**、**VPA**和**集群自动扩展器**。
- en: Next, we covered Serverless or FaaS—a newer, event-driven computing model that
    comes with autoscaling and requires almost no operations at all. With Serverless,
    we are not responsible for any OS, security patching, or server life cycle. Serverless
    is also billed based on the actual usage calculated by the number of actual function
    invocations and the time they run. Serverless technologies can be leveraged to
    implement Cloud Native applications; however, be aware of their limitations.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们介绍了Serverless或FaaS——一种更新的、基于事件驱动的计算模型，具备自动扩展功能，几乎不需要任何操作维护。使用Serverless时，我们无需负责操作系统、安全补丁或服务器生命周期管理。Serverless的计费基于实际使用情况，通过实际函数调用次数和执行时间来计算。Serverless技术可以用来实现云原生应用，但也要注意其局限性。
- en: Finally, we summarized the points about Cloud Native that we’ve learned in this
    chapter and previously, in [*Chapter 2*](B18970_02.xhtml#_idTextAnchor026). In
    the upcoming chapter, we will focus on monitoring Cloud Native applications and
    see how telemetry and observability can be implemented.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们总结了本章以及之前章节中关于云原生的要点，在[*第2章*](B18970_02.xhtml#_idTextAnchor026)中已有提到。在接下来的章节中，我们将重点讨论如何监控云原生应用，并了解如何实现遥测和可观测性。
- en: Questions
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'As we conclude, here is a list of questions for you to test your knowledge
    regarding this chapter’s material. You will find the answers in the *Assessments*
    section of the *Appendix*:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束时，这里有一组问题，供你测试自己对本章内容的理解。你可以在*附录*的*评估*部分找到答案：
- en: Which of the following helps to get better resiliency with Kubernetes?
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个选项有助于提高Kubernetes的弹性？
- en: Resource requests
  id: totrans-99
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 资源请求
- en: Multi-container pods
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 多容器Pod
- en: Reconciliation loop
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 调和循环
- en: Ingress controller
  id: totrans-102
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ingress控制器
- en: Which of the following Kubernetes autoscalers allows us to automatically increase
    and decrease the number of pods based on the load?
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪种Kubernetes自动扩展器允许我们根据负载自动增加或减少Pod的数量？
- en: VPA
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: VPA
- en: HPA
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: HPA
- en: RPA
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: RPA
- en: Cluster Autoscaler
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群自动扩展器（Cluster Autoscaler）
- en: Which of the following Kubernetes autoscalers adjusts container resource requests
    and limits based on statistical data?
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪种Kubernetes自动扩展器基于统计数据调整容器的资源请求和限制？
- en: VPA
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: VPA
- en: HPA
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: HPA
- en: RPA
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: RPA
- en: Cluster Autoscaler
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群自动扩展器（Cluster Autoscaler）
- en: Why is it important to downscale the application and infrastructure?
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么下调应用程序和基础设施的扩展很重要？
- en: To reduce the possible attack surface
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了减少可能的攻击面
- en: To avoid hitting cloud provider limits
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了避免触及云服务提供商的限制
- en: To reduce network traffic
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了减少网络流量
- en: To reduce costs when computation resources are idling
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在计算资源空闲时减少成本
- en: What best describes horizontal scaling?
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么最能描述水平扩展？
- en: Adding more CPU to the same service instance
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向同一服务实例添加更多 CPU
- en: Adding more replicas/instances of the same service
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向同一服务添加更多副本/实例
- en: Adding more RAM to the same service instance
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 向同一服务实例添加更多 RAM
- en: To schedule pods to different nodes where other pods already running
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 Pods 调度到其他已运行 Pod 的不同节点
- en: Which scaling approach is preferred for Cloud Native applications?
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种扩展方法适用于 Cloud Native 应用程序？
- en: Cluster scaling
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群扩展
- en: Cloud scaling
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 云扩展
- en: Vertical scaling
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 垂直扩展
- en: Horizontal scaling
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 水平扩展
- en: Which of the following projects allow us to operate our own Serverless platform
    on Kubernetes (pick multiple)?
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪些项目允许我们在 Kubernetes 上运营自己的无服务器平台（选择多个）？
- en: KubeVirt
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: KubeVirt
- en: KEDA
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: KEDA
- en: Knative
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Knative
- en: OpenFaaS
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenFaaS
- en: What characterizes Serverless computing (pick multiple)?
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么特征表征了无服务器计算（选择多个）？
- en: Servers are not needed anymore
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务器不再需要
- en: It supports all programming languages
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它支持所有编程语言
- en: It is event-based
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它是基于事件的
- en: The provider takes care of server management
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供商负责服务器管理
- en: What is correct about scaling microservices?
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关于微服务扩展，哪种说法是正确的？
- en: Individual microservices can be scaled in and out
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 单独的微服务可以扩展进出
- en: Only all microservices can be scaled in and out at once
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只有所有微服务可以同时进行扩展和收缩
- en: Microservices do not need to be scaled—only the infrastructure needs to be
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 微服务不需要扩展——只需要扩展基础设施
- en: Microservices are best scaled up
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 微服务最适合垂直扩展
- en: Which application design principle works best with Cloud Native?
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种应用程序设计原则最适合 Cloud Native？
- en: Self-healing
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自愈
- en: Tight coupling
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 紧耦合
- en: Decoupling
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 解耦
- en: Loose coupling
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 松耦合
- en: What describes a highly resilient application and infrastructure?
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么描述了一个高度弹性的应用程序和基础设施？
- en: Ability to automatically shut down in case of issues
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在出现问题时自动关闭的能力
- en: Ability to automatically recover from most failures
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自动从大多数故障中恢复的能力
- en: Ability to preserve the state in case of failure
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在故障情况下保持状态的能力
- en: Ability to perform rolling updates
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行滚动更新的能力
- en: What represents the smallest part of a Serverless application?
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么代表了无服务器应用程序的最小部分？
- en: Gateway
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网关
- en: Method
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 方法
- en: Container
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器
- en: Function
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 函数
- en: Which of the following is a correct statement about Serverless?
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个关于无服务器的说法是正确的？
- en: It is only billed for the actual usage
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅按实际使用量计费
- en: It is free as no servers are involved
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它是免费的，因为不涉及服务器
- en: It is billed at a constant hourly price
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按固定小时价格计费
- en: It is billed the same as IaaS services
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按与 IaaS 服务相同的方式计费
- en: Which of the following features do Cloud Native applications have (pick multiple)?
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪些是 Cloud Native 应用程序的特征（选择多个）？
- en: High scalability
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高可扩展性
- en: High efficiency
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高效率
- en: High resiliency
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高弹性
- en: High portability
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 高可移植性
- en: What should normally be scaled in order to accommodate the load?
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通常应该扩展什么以适应负载？
- en: The application and the infrastructure it runs on
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用程序及其运行的基础设施
- en: The load balancer and ingress
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 负载均衡器和入口
- en: The number of application pods
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 应用程序 Pod 的数量
- en: The number of Kubernetes worker nodes
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes 工作节点的数量
- en: Which resiliency testing tool can be used to randomly introduce failures in
    the infrastructure?
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种弹性测试工具可以随机引入基础设施中的故障？
- en: Chaos Monster
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Chaos Monster
- en: Chaos Kube
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Chaos Kube
- en: Chaos Donkey
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Chaos Donkey
- en: Chaos Monkey
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Chaos Monkey
- en: Further reading
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解本章中涉及的主题，请查看以下资源：
- en: 'Autoscaling: [https://glossary.cncf.io/auto-scaling/](https://glossary.cncf.io/auto-scaling/)'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动扩展：[https://glossary.cncf.io/auto-scaling/](https://glossary.cncf.io/auto-scaling/)
- en: 'Kubernetes HPA walkthrough: [https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/)'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes HPA 演练：[https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale-walkthrough/)
- en: 'Kubernetes Cluster Autoscaler: [https://github.com/kubernetes/autoscaler](https://github.com/kubernetes/autoscaler)'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 集群自动扩展器：[https://github.com/kubernetes/autoscaler](https://github.com/kubernetes/autoscaler)
- en: 'Chaos Monkey: [https://github.com/Netflix/chaosmonkey](https://github.com/Netflix/chaosmonkey)'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chaos Monkey: [https://github.com/Netflix/chaosmonkey](https://github.com/Netflix/chaosmonkey)'
- en: 'OpenFaaS: [https://www.openfaas.com/](https://www.openfaas.com/)'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenFaaS: [https://www.openfaas.com/](https://www.openfaas.com/)'
- en: 'Knative: [https://knative.dev/docs/](https://knative.dev/docs/)'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Knative: [https://knative.dev/docs/](https://knative.dev/docs/)'
