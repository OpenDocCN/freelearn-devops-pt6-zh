- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: DaemonSet – Maintaining Pod Singletons on Nodes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DaemonSet – 在节点上维护Pod单例
- en: The previous chapters have explained and demonstrated how to use the most common
    Kubernetes controllers for managing Pods, such as ReplicaSet, Deployment, and
    StatefulSet. Generally, when running cloud application components that contain
    the actual *business logic*, you will need either Deployments or StatefulSets
    for controlling your Pods. In some cases, when you need to run batch workloads
    as part of your application, you will use Jobs and CronJobs.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 前几章已经解释并演示了如何使用最常见的Kubernetes控制器来管理Pods，如ReplicaSet、Deployment和StatefulSet。通常，当运行包含实际*业务逻辑*的云应用组件时，你将需要使用Deployments或StatefulSets来控制你的Pods。在某些情况下，当你需要将批处理工作负载作为应用程序的一部分运行时，你将使用Jobs和CronJobs。
- en: However, in some cases, you will need to run components that have a supporting
    function and, for example, execute maintenance tasks or aggregate logs and metrics.
    More specifically, if you have any tasks that need to be executed for each Node
    in the cluster, they can be performed using a **DaemonSet**. The purpose of a
    DaemonSet is to ensure that *each* Node (unless specified otherwise) runs a *single*
    replica of a Pod. If you add a new Node to the cluster, it will automatically
    get a Pod replica scheduled. Similarly, if you remove a Node from the cluster,
    the Pod replica will be terminated – the DaemonSet will execute all the required
    actions.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在某些情况下，你需要运行具有支持功能的组件，例如执行维护任务或聚合日志和度量数据。更具体地说，如果你有需要在集群中的每个节点上执行的任务，可以使用**DaemonSet**来执行。DaemonSet的目的是确保*每个*节点（除非另有指定）运行*单个*副本的Pod。如果你向集群添加新节点，它将自动调度一个Pod副本。同样，如果你从集群中移除节点，Pod副本将被终止——DaemonSet会执行所有必需的操作。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Introducing the DaemonSet object
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍DaemonSet对象
- en: Creating and managing DaemonSets
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和管理DaemonSets
- en: Common use cases for DaemonSets
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DaemonSet的常见使用案例
- en: Alternatives to DaemonSets
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DaemonSet的替代方案
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you will need the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，你将需要以下内容：
- en: A Kubernetes cluster deployed. You can use either a local or cloud-based cluster,
    but in order to fully understand the concepts, we recommend using a *multi-node*
    Kubernetes cluster.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已部署的Kubernetes集群。你可以使用本地或基于云的集群，但为了更好地理解这些概念，我们建议使用*多节点*Kubernetes集群。
- en: The Kubernetes CLI (`kubectl`) installed on your local machine and configured
    to manage your Kubernetes cluster.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装在本地机器上的Kubernetes CLI（`kubectl`）并已配置用于管理你的Kubernetes集群。
- en: Kubernetes cluster deployment (local and cloud-based) and `kubectl` installation
    were covered in *Chapter 3*, *Installing Your First Kubernetes Cluster*.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes集群部署（本地和基于云的）以及`kubectl`安装已经在*第3章*，*安装你的第一个Kubernetes集群*中介绍过。
- en: 'You can download the latest code samples for this chapter from the official
    GitHub repository: [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter13](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter13).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从官方GitHub仓库下载本章的最新代码示例：[https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter13](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter13)。
- en: Introducing the DaemonSet object
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍DaemonSet对象
- en: The term **daemon** in operating systems has a long history and, in short, is
    used to describe a program that runs as a background process, without interactive
    control from the user. In many cases, daemons are responsible for handling maintenance
    tasks, serving network requests, or monitoring hardware activities. These are
    often processes that you want to run reliably, all the time, in the background,
    from the time you boot the operating system to when you shut it down.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 操作系统中的**守护进程**一词有着悠久的历史，简而言之，用于描述作为后台进程运行的程序，用户无法进行交互控制。在许多情况下，守护进程负责处理维护任务、提供网络请求或监控硬件活动。这些通常是你希望一直可靠地在后台运行的进程，从启动操作系统到关闭它的整个过程。
- en: Daemons are associated in most cases with Unix-like operating systems. In Windows,
    you will more commonly encounter the term *Windows service*.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 守护进程通常与类Unix操作系统相关联。在Windows中，你更常见到的术语是*Windows服务*。
- en: Imagine needing a program to run on every computer in your office, making sure
    everything stays in order. In Kubernetes, that’s where DaemonSets come in. They’re
    like special managers for Pods, ensuring a single copy of a Pod runs on each machine
    (called a Node) in your cluster. Also, in use cases like gRPC, this is crucial
    as gRPC may require a dedicated socket to be created on the node’s filesystem,
    which is easier to manage with one Pod per node.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，你需要一个程序在办公室的每台计算机上运行，以确保一切井然有序。在Kubernetes中，DaemonSet就是为此而设。它们就像是Pod的特殊管理者，确保每个节点（Node）上都有一个Pod的副本运行。此外，在像gRPC这样的应用场景中，这一点尤为重要，因为gRPC可能需要在节点的文件系统上创建一个专用的套接字，单节点一个Pod的管理方式会更加简便。
- en: 'These Pods handle crucial tasks for the entire cluster, like:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些Pod处理集群的关键任务，如：
- en: '**Monitoring**: Keeping an eye on the health of each Node'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控**：监控每个节点的健康状况'
- en: '**Logging**: Collecting information about what’s happening on each Node and
    the Pods running on them'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志记录**：收集有关每个节点及其上运行的Pod的状态信息'
- en: '**Storage management**: Handling requests for storage space for your applications'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储管理**：处理应用程序的存储空间请求'
- en: '**Network management**: Cluster components such as kube-proxy and **Container
    Network Interface** (**CNI**) (e.g., Calico) for connectivity'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络管理**：集群组件，如kube-proxy和**容器网络接口**（**CNI**）（例如，Calico）用于连接性'
- en: As your cluster grows (adding more Nodes), DaemonSets automatically add more
    Pods to manage the new machines. The opposite happens when Nodes are removed –
    the Pods on those Nodes are cleaned up automatically. Think of it as a self-adjusting
    team, always making sure every Node has the help it needs.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 随着集群的扩展（添加更多节点），DaemonSet会自动为新的机器添加更多Pod。相反，当节点被移除时，节点上的Pod会被自动清理。可以把它想象成一个自我调节的团队，始终确保每个节点都能得到所需的帮助。
- en: The following diagram shows the high-level details of a DaemonSet object.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表显示了DaemonSet对象的高级细节。
- en: '![](img/B22019_13_01.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_13_01.png)'
- en: 'Figure 13.1: DaemonSet in Kubernetes'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.1：Kubernetes中的DaemonSet
- en: In simpler setups, one DaemonSet can handle everything for a particular task
    (like monitoring) across all Nodes. More complex situations might use multiple
    DaemonSets for the same task, but with different settings or resource needs depending
    on the type of Node (think high-powered machines vs. basic ones).
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在简单的设置中，一个DaemonSet可以处理所有节点上某一特定任务（如监控）。更复杂的情况可能会使用多个DaemonSet来执行相同的任务，但根据节点类型的不同，配置或资源需求也会有所不同（例如，高性能机器与基础机器之间的差异）。
- en: By using DaemonSets, you can ensure your Kubernetes cluster has the essential
    tools running on every Node, keeping things running smoothly and efficiently.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用DaemonSet，你可以确保你的Kubernetes集群在每个节点上都运行着必要的工具，保持系统顺畅、高效地运行。
- en: All you have learned in the previous chapters about ReplicaSets, Deployments,
    and StatefulSets applies more or less to the DaemonSet. Its specification requires
    you to provide a Pod template, Pod label selectors, and, optionally, Node selectors
    if you want to schedule the Pods only on a subset of Nodes.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 你在前面章节中学到的关于ReplicaSets、Deployments和StatefulSets的知识在DaemonSet中基本适用。它的规范要求你提供Pod模板、Pod标签选择器，此外，如果你希望仅在部分节点上调度Pod，还可以选择提供节点选择器。
- en: 'Depending on the case, you may not need to communicate with the DaemonSet from
    other Pods or an external network. For example, if the job of your DaemonSet is
    just to perform a periodic cleanup of the filesystem on the Node, it is unlikely
    you would like to communicate with such Pods. If your use case requires any ingress
    or egress communication with the DaemonSet Pods, then you have the following common
    patterns:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 根据不同的情况，你可能不需要从其他Pod或外部网络与DaemonSet进行通信。例如，如果DaemonSet的任务只是定期清理节点上的文件系统，那么你可能不希望与这些Pod进行通信。如果你的应用场景需要与DaemonSet
    Pod进行任何入口或出口通信，那么你可以使用以下常见模式：
- en: '**Mapping container ports to host ports**: Since the DaemonSet Pods are guaranteed
    to be singletons on cluster Nodes, it is possible to use mapped host ports. The
    clients must know the Node IP addresses.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将容器端口映射到主机端口**：由于DaemonSet的Pod在集群节点上保证是单一副本，因此可以使用映射的主机端口。客户端必须知道节点的IP地址。'
- en: '**Pushing data to a different service**: In some cases, it may be enough that
    the DaemonSet is responsible for sending updates to other services without needing
    to allow ingress traffic.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**将数据推送到不同的服务**：在某些情况下，DaemonSet仅负责向其他服务发送更新，而无需允许入口流量。'
- en: '**Headless service matching DaemonSet Pod label selectors**: This is a similar
    pattern to the case of StatefulSets, where you can use the cluster DNS to retrieve
    multiple `A records` for Pods using the DNS name of the headless service.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无头服务匹配 DaemonSet Pod 标签选择器**：这与 StatefulSets 的情况类似，你可以使用集群 DNS，通过无头服务的 DNS
    名称来检索多个 `A 记录`，以获取 Pod。'
- en: '**Normal service matching DaemonSet Pod label selectors**: Less commonly, you
    may need to reach *any* Pod in the DaemonSet. Using a normal Service object, for
    example, the `ClusterIP` type, will allow you to communicate with a random Pod
    in the DaemonSet.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**正常服务匹配 DaemonSet Pod 标签选择器**：较少情况下，你可能需要访问 DaemonSet 中的 *任意* Pod。使用普通的 Service
    对象，比如 `ClusterIP` 类型，将允许你与 DaemonSet 中的随机 Pod 进行通信。'
- en: As we discussed, DaemonSets ensures that the Pods for essential services will
    run on all or selected nodes. Let us explore in the next section how the scheduling
    works effectively for DaemonSets.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们所讨论的，DaemonSets 确保了关键服务的 Pods 会在所有或选定的节点上运行。接下来我们将探讨 DaemonSets 如何有效地进行调度。
- en: How DaemonSet Pods are scheduled
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何调度 DaemonSet Pods
- en: DaemonSets guarantee that a single Pod runs on every eligible node in your Kubernetes
    cluster. The DaemonSet controller creates Pods with node affinity rules targeting
    specific nodes. This ensures that Pods for the DaemonSet are only scheduled on
    specific nodes that meet the desired conditions, making it useful for targeting
    certain types of nodes in complex application setups. The default scheduler then
    binds the Pod to the intended node, potentially preempting existing Pods if resources
    are insufficient. While a custom scheduler can be specified, the DaemonSet controller
    ultimately ensures that the Pod placement aligns with the desired node affinity.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: DaemonSets 保证每个符合条件的节点上都会运行一个 Pod。DaemonSet 控制器根据节点亲和性规则创建 Pods，目标是特定节点。这确保了
    DaemonSet 的 Pods 只会调度到满足条件的节点上，这对于在复杂应用程序设置中定位特定类型的节点非常有用。默认的调度器随后将 Pod 绑定到目标节点，如果资源不足，可能会抢占现有
    Pods。虽然可以指定自定义调度器，但最终是 DaemonSet 控制器确保 Pod 的位置与所需的节点亲和性一致。
- en: In the next section, we will learn how you can check the DaemonSet resources
    in the Kubernetes cluster.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将学习如何检查 Kubernetes 集群中的 DaemonSet 资源。
- en: Checking DaemonSets
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查 DaemonSets
- en: Once you deploy a Kubernetes cluster, you might already be using some of the
    DaemonSets deployed as part of the Kubernetes or cluster support components, such
    as the DNS service or CNI.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦部署了 Kubernetes 集群，你可能已经在集群支持组件（如 DNS 服务或 CNI）中使用了一些作为 DaemonSets 部署的组件。
- en: '[PRE0]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Once the cluster is created, verify the nodes in the cluster as follows:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 集群创建完成后，验证集群中的节点如下：
- en: '[PRE2]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, let us check if any DaemonSet is available in the freshly installed system:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查新安装的系统中是否有可用的 DaemonSet：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: If you are following the same method to create a `minikube` cluster, you will
    see a similar output with `calico-node` and `kube-proxy`, which are deployed as
    DaemonSets. (You can also install Calico in your other Kubernetes clusters and
    follow the remaining steps here.) You might have already noticed that we have
    enabled Calico as the CNI plugin in the `minikube` cluster earlier. Calico, when
    used for Kubernetes networking, is typically deployed as a DaemonSet.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你按照相同的方法创建 `minikube` 集群，你会看到类似的输出，包含 `calico-node` 和 `kube-proxy`，它们作为 DaemonSets
    部署。（你也可以在其他 Kubernetes 集群中安装 Calico，并按照这里的剩余步骤进行操作。）你可能已经注意到，我们之前已经在 `minikube`
    集群中启用了 Calico 作为 CNI 插件。当 Calico 用于 Kubernetes 网络时，通常会作为 DaemonSet 部署。
- en: Ignore the `kube-proxy` DaemonSet for now as `minikube` runs kube-proxy as a
    DaemonSet. This guarantees that `kube-proxy`, which is responsible for managing
    network traffic within the cluster, is always up and running on every machine
    in your `minikube` environment.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 暂时忽略 `kube-proxy` DaemonSet，因为 `minikube` 将 kube-proxy 作为 DaemonSet 运行。这保证了负责管理集群内网络流量的
    `kube-proxy` 在你的 `minikube` 环境中的每台机器上始终运行。
- en: Now, let us check the Pods deployed by the `calico-node` DaemonSet.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查由 `calico-node` DaemonSet 部署的 Pods。
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'From this output, we can see that:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从这个输出中，我们可以看到：
- en: Calico Pods are deployed across all `minikube` nodes. The Pods reside on different
    nodes, which correspond to your `minikube` virtual machines (`minikube`, `minikube-m02`,
    and `minikube-m03`). This suggests Calico is using a DaemonSet to ensure a Pod
    is running on each node.
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico Pods 被部署在所有 `minikube` 节点上。这些 Pods 分布在不同的节点上，对应你的 `minikube` 虚拟机（`minikube`、`minikube-m02`
    和 `minikube-m03`）。这表明 Calico 正在使用 DaemonSet 确保每个节点上都有一个 Pod 运行。
- en: The Pod `calico-kube-controllers-ddf655445-jx26x` is the controller of the Calico
    CNI.
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod `calico-kube-controllers-ddf655445-jx26x` 是 Calico CNI 的控制器。
- en: Since the Calico DaemonSet is installed by `minikube` in this case, we will
    not explore much on that side. But in the next section, we will learn how to deploy
    a DaemonSet from scratch and explore it in detail.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Calico DaemonSet 是由 `minikube` 安装的，因此我们不会深入探讨这一方面。但在下一部分，我们将学习如何从头开始部署 DaemonSet
    并详细探索它。
- en: Creating and managing DaemonSets
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建和管理 DaemonSets
- en: In order to demonstrate how DaemonSets work, we will use **Fluentd** Pods. Fluentd
    is a popular open-source log aggregator that centralizes log data from various
    sources. It efficiently collects, filters, and transforms log messages before
    forwarding them to different destinations for analysis and storage.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示 DaemonSet 如何工作，我们将使用 **Fluentd** Pods。Fluentd 是一个流行的开源日志聚合器，用于将来自各种来源的日志数据集中化。它高效地收集、过滤和转换日志消息，然后将它们转发到不同的目的地进行分析和存储。
- en: To access the DaemonSet endpoints, we will use a *headless* service, similar
    to what we did for StatefulSet in *Chapter 12*, *StatefulSet – Deploy Stateful
    Applications*. Most of the real use cases of DaemonSets are rather complex and
    involve mounting various system resources to the Pods. We will keep our DaemonSet
    example as simple as possible to show the principles.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 为了访问 DaemonSet 端点，我们将使用一个 *无头* 服务，类似于我们在 *第 12 章* 中为 StatefulSet 所做的。DaemonSets
    的大多数实际使用案例相对复杂，涉及将各种系统资源挂载到 Pods。为了展示基本原理，我们将使 DaemonSet 示例尽可能简单。
- en: 'If you would like to work on another example of a DaemonSet, we have provided
    a working version of Prometheus `node-exporter` deployed as a DaemonSet behind
    a headless Service: `node-exporter.yaml`. When following the guide in this section,
    the only difference is that you need to use `node-exporter` as the Service name,
    use port `9100`, and append the `/metrics` path for requests sent using `wget`.
    This DaemonSet exposes Node metrics in *Prometheus data model* format on port
    `9100` under the `/metrics` path.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想尝试另一个 DaemonSet 示例，我们提供了一个可以工作的 Prometheus `node-exporter` 示例，该示例作为 DaemonSet
    部署，并通过一个无头服务进行访问：`node-exporter.yaml`。在本节中，唯一的区别是，你需要使用 `node-exporter` 作为服务名称，使用端口
    `9100`，并在请求中添加 `/metrics` 路径，使用 `wget` 发送请求。这个 DaemonSet 会在端口 `9100` 的 `/metrics`
    路径下以 *Prometheus 数据模型* 格式公开节点指标。
- en: We will now go through all the YAML manifests required to create our DaemonSet
    and apply them to the cluster.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过所有创建 DaemonSet 所需的 YAML 清单并将其应用于集群。
- en: Creating a DaemonSet
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 DaemonSet
- en: As a best practice, let us use the declarative way to create the DaemonSet for
    our hands-on practice. First, let’s take a look at the DaemonSet YAML manifest
    file named `Fluentd-daemonset.yaml`.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最佳实践，让我们采用声明式方式来创建 DaemonSet 以进行动手操作。首先，让我们看一下名为 `Fluentd-daemonset.yaml`
    的 DaemonSet YAML 清单文件。
- en: The first part of the YAML is for creating a separate namespace for logging.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: YAML 的第一部分用于为日志创建一个独立的命名空间。
- en: '[PRE5]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: After that, we have our DaemonSet declaration details as follows.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，我们将展示 DaemonSet 声明的详细信息如下。
- en: '[PRE6]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The first part of the preceding file contains the `metadata` and Pod label
    `selector` for the DaemonSet, quite similar to what you have seen in Deployments
    and StatefulSets. In the second part of the file, we present the Pod template
    that will be used by the DaemonSet:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 前面文件的第一部分包含 DaemonSet 的 `metadata` 和 Pod 标签 `selector`，与您在 Deployments 和 StatefulSets
    中看到的非常相似。文件的第二部分展示了 DaemonSet 将使用的 Pod 模板：
- en: '[PRE7]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'As you can see, the structure of the DaemonSet spec is similar to what you
    know from Deployments and StatefulSets. The general idea is the same; you need
    to configure the Pod template and use a proper label selector to match the Pod
    labels. Note that you do *not* see the `replicas` field here, as the number of
    Pods running in the cluster will be dependent on the number of Nodes in the cluster.
    The DaemonSet specification has two main components:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，DaemonSet 规格的结构与 Deployments 和 StatefulSets 的结构类似。大体思路是相同的；你需要配置 Pod
    模板，并使用合适的标签选择器来匹配 Pod 标签。请注意，您在此处*不会*看到 `replicas` 字段，因为集群中运行的 Pods 数量将取决于集群中的节点数。DaemonSet
    规格有两个主要组件：
- en: '`spec.selector`: A label selector, which defines how to identify Pods that
    the DaemonSet owns. This can include *set-based* and *equality-based* selectors.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spec.selector`：一个标签选择器，用于定义如何识别 DaemonSet 所拥有的 Pods。这可以包括 *基于集合* 和 *基于相等性*
    的选择器。'
- en: '`spec.template`: This defines the template for Pod creation. Labels used in
    `metadata` must match the `selector`.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spec.template`：这定义了 Pod 创建的模板。`metadata` 中使用的标签必须与 `selector` 匹配。'
- en: It is also common to specify `.spec.template.spec.nodeSelector` or `.spec.template.spec.tolerations`
    in order to control the Nodes where the DaemonSet Pods are deployed. We will cover
    Pod scheduling in detail in *Chapter 19*, *Advanced Techniques for Scheduling
    Pods*. Additionally, you can specify `.spec.updateStrategy`, `.spec.revisionHistoryLimit`,
    and `.spec.minReadySeconds`, which are similar to what you have learned about
    Deployment objects.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 也很常见通过指定`.spec.template.spec.nodeSelector`或`.spec.template.spec.tolerations`来控制DaemonSet
    Pods部署到哪些节点。我们将在*第19章*，*调度Pod的高级技术*中详细讲解Pod调度。此外，你还可以指定`.spec.updateStrategy`，`.spec.revisionHistoryLimit`和`.spec.minReadySeconds`，这些与Deployment对象的配置类似。
- en: If you run hybrid Linux-Windows Kubernetes clusters, one of the common use cases
    for Node selectors or Node affinity for DaemonSets is ensuring that the Pods are
    scheduled only on Linux Nodes or only on Windows Nodes. This makes sense as the
    container runtime and operating system are very different between such Nodes.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你运行混合的Linux-Windows Kubernetes集群，Node选择器或Node亲和性在DaemonSets中的一个常见用例是确保Pod仅调度到Linux节点或仅调度到Windows节点。这样做是有意义的，因为容器运行时和操作系统在这些节点之间非常不同。
- en: Also, notice the volume mounting lines where the Fluentd pods will get access
    to the `/var/log` directory of the host (where the Pod is running) so that Fluentd
    can process the data and send it to the logging aggregator.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，请注意卷挂载行，Fluentd Pods将访问宿主机（Pod所在的主机）上的`/var/log`目录，以便Fluentd可以处理数据并将其发送到日志聚合器。
- en: Please note that in actual Deployment, we need to provide the target Elasticsearch
    servers to the Fluentd Pods so that Fluentd can send the logs. In our demonstration,
    we are not covering the Elasticsearch setup and you may ignore this part for now.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在实际部署中，我们需要向Fluentd Pods提供目标Elasticsearch服务器，以便Fluentd可以发送日志。在我们的演示中，我们没有覆盖Elasticsearch的设置，你现在可以忽略这一部分。
- en: It is possible to pass such parameters via environment variables to the containers
    as follows. (Refer to the `fluentd-daemonset.yaml` to learn more.)
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过环境变量将这些参数传递给容器，如下所示。（请参考`fluentd-daemonset.yaml`文件了解更多信息。）
- en: '[PRE8]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We have all the required YAML manifest files for our demonstration and we can
    proceed with applying the manifests to the cluster. Please follow these steps:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有所有必要的YAML清单文件进行演示，现在可以继续将这些清单应用到集群中。请按照以下步骤操作：
- en: 'Create the `fluentd-elasticsearch` DaemonSet using the following command:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建`fluentd-elasticsearch` DaemonSet：
- en: '[PRE9]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Now, you can use the `kubectl describe` command to observe the creation of
    the DaemonSet:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你可以使用`kubectl describe`命令来观察DaemonSet的创建过程：
- en: '[PRE10]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Alternatively, you can use `ds` as an abbreviation for `daemonset` when using
    the `kubectl` commands.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，你可以使用`ds`作为`daemonset`的缩写，在使用`kubectl`命令时。
- en: 'Use the `kubectl get pods` command with the `-w` option and you can see that
    there will be one Pod scheduled for each of the Nodes in the cluster, as shown
    below:'
  id: totrans-84
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`kubectl get pods`命令并加上`-w`选项，你可以看到每个集群中的节点都会调度一个Pod，如下所示：
- en: '[PRE11]'
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In our case, we have three Nodes in the cluster, so exactly three Pods have
    been created.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的例子中，集群中有三个节点，因此正好创建了三个Pod。
- en: We have successfully deployed the DaemonSet and we can now verify that it works
    as expected. Ensure that the Fluentd Pods are able to access the Kubernetes node
    log files. To confirm that, log in to one of the Fluentd Pods and check the `/var/log`
    directory.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经成功部署了DaemonSet，现在可以验证它是否按预期工作。确保Fluentd Pods能够访问Kubernetes节点的日志文件。为此，登录到一个Fluentd
    Pod并检查`/var/log`目录。
- en: '[PRE12]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This demonstrates the most important principles underlying how DaemonSet Pods
    are scheduled in Kubernetes.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了DaemonSet Pods在Kubernetes中调度的最重要原理。
- en: It is best practice to use appropriate **taints** and **tolerations** for the
    nodes to implement DaemonSets. We will learn about taints and tolerations in *Chapter
    19*, *Advanced Techniques for Scheduling Pods*.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最佳实践是为节点使用适当的**污点**和**容忍**，以实现DaemonSets。我们将在*第19章*，*调度Pod的高级技术*中学习污点和容忍。
- en: Let us learn about some advanced configurations for the DaemonSet in the next
    section.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在下一节中了解一些DaemonSet的高级配置。
- en: Prioritizing critical DaemonSets in Kubernetes
  id: totrans-92
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Kubernetes中优先考虑关键的DaemonSets
- en: When managing critical system components using DaemonSets in Kubernetes, ensuring
    their uninterrupted operation is crucial. Here’s how to leverage Pod priority
    and PriorityClasses to guarantee these essential Pods aren’t disrupted by lower-priority
    tasks.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中使用 DaemonSets 管理关键系统组件时，确保其连续运行至关重要。以下是如何利用 Pod 优先级和 PriorityClasses
    来保证这些关键 Pods 不会被低优先级任务中断的方法。
- en: Kubernetes assigns a priority level to each Pod, determining its relative importance
    within the cluster. Higher-priority Pods are considered more significant compared
    to lower-priority ones.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 为每个 Pod 分配一个优先级，决定其在集群中的相对重要性。较高优先级的 Pods 被认为比低优先级的 Pods 更重要。
- en: By assigning a higher `PriorityClass` to your DaemonSet, you elevate the importance
    of its Pods. This ensures these critical Pods are not preempted by the scheduler
    to make way for lower-priority Pods when resource constraints arise.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 通过为 DaemonSet 分配更高的 `PriorityClass`，你可以提升其 Pods 的重要性。这样可以确保这些关键 Pods 在资源紧张时不会被调度器抢占，以腾出空间给低优先级的
    Pods。
- en: A PriorityClass defines a specific priority level for Pods. Values in this class
    can range from negative integers to a maximum of 1 billion. Higher values represent
    higher priority.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: PriorityClass 定义了 Pods 的特定优先级。此类中的值可以从负整数到最大 10 亿。较高的值表示较高的优先级。
- en: A sample YAML definition for the **PriorityClass** is given below.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**PriorityClass** 的 YAML 示例定义如下。'
- en: '[PRE13]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Once you have created the PriorityClass, you can use the same in the DaemonSet
    configuration as follows.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了 PriorityClass，你可以在 DaemonSet 配置中按如下方式使用它。
- en: '[PRE14]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: For reference, system components like kube-proxy and cluster CNI (Calico) often
    utilize the built-in `system-node-critical` PriorityClass. This class possesses
    the highest priority, ensuring these vital Pods are never evicted under any circumstances.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 作为参考，像 kube-proxy 和集群 CNI（如 Calico）这样的系统组件通常使用内置的 `system-node-critical` PriorityClass。此类拥有最高优先级，确保这些重要
    Pods 在任何情况下都不会被驱逐。
- en: We will now show how you can modify the DaemonSet to roll out a new version
    of a container image for the Pods.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将展示如何修改 DaemonSet 以便为 Pods 推出新版本的容器镜像。
- en: Modifying a DaemonSet
  id: totrans-103
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 修改 DaemonSet
- en: 'Updating a DaemonSet can be done in a similar way as for Deployments. If you
    modify the *Pod template* of the DaemonSet, this will trigger a *rollout* of a
    new revision of DaemonSet according to its `updateStrategy`. There are two strategies
    available:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 更新 DaemonSet 可以通过类似于 Deployments 的方式进行。如果修改了 DaemonSet 的 *Pod 模板*，这将触发 DaemonSet
    新版本的 *滚动更新*，并根据其 `updateStrategy` 进行。提供了两种策略：
- en: '`RollingUpdate`: The default strategy, which allows you to roll out a new version
    of your daemon in a controlled way. It is similar to rolling updates in Deployments
    in that you can define `.spec.updateStrategy.rollingUpdate.maxUnavailable` to
    control how many Pods in the clusters are unavailable at most during the rollout
    (defaults to `1`) and `.spec.minReadySeconds` (defaults to `0`). It is guaranteed
    that, *at most, one* Pod of DaemonSet will be in a running state on each node
    in the cluster during the rollout process.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RollingUpdate`：默认策略，允许以受控的方式推出你的守护进程的新版本。它类似于 Deployments 中的滚动更新，你可以定义 `.spec.updateStrategy.rollingUpdate.maxUnavailable`
    来控制在滚动过程中集群中最多有多少 Pods 是不可用的（默认为 `1`），以及 `.spec.minReadySeconds`（默认为 `0`）。可以保证，在滚动过程中的每个节点上，DaemonSet
    至多只有一个 Pod 处于运行状态。'
- en: '`OnDelete`: This strategy implements the legacy behavior of StatefulSet updates
    prior to Kubernetes 1.6\. In this type of strategy, the DaemonSet will *not* automatically
    update the Pod by recreating them. You need to manually delete a Pod on a Node
    in order to get the new Pod template applied. This is useful in scenarios when
    you need to do additional manual actions or verifications before proceeding to
    the next Node.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`OnDelete`：此策略实现了 Kubernetes 1.6 之前 StatefulSet 更新的旧行为。在这种策略下，DaemonSet *不会*通过重新创建
    Pods 来自动更新。你需要手动删除节点上的 Pod，才能应用新的 Pod 模板。此策略适用于在继续下一个节点之前，需要进行额外的手动操作或验证的场景。'
- en: 'The rollout of a new DaemonSet revision can be controlled in similar ways as
    for a Deployment object. You can use the `kubectl rollout status` command and
    perform *imperative* rollbacks using the `kubectl rollout undo` command. Let’s
    demonstrate how you can *declaratively* update the container image in a DaemonSet
    Pod to a newer version:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 新的 DaemonSet 版本的滚动更新可以通过与 Deployment 对象类似的方式进行控制。你可以使用 `kubectl rollout status`
    命令并通过 `kubectl rollout undo` 命令执行 *强制* 回滚。以下是如何 *声明性* 地将 DaemonSet Pod 中的容器镜像更新到新版本的演示：
- en: 'Modify the `fluentd-daemonset.yaml` YAML manifest file so that it uses the
    `quay.io/fluentd_elasticsearch/fluentd:v4.7.5` container image in the template:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 修改 `fluentd-daemonset.yaml` YAML 清单文件，使其在模板中使用 `quay.io/fluentd_elasticsearch/fluentd:v4.7.5`
    容器镜像：
- en: '[PRE15]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Apply the manifest file to the cluster:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将清单文件应用到集群中：
- en: '[PRE16]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Immediately after that, use the `kubectl rollout status` command to see the
    progress in real time:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 紧接着，使用 `kubectl rollout status` 命令实时查看进度：
- en: '[PRE17]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Similarly, using the `kubectl describe` command, you can see events for the
    DaemonSet that exactly show what the order was of the Pod recreation:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，使用 `kubectl describe` 命令，你可以查看 DaemonSet 的事件，准确显示 Pod 重建的顺序：
- en: '[PRE18]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: You can see that the Pods were replaced one by one.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到 Pod 被一个个替换。
- en: You can change the DaemonSet container image *imperatively* using the `kubectl
    set image ds fluentd-elasticsearch fluentd-elasticsearch=quay.io/fluentd_elasticsearch/fluentd:v4.7.5
    -n logging` command. This approach is recommended only for non-production scenarios.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过 `kubectl set image ds fluentd-elasticsearch fluentd-elasticsearch=quay.io/fluentd_elasticsearch/fluentd:v4.7.5
    -n logging` 命令*强制*更改 DaemonSet 容器镜像。此方法仅推荐用于非生产环境。
- en: Additionally, the DaemonSet will automatically create Pods if a new Node joins
    the cluster (providing that it matches the selector and affinity parameters).
    If a Node is removed from the cluster, the Pod will also be terminated. The same
    will happen if you modify the labels or taints on a Node so that it matches the
    DaemonSet – a new Pod will be created for that Node. If you modify the labels
    or taints for a Node in a way that no longer matches the DaemonSet, the existing
    Pod will be terminated.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，如果新节点加入集群，DaemonSet 会自动创建 Pod（前提是节点符合选择器和亲和性参数）。如果一个节点从集群中移除，相应的 Pod 也会被终止。如果你修改节点上的标签或污点使其符合
    DaemonSet 的条件，那么会为该节点创建一个新的 Pod。如果你修改节点的标签或污点，使其不再符合 DaemonSet 的条件，现有的 Pod 将被终止。
- en: Next, we will learn how to roll back a DaemonSet update.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习如何回滚 DaemonSet 更新。
- en: Rolling back the DaemonSet
  id: totrans-120
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回滚 DaemonSet
- en: As we learned in the previous chapters, it is also possible to roll back the
    DaemonSet using the `kubectl rollback` command as follows.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的章节中所学，你也可以通过以下 `kubectl rollback` 命令回滚 DaemonSet。
- en: '[PRE19]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: However, it is highly recommended to update the YAML and apply configurations
    in a declarative method for the production environments.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，强烈建议在生产环境中通过更新 YAML 并以声明式方式应用配置。
- en: Next, we will show how you can delete a DaemonSet.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将展示如何删除 DaemonSet。
- en: Deleting a DaemonSet
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除 DaemonSet
- en: 'In order to delete a DaemonSet object, there are two possibilities:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除 DaemonSet 对象，有两种可能性：
- en: Delete the DaemonSet together with the Pods that it owns.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除 DaemonSet 及其所拥有的 Pod。
- en: Delete the DaemonSet and leave the Pods unaffected.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除 DaemonSet 并保持 Pod 不受影响。
- en: 'To delete the DaemonSet together with Pods, you can use the regular `kubectl
    delete` command as follows:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除 DaemonSet 及其 Pod，可以使用常规的 `kubectl delete` 命令，如下所示：
- en: '[PRE20]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: You will see that the Pods will first get terminated and then the DaemonSet
    will be deleted.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到 Pod 首先会被终止，然后 DaemonSet 会被删除。
- en: 'Now, if you would like to delete just the DaemonSet, you need to use the `--cascade=orphan`
    option with `kubectl delete`:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你只想删除 DaemonSet，可以在 `kubectl delete` 命令中使用 `--cascade=orphan` 选项：
- en: '[PRE21]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: After this command, if you inspect which Pods are in the cluster, you will still
    see all the Pods that were owned by the `fluentd-elasticsearch` DaemonSet.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此命令后，如果你检查集群中的 Pod，你仍然会看到所有由 `fluentd-elasticsearch` DaemonSet 所管理的 Pod。
- en: If you are draining a node using the `kubectl drain` command and this node is
    running Pods owned by a DaemonSet, you need to pass the `--ignore-daemonsets`
    flag to drain the node completely.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用 `kubectl drain` 命令进行节点排空，并且该节点正在运行由 DaemonSet 管理的 Pod，你需要传递 `--ignore-daemonsets`
    标志，以完全排空该节点。
- en: Let’s now take a look at the most common use cases for DaemonSets in Kubernetes.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看 Kubernetes 中 DaemonSet 的最常见使用场景。
- en: Common use cases for DaemonSets
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DaemonSet 的常见使用场景
- en: 'At this point, you may wonder what is the actual use of the DaemonSet and what
    the real-life use cases are for this Kubernetes object. In general, DaemonSets
    are used either for very fundamental functions of the cluster, without which it
    is not usable, or for helper workloads performing maintenance or data collection.
    We have summarized the common and interesting use cases for DaemonSets in the
    following points:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 到此时，你可能会想，DaemonSet 实际上是做什么的，现实中的使用场景有哪些。一般来说，DaemonSets 要么用于集群的基础功能，没有这些功能集群无法使用，要么用于执行维护或数据收集的辅助工作负载。我们在以下几点中总结了
    DaemonSets 的常见和有趣的使用场景：
- en: 'Depending on your cluster Deployment, the `kube-proxy` core service may be
    deployed as a DaemonSet instead of a regular operating system service. For example,
    in the case of **Azure Kubernetes Service** (**AKS**), you can see the definition
    of this DaemonSet using the `kubectl describe ds -n kube-system kube-proxy` command.
    This is a perfect example of a backbone service that needs to run as a singleton
    on each Node in the cluster. You can also see an example YAML manifest for `kube-proxy`
    here: [https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/kube-proxy/kube-proxy-ds.yaml](https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/kube-proxy/kube-proxy-ds.yaml).'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据你的集群部署方式，`kube-proxy` 核心服务可能会作为 DaemonSet 而不是常规操作系统服务进行部署。例如，在 **Azure Kubernetes
    Service**（**AKS**）的情况下，你可以使用 `kubectl describe ds -n kube-system kube-proxy` 命令查看该
    DaemonSet 的定义。这是一个典型的示例，展示了需要在集群中每个节点上以单例方式运行的骨干服务。你还可以在这里看到 `kube-proxy` 的示例
    YAML 清单：[https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/kube-proxy/kube-proxy-ds.yaml](https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/kube-proxy/kube-proxy-ds.yaml)。
- en: Another example of fundamental services running as DaemonSets is running an
    installation of **CNI** plugins and agents for maintaining the network in a Kubernetes
    cluster. We have already tested this with the Calico CNI DaemonSet in our `minikube`
    cluster at the beginning of this chapter. Another good example of such a DaemonSet
    is the Flannel agent ([https://github.com/flannel-io/flannel/blob/master/Documentation/kube-flannel.yml](https://github.com/flannel-io/flannel/blob/master/Documentation/kube-flannel.yml)),
    which runs on each Node and is responsible for allocating a subnet lease to each
    host out of a larger, preconfigured address space. This, of course, depends on
    what type of networking is installed on the cluster.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个作为 DaemonSets 运行的基础服务示例是运行 **CNI** 插件和代理程序，用于维护 Kubernetes 集群中的网络。我们已经在本章开始时通过
    `minikube` 集群测试过 Calico CNI DaemonSet。另一个很好的 DaemonSet 示例是 Flannel 代理（[https://github.com/flannel-io/flannel/blob/master/Documentation/kube-flannel.yml](https://github.com/flannel-io/flannel/blob/master/Documentation/kube-flannel.yml)），它在每个节点上运行，负责从更大的、预配置的地址空间中为每个主机分配一个子网租约。当然，这取决于集群中安装的网络类型。
- en: 'Cluster storage daemons will often be deployed as DaemonSets. A good example
    of a commonly used daemon is the **Object Storage Daemon** (**OSD**) for **Ceph**,
    which is a distributed object, block, and file storage platform. OSD is responsible
    for storing objects on the local filesystem of each Node and providing access
    to them over the network. You can find an example manifest file here (as part
    of a Helm chart template): [https://github.com/ceph/ceph-container/blob/master/examples/helm/ceph/templates/osd/daemonset.yaml](https://github.com/ceph/ceph-container/blob/master/examples/helm/ceph/templates/osd/daemonset.yaml).'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群存储守护进程通常会作为 DaemonSets 部署。一个常见的守护进程示例是 **对象存储守护进程**（**OSD**），它是 **Ceph** 的一部分，Ceph
    是一个分布式的对象、块和文件存储平台。OSD 负责在每个节点的本地文件系统上存储对象，并通过网络提供访问。你可以在这里找到一个示例清单文件（作为 Helm
    图表模板的一部分）：[https://github.com/ceph/ceph-container/blob/master/examples/helm/ceph/templates/osd/daemonset.yaml](https://github.com/ceph/ceph-container/blob/master/examples/helm/ceph/templates/osd/daemonset.yaml)。
- en: 'Ingress controllers in Kubernetes are sometimes deployed as DaemonSets. We
    will take a closer look at Ingress in *Chapter 21*, *Advanced Kubernetes: Traffic
    Management, Multi-Cluster Strategies and More*. For example, when you deploy `nginx`
    as an Ingress controller in your cluster, you have an option to deploy it as a
    DaemonSet: [https://github.com/nginxinc/kubernetes-ingress/blob/master/deployments/daemon-set/nginx-ingress.yaml](https://github.com/nginxinc/kubernetes-ingress/blob/master/deployments/daemon-set/nginx-ingress.yaml).
    Deploying an Ingress controller as a DaemonSet is especially common if you do
    Kubernetes cluster deployments on bare-metal servers.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 中的 Ingress 控制器有时作为 DaemonSet 部署。我们将在 *第21章*，*高级 Kubernetes：流量管理、多集群策略及更多*
    中更详细地探讨 Ingress。例如，当你在集群中部署 `nginx` 作为 Ingress 控制器时，你可以选择将其作为 DaemonSet 部署：[https://github.com/nginxinc/kubernetes-ingress/blob/master/deployments/daemon-set/nginx-ingress.yaml](https://github.com/nginxinc/kubernetes-ingress/blob/master/deployments/daemon-set/nginx-ingress.yaml)。如果你在裸机服务器上进行
    Kubernetes 集群部署，将 Ingress 控制器作为 DaemonSet 部署尤其常见。
- en: 'Log gathering and aggregation agents are often deployed as DaemonSets. For
    example, `fluentd` can be deployed as a DaemonSet in a cluster. You can find multiple
    YAML manifest files with examples in the official repository: [https://github.com/fluent/fluentd-kubernetes-daemonset](https://github.com/fluent/fluentd-kubernetes-daemonset).'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志收集和聚合代理通常作为 DaemonSet 部署。例如，`fluentd` 可以作为 DaemonSet 在集群中部署。你可以在官方仓库中找到多个包含示例的
    YAML 清单文件：[https://github.com/fluent/fluentd-kubernetes-daemonset](https://github.com/fluent/fluentd-kubernetes-daemonset)。
- en: 'Agents for collecting Node metrics make a perfect use case for Deployment as
    DaemonSets. A well-known example of such an agent is Prometheus `node-exporter`:
    [https://github.com/prometheus-operator/kube-prometheus/blob/main/manifests/nodeExporter-daemonset.yaml](https://github.com/prometheus-operator/kube-prometheus/blob/main/manifests/nodeExporter-daemonset.yaml).'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于收集节点指标的代理非常适合作为 DaemonSet 部署。一个著名的例子是 Prometheus 的 `node-exporter`：[https://github.com/prometheus-operator/kube-prometheus/blob/main/manifests/nodeExporter-daemonset.yaml](https://github.com/prometheus-operator/kube-prometheus/blob/main/manifests/nodeExporter-daemonset.yaml)。
- en: The list goes on – as you can see, a DaemonSet is another building block provided
    for engineers designing the workloads running on Kubernetes clusters. In many
    cases, DaemonSets are the hidden backbone of a cluster that makes it fully operational.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是其中一部分——正如你所看到的，DaemonSet 是为设计在 Kubernetes 集群上运行的工作负载的工程师提供的另一个构建模块。在许多情况下，DaemonSet
    是集群的隐性支柱，使其能够完全运行。
- en: Let us now learn about the recommended best practices for DaemonSet implementations.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们学习一下 DaemonSet 实现的推荐最佳实践。
- en: DaemonSet best practices
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DaemonSet 最佳实践
- en: 'DaemonSets are powerful tools in Kubernetes for managing Pods that need to
    run on every node. But to ensure they work as expected, there are some key things
    to keep in mind:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: DaemonSet 是 Kubernetes 中强大的工具，用于管理需要在每个节点上运行的 Pods。但为了确保它们按预期工作，有一些关键点需要记住：
- en: '**Resource requests and limits**: Briefly mentioning the importance of setting
    appropriate resource requests and limits for DaemonSet Pods can help users manage
    resource allocation effectively. This can help prevent resource starvation for
    other Pods in the cluster.'
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**资源请求与限制**：简要提到为 DaemonSet Pods 设置适当的资源请求与限制的重要性，有助于用户有效地管理资源分配。这可以帮助避免集群中其他
    Pods 资源的饥饿问题。'
- en: '**Clean and separate**: Organize your DaemonSets by placing each one in its
    own separate namespace. This keeps things tidy and simplifies managing resources.'
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**清晰且分离**：通过将每个 DaemonSet 放在其自己的命名空间中来组织它们。这可以保持整洁，并简化资源管理。'
- en: '**Scheduling smarts**: When creating a DaemonSet, it’s recommended to use `preferredDuringSchedulingIgnoredDuringExecution`
    instead of `requiredDuringSchedulingIgnoredDuringExecution`. The first option
    allows for more flexibility if there aren’t enough nodes available initially.'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**调度智能**：创建 DaemonSet 时，建议使用 `preferredDuringSchedulingIgnoredDuringExecution`
    而不是 `requiredDuringSchedulingIgnoredDuringExecution`。第一个选项在初始时如果没有足够的节点可用时，提供更多的灵活性。'
- en: '**Wait for readiness** (optional): You can use the `minReadySeconds` setting
    in your Pod schema. This tells Kubernetes to wait a certain amount of time before
    creating new Pods during an update. This helps ensure all existing Pods are healthy
    before adding new ones.'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**等待就绪**（可选）：你可以在 Pod 模式中使用 `minReadySeconds` 设置。这告诉 Kubernetes 在更新期间创建新 Pod
    之前，等待一段时间。这有助于确保所有现有 Pods 都处于健康状态，然后再添加新 Pods。'
- en: '**Monitoring and logging**: A quick note about the importance of monitoring
    and logging for DaemonSet Pods can be helpful. This allows users to track the
    health and performance of their DaemonSets and identify any potential issues.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控与日志**：简要提一下监控与日志对于 DaemonSet Pods 的重要性是有帮助的。这允许用户跟踪 DaemonSets 的健康状态和性能，并识别潜在问题。'
- en: '**Always running**: Make sure your DaemonSet Pods have a **Restart Policy**
    set to `Always` (or leave it unspecified). This guarantees that the Pods automatically
    restart if they ever crash.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**始终运行**：确保你的 DaemonSet Pods 的 **重启策略** 设置为 `Always`（或保持未指定）。这保证了 Pods 在崩溃时会自动重启。'
- en: '**High priority**: Give your DaemonSet Pods a high priority (like `10000`)
    to ensure they get the resources they need and aren’t evicted by other Pods.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**高优先级**：为你的 DaemonSet Pods 设置高优先级（例如 `10000`），以确保它们获得所需的资源，并且不会被其他 Pods 驱逐。'
- en: '**Matching labels**: Define a pod selector that matches the labels of your
    DaemonSet template. This ensures the Pods deployed by the DaemonSet are the ones
    you intended.'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**匹配标签**：定义一个 Pod 选择器，匹配你的 DaemonSet 模板的标签。这样可以确保 DaemonSet 部署的 Pods 是你所期望的。'
- en: By following these best practices, you can configure your DaemonSets to run
    smoothly and keep your Kubernetes cluster functioning optimally.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 通过遵循这些最佳实践，你可以配置你的 DaemonSets 使其平稳运行，并保持 Kubernetes 集群的最佳性能。
- en: Next, let’s discuss what possible alternatives there are to using DaemonSets.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们讨论一下使用 DaemonSets 的可能替代方案。
- en: Alternatives to DaemonSets
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: DaemonSets 的替代方案
- en: 'The reason for using DaemonSets is quite simple – you would like to have exactly
    one Pod with a particular function on each Node in the cluster. However, sometimes,
    you should consider different approaches that may fit your needs better:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 DaemonSets 的原因非常简单——你希望在集群中的每个节点上都有一个具有特定功能的 Pod。然而，有时你应该考虑其他可能更适合你需求的方法：
- en: In log-gathering scenarios, you need to evaluate whether you want to design
    your log pipeline architecture based on DaemonSets or the *sidecar* container
    pattern. Both have their advantages and disadvantages, but in general, running
    sidecar containers may be easier to implement and more robust, even though it
    may require more system resources.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在日志收集场景中，你需要评估是否希望基于 DaemonSets 或 *sidecar* 容器模式来设计你的日志管道架构。两者各有优缺点，但通常来说，运行
    sidecar 容器可能更容易实现，且更具稳健性，尽管可能需要更多的系统资源。
- en: If you just want to run periodic tasks, and you do not need to do it on each
    Node in the cluster, a better solution can be using **Kubernetes CronJobs**. Again,
    it is important to know what the actual use case is and whether running a separate
    Pod on each Node is a must-have requirement.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你只是想运行定期任务，并且不需要在集群中的每个节点上都执行，使用 **Kubernetes CronJobs** 可能是更好的解决方案。再次强调，了解实际的用例是什么，以及是否必须在每个节点上运行独立的
    Pod 是非常重要的。
- en: Operating system daemons (for example, provided by `systemd` in Ubuntu) can
    be used to do similar tasks as DaemonSets. The drawback of this approach is that
    you cannot manage these native daemons using the same tools as you manage Kubernetes
    clusters with, for example, `kubectl`. But at the same time, you do not have the
    dependency on any Kubernetes service, which may be a good thing in some cases.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作系统守护进程（例如，Ubuntu 中由 `systemd` 提供的守护进程）可以用来执行与 DaemonSets 类似的任务。该方法的缺点是，你不能像管理
    Kubernetes 集群一样使用相同的工具（例如 `kubectl`）来管理这些本地守护进程。但同时，你不依赖于任何 Kubernetes 服务，在某些情况下这可能是个好处。
- en: Static Pods ([https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/](https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/))
    can be used to achieve a similar result. This type of Pod is created based on
    a specific directory watched by `kubelet` for static manifest files. Static Pods
    cannot be managed using `kubectl` and they are most useful for cluster bootstrapping
    functions.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静态 Pods ([https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/](https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/))
    可以用来实现类似的结果。这种类型的 Pod 是基于 `kubelet` 监视的特定目录中的静态清单文件创建的。静态 Pods 无法通过 `kubectl`
    管理，最常用于集群引导功能。
- en: Finally, we can now summarize our knowledge about DaemonSets.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们现在可以总结我们关于 DaemonSets 的知识。
- en: Summary
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter, you have learned how to work with DaemonSets in Kubernetes
    and how they are used to manage special types of workloads or processes that must
    run as a singleton on each Node in the cluster. You first created an example DaemonSet
    and learned what the most important parts of its specification are. Next, you
    practiced how to roll out a new revision of a DaemonSet to the cluster and saw
    how you can monitor the Deployment. Additionally, we discussed what the most common
    use cases are for this special type of Kubernetes object and what alternatives
    there are that you could consider.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你已经学习了如何在 Kubernetes 中使用 DaemonSets，以及它们是如何用于管理必须作为单例在每个节点上运行的特殊类型的工作负载或进程。你首先创建了一个示例
    DaemonSet，并了解了其规范中最重要的部分。接下来，你练习了如何向集群推出 DaemonSet 的新版本，并观察了如何监控该部署。此外，我们还讨论了这种特殊类型的
    Kubernetes 对象的最常见使用案例以及你可以考虑的替代方案。
- en: This was the last type of Pod management controller that we discussed in this
    part of the book. In the next part of this book, we will examine some more advanced
    Kubernetes usage, starting with Helm charts and then Kubernetes operators.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们在本书这一部分讨论的最后一种 Pod 管理控制器。在本书的下一部分，我们将探讨一些更高级的 Kubernetes 使用方法，从 Helm Charts
    开始，然后是 Kubernetes Operators。
- en: Further reading
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: 'DaemonSet: [https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'DaemonSet: [https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/)'
- en: )
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'Network Policy: [https://minikube.sigs.k8s.io/docs/handbook/network_policy/](https://minikube.sigs.k8s.io/docs/handbook/network_policy/'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '网络策略: [https://minikube.sigs.k8s.io/docs/handbook/network_policy/](https://minikube.sigs.k8s.io/docs/handbook/network_policy/)'
- en: )
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'Fluentd Deployment on Kubernetes: [https://docs.fluentd.org/container-deployment/kubernetes](https://docs.fluentd.org/container-deployment/kubernetes'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fluentd 在 Kubernetes 上的部署: [https://docs.fluentd.org/container-deployment/kubernetes](https://docs.fluentd.org/container-deployment/kubernetes)'
- en: )
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: )
- en: 'Perform a Rolling Update on a DaemonSet: https://kubernetes.io/docs/tasks/manage-daemon/update-daemon-set/'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '对 DaemonSet 进行滚动更新: https://kubernetes.io/docs/tasks/manage-daemon/update-daemon-set/'
- en: Join our community on Discord
  id: totrans-177
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的社区 Discord
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
- en: '![](img/QR_Code119001106479081656.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code119001106479081656.png)'
