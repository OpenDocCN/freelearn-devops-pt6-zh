- en: '*Chapter 6*: Securing Kubernetes Effectively'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第六章*：有效地保护 Kubernetes'
- en: In previous chapters, you learned how to design and provision the infrastructure
    of Kubernetes clusters, fine-tune their configuration, and deploy extra add-ons
    and services on top of the clusters, such as networking, security, monitoring,
    and scaling.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前的章节中，你学习了如何设计和配置 Kubernetes 集群的基础设施，微调它们的配置，并在集群上部署额外的插件和服务，例如网络、安全、监控和扩展。
- en: In this chapter, you will learn about the different aspects of Kubernetes security,
    focusing on qualifying the cluster to have a production-grade security. We will
    follow an end-to-end security approach to cover all of the essential areas that
    every production cluster should have. We will know how to bring the cluster security
    closer to the production readiness state by fine-tuning the security configuration
    of the cluster and its infrastructure and deploying new security add-ons and tools,
    and finally ensure cluster security compliance and conformance to security standards
    and checks.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习 Kubernetes 安全的不同方面，重点是使集群具备生产级别的安全性。我们将采取端到端的安全方法，涵盖每个生产集群应具备的所有重要领域。我们将了解如何通过微调集群及其基础设施的安全配置、部署新的安全插件和工具，最终确保集群的安全合规性以及遵循安全标准和检查，从而使集群的安全性更加接近生产准备状态。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Securing Kubernetes infrastructure
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保护 Kubernetes 基础设施
- en: Managing cluster access
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理集群访问
- en: Managing secrets and certificates
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理密钥和证书
- en: Securing workloads and apps
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保护工作负载和应用程序
- en: Ensuring cluster security and compliance
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保集群安全和合规性
- en: Bonus security tips
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 额外的安全提示
- en: Deploying the security configurations
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署安全配置
- en: Destroying the cluster
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 销毁集群
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You should have the following tools installed from the previous chapters:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该已经在之前的章节中安装了以下工具：
- en: AWS CLI V2
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS CLI V2
- en: AWS IAM Authenticator
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS IAM Authenticator
- en: '`kubectl`'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubectl`'
- en: Terraform
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Terraform
- en: Python3
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python3
- en: PIP 3
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PIP 3
- en: virtualenv
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: virtualenv
- en: You need to have an up-and-running Kubernetes cluster
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你需要有一个正在运行的 Kubernetes 集群
- en: The code for this chapter is available at [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的代码可以在[https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06)获取。
- en: 'Check out the following link to see the Code in Action video:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 查看以下链接，观看《代码实践》视频：
- en: '[https://bit.ly/2MBwZNk](https://bit.ly/2MBwZNk)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://bit.ly/2MBwZNk](https://bit.ly/2MBwZNk)'
- en: Securing Kubernetes infrastructure
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护 Kubernetes 基础设施
- en: In [*Chapter 2*](B16192_02_Final_PG_ePub.xhtml#_idTextAnchor051), *Architecting
    Production-Grade Kubernetes Infrastructure*, we discussed the best practices for
    the network infrastructure for Kubernetes clusters and we proposed design guidelines
    that are essential for the infrastructure security of clusters. While these guidelines
    are essential for you to consider and follow, you still need to evaluate the entire
    network security requirements of your infrastructure to be sure that you have
    a complete and appropriate security solution for your environment and product.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第二章*](B16192_02_Final_PG_ePub.xhtml#_idTextAnchor051)，*构建生产级 Kubernetes 基础设施*
    中，我们讨论了 Kubernetes 集群网络基础设施的最佳实践，并提出了对集群基础设施安全至关重要的设计指南。虽然这些指南对于你考虑和遵循非常重要，但你仍然需要评估整个网络安全需求，以确保你为你的环境和产品提供了完整且适当的安全解决方案。
- en: 'Most of these security recommendations and best practices are implemented within
    the Terraform and Ansible configurations that we did in the previous chapters:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这些安全建议和最佳实践大多已经在我们之前章节中使用的 Terraform 和 Ansible 配置中实现：
- en: Use multiple availability zones (three or more) to deploy your Kubernetes cluster
    for high availability.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用多个可用区（三个或更多）来部署你的 Kubernetes 集群，以确保高可用性。
- en: Deploy the control plane and worker nodes in private subnets only. Use the public
    subnets for internet-facing load balancers.
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仅在私有子网中部署控制平面和工作节点。将公共子网用于面向互联网的负载均衡器。
- en: Do not allow public access to worker nodes. Expose services externally through
    load balancers or ingress controllers, and not through node ports.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不允许公共访问工作节点。通过负载均衡器或入口控制器对外暴露服务，而不是通过节点端口。
- en: Serve all the traffic between the API server and other control plane components
    or workers over TLS.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 API 服务器与其他控制平面组件或工作节点之间传输的所有流量都应通过 TLS 进行加密。
- en: Limit network access to the Kubernetes API endpoint.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制对 Kubernetes API 端点的网络访问。
- en: Block access to `kubelet`.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 阻止对 `kubelet` 的访问。
- en: Use security groups to block access to workers and control plane ports, except
    secure ones.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用安全组来阻止对工作节点和控制平面端口的访问，除非是安全端口。
- en: Disable SSH access to worker nodes. You can use AWS Systems Manager Session
    Manager instead of running SSHD to connect to nodes.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 禁用对工作节点的 SSH 访问。您可以使用 AWS Systems Manager Session Manager 来代替运行 SSHD 连接到节点。
- en: 'Restrict access to the EC2 instance profile credentials. By default, the containers
    in a pod use the same IAM permissions assigned to the node instance profile. This
    is considered an insecure behavior, because it gives the containers full control
    over the node and the underlying AWS services. To avoid this behavior, you must
    disable the pod''s access to the node''s instance profile by executing the following
    `iptables` commands inside the node:'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制对 EC2 实例配置文件凭证的访问。默认情况下，Pod 中的容器使用与节点实例配置文件关联的相同 IAM 权限。这被认为是一种不安全的行为，因为它赋予容器对节点和底层
    AWS 服务的完全控制。为了避免这种行为，您必须通过在节点内执行以下 `iptables` 命令来禁用 Pod 对节点实例配置文件的访问：
- en: '[PRE0]'
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: As we are using EKS, it is highly recommended to use a regular `kubelet` agent.
    Another reason for avoiding EKS node groups is that it enforces the attachment
    of public IPs to the worker nodes, which can represent security threats.
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于我们使用的是 EKS，强烈建议使用常规的 `kubelet` 代理。避免使用 EKS 节点组的另一个原因是它强制要求工作节点附加公共 IP，这可能带来安全威胁。
- en: The preceding list covers the essential production infrastructure security guidelines
    for your Kubernetes clusters. All of these guidelines are covered by cluster provisioning
    and configuration management, which we implemented in the previous chapters. It
    is worth mentioning that your cluster infrastructure may have extra security requirements
    that you should consider during infrastructure design and provisioning.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 上述列表涵盖了 Kubernetes 集群生产基础设施安全的基本指南。所有这些指南都通过集群配置和管理来涵盖，我们在前几章中实现了这些内容。值得一提的是，您的集群基础设施可能有额外的安全要求，您应在基础设施设计和部署过程中加以考虑。
- en: Managing cluster access
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理集群访问
- en: 'Requests from a cluster''s users, either humans or service accounts, need to
    go through authentication and authorization stages before hitting the API server
    and manipulating the required Kubernetes objects. A typical request goes through
    three access stages before it gets either allowed or rejected:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 集群用户的请求，无论是人类用户还是服务账户，都需要通过认证和授权阶段，然后才能到达 API 服务器并操作所需的 Kubernetes 对象。一个典型的请求需要经过三个访问阶段，才能决定是否被允许或拒绝：
- en: '![Figure 6.1 – Kubernetes access stages'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.1 – Kubernetes 访问阶段'
- en: '](img/B16192_06_001.jpg)'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.1 – Kubernetes 访问阶段](img/B16192_06_001.jpg)'
- en: Figure 6.1 – Kubernetes access stages
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1 – Kubernetes 访问阶段
- en: The request has to go through the authentication stage to verify the client's
    identity by any of the mechanisms supported by Kubernetes, then it goes through
    the authorization stage to verify which actions are allowed for this user, and
    finally it goes through the admission controller stage to decide whether any modifications
    need to be made. You will learn about each of these in the following subsections.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 请求必须通过认证阶段，使用 Kubernetes 支持的任一机制验证客户端身份，然后通过授权阶段验证该用户允许执行的操作，最后通过准入控制阶段决定是否需要进行任何修改。您将在以下子章节中了解这些过程。
- en: Cluster authentication
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集群认证
- en: Kubernetes cluster users need to successfully authenticate into the cluster
    to access its objects. However, normal cluster users, such as developers and administrators,
    are not supposed to be managed by Kubernetes, but by an external service outside
    the cluster, such as **Lightweight Directory Access Protocol** (**LDAP**), **OpenID
    Connect** (**OIDC**), AWS **Identity and Access Management** (**IAM**), or even
    a file with users and password pairs. On the other hand, service accounts are
    managed by Kubernetes, and you can add or delete them using Kubernetes API calls.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群用户需要成功认证才能访问集群对象。然而，普通的集群用户，如开发人员和管理员，不应由 Kubernetes 管理，而应由集群外部的外部服务进行管理，如
    **轻量级目录访问协议** (**LDAP**)、**OpenID Connect** (**OIDC**)、AWS **身份与访问管理** (**IAM**)，甚至是一个包含用户和密码对的文件。另一方面，服务账户由
    Kubernetes 管理，您可以使用 Kubernetes API 调用来添加或删除它们。
- en: As a cluster owner, you need to decide how you will manage the cluster's normal
    users, in other words, which external service to use. To authenticate users in
    the case of production clusters, we recommend using AWS IAM as the authentication
    service. However, it is also possible to use an OIDC identity provider, such as
    Azure Active Directory, or GitHub.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 作为集群所有者，您需要决定如何管理集群的普通用户，换句话说，选择使用哪个外部服务进行认证。对于生产集群的用户认证，我们建议使用 AWS IAM 作为认证服务。但也可以使用
    OIDC 身份提供者，如 Azure Active Directory 或 GitHub。
- en: It's worth mentioning that Kubernetes has different authentication modules for
    different means of authentication, such as client TLS certificates, passwords,
    and tokens. And the cluster administrator can configure some or all of them during
    cluster provisioning.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，Kubernetes 针对不同的认证方式（如客户端 TLS 证书、密码和令牌）有不同的认证模块。集群管理员可以在集群配置过程中配置其中的一部分或全部。
- en: Authenticating users with AWS IAM
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 AWS IAM 进行用户认证
- en: EKS supports the webhook token authentication and service account tokens. The
    webhook authentication verifies the bearer tokens. These bearer tokens are generated
    by the `aws-iam-authenticator` client when you execute `kubectl` commands. Then,
    the token is passed to `kube-apiserver` before being forwarded to the authentication
    webhook, which returns the user's account and ARN to `kube-apiserver`.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: EKS 支持 webhook 令牌认证和服务账户令牌。Webhook 认证验证承载令牌。这些承载令牌由 `aws-iam-authenticator`
    客户端在执行 `kubectl` 命令时生成。然后，令牌会传递到 `kube-apiserver`，在转发到认证 webhook 之前，认证 webhook
    返回用户的账户和 ARN 给 `kube-apiserver`。
- en: Once the user's identity has been authenticated by the AWS IAM service, `kube-apiserver`
    reads the `aws-auth` ConfigMap in the `kube-system` namespace to determine the
    `aws-auth` ConfigMap is used to create a mapping between the IAM users and roles,
    and Kubernetes RBAC groups for authorization purposes. These RBAC groups can be
    referenced in Kubernetes ClusterRoleBindings or RoleBindings.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦用户的身份通过 AWS IAM 服务认证，`kube-apiserver` 会读取 `kube-system` 命名空间中的 `aws-auth`
    ConfigMap，以确定 `aws-auth` ConfigMap 用于在 IAM 用户、角色和 Kubernetes RBAC 组之间创建映射，以便进行授权。这些
    RBAC 组可以在 Kubernetes ClusterRoleBindings 或 RoleBindings 中引用。
- en: 'We already learned how to create a custom `aws-auth` ConfigMap in [*Chapter
    4*](B16192_04_Final_PG_ePub.xhtml#_idTextAnchor100), *Managing Cluster Configuration
    with Ansible*, where we can add IAM users and IAM roles that users can assume
    to access the cluster. Please check the `aws-auth` ConfigMap''s full configuration
    code here: [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/auth/aws-auth.yaml](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/auth/aws-auth.yaml).'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经在[*第 4 章*](B16192_04_Final_PG_ePub.xhtml#_idTextAnchor100)《使用 Ansible 管理集群配置》中了解了如何创建自定义的
    `aws-auth` ConfigMap，在该章节中，我们可以添加用户可以承担的 IAM 用户和 IAM 角色，以访问集群。请在此查看 `aws-auth`
    ConfigMap 的完整配置代码：[https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/auth/aws-auth.yaml](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/auth/aws-auth.yaml)。
- en: We recommend using IAM roles to manage production cluster access, and you can
    assign these IAM roles to IAM groups and users, which makes Kubernetes authentication
    easier to operate and scale.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议使用 IAM 角色来管理生产集群的访问权限，您可以将这些 IAM 角色分配给 IAM 组和用户，这使得 Kubernetes 认证更易于操作和扩展。
- en: Modifying the EKS cluster creator
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 修改 EKS 集群创建者
- en: 'It is worth noting that EKS gives the IAM user or whatever IAM role that creates
    the cluster a permanent administrator authentication on the cluster''s Kubernetes
    API service. AWS does not provide any way to change this or to move it to a different
    IAM user or role. To minimize the security drawbacks of this limitation, we suggest
    doing the following:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，EKS 会授予创建集群的 IAM 用户或 IAM 角色对集群 Kubernetes API 服务的永久管理员认证。AWS 并未提供任何方式来更改此设置或将其转移到不同的
    IAM 用户或角色。为了尽量减少这一限制的安全隐患，我们建议采取以下措施：
- en: Use a dedicated but temporary IAM role to provision each new cluster.
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用专门的临时 IAM 角色来配置每个新的集群。
- en: After provisioning the cluster, remove all IAM permissions from this role.
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置完集群后，删除此角色的所有 IAM 权限。
- en: Update the `aws-auth` ConfigMap in the `kube-system` namespace and add more
    IAM users and roles to be able to manage and use the cluster.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新 `kube-system` 命名空间中的 `aws-auth` ConfigMap，添加更多的 IAM 用户和角色，以便能够管理和使用集群。
- en: Add these groups as subjects of `RoleBindings` and `ClusterRoleBindings` in
    the cluster RBAC as needed.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 根据需要将这些组作为`RoleBindings`和`ClusterRoleBindings`的主体，添加到集群的RBAC中。
- en: You already learned in [*Chapter 4*](B16192_04_Final_PG_ePub.xhtml#_idTextAnchor100),
    *Managing Cluster Configuration with Ansible*, how to handle this drawback in
    the Ansible cluster configuration as we created a custom `aws-auth` ConfigMap
    and `ClusterRoleBindings`.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经在[*第4章*](B16192_04_Final_PG_ePub.xhtml#_idTextAnchor100)，*使用Ansible管理集群配置*中学到了如何在Ansible集群配置中处理这一缺陷，我们创建了自定义的`aws-auth`
    ConfigMap和`ClusterRoleBindings`。
- en: Cluster authorization
  id: totrans-62
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 集群授权
- en: The second stage of cluster access is authorization. This determines whether
    the operation requested is allowed. In order for Kubernetes to authorize a request,
    it considers three inputs; first, the user who initiated the request, then the
    requested action, and finally the Kubernetes resource to be modified by the action,
    such as pods and services.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 集群访问的第二个阶段是授权。这决定了请求的操作是否被允许。为了使Kubernetes授权请求，它考虑三个输入；首先是发起请求的用户，然后是请求的操作，最后是操作将修改的Kubernetes资源，如pods和服务。
- en: When you create a cluster, you configure the authorization mode by passing its
    value to the API server. However, in EKS, all of the authorization modes (RBAC,
    attribute-based access control, and webhooks) are enabled by default, and Kubernetes
    will check each of them to authorize the requests.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建集群时，你通过将其值传递给API服务器来配置授权模式。然而，在EKS中，所有授权模式（RBAC、基于属性的访问控制和Webhooks）默认启用，Kubernetes将检查它们以授权请求。
- en: Admission controller
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审批控制器
- en: The final stage of cluster access is passing through the admission controller.
    In this step, requests are validated based on the rules defined in the admission
    controller and the requested object. There is also another type of admission controller,
    called a mutating controller, which can modify the request, such as injecting
    side car containers or modifying pod specs before sending the request to `kube-api-server`.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 集群访问的最终阶段是通过审批控制器。在此步骤中，请求根据审批控制器定义的规则和请求的对象进行验证。还有另一种类型的审批控制器，称为变更控制器（mutating
    controller），它可以修改请求，例如注入side car容器或在将请求发送到`kube-api-server`之前修改pod规格。
- en: An admission controller is a powerful authorization mechanism, and it can be
    extended by cluster users or third parties to enforce special validations and
    rules on cluster users.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 审批控制器是一种强大的授权机制，可以通过集群用户或第三方进行扩展，以在集群用户上执行特殊的验证和规则。
- en: Managing secrets and certificates
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 管理机密和证书
- en: Secrets and TLS certificates are essential security needs for modern applications,
    and while Kubernetes provides a native solution to create and consume secrets
    and sensitive data, it remains in need of additional hardening. On the other hand,
    Kubernetes has no native answer to certificate issuing and management, which is
    why we will deploy one of the popular add-ons and use it for this purpose.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 机密和TLS证书是现代应用程序的基本安全需求，虽然Kubernetes提供了原生解决方案来创建和使用机密及敏感数据，但仍需要进一步的加固。另一方面，Kubernetes没有原生的证书颁发和管理解决方案，这就是我们将部署其中一个流行的附加组件并使用它来实现这一目的的原因。
- en: Creating and managing secrets
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建和管理机密
- en: Kubernetes has a secret resource type that can be used to store sensitive data,
    such as passwords, tokens, certificates, and SSH keys. Pods can consume these
    secrets by mounting them as volumes or environment variables. However, we do not
    recommend environment variables because they can leak out and get compromised.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes具有一种机密资源类型，可以用来存储敏感数据，例如密码、令牌、证书和SSH密钥。Pods可以通过将它们挂载为卷或环境变量来使用这些机密。然而，我们不推荐使用环境变量，因为它们可能泄露并被篡改。
- en: Another challenge here arises when users decide to store the secrets that YAML
    manifests in Git repositories. In such a case, the sensitive data can be easily
    compromised because secrets do not use encryption, but Base64 encoding, which
    can simply be decoded.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 这里的另一个挑战出现在用户决定将包含机密的YAML清单存储在Git仓库时。在这种情况下，敏感数据容易受到泄露，因为机密没有使用加密，而是采用Base64编码，而Base64编码可以轻松解码。
- en: Sealed Secrets solves this problem by providing a mechanism to encrypt the secret
    sensitive data and make it safe to store in Git repositories.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 封装机密通过提供一种加密机密敏感数据的机制来解决此问题，使其可以安全地存储在Git仓库中。
- en: 'Sealed Secrets consists of two parts:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 封装机密由两部分组成：
- en: A command-line tool, `kubeseal`, to transform **Custom Resource Definition**
    (**CRD**) secrets into sealed secrets.
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一种命令行工具，`kubeseal`，用于将**自定义资源定义**（**CRD**）的机密转换为封装的机密。
- en: A Sealed Secrets controller that is used to generate the encryption key, and
    decrypt sealed secrets into secrets to be used by the pods.
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Sealed Secrets 控制器用于生成加密密钥，并将密封的秘密解密为供 pods 使用的秘密。
- en: 'To learn more about Sealed Secrets and the `kubeseal` client, please review
    these here: [https://github.com/bitnami-labs/sealed-secrets](https://github.com/bitnami-labs/sealed-secrets).'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解有关 Sealed Secrets 和 `kubeseal` 客户端的更多信息，请查看以下链接：[https://github.com/bitnami-labs/sealed-secrets](https://github.com/bitnami-labs/sealed-secrets)。
- en: This is how it works. `kubeseal` communicates with the Sealed Secrets controller
    to retrieve the encryption public key, and then it uses this key to encrypt the
    secret CRD into a sealed secret CRD. And when a pod requires use of the sealed
    secret, the controller uses the encryption private key to decrypt the sealed secret
    CRD and convert it to a regular secret CRD.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 它是这样工作的。`kubeseal` 与 Sealed Secrets 控制器通信，获取加密公钥，然后使用该公钥将秘密 CRD 加密成密封的秘密 CRD。当
    pod 需要使用密封的秘密时，控制器会使用加密私钥解密密封的秘密 CRD，并将其转换为常规的秘密 CRD。
- en: 'It is worthwhile mentioning that Sealed Secrets mitigates the security risks
    associated with secrets in a multi-tenant cluster by introducing the concept of
    scopes to limit secret use and manipulation within a namespace, or cluster-wide,
    and with the possibility to restrict or change the secret name and namespace.
    The details of the reasoning behind this can be found here in the official documentation:
    [https://github.com/bitnami-labs/sealed-secrets#scopes](https://github.com/bitnami-labs/sealed-secrets#scopes).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 值得一提的是，Sealed Secrets 通过引入作用域的概念，在多租户集群中缓解了与秘密相关的安全风险。它限制了在命名空间内或集群范围内的秘密使用和操作，并且可以限制或更改秘密的名称和命名空间。有关这一点的详细原因，可以在官方文档中找到：[https://github.com/bitnami-labs/sealed-secrets#scopes](https://github.com/bitnami-labs/sealed-secrets#scopes)。
- en: 'Now, let''s create the Ansible template and configuration to deploy the Sealed
    Secrets controller to the cluster:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建 Ansible 模板和配置，将 Sealed Secrets 控制器部署到集群中：
- en: 'Define the required configuration variables and add them to the `group_vars`
    directory in this path – `ansible/group_vars/all/sealed-secrets.yaml`. The basic
    configuration contains the number of deployment replicas and the image tag, which
    is useful for keeping track of the deployed version and controlling its upgrades:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义所需的配置变量，并将其添加到 `group_vars` 目录中的此路径 —— `ansible/group_vars/all/sealed-secrets.yaml`。基本配置包括部署副本数量和镜像标签，有助于跟踪已部署的版本并控制其升级：
- en: '[PRE1]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Important note
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 重要提示
- en: You can find the complete source code of the Sealed Secrets deployment template
    at [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets).
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 你可以在此链接找到 Sealed Secrets 部署模板的完整源代码：[https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets)。
- en: Create the deployment template for the Sealed Secrets controller in this path
    – `ansible/templates/sealed-secrets/sealed-secrets.yaml`. In this controller,
    we will only set variables for the deployment replicas and image tags. You can
    check the complete manifest YAML file at [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets/sealed-secrets.yaml](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets/sealed-secrets.yaml).
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下路径创建 Sealed Secrets 控制器的部署模板 —— `ansible/templates/sealed-secrets/sealed-secrets.yaml`。在该控制器中，我们将仅设置部署副本和镜像标签的变量。你可以在此链接查看完整的清单
    YAML 文件：[https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets/sealed-secrets.yaml](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets/sealed-secrets.yaml)。
- en: 'Install the `kubeseal` CLI for macOS as follows:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式为 macOS 安装 `kubeseal` CLI：
- en: '[PRE2]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Install it for Linux using the following command:'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用以下命令为 Linux 安装：
- en: '[PRE3]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To deploy the Sealed Secrets controller, please apply the deployment steps covered
    at the end of this chapter under the *Deploying the security configurations* section.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署 Sealed Secrets 控制器，请按照本章最后“*部署安全配置*”部分的部署步骤进行操作。
- en: Managing TLS certificates with Cert-Manager
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Cert-Manager 管理 TLS 证书
- en: 'Cert-Manager is a Kubernetes add-on and controller that allows certificates
    to be issued from different sources, such as SelfSigned, CA, Vault, and ACME/Let''s
    Encrypt, and external issuers, such as AWS Private Certificate Authority and AWS
    Key Management Service. It also ensures the validity of certificates and auto-renews
    and rotates them. You can learn more about the project here: [https://cert-manager.io/docs/](https://cert-manager.io/docs/).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Cert-Manager是一个Kubernetes插件和控制器，允许从不同来源颁发证书，例如SelfSigned、CA、Vault和ACME/Let's
    Encrypt，以及外部颁发者，如AWS私有证书颁发机构和AWS密钥管理服务。它还确保证书的有效性，并自动续期和轮换证书。你可以在这里了解更多关于该项目的信息：[https://cert-manager.io/docs/](https://cert-manager.io/docs/)。
- en: Cert-Manager will make TLS certificates available out of the box for Kubernetes
    workloads, and it will make issuing and managing these certificates a native feature
    within the Kubernetes cluster, which is easy to manage and operate.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: Cert-Manager将为Kubernetes工作负载提供现成的TLS证书，它使得在Kubernetes集群内发放和管理这些证书成为一个本地特性，易于管理和操作。
- en: Cert-Manager does not come pre-installed with the cluster, so you need to deploy
    it and specify its configuration, which includes its Docker image, the number
    of replicas to run, certificate issuers, DNS Route 53 zones, and so on.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Cert-Manager并不会预装在集群中，所以你需要自行部署它并指定其配置，包括其Docker镜像、要运行的副本数、证书颁发机构、DNS Route
    53区域等。
- en: 'To deploy Cert-Manager, we will create three Kubernetes manifest files: namespace,
    controller, and certificate issuers.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 为了部署Cert-Manager，我们将创建三个Kubernetes清单文件：命名空间、控制器和证书颁发者。
- en: 'There are various issuers supported by Cert-Manager. Please check here: [https://cert-manager.io/docs/configuration/](https://cert-manager.io/docs/configuration/).
    In this chapter, we decided to use Let''s Encrypt as it is free and commonly used,
    but you can use Cert-Manager documentation and the same deployment here with any
    of the other issuers.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Cert-Manager支持多种证书颁发者。请在这里查看：[https://cert-manager.io/docs/configuration/](https://cert-manager.io/docs/configuration/)。在本章中，我们决定使用Let's
    Encrypt，因为它是免费的并且被广泛使用，但你可以使用Cert-Manager文档，并使用相同的部署来支持其他任何颁发者。
- en: 'Now, let''s create the Ansible template and the configuration for it:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建Ansible模板并为其配置：
- en: Important note
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: You can find the complete source code of the Cert-Manager deployment template
    at [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/cert-manager](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/cert-manager).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到Cert-Manager部署模板的完整源代码：[https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/cert-manager](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/cert-manager)。
- en: 'Define the required configuration variables and add them to the `group_vars`
    directory in this path – `ansible/group_vars/all/cert-manager.yaml`. The basic
    configuration contains the number of deployment replicas and the image tags for
    controller, webhook, and `cainjector`, which is useful for keeping track of the
    version deployed and for controlling its upgrades. Also, there is the configuration
    of Let''s Encrypt issuers for both `prod` and `nonprod` ACME URLs:'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义所需的配置变量并将其添加到这个路径下的`group_vars`目录中 – `ansible/group_vars/all/cert-manager.yaml`。基本配置包含部署副本数和控制器、webhook以及`cainjector`的镜像标签，这对于跟踪已部署的版本和控制升级非常有用。此外，还包含了`prod`和`nonprod`
    ACME URL的Let's Encrypt颁发者配置：
- en: '[PRE4]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Create the namespace for Cert-Manager in this path – `ansible/templates/cert-manager/namespace.yaml`:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个路径下创建Cert-Manager的命名空间 – `ansible/templates/cert-manager/namespace.yaml`：
- en: '[PRE5]'
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Create the deployment template for the Cert-Manager controller resources in
    this path – `ansible/templates/cert-manager/cert-manager.yaml`. In this controller,
    we will only set variables for the deployment replicas and image tags. You can
    check the complete manifest YAML file here: [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/cert-manager/cert-manager.yaml](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/cert-manager/cert-manager.yaml).'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个路径下创建Cert-Manager控制器资源的部署模板 – `ansible/templates/cert-manager/cert-manager.yaml`。在这个控制器中，我们将只设置部署副本数和镜像标签的变量。你可以在这里查看完整的清单YAML文件：[https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/cert-manager/cert-manager.yaml](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/cert-manager/cert-manager.yaml)。
- en: 'Create the issuer configuration for Let''s Encrypt in this path – `ansible/templates/cert-manager/letsencrypt-clusterissuer.yaml`.
    In this file, there are two configurations, the first for the certificates used
    for production workloads, and the other for non-production workloads. The main
    difference is that Let''s Encrypt will allow you to issue as many certificates
    as you want for non-production, but only limited numbers per week for production
    ones:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在路径`ansible/templates/cert-manager/letsencrypt-clusterissuer.yaml`中创建Let's Encrypt的发行者配置。在此文件中，有两个配置，第一个是用于生产工作负载的证书，另一个是用于非生产工作负载的证书。主要的区别在于，Let's
    Encrypt会允许你为非生产环境发行任意数量的证书，但对于生产环境的证书，每周的数量是有限的：
- en: '[PRE6]'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The second part of the previous issuer configuration is very similar to the
    production issuer, but with a different Let's Encrypt server.
  id: totrans-107
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 上述发行者配置的第二部分与生产发行者非常相似，但使用了不同的Let's Encrypt服务器。
- en: To deploy the Cert-Manager add-on, please apply the deployment steps at the
    end of this chapter under the *Deploying the security configurations* section.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署Cert-Manager插件，请在本章末尾的*部署安全配置*部分中应用部署步骤。
- en: 'Here is an example of how to use Cert-Manager and Let''s Encrypt and associate
    it with an ingress controller and a domain:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是如何使用Cert-Manager和Let's Encrypt并将其与Ingress控制器和域名关联的示例：
- en: '[PRE7]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The previous `Ingress` resource uses the Cert-Manager annotation to connect
    to the Let's Encrypt TLS production certificate issuer, and it defines a host
    with a sample DNS `example.com` and `secretName` as `example-cert`, where Cert-Manager
    will store the TLS certificates retrieved from Let's Encrypt, and to be used by
    this `Ingress` resource. You can use the same `Ingress` resource, but with a domain
    name that you own.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的`Ingress`资源使用Cert-Manager注解来连接到Let's Encrypt TLS生产证书发行者，并定义了一个主机，使用样本DNS
    `example.com`和`secretName`为`example-cert`，Cert-Manager将在此存储从Let's Encrypt获取的TLS证书，并供该`Ingress`资源使用。你也可以使用相同的`Ingress`资源，但搭配一个你拥有的域名。
- en: To get an idea of how to use Cert-Manager in other use cases, please check the
    official documentation at [https://cert-manager.io/docs/usage/](https://cert-manager.io/docs/usage/).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解如何在其他使用场景中使用Cert-Manager，请查看官方文档：[https://cert-manager.io/docs/usage/](https://cert-manager.io/docs/usage/)。
- en: Securing workloads and apps
  id: totrans-113
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确保工作负载和应用程序的安全
- en: Kubernetes provides different built-in and third-party solutions to ensure that
    your production workloads are running securely. We will explore what we regard
    as a must-have for your cluster before going to production, such as workload isolation
    techniques, pod security policies, network policies, and monitoring workload runtime
    security.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes提供了不同的内置和第三方解决方案，以确保你的生产工作负载安全运行。在进入生产前，我们将探讨我们认为对你的集群至关重要的配置，如工作负载隔离技术、Pod安全策略、网络策略和监控工作负载运行时安全。
- en: Isolating critical workloads
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 隔离关键工作负载
- en: Kubernetes, by design, has a single control plane for each cluster, which makes
    sharing a single cluster among tenants and workloads challenging, and requires
    the cluster owners to have a clear strategy about cluster multi-tenancy and resource
    sharing.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes设计上每个集群只有一个控制平面，这使得在多个租户和工作负载之间共享单一集群变得具有挑战性，并且要求集群所有者拥有清晰的集群多租户和资源共享策略。
- en: 'There are different use cases where it is critical to address tenant and workload
    isolation:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在需要处理租户和工作负载隔离的不同使用场景中，这一点至关重要：
- en: In many organizations, there are multiple teams, products, or environments that
    share a cluster.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在许多组织中，有多个团队、产品或环境共享一个集群。
- en: There are cases where you provide Kubernetes as a service for your own organization
    or external organizations.
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有些情况是你将Kubernetes作为服务提供给你自己或外部组织。
- en: Also, there is a common case when your Kubernetes infrastructure serves a **Software
    as a Service** (**SaaS**) product.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，常见的一种情况是，当你的Kubernetes基础设施用于提供**软件即服务**（**SaaS**）产品时。
- en: For the preceding use cases, we need to ensure that the cluster has the required
    configuration for workload isolation, where we can approach soft multi-tenancy
    using various Kubernetes objects, such as namespaces, RBAC, quotas, and limit
    ranges. This is what you will learn in this section and across this chapter.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 对于前述的使用场景，我们需要确保集群具备所需的工作负载隔离配置，通过使用各种Kubernetes对象，如命名空间、RBAC、配额和限制范围来实现软多租户。这也是你在本节及本章中将要学习的内容。
- en: Now, we need to explore the different techniques for implementing tenants' isolation,
    while decreasing the risks associated with Kubernetes' single-tenancy design.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要探讨实现租户隔离的不同技术，同时减少与 Kubernetes 单租户设计相关的风险。
- en: Using namespaces
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用命名空间
- en: Namespaces are the first layer of isolation that Kubernetes provides. They provide
    a soft-tenancy mechanism to create boundaries for Kubernetes resources. A lot
    of Kubernetes security controls, such as network policies, access control, secrets,
    certificates, and other important security controls can be scoped on the namespace
    level. By separating tenant workloads into their own namespaces, you will be able
    to limit the impact of security attacks, as well as intentional and non-intentional
    mistakes by cluster users.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 命名空间是 Kubernetes 提供的第一层隔离机制。它们为 Kubernetes 资源创建边界，提供了软多租户机制。许多 Kubernetes 安全控制，例如网络策略、访问控制、密钥、证书以及其他重要的安全控制，都可以在命名空间级别进行作用域限制。通过将租户工作负载分配到各自的命名空间，您将能够限制安全攻击的影响，以及集群用户的有意或无意的错误。
- en: Creating separate node groups
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建独立的节点组
- en: We usually avoid privileged containers, but in some cases, such as system pods
    or product-specific technical requirements, they are unavoidable. To reduce the
    impact of a security break, we isolate these pods on dedicated nodes and node
    groups where other tenants' workloads cannot get scheduled. The same can be applied
    to the pods with sensitive data. This approach decreases the risk of sensitive
    data being accessed by a less-secure application that shares the worker node.
    However, it does come with a drawback as it could increase the infrastructure
    cost, and when you take this design decision, you should weigh security versus
    cost.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通常避免使用特权容器，但在某些情况下，例如系统 pod 或产品特定的技术要求，这些容器是不可避免的。为了减少安全漏洞的影响，我们将这些 pod 隔离在专用节点和节点组上，这样其他租户的工作负载就无法在这些节点上调度。对于包含敏感数据的
    pod 也可以采取相同的做法。该方法可以减少敏感数据被共享工作节点上不太安全的应用程序访问的风险。然而，它也带来了一定的缺点，例如可能会增加基础设施成本，在做出这一设计决策时，您需要权衡安全性与成本之间的关系。
- en: Implementing hard multi-tenancy
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实施严格的多租户架构
- en: In specific use cases, hard multi-tenancy is a must, which is usually due to
    laws and regulatory requirements. In this situation, multi-tenancy can be achieved
    by provisioning separate clusters for each tenant, and this is what we call hard
    multi-tenancy. On the flip side, however, there are drawbacks, such as the challenges
    associated with managing these clusters when they grow in number, the increased
    total cost, and also the decreased compute utilization per cluster.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在特定的使用场景下，严格的多租户架构是必须的，这通常是由于法律和监管要求。在这种情况下，可以通过为每个租户提供独立的集群来实现多租户架构，这就是我们所说的严格多租户架构。然而，这种方式也有其缺点，例如随着集群数量的增加，管理这些集群的挑战、整体成本的增加以及每个集群的计算资源利用率下降。
- en: Hardening the default pod security policy
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 强化默认的 pod 安全策略
- en: '**Pod security policy** (**PSP**) is a Kubernetes resource that is used to
    ensure that a pod has to meet specific requirements before getting created.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '**Pod 安全策略** (**PSP**) 是一种 Kubernetes 资源，用于确保 pod 在创建之前必须满足特定的要求。'
- en: PSPs have different security settings that you can configure either by increasing
    or decreasing pod privileges, aspects such as Linux capabilities allowed to the
    containers, host network access, and filesystem access.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: PSPs 有不同的安全设置，您可以通过增加或减少 pod 权限来进行配置，包括允许容器的 Linux 能力、主机网络访问以及文件系统访问等方面。
- en: It is still worthwhile mentioning that PSP is still in beta, and it would be
    unwelcome to deploy a beta feature for companies with strict production policies.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 仍然值得一提的是，PSP 仍处于测试版阶段，对于拥有严格生产政策的公司来说，部署测试版特性并不受欢迎。
- en: 'You can define multiple PSPs in your cluster and assign them to different types
    of pods and namespaces to ensure that every workload and tenant has the correct
    access rights. EKS clusters come with a default PSP called `eks.privileged`, which
    is automatically created when you provision the cluster. You can view the specs
    of the `eks.privileged` PSP by describing it as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在集群中定义多个 PSP，并将它们分配给不同类型的 pod 和命名空间，以确保每个工作负载和租户都具有正确的访问权限。EKS 集群自带一个默认的
    PSP，名为 `eks.privileged`，它会在您创建集群时自动生成。您可以通过描述该 PSP 来查看 `eks.privileged` PSP 的规格：
- en: '[PRE8]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This default `eks.privileged` PSP allows any authenticated user to run privileged
    containers across all namespaces. This behavior is intended to allow system pods
    such as the AWS VPC CNI and `kube-proxy` to run as privileged because they are
    responsible for configuring the host's network settings. However, you have to
    limit this behavior for other types of pods and namespaces.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 这个默认的 `eks.privileged` PSP 允许任何经过身份验证的用户在所有命名空间中运行特权容器。此行为旨在允许像 AWS VPC CNI
    和 `kube-proxy` 这样的系统 Pod 以特权模式运行，因为它们负责配置主机的网络设置。然而，你必须限制其他类型的 Pod 和命名空间的此类行为。
- en: 'As a best practice, we recommend that you limit privileged pods to service
    accounts within the `kube-system` namespace or any other namespace that you use
    to isolate system pods. For all other namespaces that host other types of pods,
    we recommend assigning a restrictive default PSP. The following manifest defines
    a PSP to restrict privileged pods, and accessing the host network. We will add
    this manifest to our Ansible template''s automation at the following path: `ansible/templates/psp/default-psp.yaml`:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 作为最佳实践，我们建议将特权 Pod 限制为 `kube-system` 命名空间中的服务账户，或任何你用来隔离系统 Pod 的其他命名空间。对于所有托管其他类型
    Pod 的命名空间，我们建议分配一个限制性的默认 PSP。以下清单定义了一个 PSP，用于限制特权 Pod，并禁止访问主机网络。我们将把这个清单添加到我们的
    Ansible 模板的自动化路径中：`ansible/templates/psp/default-psp.yaml`：
- en: '[PRE9]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following code snippet defines specs of the default PSP. It will not allow
    privileged containers, disables container privilege escalation, and drops all
    Linux capabilities:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段定义了默认 PSP 的规范。它不允许特权容器，禁用容器特权提升，并删除所有 Linux 能力：
- en: '[PRE10]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You can check the complete source code of the previous PSP resource here: [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/psp](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/psp).'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里查看之前 PSP 资源的完整源代码：[https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/psp](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/psp)。
- en: 'The following `ClusterRole` definition allows all roles that are bound to it
    to use the previous `default-psp` PSP:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `ClusterRole` 定义允许所有绑定到它的角色使用之前的 `default-psp` PSP：
- en: '[PRE11]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following `ClusterRoleBinding` definition binds the `default-psp-user`
    `ClusterRole` to the `system:authenticated` RBAC group of users, which means that
    any user who is added to the cluster RBAC group, `system:authenticated`, has to
    create pods that comply with the `default-psp` PSP:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `ClusterRoleBinding` 定义将 `default-psp-user` `ClusterRole` 绑定到 `system:authenticated`
    RBAC 用户组，这意味着任何被添加到集群 RBAC 用户组 `system:authenticated` 的用户，都必须创建符合 `default-psp`
    PSP 的 Pod：
- en: '[PRE12]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: You can create additional pod security policies according to your security requirements,
    but basically, your cluster needs to have two pod security policies; the first
    is `eks.privileged` for the pods in the `kube-system` namespace, and the second
    is `default-psp` for any other namespaces.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以根据安全要求创建额外的 Pod 安全策略，但基本上，你的集群需要有两种 Pod 安全策略；第一种是 `eks.privileged`，用于 `kube-system`
    命名空间中的 Pod，第二种是 `default-psp`，用于任何其他命名空间。
- en: Limiting pod access
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 限制 Pod 访问
- en: Usually, pods require access to the underlying cloud services, such as object
    stores, databases, and the DNS. Ideally, you do not want the production pods to
    access all services, or to access a service that they are not intended to use.
    This is why we need to limit pod access to just the services they use.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，Pod 需要访问底层的云服务，例如对象存储、数据库和 DNS。理想情况下，你不希望生产环境中的 Pod 访问所有服务，或访问它们不应该使用的服务。这就是为什么我们需要将
    Pod 访问限制为它们所用的服务。
- en: 'In the AWS world, this can be achieved by utilizing the IAM roles and attaching
    this role and an access policy to the pod. `kube2iam` is one of Kubernetes'' add-ons
    that can do this job efficiently. It is an open source project that is battle-tested
    in production. It is easy to deploy, configure, and use. You can learn more about
    it here: [https://github.com/jtblin/kube2iam](https://github.com/jtblin/kube2iam).'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AWS 环境中，可以通过利用 IAM 角色并将此角色及访问策略附加到 Pod 来实现这一点。`kube2iam` 是 Kubernetes 的一个附加组件，可以高效地完成这项工作。它是一个经过实际生产环境考验的开源项目，易于部署、配置和使用。你可以在这里了解更多信息：[https://github.com/jtblin/kube2iam](https://github.com/jtblin/kube2iam)。
- en: '`kube2iam` does not come pre-installed with the cluster, so you need to deploy
    it and specify its configuration, which includes its Docker image, iptables control,
    and the host network interface.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube2iam`并未预安装在集群中，因此你需要部署它并指定其配置，包括其Docker镜像、iptables控制和主机网络接口。'
- en: 'Now, let''s create the Ansible template and configuration for them:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们为它们创建Ansible模板和配置：
- en: Important note
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: You can find the complete source code at [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/kube2iam](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/kube2iam).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在[https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/kube2iam](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/kube2iam)找到完整的源代码。
- en: 'Define the required configuration variables and add them to the `group_vars`
    directory in this path – `ansible/group_vars/all/kube2iam.yaml`. The basic configuration
    contains the image tag for the `kube2iam` DaemonSet, which is useful for keeping
    track of the deployed version and for controlling its upgrades:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 定义所需的配置变量并将其添加到此路径中的`group_vars`目录——`ansible/group_vars/all/kube2iam.yaml`。基本配置包含`kube2iam`
    DaemonSet的镜像标签，这对于跟踪已部署版本和控制其升级非常有用：
- en: '[PRE13]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create the deployment template for the Cert-Manager controller resources in
    this path – `ansible/templates/cert-manager/cert-manager.yaml`. In this controller,
    we will only set variables for the deployment replicas and image tags:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此路径中创建Cert-Manager控制器资源的部署模板——`ansible/templates/cert-manager/cert-manager.yaml`。在该控制器中，我们将仅设置部署副本数和镜像标签的变量：
- en: '[PRE14]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following code snippet is the specification of the `kube2iam` DaemonSet.
    The most important part of the spec is the container runtime arguments'' section:'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下代码片段是`kube2iam` DaemonSet的规范。规格中最重要的部分是容器运行时参数的部分：
- en: '[PRE15]'
  id: totrans-158
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The most notable configuration parameter in the previous YAML file is `"--iptables=true"`,
    which allows `kube2iam` to add iptables rules to block the pods from accessing
    the underlying worker node instance profile.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 之前YAML文件中最显著的配置参数是`"--iptables=true"`，它允许`kube2iam`添加iptables规则，以阻止Pods访问底层工作节点的实例配置文件。
- en: To deploy `kube2iam`, please apply the deployment steps at the end of this chapter
    under the *Deploying the cluster's security configuration* section.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署`kube2iam`，请按照本章最后部分*部署集群安全配置*中的步骤进行操作。
- en: 'To use `kube2iam` with a pod, you have to add the `iam.amazonaws.com/role annotation`
    to the pod annotations section, and add the IAM role to be used by the pod. Here
    is an example to illustrate how to use `kube2iam` with your pods:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 要在Pod中使用`kube2iam`，你必须将`iam.amazonaws.com/role annotation`添加到Pod注释部分，并添加Pod要使用的IAM角色。以下是一个示例，说明如何在Pods中使用`kube2iam`：
- en: '[PRE16]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: The preceding pod will run an `aws-cli` container that executes the S3 list
    command for a bucket. Please make sure to replace the placeholders with a valid
    IAM role ARN to the annotation section, and a valid S3 bucket name in the container
    command section.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 上述Pod将运行一个`aws-cli`容器，该容器执行S3列表命令以获取某个桶的内容。请确保在注释部分用有效的IAM角色ARN替换占位符，并在容器命令部分用有效的S3桶名称替换。
- en: Creating network policies with Calico
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Calico创建网络策略
- en: Communication between all pods within the cluster is allowed by default. This
    behavior is unsecure, especially in multi-tenant clusters. Earlier, you learned
    about the cluster network infrastructure and how to use security groups to control
    the network traffic among a cluster's nodes. However, security groups are not
    effective when it comes to controlling the traffic between pods. This is why Kubernetes
    provides the **Network Policy API**. These network policies allow the cluster's
    users to enforce ingress and egress rules to allow or deny network traffic among
    the pods.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 集群内所有Pod之间的通信默认是允许的。这种行为是不安全的，尤其是在多租户集群中。之前，你已经学习了集群网络基础设施，以及如何使用安全组控制集群节点之间的网络流量。然而，安全组在控制Pod之间的流量时并不起作用。这就是Kubernetes提供**网络策略API**的原因。这些网络策略允许集群的用户强制执行入口和出口规则，以允许或拒绝Pod之间的网络流量。
- en: Kubernetes defines the Network Policy API specification, but it does not provide
    a built-in capability to enforce these network policies. So, to enforce them,
    you have to use a network plugin, such as Calico network policy.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes定义了网络策略API规范，但并未提供内建的能力来强制执行这些网络策略。因此，要强制执行它们，你必须使用网络插件，如Calico网络策略。
- en: 'You can check your cluster to see whether there are any network policies in
    effect by using the following `kubectl` command:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用以下 `kubectl` 命令检查集群中是否有生效的网络策略：
- en: '[PRE17]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Calico is a network policy engine that can be deployed to Kubernetes, and it
    works smoothly with EKS as well. Calico implements all of Kubernetes' network
    policy features, but it also supports an additional richer set of features, including
    policy ordering, priority, deny rules, and flexible match rules. Calico network
    policy can be applied to different types of endpoints, including pods, VMs, and
    host interfaces. Unlike Kubernetes' network policies, Calico policies can be applied
    to namespaces, pods, service accounts, or globally across the cluster.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Calico 是一个可以部署到 Kubernetes 的网络策略引擎，它与 EKS 也能顺利配合使用。Calico 实现了 Kubernetes 的所有网络策略功能，但还支持一组额外的、更丰富的功能，包括策略顺序、优先级、拒绝规则和灵活的匹配规则。Calico
    网络策略可以应用于不同类型的端点，包括 Pod、虚拟机和主机接口。与 Kubernetes 的网络策略不同，Calico 策略可以应用于命名空间、Pod、服务账户，或在集群范围内全局应用。
- en: Creating a default deny policy
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建默认拒绝策略
- en: As a security best practice, network policies should allow least privileged
    access. You start by creating a deny all policy that globally restricts all inbound
    and outbound traffic using Calico.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 作为安全最佳实践，网络策略应允许最小特权访问。你可以通过创建一个拒绝所有流量的策略，使用 Calico 全球限制所有入站和出站流量。
- en: 'The following Calico global network policy implements a default, deny-all ingress
    and egress policy across the cluster:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 Calico 全局网络策略实现了在集群中默认的拒绝所有入口和出口流量的策略：
- en: '[PRE18]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Once you have the default network policy to deny all traffic, you can add allow
    rules whenever needed by your pods. One of these policies is to add a global rule
    to allow pods to query CoreDNS for DNS resolution:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你有了默认的拒绝所有流量的网络策略，你可以在需要时为你的 Pod 添加允许规则。其中一个策略是添加一个全局规则，允许 Pod 查询 CoreDNS
    进行 DNS 解析：
- en: '[PRE19]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The preceding policy will allow egress network traffic from pods at any namespaces
    to query the CoreDNS in the `kube-system` namespace.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 上述策略将允许任何命名空间中的 Pod 发出的出口网络流量查询位于 `kube-system` 命名空间中的 CoreDNS。
- en: 'EKS does not come with Calico installed by default. So, we will include it
    in our Ansible configuration. You can view the full source code here: [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/calico-np](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/calico-np).'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: EKS 默认并未安装 Calico，因此我们将在 Ansible 配置中包含它。你可以在这里查看完整的源代码：[https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/calico-np](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/calico-np)。
- en: Monitoring runtime with Falco
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Falco 监控运行时
- en: There is an essential need to monitor workloads and containers for security
    violations at runtime. Falco enables the cluster's users to react in a timely
    manner for serious security threats and violations, or to catch security issues
    that bypassed cluster security scanning and testing.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 监控工作负载和容器在运行时的安全违规行为至关重要。Falco 使集群用户能够及时应对严重的安全威胁和违规行为，或者捕捉那些绕过集群安全扫描和测试的安全问题。
- en: 'Falco is an open source project originally developed by Sysdig with a core
    functionality of threat detection in Kubernetes. It can detect violations and
    abnormally behaving applications and send alerts pertaining to them. You can learn
    more about the Falco project here: [https://github.com/falcosecurity/falco](https://github.com/falcosecurity/falco).'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Falco 是一个开源项目，最初由 Sysdig 开发，核心功能是 Kubernetes 中的威胁检测。它能够检测违规行为和异常行为的应用程序，并发送相关警报。你可以在这里了解更多关于
    Falco 项目的信息：[https://github.com/falcosecurity/falco](https://github.com/falcosecurity/falco)。
- en: Falco runs as a daemon on top of Kubernetes' worker nodes, and it has the violation
    rules defined in configuration files that you can customize according to your
    security requirements.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: Falco 作为守护进程在 Kubernetes 的工作节点上运行，它在配置文件中定义了违规规则，你可以根据自己的安全需求进行自定义。
- en: 'Execute the following commands at the worker nodes that you want to monitor.
    This will install and deploy Falco:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在你希望监控的工作节点上执行以下命令。这将安装并部署 Falco：
- en: '[PRE20]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'To automate Falco''s deployment, we will include the previous commands in the
    worker node bootstrap user data using Terraform in this file: `terraform/modules/eks-workers/user-data.tf`.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 为了自动化部署 Falco，我们将在本文件中使用 Terraform 将之前的命令包含到工作节点的引导用户数据中：`terraform/modules/eks-workers/user-data.tf`。
- en: 'One example of the security runtime violations that Falco can detect is detecting
    whenever a shell is started inside a container. The Falco rule for this violation
    appears as follows:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Falco可以检测到的安全运行时违规的一个示例是在容器内部启动shell时的检测。此违规的Falco规则如下所示：
- en: '[PRE21]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'There are enormous rules that you can use and define in your Falco configuration.
    To learn more about them, refer to the Falco documentation and examples here:
    [https://falco.org/docs/examples/](https://falco.org/docs/examples/).'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在你的Falco配置中使用和定义大量规则。要了解更多信息，请参考Falco文档和示例：[https://falco.org/docs/examples/](https://falco.org/docs/examples/)。
- en: Ensuring cluster security and compliance
  id: totrans-188
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确保集群安全和合规性
- en: 'There are lots of moving parts and configurations that affect Kubernetes cluster
    security. And after deploying the security add-ons and adding more configurations,
    we need to make sure of the following:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多影响Kubernetes集群安全的移动部件和配置。在部署安全附加组件并添加更多配置后，我们需要确保以下内容：
- en: The cluster security configuration is valid and intact
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群安全配置有效完整
- en: The cluster is compliant with the standard security guidelines according to
    the **Center of Internet Security** (**CIS**) benchmark
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据**互联网中心安全**（**CIS**）基准，集群符合标准安全指南
- en: The cluster passes the conformance tests defined by the CNCF and its partners
    and community
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群通过CNCF及其合作伙伴和社区定义的一致性测试
- en: In this section, you will learn how to validate and guarantee each of the previous
    points through using the relevant tools.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将学习如何通过使用相关工具验证和保证上述每一点。
- en: Executing Kubernetes conformance tests
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行Kubernetes一致性测试
- en: The Kubernetes community and CNCF have defined a set of tests that you can run
    against any Kubernetes cluster to ensure that this cluster passes tests in terms
    of specific storage features, performance tests, scaling tests, provider tests,
    and other types of validation that are defined by CNCF and the Kubernetes community.
    This gives the cluster operators the confidence to use it to serve in production.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes社区和CNCF已定义了一组测试，您可以针对任何Kubernetes集群运行这些测试，以确保该集群在特定存储功能、性能测试、扩展测试、提供者测试以及由CNCF和Kubernetes社区定义的其他验证类型方面通过测试。这使得集群操作者可以信心满满地将其用于生产服务。
- en: Sonobuoy is a tool that you can use to run these conformance tests, and we recommend
    doing that for the new clusters, and periodically whenever you update your cluster.
    Sonobuoy makes it easier for you to ensure the state of your cluster without harming
    its operations or causing any downtime.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Sonobuoy是一个工具，您可以使用它来运行这些一致性测试，并建议为新集群以及定期更新集群时执行。Sonobuoy使您更容易确保集群状态，而无需影响其操作或造成任何停机时间。
- en: Installing Sonobuoy
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装Sonobuoy
- en: 'Apply the following instructions to install Sonobuoy on your local host:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 应用以下指令在本地主机上安装Sonobuoy：
- en: 'Download the latest Sonobuoy release that matches your operating system: [https://github.com/vmware-tanzu/sonobuoy/releases](https://github.com/vmware-tanzu/sonobuoy/releases).'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载与您的操作系统匹配的最新Sonobuoy版本：[https://github.com/vmware-tanzu/sonobuoy/releases](https://github.com/vmware-tanzu/sonobuoy/releases)。
- en: 'Extract the Sonobuoy binary archive:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提取Sonobuoy二进制归档：
- en: '[PRE22]'
  id: totrans-201
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Move the Sonobuoy binary archive to your `bin` folder or to any directory on
    the `PATH` system.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将Sonobuoy二进制归档移动到您的`bin`文件夹或`PATH`系统的任何目录中。
- en: Running Sonobuoy
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行Sonobuoy
- en: 'Apply the following instructions to run Sonobuoy and then view the conformance
    test results:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 应用以下指令运行Sonobuoy，然后查看一致性测试结果：
- en: 'Execute the following command to let Sonobuoy run the conformance tests and
    wait until it finishes:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下命令让Sonobuoy运行一致性测试，并等待其完成：
- en: '[PRE23]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'To get the test results, execute the following commands:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要获取测试结果，请执行以下命令：
- en: '[PRE24]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'After you finish, you can delete Sonobuoy and it will remove its namespace
    and any resources that it created for testing purposes:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，您可以删除Sonobuoy，它将删除其命名空间和为测试目的创建的任何资源：
- en: '[PRE25]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: To ensure that your Kubernetes cluster is in a conformance state, we recommend
    automating execution of the Sonobuoy tests to run periodically on a daily basis
    or following the deployment of infrastructure and Kubernetes system-level changes.
    We do not recommend more frequent and continuous runs of Sonobuoy tests to avoid
    the excessive load this could bring to the cluster.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 为确保您的Kubernetes集群处于一致性状态，我们建议定期自动化执行Sonobuoy测试，可以每天或在基础设施部署和Kubernetes系统级更改后执行。我们不建议频繁和持续运行Sonobuoy测试，以避免给集群带来过多负荷。
- en: Scanning cluster security configuration
  id: totrans-212
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扫描集群安全配置
- en: After completing the cluster conformance testing, you need to scan the configurations
    and security settings and ensure that there are no insecure or high-risk configurations.
    To achieve this, we will use `kube-scan`, which is a security scanning tool that
    scans cluster workloads and the runtime settings and assigns each one a rating
    from 0 (no risk) to 10 (high risk). `kube-scan` utilizes a scoring formula based
    on the Kubernetes Common Configuration Scoring System framework.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 完成集群一致性测试后，你需要扫描配置和安全设置，确保没有不安全或高风险的配置。为此，我们将使用`kube-scan`，它是一个安全扫描工具，用于扫描集群工作负载和运行时设置，并为每项打分，评分范围从0（无风险）到10（高风险）。`kube-scan`采用基于Kubernetes常见配置评分系统（CCSS）框架的评分公式。
- en: Installing kube-scan
  id: totrans-214
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装kube-scan
- en: '`kube-scan` is installed as a Kubernetes deployment in your cluster by using
    the following `kubectl` command:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-scan`通过以下`kubectl`命令作为Kubernetes部署安装在你的集群中：'
- en: '[PRE26]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '`kube-scan` scans the cluster when it starts, and will periodically scan it
    once every day. This way, you can enforce rescanning by restarting the `kube-scan`
    pod.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-scan`在启动时会扫描集群，并会每天定期扫描一次。这样，你可以通过重启`kube-scan` Pod来强制重新扫描。'
- en: Running kube-scan
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行kube-scan
- en: 'Apply the following instructions to run `kube-scan` and view the scanning results:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下指令运行`kube-scan`并查看扫描结果：
- en: 'To access the `kube-scan` results, you need to port forward the `kube-scan`
    service to port `8080` on your local machine:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要访问`kube-scan`结果，你需要将`kube-scan`服务端口转发到本地机器的`8080`端口：
- en: '[PRE27]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Then, open `http://localhost:8080` in your browser to view the scan results.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，在浏览器中打开`http://localhost:8080`以查看扫描结果。
- en: 'Once you finish, you can delete `kube-scan` and its resources by using the
    following `kubectl` command:'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 完成后，你可以使用以下`kubectl`命令删除`kube-scan`及其资源：
- en: '[PRE28]'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: We recommend deploying `kube-scan` to your cluster and automating the scan result
    validation to run periodically on a daily basis or after deploying infrastructure
    and Kubernetes system-level changes. We do not recommend more frequent and continuous
    runs of Sonobuoy tests to avoid the excessive load this could bring to the cluster.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议将`kube-scan`部署到集群中，并自动化扫描结果验证，确保每天定期运行，或者在部署基础设施和Kubernetes系统级别更改后运行。我们不建议频繁且持续地运行Sonobuoy测试，以避免可能给集群带来的过大负载。
- en: Executing the CIS Kubernetes benchmark
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行CIS Kubernetes基准
- en: In the final security validation stage of the cluster, you should test whether
    the cluster is deployed and configured according to the Kubernetes benchmark developed
    by the CIS.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群的最终安全验证阶段，你应该测试集群是否按照CIS开发的Kubernetes基准进行部署和配置。
- en: To execute this test, you will use `kube-bench`, which is a tool that is used
    to run CIS Kubernetes benchmark checks.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 要执行此测试，你将使用`kube-bench`，它是一个用于运行CIS Kubernetes基准检查的工具。
- en: Important note
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: For managed Kubernetes services such as EKS, you cannot use `kube-bench` to
    inspect the master nodes as you do not have access to them. However, it is still
    possible to use `kube-bench` to inspect the worker nodes.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 对于托管的Kubernetes服务（例如EKS），由于无法访问主节点，因此无法使用`kube-bench`检查主节点。但是，仍然可以使用`kube-bench`检查工作节点。
- en: Installing kube-bench
  id: totrans-231
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装kube-bench
- en: 'There are multiple ways to install `kube-bench`, one of them is to use a Docker
    container to copy the binary and the configurations to the host machine. The following
    command will install it:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 有多种方式安装`kube-bench`，其中一种是使用Docker容器将二进制文件和配置复制到主机。以下命令将进行安装：
- en: '[PRE29]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Running kube-bench
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 运行kube-bench
- en: 'Execute `kube-bench` against a Kubernetes node, and specify the Kubernetes
    version, such as 1.14 or any other supported version:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes节点上执行`kube-bench`，并指定Kubernetes版本，例如1.14或任何其他支持的版本：
- en: '[PRE30]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Instead of specifying a Kubernetes version, you can use a CIS Benchmark version,
    such as the following:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用CIS基准版本，而不是指定Kubernetes版本，例如以下版本：
- en: '[PRE31]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'And for EKS, you are allowed to run these specific targets: `master`, `node`,
    `etcd`, and `policies`:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 对于EKS，你被允许运行以下特定目标：`master`、`node`、`etcd`和`policies`：
- en: '[PRE32]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The outputs are either `PASS`; `FAIL`, which indicate that the test is completed;
    `WARN`, which means the test requires manual intervention; `INFO` is an informational
    output that requires no action.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 输出结果包括`PASS`；`FAIL`，表示测试完成；`WARN`，表示测试需要人工干预；`INFO`是一个无需采取任何行动的提示性输出。
- en: Important note
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: We recommend automating the execution of Sonobuoy, `kube-scan`, and `kube-bench`
    on a daily basis to verify security and compliance for your clusters.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议自动化执行 Sonobuoy、`kube-scan` 和 `kube-bench`，以便每天验证集群的安全性和合规性。
- en: Enabling audit logging
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启用审计日志
- en: Ensure that you enabled the cluster audit logs, and also that they are monitored
    for anomalous or unwanted API calls, especially any authorization failures. For
    EKS, you need to opt-in to enable these logs and have them streamed to CloudWatch.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 确保启用了集群审计日志，并且监控它们是否有异常或不需要的 API 调用，尤其是任何授权失败。对于 EKS，您需要选择启用这些日志，并将它们流式传输到 CloudWatch。
- en: 'To enable this, you need to update the Terraform EKS resource in this file,
    `terraform/modules/eks-cp/main.tf`, and add the following line of code:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用此功能，您需要更新此文件 `terraform/modules/eks-cp/main.tf` 中的 Terraform EKS 资源，并添加以下代码行：
- en: '[PRE33]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: After applying this Terraform change to the EKS configuration, the cluster audit
    logs will be streamed to CloudWatch, and you can take it from there and create
    alerts.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 在将此 Terraform 更改应用于 EKS 配置后，集群审计日志将被流式传输到 CloudWatch，您可以从那里创建警报。
- en: Bonus security tips
  id: totrans-249
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 额外的安全建议
- en: 'These are some general security best practices and tips that did not fit under
    any of the previous sections. However, I find them to be useful:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是一些通用的安全最佳实践和建议，它们没有适合前面任何章节的内容。然而，我认为它们很有用：
- en: Always keep Kubernetes updated to the latest version.
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 始终将 Kubernetes 更新到最新版本。
- en: Update worker AMIs to the latest version. You have to be cautious because this
    change could introduce some downtime, especially if you are not using a managed
    node group.
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将工作节点的 AMI 更新到最新版本。您需要小心，因为此更改可能会引入一些停机时间，特别是当您没有使用托管节点组时。
- en: Do not run Docker in Docker or mount the socket in a container.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不要在 Docker 中运行 Docker 或将套接字挂载到容器中。
- en: Restrict the use of `hostPath` or, if `hostPath` is necessary, restrict which
    prefixes can be used and configure the volume as read-only.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 限制使用 `hostPath`，或者如果 `hostPath` 必须使用，限制可使用的前缀并将卷配置为只读。
- en: Set requests and limits for each container to avoid resource contention and
    **Denial of Service** (**DoS**) attacks.
  id: totrans-255
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为每个容器设置请求和限制，以避免资源竞争和 **拒绝服务**（**DoS**）攻击。
- en: Whenever possible, use an optimized operating system for running containers.
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在可能的情况下，使用优化过的操作系统来运行容器。
- en: Use immutable infrastructure, and automate the rotation of the cluster worker
    nodes.
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用不可变的基础设施，并自动化集群工作节点的轮换。
- en: You should not enable the Kubernetes dashboard.
  id: totrans-258
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不应启用 Kubernetes 仪表板。
- en: Enable AWS VPC Flow Logs to capture metadata about the traffic flowing through
    a VPC, and then analyze it further for suspicious activities.
  id: totrans-259
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用 AWS VPC 流日志，以捕获流经 VPC 的流量的元数据，然后进一步分析可疑活动。
- en: Kubernetes security is a fast-growing domain, and you should keep following
    the latest guidelines and best practices, and integrate them into your processes
    and DevSecOps automations.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 安全是一个快速发展的领域，您应该不断跟随最新的指南和最佳实践，并将它们集成到您的流程和 DevSecOps 自动化中。
- en: Deploying the security configurations
  id: totrans-261
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署安全配置
- en: 'The following instructions will deploy the cluster''s Ansible playbook, and
    it will deploy the security add-ons and configuration to the cluster:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 以下说明将部署集群的 Ansible playbook，它将向集群部署安全附加组件和配置：
- en: 'Initialize the Terraform state and select the workspace by running the following
    commands:'
  id: totrans-263
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令初始化 Terraform 状态并选择工作区：
- en: '[PRE34]'
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Retrieve and configure `kubeconfig` for the target cluster:'
  id: totrans-265
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取并配置目标集群的 `kubeconfig`：
- en: '[PRE35]'
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Execute the Ansible playbook:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行 Ansible playbook：
- en: '[PRE36]'
  id: totrans-268
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: You will get the following output following successful Ansible execution:![Figure
    6.2 – Ansible execution output
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在成功执行 Ansible 后，您将得到以下输出：![图 6.2 – Ansible 执行输出
- en: '](img/B16192_06_002.jpg)'
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '](img/B16192_06_002.jpg)'
- en: Figure 6.2 – Ansible execution output
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 6.2 – Ansible 执行输出
- en: 'Execute the following `kubectl` command to get all the pods running in the
    cluster. This will ensure that the cluster configuration is applied successfully:'
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行以下 `kubectl` 命令以获取集群中运行的所有 pods。这将确保集群配置已成功应用：
- en: '[PRE37]'
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'You should get the following output, which lists all the pods running in the
    cluster including the new pods for the security add-ons:'
  id: totrans-274
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 您应该得到以下输出，其中列出了集群中运行的所有 pods，包括用于安全附加组件的新 pods：
- en: '![Figure 6.3 – List of all pods'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 6.3 – 所有 pods 的列表'
- en: '](img/B16192_06_003.jpg)'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16192_06_003.jpg)'
- en: Figure 6.3 – List of all pods
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.3 – 所有 pods 的列表
- en: Now you have completed applying the cluster configuration as per the previous
    instructions. And your cluster has all of the security add-ons and configuration
    deployed and ready for serving production.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经完成了按照之前的指示应用集群配置。您的集群已经部署了所有安全附加组件和配置，并准备好为生产环境提供服务。
- en: Destroying the cluster
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 销毁集群
- en: 'First, you should delete the `ingress-nginx` service to instruct AWS to destroy
    the NLB associated with the ingress controller. We need this step because Terraform
    will fail to destroy this NLB because it is created by Kubernetes:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您应删除`ingress-nginx`服务，以指示AWS销毁与入口控制器相关联的NLB。我们需要执行此步骤，因为Terraform会因NLB是由Kubernetes创建而无法销毁该NLB：
- en: '[PRE38]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Then, you can follow the rest of the instructions in the *Destroying the network
    and cluster infrastructure* section in [*Chapter 3*](B16192_03_Final_PG_ePub.xhtml#_idTextAnchor073),
    *Provisioning Kubernetes Clusters Using AWS and Terraform*, to destroy the Kubernetes
    cluster and all related AWS resources. Please ensure that the resources are destroyed
    in the following order:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，您可以按照[*第三章*](B16192_03_Final_PG_ePub.xhtml#_idTextAnchor073)中*销毁网络和集群基础设施*部分的其余指示，销毁Kubernetes集群和所有相关的AWS资源。请确保按以下顺序销毁这些资源：
- en: Kubernetes cluster `packtclusters` resources
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes集群`packtclusters`资源
- en: Cluster VPC resources
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 集群VPC资源
- en: Terraform shared state resources
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Terraform共享状态资源
- en: By executing the previous steps, you should have all Kubernetes and AWS infrastructure
    resources destroyed and cleaned up, ready for the hands-on practice in the next
    chapter.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行之前的步骤，您应该已经销毁并清理了所有Kubernetes和AWS基础设施资源，为下一个章节的实际操作做好准备。
- en: Summary
  id: totrans-287
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you have learned about Kubernetes security best practices,
    and learned how to apply an end-to-end security approach to the cluster's infrastructure,
    network, containers, apps, secrets, apps, and the workload's runtime. You also
    learned how to apply and validate security compliance checks and tests. You developed
    all of the required templates and configuration as code for these best practices,
    controllers, and add-ons with Ansible and Terraform.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您学习了Kubernetes安全最佳实践，并学习了如何将端到端的安全方法应用到集群的基础设施、网络、容器、应用、密钥、应用以及工作负载的运行时。您还学会了如何应用和验证安全合规性检查和测试。您开发了所有所需的模板和配置代码，用于这些最佳实践、控制器和附加组件，使用了Ansible和Terraform。
- en: You deployed Kubernetes add-ons and controllers to provide essential services
    such as `kube2iam`, Cert-Manager, Sealed Secrets, and Falco, in addition to tuning
    Kubernetes-native security features such as pod security policies, network policies,
    and RBAC.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 您部署了Kubernetes附加组件和控制器，以提供诸如`kube2iam`、Cert-Manager、Sealed Secrets和Falco等基本服务，并对Kubernetes原生的安全功能（如Pod安全策略、网络策略和RBAC）进行了调优。
- en: You acquired a solid knowledge of Kubernetes security in this chapter, but you
    should do a detailed evaluation of your cluster security requirements and take
    further action to deploy any extra tools and configurations that may be required.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 您在本章中已经掌握了Kubernetes安全的基本知识，但您应当详细评估您的集群安全需求，并采取进一步的措施，部署可能需要的额外工具和配置。
- en: In the next chapter, you will learn in detail about Kubernetes observability,
    and the monitoring and logging of best practices, tools, add-ons, and configurations
    that you need to deploy and optimize for production-grade clusters.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，您将详细了解Kubernetes的可观察性，以及监控和日志记录的最佳实践、工具、附加组件和配置，这些是您需要为生产级集群部署和优化的内容。
- en: Further reading
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: 'You can refer to the following links for more information on the topics covered
    in this chapter:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以参考以下链接，获取更多关于本章所涵盖主题的信息：
- en: '*Getting Started with Kubernetes – Third Edition* (*Chapter 14*, *Hardening
    Kubernetes*): [https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition)'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Kubernetes入门 – 第三版*（*第14章*，*加固Kubernetes*）：[https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition)'
- en: '*Mastering Kubernetes – Second Edition* ([*Chapter 5*](B16192_05_Final_PG_ePub.xhtml#_idTextAnchor118),
    *Configuring Kubernetes Security, Limits, and Accounts*): [https://www.packtpub.com/application-development/mastering-kubernetes-second-edition](https://www.packtpub.com/application-development/mastering-kubernetes-second-edition)'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*掌握Kubernetes – 第二版* ([*第五章*](B16192_05_Final_PG_ePub.xhtml#_idTextAnchor118),
    *配置Kubernetes安全、限制和账户*): [https://www.packtpub.com/application-development/mastering-kubernetes-second-edition](https://www.packtpub.com/application-development/mastering-kubernetes-second-edition)'
- en: '*Learn Kubernetes Security*: [https://www.packtpub.com/security/learn-kubernetes-security](https://www.packtpub.com/security/learn-kubernetes-security)'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*学习Kubernetes安全性*: [https://www.packtpub.com/security/learn-kubernetes-security](https://www.packtpub.com/security/learn-kubernetes-security)'
