- en: '13'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '13'
- en: High Availability and Disaster Recovery for GenAI Applications
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GenAI应用程序的高可用性和灾难恢复
- en: In this chapter, we explore the concepts of **high availability** (**HA**) and
    **disaster recovery** (**DR**) tailored for GenAI applications deployed on **Kubernetes**
    (**K8s**) clusters. Given the dynamic and resource-intensive nature of GenAI applications,
    achieving seamless scalability and robust resiliency is essential for high-quality
    production deployments. We will discuss various architectural patterns and configurations
    that empower GenAI workloads to automatically scale based on usage demand while
    ensuring continuous service, even in the event of a disaster such as a regional
    outage.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨针对部署在**Kubernetes**（**K8s**）集群上的GenAI应用程序量身定制的**高可用性**（**HA**）和**灾难恢复**（**DR**）的概念。考虑到GenAI应用程序的动态性和资源密集型特性，确保无缝的可扩展性和强大的弹性对高质量的生产部署至关重要。我们将讨论各种架构模式和配置，使GenAI工作负载能够根据使用需求自动扩展，同时确保在发生区域性故障等灾难时持续提供服务。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: Designing for HA and DR
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HA和DR的设计
- en: Resiliency in K8s
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K8s中的弹性
- en: DR strategies in K8s
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K8s中的DR策略
- en: Designing for HA and DR
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: HA和DR的设计
- en: 'HA ([https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/high-availability-is-not-disaster-recovery.html](https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/high-availability-is-not-disaster-recovery.html))
    ensures that a system remains operational with minimal downtime by eliminating
    single points of failure. It relies on *redundancy* across nodes, regions, or
    clusters and aims to maintain continuous service. HA is measured by uptime percentage,
    failover time, and system redundancy. For example, a system with 99.99% uptime
    allows only ~53 minutes of downtime per year. In the context of GenAI, where foundational
    models often drive critical business operations such as customer support, real-time
    text and image analysis, and so on, downtime can be expensive. HA ensures the
    following:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: HA ([https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/high-availability-is-not-disaster-recovery.html](https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/high-availability-is-not-disaster-recovery.html))
    确保系统在最小的停机时间内保持运行，通过消除单点故障来实现。它依赖于节点、区域或集群之间的*冗余*，并旨在保持持续的服务。HA通过正常运行时间百分比、故障切换时间和系统冗余来衡量。例如，一个正常运行时间为99.99%的系统每年只允许约53分钟的停机时间。在GenAI的背景下，基础模型通常推动着如客户支持、实时文本和图像分析等关键业务操作，停机可能非常昂贵。HA确保以下几点：
- en: Inference endpoints remain consistently responsive, meeting the business availability
    requirements
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推理端点保持一致的响应性，满足业务的可用性需求
- en: Training jobs can handle node or service failures without crashing mid-way
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练作业可以在节点或服务故障时继续运行，而不会中途崩溃
- en: DR ([https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html](https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html))
    is focused on restoring services after catastrophic failures such as hardware
    malfunctions, cyberattacks, or natural disasters. It ensures that data is backed
    up and can be restored quickly to resume operations. DR strategies involve regular
    data backups, redundancy, and automated recovery workflows. Unlike HA, which prevents
    downtime, DR accepts some level of downtime and data loss but ensures that systems
    can be restored efficiently.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: DR ([https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html](https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html))
    旨在恢复因硬件故障、网络攻击或自然灾害等灾难性故障导致的服务。它确保数据得到备份，并能够快速恢复，以恢复运营。DR策略涉及定期的数据备份、冗余以及自动化恢复工作流。与HA不同，HA旨在防止停机，而DR则接受一定程度的停机和数据丢失，但确保系统可以高效恢复。
- en: 'Three key metrics that define HA and DR are the **recovery point objective**
    (**RPO**), **recovery time objective** (**RTO**), and **maximum tolerable** **downtime**
    (**MTD**):'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 定义HA和DR的三个关键指标是**恢复点目标**（**RPO**）、**恢复时间目标**（**RTO**）和**最大容忍停机时间**（**MTD**）：
- en: RPO represents the maximum allowable data loss before recovery. A system with
    an RPO of 0 requires real-time data replication to ensure no data is lost, whereas
    an RPO of several hours may use periodic backups instead. The lower the RPO, the
    more advanced the backup mechanisms need to be.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RPO（恢复点目标）表示在恢复之前可允许的数据丢失最大量。RPO为0的系统需要实时数据复制以确保没有数据丢失，而RPO为数小时的系统可能使用定期备份。RPO越低，备份机制需要越先进。
- en: RTO determines the acceptable downtime before services must be restored. A low
    RTO of seconds or minutes requires active-active failover with redundant systems
    always on standby, while a higher RTO allows for manual intervention and restoration
    from backups.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RTO（恢复时间目标）确定了服务恢复之前可接受的停机时间。低RTO（以秒或分钟为单位）要求有活动-活动的故障转移，并且冗余系统始终处于待命状态，而较高的RTO则允许手动干预并从备份中恢复。
- en: MTD is the longest period a service can be unavailable before causing unacceptable
    consequences to an organization. It defines the threshold for downtime beyond
    which service can suffer operational or financial challenges. MTD is a key component
    of **business continuity planning** (**BCP**) and DR strategies.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MTD（最大容忍停机时间）是指服务不可用的最长时间，超过这个时间会对组织造成不可接受的后果。它定义了停机的阈值，超过该阈值服务可能面临运营或财务挑战。MTD是**业务连续性计划**（**BCP**）和灾难恢复（DR）策略的关键组成部分。
- en: '*Figure 13**.1* illustrates these key metrics – RTO, RPO, and MTD in the context
    of data loss and system downtime following a failure event.'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*图 13.1* 展示了这些关键指标——RTO、RPO和MTD在数据丢失和系统故障后的停机时间背景下的含义。'
- en: '![Figure 13.1 – Different recovery objectives](img/B31108_13_1.jpg)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.1 – 不同的恢复目标](img/B31108_13_1.jpg)'
- en: Figure 13.1 – Different recovery objectives
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.1 – 不同的恢复目标
- en: A highly available application should be able to withstand failures and maintain
    continuous operation despite partial network outages or hardware failures. It
    requires that the application has no single point of failure and workloads are
    distributed across multiple isolated failure domains, such as nodes, **Availability
    Zones** (**AZs**), and clusters.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 高可用性应用程序应该能够承受故障，并在部分网络中断或硬件故障的情况下保持持续运行。这要求应用程序没有单点故障，并且工作负载分布在多个独立的故障域中，例如节点、**可用区**（**AZs**）和集群。
- en: 'Redundancy at various levels helps to handle potential failures. Key tenets
    of K8s that help to achieve HA include the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 各级冗余有助于处理潜在的故障。实现高可用性的K8s的关键原则包括：
- en: '**Redundancy**: Avoid single points of failure in both application components
    and infrastructure. Deploying multiple replicas of the applications using K8s
    Deployment or ReplicaSet objects can ensure redundancy in case of failures.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**冗余**：避免应用组件和基础设施中的单点故障。使用K8s的Deployment或ReplicaSet对象部署多个应用副本，可以确保在故障情况下的冗余。'
- en: '**Autoscaling**: K8s **Horizontal Pod Autoscaling** (**HPA**) can help adjust
    the number of Pod replicas based on demand, ensuring that the application can
    handle varying loads efficiently. Additionally, Cluster Autoscaler and Karpenter
    can help manage the scaling of worker nodes in response to the scheduling needs
    of Pods.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动扩缩容**：K8s的**水平Pod自动扩缩容**（**HPA**）可以根据需求调整Pod副本的数量，确保应用程序能够高效地处理不同的负载。此外，集群自动扩展器（Cluster
    Autoscaler）和Karpenter可以根据Pod的调度需求帮助管理工作节点的扩展。'
- en: '**Self-healing**: Deploying applications using K8s Deployment allows K8s to
    automatically replace failed Pods, maintaining the desired state of the application.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自愈**：使用K8s Deployment部署应用程序时，K8s会自动替换故障的Pod，保持应用程序的期望状态。'
- en: '**Safer upgrades and rollbacks**: By adopting application deployment strategies
    such as blue/green and canary deployments, you can ensure that new versions of
    applications are introduced safely. These strategies enable the testing of new
    versions with a subset of users before a full rollout, reducing the risk of widespread
    issues.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**更安全的升级和回滚**：通过采用蓝绿部署和金丝雀部署等应用程序部署策略，您可以确保新版本的应用程序安全地引入。这些策略使得在全面推出之前，可以先在部分用户中测试新版本，从而减少广泛出现问题的风险。'
- en: '**Chaos engineering**: Periodically simulate failures in your applications
    to validate the HA setup. Review and improve runbooks and operational guidelines
    based on simulated incidents.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混沌工程**：定期模拟应用程序中的故障，以验证高可用性（HA）设置。根据模拟事件审查并改进运行手册和操作指南。'
- en: '**Observability**: Collect the logs, metrics, and traces for real-time visibility
    into the infrastructure and the application’s health and performance. Configure
    alerts to detect early signs of failures such as latency, error rate, and so on.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可观察性**：收集日志、指标和追踪信息，以实时查看基础设施和应用程序的健康状况及性能。配置警报以检测故障的早期迹象，如延迟、错误率等。'
- en: In this section, we discussed the importance of HA and DR for GenAI applications,
    which are uniquely sensitive to downtime and performance degradation. We also
    highlighted the key metrics that define HA and DR, such as RTO, RPO, and MTD,
    alongside the key K8s tenets that help achieve HA.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了高可用性（HA）和灾难恢复（DR）对于生成型人工智能（GenAI）应用的重要性，这些应用对停机和性能下降具有独特的敏感性。我们还重点介绍了定义HA和DR的关键指标，如RTO、RPO和MTD，以及有助于实现HA的K8s关键原则。
- en: In the next section, we will delve deeper into these concepts by focusing on
    resiliency in K8s.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将深入探讨这些概念，重点关注K8s中的弹性。
- en: Resiliency in K8s
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: K8s中的弹性
- en: GenAI applications are resource-intensive, requiring fault tolerance and scalability
    to handle model training, large-scale inference, and real-time AI workloads. GenAI
    models usually require GPUs for accelerated inference and training, making GPU
    dependency and availability a critical factor in deployment. These workloads often
    experience unpredictable resource spikes, leading to scalability challenges that
    require dynamic provisioning. Additionally, data availability and consistency
    are essential, as large AI models rely on distributed storage and caching to maintain
    performance across multiple nodes. Long-running processes further complicate resilience,
    as model training can take hours or even days.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: GenAI应用是资源密集型的，要求具备容错性和可扩展性，以处理模型训练、大规模推理和实时AI工作负载。GenAI模型通常需要GPU来加速推理和训练，因此GPU的依赖性和可用性成为部署的关键因素。这些工作负载常常会出现不可预测的资源波动，导致可扩展性挑战，这就需要动态资源配置。此外，数据的可用性和一致性也至关重要，因为大型AI模型依赖分布式存储和缓存来确保在多个节点之间保持性能。长时间运行的过程进一步加大了弹性的难度，因为模型训练可能需要几个小时甚至几天。
- en: K8s provides a robust foundation for managing GenAI workloads, but ensuring
    resiliency requires specialized configurations and best practices at every layer
    of K8s, as shown in *Figure 13**.2*.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: K8s为管理GenAI工作负载提供了坚实的基础，但要确保弹性，需要在K8s的每一层进行专门的配置和最佳实践，如*图13.2*所示。
- en: '![Figure 13.2 – K8s resiliency across different layers](img/B31108_13_2.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图13.2 – 不同层次的K8s弹性](img/B31108_13_2.jpg)'
- en: Figure 13.2 – K8s resiliency across different layers
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图13.2 – 不同层次的K8s弹性
- en: 'These layers help ensure that applications remain highly available and can
    recover from failures. Let’s cover each layer, starting from the innermost layer
    at the Pod level:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这些层次有助于确保应用保持高可用性，并能从故障中恢复。让我们从Pod级别的最内层开始，逐层介绍每个层次：
- en: '`/healthz` endpoint every 10 seconds on port `80`; similarly, the readiness
    probe is configured to check the `/``readyz` endpoint:'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每10秒在端口`80`上检查`/healthz`端点；同样，准备性探针被配置为检查`/readyz`端点：
- en: '[PRE0]'
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Replica level**: A replica is an identical copy of a Pod managed by a K8s
    controller, such as a **ReplicaSet** or **Deployment**, as covered in previous
    chapters. Having multiple replicas ensures that even if one Pod fails, other instances
    remain available to handle requests. It is especially important for AI model servers,
    such as **TensorFlow Serving** or **Triton Inference Server**, to ensure that
    inference requests can meet the SLA as the demand increases. Deployments should
    define a suitable number of replicas based on workload needs and traffic demands.
    HPA can dynamically adjust the number of replicas based on CPU, memory, and GPU
    usage, providing flexibility during high-load scenarios.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**副本级别**：副本是由K8s控制器（如**ReplicaSet**或**Deployment**）管理的Pod的完全副本，前面章节已经介绍过。拥有多个副本可以确保即使一个Pod失败，其他实例仍然可用来处理请求。对于AI模型服务器（如**TensorFlow
    Serving**或**Triton Inference Server**）来说，确保推理请求在需求增加时仍能满足服务水平协议（SLA）尤为重要。部署应根据工作负载需求和流量需求定义合适数量的副本。HPA（水平自动扩展）可以根据CPU、内存和GPU使用情况动态调整副本数量，在高负载场景下提供灵活性。'
- en: 'For inference workloads, it is a good idea to have a minimum number of GenAI
    inference/model-serving Pods remain available during updates or disruptions by
    using **PodDisruptionBudget** ([https://kubernetes.io/docs/tasks/run-application/configure-pdb/](https://kubernetes.io/docs/tasks/run-application/configure-pdb/)),
    as shown in the following K8s manifest:'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于推理工作负载，建议在更新或中断期间，使用**PodDisruptionBudget**（[https://kubernetes.io/docs/tasks/run-application/configure-pdb/](https://kubernetes.io/docs/tasks/run-application/configure-pdb/)）保持最小数量的GenAI推理/模型服务Pod可用，具体操作可以参考以下K8s清单：
- en: '[PRE1]'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`topologySpreadConstraints` to spread Pod replicas across multiple nodes:'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`topologySpreadConstraints` 用于将Pod副本分布到多个节点上：'
- en: '[PRE2]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: At the node level, K8s ensures basic resilience through health checks and eviction
    policies. However, for production-grade GenAI workloads, you often need additional
    safeguards and automatic recovery. You can leverage the K8s `node-problem-detector`
    ([https://github.com/kubernetes/node-problem-detector](https://github.com/kubernetes/node-problem-detector))
    add-on, which makes various node problems visible to the upstream layers in the
    cluster management stack. It runs as a **DaemonSet** Pod on every worker node
    to scan for failures and reports them to *apiserver*.
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在节点级别，K8s通过健康检查和驱逐策略确保基本的弹性。然而，对于生产级别的GenAI工作负载，通常需要额外的保障措施和自动恢复。你可以利用K8s的`node-problem-detector`（[https://github.com/kubernetes/node-problem-detector](https://github.com/kubernetes/node-problem-detector)）附加组件，它使集群管理堆栈中的上游层能够看到各种节点问题。它作为**DaemonSet**
    Pod在每个工作节点上运行，扫描故障并将其报告给*apiserver*。
- en: Amazon EKS introduced a **Node monitoring agent** ([https://docs.aws.amazon.com/eks/latest/userguide/node-health.html](https://docs.aws.amazon.com/eks/latest/userguide/node-health.html))
    add-on that automatically reads node logs to detect certain health issues and
    adds *NodeCondition* accordingly. This can be combined with **Node auto repair**
    ([https://docs.aws.amazon.com/eks/latest/userguide/node-health.html#node-auto-repair](https://docs.aws.amazon.com/eks/latest/userguide/node-health.html#node-auto-repair)),
    which monitors the health of nodes, automatically reacting to detected problems
    and replacing nodes when possible. For example, when **Xid errors** ([https://docs.nvidia.com/deploy/xid-errors/index.html#topic_5_1](https://docs.nvidia.com/deploy/xid-errors/index.html#topic_5_1))
    are detected on GPU nodes, it automatically replaces them after 10 minutes and
    evicts the Pods to get them scheduled on healthy nodes. Xid errors are error codes
    generated by NVIDIA GPU drivers indicating that the GPU has encountered an issue,
    such as a hang, reset, or memory fault.
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 亚马逊EKS引入了**节点监控代理**（[https://docs.aws.amazon.com/eks/latest/userguide/node-health.html](https://docs.aws.amazon.com/eks/latest/userguide/node-health.html)）附加组件，自动读取节点日志以检测某些健康问题，并相应地添加*NodeCondition*。这可以与**节点自动修复**（[https://docs.aws.amazon.com/eks/latest/userguide/node-health.html#node-auto-repair](https://docs.aws.amazon.com/eks/latest/userguide/node-health.html#node-auto-repair)）结合使用，该功能监控节点健康，自动响应检测到的问题，并在可能的情况下替换节点。例如，当GPU节点上检测到**Xid错误**（[https://docs.nvidia.com/deploy/xid-errors/index.html#topic_5_1](https://docs.nvidia.com/deploy/xid-errors/index.html#topic_5_1)）时，它会在10分钟后自动替换节点并驱逐Pods，将其重新调度到健康的节点上。Xid错误是由NVIDIA
    GPU驱动程序生成的错误代码，表示GPU遇到了问题，如死机、重置或内存故障。
- en: '**AZ level**: AZs are isolated data centers within a cloud provider’s region.
    Running workloads across multiple AZs provides higher fault tolerance, protecting
    against failures at the data center level. K8s clusters deployed in a multi-AZ
    configuration ensure that even if an entire AZ experiences an outage, applications
    continue running in another AZ. You can leverage K8s *topologySpreadConstraints*
    scheduling constraints to distribute the Pods managed by a ReplicaSet or StatefulSet
    across different failure domains, such as AZs, to ensure protection against AZ
    issues. Combine it with nodes for an additional layer of resiliency:'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可用区级别（AZ level）**：可用区（AZ）是云服务商区域内的隔离数据中心。跨多个AZ运行工作负载提供了更高的容错性，能够防止数据中心级别的故障。以多AZ配置部署的K8s集群确保即使整个AZ出现故障，应用程序仍然可以在另一个AZ中继续运行。你可以利用K8s的*topologySpreadConstraints*调度约束，将由ReplicaSet或StatefulSet管理的Pod分布到不同的故障域，如AZ，以确保对AZ问题的防护。结合节点使用，可以提供额外的弹性保护层：'
- en: '[PRE3]'
  id: totrans-45
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Additionally, Amazon EKS supports Amazon **Application Recovery Controller**
    (**ARC**) zonal shift and zonal autoshift ([https://aws.amazon.com/application-recovery-controller/](https://aws.amazon.com/application-recovery-controller/)).
    ARC helps you to manage and coordinate the recovery of applications across AZs
    and AWS Regions. With zonal shift, you can temporarily mitigate issues and incidents
    by triggering a shift and redirecting in-cluster network traffic to a healthy
    AZ. For a fully automated experience, you can authorize AWS to manage this shift
    on your behalf using zonal autoshift. With zonal autoshift, you can configure
    practice runs to test that your cluster environment functions as expected with
    one less AZ. Refer to the AWS documentation at [https://docs.aws.amazon.com/eks/latest/userguide/zone-shift.html](https://docs.aws.amazon.com/eks/latest/userguide/zone-shift.html)
    to learn more about this feature and find instructions to enable it on your EKS
    cluster.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此外，Amazon EKS支持Amazon **应用程序恢复控制器** (**ARC**) 区域迁移和区域自动迁移 ([https://aws.amazon.com/application-recovery-controller/](https://aws.amazon.com/application-recovery-controller/))。ARC帮助您管理和协调跨可用区（AZ）和AWS区域的应用恢复。通过区域迁移，您可以通过触发迁移并将集群内的网络流量重定向到健康的AZ，暂时缓解问题和事故。为了实现完全自动化体验，您可以授权AWS代为管理此迁移，使用区域自动迁移。通过区域自动迁移，您可以配置演练，测试您的集群环境在少一个AZ的情况下是否正常运行。请参考AWS文档
    [https://docs.aws.amazon.com/eks/latest/userguide/zone-shift.html](https://docs.aws.amazon.com/eks/latest/userguide/zone-shift.html)，了解更多有关此功能的信息，并查看启用该功能的步骤。
- en: '**Multi-cluster deployment**: A multi-cluster architecture involves running
    workloads across multiple independent K8s clusters. This approach is useful for
    mitigating failures at the cluster level, ensuring that if one cluster fails due
    to a control plane issue or networking disruption, another cluster can take over
    the workload. Multi-cluster deployments are often used for active-active, DR,
    and geo-distributed applications. You can leverage services such as **Amazon Route
    53** ([https://aws.amazon.com/route53/](https://aws.amazon.com/route53/)) and
    **AWS Global Accelerator** ([https://aws.amazon.com/global-accelerator/](https://aws.amazon.com/global-accelerator/))
    to perform health checks and route the traffic in a multi-cluster setup.'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多集群部署**：多集群架构涉及在多个独立的K8s集群中运行工作负载。这种方法对于缓解集群级别的故障非常有用，确保如果一个集群由于控制平面问题或网络中断而失败，另一个集群可以接管工作负载。多集群部署通常用于主动-主动、灾难恢复（DR）和地理分布式应用。您可以利用像**Amazon
    Route 53** ([https://aws.amazon.com/route53/](https://aws.amazon.com/route53/))
    和 **AWS Global Accelerator** ([https://aws.amazon.com/global-accelerator/](https://aws.amazon.com/global-accelerator/))
    这样的服务来执行健康检查并在多集群环境中路由流量。'
- en: '**Global deployment**: At the highest level, deploying workloads across multiple
    geographic regions ensures that applications remain available even if an entire
    AWS Region experiences an outage. This approach not only enhances DR capabilities
    but also provides low-latency access to users in different locations. However,
    multi-region architectures require careful management of data consistency, replication,
    and failover processes to guarantee seamless recovery when regional failures occur.
    Because Amazon EKS is a regional service, you must provision a separate EKS cluster
    in each AWS Region to achieve a truly global deployment.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**全球部署**：在最高层级，通过跨多个地理区域部署工作负载，可以确保即使整个AWS区域发生故障，应用程序仍然可用。这种方法不仅增强了灾难恢复能力，还为不同位置的用户提供了低延迟的访问。然而，多区域架构需要仔细管理数据一致性、复制和故障转移流程，以确保在发生区域故障时能够实现无缝恢复。由于Amazon
    EKS是区域性服务，您必须在每个AWS区域中配置一个单独的EKS集群，以实现真正的全球部署。'
- en: Each of these layers contributes to overall system resilience in K8s. By implementing
    redundancy at different levels, organizations can build highly available, fault-tolerant
    applications that withstand various types of failures, from individual Pod crashes
    to full-scale regional outages.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 这些层次的每一层都为K8s中的系统弹性做出了贡献。通过在不同层级实现冗余，组织可以构建高可用、容错的应用程序，这些应用程序能够承受各种类型的故障，从单个Pod崩溃到整个区域的停机。
- en: 'Other K8s options for resiliency and HA are load balancing and service discovery:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: K8s的其他高可用性和弹性选项包括负载均衡和服务发现：
- en: '**Load balancing**: K8s services provide built-in load balancing to distribute
    network traffic across multiple Pod instances. By defining a service, you can
    expose an application running on a set of Pods as a network service, with K8s
    handling the distribution of traffic to ensure no single Pod becomes a bottleneck.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载均衡**：K8s 服务提供内置的负载均衡功能，将网络流量分发到多个 Pod 实例。通过定义服务，您可以将运行在一组 Pods 上的应用程序暴露为网络服务，并由
    K8s 处理流量分配，确保没有单个 Pod 成为瓶颈。'
- en: '**Service discovery**: K8s offers service discovery mechanisms that allow applications
    and services to locate and communicate with each other efficiently, even as instances
    are created or terminated. This dynamic discovery is facilitated through environment
    variables or DNS, enabling seamless interaction between services within the cluster.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务发现**：K8s 提供了服务发现机制，允许应用程序和服务高效地定位并相互通信，即使实例正在创建或终止。通过环境变量或 DNS 实现这一动态发现，使得集群内的服务可以无缝互动。'
- en: In this section, we discussed how resiliency can be implemented at various layers
    in K8s environments, from the individual Pods to multi-AZ, multi-cluster, and
    multi-region architectures. In the next section, we will explore various DR strategies
    and how they can be applied to K8s workloads.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们讨论了如何在 K8s 环境中的各个层次实现弹性，从单个 Pods 到多可用区（AZ）、多集群和多区域架构。在下一节中，我们将探讨各种灾难恢复策略，以及它们如何应用于
    K8s 工作负载。
- en: DR strategies in K8s
  id: totrans-54
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K8s 中的灾难恢复策略
- en: DR focuses on restoring services and data after catastrophic events such as
    natural disasters, security breaches, and significant system failures. An effective
    DR plan for K8s should aim to minimize data loss (RPO) and reduce downtime (RTO).
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 灾难恢复（DR）关注的是在自然灾害、安全漏洞和重大系统故障等灾难事件后恢复服务和数据。对于 K8s 来说，一个有效的 DR 计划应当旨在最小化数据丢失（RPO）并减少停机时间（RTO）。
- en: '*Figure 13**.3* highlights four different DR strategies in the cloud, as highlighted
    in the AWS white paper for DR: [https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html](https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html).'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 13.3* 突出了 AWS 白皮书中提到的四种不同的云灾难恢复策略：[https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html](https://docs.aws.amazon.com/whitepapers/latest/disaster-recovery-workloads-on-aws/disaster-recovery-options-in-the-cloud.html)。'
- en: As we move from backup and restore to multi-site active/active, the RPO and
    RTO time shrinks from hours to minutes. However, complexity, orchestration, and
    cloud spend increase.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们从备份和恢复转向多站点的主动/主动模式，RPO（恢复点目标）和RTO（恢复时间目标）从小时缩短到分钟。然而，复杂性、编排和云支出却增加了。
- en: Choose a DR strategy based on the business application’s uptime requirements
    and use case.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 根据业务应用的正常运行时间需求和用例选择灾难恢复策略。
- en: '![Figure 13.3 – Disaster recovery strategies](img/B31108_13_3.jpg)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![图 13.3 – 灾难恢复策略](img/B31108_13_3.jpg)'
- en: Figure 13.3 – Disaster recovery strategies
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13.3 – 灾难恢复策略
- en: 'Let’s explore a high-level perspective on architecting these DR strategies
    in K8s environments:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个高层次的角度来探索在 K8s 环境中架构这些灾难恢复（DR）策略：
- en: '**Backup and restore** (**RPO/RTO time in hours**): In K8s, backup and restore
    strategies are essential for lower-priority workloads where some downtime is acceptable.
    This approach involves periodically backing up data stored in **PersistentVolumes**
    (**PVs**) and other cluster resources such as **ConfigMaps**, **Secrets**, and
    **role-based access control** (**RBAC**) policies. During a disaster, all K8s
    resources must be provisioned again, and the backed-up data is restored. This
    method is cost-effective but results in longer recovery times, as restoring backups
    and re-provisioning the cluster can take hours. While this approach is viable
    for non-mission-critical applications, it does not meet the HA needs of production
    workloads.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**备份和恢复**（**RPO/RTO 时间为小时**）：在 K8s 中，备份和恢复策略对于一些可以接受停机的低优先级工作负载至关重要。这种方法涉及定期备份存储在
    **PersistentVolumes**（**PVs**）中的数据，以及其他集群资源，如 **ConfigMaps**、**Secrets** 和 **基于角色的访问控制**（**RBAC**）策略。在灾难发生时，所有
    K8s 资源必须重新配置，并且备份的数据会被恢复。该方法具有成本效益，但恢复时间较长，因为恢复备份和重新配置集群可能需要几个小时。尽管这种方法对于非关键应用程序是可行的，但它无法满足生产工作负载对高可用性的需求。'
- en: Open source tools such as **Velero** ([https://velero.io/](https://velero.io/))
    and commercial solutions such as **Trilio for Kubernetes** ([https://trilio.io/products/kubernetes-backup-and-recovery/](https://trilio.io/products/kubernetes-backup-and-recovery/))
    and **Portworx Backup** ([https://portworx.com/kubernetes-backup/](https://portworx.com/kubernetes-backup/))
    provide automated backup and restore capabilities.
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 开源工具如**Velero** ([https://velero.io/](https://velero.io/))，以及商业解决方案如**Trilio
    for Kubernetes** ([https://trilio.io/products/kubernetes-backup-and-recovery/](https://trilio.io/products/kubernetes-backup-and-recovery/))
    和**Portworx Backup** ([https://portworx.com/kubernetes-backup/](https://portworx.com/kubernetes-backup/))，提供自动化的备份和恢复功能。
- en: Velero is an open source backup and restore solution designed for K8s workloads.
    It supports cloud-native environments, including AWS, Azure, and Google Cloud.
    Velero allows on-demand and scheduled backups of K8s clusters, covering Pods,
    deployments, and persistent volumes. It allows namespace-level and full-cluster
    backups, providing fine-grained control over data protection. One of Velero’s
    strengths is its DR and cluster migration capabilities. Its scheduling features
    allow users to define periodic backups using cron-based scheduling, ensuring compliance
    with recovery and data retention policies. The tool is designed for multi-cloud
    environments, making it easier to implement hybrid cloud strategies. Additionally,
    Velero supports encryption for secure backup storage and uses RBAC to enforce
    security best practice.
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Velero 是一个开源的备份和恢复解决方案，专为 K8s 工作负载设计。它支持云原生环境，包括 AWS、Azure 和 Google Cloud。Velero
    允许按需和定期备份 K8s 集群，涵盖 Pods、部署和持久化存储卷。它支持命名空间级别和全集群备份，提供对数据保护的精细控制。Velero 的一大优势是其灾难恢复（DR）和集群迁移能力。其调度功能允许用户通过基于
    cron 的调度定义定期备份，确保遵守恢复和数据保留策略。该工具旨在支持多云环境，简化了混合云策略的实施。此外，Velero 支持加密以确保备份存储的安全，并通过
    RBAC 强制执行安全最佳实践。
- en: Besides data, it’s also essential to restore the cluster configuration, Secrets,
    and RBAC policies. These configurations can either be backed up using the same
    tooling or deployed using **infrastructure as code** (**IaC**) or **GitOps** ([https://about.gitlab.com/topics/gitops/](https://about.gitlab.com/topics/gitops/))
    tools. This enables the quick restoration of a K8s environment in case of failure.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 除了数据外，恢复集群配置、Secrets 和 RBAC 策略同样至关重要。这些配置可以通过相同的工具进行备份，或者通过**基础设施即代码**（**IaC**）或**GitOps**
    ([https://about.gitlab.com/topics/gitops/](https://about.gitlab.com/topics/gitops/))
    工具进行部署。这使得在发生故障时可以快速恢复 K8s 环境。
- en: '**Pilot light (RPO/RTO: 10s of minutes)**: The pilot light strategy keeps essential
    data and minimal K8s infrastructure live while leaving most services idle until
    a disaster occurs. This allows for quicker recovery compared to backup and restore,
    as some resources are already running and do not need to be provisioned from scratch.
    Persistent storage remains active, ensuring that stateful applications retain
    their critical data. However, the remaining workloads, such as application services
    and networking configurations, only become active when a failure is detected.
    This approach strikes a balance between cost and recovery speed by requiring only
    a fraction of the resources to be continuously available. Tools such as Velero,
    which support namespace-level and cluster-scoped backups, enable this setup by
    ensuring that key K8s objects and data are readily available for rapid scaling
    when needed.'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pilot light（RPO/RTO：几分钟）**：Pilot light 策略通过保持关键数据和最小的 K8s 基础设施持续运行，而将大部分服务保持空闲，直到发生灾难。这与备份和恢复相比，可以更快地恢复，因为一些资源已经在运行，无需从头开始部署。持久化存储保持活动状态，确保有状态应用程序保留其关键数据。然而，其他工作负载，如应用服务和网络配置，仅在检测到故障时才会变得活跃。这种方法通过只需持续提供一小部分资源，平衡了成本和恢复速度。像
    Velero 这样的工具，支持命名空间级别和集群范围的备份，通过确保关键的 K8s 对象和数据随时可用，从而支持快速扩展需求。'
- en: '**Warm standby (RPO/RTO: minutes)**: A warm standby configuration ensures that
    a smaller-scale version of the production environment is always running, reducing
    recovery time to minutes. This approach is best suited for business-critical applications
    where downtime must be minimal, but maintaining a full-scale duplicate environment
    would be cost-prohibitive. The warm standby cluster continuously runs with scaled-down
    replicas of workloads, allowing immediate failover and rapid horizontal scaling
    when a disaster occurs. Additionally, real-time data replication solutions such
    as Portworx and Trilio for Kubernetes keep persistent storage synchronized across
    clusters, ensuring data consistency. This approach significantly reduces downtime
    while maintaining cost efficiency compared to a fully active environment.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**冷备份（RPO/RTO：几分钟）**：冷备份配置确保生产环境的较小规模版本始终运行，将恢复时间缩短到几分钟。这种方法最适合业务关键的应用程序，其中必须将停机时间保持最小化，但维护全面复制环境将成本过高。冷备份集群持续运行，使用工作负载的缩减副本，允许在发生灾难时进行即时故障转移和快速的水平扩展。此外，用于Kubernetes的实时数据复制解决方案（如Portworx和Trilio）保持集群之间的持久存储同步，确保数据一致性。与完全主动环境相比，这种方法显著降低了停机时间，同时保持成本效益。'
- en: '**Multi-site active/active (RPO/RTO: near real time)**: The multi-site active/active
    strategy offers the highest level of resilience by running multiple K8s clusters
    in different regions or cloud providers in real time. This setup ensures zero
    downtime and near-zero data loss, making it ideal for mission-critical services
    that demand continuous availability. Unlike other approaches, this strategy requires
    full redundancy, meaning that all workloads and data are replicated and running
    across multiple clusters simultaneously. Cross-region cluster deployment and cloud
    load balancers dynamically distribute traffic, ensuring seamless operation even
    if one cluster experiences an outage. Service mesh solutions such as **Istio**
    facilitate secure communication between clusters, while database replication strategies
    keep persistent data synchronized. Though this strategy incurs significant infrastructure
    costs, it provides the most reliable DR solution for organizations that cannot
    afford any service disruptions.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多地点主/活动（RPO/RTO：几乎实时）**：多地点主/活动策略通过在不同区域或云提供商中实时运行多个K8s集群，提供了最高级别的弹性。这种设置确保零停机和几乎零数据丢失，非常适合需要连续可用性的关键服务。与其他方法不同，该策略需要完全的冗余，意味着所有工作负载和数据都同时在多个集群中复制和运行。跨区域集群部署和云负载均衡器动态分配流量，即使一个集群发生故障，也能确保无缝运行。诸如**Istio**之类的服务网格解决方案促进集群之间的安全通信，而数据库复制策略保持持久数据同步。尽管这种策略会产生显著的基础设施成本，但对于那些不能承受任何服务中断的组织来说，它提供了最可靠的灾难恢复解决方案。'
- en: Let’s consider a scenario where you have a GenAI application running in the
    AWS US-EAST-1 Region, which is your primary region. To ensure HA, you maintain
    a warm standby cluster in the US-WEST-2 region with a minimal compute footprint.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在AWS US-EAST-1地区运行一个GenAI应用程序，这是你的主要区域。为了确保高可用性，你在US-WEST-2地区维护了一个冷备份集群，具有最小的计算占用。
- en: 'In the event of a regional outage in US-EAST-1, the following steps detail
    how the failover process would occur:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在US-EAST-1发生区域性故障时，以下步骤详细描述了故障转移过程的发生方式：
- en: Cloud monitoring, such as Amazon Route 53 health checks and CloudWatch alarms,
    detects that services in US-EAST-1 are unavailable. Application-level readiness
    and liveness probes start failing, indicating service degradation.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云监控，例如Amazon Route 53健康检查和CloudWatch警报，检测到US-EAST-1地区的服务不可用。应用程序级别的就绪性和存活性探测开始失败，表明服务出现了降级。
- en: DNS failover mechanisms, such as the **Amazon Route 53 failover routing** ([https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-failover.html](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-failover.html))
    policy, automatically redirect traffic to the US-WEST-2 standby cluster.
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DNS故障转移机制，例如**Amazon Route 53故障转移路由**（[https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-failover.html](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/routing-policy-failover.html)）策略，自动将流量重定向到US-WEST-2备用集群。
- en: HPA/Cluster Autoscaler in the standby cluster triggers scale-up events. GenAI
    application endpoints and underlying worker nodes scale out to handle the production
    load.
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在备用集群中，HPA/集群自动缩放器触发了扩展事件。GenAI应用程序的端点和底层工作节点扩展以处理生产负载。
- en: The standby cluster switches from passive to active mode, serving production
    traffic.
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 备用集群从被动模式切换到活动模式，提供生产流量服务。
- en: Once US-EAST-1 is available again, evaluate data integrity and sync any missed
    transactions or logs. Once resynced, demote US-WEST-2 back to standby mode and
    resume normal operations in the primary region.
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一旦 US-EAST-1 区域恢复，评估数据完整性并同步任何错过的事务或日志。重新同步后，将 US-WEST-2 区域恢复为待命模式，并在主区域恢复正常操作。
- en: Additional K8s DR considerations
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外的 K8s 灾难恢复（DR）考虑事项
- en: 'In this section, we explore the importance of automating DR using chaos engineering
    to validate the system’s resilience and implementing proactive monitoring to detect
    outages early:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了利用混沌工程自动化灾难恢复、验证系统韧性的重要性，以及实施主动监控以早期检测故障的必要性：
- en: '**DR automation and testing**: Automating DR processes significantly reduces
    human error and accelerates recovery times. Using IaC tools such as Terraform
    ensures that K8s clusters can be redeployed quickly and consistently in the event
    of an outage. Automated failover solutions, such as Amazon Route 53 health checks,
    detect failures and reroute traffic to healthy instances automatically. To validate
    DR readiness, organizations should regularly conduct DR testing and drills.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灾难恢复自动化与测试**：自动化灾难恢复流程显著减少了人为错误并加速了恢复时间。使用基础设施即代码（IaC）工具，如 Terraform，确保在发生故障时
    K8s 集群能够快速且一致地重新部署。自动故障转移解决方案，如 Amazon Route 53 健康检查，可以检测故障并自动将流量重定向到健康实例。为了验证灾难恢复的准备情况，组织应定期进行灾难恢复测试和演练。'
- en: Chaos engineering tools include **Chaos Mesh** ([https://chaos-mesh.org/](https://chaos-mesh.org/)),
    a cloud-native, open source K8s chaos engineering platform that allows users to
    simulate various failure scenarios within K8s clusters. It supports fine-grained
    chaos experiments at multiple levels, including the Pod, network, and storage
    levels. It can inject Pod failures, network disruptions, and node crashes in K8s
    Deployment. It also supports **CustomResourceDefinition** (**CRDs**) to define
    chaos experiments declaratively.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 混沌工程工具包括 **Chaos Mesh**（[https://chaos-mesh.org/](https://chaos-mesh.org/)），一个云原生的开源
    K8s 混沌工程平台，允许用户在 K8s 集群内模拟各种故障场景。它支持在多个层级（如 Pod、网络和存储层）进行精细化的混沌实验。它可以注入 Pod 故障、网络中断和节点崩溃到
    K8s 部署中。它还支持 **CustomResourceDefinition** (**CRD**) 来声明式地定义混沌实验。
- en: '**Monitoring and observability**: Proactive monitoring and observability help
    detect issues before they escalate into major outages. K8s provides built-in health
    checks through liveness and readiness probes, which restart unhealthy Pods to
    prevent failures from impacting the entire system. Logging and metrics collection
    tools such as Prometheus, Grafana, Fluentd, and Elasticsearch enable real-time
    visibility into cluster performance and system health. Implementing an alerting
    system integrated with PagerDuty or Slack ensures that incidents trigger immediate
    notifications, allowing response teams to act quickly and mitigate potential disruptions.
    A well-configured observability stack is crucial for diagnosing issues and optimizing
    DR strategies.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控与可观测性**：主动的监控和可观测性有助于在问题升级为重大故障之前及时发现。K8s 提供了通过活性和就绪探针进行的内置健康检查，能够重新启动不健康的
    Pod，防止故障影响整个系统。日志和度量收集工具，如 Prometheus、Grafana、Fluentd 和 Elasticsearch，使集群性能和系统健康状况的实时可见性成为可能。实现与
    PagerDuty 或 Slack 集成的告警系统确保事故触发即时通知，帮助响应团队迅速采取行动，减轻潜在的中断。配置良好的可观测性堆栈对于诊断问题和优化灾难恢复策略至关重要。'
- en: Summary
  id: totrans-81
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the key concepts for HA and DR for GenAI applications
    deployed on K8s. Given the resource-intensive nature of GenAI workloads, it is
    critical to have scalability and resilience against hardware failures and regional
    outages.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了部署在 K8s 上的 GenAI 应用程序的高可用性（HA）和灾难恢复（DR）关键概念。鉴于 GenAI 工作负载对资源的高度依赖，确保在硬件故障和区域性停机事件中具有可扩展性和韧性至关重要。
- en: HA minimizes downtime by eliminating single points of failure through redundancy
    across nodes, clusters, and regions. Key HA strategies in K8s include auto-scaling,
    self-healing, multi-cluster deployments, and load balancing.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 高可用性（HA）通过在节点、集群和区域之间的冗余消除单点故障，从而最大限度地减少停机时间。K8s 中的主要 HA 策略包括自动扩展、自愈、多集群部署和负载均衡。
- en: DR focuses on restoring services after failures such as hardware malfunctions,
    cyberattacks, and natural disasters. Key DR metrics include RPO, RTO, and MTD.
    Various DR strategies include backup and restore (slow recovery but cost-effective),
    pilot light (minimal infrastructure remaining active for quicker recovery), warm
    standby (scaled-down live environment that quickly scales up), and multi-site
    active/active deployment (fully redundant clusters ensuring near-zero downtime).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: DR专注于在硬件故障、网络攻击和自然灾害等故障发生后恢复服务。关键的DR指标包括RPO、RTO和MTD。各种DR策略包括备份与恢复（恢复速度慢但具有成本效益）、飞行器灯（保持最小基础设施活跃以便更快恢复）、温备（缩小规模的实时环境，能够快速扩展）和多站点活动/活动部署（完全冗余集群，确保接近零的停机时间）。
- en: Additionally, chaos engineering, automation, monitoring, and observability are
    crucial for enhancing HA and DR.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，混沌工程、自动化、监控和可观察性对于增强HA和DR至关重要。
- en: In the next chapter, we will cover a few other advanced GenAI topics related
    to K8s.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍与K8s相关的其他一些高级GenAI主题。
