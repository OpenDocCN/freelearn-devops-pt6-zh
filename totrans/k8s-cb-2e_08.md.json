["```\n// you can also get this file through code bundle\n$ cat additional-kubeadm-config\napiVersion: kubeadm.k8s.io/v1alpha1\nkind: MasterConfiguration\napiServerExtraArgs:\n  insecure-bind-address: \"0.0.0.0\"\n  insecure-port: \"8080\"\n// start cluster with additional system settings\n$ sudo kubeadm init --config ./additional-kubeadm-config\n```", "```\n// on localhost cluster, the following commands should be successful\n$ curl http://localhost:8080\n$ curl http://$REMOTE_MASTER_NODE:8080\n```", "```\n// the settings created by kubeadm\n$ kubectl config view\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: REDACTED\n    server: https://192.168.122.101:6443\n  name: kubernetes\ncontexts:\n- context:\n    cluster: kubernetes\n    user: kubernetes-admin\n  name: kubernetes-admin@kubernetes\ncurrent-context: kubernetes-admin@kubernetes kind: Config\npreferences: {}\nusers:\n- name: kubernetes-admin\n  user:\n    client-certificate-data: REDACTED\n    client-key-data: REDACTED\n```", "```\n// in default, the kubeconfig used by client is the one under $HOME\n$ cp ~/.kube/config ~/original-kubeconfig\n```", "```\n// in the terminal of localhost cluster\n$ kubectl run local-nginx --image=nginx --replicas=2 --port=80\ndeployment \"local-nginx\" created\n// check the running pods\n$ kubectl get pod\nNAME                           READY     STATUS    RESTARTS   AGE\nlocal-nginx-6484bbb57d-xpjp2   1/1       Running   0          1m\nlocal-nginx-6484bbb57d-z4qgp   1/1       Running   0          1m\n// in the terminal of remote cluster\n$ kubectl run remote-nginx --image=nginx --replicas=4 --port=80\ndeployment \"remote-nginx\" created\n$ kubectl get pod\nNAME                            READY     STATUS    RESTARTS   AGE\nremote-nginx-5dd7b9cb7d-fxr9m   1/1       Running   0          29s\nremote-nginx-5dd7b9cb7d-gj2ft   1/1       Running   0          29s\nremote-nginx-5dd7b9cb7d-h7lmj   1/1       Running   0          29s\nremote-nginx-5dd7b9cb7d-hz766   1/1       Running   0          29s\n```", "```\n// check the details of setting up credentials\n$ kubectl config set-credentials -h\n// in localhost cluster, copy the based file into a new one\n$ cp ~/original-kubeconfig ~/new-kubeconfig\n// add a user \"user-local\" with credential named \"myself@localhost\" in kubeconfig \"new-kubeconfig\"\n$ kubectl config set-credentials myself@localhost --username=user-local --password=passwordlocal --kubeconfig=\"new-kubeconfig\"\nUser \"myself@local\" set.\n```", "```\n// renew live kubeconfig file with previous update\n$ cp ~/new-kubeconfig ~/.kube/config\n// add another credential in localhost cluster, this time, let's update current settings directly\n$ kubectl config set-credentials myself@remote --username=user-remote --password=passwordremote\nUser \"myself@remote\" set.\n```", "```\n$ kubectl config view\n...\nusers:\n- name: myself@local\n  user:\n    password: passwordlocal\n    username: user-local\n- name: myself@remote\n  user:\n    password: passwordremote\n    username: user-remote\n```", "```\n// in localhost cluster, create a cluster information pointing to itself\n $ kubectl config set-cluster local-cluster --insecure-skip-tls-verify=true --server=http://localhost:8080\n Cluster \"local-cluster\" set.\n // another cluster information is about the remote one\n $ kubectl config set-cluster remote-cluster --insecure-skip-tls-verify=true --server=http://$REMOTE_MASTER_NODE:8080\n Cluster \"remote-cluster\" set.\n // check kubeconfig in localhost cluster, in this example, the remote master node has the hostname \"node01\"\n $ kubectl config view\n apiVersion: v1\n clusters:\n ...\n - cluster:\n     insecure-skip-tls-verify: true\n     server: http://localhost:8080\n   name: local-cluster\n - cluster:\n     insecure-skip-tls-verify: true\n     server: http://node01:8080\n   name: remote-cluster\n ...\n```", "```\n// in localhost cluster, create a context for accessing local cluster's default namespace\n$ kubectl config set-context default/local/myself --user=myself@local --namespace=default --cluster=local-cluster\nContext \"default/local/myself\" created.\n// furthermore, create another context for remote cluster\n$ kubectl config set-context default/remote/myself --user=myself@remote --namespace=default --cluster=remote-cluster\nContext \"default/remote/myself\" created.\n```", "```\n$ kubectl config view\n...\ncontexts:\n- context:\n    cluster: local-cluster\n    namespace: default\n    user: myself@local\n  name: default/local/myself\n- context:\n    cluster: remote-cluster\n    namespace: default\n    user: myself@remote\n  name: default/remote/myself\n...\n```", "```\n// check current context\n$ kubectl config current-context\nkubernetes-admin@kubernetes\n\n// use the new local context instead\n$ kubectl config use-context default/local/myself\nSwitched to context \"default/local/myself\".\n// check resource for the status of context\n$ kubectl get pod\nNAME                           READY     STATUS    RESTARTS   AGE\nlocal-nginx-6484bbb57d-xpjp2   1/1       Running   0          2h\nlocal-nginx-6484bbb57d-z4qgp   1/1       Running   0          2h\n```", "```\n// switch to the context of remote cluster\n$ kubectl config use-context default/remote/myself\nSwitched to context \"default/remote/myself\".\n// check the pods\n$ kubectl get pod\nNAME                            READY     STATUS    RESTARTS   AGE\nremote-nginx-5dd7b9cb7d-fxr9m   1/1       Running   0          2h\nremote-nginx-5dd7b9cb7d-gj2ft   1/1       Running   0          2h\nremote-nginx-5dd7b9cb7d-h7lmj   1/1       Running   0          2h\nremote-nginx-5dd7b9cb7d-hz766   1/1       Running   0          2h\n```", "```\n// delete the customized local context\n$ kubectl config delete-cluster local-cluster\ndeleted cluster local-cluster from $HOME/.kube/config\n\n// unset the local user\n// to remove cluster, using property clusters.CLUSTER_NAME; to remove contexts, using property contexts.CONTEXT_NAME\n$ kubectl config unset users.myself@local\nProperty \"users.myself@local\" unset.\n```", "```\n// remove all of our practices\n$ cp ~/original-kubeconfig ~/.kube/config\n// check your kubeconfig to make sure it has been cleaned\n$ kubectl config view\n```", "```\n$ kubectl create namespace chap8-no-qos\nnamespace \"chap8-no-qos\" created\n\n$ kubectl create namespace chap8-qos\nnamespace \"chap8-qos\" created\n```", "```\n$ cat resource-request-cpu.yml\napiVersion: v1\nkind: LimitRange\nmetadata:\n  name: resource-request-cpu\nspec:\n  limits:\n  - defaultRequest:\n cpu: 0.1\n    type: Container\n```", "```\n$ kubectl create -f resource-request-cpu.yml --namespace=chap8-qos\nlimitrange \"resource-request-cpu\" created\n```", "```\n//chap8-no-qos doesn't have any resource limits value\n$ kubectl describe namespaces chap8-no-qos\nName:         chap8-no-qos\nLabels:       <none>\nAnnotations:  <none>\nStatus:       Active\nNo resource quota.\nNo resource limits.\n\n//chap8-qos namespace has a resource limits value\n$ kubectl describe namespaces chap8-qos\nName:         chap8-qos\nLabels:       <none>\nAnnotations:  <none>\nStatus:       Active\nNo resource quota.\nResource Limits\n Type       Resource  Min  Max  Default Request  Default Limit  Max Limit/Request Ratio\n ----       --------  ---  ---  ---------------  -------------  -----------------------\n Container  cpu       -    -    100m             -              -\n```", "```\n$ cat besteffort-explicit.yml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: besteffort\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n cpu: 0\n memory: 0\n```", "```\n$ kubectl create -f besteffort-explicit.yml --namespace=chap8-qos\npod \"besteffort\" created\n\n$ kubectl create -f besteffort-explicit.yml --namespace=chap8-no-qos\npod \"besteffort\" created\n```", "```\n$ kubectl describe pods besteffort --namespace=chap8-qos | grep QoS\nQoS Class:       BestEffort\n\n$ kubectl describe pods besteffort --namespace=chap8-no-qos | grep QoS\nQoS Class:       BestEffort\n```", "```\n$ kubectl delete pod --all --namespace=chap8-qos\npod \"besteffort\" deleted\n\n$ kubectl delete pod --all --namespace=chap8-no-qos\npod \"besteffort\" deleted\n```", "```\n$ cat besteffort-implicit.yml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: besteffort\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n```", "```\n$ kubectl create -f besteffort-implicit.yml --namespace=chap8-qos\npod \"besteffort\" created\n\n$ kubectl create -f besteffort-implicit.yml --namespace=chap8-no-qos\npod \"besteffort\" created\n```", "```\n$ kubectl describe pods besteffort --namespace=chap8-no-qos |grep QoS\nQoS Class:       BestEffort\n\n$ kubectl describe pods besteffort --namespace=chap8-qos |grep QoS\nQoS Class:       Burstable\n```", "```\n$ cat guaranteed.yml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: guaranteed-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      limits:\n cpu: 0.3\n memory: 350Mi\n requests:\n cpu: 0.3\n memory: 350Mi\n```", "```\n$ kubectl create -f guaranteed.yml --namespace=chap8-no-qos\npod \"guaranteed-pod\" created\n```", "```\n$ kubectl describe pods guaranteed-pod --namespace=chap8-no-qos |grep QoS\nQoS Class:       Guaranteed\n```", "```\n$ cat burstable.yml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: burstable-pod\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    resources:\n      requests:\n cpu: 0.1\n memory: 10Mi\n limits:\n cpu: 0.5\n memory: 300Mi\n```", "```\n$ kubectl create -f burstable.yml --namespace=chap8-no-qos\npod \"burstable-pod\" created\n```", "```\n$ kubectl describe pods burstable-pod --namespace=chap8-no-qos |grep QoS\nQoS Class:       Burstable\n```", "```\n//Find a node name\n$ kubectl get nodes\nNAME       STATUS    ROLES     AGE       VERSION\nminikube   Ready     <none>    22h       v1.9.0\n\n//Specify node name 'minikube' \n$ kubectl describe nodes minikube\nName:               minikube\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n...\n...\nAllocatable:\n cpu:     2 memory:  1945652Ki pods:    110\n```", "```\n// check if minikube runs well\n$ minikube status\nminikube: Running\ncluster: Running\nkubectl: Correctly Configured: pointing to minikube-vm at 192.168.99.100\n// check the Kubernetes system by components\n$ kubectl get cs\nNAME                 STATUS    MESSAGE              ERROR\nscheduler            Healthy   ok\ncontroller-manager   Healthy   ok\netcd-0               Healthy   {\"health\": \"true\"}\n```", "```\n$ minikube dashboard\nOpening kubernetes dashboard in default browser...\n```", "```\n$ kubectl create -f\nhttps://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml\nsecret \"kubernetes-dashboard-certs\" created\nserviceaccount \"kubernetes-dashboard\" created\nrole \"kubernetes-dashboard-minimal\" created\nrolebinding \"kubernetes-dashboard-minimal\" created\ndeployment \"kubernetes-dashboard\" created\nservice \"kubernetes-dashboard\" created\n```", "```\n$ kubectl proxy\nStarting to serve on 127.0.0.1:8001\n```", "```\n// check the service account in your system\n$ kubectl get secret -n kube-system\nNAME                               TYPE                                  DATA      AGE\ndefault-token-7jfmd                kubernetes.io/service-account-token   3         51d\nkubernetes-dashboard-certs         Opaque                                0         2d\nkubernetes-dashboard-key-holder    Opaque                                2         51d\nkubernetes-dashboard-token-jw42n   kubernetes.io/service-account-token   3         2d\n// grabbing token by checking the detail information of the service account with prefix \"kubernetes-dashboard-token-\"\n$ kubectl describe secret kubernetes-dashboard-token-jw42n -n kube-system\nName:         kubernetes-dashboard-token-jw42n\nNamespace:    kube-system\nLabels:       <none>\nAnnotations:  kubernetes.io/service-account.name=kubernetes-dashboard\n              kubernetes.io/service-account.uid=253a1a8f-210b-11e8-b301-8230b6ac4959\nType:  kubernetes.io/service-account-token\nData\n====\nca.crt:     1066 bytes\nnamespace:  11 bytes\ntoken:     \neyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Ii....\n```", "```\n// the configuration file for creating Deployment and Service on new Namespace: dashboard-test\n$ cat my-nginx.yaml\napiVersion: apps/v1beta2\nkind: Deployment\nmetadata:\n  name: my-nginx\n  namespace: dashboard-test\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      run: demo\n  template:\n    metadata:\n      labels:\n        run: demo\n    spec:\n      containers:\n      - name: my-container\n        image: nginx\n        ports:\n        - containerPort: 80\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-nginx\n  namespace: dashboard-test\nspec:\n  ports:\n    - protocol: TCP\n      port: 80\n  type: NodePort\n  selector:\n    run: demo\n```", "```\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: dashboard-test\n```", "```\n//curl by API endpoint\n$ kubectl proxy\nStarting to serve on 127.0.0.1:8001\n```", "```\n$ kubectl proxy &\n[1] 6372\nStarting to serve on 127.0.0.1:8001\n```", "```\n$ kill -j9 6372\n```", "```\n$ curl http://127.0.0.1:8001/api\n{\n  \"kind\": \"APIVersions\",\n  \"versions\": [\n    \"v1\"\n  ],\n  \"serverAddressByClientCIDRs\": [\n    {\n      \"clientCIDR\": \"0.0.0.0/0\",\n      \"serverAddress\": \"10.0.2.15:8443\"\n    }\n  ]\n}\n```", "```\n$ APISERVER=$(kubectl config view | grep server | cut -f 2- -d \":\" | tr -d \" \")\n// get the token of default service account\n$ TOKEN=$(kubectl get secret --field-selector type=kubernetes.io/service-account-token -o name | grep default-token- | head -n 1 | xargs kubectl get -o 'jsonpath={.data.token}' | base64 -d)\n$ curl $APISERVER/api -H \"Authorization: Bearer $TOKEN\" --insecure\n```", "```\n$ curl $APISERVER/api/v1/namespaces/default/services -H \"Authorization: Bearer $TOKEN\" --insecure\n...\n \"status\": \"Failure\",\n \"message\": \"services is forbidden: User \\\"system:serviceaccount:default:default\\\" cannot list services in the namespace \\\"default\\\"\",\n \"reason\": \"Forbidden\",\n...\n$ kubectl create -f rbac.yaml\nclusterrolebinding \"fabric8-rbac\" created\n// now the API request is successful\n$ curl $APISERVER/api/v1/namespaces/default/services -H \"Authorization: Bearer $TOKEN\" --insecure\n{\n   \"kind\": \"ServiceList\",\n   \"apiVersion\": \"v1\",\n   \"metadata\": {\n      \"selfLink\": \"/api/v1/namespaces/default/services\",\n      \"resourceVersion\": \"291954\"\n    },\n...\n```", "```\n$ cat nginx-deployment.json\n{\n  \"apiVersion\": \"apps/v1\",\n  \"kind\": \"Deployment\",\n  \"metadata\": {\n    \"name\": \"my-nginx\"\n  },\n  \"spec\": {\n    \"replicas\": 2,\n       \"selector\": {\n      \"matchLabels\": {\n        \"app\": \"nginx\"\n      }\n    },\n    \"template\": {\n      \"metadata\": {\n        \"labels\": {\n          \"app\": \"nginx\"\n        }\n      },\n      \"spec\": {\n        \"containers\": [\n          {\n            \"image\": \"nginx\",\n            \"name\": \"my-nginx\"\n          }\n        ]\n      }\n    }\n  }\n}\n```", "```\n$ curl -X POST -H \"Content-type: application/json\" -d @nginx-deployment.json http://localhost:8001/apis/apps/v1/namespaces/default/deployments\n{\n  \"kind\": \"Deployment\",\n  \"apiVersion\": \"apps/v1\",\n  \"metadata\": {\n    \"name\": \"my-nginx\",\n    \"namespace\": \"default\",\n    \"selfLink\": \"/apis/apps/v1/namespaces/default/deployments/my-nginx\",\n    \"uid\": \"6eca324e-2cc8-11e8-806a-080027b04dc6\",\n    \"resourceVersion\": \"209\",\n    \"generation\": 1,\n    \"creationTimestamp\": \"2018-03-21T05:26:39Z\",\n    \"labels\": {\n      \"app\": \"nginx\"\n    }\n  },\n...\n```", "```\n$ kubectl get deployment\nNAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nmy-nginx   2         2         2            2           1m\n```", "```\n// the operation \"-X GET\" can be ignored, since\n$ curl -X GET http://localhost:8001/apis/apps/v1/namespaces/default/deployments\n```", "```\n$ curl -X DELETE http://localhost:8001/apis/apps/v1/namespaces/default/deployments/my-nginx\n{\n  \"kind\": \"Status\",\n  \"apiVersion\": \"v1\",\n  \"metadata\": {\n  },\n  \"status\": \"Success\",\n  \"details\": {\n    \"name\": \"my-nginx\",\n    \"group\": \"apps\",\n    \"kind\": \"deployments\",\n    \"uid\": \"386a3aaa-2d2d-11e8-9843-080027b04dc6\"\n  }\n}\n```", "```\n$ pip install kubernetes\n```", "```\n$ cat create_deployment.py\nfrom kubernetes import client, config\nimport json\nconfig.load_kube_config()\nresource_config = json.load(open(\"./nginx-deployment.json\"))\napi_instance = client.AppsV1Api()\nresponse = api_instance.create_namespaced_deployment(body=resource_config, namespace=\"default\")\nprint(\"success, status={}\".format(response.status))\n```", "```\n$ python create_deployment.py\n```", "```\n$ kubectl get deploy kube-dns --namespace=kube-system\nNAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nkube-dns   1         1         1            1           1d\n```", "```\n$ minikube addons list |grep kube-dns\n- kube-dns: enabled\n```", "```\n$ minikube addons enable kube-dns\n```", "```\n$ kubectl create namespace chap8-domain1\nnamespace \"chap8-domain1\" created\n\n$ kubectl create namespace chap8-domain2\nnamespace \"chap8-domain2\" created\n\n//check chap8-domain1 and chap8-domain2\n$ kubectl get namespaces\nNAME            STATUS    AGE\nchap8-domain1   Active    16s\nchap8-domain2 Active    14s\ndefault         Active    4h\nkube-public     Active    4h\nkube-system     Active    4h \n```", "```\n$ kubectl run my-apache --image=httpd --namespace chap8-domain1\ndeployment \"my-apache\" created\n\n$ kubectl run my-apache --image=httpd --namespace chap8-domain2\ndeployment \"my-apache\" created\n```", "```\n$ kubectl get pods -o wide --namespace=chap8-domain1\nNAME                         READY     STATUS    RESTARTS   AGE       IP           NODE\nmy-apache-55fb679f49-qw58f   1/1       Running   0          27s        172.17.0.4   minikube\n\n$ kubectl get pods -o wide --namespace=chap8-domain2\nNAME                         READY     STATUS    RESTARTS   AGE       IP           NODE\nmy-apache-55fb679f49-z9gsr   1/1       Running   0          26s        172.17.0.5   minikube\n```", "```\n$ kubectl run -it busybox --restart=Never --image=busybox\n```", "```\n# nslookup 172-17-0-4.chap8-domain1.pod.cluster.local\nServer: 10.96.0.10\nAddress 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local\n\nName: 172-17-0-4.chap8-domain1.pod.cluster.local\nAddress 1: 172.17.0.4\n```", "```\n# nslookup 172-17-0-5.chap8-domain2.pod.cluster.local\nServer: 10.96.0.10\nAddress 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local\n\nName: 172-17-0-5.chap8-domain2.pod.cluster.local\nAddress 1: 172.17.0.5\n```", "```\n# exit\n$ kubectl delete pod busybox\npod \"busybox\" deleted\n```", "```\n$ kubectl expose deploy my-apache --namespace=chap8-domain1 --name=my-apache-svc --port=80 --type=ClusterIP\nservice \"my-apache-svc\" exposed\n\n$ kubectl expose deploy my-apache --namespace=chap8-domain2 --name=my-apache-svc --port=80 --type=ClusterIP\nservice \"my-apache-svc\" exposed\n```", "```\n$ kubectl get svc my-apache-svc --namespace=chap8-domain1 \nNAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE\nmy-apache-svc   ClusterIP   10.96.117.206   <none>        80/TCP    32s\n\n$ kubectl get svc my-apache-svc --namespace=chap8-domain2\nNAME            TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE\nmy-apache-svc   ClusterIP   10.105.27.49   <none>        80/TCP    49s\n```", "```\n$ kubectl run -it busybox --restart=Never --image=busybox \n\n```", "```\n//query Normal Service on chap8-domain1\n# nslookup my-apache-svc.chap8-domain1.svc.cluster.local\nServer: 10.96.0.10\nAddress 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local \n\nName: my-apache-svc.chap8-domain1.svc.cluster.local\nAddress 1: 10.96.117.206 my-apache-svc.chap8-domain1.svc.cluster.local\n\n//query Normal Service on chap8-domain2\n# nslookup my-apache-svc.chap8-domain2.svc.cluster.local\nServer: 10.96.0.10\nAddress 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local \n\nName: my-apache-svc.chap8-domain2.svc.cluster.local\nAddress 1: 10.105.27.49 my-apache-svc.chap8-domain2.svc.cluster.local\n```", "```\n# wget -q -O - my-apache-svc.chap8-domain1.svc.cluster.local\n<html><body><h1>It works!</h1></body></html>\n\n# wget -q -O - my-apache-svc.chap8-domain2.svc.cluster.local\n<html><body><h1>It works!</h1></body></html>\n```", "```\n# exit \n$ kubectl delete pod busybox\npod \"busybox\" deleted\n```", "```\n$ cat nginx-sts.yaml \napiVersion: v1\nkind: Service\nmetadata:\n  name: nginx-sts-svc\n  labels:\n    app: nginx-sts\nspec:\n  ports:\n  - port: 80\n  selector:\n    app: nginx-sts\n---\napiVersion: apps/v1beta1\nkind: StatefulSet\nmetadata:\n  name: nginx-sts\nspec:\n  serviceName: \"nginx-sts-svc\"\n  replicas: 3\n  template:\n    metadata:\n      labels:\n        app: nginx-sts\n    spec:\n      containers:\n        - name: nginx-sts\n          image: nginx\n          ports:\n          - containerPort: 80\n      restartPolicy: Always\n```", "```\n$ kubectl create -f nginx-sts.yaml --namespace=chap8-domain2\nservice \"nginx-sts-svc\" created\nstatefulset \"nginx-sts\" created\n```", "```\n//check StatefulSet (in short sts)\n$ kubectl get sts --namespace=chap8-domain2\nNAME        DESIRED   CURRENT   AGE\nnginx-sts   3         3         46s\n\n//check Service (in short svc)\n$ kubectl get svc nginx-sts-svc --namespace=chap8-domain2\nNAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE\nnginx-sts-svc   ClusterIP   10.104.63.124   <none>        80/TCP    8m \n\n//check Pod with \"-o wide\" to show an IP address\n$ kubectl get pods --namespace=chap8-domain2 -o wide\nNAME                         READY     STATUS    RESTARTS   AGE       IP            NODE\nmy-apache-55fb679f49-z9gsr   1/1       Running   1          22h       172.17.0.4    minikube\nnginx-sts-0                  1/1       Running   0          2m        172.17.0.2    minikube\nnginx-sts-1                  1/1       Running   0          2m        172.17.0.9    minikube\nnginx-sts-2                  1/1       Running   0          1m        172.17.0.10   minikube\n```", "```\n$ kubectl run -it busybox --restart=Never --image=busybox \n```", "```\n# nslookup nginx-sts-svc.chap8-domain2.svc.cluster.local\nServer:    10.96.0.10\nAddress 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local\n\nName:      nginx-sts-svc.chap8-domain2.svc.cluster.local\nAddress 1: 10.104.63.124 nginx-sts-svc.chap8-domain2.svc.cluster.local\n```", "```\n# nslookup nginx-sts-0.nginx-sts-svc.chap8-domain2.svc.cluster.local\nServer:    10.96.0.10\nAddress 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local\nName:      nginx-sts-0.nginx-sts-svc.chap8-domain2.svc.cluster.local\nAddress 1: 172.17.0.2 nginx-sts-0.nginx-sts-svc.chap8-domain2.svc.cluster.local\n\n# nslookup nginx-sts-1.nginx-sts-svc.chap8-domain2.svc.cluster.local\nServer:    10.96.0.10\nAddress 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local\nName:      nginx-sts-1.nginx-sts-svc.chap8-domain2.svc.cluster.local\nAddress 1: 172.17.0.9 nginx-sts-1.nginx-sts-svc.chap8-domain2.svc.cluster.local\n\n# nslookup nginx-sts-2.nginx-sts-svc.chap8-domain2.svc.cluster.local\nServer:    10.96.0.10\nAddress 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local\nName:      nginx-sts-2.nginx-sts-svc.chap8-domain2.svc.cluster.local\nAddress 1: 172.17.0.10 nginx-sts-2.nginx-sts-svc.chap8-domain2.svc.cluster.local\n```", "```\n# exit\n$ kubectl delete pod busybox\npod \"busybox\" deleted\n```", "```\n$ kubectl expose deploy my-apache --namespace=chap8-domain1 --name=my-apache-svc-hl --port=80 --type=ClusterIP --cluster-ip=None\nservice \"my-apache-svc-hl\" exposed\n\n$ kubectl expose deploy my-apache --namespace=chap8-domain2 --name=my-apache-svc-hl --port=80 --type=ClusterIP --cluster-ip=None\nservice \"my-apache-svc-hl\" exposed\n```", "```\n$ kubectl get svc my-apache-svc-hl --namespace=chap8-domain1\nNAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nmy-apache-svc-hl   ClusterIP   None         <none>        80/TCP    13m\n\n$ kubectl get svc my-apache-svc-hl --namespace=chap8-domain2\nNAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE\nmy-apache-svc-hl   ClusterIP   None         <none>        80/TCP    13m\n```", "```\n$ kubectl run -it busybox --restart=Never --image=busybox\n\n```", "```\n# nslookup my-apache-svc-hl.chap8-domain1.svc.cluster.local\nServer: 10.96.0.10\nAddress 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local\n\nName: my-apache-svc-hl.chap8-domain1.svc.cluster.local\nAddress 1: 172.17.0.4 # nslookup my-apache-svc-hl.chap8-domain2.svc.cluster.local\nServer: 10.96.0.10\nAddress 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local\n\nName: my-apache-svc-hl.chap8-domain2.svc.cluster.local\nAddress 1: 172.17.0.5 \n```", "```\n# exit\n$ kubectl delete pod busybox\npod \"busybox\" deleted\n```", "```\n//specify --replicas=3 \n$ kubectl scale deploy my-apache --namespace=chap8-domain1 --replicas=3\ndeployment \"my-apache\" scaled\n\n//Now there are 3 Apache Pods\n$ kubectl get pods --namespace=chap8-domain1 -o wide\nNAME                         READY     STATUS    RESTARTS   AGE       IP           NODE\nmy-apache-55fb679f49-c8wg7   1/1       Running   0          1m        172.17.0.7   minikube\nmy-apache-55fb679f49-cgnj8   1/1       Running   0          1m        172.17.0.8   minikube\nmy-apache-55fb679f49-qw58f   1/1       Running   0          8h       172.17.0.4   minikube\n\n//launch busybox to run nslookup command\n$ kubectl run -it busybox --restart=Never --image=busybox\n\n//query Headless service name\n# nslookup my-apache-svc-hl.chap8-domain1.svc.cluster.local\nServer: 10.96.0.10\n\nAddress 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local\nName: my-apache-svc-hl.chap8-domain1.svc.cluster.local\nAddress 1: 172.17.0.4\nAddress 2: 172.17.0.7\nAddress 3: 172.17.0.8\n\n//quit busybox and release it\n# exit\n$ kubectl delete pod busybox \npod \"busybox\" deleted\n```", "```\n// check default service accoun\n# kubectl describe serviceaccount default\nName:                default\nNamespace:           default\nLabels:              <none>\nAnnotations:         <none>\nImage pull secrets:  <none>\nMountable secrets:   default-token-q4qdh\nTokens:              default-token-q4qdh\nEvents:              <none>\n```", "```\n// configuration file of a ServiceAccount named chapter8-serviceaccount\n# cat serviceaccount.yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: chapter8-serviceaccount\n// create service account\n# kubectl create -f serviceaccount.yaml\nserviceaccount \"chapter8-serviceaccount\" created\n// describe the service account we just created\n# kubectl describe serviceaccount chapter8-serviceaccount\nName:                chapter8-serviceaccount\nNamespace:           default\nLabels:              <none>\nAnnotations:         <none>\nImage pull secrets:  <none>\nMountable secrets:   chapter8-serviceaccount-token-nxh47\nTokens:              chapter8-serviceaccount-token-nxh47\nEvents:              <none>\n```", "```\n// check the details of the secret\n# kubectl get secret chapter8-serviceaccount-token-nxh47 -o yaml\napiVersion: v1\ndata:\n  ca.crt: <base64 encoded>\n  namespace: ZGVmYXVsdA==\n  token: <bearer token, base64 encoded>\nkind: Secret\nmetadata:\n  annotations:\n    kubernetes.io/service-account.name: chapter8-serviceaccount\n    name: chapter8-serviceaccount-token-nxh47\n  namespace: default\n  ...\ntype: kubernetes.io/service-account-token\n```", "```\n# echo \"ZGVmYXVsdA==\" | base64 --decode \ndefault \n```", "```\n// get the decoded token from secret chapter8-serviceaccount-token-nxh47 \n# TOKEN=`echo \"<bearer token, base64 encoded>\" | base64 --decode` \n```", "```\n// get the decoded ca.crt from secret chapter8-serviceaccount-token-nxh47 \n# echo \"<ca.crt, base64 encoded>\" | base64 --decode > cert \n```", "```\n# kubectl config view\napiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: REDACTED\n    server: https://api.demo-k8s.net\n  name: demo-k8s.net\n- cluster:\n    certificate-authority: /Users/chloelee/.minikube/ca.crt\n    server: https://192.168.99.100:8443\n  name: minikube\n...\n```", "```\n# curl --cacert cert https://192.168.99.100:8443/api --header \"Authorization: Bearer $TOKEN\"\n{\n  \"kind\": \"APIVersions\",\n  \"versions\": [\n    \"v1\"\n  ],\n  \"serverAddressByClientCIDRs\": [\n    {\n      \"clientCIDR\": \"0.0.0.0/0\",\n      \"serverAddress\": \"10.0.2.15:8443\"\n    }\n  ]\n}\n```", "```\n# curl --cacert cert https://192.168.99.100:8443/api/v1 --header \"Authorization: Bearer $TOKEN\"\n{\n  \"kind\": \"APIResourceList\",\n  \"groupVersion\": \"v1\",\n  \"resources\": [\n   ...\n   {\n      \"name\": \"configmaps\",\n      \"singularName\": \"\",\n      \"namespaced\": true,\n      \"kind\": \"ConfigMap\",\n      \"verbs\": [\n        \"create\",\n        \"delete\",\n        \"deletecollection\",\n        \"get\",\n        \"list\",\n        \"patch\",\n        \"update\",\n        \"watch\"\n      ],      \n      \"shortNames\": [\"cm\"]\n    }\n  ],  ...\n}\n```", "```\n# curl --cacert cert https://192.168.99.100:8443/api/v1/configmaps --header \"Authorization: Bearer $TOKEN\" |grep \\\"name\\\"\n        \"name\": \"extension-apiserver-authentication\",\n        \"name\": \"ingress-controller-leader-nginx\",\n        \"name\": \"kube-dns\",\n        \"name\": \"nginx-load-balancer-conf\",\n```", "```\n# kubectl get configmaps --all-namespaces\nNAMESPACE     NAME                                 DATA      AGE\nkube-system   extension-apiserver-authentication   6         6d\nkube-system   ingress-controller-leader-nginx      0         6d\nkube-system   kube-dns                             0         6d\nkube-system   nginx-load-balancer-conf             1         6d\n```", "```\n// generate a private key for Linda\n# openssl genrsa -out linda.key 2048\nGenerating RSA private key, 2048 bit long modulus\n..............+++\n..............+++\ne is 65537 (0x10001)\n// generate a certificate sign request (.csr) for Linda. Make sure /CN is equal to the username.\n# openssl req -new -key linda.key -out linda.csr -subj \"/CN=linda\"\n```", "```\n// generate a cert\n# openssl x509 -req -in linda.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out linda.crt -days 30\nSignature ok\nsubject=/CN=linda\nGetting CA Private Key\n```", "```\n# kubectl config set-credentials linda --client-certificate=linda.crt --client-key=linda.key \nUser \"linda\" set. \n```", "```\n# kubectl config view\ncurrent-context: minikube\nkind: Config\nusers:\n  - name: linda\n  user:\n    client-certificate: /k8s-cookbooks-2e/ch8/linda.crt\n    client-key: /k8s-cookbooks-2e/ch8/linda.key\n...\n```", "```\n# kubectl config set-context linda-context --cluster=minikube --user=linda\n```", "```\n# cat client_secret_140285873781-f9h7d7bmi6ec1qa0892mk52t3o874j5d.apps.googleusercontent.com.json\n{\n    \"installed\":{\n        \"client_id\":\"140285873781\nf9h7d7bmi6ec1qa0892mk52t3o874j5d.apps.googleusercontent.com\",\n        \"project_id\":\"kubernetes-cookbook\",\n        \"auth_uri\":\"https://accounts.google.com/o/oauth2/auth\",\n        \"token_uri\":\"https://accounts.google.com/o/oauth2/token\",\n        \"auth_provider_x509_cert_url\":\"https://www.googleapis.com/oauth2/v1/certs\",\n        \"client_secret\":\"Ez0m1L7436mlJQErhalp3Gda\",\n        \"redirect_uris\":[\n            \"urn:ietf:wg:oauth:2.0:oob\",\n            \"http://localhost\"\n        ]\n    }\n}\n```", "```\n// start minikube cluster and passing oidc parameters. \n# minikube start --extra-config=apiserver.Authorization.Mode=RBAC --extra-config=apiserver.Authentication.OIDC.IssuerURL=https://accounts.google.com --extra-config=apiserver.Authentication.OIDC.UsernameClaim=email --extra-config=apiserver.Authentication.OIDC.ClientID=\"140285873781-f9h7d7bmi6ec1qa0892mk52t3o874j5d.apps.googleusercontent.com\" \n```", "```\n// https://accounts.google.com/o/oauth2/v2/auth?client_id=<client_id>&response_type=code&scope=openid%20email&redirect_uri=urn:ietf:wg:oauth:2.0:oob\n# https://accounts.google.com/o/oauth2/v2/auth?client_id=140285873781-f9h7d7bmi6ec1qa0892mk52t3o874j5d.apps.googleusercontent.com&response_type=code&scope=openid%20email&redirect_uri=urn:ietf:wg:oauth:2.0:oob\n```", "```\n// curl -d \"grant_type=authorization_code&client_id=<client_id>&client_secret=<client_secret>&redirect_uri=urn:ietf:wg:oauth:2.0:oob&code=<code>\" -X POST https://www.googleapis.com/oauth2/v4/token\n# curl -d \"grant_type=authorization_code&client_id=140285873781-f9h7d7bmi6ec1qa0892mk52t3o874j5d.apps.googleusercontent.com&client_secret=Ez0m1L7436mlJQErhalp3Gda&redirect_uri=urn:ietf:wg:oauth:2.0:oob&code=4/AAAd5nqWFkpKmxo0b_HZGlcAh57zbJzggKmoOG0BH9gJhfgvQK0iu9w\" -X POST https://www.googleapis.com/oauth2/v4/token\n{\n \"access_token\": \"ya29.GluJBQIhJy34vqJl7V6lPF9YSXmKauvvctjUJHwx72gKDDJikiKzQed9iUnmqEv8gLYg43H6zTSYn1qohkNce1Q3fMl6wbrGMCuXfRlipTcPtZnFt1jNalqMMTCm\",\n \"token_type\": \"Bearer\",\n \"expires_in\": 3600,\n \"refresh_token\": \"1/72xFflvdTRdqhjn70Bcar3qyWDiFw-8KoNm6LdFPorQ\",\n \"id_token\": \"eyJhbGc...mapQ\"\n}\n```", "```\n// append to kubeconfig file.\n- name: chloe-k8scookbook@gmail.com\n  user:\n    auth-provider:\n      config:\n        client-id: 140285873781-f9h7d7bmi6ec1qa0892mk52t3o874j5d.apps.googleusercontent.com\n        client-secret: Ez0m1L7436mlJQErhalp3Gda\n        id-token: eyJhbGc...mapQ\n        idp-issuer-url: https://accounts.google.com\n        refresh-token: 1/72xFflvdTRdqhjn70Bcar3qyWDiFw-8KoNm6LdFPorQ\n      name: oidc\n```", "```\n# kubectl --user=chloe-k8scookbook@gmail.com get nodes \nError from server (Forbidden): nodes is forbidden: User \"chloe-k8scookbook@gmail.com\" cannot list nodes at the cluster scope \n```", "```\n# cat role.yaml\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: configmap-ro\nrules:\n  - apiGroups: [\"*\"]\n    resources: [\"configmaps\"]\n    verbs: [\"watch\", \"get\", \"list\"]\n```", "```\n# cat rolebinding.yaml\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: devops-role-binding\nsubjects:\n- apiGroup: \"\"\n  kind: User\n  name: linda\nroleRef:\n  apiGroup: \"\"\n  kind: Role\n  name: configmap-ro\n```", "```\nsystem:serviceaccount:<namespace>:<serviceaccountname>\n```", "```\n# cat serviceaccount_clusterrole.yaml\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: cd-role\nrules:\n- apiGroups: [\"extensions\", \"apps\"]\n  resources:\n  - deployments\n  - replicasets\n  - ingresses\n  verbs: [\"*\"]\n- apiGroups: [\"\"]\n  resources:\n  - namespaces\n  - events\n  verbs: [\"get\", \"list\", \"watch\"]\n- apiGroups: [\"\"]\n  resources:\n  - pods\n  - services\n  - secrets\n  - replicationcontrollers\n  - persistentvolumeclaims\n  - jobs\n  - cronjobs\n  verbs: [\"*\"]---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: cd-role-binding\nroleRef:\n  apiGroup: rbac.authorization.k8s.io\n  kind: ClusterRole\n  name: cd-role\nsubjects:\n- apiGroup: rbac.authorization.k8s.io\n  kind: User\n  name: system:serviceaccount:default:chapter8-serviceaccount\n```", "```\n# cat oidc_clusterrole.yaml\nkind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: oidc-admin-role\nrules:\n  - apiGroups: [\"*\"]\n    resources: [\"*\"]\n    verbs: [\"*\"]\n---\nkind: ClusterRoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: admin-binding\nsubjects:\n  - kind: User\n    name: chloe-k8scookbook@gmail.com\n    apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: oidc-admin-role\n  apiGroup: rbac.authorization.k8s.io\n```", "```\n# kubectl --user=chloe-k8scookbook@gmail.com get nodes \nNAME STATUS ROLES AGE VERSION minikube Ready <none> 6d v1.9.4 \n```"]