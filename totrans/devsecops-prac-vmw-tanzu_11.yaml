- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Enabling Secure Inter-Service Communication with Tanzu Service Mesh
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Tanzu Service Mesh 实现安全的服务间通信
- en: Enterprise software has changed significantly in the last few years. Some of
    you reading this may remember when most software was written as a single monolith
    by a small team of developers. The application had to be deployed, updated, started,
    stopped, and scaled as a single unit.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 企业软件在过去几年发生了显著变化。你们中的一些人可能还记得，大多数软件曾是由一小队开发者编写成一个单体应用。应用必须作为一个整体进行部署、更新、启动、停止和扩展。
- en: 'As software began to evolve in the early to mid-2000s, demands on software
    and software developers started to grow along four axes:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 随着软件在2000年代初期到中期的发展，软件和软件开发人员的需求开始在四个方面增长：
- en: '**Time to value**: Teams were expected to deliver bug fixes, improvements,
    and new value-delivering features on ever-shrinking timelines.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**价值实现时间**：团队被期望在不断缩短的时间内交付 bug 修复、改进以及新功能。'
- en: '**Elasticity**: Teams needed to scale “hot” services independently and deploy
    individual features without having to build, test, and deploy the entire monolith
    all at once.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**弹性**：团队需要独立扩展“热”服务，并能够部署单个功能，而不需要一次性构建、测试和部署整个单体应用。'
- en: '**Fault-tolerance**: When an individual service failed or started to degrade,
    it shouldn’t affect other services, and the system should be able to work around
    the problematic service.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**容错性**：当某个服务失败或开始下降时，不应该影响其他服务，系统应能够绕过出现问题的服务继续运作。'
- en: '**Programming languages and frameworks**: The technology landscape began to
    move too quickly for monolithic applications to keep up. Developers felt stifled
    and constrained by the older, less agile technology.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编程语言和框架**：技术领域的发展速度太快，单体应用已无法跟上。开发人员感到受限，无法发挥较旧、不够灵活的技术。'
- en: 'These demands led to the near-universal adoption of design patterns such as
    microservices ([https://en.wikipedia.org/wiki/Microservices](https://en.wikipedia.org/wiki/Microservices)).
    Furthermore, as microservices came to predominate software development and teams
    became more independent and autonomous, new architecture paradigms began to emerge,
    specifically hybrid and multi-cloud:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 这些需求促使了如微服务等设计模式的几乎普遍采用（[https://en.wikipedia.org/wiki/Microservices](https://en.wikipedia.org/wiki/Microservices)）。此外，随着微服务在软件开发中占据主导地位，团队变得更加独立和自主，新的架构范式开始出现，特别是混合云和多云：
- en: '**Hybrid cloud**: This refers to deploying apps consisting of legacy VMs, Kubernetes
    services, serverless functions, and possibly other technologies such as **Platform-as-a-Service**
    (**PaaS**) across an on-premises data center and the public cloud.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**混合云**：指的是在本地数据中心和公有云之间部署由传统虚拟机、Kubernetes 服务、无服务器函数以及可能的其他技术（如**平台即服务**（**PaaS**））组成的应用。'
- en: '**Multi-cloud**: This refers to deploying an application across multiple **Virtual
    Private Clouds** (**VPCs**) across one or more cloud providers.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多云**：指的是跨多个云提供商的多个**虚拟私有云**（**VPC**）部署应用。'
- en: 'Google has some interesting material on these architectures here: [https://cloud.google.com/architecture/hybrid-and-multi-cloud-patterns-and-practices](https://cloud.google.com/architecture/hybrid-and-multi-cloud-patterns-and-practices).'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Google 在这里提供了有关这些架构的一些有趣材料：[https://cloud.google.com/architecture/hybrid-and-multi-cloud-patterns-and-practices](https://cloud.google.com/architecture/hybrid-and-multi-cloud-patterns-and-practices)。
- en: For reasons we’ll discuss shortly, Tanzu Service Mesh is the ideal tool for
    teams tasked with securely and consistently delivering fixes and features while
    operating in complex modern environments.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 出于我们稍后将讨论的原因，Tanzu Service Mesh 是为那些在复杂现代环境中需要安全、一致地交付修复和新特性的团队量身定制的理想工具。
- en: 'In this chapter, we will cover these topics:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Why Tanzu Service Mesh?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么选择 Tanzu Service Mesh？
- en: Features and capabilities of Tanzu Service Mesh
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tanzu Service Mesh 的功能和特性
- en: How to get started with Tanzu Service Mesh
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何开始使用 Tanzu Service Mesh
- en: How to perform key day-2 operations on Tanzu Service Mesh
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 Tanzu Service Mesh 上执行关键的日常运营
- en: GSLB with NSX-T Advanced Load Balancer and Tanzu Service Mesh
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 NSX-T 高级负载均衡器和 Tanzu Service Mesh 实现 GSLB
- en: With that, let’s jump in and dive deep into why a team might need Tanzu Service
    Mesh.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 既然如此，我们开始深入探讨为什么团队可能需要 Tanzu Service Mesh。
- en: Why Tanzu Service Mesh?
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择 Tanzu Service Mesh？
- en: 'Tanzu Service Mesh is a tool built expressly to enable the meaningful business
    outcomes we just described (fast time to value, elasticity, fault tolerance, and
    so on) while operating in the context of a hybrid or multi-cloud environment.
    Here are some examples:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: Tanzu Service Mesh 是一个专为支持我们刚刚描述的有意义的业务成果（快速价值交付、弹性、容错等）而构建的工具，同时它也能在混合云或多云环境中运行。以下是一些示例：
- en: How do we deliver a faster time to value when we have to update 100 dependent
    services whenever a core service moves from one cloud to another?
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当核心服务从一个云迁移到另一个云时，我们必须更新 100 个依赖服务，那么如何更快地交付价值？
- en: Do we realize the full value of an elastic system if every cloud has a different
    process and toolset for deploying and scaling?
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果每个云都有不同的部署和扩展流程及工具集，那么我们是否真正实现了弹性系统的全部价值？
- en: The same goes for detecting and remediating faults. Are we fully benefitting
    from a resilient system if we have to maintain different tools for monitoring,
    alerting, and remediating across clouds?
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检测和修复故障同样如此。如果我们不得不为跨云的监控、警报和修复维护不同的工具，那么我们能充分受益于一个具有弹性的系统吗？
- en: Let’s say that you were to invest the time and effort to centralize tooling
    and monitoring to work across multiple clouds. How do you keep your tech up to
    date as languages, frameworks, and technologies continue their inexorable forward
    march? Is the continued ongoing investment worthwhile?
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假设你投入时间和精力，将工具和监控集中化以便跨多个云平台工作。当语言、框架和技术持续向前发展时，你如何保持技术的更新？这种持续的投资是否值得？
- en: 'Tanzu Service Mesh sits squarely in the middle of this problem space, bringing
    the benefits of large, distributed microservice architectures to multi and hybrid
    cloud architectures. It may help to visualize the problem space: delivering business
    outcomes across clouds and on-premises, across multiple technologies and frameworks:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: Tanzu Service Mesh 完全位于这个问题空间的核心，它将大型分布式微服务架构的好处带入到多云和混合云架构中。你可以通过想象这个问题空间来帮助理解：跨云和本地，跨多个技术和框架交付业务成果：
- en: "![Figure 1\uFEFF1.1 – Business outcomes across clouds and technologies](img/B18145_11_01.jpg)"
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: "![图 1\uFEFF1.1 – 跨云和技术的业务成果](img/B18145_11_01.jpg)"
- en: Figure 11.1 – Business outcomes across clouds and technologies
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – 跨云和技术的业务成果
- en: Now that we’ve scratched the surface of why you would want to use this tool,
    let’s dive deep into the features and capabilities that enable those *whys*.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经初步了解了为什么你会想使用这个工具，现在让我们深入探讨一下那些实现这些*原因*的功能和能力。
- en: Features and capabilities of Tanzu Service Mesh
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Tanzu Service Mesh 的功能和能力
- en: 'Here are eight concrete features that Tanzu Service Mesh provides. These features
    enable the specific capabilities necessary to accomplish what we described in
    the previous section: how we deliver tangible outcomes in a multi or hybrid cloud
    environment:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Tanzu Service Mesh 提供的八个具体功能。这些功能使得实现我们在前一节中描述的目标成为可能：如何在多云或混合云环境中交付切实的成果：
- en: '**Out-of-the-box enablement of hybrid and multi-cloud architectures**: With
    a few clicks in the UI or API calls, you can onboard multiple different clouds
    and architectures (Kubernetes, legacy, serverless) into a single virtual space
    where you can quickly and easily stand up any of the various industry standard
    multi-cloud or hybrid cloud architectures.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开箱即用的混合云和多云架构支持**：只需通过几次点击 UI 或 API 调用，你就可以将多个不同的云和架构（Kubernetes、传统架构、无服务器架构）整合到一个虚拟空间中，在该空间内你可以快速且轻松地搭建任何行业标准的多云或混合云架构。'
- en: '**Effortlessly move apps between clouds**: You can deploy your app in a different
    VPC, a different platform (VMs versus Kubernetes), or even an entirely different
    cloud provider without affecting dependent apps and services.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**轻松在云之间迁移应用**：你可以将应用部署到不同的 VPC、不同的平台（虚拟机与 Kubernetes）上，甚至是完全不同的云提供商，而不影响依赖的应用和服务。'
- en: '**Automatic high availability**: You can deploy the same service to multiple
    clouds and the service mesh will automatically load balance between them. This
    includes transparently failing over from one cloud to another when the service
    fails in one location.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动高可用性**：你可以将相同的服务部署到多个云平台，服务网格将自动在它们之间进行负载均衡。这包括当一个位置的服务发生故障时，自动从一个云切换到另一个云。'
- en: '**SLO tracking with AutoScaling**: Tanzu Service Mesh allows you to define
    **Service-Level Objectives** (**SLOs**), track your error budget relative to the
    SLOs, and even autoscale services when SLOs aren’t being met.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**自动扩展的SLO跟踪**：Tanzu Service Mesh允许你定义**服务级别目标**（**SLOs**），跟踪你的错误预算相对于SLO的情况，甚至在SLO未达标时自动扩展服务。'
- en: '**End-to-end mTLS**: With zero operator effort or toil, Tanzu Service Mesh
    uses sidecars to secure all inter-service traffic in both directions. This allows
    for guaranteed client and server identity, which can be used to further secure
    the services.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端到端mTLS**：通过零操作员工作量，Tanzu Service Mesh使用边车（sidecars）确保所有服务间的双向流量安全。这保证了客户端和服务器的身份，可以进一步用于加强服务安全。'
- en: '**Security policies and auditing**: With bi-directional TLS, client and server
    IDs are cryptographically guaranteed. This allows you to create airtight *allow*
    and *deny* policies that dictate which services can communicate with each other.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全策略与审计**：通过双向TLS，客户端和服务器ID在加密上得到了保证。这使得你能够创建严密的*允许*和*拒绝*策略，指定哪些服务可以相互通信。'
- en: '**Full workload visualization**: Tanzu Service Mesh gives a real-time visualization
    of all the services in the mesh, complete with metrics.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**完整工作负载可视化**：Tanzu Service Mesh实时可视化网格中的所有服务，并提供度量数据。'
- en: '**Tight control over deployments**: Tanzu Service Mesh gives you all the tools
    in the Istio toolbox to control rollouts of a service: traffic shaping, canary
    deploys, A/B testing, and more.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**紧密控制部署**：Tanzu Service Mesh为你提供了Istio工具箱中的所有工具，以控制服务的发布：流量 shaping、金丝雀发布、A/B测试等。'
- en: With those features, I hope you now understand why you would use Tanzu Service
    Mesh. Now, let’s get our hands dirty and get started with it.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这些功能，我希望你现在理解为什么要使用Tanzu Service Mesh。接下来，让我们开始动手操作，正式开始使用它。
- en: How to get started with Tanzu Service Mesh
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何开始使用Tanzu Service Mesh
- en: 'Tanzu Service Mesh consists of controllers that install into your Kubernetes
    clusters as well as a central SaaS global control plane. The SaaS control plane
    does a few things:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Tanzu Service Mesh由安装到Kubernetes集群中的控制器和一个中央SaaS全球控制平面组成。SaaS控制平面执行以下任务：
- en: Manages installation of Tanzu Service Mesh components onto Kubernetes clusters
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理Tanzu Service Mesh组件在Kubernetes集群上的安装
- en: Automatically updates those components as necessary
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据需要自动更新这些组件
- en: Sends global configuration down to those controllers (for example, the location
    of services on other clusters)
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将全局配置发送到这些控制器（例如，其他集群上服务的位置）
- en: Manages and deploys policies on the Kubernetes clusters
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理和部署Kubernetes集群上的策略
- en: Gathers metrics to enable visualization and SLOs
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 收集度量数据以实现可视化和SLO（服务级别目标）
- en: To get started with Tanzu Service Mesh, let’s log into our VMware Cloud Services
    Console and select the **Tanzu Service Mesh** tile from the list of services.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用Tanzu Service Mesh，我们需要登录到VMware Cloud Services控制台，并从服务列表中选择**Tanzu Service
    Mesh**模块。
- en: Important note
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'Tanzu Service Mesh is the one product in this book that’s neither free to use
    nor provides a self-service avenue to enable a trial. If you don’t currently have
    a license for Tanzu Service Mesh, you’ll need to reach out to your VMware Account
    Executive to set up a trial. If that’s not possible, much of what we’ll cover
    in this section is also included in a free VMware hands-on lab for Tanzu Service
    Mesh located here: [https://labs.hol.vmware.com/HOL/catalogs/lab/8509](https://labs.hol.vmware.com/HOL/catalogs/lab/8509).'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Tanzu Service Mesh是本书中唯一一个既不是免费使用也没有提供自助试用途径的产品。如果你目前没有Tanzu Service Mesh的许可证，你需要联系你的VMware客户经理来设置试用。如果这不可行，我们将在本节中涵盖的许多内容也可以在VMware为Tanzu
    Service Mesh提供的免费实践实验室中找到，网址如下：[https://labs.hol.vmware.com/HOL/catalogs/lab/8509](https://labs.hol.vmware.com/HOL/catalogs/lab/8509)。
- en: 'The VMware Cloud Services Console is located here: https://console.cloud.vmware.com/csp/gateway/portal/#/consumer/services/organization.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: VMware Cloud Services控制台位于这里：https://console.cloud.vmware.com/csp/gateway/portal/#/consumer/services/organization。
- en: 'Select **Launch Service** from the **Tanzu Service Mesh** tile, as shown in
    the following screenshot:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 从下图所示的**Tanzu Service Mesh**模块中选择**启动服务**：
- en: "![Figure 1\uFEFF1.2 – Launching Tanzu Service Mesh](img/B18145_11_02.jpg)"
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: "![图 1\uFEFF1.2 – 启动Tanzu Service Mesh](img/B18145_11_02.jpg)"
- en: Figure 11.2 – Launching Tanzu Service Mesh
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – 启动Tanzu Service Mesh
- en: Once we launch the Tanzu Service Mesh app, we’re ready to onboard our Kubernetes
    clusters.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦启动Tanzu Service Mesh应用程序，我们就可以开始将Kubernetes集群接入其中。
- en: Onboarding Kubernetes clusters
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启动Kubernetes集群
- en: This example requires two separate clusters with the ability to create `LoadBalancer`
    services. You can refer to the *Appendix* to explore your options for standing
    up Kubernetes clusters. For this exercise, I’d strongly recommend using one of
    the public cloud offerings (EKS, AKS, GKE, or TKG on the public cloud) simply
    because they make it very easy to stand up `LoadBalancer` services, which are
    a must-have for this exercise.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例需要两个独立的集群，并且能够创建`LoadBalancer`服务。你可以参考*附录*来探索搭建Kubernetes集群的选项。对于这个练习，我强烈建议使用公共云服务（EKS、AKS、GKE或公共云上的TKG），因为它们非常方便创建`LoadBalancer`服务，而这是这个练习所必需的。
- en: 'Here are the steps to onboard your clusters:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是加入集群的步骤：
- en: Select **New Workflow** | **Onboard** **New Cluster**.
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择**新工作流** | **加入新集群**。
- en: In the dialog, give your cluster a name (for example, `cluster-1`) and click
    **Generate Security Token**. This will generate some credentials that your Kubernetes
    cluster will use to connect to the SaaS control plane.
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在对话框中，为你的集群命名（例如，`cluster-1`），然后点击**生成安全令牌**。这将生成一些凭据，供你的Kubernetes集群连接到SaaS控制平面使用。
- en: 'From your terminal, make sure that you have kubectl pointed to your first cluster:'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在终端中，确保你已经将kubectl指向第一个集群：
- en: '[PRE0]'
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Then, copy each of the kubectl commands from the UI into your terminal:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，将UI中的每个kubectl命令复制到你的终端中：
- en: '[PRE4]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '[PRE6]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '[PRE8]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[PRE10]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[PRE12]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The first command installs the control plane components. These components will
    turn around and install Istio locally, as well as check in with the global SaaS
    control plane to check for updates.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令安装控制平面组件。这些组件将回过头来安装Istio，并与全局SaaS控制平面进行检查以查看是否有更新。
- en: The second command creates a Kubernetes secret that will be used to authenticate
    to the global SaaS control plane.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个命令创建一个Kubernetes秘密，用于认证到全球SaaS控制平面。
- en: Finally, click the green **Install Tanzu Service Mesh** button. That will instruct
    the components running on your Kubernetes cluster to pull down and install the
    Istio data plane components.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，点击绿色的**安装Tanzu Service Mesh**按钮。这将指示在你的Kubernetes集群上运行的组件拉取并安装Istio数据平面组件。
- en: Repeat this entire process for your second Kubernetes cluster.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对你的第二个Kubernetes集群重复整个过程。
- en: 'At this point, you should have Tanzu Service Mesh up and running on both of
    your clusters and they should be visible in the Tanzu Service Mesh UI in the **Clusters**
    pane. You should see something like what’s shown in the following screenshot.
    You’ll notice that we have four nodes on each cluster but no services yet:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你应该已经在两个集群上启动并运行Tanzu Service Mesh，并且它们应该在Tanzu Service Mesh UI的**集群**面板中可见。你应该会看到类似以下截图的内容。你会注意到我们每个集群上有四个节点，但还没有服务：
- en: "![Figure 1\uFEFF1.3 – Two clusters onboarded](img/B18145_11_03.jpg)"
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: "![图 1\uFEFF1.3 – 两个集群已加入](img/B18145_11_03.jpg)"
- en: Figure 11.3 – Two clusters onboarded
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 – 两个集群已加入
- en: Next, we’ll need to create a namespace in each cluster that we’ll use as our
    Global Namespace in Tanzu Service Mesh.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要在每个集群中创建一个命名空间，作为我们在Tanzu Service Mesh中的全局命名空间。
- en: Creating a Tanzu Service Mesh Global Namespace
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建Tanzu Service Mesh全局命名空间
- en: 'A `acme` in each cluster. Now, all the services in the `acme` namespace on
    cluster 1 can see all the services in the `acme` namespace on cluster 2, and vice
    versa. Here’s how we go about creating the GNS across our two onboarded clusters:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 每个集群中都有一个`acme`。现在，集群 1 中`acme`命名空间中的所有服务可以看到集群 2 中`acme`命名空间中的所有服务，反之亦然。以下是如何在我们两个已加入的集群之间创建GNS的步骤：
- en: 'Go ahead and create the namespaces:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续创建命名空间：
- en: '[PRE20]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: '[PRE24]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '[PRE27]'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Next, we must create the logical GNS in the Tanzu Service Mesh UI. Here are
    the steps at a high level:'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们必须在Tanzu Service Mesh UI中创建逻辑GNS。以下是高层次的步骤：
- en: Select `acme-gns`.
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择`acme-gns`。
- en: Select a domain for the GNS. This will be how services find each other, so I’d
    recommend against something that may need to resolve via DNS (for example, `acme.com`,
    `mygns.net`). Instead, I chose to use `devsecops-acme.gns` as something that won’t
    be confused with a public domain name. For future steps to work without additional
    changes, I’d recommend using the same domain for your GNS.
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为GNS选择一个域名。这将是服务相互发现的方式，因此我建议避免使用可能需要通过DNS解析的域名（例如，`acme.com`，`mygns.net`）。相反，我选择了`devsecops-acme.gns`，这是一个不会与公共域名混淆的名称。为了确保后续步骤不需要额外的更改，我建议为你的GNS使用相同的域名。
- en: 'You should see something like the following:'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你应该会看到如下所示的内容：
- en: "![Figure 1\uFEFF1.4 – Naming and selecting a unique domain](img/B18145_11_04.jpg)"
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: "![图 1\uFEFF1.4 – 命名并选择唯一域](img/B18145_11_04.jpg)"
- en: Figure 11.4 – Naming and selecting a unique domain
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 – 命名和选择唯一的域
- en: 'Next, we’ll need to map the `acme` namespace within each of our two clusters
    to this GNS on the **Namespace Mapping** screen, as per the following screenshot:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们需要在每个集群的 **命名空间映射** 屏幕中将 `acme` 命名空间映射到这个 GNS，如下截图所示：
- en: "![Figure 1\uFEFF1.5 – Global Namespace Mapping](img/B18145_11_05.jpg)"
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.5 – 全局命名空间映射](img/B18145_11_05.jpg)'
- en: Figure 11.5 – Global Namespace Mapping
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.5 – 全局命名空间映射
- en: 'For the remaining screens, you can accept the defaults. In the end, you should
    see your GNS in the **GNS Overview** tab in the UI:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于剩余的屏幕，你可以接受默认设置。最后，你应该在 UI 的 **GNS 概览** 标签页中看到你的 GNS：
- en: "![Figure 1\uFEFF1.6 – New GNS](img/B18145_11_06.jpg)"
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.6 – 新的 GNS](img/B18145_11_06.jpg)'
- en: Figure 11.6 – New GNS
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6 – 新的 GNS
- en: Now that our GNS is up and running, it’s time to deploy some services to our
    clusters that will communicate over the GNS.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的 GNS 已经启动并运行，是时候将一些服务部署到我们的集群中，这些服务将通过 GNS 进行通信。
- en: Installing services
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装服务
- en: 'The files in the following steps will install a simple microservice-based application
    called *Acme Fitness*. If you chose `devsecops-acme.gns` as your domain, you can
    deploy these files as-is; otherwise, you’ll need to update the internal references
    to reflect your domain name. The manifests can be found here: [https://github.com/PacktPublishing/DevSecOps-in-Practice-with-VMware-Tanzu/tree/main/chapter-12](https://github.com/PacktPublishing/DevSecOps-in-Practice-with-VMware-Tanzu/tree/main/chapter-12):'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤中的文件将安装一个名为 *Acme Fitness* 的简单基于微服务的应用程序。如果你选择了 `devsecops-acme.gns` 作为你的域名，你可以直接部署这些文件；否则，你需要更新内部引用以反映你的域名。清单文件可以在此处找到：[https://github.com/PacktPublishing/DevSecOps-in-Practice-with-VMware-Tanzu/tree/main/chapter-12](https://github.com/PacktPublishing/DevSecOps-in-Practice-with-VMware-Tanzu/tree/main/chapter-12)：
- en: 'Make sure you’re pointing to your first Kubernetes cluster and deploying the
    YAML manifest for `cluster-1`. It’s important to note `-n acme` at the end of
    the commands. You need to explicitly declare that these services are to be deployed
    to the `acme` namespace. This will install a few things:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你指向的是第一个 Kubernetes 集群，并且部署的是 `cluster-1` 的 YAML 清单。请注意命令末尾的 `-n acme`，这非常重要。你需要明确声明这些服务将被部署到
    `acme` 命名空间。这将安装一些东西：
- en: Secrets that apps will use to talk to their data services.
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序将使用的机密，用于与其数据服务进行通信。
- en: Several data services (MongoDB, Redis, and so on).
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 若干数据服务（如 MongoDB、Redis 等）。
- en: Some microservice-based applications.
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一些基于微服务的应用程序。
- en: A gateway, which is like a virtual L7 load balancer that tells Tanzu Service
    Mesh where to route certain incoming requests. In our case, this is the only external-facing
    application running on the cluster, so we’ll route all requests coming in from
    outside the cluster to our frontend service, which we have called `shopping`.
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个网关，类似于一个虚拟的 L7 负载均衡器，告诉 Tanzu 服务网格将某些传入请求路由到哪里。在我们的案例中，这是唯一一个面向外部的应用程序，运行在集群中，因此我们将所有从集群外部传入的请求路由到我们的前端服务，服务名称为
    `shopping`。
- en: 'Then, switch to `cluster-2` and deploy that manifest. Here are the commands
    I used to deploy the services into both of my Kubernetes clusters:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，切换到 `cluster-2` 并部署该清单。以下是我用来将服务部署到我两个 Kubernetes 集群中的命令：
- en: '[PRE28]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Accessing the application
  id: totrans-124
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问应用
- en: Now that we’ve installed the services across two clusters, let’s verify that
    the app is up and running. Switch your kubectl context back to the first cluster
    and get the details of the `istio-ingressgateway` service in the `istio-system`
    namespace. If you’re running on EKS, you might get the hostname of a load balancer;
    otherwise, you may see an IPv4 address. Grab the hostname or external IP and plug
    it into your browser using `http`, not `https`.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在两个集群中安装了服务，让我们来验证应用是否正常运行。将你的 kubectl 上下文切换回第一个集群，并获取 `istio-ingressgateway`
    服务在 `istio-system` 命名空间中的详细信息。如果你在 EKS 上运行，可能会获得负载均衡器的主机名；否则，你可能会看到一个 IPv4 地址。获取主机名或外部
    IP，并将其插入浏览器中，使用 `http`，而不是 `https`。
- en: 'Here’s how I got the service. Notice that I’m pointed at the first cluster
    and I’m on EKS, so I’m getting a load balancer hostname as my *external IP*:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是我获得服务的过程。请注意，我指向的是第一个集群，并且我使用的是 EKS，因此我获得了一个负载均衡器的主机名作为我的*外部 IP*：
- en: '[PRE29]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: And here’s what you’d expect to see in the browser. If the yoga mat and water
    bottle images appear, then you know everything is working. The page itself is
    hosted in cluster 1 and the catalog is hosted in cluster 2!
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你在浏览器中预期看到的内容。如果瑜伽垫和水瓶的图像出现，那么你就知道一切正常。该页面本身托管在集群 1 中，而目录托管在集群 2 中！
- en: "![Figure 1\uFEFF1.7 – Acme Fitness deployed across two clusters](img/B18145_11_07.jpg)"
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: "![图 1\uFEFF1.7 – Acme Fitness 部署在两个集群上](img/B18145_11_07.jpg)"
- en: Figure 11.7 – Acme Fitness deployed across two clusters
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7 – Acme Fitness 部署在两个集群上
- en: Next, we’ll need to generate some inter-service traffic so that the Tanzu Service
    Mesh UI can visualize all the connections.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们需要生成一些服务间流量，以便 Tanzu Service Mesh UI 可以可视化所有连接。
- en: Generating application traffic
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成应用流量
- en: 'Here are some things you can do to make sure that all the services get some
    traffic:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些你可以做的事情，以确保所有服务都能接收到流量：
- en: Click the login button next to the shopping cart.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击购物车旁边的登录按钮。
- en: 'Log in with the following credentials – username: `dwight` password: `vmware1!`.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用以下凭据登录——用户名：`dwight`，密码：`vmware1!`。
- en: Click the **Catalog** link at the top of the screen.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击屏幕顶部的 **Catalog** 链接。
- en: Browse to an item.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 浏览一个项目。
- en: Add it to your cart.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将其添加到购物车。
- en: Click the **Shopping** **Cart** button.
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击 **Shopping** **Cart** 按钮。
- en: Click **Proceed** **to Checkout**.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击 **Proceed** **to Checkout**。
- en: Go through the checkout process. Any 16-digit number will work for a credit
    card number.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成结账流程。任何 16 位数字都可以作为信用卡号码。
- en: 'Now, we can return to the GNS screen for our `acme-gns` in the Tanzu Service
    Mesh UI. You should see all the services spread across the two clusters, as shown
    in the following screenshot:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以返回 Tanzu Service Mesh UI 中的 `acme-gns` 页面。你应该能看到所有服务分布在两个集群中的情况，如下图所示：
- en: "![Figure 1\uFEFF1.8 – Tanzu Service Mesh service visualization](img/B18145_11_08.jpg)"
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: "![图 1\uFEFF1.8 – Tanzu Service Mesh 服务可视化](img/B18145_11_08.jpg)"
- en: Figure 11.8 – Tanzu Service Mesh service visualization
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.8 – Tanzu Service Mesh 服务可视化
- en: 'At this point, you have successfully done the following:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，你已经成功完成了以下操作：
- en: Stood up a new Service Mesh
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动了一个新的 Service Mesh
- en: Onboarded multiple clusters
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已加入多个集群
- en: Federated them into a GNS
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将它们联合到一个 GNS 中
- en: Deployed a distributed app
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署了分布式应用
- en: Verified the app’s functionality and cross-cluster communications
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证了应用的功能和跨集群通信
- en: That’s an impressive list for day one. Now, let’s move on to some operations
    you may consider after you’ve accomplished your day-1 checklist.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这是第一天的令人印象深刻的清单。现在，我们来看看在完成了第一天的任务清单后，你可能会考虑的一些操作。
- en: How to perform key day-2 operations on Tanzu Service Mesh
  id: totrans-152
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何在 Tanzu Service Mesh 上执行关键的 Day-2 操作
- en: At this point, we have a distributed application successfully working across
    two Kubernetes clusters. If you were doing this in a real production environment,
    there are some *day-2* concerns you’d want to address. For example, it’s great
    that the catalog service can run on a separate cluster, but what if that cluster
    goes down? How could we load balance across instances on multiple clusters?
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经成功地在两个 Kubernetes 集群中运行了一个分布式应用。如果你在真实的生产环境中进行此操作，可能会遇到一些 *Day-2*
    的问题需要解决。例如，目录服务可以运行在单独的集群上，但如果该集群出现故障怎么办？我们如何在多个集群的实例间进行负载均衡呢？
- en: Furthermore, we’re living in a world where deployment, upkeep, measuring, and
    monitoring of services are often the responsibility of **Site Reliability Engineers**
    (**SREs**). If you were the SRE for Acme Fitness, you would have already identified
    **Service-Level Indicators** (**SLIs**) and defined SLOs for your services. Tanzu
    Service Mesh greatly simplifies this by allowing you to define your SLIs and SLOs
    right in the Tanzu Service Mesh UI and measure how your services are meeting those
    SLOs using real-time metrics.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们正处在一个这样的世界中：服务的部署、维护、度量和监控通常是 **站点可靠性工程师**（**SREs**）的职责。如果你是 Acme Fitness
    的 SRE，你应该已经识别出了 **服务水平指标**（**SLIs**）并为你的服务定义了 SLO。Tanzu Service Mesh 通过允许你在 Tanzu
    Service Mesh UI 中定义 SLIs 和 SLOs，并使用实时指标来衡量服务是否达到了这些 SLO，从而大大简化了这一过程。
- en: Enabling service high availability
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启用服务高可用性
- en: First, let’s address making a service highly available. In our example app,
    most of the services are on `cluster-1`, while the catalog and its data store
    are on `cluster-2`. Tanzu Service Mesh lets us stand up additional instances of
    a service across multiple clusters and automatically load balances between all
    the instances as they come online.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们来讨论如何让服务具备高可用性。在我们的示例应用中，大多数服务都运行在`cluster-1`上，而目录服务及其数据存储则位于`cluster-2`上。Tanzu
    Service Mesh 使我们能够在多个集群中部署服务的额外实例，并且会自动在所有实例上线时进行负载均衡。
- en: 'For our purposes, let’s just deploy another instance of the catalog service
    onto `cluster-1`. We can do that very easily by targeting `cluster-1` and applying
    the `cluster-2` deployment manifest, like so:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的目的，假设我们只需将目录服务的另一个实例部署到 `cluster-1` 上。我们可以通过以下方式非常轻松地实现：定位到 `cluster-1`
    并应用 `cluster-2` 的部署清单：
- en: '[PRE30]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Now, if we go back to the app and access the catalog a few times, we should
    see a visualization like the one shown in the following screenshot. Notice how
    Tanzu Service Mesh automatically load balances between the two catalog instances:
    one in `cluster-1` and the other in `cluster-2`:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果我们回到应用并多次访问目录，我们应该能看到像下面截图中的可视化效果。请注意，Tanzu 服务网格会自动在两个目录实例之间进行负载均衡：一个在
    `cluster-1`，另一个在 `cluster-2`：
- en: "![Figure 1\uFEFF1.9 – Automatic load balancing across multiple clusters](img/B18145_11_09.jpg)"
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.9 – 跨多个集群的自动负载均衡](img/B18145_11_09.jpg)'
- en: Figure 11.9 – Automatic load balancing across multiple clusters
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.9 – 跨多个集群的自动负载均衡
- en: Next, let’s track some SLOs.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们追踪一些 SLO。
- en: Defining and measuring SLOs
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定义和衡量 SLO
- en: For this task, we’ll walk through the desired outcome and the steps we follow
    to achieve that outcome. We’ll show some screenshots along the way so we can double-check
    our work. Then, we’ll talk about what the various fields represent.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个任务，我们将展示期望的结果和我们为实现这个结果所遵循的步骤。我们将展示一些截图，方便我们检查工作是否正确。接下来，我们会讲解各个字段的含义。
- en: Desired outcome
  id: totrans-165
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 期望的结果
- en: Let’s say that we’re the SREs for Acme Fitness and we have an SLO for the catalog
    service that it be up and healthy 99.99% of the time, sometimes called *four nines
    uptime*. In our case, we define *healthy* as having 90% of our requests complete
    within 100 milliseconds.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们是 Acme Fitness 的 SRE，并且我们有一个关于目录服务的 SLO，要求其 99.99% 的时间内保持正常运行，通常称为*四个九的正常运行时间*。在我们的案例中，我们定义*健康*为
    90% 的请求在 100 毫秒内完成。
- en: Let’s go into the Tanzu Service Mesh UI and define this SLO so that we can have
    Tanzu Service Mesh accurately measure how well we’re meeting this SLO.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们进入 Tanzu 服务网格 UI，定义这个 SLO，以便让 Tanzu 服务网格准确衡量我们是否达到了这个 SLO。
- en: Site Reliability Engineering
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 站点可靠性工程
- en: 'If you’re not familiar with the concepts of SREs, SLOs, and SLIs, I’d strongly
    recommend reading the *Site Reliability Engineering* book. You can get an eBook
    or hard copy from the usual sources, or you can read it for free online from the
    Google SRE website: [https://sre.google/](https://sre.google/).'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不熟悉 SRE、SLO 和 SLI 的概念，我强烈推荐阅读《*站点可靠性工程*》一书。你可以从常见的渠道获取电子书或纸质书，或者从 Google
    SRE 网站上免费阅读：[https://sre.google/](https://sre.google/)。
- en: Implementing the SLO
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 实现 SLO
- en: 'From the Tanzu Service Mesh UI, navigate to **New Workflow** | **New SLO Policy**
    | **Monitored SLO**. This will launch a wizard. You can fill in the first screen’s
    form values as follows:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 从 Tanzu 服务网格 UI 中，导航到 **新建工作流** | **新建 SLO 策略** | **监控的 SLO**。这将启动一个向导。你可以按照以下方式填写第一页的表单值：
- en: '`acme-catalog-health`'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`acme-catalog-health`'
- en: '`GNS` `Policy`, GNS=`acme-gns`'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`GNS` `策略`，GNS=`acme-gns`'
- en: '**Service Level Indicators**: p90 Latency is less than 100 ms'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务水平指标**：p90 延迟小于 100 毫秒'
- en: '**Service Level Objective**: The service should be healthy 99.99% of the time'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务水平目标**：服务应保持健康，99.99% 的时间内正常运行'
- en: Click **Next**
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 点击 **下一步**
- en: On the second screen, select the *catalog* service and click next. You could
    choose to apply this SLO to multiple services if you want to.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二屏幕上，选择 *catalog* 服务并点击下一步。如果你愿意，你还可以选择将这个 SLO 应用到多个服务。
- en: 'Finally, you’ll be shown a summary like this one. Notice that it calculates
    the approximate monthly budget of time your service can be outside of the healthy
    range. As the service goes into an unhealthy state over a month, the budget will
    be updated:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你将看到像这样的摘要。注意，它会计算出你的服务可以在不健康范围内的月度预算时间。随着服务在一个月内变为不健康状态，预算会进行更新：
- en: "![Figure 1\uFEFF1.10 – SLO details](img/B18145_11_10.jpg)"
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.10 – SLO 详细信息](img/B18145_11_10.jpg)'
- en: Figure 11.10 – SLO details
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.10 – SLO 详细信息
- en: 'Now, you can view your services’ performance relative to their SLOs by navigating
    to **Policies** | **SLOs** and clicking on the name of your SLO. Here’s one I
    set up previously with an unreasonable latency threshold of 5 ms. This was to
    demonstrate what things look like when you don’t meet your error budget:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以通过导航到 **策略** | **SLOs** 并点击你的 SLO 名称，查看服务相对于其 SLO 的表现。这里是我之前设置的一个 SLO，它有一个不合理的延迟阈值为
    5 毫秒。这样做是为了展示当没有达到错误预算时的情况：
- en: "![Figure 1\uFEFF1.11 – SLO in the red](img/B18145_11_11.jpg)"
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.11 – SLO 进入红区](img/B18145_11_11.jpg)'
- en: Figure 11.11 – SLO in the red
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.11 – SLO 进入红区
- en: This shows us that we have an error budget of 4 minutes and 19 seconds for the
    month to be in an unhealthy state, and we’ve already exceeded that budget by just
    over 3 minutes. SLOs are incredibly powerful tools for SREs and they’re very easy
    to set up and maintain in Tanzu Service Mesh. Now, let’s move on to some other
    day-2 tasks that might be of interest.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: Other day-2 operations for further research
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To comprehensively cover all the day-2 functionality wrapped up in Tanzu Service
    Mesh would potentially double the length of this book; so, with that in mind,
    here’s a list of some items for further exploration, along with links to the relevant
    documentation:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '**Actionable SLOs**: You can configure your SLO to perform auto-healing actions
    when an SLI falls out of range. For example, when latency gets too high, Tanzu
    Service Mesh can autoscale the service to better handle the load: [https://docs.vmware.com/en/VMware-Tanzu-Service-Mesh/services/slos-with-tsm/GUID-1B9A2D61-D264-44FB-8A06-40277AD42A8E.html](https://docs.vmware.com/en/VMware-Tanzu-Service-Mesh/services/slos-with-tsm/GUID-1B9A2D61-D264-44FB-8A06-40277AD42A8E.html).'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Onboard some External Services**: Some services live outside of Kubernetes
    but need to participate in the mesh: [https://docs.vmware.com/en/VMware-Tanzu-Service-Mesh/services/using-tanzu-service-mesh-guide/GUID-F7DC3814-0C3B-42E8-94A1-64B4B182D783.html](https://docs.vmware.com/en/VMware-Tanzu-Service-Mesh/services/using-tanzu-service-mesh-guide/GUID-F7DC3814-0C3B-42E8-94A1-64B4B182D783.html).'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Create a Public Service**: This is a service that is reachable from the internet
    or a network outside the scope of the service mesh, such as an on-premises corporate
    network: [https://docs.vmware.com/en/VMware-Tanzu-Service-Mesh/services/using-tanzu-service-mesh-guide/GUID-58A3FA7C-4EFC-44B2-B37B-D2152CB16359.html](https://docs.vmware.com/en/VMware-Tanzu-Service-Mesh/services/using-tanzu-service-mesh-guide/GUID-58A3FA7C-4EFC-44B2-B37B-D2152CB16359.html).'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we’ve thoroughly covered some day-2 tasks, let’s dive deep into one
    particularly important one, **Global Server Load** **Balancing** (**GSLB**).
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: GSLB with NSX-T Advanced Load Balancer and Tanzu Service Mesh
  id: totrans-191
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One particular day-2 task that is worthy of its own section is implementing
    GSLB with Tanzu Service Mesh and NSX Advanced Load Balancer.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: NSX Advanced Load Balancer
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**NSX Advanced Load Balancer** (**NSX-ALB**) is a product that, while not technically
    part of the Tanzu portfolio, complements it very well. You can learn more about
    it, especially as it pertains to GSLB, here: https://avinetworks.com/docs/20.1/gslb-architecture-terminology-object-model/#gslbsites.'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: 'In short, NSX-ALB is a powerful software load balancer that’s completely API-driven,
    allowing for tight integrations with other API-driven technologies such as Kubernetes
    or Tanzu Service Mesh. In addition to enabling the usual functions of an enterprise
    load balancer such as VIPs, traffic policies, and WAF, it also provides a robust
    DNS implementation, which makes it especially useful for GSLB. The following is
    a rough diagram of how Tanzu Service Mesh and NSX-ALB work alongside your corporate
    DNS (or public DNS) to provide access to services across data centers, multiple
    regions, and different cloud providers:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 1\uFEFF1.12 – NSX Advanced Load Balancer and Tanzu Service Mesh](img/B18145_11_12.jpg)"
  id: totrans-196
  prefs: []
  type: TYPE_IMG
- en: Figure 11.12 – NSX Advanced Load Balancer and Tanzu Service Mesh
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Before we can fully understand how Tanzu Service Mesh works with NSX-ALB’s GSLB,
    let’s quickly describe how NSX-ALB does GSLB on its own.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: Detour – GSLB without Tanzu Service Mesh
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'NSX ALB enables GSLB by implementing a DNS that will return the IP of a working
    instance of the service. Here’s the sequence of events:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: The client asks their local DNS server for an IP address for `shopping.gslb.acme.com`.
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The local DNS forwards to the authoritative DNS server for `gslb.acme.com`,
    which lives in the New York data center.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The authoritative DNS server, depending on the GSLB load balancing strategy
    and the health of the service instances, will return one of three IP addresses:
    the instance in the New York data center, the instance in the London data center,
    or the instance in AWS Oregon. Let’s say it returns `20.30.40.50`, which is the
    IP address of the NSX ALB Service Engines in the New York data center.'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The client makes an HTTPS request to `20.30.40.50` with an SNI header of `shopping.gslb.acme.com.`
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The NSX ALB Service Engine knows that requests with that particular SNI get
    routed to the `shopping` service in the `acme` namespace in the Kubernetes cluster
    running locally in the data center.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The client successfully orders his yoga mat.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, let’s layer in Tanzu Service Mesh.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: GSLB with NSX-ALB and Tanzu Service Mesh
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Everything from the previous section still applies, but rather than an operator
    manually setting up GSLB for the `shopping` service, she registers it in the service
    mesh as a `public` service ([https://docs.vmware.com/en/VMware-Tanzu-Service-Mesh/services/using-tanzu-service-mesh-guide/GUID-58A3FA7C-4EFC-44B2-B37B-D2152CB16359.html](https://docs.vmware.com/en/VMware-Tanzu-Service-Mesh/services/using-tanzu-service-mesh-guide/GUID-58A3FA7C-4EFC-44B2-B37B-D2152CB16359.html)).
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, she integrates Tanzu Service Mesh with her NSX ALB instances. Finally,
    Tanzu Service Mesh automatically begins to configure GSLB. Wherever the `shopping`
    service is deployed in the GNS, Tanzu Service Mesh will configure the GSLB DNS
    resolver to point to a cluster containing that service. You can read about this
    process in detail here: [https://docs.vmware.com/en/VMware-Tanzu-Service-Mesh/services/using-tanzu-service-mesh-guide/GUID-896EA3FA-17EA-49E2-B981-5C9634E45512.html](https://docs.vmware.com/en/VMware-Tanzu-Service-Mesh/services/using-tanzu-service-mesh-guide/GUID-896EA3FA-17EA-49E2-B981-5C9634E45512.html).'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-211
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we onboarded onto Tanzu Service Mesh, deployed a real-world
    application, discussed day-2 operations, and even covered GSLB, a very advanced
    topic. In the next chapter, we’ll attempt to put all the pieces together and paint
    a picture of what “good” looks like when using the entire Tanzu portfolio. I hope
    you’ll continue!
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
