- en: '1'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding Kubernetes Secrets Management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter will provide you with a refresher about containers, as well as
    a comprehensive overview of Kubernetes and its Secrets management implementation.
    By the end of this first walk-through, all personas (developers, platform, and
    security engineers) will know how to design and implement these topics with a
    set of hands-on examples. While going through these examples, we will highlight
    the respective security concerns that this book will address by covering a series
    of use cases that will lead to a production-grade solution for hybrid multi-cloud
    scenarios, including the business continuity perspective.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Kubernetes’ origins and design principles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up our first Kubernetes testing environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring Kubernetes `Secret` and `ConfigMap` objects
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Analyzing why Kubernetes Secrets are important
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unveiling the challenges and risks associated with Kubernetes Secrets management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mapping the objectives and scope of this book
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To complete the hands-on parts of this chapter, we will be leveraging a series
    of tools and platforms that are commonly used to interact with containers, Kubernetes,
    and Secrets management. For this first chapter, we will be setting up this environment
    together and ramping up with a friendly desktop graphical solution for the first
    set of examples. Don’t worry – we have you covered with our Code in Action and
    GitHub repository, which contains the macOS installation example. Here is the
    list of required tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '`systemd` at the user level to autostart containers/Pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Podman Desktop** ([https://podman-desktop.io](https://podman-desktop.io))
    is an open source software that provides a graphical user interface for building,
    starting, and debugging containers, running local Kubernetes instances, easing
    the migration from containers to Pods, and even connecting with remote platforms
    such as Red Hat OpenShift, Azure Kubernetes Engine, and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Golang** ([https://go.dev](https://go.dev)) or Go is a programming language
    that will be used within our examples. Note that Kubernetes and most of its third-party
    components are written in Go.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Git** ([https://git-scm.com](https://git-scm.com)) is a version control system
    that we will be using to cover this book’s examples but will also leverage in
    our discovery of Secrets management solutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This book’s GitHub repository contains the digital material linked to this
    book: [https://github.com/PacktPublishing/Kubernetes-Secrets-Handbook](https://github.com/PacktPublishing/Kubernetes-Secrets-Handbook).'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Kubernetes’ origins and design principles
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While the evolution from one platform to another might be obvious, the compelling
    event and inner mechanics might not be. To safely handle sensitive data within
    Kubernetes, we have to understand both its historical and architectural evolutions.
    This will help us implement a secure production-grade environment for our critical
    business applications.
  prefs: []
  type: TYPE_NORMAL
- en: The next few sections will describe a series of concepts, explore and practice
    them with a simple container runtime and Kubernetes cluster, and establish their
    direct relationships with security concerns that this handbook will address.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: While we expect you to perform the hands-on examples while reading along, we
    understand that you might not have the opportunity to do so. As such, we have
    provided briefings and debriefings for each hands-on example.
  prefs: []
  type: TYPE_NORMAL
- en: From bare metal to containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Four decades ago, deploying applications was done on a physical server, usually
    referred to as a *bare metal* installation. This approach allowed workloads to
    have direct access to physical resources with the best native performance possible.
    Due to out-of-the-box limitations for resource management from a software perspective,
    deploying more than one application on a physical server has always been an operational
    challenge that has resulted in a suboptimal model with the following root causes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Physical resource utilization**: A reduced set of applications is deployed
    on a physical machine to limit the potential degradation of services due to the
    lack of proper resource management capabilities that would have helped address
    applications hogging all the compute resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability, flexibility, and time to market**: The lead time in weeks or
    even months to procure, rack and stack, provision the physical machine, and have
    the application installed, which impacts business growth.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The total cost of ownership** (**TCO**) **versus innovation**: The procurement,
    integration, operations, and life cycle of physical servers, along with underutilized
    resources with limited prototyping due to high costs and lead time, slows down
    the organization’s innovation capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Then, in the early 2000s, virtualization or *hypervisors* became available for
    commoditized open systems. A hypervisor is a piece of software that’s merged into
    the operating system, installed on bare metal, that allows the IT department to
    create virtual machines. With this, operations teams were able to create and tailor
    these virtual machines to the application’s precise requirements with the ability
    to adapt the compute resources during the application’s life cycle and their usage
    by the business. Thanks to proper resource management and isolation, multiple
    virtual machines could run on a single server without having noisy neighbors causing
    potential service degradations.
  prefs: []
  type: TYPE_NORMAL
- en: 'This model provided tremendous optimizations that helped accelerate the digitalization
    of services and introduce a new market aside from the traditional data center
    business – cloud computing. However, the virtualization model created a new set
    of challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: The never-ending increase of virtual machines thanks to continuous innovation.
    This exponential growth of assets amplifies the operational burden to maintain
    and secure operating systems, libraries, and applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The increasing need for automation to perform daily **Create, Read, Update,
    and Delete** (**CRUD**) operations at a large scale involving complex infrastructure
    and security components.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The need for a well-thought governance that’s enforced to address the life cycle,
    security, and business continuity for thousands of services to support the business
    continuity of the organization’s critical applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, containers made their way as the next layer of optimization. Although
    the construct of containers was not new, as with virtualization, it required a
    major player to invest in the commoditized open systems to organically make it
    the next (r)evolution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s think about a container as a lightweight virtual machine but without
    the need for a full operating system, which reduces the overall footprint and
    operational burden related to the software development life cycle and security
    management. Instead, multiple applications, as containers, share the underlying
    physical host from a software and hardware level without the overhead of the hypervisor
    benefiting from nearly machine-native performance. The container provides you
    with the following benefits:'
  prefs: []
  type: TYPE_NORMAL
- en: A well-defined standard by the OCI ([https://opencontainers.org](https://opencontainers.org))
    to ease with building, (re)distributing, and deploying containers to any platform
    that’s compliant with the specifications of the OCI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A highly efficient, predictable, and immutable medium that’s application-centric
    and only includes the necessary libraries and the application runtime
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application portability thanks to an infrastructure and platform-agnostic solution
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An organic separation of concerns between the developers and platform engineers
    as there is no need to access the physical or virtual host operating system to
    develop, build, test, and deploy applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Embracing an automation-first approach and DevOps practices to address the infrastructure,
    application, and security management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Not mentioning a few challenges would be wrong, so here are some:'
  prefs: []
  type: TYPE_NORMAL
- en: Most IT organizations have difficulties embracing a new paradigm from both an
    architectural and management perspective
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Considering the organic serparation of concerns between the developers and platform
    engineers as a support to silos
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There’s an overhype around microservices, which leads to potential suboptimal
    application architecture with no performance optimization but added complexity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows the bottom-up stack, which shows the potential
    application density per physical server with their respective deployment type:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.1 – Layer comparison between bare metal, virtual machines, and containers](img/B20970_01_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.1 – Layer comparison between bare metal, virtual machines, and containers
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ve already cited a series of benefits, and yet, we should emphasize additional
    ones that help with rapid prototyping, faster deployment, easy live functional
    testing, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: A smaller code base to maintain and enrich per microservice with easier rollout/rollback
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The capability to run in a degraded mode when one of the microservices fails
    but not the others
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to troubleshoot misbehaving microservices without impacting the
    entire application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s faster to recover from failure as only the related microservice must be
    rescheduled
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Granular compute resource allocation and scalability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not only do microservices help decouple large monolithic applications but they
    also introduce new design patterns to accelerate innovation.
  prefs: []
  type: TYPE_NORMAL
- en: 'This sounds fantastic, doesn’t it? It does, but we still have a major missing
    element here: container runtimes such as Docker or Podman do not provide any resiliency
    in case of failures. To do so, a container runtime requires an additional software
    layer providing the applications with high availability capabilities. Managing
    hundreds of microservices at scale demands a robust and highly resilient orchestrator
    to ensure the business continuity of the applications while guaranteeing a high
    level of automation and abstraction toward the underlying infrastructure. This
    will lead to frictionless build, deploy, and run operations, improving the day-to-day
    responsibilities of the IT staff involved with the workloads that are deployed
    on the application platforms.'
  prefs: []
  type: TYPE_NORMAL
- en: This is a big ask and a challenge that many IT departments are facing and trying
    to solve, even more so with legacy patterns. The answer to this complex equation
    is Kubernetes, a container platform or, as we should call it, an application platform.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are no better words to describe what Kubernetes is all about than the
    words from the Kubernetes project maintainers: “*Containers are a good way to
    bundle and run your applications. In a production environment, you need to manage
    the containers that run the applications and ensure that there is no downtime.
    For example, if a container goes down, another container needs to start. Wouldn’t
    it be easier if this behavior was handled by* *a system?*'
  prefs: []
  type: TYPE_NORMAL
- en: '*That’s how Kubernetes comes to the rescue! Kubernetes provides you with a
    framework to run distributed systems resiliently. It takes care of scaling and
    failover for your application, provides deployment patterns, and* *more.*” ([https://kubernetes.io/docs/concepts/overview/#why-you-need-kubernetes-and-what-can-it-do](https://kubernetes.io/docs/concepts/overview/#why-you-need-kubernetes-and-what-can-it-do))'
  prefs: []
  type: TYPE_NORMAL
- en: 'The same page lists the following benefits of Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: Service discovery and load balancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Storage orchestration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automated rollouts and rollbacks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic bin packing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Self-healing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secret and configuration management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While reading through this handbook, we will explore and practice all of these
    benefits while designing a production-grade Secrets management solution for critical
    workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes design principles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have established the context regarding the evolution and adoption of containers
    with the need for Kubernetes to support our applications with resiliency, scalability,
    and deployment patterns in mind. But how is Kubernetes capable of such a frictionless
    experience?
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is my attempt to answer this question based on having experience as a
    former cloud architect within the Red Hat Professional Services organization:'
  prefs: []
  type: TYPE_NORMAL
- en: From a workload perspective, every infrastructure requirement that an application
    will consume is simply defined in a declarative way without the need for there
    to be a domain specialist in networking, storage, security, and so on. The YAML
    manifest describing the desired state of `Pod`, `Service`, and `Deployment` objects
    is then handled by Kubernetes as a service broker for every specific vendor who
    has a Kubernetes integration. In other words, application teams can safely write
    a manifest that is agnostic of the environment and Kubernetes distribution on
    which they will deploy the workloads.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: From an infrastructure perspective, every component of the stack has a corresponding
    Kubernetes API object. If not, the vendor can introduce their own with the standard
    Kubernetes API object called `CustomResourceDefinition`, also known as **CRD**.
    This guarantees a common standard, even when interacting with third-party software,
    hardware, or cloud vendors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When Kubernetes receives a request with a valid object definition, the orchestrator
    will apply the related CRUD operation. In other words, Kubernetes introduces native
    automation and orchestration. The same principles should apply to every Kubernetes
    component running as a container so that they benefit from self-healing, resiliency,
    and scalability while being agnostic of the underlying software, hardware, or
    cloud provider.
  prefs: []
  type: TYPE_NORMAL
- en: This approach supports the portability not only of containerized applications
    but of the entire application platform while reducing the need for technology
    domain specialists to be involved when deploying an application, maintaining the
    platform, and even enriching the Kubernetes project with new features or components.
  prefs: []
  type: TYPE_NORMAL
- en: 'The concept of a YAML manifest to define a Kubernetes API object has been floating
    around for a while. It is time to look at a simple example that shows the desired
    state of a `Pod` object (a logical grouping for one or multiple containers):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This `Pod` object’s definition provides the necessary information for Kubernetes
    to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Define the desired state for a `Pod` object with the name `hello-app`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specify that there are `containers` and that one of them is called `hello-world`
    and uses a container image of `hello-path`. For this, we want version `0.1` to
    be pulled from a container registry.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accept incoming traffic to the `hello-world` application, using port `8080`
    at the container level.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That’s it! This is our first `Pod` definition. It allows us to deploy a simple
    containerized application with no fuzz and zero knowledge of the underlying infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is not much magic behind this orchestration but the work of multiple
    components provides a fantastic level of resilience and abstraction, as well as
    a frictionless experience. The following diagram provides an overview of the components
    that run within a Kubernetes instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.2 – Kubernetes components](img/B20970_01_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.2 – Kubernetes components
  prefs: []
  type: TYPE_NORMAL
- en: 'A Kubernetes cluster can be divided into two logical groups – the control plane
    (some distributions refer to this as the master node) and the (worker) nodes.
    Let’s drill down into each logical group and discover their respective components:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Control plane:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-apiserver`: This component is responsible for exposing the Kubernetes
    API and enabling CRUD operations regarding the object definitions and their state
    within `etcd`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`etcd`: This component is a key value store and serves as the asset management
    service. A corrupted `etcd` results in a full disaster scenario.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-scheduler`: This component tracks the desired state of `Pod` and will
    address any potential drift within the cluster. As an example, if a `Pod` object
    definition is created or modified, `kube-scheduler` will adjust its state so that
    the containers only run on a healthy node.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-controller-manager`: This component runs a series of controllers that
    are responsible for handling the desired state of the nodes, jobs, endpoints,
    and service accounts. Controllers are reconciliation loops that track the difference
    between the desired and current state of an object and adjust the latter so that
    it matches the latest object definition.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cloud-controller-manager` (*optional*): Similar to `kube-controller-manager`,
    this component, when deploying Kubernetes in the cloud, enriches the cluster with
    additional abstractions to interact with the related cloud provider services.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nodes (and the control plane too!):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubelet`: This component interacts with `kube-apiserver` to verify and adjust
    the desired states of Pods bound to the node'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubeproxy`: This component provides the basic network plumbing on each node
    while maintaining the networking rules to allow (or not) the internal and external
    network traffic to Pods'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`container runtime`: This component runs the containers'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: There are additional components that should be considered as add-ons due to
    their direct dependency on the Kubernetes distribution. These add-ons would be
    responsible for handling services such as DNS, logging, metrics, the user interface,
    and more.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: In a dev/test environment, a single node might be deployed to act both as a
    control plane and a worker node on which Pods will be scheduled. However, for
    resiliency purposes, a production-grade environment should consider a minimum
    of three control planes with dedicated worker nodes to improve resilience and
    separation of concerns, as well as dedicate compute resources for the applications.
  prefs: []
  type: TYPE_NORMAL
- en: Getting hands-on – from a local container to a Kubernetes Pod
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main benefits of containers are their portability and being platform agnostic.
    Deploying the famous *Hello World* application within a container using Docker,
    Podman, or Kubernetes should not require us to modify the application code. I
    will even go a step further and say that we should not care about the underlying
    infrastructure. On the other hand, there would be a large umbrella of constraints
    to deal with when deploying an application with a bare metal or virtualization
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we start, we assume that you have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: All the technical requirements mentioned at the beginning of this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to this book’s GitHub repository ([https://github.com/PacktPublishing/Kubernetes-Secrets-Handbook](https://github.com/PacktPublishing/Kubernetes-Secrets-Handbook))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This example at hand; it is available in the `ch01/example01` folder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s have a look at a simple example illustrating a basic software supply
    chain:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Building the application binary**: The example is a simple Go application
    showcasing an HTTP service and console logging capabilities'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Building the container image, including the application binary**: The application
    will be built using a Golang toolset container image; a second small footprint
    container image will be used to carry the application binary'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Running the containerized application using Podman**: This first run will
    leverage the graphical interface of Podman Desktop to illustrate the rather simple
    process of running a container'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubectl` command line to showcase how to process our first YAML manifest to
    create a Kubernetes `Pod` object'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that this example is agnostic of the CPU architecture on which the overall
    process will take place. This means that you can safely perform the same exercise
    on different CPU targets without the need to rewrite code or change any of the
    configuration files.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is interesting to note that a container runtime such as Docker or Podman
    is used to build the application and the container image containing our application
    binary. This is done via a text file called a Dockerfile, which defines all the
    necessary steps to build our container image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The Dockerfile build steps are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Fetch the `go-toolset` image for the build.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Get all the application content in that image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the Go build process.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Fetch the `ubi-micro` image as the target container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set some container image metadata.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Copy the binary from the build image to the target image.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set a port exposure for the application. Here, this is `8080`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the application binary.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: That’s it! Once the application has been built and the container image has been
    successfully created and pushed to the registry, the container image will be available
    in the localhost container registry, after which the container can be started
    using either Docker or Podman. This can be done through one simple command line
    with a few parameters, though you can leverage the Podman Desktop graphical interface.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, running this container on an application platform such as
    Kubernetes requires a different approach – that is, declaratively using a YAML
    manifest. An example was supplied earlier in this chapter and can be found in
    this book’s GitHub repository. This YAML manifest is submitted to `kube-apiserver`
    via a tool such as `kubectl`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a transactional overview of a Kubernetes `Pod` object’s creation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 1.3 – Kubernetes Pod creation](img/B20970_01_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.3 – Kubernetes Pod creation
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, the `etcd` record is continuously updated during the `Pod` object’s
    creation. The desired state is saved; the current status of every component involved
    in the process is also saved, which generates a sort of audit trail. Such a design
    allows for easier debugging when the desired outcome is not achieved.
  prefs: []
  type: TYPE_NORMAL
- en: As soon as the `Pod` object is registered within `etcd`, all the Kubernetes
    components are on a mission to converge toward the desired state, regardless of
    potential issues such as network partitioning, node failure, and more. This is
    the difference between running containers on a single machine with a local container
    runtime such as Docker or Podman and orchestrating containers at scale with a
    container platform such as Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s some food for thought:'
  prefs: []
  type: TYPE_NORMAL
- en: I wrote “*running the containerized applications*” and “*deploying the containerized
    application*” to illustrate the difference between a container runtime such as
    Docker or Podman running a containerized application and Kubernetes scheduling
    containers and orchestrating other resources such as networking, storage, Secrets,
    and more. Note that there is a Kubernetes object called `Deployment` that addresses
    release management and scalability capabilities. For more details, see [https://kubernetes.io/docs/concepts/workloads/controllers/deployment/](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing such an exercise even in a non-production environment using virtual
    machines could take days, even weeks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developing applications using containers, for both monolithic or microservice
    application architecture, allows for a truly agile development cycle calling for
    everything to be continuous (development, integration, improvement, and deployment).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using YAML manifests to deploy applications will trigger an organic usage of
    Git repositories that will spark another practice – GitOps. In short, every desired
    state definition of an application and its infrastructure management lands in
    a Git repository, providing the *application* and *infrastructure* teams with
    a central point of configuration management, including, by default, authorization,
    peer review, and organization.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that, we’ve transitioned from running the target application through a
    local container to running it through a Kubernetes Pod. By doing so, we acquired
    an understanding of how a Pod is created, which Kubernetes components are involved,
    the interactions that are involved, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Secrets within Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we had a refresher on containers and Kubernetes, and we also
    proceeded with a hands-on example that helped us establish key concepts, such
    as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The evolution of application deployment through times and technologies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why containers and Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The architecture and principles of Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building and running containers using Podman Desktop and Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With the knowledge we’ve acquired, we can start looking at the more advanced
    concept of Secrets within Kubernetes. We will dive into the details of how Secrets
    are stored on Kubernetes, how they are injected into a Pod, which is the smallest
    execution unit, and the security concerns that we have to tackle.
  prefs: []
  type: TYPE_NORMAL
- en: Secrets concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Interestingly enough, during my time designing and deploying Red Hat OpenShift,
    this topic was always considered irrelevant to the customer and partner teams
    that I was working with. Reflecting, I concluded that this is linked to the legacy
    patterns we have been working with for the last two or three decades.
  prefs: []
  type: TYPE_NORMAL
- en: In a traditional environment, both with physical and virtual machines, there
    is a clear outcome from the separation of concerns principle. The infrastructure
    teams care about the infrastructure and the application teams care about applications.
    This includes managing Secrets such as credentials, tokens, license keys, certificates,
    and more. No one from the application teams will share credentials for a MySQL
    database with the infrastructure teams.
  prefs: []
  type: TYPE_NORMAL
- en: 'When it comes to Kubernetes, these concerns are, by design, merged into a point
    of entry: the application platform. Despite the separation of concerns, the Kubernetes
    integration with external API-driven services requires credentials, tokens, or
    certificates to authenticate and trust themselves. These Secrets have to stay
    within the platform to ensure resiliency, scalability, and orchestration for both
    the cluster and applications.'
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to the container image’s design, Secrets cannot be hardcoded or
    included in the container image. By hardcoding Secrets, they become available
    to all internal and external stakeholders with access to the container image registry.
    If the container image is pushed to a public registry, which is common to ease
    with redistribution, it will make the Secrets available to an even wider audience.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is the reason why Kubernetes has a Secrets management framework built
    into it with a dedicated API object called `Secret`. Here is an overview of what
    a `Secret` object definition would look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s go through the manifest:'
  prefs: []
  type: TYPE_NORMAL
- en: We informed Kubernetes that we wanted to create a `Secret` object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The name for this object is `mysecret` and we defined a type called `Opaque`,
    which means that we are defining the container of the `data` field ourselves
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `data` field is composed of two key-value pairs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s have a closer look at these key-value pairs. What seems to be a random
    set of characters is data being encoded in `base64`.
  prefs: []
  type: TYPE_NORMAL
- en: Why `base64`? While we could assume the need to encrypt sensitive data such
    as credentials, the usage of `base64` is only to ease the processing that’s done
    through the command line, the network, and by `kube-apiserver` to avoid us processing
    a truncated payload due to special characters.
  prefs: []
  type: TYPE_NORMAL
- en: These two entries can be decoded on every operating system or website offering
    a `base64` encoding/decoding tool. So, should we assume that `kube-apiserver`,
    when saving the payload within the `etcd` key store, will encrypt the data? Well,
    this handbook has already given you a good hint that it doesn’t!
  prefs: []
  type: TYPE_NORMAL
- en: 'Another API object has a similar data field that can be used to share sensitive
    data with an application: `ConfigMap`. While `ConfigMap` was designed to carry
    out environment variables and application arguments, its usage has been rapidly
    adopted by developers to also include advanced application configuration, similar
    to a license key file. This object’s content could be leveraged by a malicious
    hacker to access containers, gain access to other workloads either inside or outside
    the platform, and even gain control of the Kubernetes cluster. As such, `ConfigMap`
    should be carefully handled, just like `Secret` objects. Here is an overview of
    a `ConfigMap` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, there is a major difference between the `data` field of `Secret`
    and the `data` field of `ConfigMap` – the encoding part. The `data` field specification
    of `ConfigMap` expects UTF-8 strings while the `Secret` one expects key-value
    pairs with the value encoded in `base64`. This example shows a way to set an application
    to `dev` mode, thus enabling extra instrumentation for debugging purposes.
  prefs: []
  type: TYPE_NORMAL
- en: Storing Secrets on Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now is a good time for a second hands-on example so that we can understand
    the differences between Secrets and the other Kubernetes objects, such as `ConfigMap`.
    Before we start, we assume that you have the following:'
  prefs: []
  type: TYPE_NORMAL
- en: All the technical requirements mentioned at the beginning of this chapter
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Access to this book’s GitHub repository: [https://github.com/PacktPublishing/Kubernetes-Secrets-Handbook](https://github.com/PacktPublishing/Kubernetes-Secrets-Handbook)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The example at hand; it is available in the `ch01/example02` folder
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s have a look at what we are accomplishing with this example:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we are creating a `Secret` object using the provided YAML manifest, a
    secret definition similar to the one we created for `mysecret` earlier. We are
    also checking its status and how to recover its definition from Kubernetes. This
    is always handy when we want to recover the current state of an object so that
    we can create it again later. We are also decoding the `base64` payload to reveal
    the key-value pairs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we are recovering the YAML manifest from Kubernetes to show a very simple
    way to get back our `Secret` object and its sensitive data. In other words, if
    malicious hackers succeed in interacting with `kube-apiserver`, then they can
    extract some or all `Secret` objects from a Kubernetes cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Next, we are creating a new `Secret` object from scratch by encoding the key-value
    pairs in `base64`, writing the YAML manifest, and pushing it via the command line.
    Here is a transactional overview of a Kubernetes `Secret` object’s creation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.4 – Secret creation](img/B20970_01_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.4 – Secret creation
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to access the `Secret` payload from a `Pod` object. In this
    example, we are using a special type of container called `busybox` that provides
    a small footprint environment that’s ideal for performing testing/debugging. The
    `Pod` manifest includes the reference to our newly created `Secret` object and
    assigns the value to an environment variable that we will `echo` from `busybox`.
    This will appear within container logs. Here is a transactional overview of a
    Kubernetes `Pod` object being created, including the `Secret` object being injected:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 1.5 – Injecting Secret into Pod](img/B20970_01_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1.5 – Injecting Secret into Pod
  prefs: []
  type: TYPE_NORMAL
- en: Note that the `kubelet` component will be responsible for decoding the `base64`
    payload. This is to ensure that the payload is transported between the different
    components and across the wire.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, we access the `etcd` key store via its API. This shows that the data that’s
    retrieved via such a method is not encrypted nor `base64` encoded! At this stage,
    malicious hackers who have successfully breached the `etcd` Pod have full access
    to Kubernetes asset management and can control the entire destiny of the application
    platform up to a cloud provider account if it’s deployed in such a setup.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, we are going one step further by extracting the `etcd` file locally
    and examining it to retrieve our last created `Secret` object. This seems to be
    a far-fetched scenario but think about filesystem access or backups taken of the
    Kubernetes cluster, which includes the `etcd` file. Even if the Kubernetes cluster
    is well-hardened with limited security exposure, malicious hackers who breach
    the storage and/or backup system(s) can retrieve all the `Secret` objects from
    such files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compared to the previous `Pod` creation workflow, we can establish the relatively
    low impact from a transaction perspective on the overall process. Note that our
    first example shows how to load the `Secret` key-value pairs as environment variables.
    However, other options also exist; we will be exploring their potential mitigations
    later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'Only the container that has the environment variable defined within its `Pod`
    specs will have access to the key-value pairs. However, containers running with
    `privileged: true` will have access to all Secrets from the node on which it runs,
    resulting in a major security exposure.'
  prefs: []
  type: TYPE_NORMAL
- en: Why should we care?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While Kubernetes provides a frictionless experience for both the platform and
    application teams, it does not provide you with a hardened solution.
  prefs: []
  type: TYPE_NORMAL
- en: The first approach to tackle this security concern would be to leverage a vault
    solution (the likes of HashiCorp Vault, CyberArk Conjure, or Azure Key Vault).
    However, this would only secure the application side. We are still exposed to
    taking into account the usage of `ConfigMap` or multi-cluster services such as
    application interconnect, which involves leveraging mutual authentication with
    certificates generated and deployed within the application platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, let’s rethink the requirements into simple layers:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Secret` objects are created to allow internal components to interact with
    others (storage, networking, execution units, controllers, and so on). Third-party
    components being deployed later on to enrich the platform’s capabilities will
    follow the same model. These `Secret` objects should not be offloaded to a vault
    solution for resilience purposes. If there is any type of partitioning with the
    external Vault solution, the Kubernetes cluster will start collapsing, along with
    all the workloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ConfigMap` object, an encryption key for their volumes, TLS certificates,
    and so on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Similar to the observation about platform-related `Secret` objects, these should
    be stored within Kubernetes to ensure the scheduling, self-healing, and operability
    capabilities of the application platform.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By design, Kubernetes will not become a storage system or an encrypted Vault
    to protect sensitive data. Instead, Kubernetes will provide the necessary framework
    to interconnect and leverage the expertise of third-party solutions addressing
    each domain’s specific needs.
  prefs: []
  type: TYPE_NORMAL
- en: Considering these aspects, addressing the security concerns for Secrets Management
    in Kubernetes is not as simple as ticking a box.
  prefs: []
  type: TYPE_NORMAL
- en: Security exposures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we have established the benefits of containerized applications
    running on Kubernetes but also the security challenges of Secrets Management on
    such application platforms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Through our hands-on examples, we have acknowledged how unsafe our sensitive
    data is within `Secret` and `ConfigMap` objects. We can also list a series of
    security exposures to be exploited to compromise the application platform, including
    external services:'
  prefs: []
  type: TYPE_NORMAL
- en: '**kube-apiserver**: This is the main component of Kubernetes and malicious
    hackers can leverage this first point of entry to the application platform'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`etcd` does not provide any encryption capabilities. The database file is a
    binary file that can be easily read.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-apiserver` component, `etcd` is an API-driven service and any access
    or network trace can expose the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Pod` object means accessing the filesystem on which the database file is written.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`etcd` Pod has its filesystem hosted on a volume to provide persistent storage.
    This volume is attached to the node, and by accessing the node, the data can also
    be accessed through the attached volume.*   `etcd` file. Accessing the backup
    can expose the data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are various ways that Secrets can be exposed. For example, you can interact
    with Kubernetes components such as `kube-apiserver` and `etcd` to do this or go
    through a physical level such as direct node access or access to backups.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we introduced containers, Kubernetes, and Secrets. We provided
    an overview of the history so far, going through the concepts of bare metal, virtual
    machine, and container-based deployments. We had the opportunity to understand
    the benefits of containerization and introduce container orchestration engines.
    We learned more about Kubernetes and its components, which made it possible for
    us to run our first Kubernetes secret example and also have a deep dive into the
    Kubernetes components involved to facilitate secret usage. This helped us identify
    the security and robustness concerns that come with the usage of Kubernetes Secrets.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will focus on the different types of Kubernetes Secrets,
    their usages, and the cross-cutting concerns that Secrets come with, such as auditing
    and access permissions.
  prefs: []
  type: TYPE_NORMAL
