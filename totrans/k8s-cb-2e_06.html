<html><head></head><body>
        <section>

                            <header>
                    <h1 class="header-title">Building Kubernetes on AWS</h1>
                </header>
            
            <article>
                
<p class="mce-root">The following recipes are covered in this chapter:</p>
<ul>
<li>Playing with Amazon Web Services</li>
<li>Setting up Kubernetes by kops</li>
<li>Using AWS as Kubernetes Cloud Provider</li>
<li>Managing Kubernete cluster on AWS by kops</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Introduction</h1>
                </header>
            
            <article>
                
<div class="page">
<div class="layoutArea">
<div class="column">
<p>Based on a recent survey of the Cloud Native Computing Foundation, CNCF, <strong>Amazon Web Services</strong> (<strong>AWS</strong>) is a dominant solution for production-level Kubernetes systems (<a href="https://www.cncf.io/blog/2017/12/06/cloud-native-technologies-scaling-production-applications/">https://www.cncf.io/blog/2017/12/06/cloud-native-technologies-scaling-production-applications/</a>). In this chapter, you will learn about the cloud services of AWS, and how these services work together to deliver a robust Kubernetes system. We will also introduce how kops works, a tool for Kubernetes operation, which helps us manage the Kubernetes cluster. Let's explore the world of Kubernetes in AWS!</p>
</div>
</div>
</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Playing with Amazon Web Services</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT"><span>Amazon Web Services (</span><a href="https://aws.amazon.com/"><span>https://aws.amazon.com</span></a><span>) is the most popular public cloud service. It provides the online service for Virtual Server (EC2), Software Defined Network (VPC), Object Store (S3), and so on. It is a suitable infrastructure to set up a Kubernetes cluster. We will explore AWS to understand the fundamental function of AWS.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT"><span>First of all, you need to sign up to AWS. AWS gives a free tier that allows you to use some amount of AWS resources, free for 12 months. Go to</span> <a href="https://aws.amazon.com/free/"><span>https://aws.amazon.com/free/</span></a> <span>to register your information and credit card. It may take 24 hours to verify and activate your account.</span></p>
<p class="NormalPACKT"><span>Once your AWS account is activated, we need to create one <strong>Identity and Access Management</strong> (<strong>IAM</strong>) user, which will control your AWS infrastructure via APIs. Then, install the AWS</span> CLI <span>on to your computer.</span></p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating an IAM user</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT"><span>Perform the following steps to create an IAM user:</span></p>
<ol>
<li class="NormalPACKT"><span>Go to AWS Web console</span> <a href="https://console.aws.amazon.com"><span>https://console.aws.amazon.com</span></a>.</li>
<li class="NormalPACKT"><span>Click on <span class="packt_screen">IAM</span> (use the search box, which makes it easier to find):</span></li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-657 image-border" src="assets/e5cf92cc-6868-4735-a725-6d57a0725e32.png" style="width:51.75em;height:25.75em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Access to IAM console</div>
<ol start="3">
<li>Click on <span class="packt_screen">Users</span> in the left navigation and then click on <span class="packt_screen">Add user</span>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-658 image-border" src="assets/35a36126-64d0-49e6-9a79-103209103aaa.png" style="width:41.83em;height:20.83em;"/></div>
<div class="mce-root packt_figref CDPAlignCenter CDPAlign"><span>Creating an IAM user</span></div>
<ol start="4">
<li>Type <span class="packt_screen">User name</span> <kbd>chap6</kbd>, then choose <span class="packt_screen">Programmatic access</span>:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-660 image-border" src="assets/fe599cfc-8532-499e-9784-30dfc41a75cd.png" style="width:38.75em;height:24.25em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span><span>Creating chap6 user</span></span></div>
<ol start="5">
<li>Choose <span class="packt_screen">Attach existing policies</span> <span class="packt_screen">directly</span>, as shown in the following screenshot,<span class="packt_screen"> </span>and then select the following policies:
<ul>
<li><span class="packt_screen">AmazonEC2FullAccess</span></li>
<li><span class="packt_screen">AmazonRoute53FullAcccess</span></li>
<li><span class="packt_screen">AmazonS3FullAccess</span></li>
<li><span class="packt_screen">AmazonVPCFullAccess</span></li>
<li><span class="packt_screen">IAMFullAccess</span></li>
</ul>
</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-661 image-border" src="assets/301e2810-98e5-4151-94f4-c7983a5d6d22.png" style="width:45.00em;height:27.50em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Attaching the necessary Policy</span></div>
<ol start="6">
<li>Eventually, it generates <span class="packt_screen">Access key ID</span> and <span class="packt_screen">Secret access key</span>. Copy and paste into your text editor or click on <span class="packt_screen">Download .csv</span> to preserve to your computer:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-662 image-border" src="assets/15b0a0e3-91ca-4c49-9074-48a042f112e9.png" style="width:46.50em;height:28.42em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Downloading Access key ID and Secret access key</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing AWS CLI on macOS</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT"><span>Install <kbd>awscli</kbd> to macOS using HomeBrew (<a href="https://brew.sh">https://brew.sh</a>); this is the easiest way. HomeBrew has already been introduced in</span> <a href="4dd5324f-b753-4c80-b891-bd8e6013b2c1.xhtml" target="_blank">Chapter 1</a>, <span><em>Building your own Kubernetes Cluster</em>, while installing minikube.</span></p>
<p class="NormalPACKT"><span>To install awscli by HomeBrew on your Mac, perform the following steps:</span></p>
<ol>
<li class="NormalPACKT"><span>Type the following command to update the latest formula:</span></li>
</ol>
<pre class="NormalPACKT" style="padding-left: 90px"><strong><span>$ brew update</span></strong></pre>
<ol start="2">
<li>Specify <kbd>awscli</kbd> to install:</li>
</ol>
<pre class="NormalPACKT" style="padding-left: 90px"><strong><span>$ brew install awscli</span></strong></pre>
<ol start="3">
<li>Verify the <kbd>aws</kbd> command using the<kbd> --version</kbd> option:</li>
</ol>
<pre class="NormalPACKT" style="padding-left: 90px"><strong><span>$ aws --version<br/></span><span>aws-cli/1.15.0 Python/3.6.5 Darwin/17.5.0 botocore/1.10.0</span></strong></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Installing AWS CLI on Windows</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT"><span>Install awscli on Windows; there is a Windows installer package, which is the easiest way to install  awscli on to your Windows:</span></p>
<ol>
<li class="NormalPACKT"><span>Go to AWS Command Line Interface page (</span><a href="https://aws.amazon.com/cli/"><span>https://aws.amazon.com/cli/</span></a><span>).</span></li>
<li class="NormalPACKT">Download Windows installer 64 bit (<a href="https://s3.amazonaws.com/aws-cli/AWSCLI64.msi">https://s3.amazonaws.com/aws-cli/AWSCLI64.msi</a><span>) or 32 bit (</span><a href="https://s3.amazonaws.com/aws-cli/AWSCLI32.msi">https://s3.amazonaws.com/aws-cli/AWSCLI32.msi</a><span>), based on your Windows OS.</span></li>
<li class="NormalPACKT">Launch AWS CLI installer, and then choose the default option to proceed with the installation:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-677 image-border" src="assets/d30f75b4-ae98-4293-9f1c-bfde62241948.png" style="width:30.83em;height:23.58em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span><span>Installing AWS CLI for Windows</span></span></div>
<ol start="4">
<li>After complete installation, launch Command Prompt. Then, type the <kbd>aws</kbd> command with the <kbd>--version</kbd> option to verify:</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-678 image-border" src="assets/5f175700-22de-4607-9433-3c09cd6f7fad.png" style="width:37.08em;height:19.42em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>Showing aws command on Windows</span></div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>First of all, you need to set your <span class="packt_screen">AWS Access Key ID</span> and <span class="packt_screen">AWS Secret Access Key</span> for awscli. We've already acquired <kbd>chap6</kbd><span> for the IAM user.</span> We will use this user's Access Key ID and Secret Access Key.</p>
<ol>
<li>Launch terminal (Command Prompt for Windows), and then use the <kbd>aws</kbd> command to set <kbd>Access Key ID</kbd> and <kbd>Secret Access Key</kbd>. Also, set the default region as <kbd>us-east-1</kbd>:</li>
</ol>
<pre style="padding-left: 90px">$ aws configure<br/>AWS Access Key ID [None]: <strong>&lt;Your Access KeyID&gt;</strong><br/>AWS Secret Access Key [None]: <strong>&lt;Your Secret Access Key&gt;</strong><br/>Default region name [None]: <strong>us-east-1</strong><br/>Default output format [None]:</pre>
<ol start="2">
<li>Check <kbd>chap6</kbd> <span>IAM user </span>using the following command:</li>
</ol>
<pre style="padding-left: 90px">$ aws iam get-user<br/>{<br/>   "User": {<br/>       "Path": "/",<br/>       "UserName": "chap6",<br/>       "UserId": "*********************",<br/>       "Arn": "arn:aws:iam::***************:user/chap6",<br/>       "CreateDate": "2018-04-14T04:22:21Z"<br/>    }<br/>}</pre>
<p>That's it! Now you can start using AWS to launch your own network and instances.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>Let's explorer AWS to launch a typical infrastructure. Using awscli to build your own VPC, Subnet, Gateway, and Security group. Then, launch the EC2 instance to understand the basic usage of AWS.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Creating VPC and Subnets</h1>
                </header>
            
            <article>
                
<p><strong>Virtual Private Cloud</strong> (<strong><span>VPC</span></strong>) is a Software-Defined Network. You can configure a virtual network on AWS. Subnets are inside of VPC that define network block (<strong>Classless Inter Domain Routing</strong> (<strong><span>CIDR</span></strong>)) such as <kbd>192.168.1.0/24</kbd>.</p>
<p>Let's create one VPC and two subnets using the following steps:</p>
<ol>
<li>Create a new VPC that has <kbd>192.168.0.0/16</kbd> CIDR block (IP range: <kbd>192.168.0.0</kbd> – <kbd>192.168.255.255</kbd>). Then, capture <kbd>VpcId</kbd>:</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 create-vpc --cidr-block 192.168.0.0/16<br/>{<br/>    "Vpc": {<br/>        "CidrBlock": "192.168.0.0/16",<br/>        "DhcpOptionsId": "dopt-3d901958",<br/>        "State": "pending",<br/>        "VpcId": "<strong>vpc-69cfbd12</strong>",<br/>        "InstanceTenancy": "default",<br/>       "Ipv6CidrBlockAssociationSet": [],<br/>        "CidrBlockAssociationSet": [<br/>            {<br/>                "AssociationId": "vpc-cidr-assoc-c35411ae",<br/>                "CidrBlock": "192.168.0.0/16",<br/>                "CidrBlockState": {<br/>                    "State": "associated"<br/>                }<br/>            }<br/>        ],<br/>        "IsDefault": false,<br/>        "Tags": []<br/>    }<br/>}</pre>
<ol start="2">
<li>Create the first subnet under the VPC (<kbd>vpc-69cfbd12</kbd>) that has <kbd>192.168.0.0/24</kbd> CIDR block (IP range: <kbd>192.168.0.0</kbd> – <kbd>192.168.0.255</kbd>) and specify the availability zone as <kbd>us-east-1a</kbd>. Then, capture <kbd>SubnetId:</kbd></li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 create-subnet --vpc-id vpc-69cfbd12 --cidr-block 192.168.0.0/24 --availability-zone us-east-1a<br/>{<br/>    "Subnet": {<br/>        "AvailabilityZone": "us-east-1a",<br/>        "AvailableIpAddressCount": 251,<br/>        "CidrBlock": "192.168.0.0/24",<br/>        "DefaultForAz": false,<br/>        "MapPublicIpOnLaunch": false,<br/>        "State": "pending",<br/>        "SubnetId": "<strong>subnet-6296863f</strong>",<br/>        "VpcId": "vpc-69cfbd12",<br/>       "AssignIpv6AddressOnCreation": false,<br/>       "Ipv6CidrBlockAssociationSet": []<br/>    }<br/>}</pre>
<ol start="3">
<li>Create the second subnet on <kbd>us-east-1b</kbd>, which has <kbd>192.168.1.0/24</kbd> CIDR block (IP range: <kbd>192.168.1.0</kbd> – <kbd>192.168.1.255</kbd>). Then, capture <kbd>SubnetId</kbd>:</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 create-subnet --vpc-id vpc-69cfbd12 --cidr-block 192.168.1.0/24 --availability-zone us-east-1b<br/>{<br/>    "Subnet": {<br/>        "AvailabilityZone": "us-east-1b",<br/>        "AvailableIpAddressCount": 251,<br/>        "CidrBlock": "192.168.1.0/24",<br/>        "DefaultForAz": false,<br/>        "MapPublicIpOnLaunch": false,<br/>        "State": "pending",<br/>        "SubnetId": "<strong>subnet-ce947da9</strong>",<br/>        "VpcId": "vpc-69cfbd12",<br/>       "AssignIpv6AddressOnCreation": false,<br/>       "Ipv6CidrBlockAssociationSet": []<br/>    }<br/>}</pre>
<ol start="4">
<li>Check the subnet list under VPC (<kbd>vpc-69cfbd12</kbd>) using the following command:</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 describe-subnets --filters "Name=vpc-id,Values=vpc-69cfbd12" --query "Subnets[*].{Vpc:VpcId,CIDR:CidrBlock,AZ:AvailabilityZone,Id:SubnetId}" --output=table<br/>---------------------------------------------------------------------<br/>|                          DescribeSubnets                          |<br/>+------------+------------------+-------------------+---------------+<br/>|     AZ     |      CIDR        |       Id          |      Vpc      |<br/>+------------+------------------+-------------------+---------------+<br/>|  <strong>us-east-1a</strong>|  <strong>192.168.0.0/24</strong>  |  <strong>subnet-6296863f</strong>  |  <strong>vpc-69cfbd12 </strong>|<br/>|  <strong>us-east-1b</strong>|  <strong>192.168.1.0/24</strong>  |  <strong>subnet-ce947da9</strong>  |  <strong>vpc-69cfbd12 </strong>|<br/>+------------+------------------+-------------------+---------------+</pre>
<p>This looks good!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Internet gateway</h1>
                </header>
            
            <article>
                
<p>To access your VPC network, you need to have a gateway that accesses it from the internet. <strong>Internet Gateway</strong> (<strong>IGW</strong>) is the one that connects the internet to your VPC.</p>
<p>Then, in the subnets under VPC, you can set the default route to go to IGW or not. If it routes to IGW, the subnet is classified as the public subnet. Then, you can assign the global IP address on the public subnet.</p>
<p>Let's configure the first subnet (<kbd>192.168.0.0/24</kbd>) as the public subnet that routes to IGW using the following steps:</p>
<ol>
<li>Create IGW and capture <kbd>InternetGatewayId</kbd>:</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 create-internet-gateway<br/>{<br/>   "InternetGateway": {<br/>       "Attachments": [],<br/>       "InternetGatewayId": "<strong>igw-e50b849d</strong>",<br/>       "Tags": []<br/>    }<br/>}</pre>
<ol start="2">
<li>Attach IGW (<kbd>igw-e50b849d</kbd>) to your VPC (<kbd>vpc-69cfbd12</kbd>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 attach-internet-gateway --vpc-id vpc-69cfbd12 --internet-gateway-id igw-e50b849d</pre>
<ol start="3">
<li>Create a routing table on VPC (<kbd>vpc-69cfbd12</kbd>) and then capture <kbd>RouteTableId:</kbd></li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 create-route-table --vpc-id vpc-69cfbd12<br/>{<br/>    "RouteTable": {<br/>       "Associations": [],<br/>       "PropagatingVgws": [],<br/>       "RouteTableId": "<strong>rtb-a9e791d5</strong>",<br/>       "Routes": [<br/>            {<br/>               "DestinationCidrBlock": "192.168.0.0/16",<br/>               "GatewayId": "local",<br/>               "Origin": "CreateRouteTable",<br/>               "State": "active"<br/>            }<br/>        ],<br/>       "Tags": [],<br/>       "VpcId": "vpc-69cfbd12"<br/>    }<br/>}</pre>
<ol start="4">
<li>Set the default route (<kbd>0.0.0.0/0</kbd>) for r<span>oute table (</span><kbd>rtb-a9e791d5</kbd><span>)</span> as IGW (<kbd>igw-e50b849d</kbd>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 create-route --route-table-id rtb-a9e791d5 --gateway-id igw-e50b849d --destination-cidr-block 0.0.0.0/0</pre>
<ol start="5">
<li>Associate route table (<kbd>rtb-a9e791d5</kbd>) to public subnet (<kbd>subnet-6296863f</kbd>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 associate-route-table --route-table-id rtb-a9e791d5 --subnet-id subnet-6296863f</pre>
<ol start="6">
<li>Enable autoassign public IP on the public subnet (<kbd>subnet-6296863f</kbd>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 modify-subnet-attribute --subnet-id subnet-6296863f --map-public-ip-on-launch</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">NAT-GW</h1>
                </header>
            
            <article>
                
<p>What happens if the subnet default route is not pointing to IGW? The subnet is classified as a private subnet with no connectivity to the internet. However, some of situation, your VM in private subnet needs to access to the Internet. For example, download some security patch.</p>
<p>In this case, you can setup NAT-GW. It allows you access to the internet from the private subnet. However, it allows outgoing traffic only, so you cannot assign public IP address for a private subnet. Therefore, it is suitable for backend instances, such as the database.</p>
<p>Let's create NAT-GW and configure a second subnet (<kbd>192.168.1.0/24</kbd>) as a private subnet that routes to NAT-GW using the following steps:</p>
<ol>
<li>NAT-GW needs a Global IP address, so create <strong>Elastic IP</strong> (<strong><span>EIP</span></strong>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 allocate-address<br/>{<br/>   "PublicIp": "18.232.18.38",<br/>   "AllocationId": "<strong>eipalloc-bad28bb3</strong>",<br/>   "Domain": "vpc"<br/>}</pre>
<ol start="2">
<li>Create NAT-GW on the public subnet (<kbd>subnet-6296863f</kbd>) and assign EIP (<kbd>eipalloc-bad28bb3</kbd>). Then, capture <kbd>NatGatewayId</kbd>.</li>
</ol>
<div class="packt_infobox">Since NAT-GW needs to access the internet, it must be located on the public subnet instead of the private subnet.</div>
<p style="padding-left: 60px">Input the following command:</p>
<pre style="padding-left: 90px">$ aws ec2 create-nat-gateway --subnet-id subnet-6296863f --allocation-id eipalloc-bad28bb3<br/>{<br/>   "NatGateway": {<br/>       "CreateTime": "2018-04-14T18:49:36.000Z",<br/>       "NatGatewayAddresses": [<br/>            {<br/>               "AllocationId": "eipalloc-bad28bb3"<br/>            }<br/>       ],<br/>       "NatGatewayId": "<strong>nat-0b12be42c575bba43</strong>",<br/>       "State": "pending",<br/>       "SubnetId": "subnet-6296863f",<br/>       "VpcId": "vpc-69cfbd12"<br/>    }<br/>}</pre>
<ol start="3">
<li>Create the route table and capture <kbd>RouteTableId</kbd>:</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 create-route-table --vpc-id vpc-69cfbd12<br/>{<br/>   "RouteTable": {<br/>       "Associations": [],<br/>       "PropagatingVgws": [],<br/>       "RouteTableId": "<strong>rtb-70f1870c</strong>",<br/>       "Routes": [<br/>            {<br/>               "DestinationCidrBlock": "192.168.0.0/16",<br/>               "GatewayId": "local",<br/>               "Origin": "CreateRouteTable",<br/>               "State": "active"<br/>            }<br/>        ],<br/>       "Tags": [],<br/>       "VpcId": "vpc-69cfbd12"<br/>    }<br/>}</pre>
<ol start="4">
<li>Set the <span>default route (</span><kbd>0.0.0.0/0</kbd><span>) of the r</span>oute table (<kbd>rtb-70f1870c</kbd>) to NAT-GW (<kbd>nat-0b12be42c575bba43</kbd>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 create-route --route-table-id rtb-70f1870c --nat-gateway-id nat-0b12be42c575bba43 --destination-cidr-block 0.0.0.0/0</pre>
<ol start="5">
<li>Associate route table (<kbd>rtb-70f1870c</kbd>) to private subnet (<kbd>subnet-ce947da</kbd><span class="packt_screen">9</span>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 associate-route-table --route-table-id rtb-70f1870c --subnet-id subnet-ce947da9</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Security group</h1>
                </header>
            
            <article>
                
<p>Before launching your Virtual Server (EC2), you need to create a Security Group that has an appropriate security rule. Now, we have two subnets, public and private. Let's set public subnet such that it allows <kbd>ssh</kbd> (<kbd>22/tcp</kbd>) and <kbd>http</kbd> (<kbd>80/tcp</kbd>) from the internet. Then, set the private subnet such that it allows ssh from the public subnet:</p>
<ol>
<li>Create one security group for the public subnet on VPC (<kbd>vpc-69cfbd12</kbd>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 create-security-group --vpc-id vpc-69cfbd12 --group-name public --description "public facing host"<br/>{<br/>   "GroupId": "sg-dd8a3f94"<br/>}</pre>
<ol start="2">
<li>Add the ssh allow rule to the public security group (<kbd>sg-dd8a3f94</kbd>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 authorize-security-group-ingress --group-id sg-dd8a3f94 --protocol tcp --port 22 --cidr 0.0.0.0/0</pre>
<ol start="3">
<li>Add the <kbd>http</kbd> allow rule to the public security group (<kbd>sg-dd8a3f94</kbd>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 authorize-security-group-ingress --group-id sg-dd8a3f94 --protocol tcp --port 80 --cidr 0.0.0.0/0</pre>
<ol start="4">
<li>Create a second security group for the private subnet on VPC (<kbd>vpc-69cfbd12</kbd>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 create-security-group --vpc-id vpc-69cfbd12 --group-name private --description "private subnet host"<br/>{<br/>   "GroupId": "sg-a18c39e8"<br/>}</pre>
<ol start="5">
<li>Add an <kbd>ssh</kbd> allow rule to the private security group (<kbd>sg-a18c39e8</kbd>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 authorize-security-group-ingress --group-id sg-a18c39e8 --protocol tcp --port 22 --source-group sg-dd8a3f94</pre>
<ol start="6">
<li>Check the Security Group list using the following command:</li>
</ol>
<pre style="padding-left: 90px"><span>$ aws ec2 describe-security-groups --filters "Name=vpc-id, Values=vpc-69cfbd12" --query "SecurityGroups[*].{id:GroupId,name:GroupName}" --output table<br/></span><span>----------------------------<br/></span><span>|<span class="Apple-converted-space">  </span>DescribeSecurityGroups<span class="Apple-converted-space">  </span>|<br/></span><span>+--------------+-----------+<br/></span><span>|<span class="Apple-converted-space">      </span>id<span class="Apple-converted-space">      </span>| <span class="Apple-converted-space">  </span>name<span class="Apple-converted-space">    </span>|<br/></span><span>+--------------+-----------+<br/></span><span>|<span class="Apple-converted-space">  </span></span><span>sg-2ed56067</span><span> |<span class="Apple-converted-space">  </span></span><span>default</span><span><span class="Apple-converted-space">  </span>|<br/></span><span>|<span class="Apple-converted-space">  </span></span><span>sg-a18c39e8</span><span> |<span class="Apple-converted-space">  </span></span><span>private</span><span><span class="Apple-converted-space">  </span>|<br/></span><span>|<span class="Apple-converted-space">  </span></span><span>sg-dd8a3f94</span><span> |<span class="Apple-converted-space">  </span></span><span>public</span><span> <span class="Apple-converted-space">  </span>|<br/></span><span>+--------------+-----------+</span></pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">EC2</h1>
                </header>
            
            <article>
                
<p>Now you need to upload your ssh public key and then launch the EC2 instance on both the public subnet and the private subnet:</p>
<ol>
<li>Upload your ssh public key (assume you have a public key that is located at <kbd>~/.ssh/id_rsa.pub</kbd>):</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 import-key-pair --key-name=<strong>chap6-key</strong> --public-key-material "`cat ~/.ssh/id_rsa.pub`"</pre>
<ol start="2">
<li>Launch the first EC2 instance with the following parameters:
<ul>
<li>Use Amazon Linux image: <kbd>ami-1853ac65</kbd> (Amazon Linux)</li>
<li>T2.nano instance type: <kbd>t2.nano</kbd></li>
<li>Ssh key: <kbd>chap6-key</kbd></li>
<li>Public Subnet: <kbd>subnet-6296863f</kbd></li>
<li>Public Security Group: <kbd>sg-dd8a3f94</kbd></li>
</ul>
</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 run-instances --image-id ami-1853ac65 --instance-type t2.nano --key-name chap6-key --security-group-ids sg-dd8a3f94 --subnet-id subnet-6296863f</pre>
<ol start="3">
<li>Launch the second EC2 instance with the following parameters:
<ul>
<li>Use Amazon Linux image: <kbd>ami-1853ac65</kbd></li>
<li>T2.nano instance type: <kbd>t2.nano</kbd></li>
<li>Ssh key: <kbd>chap6-key</kbd></li>
<li>Private subnet: <kbd>subnet-ce947da9</kbd></li>
<li>Private Secuity Group: <kbd>sg-a18c39e8</kbd></li>
</ul>
</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 run-instances --image-id ami-1853ac65 --instance-type t2.nano --key-name chap6-key --security-group-ids sg-a18c39e8 --subnet-id subnet-ce947da9</pre>
<ol start="4">
<li>Check the status of the EC2 instances:</li>
</ol>
<pre style="padding-left: 90px">$ aws ec2 describe-instances --filters "Name=vpc-id,Values=vpc-69cfbd12" --query "Reservations[*].Instances[*].{id:InstanceId,PublicIP:PublicIpAddress,PrivateIP:PrivateIpAddress,Subnet:SubnetId}" --output=table<br/>-------------------------------------------------------------------------------<br/>|                             DescribeInstances                              |<br/>+---------------+-----------------+------------------+------------------------+<br/>|   PrivateIP   |   PublicIP     |     Subnet       |          id            |<br/>+---------------+-----------------+------------------+------------------------+<br/>|  <strong>192.168.0.206</strong>|  <strong>34.228.228.140</strong>|  <strong>subnet-6296863f</strong>|  <strong>i-03a0e49d26a2dafa4</strong>   |<br/>|  <strong>192.168.1.218</strong>|  <strong>None</strong>           | <strong>subnet-ce947da9</strong>|  <strong>i-063080766d2f2f520</strong>   |<br/>+---------------+-----------------+------------------+------------------------+</pre>
<ol start="5">
<li>SSH (use the <kbd>-A</kbd> option to forward your authentication info) to the public EC2 host from your computer:</li>
</ol>
<pre style="padding-left: 90px">$ ssh -A ec2-user@34.228.228.140<br/>The authenticity of host '34.228.228.140 (34.228.228.140)' can't be established.<br/>ECDSA key fingerprint is SHA256:lE7hoBhHntVDvRItnasqyHRynajn2iuHJ7U3nsWySRU.<br/>Are you sure you want to continue connecting (yes/no)? yes<br/>Warning: Permanently added '34.228.228.140' (ECDSA) to the list of known hosts.<br/>       __|  __|_  )<br/>       _|  (    /   Amazon Linux AMI<br/>      ___|\___|___|<br/>https://aws.amazon.com/amazon-linux-ami/2017.09-release-notes/<br/>8 package(s) needed for security, out of 13 available<br/>Run "sudo yum update" to apply all updates.<br/>[ec2-user@ip-192-168-0-206 ~]$</pre>
<ol start="6">
<li>Install and launch nginx to the public EC2 host:</li>
</ol>
<pre style="padding-left: 90px">[ec2-user@ip-192-168-0-206 ~]$ sudo yum -y install nginx<br/>[ec2-user@ip-192-168-0-206 ~]$ sudo service nginx start<br/>Starting nginx:                                            [ OK  ]</pre>
<ol start="7">
<li>Make sure you can access the nginx server from your machine (see the following screenshot):</li>
</ol>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-666 image-border" src="assets/ecb8ab27-c187-49c4-ab25-ce68e6d67977.png" style="width:47.92em;height:18.92em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Accessing nginx web server on public host</div>
<ol start="8">
<li>SSH from the public host to the private host (you must use a private IP address):</li>
</ol>
<pre style="padding-left: 90px">$ ssh 192.168.1.218</pre>
<ol start="9">
<li>Make sure the private host can perform yum update via NAT-GW:</li>
</ol>
<pre style="padding-left: 90px">[ec2-user@ip-192-168-1-218 ~]$ sudo yum -y update</pre>
<p>Congratulations! You can set up your own infrastructure on AWS, as shown in the following diagram, which has the following:</p>
<ul>
<li>One VPC with CIDR <kbd>192.168.0.0/16</kbd></li>
<li>IGW</li>
<li>NAT-GW</li>
<li>Two Subnets
<ul>
<li>public subnet: <kbd>192.168.0.0/24</kbd> route to IGW</li>
<li>private subnet: 192.168.1.0/24 route to NAT-GW</li>
</ul>
</li>
<li>Two EC2 instances (public and private)</li>
<li>Two Security Groups (allow public http/ssh and private ssh)</li>
</ul>
<p>Now, take a look at the diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-665 image-border" src="assets/97480e7b-4918-4383-841c-372a6992a957.png" style="width:26.42em;height:21.25em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>AWS components diagram</span></div>
<p class="mce-root">In this section, you have learned how to use AWS from scratch. We have covered its basic uses, but it is important to know while setup Kubernetes on AWS. Next, we will explore how to set up Kubernetes on AWS.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Setting up Kubernetes with kops</h1>
                </header>
            
            <article>
                
<p>What is kops? It is the abbreviated term of Kubernetes Operation (<a href="https://github.com/kubernetes/kops">https://github.com/kubernetes/kops</a>). Similar to kubeadm, minikube, and kubespray, kops reduces the heavy duty of building up a Kubernetes cluster by ourselves. It helps in creation, and provides an interface to users for managing the clusters. Furthermore, kops achieves a more automatic installing procedure and delivers a production-level system. It targets to support dominate cloud platforms, such as AWS, GCE, and VMware vSphere. In this recipe, we will talk about how to run a Kubernetes cluster with kops.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p>Before our major tutorial, we will need to install kops on to your local host. It is a straightforward step for downloading the binary file and moving it to the system directory of the execution file:</p>
<pre>// download the latest stable kops binary<br/>$ curl -LO https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d '"' -f 4)/kops-linux-amd64<br/>$ chmod +x kops-linux-amd64<br/>$ sudo mv kops-linux-amd64 /usr/local/bin/kops<br/>// verify the command is workable<br/>$ kops version<br/>Version 1.9.0 (git-cccd71e67)</pre>
<p>Next, we have to prepare some AWS configuration on your host and required services for cluster. Refer to the following items and make sure that they are ready:</p>
<ul>
<li><strong>IAM user</strong>: Since kops would create and build several AWS service components together for you, you must have an IAM user with kops required permissions. We've created an IAM user named <span class="packt_screen">chap6</span> in the previous section that has the following policies with the necessary permissions for kops:
<ul>
<li>AmazonEC2FullAccess</li>
<li>AmazonRoute53FullAccess</li>
<li>AmazonS3FullAccess</li>
<li>IAMFullAccess</li>
<li>AmazonVPCFullAccess</li>
</ul>
</li>
</ul>
<p style="padding-left: 60px"><span>Then, exposing the AWS access key ID and secret key as environment variables can make this role applied on host while firing <kbd>kops</kbd> commands:</span></p>
<p> </p>
<pre style="padding-left: 90px">$ export AWS_ACCESS_KEY_ID=${string of 20 capital character combination}<br/>$ export AWS_SECRET_ACCESS_KEY=${string of 40 character and number combination}</pre>
<ul>
<li><strong>Prepare an S3 bucket for storing cluster configuration</strong>: In our demonstration later, the S3 bucket name will be <kbd>kubernetes-cookbook</kbd>.</li>
<li><strong>Prepare a Route53 DNS domain for accessing points of cluster</strong>: In our demonstration later, the domain name we use will be <kbd>k8s-cookbook.net</kbd>.</li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>We can easily run up a Kubernetes cluster using a single command with parameters containing complete configurations. These parameters are described in the following table:</p>
<table border="1" style="border-collapse: collapse;width: 100%">
<tbody>
<tr>
<td>
<p><strong>Parameter</strong></p>
</td>
<td>
<p><strong>Description</strong></p>
</td>
<td>
<p><strong>Value in example</strong></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--name</kbd></p>
</td>
<td>
<p>This is the name of the cluster. It will also be the domain name of the cluster's entry point. So you can utilize your Route53 DNS domain with a customized name, for example, <kbd>{your cluster name}.{your Route53 domain name}</kbd>.</p>
</td>
<td>
<p><kbd>my-cluster.k8s-cookbook.net</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--state</kbd></p>
</td>
<td>
<p>This indicates the S3 bucket that stores the status of the cluster in the format <kbd>s3://{bucket name}</kbd>.</p>
</td>
<td>
<p><kbd>s3://kubernetes-cookbook</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--zones</kbd></p>
</td>
<td>
<p>This is the availability zone where you need to build your cluster.</p>
</td>
<td>
<p><kbd>us-east-1a</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--cloud</kbd></p>
</td>
<td>
<p>This is the cloud provider.</p>
</td>
<td>
<p><kbd>aws</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--network-cidr</kbd></p>
</td>
<td>
<p>Here, kops helps to create independent CIDR range for the new VPC.</p>
</td>
<td>
<p><kbd>10.0.0.0/16</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--master-size</kbd></p>
</td>
<td>
<p>This is the instance size of Kubernetes master.</p>
</td>
<td>
<p><kbd>t2.large</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--node-size</kbd></p>
</td>
<td>
<p>This is the instance size of Kubernetes nodes.</p>
</td>
<td>
<p><kbd>t2.medium</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--node-count</kbd></p>
</td>
<td>
<p>This is the number of nodes in the cluster.</p>
</td>
<td>
<p><kbd>2</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--network</kbd></p>
</td>
<td>
<p>This is the overlay network used in this cluster.</p>
</td>
<td>
<p><kbd>calico</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--topology</kbd></p>
</td>
<td>
<p>This helps you decide whether the cluster is public facing.</p>
</td>
<td>
<p><kbd>private</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--ssh-public-key</kbd></p>
</td>
<td>
<p>This helps you assign an SSH public key for bastion server, then we may log in through the private key.</p>
</td>
<td>
<p><kbd>~/.ssh/id_rsa.pub</kbd></p>
</td>
</tr>
<tr>
<td>
<p><kbd>--bastion</kbd></p>
</td>
<td>
<p>This gives you an indication to create the bastion server.</p>
</td>
<td>
<p>N/A</p>
</td>
</tr>
<tr>
<td>
<p><kbd>--yes</kbd></p>
</td>
<td>
<p>This gives you the confirmation for executing immediately.</p>
</td>
<td>
<p>N/A</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>Now we are ready to compose the configurations into a command and fire it:</p>
<pre>$ kops create cluster --name my-cluster.k8s-cookbook.net --state=s3://kubernetes-cookbook --zones us-east-1a --cloud aws --network-cidr 10.0.0.0/16 --master-size t2.large --node-size t2.medium --node-count 2 --networking calico --topology private --ssh-public-key ~/.ssh/id_rsa.pub --bastion --yes<br/>...<br/>I0408 15:19:21.794035   13144 executor.go:91] Tasks: 105 done / 105 total; 0 can run<br/>I0408 15:19:21.794111   13144 dns.go:153] Pre-creating DNS records<br/>I0408 15:19:22.420077   13144 update_cluster.go:248] Exporting kubecfg for cluster<br/><strong>kops has set your kubectl context to my-cluster.k8s-cookbook.net<br/></strong>Cluster is starting.  It should be ready in a few minutes.<br/>...</pre>
<p>After a few minutes, the command takes out the preceding logs showing what AWS services have been created and served for you kops-built Kubernetes cluster. You can even check your AWS console to verify their relationships, which will look similar to the following diagram:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-667 image-border" src="assets/43f90e6c-c355-49df-8f2b-f59719ddca51.png" style="width:38.33em;height:26.75em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">The components of Kubernetes cluster in AWS created by kops</div>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How it works...</h1>
                </header>
            
            <article>
                
<p>From localhost, users can interact with the cluster on AWS using the kops command:</p>
<pre>//check the cluster<br/>$ kops get cluster --state s3://kubernetes-cookbook<br/>NAME                         CLOUD  ZONES<br/>my-cluster.k8s-cookbook.net  aws    us-east-1a</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Working with kops-built AWS cluster</h1>
                </header>
            
            <article>
                
<p>Furthermore, as you can see in the previous section, the last few logs of kops cluster creation shows that the environment of the client is also ready. It means that kops helps to bind the API server to our host securely as well. We may use the <kbd>kubectl</kbd> command like we were in Kubernetes master. What we need to do is install kubectl manually. It would be as simple as installing kops; just download the binary file:</p>
<pre>// install kubectl on local<br/>$ curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl<br/>$ chmod +x kubectl<br/>$ sudo mv kubectl /usr/local/bin/<br/>// check the nodes in cluster on AWS<br/>$ kubectl get nodes<br/>NAME                          STATUS    ROLES     AGE       VERSION<br/>ip-10-0-39-216.ec2.internal   Ready     master    2m        v1.8.7<br/>ip-10-0-40-26.ec2.internal    Ready     node      31s       v1.8.7<br/>ip-10-0-50-147.ec2.internal   Ready     node      33s       v1.8.7</pre>
<p>However, you can still access the nodes in the cluster. Since the cluster is set down in a private network, we will require to login to the bastion server first, and jump to the nodes for the next:</p>
<pre>//add private key to ssh authentication agent<br/>$ ssh-add ~/.ssh/id_rsa<br/><br/>//use your private key with flag “-i”<br/>//we avoid it since the private key is in default location, ~/.ssh/id_rsa<br/>//also use -A option to forward an authentication agent<br/>$ ssh -A admin@bastion.my-cluster.k8s-cookbook.net<br/><br/>The programs included with the Debian GNU/Linux system are free software;<br/>the exact distribution terms for each program are described in the<br/>individual files in /usr/share/doc/*/copyright.<br/><br/>Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent<br/>permitted by applicable law.<br/>Last login: Sun Apr  8 19:37:31 2018 from 10.0.2.167<br/>// access the master node with its private IP<br/>admin@ip-10-0-0-70:~$ ssh 10.0.39.216<br/><br/>The programs included with the Debian GNU/Linux system are free software;<br/>the exact distribution terms for each program are described in the<br/>individual files in /usr/share/doc/*/copyright.<br/><br/>Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent<br/>permitted by applicable law.<br/>Last login: Sun Apr  8 19:36:22 2018 from 10.0.0.70<br/>admin@ip-10-0-39-216:~$</pre>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Deleting kops-built AWS cluster</h1>
                </header>
            
            <article>
                
<p>We can simply remove our cluster using the kops command as follows:</p>
<pre>$ kops delete cluster --name my-cluster.k8s-cookbook.net --state s3://kubernetes-cookbook --yes<br/>Deleted cluster: "my-cluster.k8s-cookbook.net"</pre>
<p>It will clean the AWS services for you. <span>But some other services created by</span> yourself: S3 bucket, IAM role with powerful authorization, and Route53 domain name; kops will not remove them on user's behavior. Remember to delete the no used AWS services on your side.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li><em>Playing with Amazon Web Services</em></li>
<li><em>Using AWS as Kubernetes Cloud Provider</em></li>
<li><em>Managing Kubernetes cluster on AWS by kops</em></li>
<li><em>Setting up the Kubernetes cluster on Linux by kubeadm</em> in <a href="4dd5324f-b753-4c80-b891-bd8e6013b2c1.xhtml" target="_blank">Chapter 1</a>, <em>Building your own Kubernetes <span>Cluster</span></em></li>
<li><em>Setting up Kubernetes cluster on Linux by kubespray</em> in <a href="4dd5324f-b753-4c80-b891-bd8e6013b2c1.xhtml" target="_blank">Chapter 1</a>, <em>Building your own Kubernetes</em> <em><span>Cluster</span></em></li>
</ul>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Using AWS as Kubernetes Cloud Provider</h1>
                </header>
            
            <article>
                
<p>From Kubernetes 1.6, <strong>Cloud Controller Manager</strong> (<strong>CCM</strong>) was introduced, which defines a set of interfaces so that different cloud providers could evolve their own implementations out of the Kubernetes release cycle. Talking to the cloud providers, you can't ignore the biggest player: Amazon Web Service. According to the Cloud Native Computing Foundation, in 2017, 63% of Kubernetes workloads run on AWS. AWS CloudProvider supports Service as <strong>Elastic Load Balancer</strong> (<strong>ELB</strong>) and Amazon <strong>Elastic Block Store</strong> (<strong>EBS</strong>) as StorageClass.</p>
<p>At the time this book was written, Amazon Elastic Container Service for Kubernetes (Amazon EKS) was under preview, which is a hosted Kubernetes service in AWS. Ideally, it'll have better integration with Kubernetes, such as <strong>Application Load Balancer</strong> (<strong>ALB</strong>) for Ingress, authorization, and networking. Currently in AWS, the limitation of routes per route tables in VPC is 50; it could be up to 100 as requested. However, network performance may be impacted if the routes exceed 50 according to the official documentation of AWS. While kops uses kubenet networking by default, which allocates a/24 CIDR to each node and configures the routes in route table in AWS VPC. This might lead to the performance hit if the cluster has more than 50 nodes. Using a CNI network could address this problem.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT">For following along with the examples in this recipe, you'll need to create a Kubernetes cluster in AWS. The following example is using kops to provision a Kubernetes cluster named <kbd>k8s-cookbook.net</kbd> in AWS; as the preceding recipes show, set <kbd>$KOPS_STATE_STORE</kbd> as a s3 bucket to store your kops configuration and metadata:</p>
<pre># kops create cluster --master-count 1 --node-count 2 --zones us-east-1a,us-east-1b,us-east-1c --node-size t2.micro --master-size t2.small --topology private --networking calico --authorization=rbac --cloud-labels "Environment=dev" --state $KOPS_STATE_STORE --name k8s-cookbook.net <br/>I0408 16:10:12.212571 34744 create_cluster.go:1318] Using SSH public key: /Users/k8s/.ssh/id_rsa.pub I0408 16:10:13.959274 34744 create_cluster.go:472] Inferred --cloud=aws from zone "us-east-1a" <br/>I0408 16:10:14.418739 34744 subnets.go:184] Assigned CIDR 172.20.32.0/19 to subnet us-east-1a <br/>I0408 16:10:14.418769 34744 subnets.go:184] Assigned CIDR 172.20.64.0/19 to subnet us-east-1b I0408 16:10:14.418777 34744 subnets.go:184] Assigned CIDR 172.20.96.0/19 to subnet us-east-1c <br/>I0408 16:10:14.418785 34744 subnets.go:198] Assigned CIDR 172.20.0.0/22 to subnet utility-us-east-1a I0408 16:10:14.418793 34744 subnets.go:198] Assigned CIDR 172.20.4.0/22 to subnet utility-us-east-1b <br/>I0408 16:10:14.418801 34744 subnets.go:198] Assigned CIDR 172.20.8.0/22 to subnet utility-us-east-1c ... <br/>Finally configure your cluster with: kops update cluster k8s-cookbook.net --yes</pre>
<p>Once we run the recommended kops update cluster <kbd>&lt;cluster_name&gt; --yes</kbd> command, after a few minutes, the cluster is up and running. We can use the kops validate cluster to check whether the cluster components are all up:</p>
<pre># kops validate cluster<br/>Using cluster from kubectl context: k8s-cookbook.net<br/>Validating cluster k8s-cookbook.net<br/>INSTANCE GROUPS<br/>NAME                  ROLE   MACHINETYPE   MIN    MAX    SUBNETS<br/>master-us-east-1a     Master t2.small      1      1      us-east-1a<br/>nodes                 Node   t2.micro      2      2      us-east-1a,us-east-1b,us-east-1c<br/>NODE STATUS           <br/>NAME                              ROLE   READY                 <br/>ip-172-20-44-140.ec2.internal     node   True<br/>ip-172-20-62-204.ec2.internal     master True<br/>ip-172-20-87-38.ec2.internal      node   True<br/>Your cluster k8s-cookbook.net is ready</pre>
<p class="NormalPACKT">We're good to go!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>When running Kubernetes in AWS, there are two possible integrations we could use: ELB as Service with <kbd>LoadBalancer</kbd> Type and Amazon Elastic Block Store as <kbd>StorageClass</kbd>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Elastic load balancer as LoadBalancer service</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT">Let's create a <kbd>LoadBalancer</kbd> Service with Pods underneath, which is what we learned in <a href="51ca5358-d5fe-4eb2-a52d-65a399617fcf.xhtml" target="_blank">Chapter 3</a>, <span><em>Playing with Containers</em></span>:</p>
<pre># cat aws-service.yaml<br/>apiVersion: apps/v1<br/>kind: Deployment<br/>metadata:<br/>  name: nginx<br/>spec:<br/>  replicas: 3<br/>  selector:<br/>    matchLabels:<br/>      run: nginx<br/>  template:<br/>    metadata:<br/>      labels:<br/>        run: nginx<br/>    spec:<br/>      containers:<br/>        - image: nginx<br/>          name: nginx<br/>          ports:<br/>            - containerPort: 80<br/>---<br/>apiVersion: v1<br/>kind: Service<br/>metadata:<br/>  name: nginx<br/>spec:<br/>  ports:<br/>    - port: 80<br/>      targetPort: 80<br/>  type: LoadBalancer<br/>  selector:<br/>    run: nginx</pre>
<p class="NormalPACKT">In the preceding template, we declared one nginx Pod and associated it with the <kbd>LoadBalancer</kbd> service. The service will direct the packet to container port <kbd>80</kbd>:</p>
<pre># kubectl create -f aws-service.yaml <br/>deployment.apps "nginx" created <br/>service "nginx" created </pre>
<p class="NormalPACKT">Let's describe our <kbd>nginx</kbd> Service:</p>
<pre># kubectl describe svc nginx<br/>Name:                     nginx<br/>Namespace:                default<br/>Labels:                   &lt;none&gt;<br/>Annotations:              &lt;none&gt;<br/>Selector:                 run=nginx<br/>Type:                     LoadBalancer<br/>IP:                       100.68.35.30<br/>LoadBalancer Ingress:     a9da4ef1d402211e8b1240ef0c7f25d3-1251329976.us-east-1.elb.amazonaws.com<br/>Port:                     &lt;unset&gt;  80/TCP<br/>TargetPort:               80/TCP<br/>NodePort:                 &lt;unset&gt;  31384/TCP<br/>Endpoints:                100.124.40.196:80,100.99.102.130:80,100.99.102.131:80<br/>Session Affinity:         None<br/>External Traffic Policy:  Cluster<br/>Events:<br/>  Type    Reason                Age   From                Message<br/>  ----    ------                ----  ----                -------<br/>  Normal  EnsuringLoadBalancer  2m    service-controller  Ensuring load balancer<br/>  Normal  EnsuredLoadBalancer   2m    service-controller  Ensured load balancer </pre>
<p>After the service is created, we will find out that the AWS CloudProvider will provision a classic load balancer with the endpoint <kbd>adb576a05401911e8b1240ef0c7f25d3-1637943008.us-east-1.elb.amazonaws.com</kbd>. We can check its detailed settings via the aws command-line interface (<a href="https://aws.amazon.com/cli/">https://aws.amazon.com/cli/</a>).</p>
<div class="packt_infobox">
<div>
<p>To install aws CLI, you can use pip to install in Mac or Linux (<kbd>pip install awscli</kbd>); for Windows users, you'll have to download the installer from the official website.</p>
</div>
</div>
<p>The combination of AWS CLI commands is <kbd>aws [options] &lt;command&gt; &lt;subcommand&gt; [&lt;subcommand&gt; ...] [parameters]</kbd>. For listing load balancers, we'll use <kbd>aws elb describe-load-balancers</kbd> as the major command. Using the <kbd>--load-balancer-names parameter</kbd> will filter load balancers by name, and for the <kbd>--output</kbd><span> parameter</span>, you can choose text, JSON, or table:</p>
<pre># aws elb describe-load-balancers --load-balancer-names a9da4ef1d402211e8b1240ef0c7f25d3 --output text<br/>LOADBALANCERDESCRIPTIONS     a9da4ef1d402211e8b1240ef0c7f25d3-1251329976.us-east-1.elb.amazonaws.com Z35SXDOTRQ7X7K 2018-04-14T20:30:45.990Z       a9da4ef1d402211e8b1240ef0c7f25d3-1251329976.us-east-1.elb.amazonaws.com a9da4ef1d402211e8b1240ef0c7f25d3    internet-facing       vpc-07374a7c<br/>AVAILABILITYZONES     us-east-1a<br/>AVAILABILITYZONES     us-east-1b<br/>AVAILABILITYZONES     us-east-1c<br/>HEALTHCHECK   2      10     TCP:31384     5      6<br/>INSTANCES     i-03cafedc27dca591b<br/>INSTANCES     i-060f9d17d9b473074<br/>LISTENER      31384  TCP    80     TCP<br/>SECURITYGROUPS sg-3b4efb72<br/>SOURCESECURITYGROUP   k8s-elb-a9da4ef1d402211e8b1240ef0c7f25d3   516726565417<br/>SUBNETS subnet-088f9d27<br/>SUBNETS subnet-e7ec0580<br/>SUBNETS subnet-f38191ae</pre>
<p class="NormalPACKT">If we access this ELB endpoint port <kbd>80</kbd>, we'll see the nginx welcome page:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-668 image-border" src="assets/40c40acf-d984-4021-ab91-c7f7f92e54bd.png" style="width:41.67em;height:12.50em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign">Access ELB endpoint to access LoadBalancer Service</div>
<p class="NormalPACKT">Behind the scene, AWS CloudProvider creates a AWS elastic load balancer and configures its ingress rules and listeners by the Service we just defined. The following is a diagram of how the traffic gets into the Pods:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-669 image-border" src="assets/63c00acb-0240-4931-9813-9ffa62912489.png" style="width:48.08em;height:21.17em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span><span>The illustration of Kubernetes resources and AWS resources for Service with LoadBalancer type</span></span></div>
<p>The external load balancer receives the requests and forwards them to EC2 instances using a round-robin algorithm. For Kubernetes, the traffic gets into the Service via NodePort and starts a Service-to-Pod communication. For more information about external-to-Service and Service-to-Pod communications, you can refer to <a href="51ca5358-d5fe-4eb2-a52d-65a399617fcf.xhtml" target="_blank">Chapter 3</a>, <em>Playing with Containers</em>.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Elastic Block Store as StorageClass</h1>
                </header>
            
            <article>
                
<p>We've learned about Volumes in <a href="e9a51674-078b-4ffc-a76c-98774150bfa3.xhtml" target="_blank">Chapter 2</a>, <em><span>Walking through Kubernetes Concepts</span></em>. We know <kbd>PersistentVolumeClaims</kbd> is used to abstract storage resources from users. It can dynamically provision the <kbd>PersistentVolume</kbd> via <kbd>StorageClass</kbd>. The default provisioner in <kbd>StorageClass</kbd> in <strong>AWS CloudProvider is Elastic Block Storage Service</strong>‎ (<strong>aws-ebs</strong>). Whenever you request a PVC, aws-ebs provisioner will create a volume in AWS EBS.</p>
<p>Let's check the storage class in our cluster:</p>
<pre>// list all storageclass<br/># kubectl get storageclass<br/>NAME            PROVISIONER             AGE<br/>default         kubernetes.io/aws-ebs   2h<br/>gp2 (default)   kubernetes.io/aws-ebs   2h<br/>In this recipe, we'll reuse the PVC example we mentioned in Chapter 2-6:<br/># cat chapter2/2-6_volumes/2-6-7_pvc.yaml<br/>apiVersion: "v1"<br/>kind: "PersistentVolumeClaim"<br/>metadata:<br/>  name: "pvclaim01"<br/>spec:<br/>  accessModes:<br/>    - ReadWriteOnce<br/>  resources:<br/>    requests:<br/>      storage: 1Gi<br/>// create pvc<br/># kubectl create -f chapter2/2-6_volumes/2-6-7_pvc.yaml<br/>persistentvolumeclaim "pvclaim01" created<br/>// check pvc is created successfully.<br/># kubectl get pvc<br/>NAME        STATUS    VOLUME                                     CAPACITY   <br/>pvclaim01   Bound     pvc-e3d881d4-402e-11e8-b124-0ef0c7f25d36   1Gi        <br/>ACCESS    MODES   STORAGECLASS   AGE<br/>RWO            gp2            16m</pre>
<p>After PVC is created, an associated PV will be created:</p>
<pre># kubectl get pv<br/>NAME                                       CAPACITY   ACCESS MODES   <br/>pvc-e3d881d4-402e-11e8-b124-0ef0c7f25d36   1Gi        RWO<br/>RECLAIM POLICY   STATUS    CLAIM               STORAGECLASS   REASON    AGE<br/>Delete           Bound     default/pvclaim01   gp2                      16m</pre>
<p>You can take a closer look at PV here:</p>
<pre># kubectl describe pv pvc-e3d881d4-402e-11e8-b124-0ef0c7f25d36<br/>Name:            pvc-e3d881d4-402e-11e8-b124-0ef0c7f25d36<br/>Labels:          failure-domain.beta.kubernetes.io/region=us-east-1<br/>                 failure-domain.beta.kubernetes.io/zone=us-east-1a<br/>Annotations:     kubernetes.io/createdby=aws-ebs-dynamic-provisioner<br/>                 pv.kubernetes.io/bound-by-controller=yes<br/>                 pv.kubernetes.io/provisioned-by=kubernetes.io/aws-ebs<br/>Claim:           default/pvclaim01<br/>...<br/>Source:<br/>    Type:       AWSElasticBlockStore (a Persistent Disk resource in AWS)<br/>    VolumeID:   aws://us-east-1a/vol-035ca31b9cc1820d7<br/>    FSType:     ext4<br/>    Partition:  0<br/>    ReadOnly:   false</pre>
<p>We can find that it's associated with the claim we just created <kbd>pvclaim01</kbd> and the source type is <kbd>AWSElasticBlockStore</kbd>, as expected.</p>
<p>We can use AWS CLI to inspect the volume we created in EBS. Using the <kbd>--filter Name=tag-</kbd>value we can filter the volumes in EBS:</p>
<pre>// aws ec2 describe-volumes --filter Name=tag-value,Values=$PV_NAME<br/># aws ec2 describe-volumes --filter Name=tag-value,Values="pvc-e3d881d4-402e-11e8-b124-0ef0c7f25d36"{<br/>    "Volumes": [<br/>        {<br/>            "AvailabilityZone": "us-east-1a",<br/>             "Tags": [<br/>                {   "Value": "k8s-cookbook.net",<br/>                    "Key": "KubernetesCluster" },<br/>                {   "Value": "default",<br/>                    "Key": "kubernetes.io/created-for/pvc/namespace" },<br/>                {   "Value": "k8s-cookbook.net-dynamic-pvc-e3d881d4-402e-11e8-b124-0ef0c7f25d36",<br/>                    "Key": "Name" },<br/>                {   "Value": "pvclaim01",<br/>                    "Key": "kubernetes.io/created-for/pvc/name" },<br/>                {   "Value": "owned",<br/>                    "Key": "kubernetes.io/cluster/k8s-cookbook.net" },<br/>                {   "Value": "pvc-e3d881d4-402e-11e8-b124-0ef0c7f25d36",<br/>                    "Key": "kubernetes.io/created-for/pv/name" }],<br/>            "VolumeType": "gp2",<br/>            "VolumeId": "vol-035ca31b9cc1820d7",<br/>         ...<br/>        }    <br/>   ]<br/>}</pre>
<p>We can see that the EBS resource has been tagged with lots of different values: by observing these tags, we can know which Kubernetes cluster, namespace, PVC, and PV are associated with this EBS volume.</p>
<p>Thanks to dynamic provisioning that StorageClass and CloudProvider support, Volume management is no longer a huge pain. We can create and destroy PV on the fly.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p>At the time of writing this book, there is no native way in Kubernetes 1.10 to support Ingress integration in AWS CloudProvider yet (ideally with application load balancer). Alternatively, kops provides addons that allow you to do so. The first one is ingress-nginx (<a href="https://github.com/kubernetes/kops/tree/master/addons/ingress-nginx">https://github.com/kubernetes/kops/tree/master/addons/ingress-nginx</a>), which is powered by nginx (<a href="https://nginx.org">https://nginx.org</a>) and AWS Elastic Load Balancer. The requests will go through ELB to nginx, and nginx will dispatch the requests, based on the path definition in Ingress. Another alternative is running skipper as kubernetes-ingress-controller (<a href="https://zalando.github.io/skipper/dataclients/kubernetes">https://zalando.github.io/skipper/dataclients/kubernetes</a>). Kops also provides add-ons to help you deploy and leverage skipper and AWS Application Load Balancer (<a href="https://github.com/kubernetes/kops/tree/master/addons/kube-ingress-aws-controller">https://github.com/kubernetes/kops/tree/master/addons/kube-ingress-aws-controller</a>).</p>
<p>We're expecting CCM and Amazon EKS (<a href="https://aws.amazon.com/eks/">https://aws.amazon.com/eks/</a>) to provide more native integration for Ingress via AWS Application Load Balancer, and there will be more to come!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Managing Kubernetes cluster on AWS by kops</h1>
                </header>
            
            <article>
                
<p>In kops, both Kubernetes masters and nodes are running as auto-scaling groups in AWS. In kops, the concept is called <strong>instance groups</strong> (<strong>ig</strong>), which indicate the same type of instances in your cluster. Similar to nodes across zones, or masters in each availability zone, we could check it via the kops command line:</p>
<pre>// kops get instancegroups or kops get ig <br/># kops get instancegroups --name k8s-cookbook.net <br/>NAME ROLE MACHINETYPE MIN MAX ZONES <br/>master-us-east-1a Master t2.small 1 1 us-east-1a <br/>nodes Node t2.micro 2 2 us-east-1a,us-east-1b,us-east-1c </pre>
<p>With kops, you can change the instance type, resize instance groups (masters and nodes), rolling-update, and upgrade cluster. Kops also supports configuration for specific AWS features, such as enable AWS detailed monitoring for the instances in the cluster.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Getting ready</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT">For performing this recipe, you'll need a Kubernetes cluster deployed by kops in AWS. You will need to follow the previous recipes in this chapter to launch a cluster. Here, we'll use the same cluster we created in the previous recipe:</p>
<pre># kops validate cluster<br/>Using cluster from kubectl context: k8s-cookbook.net<br/>Validating cluster k8s-cookbook.net<br/>INSTANCE GROUPS<br/>NAME                  ROLE   MACHINETYPE   MIN    MAX    SUBNETS<br/>master-us-east-1a     Master t2.small      1      1      us-east-1a<br/>nodes                 Node   t2.micro      2      2      us-east-1a,us-east-1b,us-east-1c<br/>NODE STATUS<br/>NAME                         ROLE   READY<br/>ip-172-20-44-140.ec2.internal       node   True<br/>ip-172-20-62-204.ec2.internal       master True<br/>ip-172-20-87-38.ec2.internal node   True<br/>Your cluster k8s-cookbook.net is ready</pre>
<p class="NormalPACKT">In the previous recipe, we've had the <kbd>KOPS_STATE_STORE</kbd> environment variable set as one of our S3 bucket names by the format <kbd>s3://&lt;bucket_name&gt;</kbd> to store the kops configuration and metadata.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">How to do it...</h1>
                </header>
            
            <article>
                
<p>The upcoming subsections cover some common operational examples that cluster administrators may run into.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Modifying and resizing instance groups</h1>
                </header>
            
            <article>
                
<p>Modifying instance groups may be cumbersome if you deploy all instances manually. You'll need to update instances one by one or relaunch them. By kops, we can easily perform the update without pain.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Updating nodes</h1>
                </header>
            
            <article>
                
<p>Using the kops edit command, we can modify the instance type and the node count:</p>
<pre>// kops edit ig nodes<br/># kops edit instancegroups nodes --name k8s-cookbook.net<br/>apiVersion: kops/v1alpha2<br/>kind: InstanceGroup<br/>metadata:<br/>  creationTimestamp: 2018-04-14T19:06:47Z<br/>  labels:<br/>    kops.k8s.io/cluster: k8s-cookbook.net<br/>  name: nodes<br/>spec:<br/>  image: kope.io/k8s-1.8-debian-jessie-amd64-hvm-ebs-2018-02-08<br/>  machineType: t2.micro<br/>  maxSize: 2<br/>  minSize: 2<br/>  nodeLabels:<br/>    kops.k8s.io/instancegroup: nodes<br/>  role: Node<br/>  subnets:<br/>  - us-east-1a<br/>  - us-east-1b<br/>  - us-east-1c</pre>
<p class="NormalPACKT">In this example, we modify both minSize and maxSize from <kbd>2</kbd> to <kbd>3</kbd>. After the modification, we'll need to run the kops update to see it take effect:</p>
<pre># kops update cluster k8s-cookbook.net --yes<br/>...<br/>I0414 21:23:52.505171   16291 update_cluster.go:291] Exporting kubecfg for cluster<br/>kops has set your kubectl context to k8s-cookbook.net<br/>Cluster changes have been applied to the cloud.<br/>Changes may require instances to restart: kops rolling-update cluster</pre>
<p class="NormalPACKT">Some updates will need a rolling-update cluster. In this example, kops has updated the configuration in the AWS auto scaling group. AWS will then launch a new instance to accommodate the change. The following is a screenshot from AWS Auto Scaling Group's console:</p>
<div class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-679 image-border" src="assets/544524b9-bc0f-422c-b4f7-3632b3e32a07.png" style="width:72.92em;height:6.25em;"/></div>
<div class="packt_figref CDPAlignCenter CDPAlign"><span>nodes_in_AWS_Auto_Scaling_Groups</span></div>
<div>
<p>We can see that the configuration has been updated, and AWS is scaling a new instance. After few minutes, we can check cluster status via <kbd>kops validate</kbd> or <kbd>kubectl get nodes</kbd>:</p>
<pre># kops validate cluster<br/>Using cluster from kubectl context: k8s-cookbook.net<br/>Validating cluster k8s-cookbook.net<br/>INSTANCE GROUPS<br/>NAME                  ROLE   MACHINETYPE   MIN    MAX    SUBNETS<br/>master-us-east-1a     Master t2.small      1      1      us-east-1a<br/>nodes                 Node   t2.micro      3      3      us-east-1a,us-east-1b,us-east-1c<br/>NODE STATUS<br/>NAME                         ROLE   READY<br/>ip-172-20-119-170.ec2.internal      node   True<br/>ip-172-20-44-140.ec2.internal       node   True<br/>ip-172-20-62-204.ec2.internal       master True<br/>ip-172-20-87-38.ec2.internal node   True</pre></div>
<p class="NormalPACKT">Everything looks good!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Updating masters</h1>
                </header>
            
            <article>
                
<p class="NormalPACKT">Updating masters is the same as updating nodes. Note that masters in the same availability zone are in one instance group. This means that you can't add additional subnets into the master instance group. In the following example, we'll resize the master count from 1 to 2.</p>
<div class="packt_infobox">
<div>
<p>In this recipe, we only make the master count 1. In the real world, the recommended way is to deploy masters to at least two availability zones and have three masters per zone (one kops instance group). You can achieve that via the <kbd>--master-count</kbd> and <kbd>--master-zones</kbd> parameters when launching the cluster.</p>
</div>
</div>
<p>Now take a look at the following command:</p>
<pre># kops edit ig master-us-east-1a<br/>apiVersion: kops/v1alpha2<br/>kind: InstanceGroup<br/>metadata:<br/>  creationTimestamp: 2018-04-14T19:06:47Z<br/>  labels:<br/>    kops.k8s.io/cluster: k8s-cookbook.net<br/>  name: master-us-east-1a<br/>spec:<br/>  image: kope.io/k8s-1.8-debian-jessie-amd64-hvm-ebs-2018-02-08<br/>  machineType: t2.small<br/>  maxSize: 1<br/>  minSize: 1<br/>  nodeLabels:<br/>    kops.k8s.io/instancegroup: master-us-east-1a<br/>  role: Master<br/>  subnets:<br/>  - us-east-1a</pre>
<p>Before applying the change, we can run the update cluster command without <kbd>--yes</kbd> in the dry run mode:</p>
<pre># kops update cluster k8s-cookbook.net<br/>...<br/>Will modify resources:<br/>  AutoscalingGroup/master-us-east-1a.masters.k8s-cookbook.net<br/>       MinSize                1 -&gt; 2<br/>       MaxSize                1 -&gt; 2<br/>Must specify --yes to apply changes</pre>
<p class="NormalPACKT">After we verify the dry run message as expected, we can perform the update as follows. In this case, we'll have to perform a rolling update.</p>
<div class="packt_tip">
<div>
<p><span class="packt_screen">How to know whether a rolling update is needed</span><br/>
If we didn't run a kops rolling update in the preceding example, kops will show a validation error when running the kops validate cluster:<br/>
VALIDATION ERRORS<br/>
KIND                NAME                          MESSAGE<br/>
InstanceGroup     <kbd>master-us-east-1a</kbd> InstanceGroup <kbd>master-us-east-1a</kbd> did not have enough nodes 1 vs 2</p>
</div>
</div>
<p class="NormalPACKT">Remember to replace k8s-cookbook.net with your cluster name.</p>
<pre># kops update cluster k8s-cookbook.net –-yes &amp;&amp; kops rolling-update cluster<br/>...<br/>Using cluster from kubectl context: k8s-cookbook.net<br/>NAME                  STATUS NEEDUPDATE    READY  MIN    MAX    NODES<br/>master-us-east-1a     Ready  0             2      2      2      1<br/>nodes                 Ready  0             3      3      3      3<br/>No rolling-update required.</pre>
<p>Just like modifying nodes, we can use both <kbd>kubectl get nodes</kbd> and <kbd>kops validate cluster</kbd> to check whether the new master has joined the cluster.</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">Upgrading a cluster</h1>
                </header>
            
            <article>
                
<p>For demonstrating how we upgrade the Kubernetes version, we'll first launch the cluster with the 1.8.7 version. For detailed instructions of parameters, refer to the previous recipes in this chapter. Input the following command:</p>
<pre>// launch a cluster with additional parameter --kubernetes-version 1.8.7 # kops create cluster --master-count 1 --node-count 2 --zones us-east-1a,us-east-1b,us-east-1c --node-size t2.micro --master-size t2.small --topology private --networking calico --authorization=rbac --cloud-labels "Environment=dev" --state $KOPS_STATE_STORE --kubernetes-version 1.8.7 --name k8s-cookbook.net --yes </pre>
<p>After few minutes, we can see that the master and the nodes are up with version 1.8.7:</p>
<pre># kubectl get nodes <br/>NAME STATUS ROLES AGE VERSION <br/>ip-172-20-44-128.ec2.internal Ready master 3m v1.8.7 <br/>ip-172-20-55-191.ec2.internal Ready node 1m v1.8.7 <br/>ip-172-20-64-30.ec2.internal Ready node 1m v1.8.7</pre>
<p>In the following example, we'll walk through how to upgrade Kubernetes cluster from 1.8.7 to 1.9.3 using kops. Firstly, run the kops upgrade cluster command. Kops will show us the latest version that we could upgrade to:</p>
<pre># kops upgrade cluster k8s-cookbook.net --yes <br/>ITEM PROPERTY OLD NEW <br/>Cluster KubernetesVersion 1.8.7 1.9.3 <br/>Updates applied to configuration. You can now apply these changes, <br/>using `kops update cluster k8s-cookbook.net` </pre>
<p>It indicates that the configuration has been updated, and that we'll need to update the cluster now. We run command with the dryrun mode to check what will be modified first:</p>
<pre>// update cluster<br/># kops update cluster k8s-cookbook.net<br/>...<br/>Will modify resources:<br/>  LaunchConfiguration/master-us-east-1a.masters.k8s-cookbook.net<br/>       UserData<br/>                             ...<br/>                             +   image: gcr.io/google_containers/kube-apiserver:v1.9.3<br/>                             -   image: gcr.io/google_containers/kube-apiserver:v1.8.7<br/>                             ...<br/>                             +   image: gcr.io/google_containers/kube-controller<br/>manager:v1.9.3<br/>                             -   image: gcr.io/google_containers/kube-controller-manager:v1.8.7<br/>                             ...<br/>                                 hostnameOverride: '@aws'<br/>                             +   image: gcr.io/google_containers/kube-proxy:v1.9.3<br/>                             -   image: gcr.io/google_containers/kube-proxy:v1.8.7<br/>                                 logLevel: 2<br/>                               kubeScheduler:<br/>                             +   image: gcr.io/google_containers/kube-scheduler:v1.9.3<br/>                             -   image: gcr.io/google_containers/kube<br/>scheduler:v1.8.7<br/>                             ...<br/>Must specify --yes to apply changes</pre>
<p>We could see all of the components moved from v1.8.7 to v1.9.3 in Auto Scaling Launch Configuration. After verifying that everything is good, we can run the same command with the <kbd>--yes</kbd> parameter:</p>
<pre>// run the same command with --yes <br/># kops update cluster k8s-cookbook.net --yes <br/>... <br/>kops has set your kubectl context to k8s-cookbook.net <br/>Cluster changes have been applied to the cloud. <br/>Changes may require instances to restart: kops rolling-update cluster </pre>
<p>In this case, we need to run the rolling update for the cluster:</p>
<pre># kops rolling-update cluster --yes<br/>Using cluster from kubectl context: k8s-cookbook.net<br/>NAME                  STATUS        NEEDUPDATE    READY  MIN    MAX    NODES<br/>master-us-east-1a     NeedsUpdate   1             0      1      1      1<br/>nodes                 NeedsUpdate   2             0      2      2      2<br/>I0414 22:45:05.887024   51333 rollingupdate.go:193] Rolling update completed for cluster "k8s-cookbook.net"!</pre>
<p>All the nodes have been upgraded to 1.9.3! When performing the rolling update, kops drains one instance first then cordons the node. The auto-scaling group will bring up another node with the updated user data, which contains the Kubernetes component images with the updates. For avoiding downtime, you should have multiple masters and nodes as the basic deployment.</p>
<p>After a rolling update is completed, we can check the cluster version via <kbd>kubectl get nodes</kbd>:</p>
<pre># kubectl get nodes<br/>NAME                            STATUS    ROLES     AGE       VERSION<br/>ip-172-20-116-81.ec2.internal   Ready     node      14m       v1.9.3<br/>ip-172-20-41-113.ec2.internal   Ready     master    17m       v1.9.3<br/>ip-172-20-56-230.ec2.internal   Ready     node      8m        v1.9.3</pre>
<p>All the nodes have been upgraded to 1.9.3!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">There's more...</h1>
                </header>
            
            <article>
                
<p class="mce-root">In kops, there are lots of useful addons, such as autoscaling nodes (<a href="https://github.com/kubernetes/kops/tree/master/addons/cluster-autoscaler">https://github.com/kubernetes/kops/tree/master/addons/cluster-autoscaler</a>)  and mapping the service to the record in Route53 (<a href="https://github.com/kubernetes/kops/tree/master/addons/route53-mapper">https://github.com/kubernetes/kops/tree/master/addons/route53-mapper</a>). Refer to the add-ons page to find out more!</p>


            </article>

            
        </section>
    

        <section>

                            <header>
                    <h1 class="header-title">See also</h1>
                </header>
            
            <article>
                
<ul>
<li><em>Deployment API</em> in <a href="e9a51674-078b-4ffc-a76c-98774150bfa3.xhtml" target="_blank">Chapter 2</a>, <em>Walking through <span>Kubernetes</span> Concepts</em></li>
<li><em>Building multiple masters</em> in <a href="1a0d884d-59d3-4f67-adee-2d2e37030132.xhtml" target="_blank">Chapter 4</a>, <em><span>Building High-Availability Clusters</span></em></li>
<li><em>Managing Kubernetes cluster on GKE</em> in <a href="dfc46490-f109-4f07-ba76-1a381b006d76.xhtml" target="_blank">Chapter 7</a>, <em>Building Kubernetes on GCP</em></li>
</ul>


            </article>

            
        </section>
    </body></html>