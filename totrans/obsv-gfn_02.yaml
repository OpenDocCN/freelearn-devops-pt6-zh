- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Instrumenting Applications and Infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous chapter introduced observability, with examples outside of the
    computing world to give you a generic understanding of the subject. In this chapter,
    we’ll build on those examples by providing a high-level overview of both application
    and infrastructure instrumentation. We will look at the data created by systems
    and how that fits into the different telemetry types and common protocols in use.
    We will also explore widely used libraries for popular programming languages that
    simplify instrumenting applications. To finish, we will cover more traditional
    telemetry collection from infrastructure components, operating systems, and network
    devices. This will give you insight into the components that are still in operation
    today that run applications and Kubernetes workloads. This chapter is aimed at
    readers of all technical abilities and no specific technologies are needed. An
    understanding of observability terminology (for example, logs, metrics, traces,
    and instrumentation) is helpful. It aims to provide an overview of the technology
    space and act as a valuable resource that you can quickly reference when you are
    working with your observability solutions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we explore the following introductory sections:'
  prefs: []
  type: TYPE_NORMAL
- en: Common log formats
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics protocols and best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracing protocols and best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using libraries to instrument efficiently
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Infrastructure data technologies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common log formats
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Log files are a standard component of computer systems and an essential tool
    for software developers and operators – in our example, Diego and Ophelia, respectively.
    Logs support performance and capacity monitoring in infrastructure, bug detection
    in software, root cause analysis, user behavior tracking, and more. There is no
    perfect recipe for logs and as such, it does not matter what your logs look like,
    though following certain guidelines will help your future self when you need to
    analyze logs. In this section, we will learn about different log formats and how
    the data can be used. Log formats are the definition of what a log file looks
    like and should explain how the data can be interpreted.
  prefs: []
  type: TYPE_NORMAL
- en: Log formats usually identify if they are structured or unstructured, the data
    types used in them, and if any encoding or delimitation is being used. We’ll explore
    structure first and then look at example log formats in more detail in the following
    sections.
  prefs: []
  type: TYPE_NORMAL
- en: Structured, semi-structured, and unstructured logging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As mentioned previously, it does not matter what your logs look like and they
    can come in structured, semi-structured, or unstructured formats. However, when
    designing and building observability solutions, it’s important to understand the
    log formats you are working with. This ensures that you can ingest, parse, and
    store the data in a way that it can be used effectively. If you familiarized yourself
    with the personas in [*Chapter 1*](B18277_01.xhtml#_idTextAnchor018), you have
    an awareness of who they will be used by and for what purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Structured logging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`name=Diego` or `city=Berlin`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of a structured log format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: An additional benefit of structured logging is that you can validate the conformation
    of the data to a schema with tools such as JSON schema. This opens up the possibility
    of making version control changes to the schema, which is where logs and event
    bus technology overlap.
  prefs: []
  type: TYPE_NORMAL
- en: Semi-structured logging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Semi-structured logs** aim to bridge the gap between unstructured and structured
    and, as a result, can be quite complicated. They are designed to be easy for humans
    to read but also have a schema that makes it possible for machines to process
    them too. They have complex field and event separators and usually come with a
    defined pattern to aid with ingesting and parsing. Parsing is usually done using
    regular expressions or other code.'
  prefs: []
  type: TYPE_NORMAL
- en: Unstructured logging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Unstructured logging** typically refers to log entries that are presented
    in a textual format that can easily be read by humans but is difficult for machines
    to process. They are often color-coded with blank spaces to improve presentation
    and readability. It is this presentation that creates issues for machines to process
    the logs. Parsing and splitting the data correctly creates a disassociation between
    events and their identifying metadata. An unstructured log will require some custom
    parsing, requiring intimate knowledge of the data and often creating additional
    work for the engineer (*Ophelia*) when ingesting data. This also creates technical
    liability; the dependency on the log remaining the same restricts developers from
    changing logs or runs the risk of parsing and reporting on unstructured logs prone
    to breaking.'
  prefs: []
  type: TYPE_NORMAL
- en: To aid the ability of machines to process unstructured logs, encapsulation prevents
    entries such as stack traces from splitting at an inappropriate location.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a multiline log, with a naive encapsulation
    that looks for line breaks; this will appear in logging systems as four distinct
    events:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: With encapsulation based on the timestamp at the start of the event, this will
    be stored correctly for searching.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will explore common log formats found in today’s
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: Sample log formats
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Many log formats have been used in computer systems. All of these formats have
    a common goal of presenting a standard structure or set of fields for recording
    important information about the activity of a computer system. The following table
    aims to provide easy reference for some of the more notable ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Format** | **Overview** |'
  prefs: []
  type: TYPE_TB
- en: '| **Common Event** **Format** (**CEF**) | CEF is an open logging and auditing
    format from ArcSight that aims to provide a simple interface to record security-related
    events. |'
  prefs: []
  type: TYPE_TB
- en: '| **NCSA** **Common Log** **Format** (**CLF**) | The NCSA CLF is historically
    used on web servers to record information about requests made to the server. This
    format has been extended by the CLF to include additional information about the
    browser (user-agent) and the referer. |'
  prefs: []
  type: TYPE_TB
- en: '| **W3C Extended Log** **File Format** | W3C Extended Log File Format is a
    log format commonly used by Windows Internet Information Services servers (web
    servers). |'
  prefs: []
  type: TYPE_TB
- en: '| **Windows** **Event Log** | Windows Event Log is the standard log format
    used by the Windows operating system. These logs record events that occur on the
    system and are categorized System, Application, Security, Setup, and Forwarded
    events. |'
  prefs: []
  type: TYPE_TB
- en: '| **JavaScript Object** **Notation** (**JSON**) | JSON is an open standard
    file format that is very useful for easily parsing structured log events. |'
  prefs: []
  type: TYPE_TB
- en: '| **Syslog** | Syslog is a standard that’s used across many hardware devices
    such as networking, compute, and storage, and is used by the Linux kernel for
    logging. |'
  prefs: []
  type: TYPE_TB
- en: '| **Logfmt** | Logfmt does not have a defined standard but is a widely used
    form of human-readable structured logging. |'
  prefs: []
  type: TYPE_TB
- en: Table 2.1 – Log format overview
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at these formats in greater detail.
  prefs: []
  type: TYPE_NORMAL
- en: CEF
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Developed by ArcSight to fulfill the **Security Information and Event Management**
    (**SIEM**) use case, the CEF is a structured text-based log format. Using UTF-8
    encoding, the format contains a prefix, a CEF header, and a body containing additional
    enrichment data.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table shows the log sections of the CEF format:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Log Section** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| Prefix | It combines the event timestamp and source hostname. |'
  prefs: []
  type: TYPE_TB
- en: '| CEF header | It combines the following pieces of metadata:'
  prefs: []
  type: TYPE_NORMAL
- en: Software version
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vendor name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Product name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Product version
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Product event class identification code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Event name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Event severity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Body | It contains a list of key-value pairs |'
  prefs: []
  type: TYPE_TB
- en: Table 2.2 – CEF format
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example CEF log event:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: NCSA CLF
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As one of the oldest log formats used by web servers, the NCSA CLF has for a
    long time been the most common and well-known log formats. It has a fixed format
    text-based structure and therefore cannot be customized at all.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the NCSA CLF field list:'
  prefs: []
  type: TYPE_NORMAL
- en: Remote host address
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remote log name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Username
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Timestamp
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Request and protocol version
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HTTP status code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bytes sent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where data is missing from the log, a hyphen acts as a placeholder. Unsupported
    characters are replaced with the `+` symbol.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example NCSA CLF log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: W3C Extended Log File Format
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Microsoft Internet Information Server log format known as W3C is a structured
    yet configurable format. Full control over the included fields ensures log files
    contain the most relevant data. Identification of the information or direction
    of flow is denoted using a string prefix: server (*S*), client (*C*), server to
    client (*SC*), and client to server (*CS*).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the W3C Extended Log File Format field list:'
  prefs: []
  type: TYPE_NORMAL
- en: Timestamp
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Client IP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Server IP
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: URI-stem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HTTP status code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bytes sent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bytes received
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Time taken
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Version
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is an example W3C log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Microsoft Windows Event Log
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Microsoft Windows operating system comes with a built-in complex structured
    logging system that captures data related to specific events on the operating
    system. There are four common Windows event log categories – system, application,
    security, and setup – and an additional special category for forwarded events.
  prefs: []
  type: TYPE_NORMAL
- en: 'Each event log is also one of five different types: information, warning, error,
    success audit, and failure audit. Windows Event Log is one of the most verbose
    log formats in use. It usually includes details such as timestamp, event ID, username,
    hostname, message, and category, making it invaluable in diagnosing problems.
    Windows event IDs are documented and searchable, so you can easily get detailed
    information regarding the log event; they are grouped into categories, narrowing
    down the area where the event occurred, which makes debugging very accurate.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a trimmed example of Microsoft Windows Event Log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: JSON
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As one of the newer yet most commonly used log formats today, JSON is a structured
    format constructed from multiple key-value pairs. Using JSON, data can be nested
    into different layers while keeping the format easy to read. Additionally, different
    data types can be represented, such as string, number, Boolean, null, object,
    and array.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example JSON log file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Syslog
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The go-to log format for many years and still widely used, Syslog is a defined
    standard for creating and transmitting logs. The `514` and `6514`, with the latter
    being used for encryption.
  prefs: []
  type: TYPE_NORMAL
- en: The Syslog message format combines a standardized header and message holding
    the body of the log.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example Syslog log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Logfmt
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Logfmt is a widely used log format that fits as human readable and structured
    so that computers and people can both read it. A Logfmt-formatted log line consists
    of any number of key-value pairs that can be easily parsed. As there are no standards,
    it is easy to extend and perfect for developers to simply add more key-value pairs
    to the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example Logfmt log:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Exploring metric types and best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Metrics, along with logs, are an essential tool for software developers (*Diego*)
    and operators (*Ophelia*), providing them with indicators regarding the state
    of applications and systems. Resource usage data is great for monitoring a metric
    that captures numerical data over time. There are many different types of resources
    but some good examples would be CPU or RAM usage, the number of messages in a
    queue, and the number of received HTTP requests. Metrics are frequently generated
    and easily enriched with labels, attributes, or dimensions, making them efficient
    to search and ideal in determining if something is wrong, or different from usual.
  prefs: []
  type: TYPE_NORMAL
- en: 'A metric commonly has the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Name**: This uniquely identifies the metric'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data point value(s)**: The data that’s stored varies by metric type'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dimensions**: Additional enrichment labels or attributes that support analysis'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metrics capture the behavior of the data they represent. CPU usage would go
    up and down between 0% and 100% usage, whereas the number of received HTTP requests
    could increase indefinitely. In the following section, we will look at metric
    types, which allow us to capture the behavior of the metric being collected.
  prefs: []
  type: TYPE_NORMAL
- en: Metric types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Metrics vary in characteristics and structure. There are four common types
    of metrics, from simple single values to more complex values:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Counter**: This metric represents the last increment value. This could be
    the incremental change from the last recording or the total increment since the
    recording started.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are some examples of this metric:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The number of requests served
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Tasks completed
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Errors reported
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: How the value is reset to zero depends on the protocol used to collect them,
    so it is important to factor this in for your use case. The StatsD implementation
    resets the counter every time the value is flushed, and Prometheus resets the
    counter when the application process restarts.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Gauge**: A gauge metric is a snapshot of state and can be used to take a
    measure of something reporting continuously. As such, it is usually made more
    useful by aggregating with sum, average, minimum, or maximum over a certain period.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are some examples of this metric:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Temperature
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Items in queue
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Disk space used
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Number of concurrent requests
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Like counter, the definitions for gauge vary in implementation, so be sure to
    verify how the protocol you select will report gauge metrics.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`_count`), a sum of all the values of the measurements (`_sum`), and several
    buckets that have a count of events with a measure less than or equal (`le`) to
    a defined value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Definitions can vary in implementation – for example, Prometheus has a `histogram_quantile`
    function that can be used to calculate percentiles from histogram metrics.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`_count` and `_sum` metrics and several groupings. Unlike a histogram, these
    groupings are a quantile, and the value represents the value of that quantile
    at the point in time for the measurement. For example, a quantile of 0.99 and
    a value of 3.2148 would indicate that 99% of the sampled data was smaller than
    3.2148.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Again, definitions can vary in implementation, so work out what your goals are
    from your metrics to ensure the capabilities are supported by your choice of protocol.
    It’s useful to note that, in Prometheus, summary metrics have a significant drawback
    in modern systems as they cannot be aggregated over multiple sources.
  prefs: []
  type: TYPE_NORMAL
- en: There are some distinct differences between these metric types, as we will discuss
    in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing metric types
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following table describes each type in general terms. When querying them,
    this provides a useful reference when approaching metric adoption:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Consideration** | **Counter** | **Gauge** | **Histogram** | **Summary**
    |'
  prefs: []
  type: TYPE_TB
- en: '| Structure | Simple | Simple | Complex | Complex |'
  prefs: []
  type: TYPE_TB
- en: '| Can increase and decrease | No | Yes | No | No |'
  prefs: []
  type: TYPE_TB
- en: '| Is an approximation | No | No | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Can calculate percentiles | No | No | Yes | Yes |'
  prefs: []
  type: TYPE_TB
- en: '| Can use a rate function | Yes | No | No | No |'
  prefs: []
  type: TYPE_TB
- en: '| Can be queried with the `prometheus` `histogram_quantile` function | No |
    No | Yes | No |'
  prefs: []
  type: TYPE_TB
- en: '| Can be aggregated across multiple series | Yes | Yes | Yes | No |'
  prefs: []
  type: TYPE_TB
- en: Table 2.3 – Comparison of metric types
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table provides a few reference examples of the type and values
    expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Metric Type** | **Data Field** | **Value** |'
  prefs: []
  type: TYPE_TB
- en: '| **Counter** | Last increment | 15 |'
  prefs: []
  type: TYPE_TB
- en: '| **Gauge** | Last value | 25.4 |'
  prefs: []
  type: TYPE_TB
- en: '| **Histogram** | Min | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| Max | 100 |'
  prefs: []
  type: TYPE_TB
- en: '| Count | 10 |'
  prefs: []
  type: TYPE_TB
- en: '| **Interval** | 20 |'
  prefs: []
  type: TYPE_TB
- en: '| 0-20 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| 20-40 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 40-60 | 4 |'
  prefs: []
  type: TYPE_TB
- en: '| 60-80 | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| 80-100 | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| **Summary** | Min | 1.2ms |'
  prefs: []
  type: TYPE_TB
- en: '|  | Max | 4.23ms |'
  prefs: []
  type: TYPE_TB
- en: '|  | Count | 10 |'
  prefs: []
  type: TYPE_TB
- en: '|  | Sum |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | **Percentiles/Quantiles** |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | P90 | 2.98ms |'
  prefs: []
  type: TYPE_TB
- en: '|  | P95 | 3.76ms |'
  prefs: []
  type: TYPE_TB
- en: '|  | P99 | 4.23ms |'
  prefs: []
  type: TYPE_TB
- en: Table 2.4 – Metric type example data
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve looked at the different types of metrics, let’s look at the different
    technologies used to transmit metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Metric protocols
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Metric protocols** are collections of tools and libraries for instrumenting
    applications, data formats to transmit, clients to collect data, and often storage
    and visualization tools. Some common protocols that are in use today are described
    in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Metric Protocol** | **Features** |'
  prefs: []
  type: TYPE_TB
- en: '| **StatsD** | It supports the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Counters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gauges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Timers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Histograms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| **DogStatsD** | DogStatsD implements the StatsD protocol and adds a few Datadog-specific
    extensions:'
  prefs: []
  type: TYPE_NORMAL
- en: Histogram metric type
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service checks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Events
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tagging
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| **OpenTelemetry** **Protocol** (**OTLP**) | It supports the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Counters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gauges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Histograms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summaries (legacy support)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Prometheus** | It supports the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Counters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gauges
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cumulative histograms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summaries
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.5 – Common metric protocols and their features
  prefs: []
  type: TYPE_NORMAL
- en: Metrics are very powerful, but some pitfalls can catch people out. Some of these
    can lead to expensive mistakes. To avoid these pitfalls, let’s discuss some best
    practices.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for implementing metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Introducing metrics into your services is a very good way to gain a huge amount
    of visibility on how they behave in real situations. The following best practices
    are from our experience with metrics and will help you manage scope creep, cost,
    and linking metrics up with traces:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Set your objectives**: Work out what your objectives are from your metrics.
    We have already spoken about the variation in implementation between metric protocols
    – this can have a big impact if you are expecting to use a metric in a certain
    way and haven’t factored in nuances.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This will also help you define **service-level indicators** (**SLIs**) and **service-level
    objectives** (**SLOs**), which will be useful in [*Chapter 9*](B18277_09.xhtml#_idTextAnchor183),
    *Managing Incidents* *Using Alerts*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Manage cardinality**: Cardinality is generally defined as the number of unique
    elements in a set. High cardinality may provide richer, more useful data, but
    at the cost of monitoring performance impacts or increased storage costs. For
    example, if you dimension your metrics by server name, the sample could be small,
    maybe a few hundred metrics. If we compare this to dimensioning by user, which
    could be in the millions, the increase in the number of metrics produced is exponential.
    This increase has a direct impact on load and storage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Take time to understand the capabilities of the observability backend – things
    such as the billing framework, limitations, storage, and performance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Add context**: The ability to correlate (establish a common identifier) metrics
    with traces has been introduced to Grafana and Open Telemetry recently with exemplars.
    They enable quick visualization and linking between a metric data point and a
    specific trace span, thus giving improved context and detail to your data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we just discussed, metrics capture numerical data from a single service;
    however, the systems that operate today may consist of multiple services. Distributed
    tracing is a way to gain visibility of the communications between services. Let’s
    take a look at tracing protocols and some best practices regarding them.
  prefs: []
  type: TYPE_NORMAL
- en: Tracing protocols and best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Tracing**, or as it is more commonly referred to, **distributed tracing**,
    tracks application requests as they are made between services of a system. It
    allows you to follow a single request through an entire system or look at the
    aggregate data over requests to better understand distributed behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: This capability provides software developers (*Diego*), operators (*Ophelia*),
    and service managers (*Steven*) with valuable tools that enable an understanding
    of the flow of logic that is essential for troubleshooting. Instrumenting your
    code by adding traces helps you easily pinpoint almost any issue or at least have
    a clear indicator of where the problem could be. **Distributed tracing** uses
    the concepts of spans and traces to capture this data. Let’s examine these in
    more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Spans and traces
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The **trace record** is the parent object that represents the data flow or
    execution path through the system being observed. Each **trace** will contain
    one or more **span** records that represent the logical operations. This relationship
    between traces and spans is illustrated in the following figure, in what can be
    thought of as a directed acyclic graph of spans:'
  prefs: []
  type: TYPE_NORMAL
- en: '![ Figure 2.1 – Traces and spans](img/B18277_02_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2.1 – Traces and spans
  prefs: []
  type: TYPE_NORMAL
- en: 'A trace is pieced together from multiple spans and would usually report the
    following information:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Identifier**: Uniquely identifies the trace'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Name**: Describes the overall work being recorded'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Timing details**: Provides the start and end timestamps for the complete
    trace'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A span commonly has the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Trace identifier**: Establishes the trace relationship'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Identifier**: Uniquely identifies the span'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parent span identifier**: Establishes a parent relationship'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Name**: Describes the work being recorded'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Timing details**: Provides the start and end timestamps'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A trace identifier will be automatically generated if one has not been received
    by the calling operation; each application will pass the trace ID along to the
    next.
  prefs: []
  type: TYPE_NORMAL
- en: The start and end timestamps for the operation help identify which stages are
    taking the most time. You can drill down to identify dependencies on other services
    and how they contribute to the overall trace timings.
  prefs: []
  type: TYPE_NORMAL
- en: Spans can often have additional fields that are specific to the protocol implemented.
    Investigating the options against your use case will help provide the right diagnostics
    for your system.
  prefs: []
  type: TYPE_NORMAL
- en: Tracing protocols
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As with all technology, standards have taken a while to be formalized for tracing,
    and a few protocols have been implemented. Some common protocols that are in use
    today are described in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Protocol Name** | **Features** |'
  prefs: []
  type: TYPE_TB
- en: '| OTLP | It supports the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Additional fields
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Span attributes (metadata about the operation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Context propagation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Span events (meaningful point-in-time annotation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Span links (imply a causal relationship between spans)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Span kind (additional details supporting the assembly of a trace)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Zipkin | It supports the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Additional fields
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Span tags (metadata about the operation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Context propagation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Span annotations (such as OTLP events and meaningful point-in-time annotation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Span kind (additional details supporting the assembly of a trace)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Jaeger | It supports two formats – Jaeger Thrift and Jaeger Proto – with
    similar characteristics. Jaeger Proto has been discontinued in favor of OTLP.It
    supports the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Additional fields
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Span tags (metadata about the operation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Context propagation (Thrift only; Proto does not support this)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Span logs (meaningful point-in-time annotation)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Span references (imply a causal relationship between spans)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Span kind (similar to OTLP, this is stored as a special type of span tag)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: Table 2.6 – Distributed tracing protocols and features
  prefs: []
  type: TYPE_NORMAL
- en: Implementing distributed tracing can be a daunting task, so let’s discuss some
    best practices that will help you avoid common mistakes and issues.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for setting up distributed tracing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far, we have described how traces will help you with problem resolution.
    However, when producing traces, it’s worth considering the additional system visibility
    against cost and performance impacts. Let’s discuss some of the best practices
    that should be considered when implementing tracing on any application or system.
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The process of generating trace information can potentially incur a performance
    overhead at the application level. Mix this with the reduced level of control
    with auto-instrumentation and the problem can increase.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of the possible impacts to consider:'
  prefs: []
  type: TYPE_NORMAL
- en: Increased latency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory overhead
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Slower startup time
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Some of the more recent observability agents have addressed a lot of the issues
    with configurable options. For example, the OpenTelemetry Collector offers a sampling
    configuration that will submit 0% to 100% of spans to the collection tool. This
    sampling implementation will also notify any downstream services that the parent
    sampled its span so that the full trace will be collected.
  prefs: []
  type: TYPE_NORMAL
- en: Cost
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Increased network and storage costs can become a factor and need factoring in
    as a limitation when designing your observability solution. However, this does
    depend on your observability backend and if you are doing additional processing
    or filtering when the data is being transmitted.
  prefs: []
  type: TYPE_NORMAL
- en: 'The mitigation practices are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sampling**: Only sends a percentage of traces'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Filtering**: Restricts which traces are transmitted and stored'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Retention**: Sets optimal data storage durations'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accuracy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To ensure one of the major benefits of tracing is implemented, it is important
    to ensure context propagation is working correctly. Without the relationships
    being established between the operations, spans will be broken across multiple
    traces. Validating and solving this problem will increase the usability and adoption
    of tracing for fast issue resolution.
  prefs: []
  type: TYPE_NORMAL
- en: With most code, libraries are used so that developers can focus on writing code
    that provides value to the organization. The modern libraries that are available
    will help you instrument quickly so that you can start using the data collected
    from your application. We’ll explore this next.
  prefs: []
  type: TYPE_NORMAL
- en: Using libraries to instrument efficiently
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Instrumenting your application code to emit the telemetry of logs, metrics,
    and traces can be complex, time-consuming, and difficult to maintain. There are
    two main approaches to solving this problem – automatic instrumentation and manual
    instrumentation – with a wide selection of SDKs and libraries available to support
    them. Here is a brief overview of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Automatic instrumentation**: Automatic instrumentation is the simplest to
    implement but can lack the level of control that’s often required when building
    an observability platform. In a very short space of time, it will provide visibility
    into your application and help you start answering your observability questions.
    Without careful configuration and design, this will lead to other problems such
    as performance and cost issues, and, in the worst case, render the observability
    platform useless.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The approach varies depending on the programming language; for example, code
    manipulation (during compilation or at runtime) is often used with Java, whereas
    monkey patching (updating behavior dynamically at runtime) is often used with
    Python and JavaScript.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Manual instrumentation**: Manual instrumentation can be quite complex, depending
    on the systems being instrumented. It requires an intimate knowledge of the application
    code, with the benefit of allowing you to specify exactly what telemetry you want.
    Additionally, you need to understand the observability API you are working with.
    Though SDKs and libraries have simplified this, a lot of work must be done to
    understand the implementation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are interested in further reading about application instrumentation,
    there is an excellent section dedicated to the subject in Alex Boten’s book *Cloud-Native
    Observability with OpenTelemetry*, by Packt Publishing.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve seen how various libraries approach instrumentation, let’s look
    at some of the common libraries that are used in different languages.
  prefs: []
  type: TYPE_NORMAL
- en: Popular libraries for different programming languages
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There have been many telemetry solutions, SDKs, and libraries over the years;
    however, in more recent history, there has been a concerted effort to align on
    supporting the OpenTelemetry standard. With its goal to provide a set of standardized
    vendor-agnostic SDKs, APIs, and tools for ingesting, transforming, and transporting
    data to an observability backend platform, there are obvious benefits. We will
    look at the OpenTelemetry libraries in this section to focus on where the most
    enhancements are currently. However, investigating what is appropriate for your
    use case is important. One drawback of this concerted development effort is that
    it creates a fast-changing landscape, so you have to pay attention to release
    stability and monitor for changes and improvements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of the available instrumentation libraries:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Language** | **SDKs** **and Libraries** | **Notes** |'
  prefs: []
  type: TYPE_TB
- en: '| JavaScript | OpenTelemetry JavaScript SDK | Multiple resources and examples
    are available that cover Node.js and browser implementations. |'
  prefs: []
  type: TYPE_TB
- en: '| JavaScript | OpenTelemetry JavaScript Contrib | An additional repository
    for OpenTelemetry JavaScript contributions that are not part of the core repository
    and core distribution of the API and the SDK. |'
  prefs: []
  type: TYPE_TB
- en: '| Python | OpenTelemetry Python SDK | At the time of writing, both traces and
    metrics are stable, with logs in an experimental state. |'
  prefs: []
  type: TYPE_TB
- en: '| Python | OpenTelemetry Python Contrib | An additional repository for OpenTelemetry
    Python contributions. At the time of writing, Contrib libraries are in beta and
    active development. |'
  prefs: []
  type: TYPE_TB
- en: '| Java | OpenTelemetry Java SDK | There is a long list of supported libraries
    and frameworks with good documentation to get you started. |'
  prefs: []
  type: TYPE_TB
- en: '| Java | Spring Boot/Micrometer | As of Spring Boot 3, the default exporter
    for Micrometer is OTLP. |'
  prefs: []
  type: TYPE_TB
- en: Table 2.7 – Common libraries and SDKs for telemetry
  prefs: []
  type: TYPE_NORMAL
- en: Applications are only one part of the computer systems we work with today. Our
    infrastructure components, such as switches, servers, Kubernetes clusters, and
    more, are just as important to observe. We’ll discuss how we can do this in the
    next section.
  prefs: []
  type: TYPE_NORMAL
- en: Infrastructure data technologies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this chapter, we have focused on implementations that work well for
    cloud technologies and containerized platforms. Underneath all of the abstraction
    are physical components, the servers running the workloads, the network and security
    devices handling communications, and the power and cooling components that keep
    things running. These have not dramatically changed over time and neither has
    the telemetry reported by the logs and metrics. Let’s take a look at the common
    infrastructure components and standards used in this area.
  prefs: []
  type: TYPE_NORMAL
- en: Common infrastructure components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Infrastructure can largely be categorized into some broad categories, as we
    will discuss in the following sections. The types of data you can collect will
    differ on the category of the component.
  prefs: []
  type: TYPE_NORMAL
- en: Compute or bare metal
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Servers are often referred to as **bare metal** or compute; these are physical
    devices that are used for computation. Often, these systems would run virtualized
    operating systems that can collect server telemetry. Usually, you will run an
    agent on the operating system that scrapes metrics or reads log files and then
    transports them to a receiver. The data that’s obtained from server equipment
    can not only help in diagnosing and responding to issues but can help predict
    capacity problems that may arise in the future. Often, these devices can send
    data outside of any virtual operating system as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, here are a few telemetry examples that can indicate if a system
    is close to capacity in any area:'
  prefs: []
  type: TYPE_NORMAL
- en: System temperature
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CPU utilization percent
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall disk space used and remaining
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory usage and free memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network devices
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Network and security devices such as switches and firewalls come with the capability
    to send monitoring information via SNMP to a receiver. Firewalls can often send
    Syslog-formatted logs to a receiver. The telemetry provided helps diagnose issues
    with connectivity – for example, latency and throughput are difficult to investigate
    without information from the hardware.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some telemetry examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Latency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Throughput
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Packet loss
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bandwidth
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Power components
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The components that provide power or cooling are often built with the capability
    to emit telemetry over SNMP to a receiver. Some older components will implement
    the Modbus protocol and expose registers that can be read to obtain metrics. The
    telemetry reported at this level is simplistic but essential when you are operating
    your data center. If, for example, you are running on backup power, you need to
    react fast to protect the systems or trigger other mitigation activities.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some telemetry examples:'
  prefs: []
  type: TYPE_NORMAL
- en: Power supply state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backup power supply state
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voltage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wattage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Current
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As infrastructure components have been used for many years, there are some agreed-upon
    standards for data structures and transmission. Let’s look at those original standards
    now.
  prefs: []
  type: TYPE_NORMAL
- en: Common standards for infrastructure components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are a few well-established standards that are used by infrastructure
    components that you may need to monitor. These include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Syslog**: Syslog has been around since the 1980s and is very common in infrastructure
    components. Created as part of the **Sendmail project** by Eric Allman, it was
    quickly adopted and became the standard logging solution on Unix-like platforms.
    It is very popular because of its ease of use. To use Syslog, you need a client
    available to receive the data, and each device needs to be configured to send
    data there. Common clients include RSyslog and Syslog-ng, and the OpenTelemetry
    Collector also supports this protocol.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Syslog message format provides a structured framework that has allowed organizations
    to provide vendor-specific extensions. Contributing to its success and longevity,
    most modern observability tooling providers still supply an interface to receive
    Syslog messages. The logs can then be accessed and analyzed alongside other system
    and application telemetry.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Simple Network Management Protocol** (**SNMP**): Forming part of the original
    Internet Protocol suite defined by the **Internet Engineering Task Force** (**IETF**),
    SNMP is commonly used in networking infrastructure. A lot of the protocol is not
    of interest for observability, but **SNMP Traps** allow devices to inform the
    manager about significant events.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SNMP provides a common mechanism for network devices to relay management and,
    specifically in the context of this chapter, monitoring information within single
    and multi-vendor LAN or WAN environments. It is different from other telemetry
    receivers as it requires more specific knowledge of the devices on the network,
    and specific configurations for the metrics to be collected. Here are some examples
    of data that can be collected from SNMP:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| **Data Type** | **Example** **Metrics Collected** |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Network data | ProcessesUptimeThroughput |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: '| Device data | Memory usageCPU usageTemperature |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: Table 2.8 – Example SNMP Trap information
  prefs: []
  type: TYPE_NORMAL
- en: You may encounter other formats out in the wide world of engineering. We have
    covered a lot of the common formats here and have hopefully given you an indication
    of the types of information you will need to help you work with telemetry in Grafana.
    Grafana will handle just about whatever you can throw at it. Knowing what’s important
    and preparing for that will help you when you’re building your visualizations
    and alerts on that data. Now, let’s quickly recap what we’ve covered in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored the foundations that modern observability is built
    on. This will serve as easy reference and support for future chapters in this
    book and your own projects. First, we looked at the common log formats and their
    examples, which will assist us in [*Chapter 4*](B18277_04.xhtml#_idTextAnchor092),
    *Looking at Logs with Grafana Loki*. Then, we took a closer look at metrics, their
    differing types, some example protocols, and best practices to consider when designing
    metric-based observability. What we covered here will help with [*Chapter 5*](B18277_05.xhtml#_idTextAnchor106),
    *Monitoring with Metrics Using Grafana Mimir and Prometheus*. We then moved on
    to traces and spans, where we looked at current protocols and some best practices
    to consider when building an efficient and effective trace-based observability
    platform. This section lays the groundwork for [*Chapter 6*](B18277_06.xhtml#_idTextAnchor134),
    *Tracing Technicalities with Grafana Tempo*. After looking at the telemetry of
    observability, we learned about application instrumentation, which we will see
    more of in [*Chapter 3*](B18277_03.xhtml#_idTextAnchor063), *Setting Up a Learning
    Environment with Demo Applications*, and later chapters where we go into specifics
    with logs, metrics, and traces. Lastly, we considered some of the more traditional
    infrastructure telemetry.
  prefs: []
  type: TYPE_NORMAL
- en: With the overview of application and infrastructure instrumentation complete,
    we can now start playing with logs, metrics, and traces. In the next chapter,
    we will get our learning environment up and running.
  prefs: []
  type: TYPE_NORMAL
