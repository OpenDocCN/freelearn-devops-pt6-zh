- en: Walking through Kubernetes Concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Linking Pods and containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing Pods with ReplicaSets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment API
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with Services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with Volumes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with Secrets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with names
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with Namespaces
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with labels and selectors
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we will start by creating different kinds of resources on the
    Kubernetes system. In order to realize your application in a microservices structure,
    reading the recipes in this chapter will be a good start towards understanding
    the concepts of the Kubernetes resources and consolidating them. After you deploy
    applications in Kubernetes, you can work on its scalable and efficient container
    management, and also fulfill the DevOps delivering procedure of microservices.
  prefs: []
  type: TYPE_NORMAL
- en: An overview of Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with Kubernetes is quite easy, using either a **Command Line Interface**
    (**CLI**) or API (RESTful). This section will describe Kubernetes control by CLI.
    The CLI we use in this chapter is version 1.10.2.
  prefs: []
  type: TYPE_NORMAL
- en: 'After you install Kubernetes master, you can run a `kubectl` command as follows.
    It shows the kubectl and Kubernetes master versions (both the API Server and CLI
    are v1.10.2):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`kubectl` connects the Kubernetes API server using the RESTful API. By default,
    it attempts to access the localhost if `.kube/config` is not configured, otherwise
    you need to specify the API server address using the `--server` parameter. Therefore,
    it is recommended to use `kubectl` on the API server machine for practice.'
  prefs: []
  type: TYPE_NORMAL
- en: If you use kubectl over the network, you need to consider authentication and
    authorization for the API server. See [Chapter 7](d82d7591-b68a-42e7-ae48-5ee5a468975e.xhtml),
    *Building Kubernetes on GCP*.
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl` is the only command for Kubernetes clusters, and it controls the
    Kubernetes cluster manager. Find more information at [http://kubernetes.io/docs/user-guide/kubectl-overview/](http://kubernetes.io/docs/user-guide/kubectl-overview/).
    Any container, or Kubernetes cluster operation, can be performed by a `kubectl`
    command.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition, kubectl allows the inputting of information via either the command
    line's optional arguments or a file (use the `-f` option); it is highly recommended
    to use a file, because you can maintain Kubernetes configuration as code. This
    will be described in detail in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a typical `kubectl` command-line argument:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The attributes of the preceding command are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`command`: Specifies the operation that you want to perform on one or more
    resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`TYPE`: Specifies the resource type. Resource types are case-sensitive and
    you can specify the singular, plural, or abbreviated forms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NAME`: Specifies the name of the resource. Names are case-sensitive. If the
    name is omitted, details for all resources are displayed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`flags`: Specifies optional flags.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, if you want to launch `nginx`, you can use either the `kubectl
    run` command or the `kubectl create -f` command with the YAML file as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `run` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Use the `create -f` command with the YAML file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to see the status of the Deployment, type the `kubectl get` command
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'If you also want the support abbreviation, type the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If you want to delete these resources, type the `kubectl delete` command as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The `kubectl` command supports many kinds of sub-commands; use the `-h` option
    to see the details, for example:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'This section describes how to use the `kubectl` command to control the Kubernetes
    cluster. The following recipes describe how to set up Kubernetes components:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Setting up a Kubernetes cluster on macOS using minikube* and *Set up a Kubernetes
    cluster on Windows** using minikube* in [Chapter 1](4dd5324f-b753-4c80-b891-bd8e6013b2c1.xhtml),
    *Building Your Own Kubernetes Cluster*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Setting up a Kubernetes cluster on Linux using kubeadm* in [Chapter 1](4dd5324f-b753-4c80-b891-bd8e6013b2c1.xhtml),
    *Building Your Own Kubernetes Cluster*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Setting up a Kubernetes cluster on Linux using kubespray (Ansible) *in [Chapter
    1](4dd5324f-b753-4c80-b891-bd8e6013b2c1.xhtml), *Building Your Own Kubernetes Cluster*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linking Pods and containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Pod is a group of one or more containers and the smallest deployable unit
    in Kubernetes. Pods are always co-located and co-scheduled, and run in a shared
    context. Each Pod is isolated by the following Linux namespaces:'
  prefs: []
  type: TYPE_NORMAL
- en: The **process ID** (**PID**) namespace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The network namespace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **interprocess communication** (**IPC**) namespace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **unix time sharing** (**UTS**) namespace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a pre-container world, they would have been executed on the same physical
    or virtual machine.
  prefs: []
  type: TYPE_NORMAL
- en: It is useful to construct your own application stack Pod (for example, web server
    and database) that are mixed by different Docker images.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You must have a Kubernetes cluster and make sure that the Kubernetes node has
    accessibility to the Docker Hub ([https://hub.docker.com](https://hub.docker.com))
    in order to download Docker images.
  prefs: []
  type: TYPE_NORMAL
- en: If you are running minikube, use `minikube ssh` to log on to the minikube VM
    first, then run the `docker pull` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can simulate downloading a Docker image by using the `docker pull` command
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following are the steps to create a Pod has 2 containers:'
  prefs: []
  type: TYPE_NORMAL
- en: Log on to the Kubernetes machine (no need to log on if using minikube) and prepare
    the following YAML file. It defines the launch `nginx` container and the CentOS
    container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The `nginx` container opens the HTTP port (TCP/`80`). On the other hand, the
    CentOS container attempts to access the `localhost:80` every three seconds using
    the `curl` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, execute the `kubectl create` command to launch `my-first-pod` as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: It takes between a few seconds and a few minutes, depending on the network bandwidth
    of the Docker Hub and Kubernetes node's spec.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check `kubectl get pods` to see the status, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now both the nginx container (`my-nginx`) and the CentOS container (`my-centos`)
    are ready.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s check whether the CentOS container can access `nginx` or not. You can
    run the `kubectl exec` command to run bash on the CentOS container, then run the `curl`
    command to access the `nginx`, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the Pod links two different containers, `nginx` and `CentOS`,
    into the same Linux network namespace.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When launching a Pod, the Kubernetes scheduler dispatches to the kubelet process
    to handle all the operations to launch both `nginx` and `CentOS` containers on
    one Kubernetes node.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates these two containers and the Pod; these two
    containers can communicate via the localhost network, because within the Pod containers,
    it share the network interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/17157006-2419-4268-9291-481e14d19121.png)'
  prefs: []
  type: TYPE_IMG
- en: A Pod has two containers, which can communicate via localhost
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have two or more nodes, you can check the `-o wide` option to find a
    node which runs a Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Log in to that node, then you can check the `docker ps | grep my-first-pod` command
    to see the running containers as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/73ca0964-dd98-4df3-b84b-868116a59e25.png)'
  prefs: []
  type: TYPE_IMG
- en: List of containers that belong to my-first-pod
  prefs: []
  type: TYPE_NORMAL
- en: You may notice that `my-first-pod` contains three containers; `centos`, `nginx`,
    and `pause` are running instead of two. Because each Pod we need to keep belongs
    to a particular Linux namespace, if both the CentOS and nginx containers die,
    the namespace will also destroyed. Therefore, the pause container just remains
    in the Pod to maintain Linux namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s launch a second Pod, rename it as `my-second-pod`, and run the `kubectl`
    create command as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you have two Pods; each Pod has two containers, `centos` and `nginx`. So
    a total of four containers are running on your Kubernetes cluster as in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/75affb40-1877-4289-b830-42e63715dad9.png)'
  prefs: []
  type: TYPE_IMG
- en: Duplicate Pod from my-first-pod to my-second-pod
  prefs: []
  type: TYPE_NORMAL
- en: If you would like to deploy more of the same Pod, consider using a Deployment
    (ReplicaSet) instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'After your testing, you can run the `kubectl` delete command to delete your
    Pod from the Kubernetes cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This recipe from this chapter described how to control Pods. They are the basic
    components of Kubernetes operation. The following recipes will describe the advanced
    operation of Pods using Deployments, Services, and so on:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Managing Pods with ReplicaSets*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Deployment API*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with Services *'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with labels and selectors*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing Pods with ReplicaSets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A ReplicaSet is a term for API objects in Kubernetes that refer to Pod replicas.
    The idea is to be able to control a set of Pods'' behaviors. The ReplicaSet ensures
    that the Pods, in the amount of a user-specified number, are running all the time.
    If some Pods in the ReplicaSet crash and terminate, the system will recreate Pods
    with the original configurations on healthy nodes automatically, and keep a certain
    number of processes continuously running. While changing the size of set, users
    can scale the application out or down easily. According to this feature, no matter
    whether you need replicas of Pods or not, you can always rely on ReplicaSet for
    auto-recovery and scalability. In this recipe, you''re going to learn how to manage
    your Pods with ReplicaSet:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/940902c6-7d59-4f0e-81c8-b2cebfc002be.png)'
  prefs: []
  type: TYPE_IMG
- en: ReplicaSet and their Pods on two nodes
  prefs: []
  type: TYPE_NORMAL
- en: 'The ReplicaSet usually handles a tier of applications. As you can see in the
    preceding diagram, we launch a ReplicaSet with three Pod replicas. Some mechanism
    details are listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The **kube-controller-manager** daemon helps to maintain the resource running
    in its desired state. For example, the desired state of ReplicaSet in the diagram
    is three Pod replicas.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **kube-scheduler** daemon on master, the scheduler of Kubernetes, takes
    charge of assigning tasks to healthy nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The selector of the ReplicaSet is used for deciding which Pods it covers. If
    the key-value pairs in the Pod's label include all items in the selector of the
    ReplicaSet, this Pod belongs to this ReplicaSet. As you will see, the diagram
    shows three Pods are under the charge of the ReplicaSet. Even though Pod 2 has
    a different label of `env`, it is selected since the other two labels, `role`
    and `project`, match the ReplicaSet's selector.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ReplicationController? ReplicaSet?** For experienced Kubernetes players,
    you may notice ReplicaSet looks quite similar to the ReplicationController. Since
    version 1.2 of Kubernetes, in order to concentrate on different features, the
    ReplicationController''s functionality has been covered by ReplicaSet and Deployment.
    ReplicaSet focuses on the Pod replica, keeping certain Pods running in healthy
    states. On the other hand, Deployment is a higher-level API, which can manage
    the ReplicaSet, perform application rolling updates, and expose the services.
    In Kubernetes v1.8.3, users can still create replication controllers. However,
    using Deployment with ReplicaSet is more recommended because these are up to date
    and have finer granularity of configuration.'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating a ReplicaSet is the same as creating any Kubernetes resource; we fire
    the `kubectl` command on the Kubernetes master. Therefore, we ensure your Kubernetes
    environment is ready to accept your order. More than that, the Kubernetes node
    should be able to access the Docker Hub. For the demonstration in the following
    few pages, we would take official `nginx` docker image for example, which stores
    in public docker registry as well.
  prefs: []
  type: TYPE_NORMAL
- en: '**The evaluation of a prepared Kubernetes system** You can verify whether your
    Kuberenetes master is a practical one through checking the items here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Check whether the daemons are running or no**t: There should be three working
    daemon processes on the master node: `apiserver`, `scheduler`, and `controller-manager`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Check whether the command kubectl exists and is workable**: Try the command
    `kubectl get cs` to cover this bullet point and the first one. You can verify
    not only the status of components but also the feasibility of `kubectl`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Check whether the nodes are ready to work**: You can check them by using
    the command `kubectl get nodes` to get their status.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the case that some items listed here are invalid, please refer to [Chapter
    1](4dd5324f-b753-4c80-b891-bd8e6013b2c1.xhtml), *Building Your Own Kubernetes
    Cluster,* for proper guidelines based on the installation you chose.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will demonstrate the life cycle of a ReplicaSet from creation
    to destruction.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a ReplicaSet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When trying to use the command line to launch a Kubernetes Service immediately,
    we usually fire `kubectl run`. However, it would creates a Deployment by default,
    and not only taking care of the Pod replica but also providing a container-updating
    mechanism. To simply create a standalone ReplicaSet, we can exploit a configuration
    YAML file and run it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding file is the YAML for our first ReplicaSet. It defines a ReplicaSet
    named `my-first-replicaset`, which has three replicas for its Pods. Labels and
    the selector are the most characteristic settings of ReplicaSet. There are two
    sets of labels: one for ReplicaSet, the other for Pods. The first label for ReplicaSet
    is under the metadata of this resource, right beneath the name, which is simply
    used for description. However, the other label value under the template''s metadata,
    the one for Pods, is also used for identification. ReplicaSet takes charge of
    the Pods which have the labels covered by its selector.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In our example configuration file, the selector of ReplicaSet looks for Pods
    with `project: My-Happy-Web` and `role: frontend` tags. Since we initiate Pods
    under control of this ReplicaSet, the Pods'' labels should definitely include
    what selector cares. You may get following error message while creating a ReplicaSet
    with incorrectly labeled Pods: `` `selector` does not match template `labels`
    ``.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create ReplicaSet through this file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '**The API version of ReplicaSet in Kubernetes v1.9**'
  prefs: []
  type: TYPE_NORMAL
- en: While this book is under construction, Kubernetes v1.9 is released. The API
    version of ReplicaSet turns to a stable version `apps/v1` instead of `apps/v1beta2`.
    If you have an older version Kubernetes, please change the value of `apiVersion` to
    `apps/v1beta2`, or you can just update your Kubernetes system.
  prefs: []
  type: TYPE_NORMAL
- en: Getting the details of a ReplicaSet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After we create the ReplicaSet, the subcommands `get` and `describe` can help
    us to capture its information and the status of Pods. In the CLI of Kubernetes,
    we are able to use the abbreviation rs for resource type, instead of the full
    name ReplicaSet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: This result shows roughly that the Pod replicas of `my-first-replicaset` are
    all running successfully; currently running Pods are of the desired number and
    all of them are ready for serving requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'For detailed information, check by using the subcommand `describe`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that the output lists ReplicaSet''s particulars of the configuration,
    just like what we requested in the YAML file. Furthermore, the logs for the creation
    of Pods are shown as part of ReplicaSet, which confirms that the Pod replicas
    are successfully created and designated with unique names. You can also check
    Pods by name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Changing the configuration of a ReplicaSet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The subcommands known as `edit`, `patch`, and `replace` can help to update live
    Kubernetes resources. All these functionalities change the settings by way of
    modifying a configuration file. Here we just take `edit`, for example.
  prefs: []
  type: TYPE_NORMAL
- en: 'The subcommand edit lets users modify resource configuration through the editor.
    Try to update your ReplicaSet through the command `kubectl edit rs $REPLICASET_NAME`;
    you will access this resource via the default editor with a YAML configuration
    file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In the demonstration, we succeed to add one Pod in the set, yet this is not
    the best practice for auto-scaling the Pod. Take a look at the *Working with configuration
    files* recipe in [Chapter 3](51ca5358-d5fe-4eb2-a52d-65a399617fcf.xhtml), *Playing
    with Containers*,for Reference, and try to change the other values.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting a ReplicaSet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to remove the ReplicaSet from the Kubernetes system, you can rely
    on the subcommand `delete`. When we fire `delete` to remove the resource, it removes
    the target objects forcefully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: We find that the response time is quite short and the effect is also instantaneous.
  prefs: []
  type: TYPE_NORMAL
- en: '**Removing the Pod under ReplicaSet** As we mentioned previously, it is impossible
    to scale down the ReplicaSet by deleting the Pod, because while a Pod is removed,
    the ReplicaSet is out of stable status: if the desired number of Pods is not met,
    and the controller manager will ask ReplicaSet to create another one. The concept
    is shown in the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: You will find that although the `my-first-replicaset-bxf45` Pod is removed,
    the `my-first-replicaset-dvbpg` Pod is created automatically and attached to this
    ReplicaSet.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The ReplicaSet defines a set of Pods by using a Pod template and labels. As
    in the ideas from previous sections, the ReplicaSet only manages the Pods via
    their labels. It is possible that the Pod template and the configuration of the
    Pod are different. This also means that standalone Pods can be added into a set
    by using label modification.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s evaluate this concept of selectors and labels by creating a ReplicaSet
    similar to the diagram at the beginning of this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/dd292c2f-714e-431e-a7f0-c134076653fe.png)'
  prefs: []
  type: TYPE_IMG
- en: The ReplicaSet would cover Pods which have the same labels describing in its
    selector
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we are going to create a CentOS Pod with the labels project: `My-Happy-Web`,
    `role: frontend`, and `env: test`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: After adding this command, a standalone Pod runs with the labels we specified.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, go create your first ReplicaSet example by using the YAML file again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'As in the preceding result, only two Pods are created. It is because the Pod
    `standalone-pod` is considered one of the sets taken by `my-first-replicaset`.
    Remember that `my-first-replicaset` takes care of the Pods labeled with project: `My-Happy-Web`
    and `role:frontend` (ignore the `env `tag). Go check the standalone Pod; you will
    find it belongs to a member of the ReplicaSet as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Similarly, once we delete the set, the standalone Pod will be removed with
    the group:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are multiple Kubernetes resources for Pod management. Users are encouraged
    to leverage various types of resources to meet different purposes. Let''s comparing
    the resource types listed below with ReplicaSet:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Deployment**: In general cases, Kubernetes Deployments are used together
    with ReplicaSet for complete Pod management: container rolling updates, load balancing,
    and service exposing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Job**: Sometimes, we want the Pods run as a job instead of a service. A Kubernetes
    job is suitable for this situation. You can consider it a ReplicaSet with the
    constraint of termination.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DaemonSet**: More than ReplicaSet, the Kubernetes DaemonSet guarantees that
    the specified set is running on every node in the cluster. That said, a subset
    of ReplicaSet on every node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To get more idea and instruction, you can check the recipe *Ensuring flexible
    usage of your containers* in [Chapter 3](51ca5358-d5fe-4eb2-a52d-65a399617fcf.xhtml),
    *Playing with Containers*.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now you understand the idea of ReplicaSet. Continue to look up the following
    recipes in this chapter for more Kubernetes resources, which will allow you to
    explore the magical effects of ReplicaSet:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Deployment API*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with Services*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with labels an selectors*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Moreover, since you have built a simple ReplicaSet by using a configuration
    file, refer to more details about creating your own configuration files for Kubernetes
    resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Working with configuration files* section in [Chapter 3](51ca5358-d5fe-4eb2-a52d-65a399617fcf.xhtml),
    **Playing with Containers**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment API
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Deployment API was introduced in Kubernetes version 1.2\. It is replacing
    the replication controller. The functionalities of rolling-update and rollback
    by replication controller, it was achieved with client side (`kubectl` command
    and `REST API`), that `kubectl` need to keep connect while updating a replication
    controller. On the other hand, Deployments takes care of the process of rolling-update
    and rollback at the server side. Once that request is accepted, the client can
    disconnect immediately.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the Deployments API is designed as a higher-level API to manage ReplicaSet
    objects. This section will explore how to use the Deployments API to manage ReplicaSets.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to create Deployment objects, as usual, use the `kubectl run` command
    or prepare the YAML/JSON file that describe Deployment configuration. This example
    is using the `kubectl run` command to create a `my-nginx` Deployment object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, a Deployment object `my-nginx` creates one `ReplicaSet`, which
    has an identifier: `<Deployment name>-<hex decimal hash>`. And then ReplicaSet
    creates three Pods which have an identifier: `<ReplicaSet id>-<random id>`.'
  prefs: []
  type: TYPE_NORMAL
- en: Until Kubernetes version 1.8, `<Deployment name>-<pod-template-hash value (number)>`
    was used as a ReplicaSet identifier instead of a hex decimal hash.
  prefs: []
  type: TYPE_NORMAL
- en: For more details, look at pull request: [https://github.com/kubernetes/kubernetes/pull/51538](https://github.com/kubernetes/kubernetes/pull/51538).
  prefs: []
  type: TYPE_NORMAL
- en: 'This diagram illustrates the **Deployment**, **ReplicaSet**, and **Pod** relationship:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/48a785dd-5ce1-4a9b-8145-9d8aacdfd6e9.png)'
  prefs: []
  type: TYPE_IMG
- en: Relationship diagram for Deployments, ReplicaSets, and Pods
  prefs: []
  type: TYPE_NORMAL
- en: 'Because of this relationship, if you perform `delete` on a `my-nginx` Deployment
    object, it will also attempt to delete ReplicaSet and Pods respectively:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This example is just a simple `create` and `delete`, that easy to understand
    Deployment object and ReplicaSet object 1:1 relationship at this moment. However,
    a Deployment object can manage many ReplicaSets to preserve as a history. So the
    actual relationship is 1:N, as in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/48c720e2-16f1-473d-aa22-aad05204a347.png)'
  prefs: []
  type: TYPE_IMG
- en: Deployments maintain ReplicaSet history
  prefs: []
  type: TYPE_NORMAL
- en: To understand the 1:N relationship, let's recreate this Deployment object again
    and perform to make some changes to see how Deployment manages ReplicaSet history.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You may run the `kubectl run` command to recreate `my-nginx`, or write a Deployments
    configuration file that produces the same result. This is a great opportunity
    to learn about the Deployment configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: 'This example is an equivalent of `kubectl run my-nginx --image=nginx:1.11.0
    --port=80 --replicas=3`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'These parameters, sorted by key and value, are described here:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Key** | **Value** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `apiVersion` | `apps/v1` | Until Kubernetes v1.8, it had been used apps/v1Beta1,
    v1.8 used apps/v1Beta2, then v1.9 or later use apps/v1 |'
  prefs: []
  type: TYPE_TB
- en: '| `kind` | `deployment` | Indicates that this is a set of Deployment configurations
    |'
  prefs: []
  type: TYPE_TB
- en: '| `metadata.name` | `my-nginx` | Name of Deployment |'
  prefs: []
  type: TYPE_TB
- en: '| `spec.replicas` | `3` | Desire to have three Pods |'
  prefs: []
  type: TYPE_TB
- en: '| `spec.selector.matchLabels` | `run:my-nginx` | Control ReplicaSet/Pods which
    have this label |'
  prefs: []
  type: TYPE_TB
- en: '| `spec.template.metadata.labels` | `run:my-nginx` | Assigns this label when
    creating a ReplicaSet/Pod; it must match `spec.selector.matchLabels` |'
  prefs: []
  type: TYPE_TB
- en: '| `spec.template.spec.containers` | name: `my-nginx`image: `nginx:1.11.0`port:`-
    containerPort:80` | ReplicaSet creates and manages Pods which have:'
  prefs: []
  type: TYPE_NORMAL
- en: name as `my-nginx`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container image as nginx version 1.11.0
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Publish port number `80`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: If you use this YAML file to create a Deployment, use the `kubectl create` command
    instead of `kubectl run`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that, this time, you should also specify `--save-config`, which allows
    you to update the resource using the `kubectl apply` command in the future. In
    addition, specify `--record` which can store the command line history. Those two
    options are not mandatory to manage ReplicaSet history but help you to preserve
    better information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: You can see a property `OldReplicaSets` and  `NewReplicaSet` in the preceding
    code, which are some association between Deployment and ReplicaSet.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever you update a definition of a container template, for example, changing
    the nginx image version from 1.11.0 to 1.12.0, then Deployment `my-nginx` will
    create a new ReplicaSet. Then the property `NewReplicaSet` will point to the new
    ReplicaSet which has nginx version 1.12.0.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, the `OldReplicaSets` property points to an old ReplicaSet
    which has nginx version 1.11.0 until new ReplicaSet is complete to setup new Pod.
  prefs: []
  type: TYPE_NORMAL
- en: These old/new ReplicaSet associations between Deployment, Kubernetes administrator
    can easy to achieve rollback operation in case new ReplicaSet has any issues.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, Deployment can keep preserves the history of ReplicaSet which were
    associated with it before. Therefore, Deployment can anytime to change back (rollback)
    to any point of older ReplicaSet.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As mentioned earlier, let''s bump the nginx image version from 1.11.0 to 1.12.0\.
    There are two ways to change the container image: use the `kubectl set` command,
    or update YAML then use the `kubectl apply` command.'
  prefs: []
  type: TYPE_NORMAL
- en: Using the `kubectl set` command is quicker and there is better visibility when
    using the `--record` option.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, updating YAML and using the `kubectl apply` command is better
    to preserve the entire Deployment YAML configuration file, which is better when
    using a version control system such as `git`.
  prefs: []
  type: TYPE_NORMAL
- en: Using kubectl set to update the container image
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Use the `kubectl set` command allows us to overwrite the `spec.template.spec.containers[].image`
    property that is similar to using the `kubectl run` command to specify the image
    file. The following example specifies `my-nginx` deployment to set the container
    `my-nginx` to change the image to nginx version 1.12.0:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, `OldReplicaSets` becomes the previous `ReplicaSet` (`my-nginx-54bb7bbcf9`)
    and `NewReplicaSet` becomes `my-nginx-77769b7666`. Note that you can see the `OldReplicaSets`
    property until `NewReplicaSet` is ready, so once the new `ReplicaSet` is successfully
    launched, `OldReplicaSet` becomes `<none>`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'If you can see the `ReplicaSet` list by `kubectl get rs`, you can see two ReplicaSet,
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, in the old `ReplicaSet` (`my-nginx-54bb7bbcf9`), the numbers
    of `DESIRED/CURRENT/READY` pods are all zero.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, because the preceding example uses the `--record` option, you
    can see the history of the Deployment `my-nginx` rollout with the `kubectl rollout
    history` command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Updating the YAML and using kubectl apply
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For demo purposes, copy `deploy.yaml` to `deploy_1.12.2.yaml` and change the
    `nginx` version to `1.12.2`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Then run the `kubectl apply` command with the `--record` option:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This will perform the same thing as the `kubectl set` image command, so you
    can see that the nginx image version has been bumped up to `1.12.2`; also, the
    `OldReplicaSets`/`NewReplicaSet` combination has been changed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'After a few moments, `NewReplicaSet` will be ready. Then there will be a total
    of three `ReplicaSets` existing on your system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also see the rollout history:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Whenever you want to revert to a previous `ReplicaSet`, which means rolling
    back to the previous nginx version, you can use `kubectl rollout undo` with the
    `--to-revision` option. For example, if you want to roll back to revision 2 in
    your history (`kubectl set image deployment/my-nginx my-nginx=nginx:1.12.0 --record=true`),
    specify `--to-revision=2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'A few moments later, Deployment will deactivate the current `ReplicaSet`, which
    uses the Pod template with `nginx` version `1.12.2`, and will then activate the `ReplicaSet`
    which uses `nginx` version `1.12`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, you learned about the concept of Deployment. It is an important
    core feature in Kubernetes ReplicaSet life cycle management. It allows us to achieve
    rollout and rollback functionalities, and can integrate to CI/CD. In the following
    chapter you will see detailed operations of rollout and rollback:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Updating live containers* section in [Chapter 3](51ca5358-d5fe-4eb2-a52d-65a399617fcf.xhtml),
    *Playing with Containers*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Setting up a continuous delivery pipeline *section in [Chapter 5](669edaf0-c274-48fa-81d8-61150fa36df5.xhtml),
    *Building Continuous Delivery Pipelines*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The network service is an application that receives requests and provides a
    solution. Clients access the service by a network connection. They don''t have
    to know the architecture of the service or how it runs. The only thing that clients
    have to verify is whether the endpoint of the service can be accessed, and then
    follow its usage policy to get the response of the server. The Kubernetes Service
    has similar ideas. It is not necessary to understand every Pod before reaching
    their functionalities. For components outside the Kubernetes system, they just
    access the Kubernetes Service with an exposed network port to communicate with
    running Pods. It is not necessary to be aware of the containers'' IPs and ports.
    Behind Kubernetes Services, we can fulfill a zero-downtime update for our container
    programs without struggling:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/feaa67cf-b59c-43b1-87f2-5e0647c966ed.png)'
  prefs: []
  type: TYPE_IMG
- en: Kubernetes Service-covered Pods by labels of Pods and their selectors
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding diagram shows the basic structure of the **Service** and realizes
    the following concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: As with the **D****eployment**, the **Service** directs requests to Pods that
    have labels containing the Service's selector. In other words, the Pods selected
    by the **Service** are based on their labels.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The load of requests sent to the Services will distribute to three Pods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Deployment**, along with ReplicaSet, ensures that the number of running
    Pods meets its desired state. It monitors the Pods for the **Service**, making
    sure they will be healthy for taking over duties from the **Service**.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service** is an abstraction layer for grouping Pods, which allows for Pods
    scaling across nodes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this recipe, you will learn how to create Services in front of your Pods
    for the requests.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Prior to applying Kubernetes Services, it is important to verify whether all
    nodes in the system are running `kube-proxy`. The daemon `kube-proxy` works as
    a network proxy in a node. It helps to reflect Service settings, such as IPs or
    ports on each node, and to do network forwarding. To check if `kube-proxy` is
    running or not, we take a look at network connections:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Once you see the output, the process ID `2326`, `kube-proxy`, listening on port
    `10249` on localhost, the node is ready for Kubernetes Services. Go ahead and
    verify whether all of your nodes in the Kubernetes cluster having `kube-proxy`
    running on them.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As mentioned in the previous section, the Kubernetes Service exposes Pods by
    selecting them through corresponding labels. However, there is another configuration
    we have to take care of: the network port. As the following diagram indicates,
    the Service and Pod have their own key-value pair labels and ports:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/28ed7767-9dc7-4b82-9de3-3a6f99d969d0.png)'
  prefs: []
  type: TYPE_IMG
- en: Network port mapping between Service and Pod
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, setting the selector of Service and binding the service exposed port
    to the container port are required to be carried out while creating Services.
    If either of them fail to be set properly, clients won't get responses or will
    get connection-refused errors.
  prefs: []
  type: TYPE_NORMAL
- en: We can define and create a new Kubernetes Service through the CLI or a configuration
    file. Here, we are going to explain how to deploy the Services by command. The
    subcommands `expose` and `describe` are utilized in the following commands for
    various scenarios. For file-format creation, it is recommended to read the *Working
    with configuration files* recipe in [Chapter 3](51ca5358-d5fe-4eb2-a52d-65a399617fcf.xhtml),
    *Playing with Containers*, for a detailed discussion.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Service for different resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can attach a Service to a Pod, a Deployment, an endpoint outside the Kubernetes
    system, or even another Service. We will show you these, one by one, in this section.
    The creation of the Kubernetes Service looks similar to these command formats:
    `kubectl expose $RESOURCE_TYPE $RESOURCE_NAME [OTHER TAGS]` or `kubectl expose
    -f $CONFIG_FILE`. The resource types (Pod, Deployment, and Service) are supported
    by the subcommand `expose`. So is the configuration file, which follows the limitation type.
    Accordingly, for a later demonstration we will attach the newly created Service
    to the endpoint by the configuration file.'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Service for a Pod
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes Pods covered by Service require labels, so that Service can recognize
    who is the one it should take charge of. In the following commands, we create
    a Pod with labels first, and attach a Service on it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'You may find that, based on the preceding command, we did not assign any selector
    to this Service. Nonetheless, since Service `nginx-service` takes the port forwarding
    task of Pod `nginx-pod`, it will take the labels of the Pod as its selector. Go ahead
    and check the details of the Service with the subcommand `describe`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: Now you can see that, for guaranteeing the responsibility, this successfully
    exposed Service just copied the labels of the Pod as its selector. The value list
    after `Endpoints` was the IP of the Pod and its exposed port `80`. Furthermore,
    the Service took the Pod's labels as its own. According to this example, the Pod
    can be accessed through Service by surfing `10.96.107.213:8080`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Except for the selector of Service, some parameters can be automatically configured
    if they are bypassed by users. One parameter is the labels of the Pod; another
    is the name of the Service; and the other is the exposed port of the Service.
    Let''s take a look at how this simple set of Pod and Service can be managed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that the Service inherited the name, label, and port from
    the Pod. The selector was assigned the dummy label with the key named `run` and
    the value named as Pod''s name, which is just the same dummy one of Pod `nginx-no-label`.
    Users should access the Service through port `80`, as well. For such simple settings,
    you can alternatively try the following command to create the Pods and Service
    at the same time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Creating a Service for a Deployment with an external IP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes Deployment is the ideal resource type for a Service. For Pods supervised
    by the ReplicaSet and Deployment, the Kubernetes system has a controller manager
    to look over the their life cycles. It is also helpful for updating the version
    or state of the program by binding the existing Services to another Deployment.
    For the following commands, we create a Deployment first, and attach a Service
    with an external IP:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s go ahead and check the details of the newly created Service, `another-nginx-service`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'Apart from the Service IP (in the case of the preceding command, `10.100.109.230`),
    which can be accessed within the Kubernetes system, the Service can now be connected
    through an external one (`192.168.122.102`, for example) beyond the Kubernetes
    system. While the Kubernetes master is able to communicate with every node, in
    this case, we can fire a request to the Service such as the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: Creating a Service for an Endpoint without a selector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, we are going to create an Endpoint directing the external service. A
    Kubernetes Endpoint is an abstraction, making components beyond Kubernetes (for
    instance, a database in other system) become a part of Kubernetes resources. It
    provides a feasible use case for a hybrid environment. To create an endpoint,
    an IP address, along with a port, is required. Please take a look at the following
    template:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The template defines an Endpoint named `k8s-ep`, which points to the IP of
    the host of the official Kubernetes website ([https://kubernetes.io](https://kubernetes.io)).
    Never mind that this Endpoint forwards to a plain HTML; we just take this Endpoint
    as an example. As mentioned, Endpoint is not a resource supported by the Kubernetes
    API for exposing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: In Kubernetes, an Endpoint not only represents an external service; an internal
    Kubernetes Service is also a Kubernetes Endpoint. You can check Endpoint resources
    with the command `kubectl get endpoints`. You will find that there is not a single
    endpoint `k8s-ep` (which you just created), but many endpoints named the same
    as the Services in previous pages. When a Service is created with a selector and
    exposes certain resources (such as a Pod, Deployment, or other Service), a corresponding
    Endpoint with the same name is created at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: 'Therefore, we still can create a Service associated with the Endpoint using
    an identical name, as in the following template:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'The relationship between the Endpoints and the Service is built up with the
    resource name. For the Service `k8s-ep`, we didn''t indicate the selector, since
    it did not actually take any Pod in responsibility:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'Now you can see that the endpoint of the Service is just the one defined in
    `k8s-endpoint.yaml`. It is good for us to access the outside world through the
    Kubernetes Service! In the case earlier, we can verify the result with the following
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: Creating a Service for another Service with session affinity
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While building a Service over another, we may think of multiple layers for
    port forwarding. In spite of redirecting traffic from one port to another, the
    action of exposing a Service is actually copying the setting of one Service to
    another. This scenario could be utilized as updating the Service setting, without
    causing headaches to current clients and servers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Here we are! We successfully exposed another Service with similar settings
    to the Service `another-nginx-service`. The commands and output can be summarized
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A new Service name is required**: Although we can copy the configurations
    from another Service, the name of the resource type should always be unique. When
    exposing a Service without the tag `--name`, you will get the error message: `Error
    from server (AlreadyExists): services "another-nginx-service" already exists`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Adding or updating the configuration is workable**: We are able to add a
    new configuration, like adding session affinity; or we can update the port of
    the Service, like here, where we change to open port `8081` instead of `8080`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Avoid changing target port**: Because the target port is along with the IP
    of the Pods, once the Service exposing changes the target port, the newly copied
    Service cannot forward traffic to the same endpoints. In the preceding example,
    since the new target port is defined, we should point out the container port again.
    It prevented the new Service from using the target port as the container port
    and turned out a misleading transaction.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With session affinity, the list of description tags session affinity as `ClientIP`.
    For the current Kubernetes version, the client IP is the only option for session
    affinity. It takes the action as a hash function: with the same IP address, the
    request will always send to the identical Pod. However, this could be a problem
    if there is a load balancer or ingress controller in front of the Kubernetes Service:
    the requests would be considered to come from the same source, and the traffic
    forwarded to a single Pod. Users have to handle this issue on their own, for example,
    by building an HA proxy server instead of using the Kubernetes Service.'
  prefs: []
  type: TYPE_NORMAL
- en: Deleting a Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you go through every command in this section, there are definitely some
    demonstrated Kubernetes Services (we counted six of them) that should be removed.
    To delete a Service, the same as with any other Kubernetes resource, you can remove
    the Service with the name or the configuration file through the subcommand `delete`.
    When you try to remove the Service and the Endpoint at the same time, the following
    situation will happen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: This is because a Service is also a Kubernetes Endpoint. That's why, although
    we created the Service and the endpoint separately, once they are considered to
    work as a unit, the Endpoint is going to be removed when the Service is removed.
    Thus, the error message expresses that there is no endpoint called `k8s-ep`, since
    it was already removed with the Service deletion.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: On the network protocol stack, the Kubernetes Service relies on the transport
    layer, working together with the **overlay network** and `kube-proxy`. The overlay
    network of Kubernetes builds up a cluster network by allocating a subnet lease
    out of a pre-configured address space and storing the network configuration in
    `etcd`; on the other hand, `kube-proxy` helps to forward traffic from the endpoints
    of Services to the Pods through `iptables` settings.
  prefs: []
  type: TYPE_NORMAL
- en: '**Proxy-mode and Service **`kube-proxy`  currently has three modes with different
    implementation methods: `userspace`, `iptables`, and `ipvs`. The modes affect
    how the requests of clients reach to certain Pods through the Kubernete Service:'
  prefs: []
  type: TYPE_NORMAL
- en: '`userspace`: `kube-proxy` opens a random port, called a proxy port, for each
    Service on the local node, then updates the `iptables` rules, which capture any
    request sent to the Service and forward it to the proxy port. In the end, any
    message sent to the proxy port will be passed to the Pods covered by the Service.
    It is less efficient, since the traffic is required to go to `kube-proxy` for
    routing to the Pod.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`iptables`: As with the `userspace` mode, there are also required `iptables`
    rules for redirecting the client traffic. But there is no proxy port as mediator.
    Faster but need to take care the liveness of Pod. By default, there is no way
    for a request to retry another Pod if the target one fails. To avoid accessing
    the unhealthy Pod, health-checking Pods and updating `iptables` in time is necessary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ipvs`: `ipvs` is the beta feature in Kubernetes v1.9\. In this mode, `kube-proxy`
    builds up the interface called netlink between the Service and its backend set.
    The `ipvs` mode takes care of the downside in both `userspace` and `iptables`;
    it is even faster, since the routing rules stored a hash table structure in the
    kernel space, and even reliable that `kube-proxy` keeps checking the consistency
    of `netlinks`. `ipvs` even provides multiple load balancing options.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The system picks the optimal and stable one as the default setting for `kube-proxy`.
    Currently, it is the mode `iptables`.
  prefs: []
  type: TYPE_NORMAL
- en: 'When a Pod tries to communicate with a Service, it can find the Service through
    environment variables or a DNS host lookup. Let''s give it a try in the following
    scenario of accessing a service in a Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'You will find that the Pod `my-2nd-centos` comes out with additional variables
    showing information for the Service `my-nginx-service`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'This is because the system failed to do a real-time update for Services; only
    the Pods created subsequently can be applied to accessing the Service through
    environment variables. With this ordering-dependent constraint, pay attention
    to running your Kubernetes resources in a proper sequence if they have to interact
    with each other in this way. The keys of the environment variables representing
    the Service host are formed as `<SERVICE NAME>_SERVICE_HOST`, and the Service
    port is like `<SERVICE NAME>_SERVICE_PORT`. In the preceding example, the dash
    in the name is also transferred to the underscore:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Nevertheless, if the `kube-dns` add-on is installed, which is a DNS server
    in the Kubernetes system, any Pod in the same Namespace can access the Service,
    no matter when the Service was created. The hostname of the Service would be formed
    as `<SERVICE NAME>.<NAMESPACE>.svc.cluster.local`. `cluster.local` is the default
    cluster domain defined in booting `kube-dns`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The Kubernetes Service has four types: `ClusterIP`, `NodePort`, `LoadBalancer`,
    and `ExternalName`. In the *How to do it...* section in this recipe, we only demonstrate
    the default type, `ClusterIP`. The type `ClusterIP` indicates that the Kubernetes
    Service is assigned a unique virtual IP in the overlay network, which also means
    the identity in this Kubernetes cluster. `ClusterIP` guarantees that the Service
    is accessible internally.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram expresses the availability coverage of the types, and
    their entry points:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/516627fc-54d3-4283-ba0f-70d54d0d7978.png)'
  prefs: []
  type: TYPE_IMG
- en: Four Service types and their entry points
  prefs: []
  type: TYPE_NORMAL
- en: For the `NodePort` type, it covers the `ClusterIP`'s features, has a peer-accessible
    virtual IP, and also allows the user to expose Services on each node with the
    same port. The type `LoadBalancer` is on the top of the other two types. The `LoadBalancer`
    Service would be exposed internally and on the node. More than that, if your cloud
    provider supports external load balancing servers, you can bind the load balancer
    IP to the Service, and this will become another exposing point. On the other hand,
    the type `ExternalName` is used for the endpoint out of your Kubernetes system.
    It is similar to the Endpoint we created with the configuration file in a previous
    section; moreover, a single `ExternalName` Service can provide this feature.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the subcommand `create` to create Services in different types:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example of the `NodePort` Service, you can see that it still has the
    virtual IP (`10.105.106.134`) in the cluster, and can be accessed through port
    `31336` of any Kubernetes node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 'In the case here, we demonstrate creating an `ExternalName` Service which exposes
    the `CNAME kubernetes.io`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: Yet, we cannot build an `ExternalName` Service in CLI with the subcommand `expose`,
    because `expose` works on exposing the Kubernetes resources, while the `ExternalName` Service
    is for the resources in the outside world. Then, it is also reasonable that the
    `ExternalName` Service doesn't need to be defined with the selector.
  prefs: []
  type: TYPE_NORMAL
- en: '**Using the subcommand "create" to create Services** While using the subcommand
    `create` on Service creation, the command line would look like this: `kubectl
    create service <SERVICE TYPE> <SERVICE NAME> [OPTIONS]`. And we can put the Service
    types at `<SERVICE TYPE>`, such as `clusterip`, `nodeport`, `loadbalancer`, and
    `externalname`. With this method, we cannot specify the selector of the Service.
    As with the `NodePort` Service we created in that section, only a default selector, `app:
    my-nginx`, is created, and we have to assign this label to a later created Deployment
    `test-nodeport`. Except for the type `ExternalName`, Service types can be created
    with the subcommand `expose` with the tag `type`. Try to create the `NodePort` service
    with `kubectl expose` for existing resources!'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To get the best practices of Kubernetes Services, the following recipes in
    [Chapter 2](e9a51674-078b-4ffc-a76c-98774150bfa3.xhtml), *Walking though Kubernetes
    Concepts*, are suggested reading:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Deployment API*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with Secrets*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with labels and selectors*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There is more advanced knowledge to make your service more functional and flexible.
    Stay tuned:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Forwarding container ports* section in [Chapter 3](51ca5358-d5fe-4eb2-a52d-65a399617fcf.xhtml),
    *Playing with Containers*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Ensuring flexible usage of your containers* section in [Chapter 3](51ca5358-d5fe-4eb2-a52d-65a399617fcf.xhtml),
    *Playing with Containers*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with volumes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Files in a container are ephemeral. When the container is terminated, the files
    are gone. Docker has introduced data volumes to help us persist data ([https://docs.docker.com/engine/admin/volumes/volumes](https://docs.docker.com/engine/admin/volumes/volumes)).
    However, when it comes to multiple hosts, as a container cluster, it is hard to
    manage volumes across all the containers and hosts for file sharing or provisioning
    volume dynamically. Kubernetes introduces volume, which lives with a Pod across
    a container life cycle. It supports various types of volumes, including popular
    network disk solutions and storage services in different public clouds. Here are
    a few:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Volume type** | **Storage provider** |'
  prefs: []
  type: TYPE_TB
- en: '| `emptyDir` | Localhost |'
  prefs: []
  type: TYPE_TB
- en: '| `hostPath` | Localhost |'
  prefs: []
  type: TYPE_TB
- en: '| `glusterfs` | GlusterFS cluster |'
  prefs: []
  type: TYPE_TB
- en: '| `downwardAPI` | Kubernetes Pod information |'
  prefs: []
  type: TYPE_TB
- en: '| `nfs` | NFS server |'
  prefs: []
  type: TYPE_TB
- en: '| `awsElasticBlockStore` | Amazon Web Service Amazon Elastic Block Store |'
  prefs: []
  type: TYPE_TB
- en: '| `gcePersistentDisk` | Google Compute Engine persistent disk |'
  prefs: []
  type: TYPE_TB
- en: '| `azureDisk` | Azure disk storage |'
  prefs: []
  type: TYPE_TB
- en: '| `projected` | Kubernetes resources; currently supports `secret`, `downwardAPI`,
    and `configMap` |'
  prefs: []
  type: TYPE_TB
- en: '| `secret` | Kubernetes Secret resource |'
  prefs: []
  type: TYPE_TB
- en: '| `vSphereVolume` | vSphere VMDK volume |'
  prefs: []
  type: TYPE_TB
- en: '| `gitRepo` | Git repository |'
  prefs: []
  type: TYPE_TB
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Storage providers are required when you start to use volume in Kubernetes, except
    for `emptyDir`, which will be erased when the Pod is removed. For other storage
    providers, folders, servers, or clusters have to be built before using them in
    the Pod definition. Dynamic provisioning was promoted to stable in Kubernetes
    version 1.6, which allows you to provision storage based on the supported cloud
    provider.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we'll walk through the details of `emptyDir`, `hostPath`, `nfs`,
    `glusterfs`, `downwardAPI`, and `gitRepo`. `Secret`, which is used to store credentials,
    will be introduced in the next section. `Projected`, on the other hand, is a way
    one could group other volume resources under one single mount point. As it only
    supports `secret`, `downwardAPI`, and `configMap`, we'll be introducing this in
    the Secret section, as well. The rest of the volume types have similar Kubernetes
    syntax, just with different backend volume implementations.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Volumes are defined in the volumes section of the pod definition with unique
    names. Each type of volume has a different configuration to be set. Once you define
    the volumes, you can mount them in the `volumeMounts` section in the container
    specs. `volumeMounts.name` and `volumeMounts.mountPath` are required, which indicate
    the name of the volumes you defined and the mount path inside the container, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: We'll use the Kubernetes configuration file with the YAML format to create a
    Pod with volumes in the following examples.
  prefs: []
  type: TYPE_NORMAL
- en: emptyDir
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`emptyDir` is the simplest volume type, which will create an empty volume for
    containers in the same Pod to share. When the Pod is removed, the files in `emptyDir`
    will be erased, as well. `emptyDir` is created when a Pod is created. In the following
    configuration file, we''ll create a Pod running Ubuntu with commands to sleep
    for `3600` seconds. As you can see, one volume is defined in the volumes section
    with name data, and the volumes will be mounted under the `/data-mount` path in
    the Ubuntu container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: '**Check which node the Pod is running on** By using the `kubectl describe pod
    <Pod name> | grep Node` command, you can check which node the Pod is running on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'After the Pod is running, you can use `docker inspect <container ID>` on the
    target node and you can see the detailed mount points inside your container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: Kubernetes mounts `/var/lib/kubelet/pods/<id>/volumes/kubernetes.io~empty-dir/<volumeMount
    name>` to `/data-mount` for the Pod to use. If you create a Pod with more than
    one container, all of them will mount the same destination `/data-mount` with
    the same source. The default mount propagation is `rprivate`, which means any
    mount points on the host are invisible in the container, and vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: '`emptyDir` could be mounted as `tmpfs` by setting `emptyDir.medium` as `Memory`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Taking the previous configuration file `2-6-1_emptyDir_mem.yaml` as an example,
    it would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'We could verify whether it''s successfully mounted with the `kubectl exec <pod_name>
    <commands>` command. We''ll run the `df` command in this container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: Note that `tmpfs` is stored in memory instead of in the filesystem. No file
    will be created, and it'll be flushed in every reboot. In addition, it is constrained
    by memory limits in Kubernetes. For more information about container resource
    constraint, refer to *Working with Namespace* in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: If you have more than one container inside a Pod, the `Kubectl exec` command
    will be `kubectl exec <pod_name> <container_name> <commands>`.
  prefs: []
  type: TYPE_NORMAL
- en: hostPath
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`hostPath` acts as data volume in Docker. The local folder on a node listed
    in `hostPath` will be mounted into the Pod. Since the Pod can run on any nodes,
    read/write functions happening in the volume could explicitly exist in the node
    on which the Pod is running. In Kubernetes, however, the Pod should not be node-aware.
    Please note that the configuration and files might be different on different nodes
    when using `hostPath`. Therefore, the same Pod, created by the same command or
    configuration file, might act differently on different nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'By using `hostPath`, you''re able to read and write the files between containers
    and localhost disks of nodes. What we need for volume definition is for `hostPath.path`
    to specify the target mounted folder on the node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'Using `docker inspect` to check the volume details, you will see the volume
    on the host is mounted in the `/data-mount` destination:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: If we run `kubectl exec ubuntu touch /data-mount/sample`, we should be able
    to see one empty file, named `sample under /tmp/data`, on the host.
  prefs: []
  type: TYPE_NORMAL
- en: NFS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can mount an **network filesystem** (**NFS**) to your Pod as `nfs volume`.
    Multiple Pods can mount and share the files in the same `nfs volume`. The data
    stored into `nfs volume` will be persistent across the Pod lifetime. You have
    to create your own NFS server before using `nfs volume`, and make sure the `nfs-utils`
    package is installed on Kubernetes minions.
  prefs: []
  type: TYPE_NORMAL
- en: Check whether your NFS server works before you go. You should check out the `/etc/exports`
    file with a proper sharing parameter and directory, and use the `mount -t nfs
    <nfs server>:<share name> <local mounted point>` command to check whether it could
    be mounted locally.
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration file of the volume type with NFS is similar to others, but
    `nfs.server` and `nfs.path` are required in the volume definition to specify NFS
    server information and the path mounted from. `nfs.readOnly` is an optional field
    for specifying whether the volume is read-only or not (the default is `false`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 'After you run `kubectl create –f 2-6-3_nfs.yaml`, you can describe your Pod
    with `kubectl describe <pod name>` to check the mounting status. If it''s mounted
    successfully, it should show conditions. Ready as true and the target `nfs` you
    mount:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: 'If we inspect the container with the `docker` command, we can see the volume
    information in the `Mounts` section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: Actually, Kubernetes just mounts your `<nfs server>:<share name>` into `/var/lib/kubelet/pods/<id>/volumes/kubernetes.io~nfs/nfs`,
    and then mounts it into the container as the destination in `/data-mount`. You
    could also use `kubectl exec` to touch the file, to test whether it's perfectly
    mounted.
  prefs: []
  type: TYPE_NORMAL
- en: glusterfs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GlusterFS ([https://www.gluster.org](https://www.gluster.org)) is a scalable,
    network-attached storage filesystem. The `glusterfs` volume type allows you to
    mount GlusterFS volume into your Pod. Just like NFS volume, the data in `glusterfs`
    volume is persistent across the Pod lifetime. If the Pod is terminated, the data
    is still accessible in `glusterfs` volume. You should build the GlusterFS system
    before using `glusterfs` volume.
  prefs: []
  type: TYPE_NORMAL
- en: Check whether `glusterfs` works before you go. By using `glusterfs` volume information
    on GlusterFS servers, you can see currently available volumes. By using `mount
    -t glusterfs <glusterfs server>:/<volume name> <local mounted point>` on local,
    you can check whether the GlusterFS system can be successfully mounted.
  prefs: []
  type: TYPE_NORMAL
- en: Since the volume replica in GlusterFS must be greater than `1`, let's assume
    we have two replicas in the servers `gfs1` and `gfs2`, and the volume name is
    `gvol`.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we need to create an endpoint acting as a bridge for `gfs1` and `gfs2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can use `kubectl get endpoints` to check the endpoint was created
    properly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we should be able to create the Pod with `glusterfs` volume by
    `glusterfs.yaml`. The parameters of the `glusterfs` volume definition are `glusterfs.endpoints`,
    which specify the endpoint name we just created, and `glusterfs.path`, which is
    the volume name `gvol`. `glusterfs.readOnly` is used to set whether the volume
    is mounted in read-only mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check the volume setting with `kubectl describle`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: Using `docker inspect`, you should be able to see that the mounted source is
    `/var/lib/kubelet/pods/<id>/volumes/kubernetes.io~glusterfs/data` to the destination
    `/data-mount`.
  prefs: []
  type: TYPE_NORMAL
- en: downwardAPI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`downwardAPI` volume is used to expose Pod information into a container. The
    definition of `downwardAPI` is a list of items. An item contains a path and `fieldRef`.
    Kubernetes will dump the specified metadata listed in `fieldRef` to a file named
    `path` under `mountPath` and mount the `<volume name>` into the destination you
    specified. Currently supported metadata for `downwardAPI` volume includes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Field path** | **Scope** | **Definition** |'
  prefs: []
  type: TYPE_TB
- en: '| `spec.nodeName` | Pod | The node that the Pod is running on |'
  prefs: []
  type: TYPE_TB
- en: '| `spec.serviceAccountName` | Pod | The service account associating with the
    current Pod |'
  prefs: []
  type: TYPE_TB
- en: '| `metadata.name` | Pod | The name of the Pod |'
  prefs: []
  type: TYPE_TB
- en: '| `metadata.namespace` | Pod | The Namespace that the Pod belongs to |'
  prefs: []
  type: TYPE_TB
- en: '| `metadata.annotations` | Pod | The annotations of the Pod |'
  prefs: []
  type: TYPE_TB
- en: '| `metadata.labels` | Pod | The labels of the Pod |'
  prefs: []
  type: TYPE_TB
- en: '| `status.podIP` | Pod | The ip of the Pod |'
  prefs: []
  type: TYPE_TB
- en: '| `limits.cpu` | Container | The CPU limits of the container |'
  prefs: []
  type: TYPE_TB
- en: '| `requests.cpu` | Container | The CPU requests of the container |'
  prefs: []
  type: TYPE_TB
- en: '| `limits.memory` | Container | The memory limits of the container |'
  prefs: []
  type: TYPE_TB
- en: '| `requests.memory` | Container | The memory requests of the container |'
  prefs: []
  type: TYPE_TB
- en: '| `limits.ephemeral-storage` | Container | The ephemeral storage limits of
    the container |'
  prefs: []
  type: TYPE_TB
- en: '| `requests.ephemeral-storage` | Container | The ephemeral storage requests
    of the container |'
  prefs: []
  type: TYPE_TB
- en: 'We use `fieldRef.fieldPath` if the scope is with a Pod; `resourceFieldRef`
    is used when the scope is with a container. For example, the following configuration
    file could expose `metadata.labels` in `/data-mount` volume in an Ubuntu container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: 'By describing the `pod`, we could check that the volume is mounted successfully
    to `/data-mount`, and `metadata.labels` is pointed to the `metadata` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: We could check the file inside the container with `kubectl exec downwardapi
    cat /data-mount/metadata`, and you should be able to see `env="example" presents`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If it''s in the container scope, we''ll have to specify the container name:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: 'We could use the `docker inspect <container_name>` command inside a node to
    check the implementation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: Kubernetes exposes `pod` information in source volume, and mounts it to `/data-mount`.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the IP of the Pod, using environment variable to propagate in Pod spec
    would be must easier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: The sample folder in the Kubernetes GitHub ([https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information](https://kubernetes.io/docs/tasks/inject-data-application/downward-api-volume-expose-pod-information))
    contains more examples for both environment variables and `downwardAPI` volume.
  prefs: []
  type: TYPE_NORMAL
- en: gitRepo
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`gitRepo` is a convenient volume type that clones your existing Git repository
    into a container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, the volume plugin mounts an empty directory and runs
    the git clone `<gitRepo.repolist>` to clone the repository into it. Then the Ubuntu
    container will be able to access it.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous cases, the user needs to know the details of the storage provider.
    Kubernetes provides `PersistentVolumes` and `PersistentVolumeClaim` to abstract
    the details of the storage provider and storage consumer.
  prefs: []
  type: TYPE_NORMAL
- en: PersistentVolumes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An illustration of `PersistentVolume` is shown in the following graph. First,
    the administrator provisions the specification of a `PersistentVolume`. Then the
    consumer requests for storage with `PersistentVolumeClaim`. Finally, the Pod mounts
    the volume with the reference of `PersistentVolumeClaim`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f65303f4-59e5-4814-a38b-d6a38bd7977b.png)'
  prefs: []
  type: TYPE_IMG
- en: PersistentVolumeClaims is an abstract layer to decouple volumes for a Pod and
    physical volume resource
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example using `NFS`. The administrator needs to provision and allocate
    `PersistentVolume` first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that there are three parameters here: `capacity`, `accessModes`,
    and `persistentVolumeReclaimPolicy`. `capacity` is the size of this `PersistentVolume`.
    Now, `accessModes` is based on the capability of the storage provider and can
    be set to a specific mode during provision. For example, NFS supports multiple
    readers and writers simultaneously—then we can specify the `accessModes` as one
    of `ReadWriteOnce`, `ReadOnlyMany`, or `ReadWriteMany`. Now, `persistentVolumeReclaimPolicy`
    is used to define the behavior when `PersistentVolume` is released. The currently
    supported policy is retain and recycle for `nfs` and `hostPath`. You have to clean
    the volume by yourself in retain mode; on the other hand, Kubernetes will scrub
    the volume in recycle mode.'
  prefs: []
  type: TYPE_NORMAL
- en: 'PV is a resource like a node. We could use `kubectl get pv` to see current
    provisioned PVs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will need to bind `PersistentVolume` with `PersistentVolumeClaim`
    in order to mount it as volume into the `pod`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: The constraints of `accessModes` and storage can be set in `PersistentVolumeClaim`.
    If the claim is bound successfully, its status will turn to `Bound`; on the other
    hand, if the status is `Unbound`, it means there is no PV currently matching the
    requests.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then we are able to mount the PV as volume with the reference of `PersistentVolumeClaim`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'It will be similar syntax to other volume types. Just add the `claimName` of
    `persistentVolumeClaim` in the volume definition. We are all set! Let''s check
    the details to see whether we mounted it successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see we have a volume mounted in the Pod `nginx` with the type `pv pvclaim01`.
    Use `docker inspect` to see how it is mounted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: Kubernetes mounts `/var/lib/kubelet/pods/<id>/volumes/kubernetes.io~nfs/< persistentvolume
    name>` into the destination in the Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Using storage classes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In the cloud world, people provision storage or data volume dynamically. While
    `PersistentVolumeClaim` is based on existing static `PersistentVolume` that is
    provisioned by administrators, it might be really beneficial if the cloud volume
    could be requested dynamically when it needs to be. Storage classes are designed
    to resolve this problem. To make storage classes available in your cluster, three
    conditions need to be met. First, the `DefaultStorageClass` admission controller
    has to be enabled (refer to [Chapter 7](d82d7591-b68a-42e7-ae48-5ee5a468975e.xhtml),
    *Building Kubernetes on GCP*). Then `PersistentVolumeClaim` needs to request a
    storage class. The last condition is trivial; administrators have to configure
    a storage class in order to make dynamic provisioning work:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/23a069b1-0d06-4c86-8762-e3fe472a7a87.png)'
  prefs: []
  type: TYPE_IMG
- en: StorageClass dynamically allocates a PV and associates it with a PVC
  prefs: []
  type: TYPE_NORMAL
- en: The default storage classes are various, basically based on your underlying
    cloud provider. Storage classes are the abstract way to define underlying storage
    providers. They have different syntax based on different types of providers. Default
    storage classes can be changed, but cannot be deleted. The default storage class
    has an annotation `storageclass.beta.kubernetes.io/is-default-class=true` on.
    Removing that annotation can disable the dynamic provisioning. Moving the annotation
    to another storage class can switch the default storage class. If no storage classes
    have that annotation, dynamic provisioning will not be triggered when there is
    a new `PersistentVolumeClaim`.
  prefs: []
  type: TYPE_NORMAL
- en: gcePersistentDisk
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`gcePersistentDisk` volume mounts a **Google Compute Engine** (**GCE**) **Persistent
    Disk** (**PD**) into a Pod. If you provision it statically, you''ll have to create
    it first with the `gcloud` command or in the GCE console. The following is an
    example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE90]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, and more cost-effectively, we could use dynamic provisioning.
    Then we don''t need to provision PD beforehand. For enabling dynamic provisioning,
    the `DefaultStorageClass` admission controller has to be enabled on the API server.
    In some Kubernetes environments, it has been enabled by default, such as in GCE.
    We could explicitly disable it by setting the `storageClassName: "" in Pod/Deployment/ReplicaSet`
    configuration file.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we''ll introduce how to create a non-default `StorageClass`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE91]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see we have a default storage class named `standard`. If that''s the
    desired provider, then you don''t need to create your own storage classes. In
    the following example, we''ll create a new storage class named `example`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE92]'
  prefs: []
  type: TYPE_PRE
- en: 'For the type, you can specify any storage type that GCE supports, such as `pd-ssd`.
    You can specify zones by changing zone parameters, too. Next, we''ll add a `PersistentVolumeClaim`
    for using this storage class:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE93]'
  prefs: []
  type: TYPE_PRE
- en: 'This configuration file will create a PVC by specifying the storage class named
    `example`. A PV will be created by the claim. When a PVC is in `Bound` status,
    Kubernetes will always bind that PV to the matching PVC. Then, let''s have a Pod
    using this PVC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE94]'
  prefs: []
  type: TYPE_PRE
- en: We can see that `gce-pd` is mounted under `/mount-path`. Let's see if the volume
    has been provisioned dynamically.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, you could use `gcloud compute disks list. gcloud` in a command-line
    tool in GCE.
  prefs: []
  type: TYPE_NORMAL
- en: awsElasticBlockStore
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`awsElasticBlockStore` volume mounts an **Amazon Web Service Elastic Block
    Store** (**AWS EBS**) volume. It''s a service that provides persistent block storage
    for Amazon EC2\. Just like the GCE persistent disk, we can provision it statically
    or dynamically.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To provision it statically, administrators have to create an EBS volume by
    the AWS console or AWS CLI beforehand. The following is an example of how to mount
    an existing EBS volume to the containers in a Deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE95]'
  prefs: []
  type: TYPE_PRE
- en: 'To provision it dynamically, on the other hand, just like how we demonstrated
    in the GCE persistent disk, we first create a non-default storage class; you''re
    free to use a default storage class as well. Here, our environment is provisioned
    by kops ([https://github.com/kubernetes/kops](https://github.com/kubernetes/kops);
    for more information, please refer to [Chapter 6](b7e1d803-52d0-493b-9123-5848da3fa9ec.xhtml),
    *Building Kubernetes on AWS*). The environment has been bound with the required
    IAM policies, such as `ec2:AttachVolume`, `ec2:CreateVolume`, `ec2:DetachVolume`,
    and `ec2:DeleteVolume`. If you provision it from scratch, be sure that you have
    required policies attaching to the masters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE96]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we create a PVC with the storage class name we just created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE97]'
  prefs: []
  type: TYPE_PRE
- en: 'When Kubernetes receives the request of `PersistentVolumeClaim`, it''ll try
    to allocate a new `PersistentVolume`, or bind to an existing PV, if possible:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE98]'
  prefs: []
  type: TYPE_PRE
- en: We can check the corresponding PV in the AWS console, as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'At the end, we create a Deployment with this volume by specifying `persistentVolumeClaim`
    in the spec:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE99]'
  prefs: []
  type: TYPE_PRE
- en: 'By specifying `claimName` as `aws-example`, it''ll then use the EBS volume
    we just create by PVC, which is requested to AWS dynamically. If we take a look
    at the Pod description with `kubectl describe pod <pod_name>`, we can see the
    details of the volumes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE100]'
  prefs: []
  type: TYPE_PRE
- en: EBS volume `vol-0fccc3b0af8c17727` is mounted under `/mount-path` inside the
    container.
  prefs: []
  type: TYPE_NORMAL
- en: If the volume was dynamically provisioned, the default reclaim policy is set
    to `delete`. Set it to `retain` if you want to keep them, even if a PVC is deleted.
  prefs: []
  type: TYPE_NORMAL
- en: '**The StorageObjectInUseProtection admission controller**'
  prefs: []
  type: TYPE_NORMAL
- en: A PVC might be deleted accidentally by user even if it's used by a Pod. In Kubernetes
    v1.10, a new admission controller is added to prevent this from happening.` kubernetes.io/pv-protection`
    or `kubernetes.io/pvc-protection` finalizer will be added into PV or PVC by `StorageObjectInUseProtection`
    admission controller. Then when object deletion request is sent, admission controller
    will do pre-delete check and see if there is any Pod are using it. This will prevent
    data loss.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Volumes can be mounted on the Pods by declaring in Pods or ReplicaSet spec.
    Check out the following recipes to jog your memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Working with Pods* section in [Chapter 2](e9a51674-078b-4ffc-a76c-98774150bfa3.xhtml), *Walking
    through Kubernetes Concepts*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with replica sets* section in [Chapter 2](e9a51674-078b-4ffc-a76c-98774150bfa3.xhtml), *Walking
    through Kubernetes Concepts*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with Secrets* section in [Chapter 2](e9a51674-078b-4ffc-a76c-98774150bfa3.xhtml), *Walking
    through Kubernetes Concepts*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Setting resource in nodes* section in [Chapter 8](d82d7591-b68a-42e7-ae48-5ee5a468975e.xhtml), *Advanced
    Cluster Administration*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Authentication and authorization* section in [Chapter 8](d82d7591-b68a-42e7-ae48-5ee5a468975e.xhtml), *Advanced
    Cluster Administration*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with Secrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes Secrets manage information in key-value formats with the value encoded.
    It can be a password, access key, or token. With Secrets, users don't have to
    expose sensitive data in the configuration file. Secrets can reduce the risk of
    credential leaks and make our resource configurations more organized.
  prefs: []
  type: TYPE_NORMAL
- en: 'Currently, there are three types of Secrets:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generic/Opaque: [https://en.wikipedia.org/wiki/Opaque_data_type](https://en.wikipedia.org/wiki/Opaque_data_type)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker registry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TLS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Generic/Opaque is the default type that we're using in our application. Docker
    registry is used to store the credential of a private Docker registry. TLS Secret
    is used to store the CA certificate bundle for cluster administration.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes creates built-in Secrets for the credentials that using to access
    API server.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before using Secrets, we have to keep in mind that Secret should be always created
    before dependent Pods, so dependent Pods can reference it properly. In addition,
    Secrets have a 1 MB size limitation. It works properly for defining a bunch of
    information in a single Secret. However, Secret is not designed for storing large
    amounts of data. For configuration data, consider using `ConfigMaps`. For large
    amounts of non-sensitive data, consider using volumes instead.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the following example, we'll walk through how to create a Generic/Opaque
    Secret and use it in your Pods by assuming that we have an access token that needs
    to be used inside a Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Secret
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are two ways to create a Secret. The first one is with `kubectl create
    secret` in the command line, and the other one is with direct resource creation
    in the configuration file.
  prefs: []
  type: TYPE_NORMAL
- en: Working with kubectl create command line
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By using `kubectl create secret` command line, you can create a Secret from
    a file, directory, or literal value. With this method, you don''t need to encode
    the Secret by yourself. Kubernetes will do that for you:'
  prefs: []
  type: TYPE_NORMAL
- en: From a file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If a file is the source of Secret, we''ll have to create a text file which
    contains our sensitive data first:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE101]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we could use `kubectl create secret` in the command line to create the
    Secret. The syntax is:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE102]'
  prefs: []
  type: TYPE_PRE
- en: 'In our case, we use generic Secret type, since the access token is neither
    the Docker registry image pull Secrets nor TLS information:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE103]'
  prefs: []
  type: TYPE_PRE
- en: 'You can check the detailed Secret information with the `kubectl get secret`
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE104]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use the `base64` command ([https://linux.die.net/man/1/base64](https://linux.die.net/man/1/base64))
    in Linux to decode the encoded Secret:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE105]'
  prefs: []
  type: TYPE_PRE
- en: From a directory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Creating a Secret from a directory is similar to creating from a file, using
    the same command, but with `directory`. Kubernetes will iterate all the files
    inside that directory and create a Secret for you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE106]'
  prefs: []
  type: TYPE_PRE
- en: You can check the Secret with the `kubectl get secret access-token -o yaml`
    command again and see if they're identical to the ones from the file.
  prefs: []
  type: TYPE_NORMAL
- en: From a literal value
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes supports creating a Secret with a single command line, as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE107]'
  prefs: []
  type: TYPE_PRE
- en: 'Then we can use the `get secret` command to check if they''re identical to
    the previous method:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE108]'
  prefs: []
  type: TYPE_PRE
- en: Via configuration file
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A Secret can also be created directly through the configuration file; however,
    you''ll have to encode the Secret manually. Just use the kind of Secret:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE109]'
  prefs: []
  type: TYPE_PRE
- en: Using Secrets in Pods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To use Secrets inside Pods, we can choose to expose them in environment variables
    or mount the Secrets as volumes.
  prefs: []
  type: TYPE_NORMAL
- en: By environment variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In terms of accessing Secrets inside a Pod, add `env section` inside the container
    spec as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE110]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding example, we expose `2-7-1_access-token` key in access-token
    Secret as `ACCESS_TOKEN` environment variable, and print it out through a while
    infinite loop. Check the `stdout via kubectl` log command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE111]'
  prefs: []
  type: TYPE_PRE
- en: Note that the environment variable was exposed during Pod creation. If a new
    value of Secret is pushed, you'll have to re-launch/rolling-update a Pod or Deployment
    to reflect that.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we describe the `secret-example-env` Pod, we can see that an environment
    variable was set to a Secret:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE112]'
  prefs: []
  type: TYPE_PRE
- en: By volumes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A Secret can be also mounted as volume by using the Secret type of the volume.
    The following is an example of how to use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE113]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding example will mount `secret-volume` into the `/secret mount` point
    inside the Pod. `/secret` will contain a file with the name token, which contains
    our access token. If we check the Pod details, it''ll show that we mounted a read-only
    Secret volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE114]'
  prefs: []
  type: TYPE_PRE
- en: 'If we check the `stdout`, it''ll show the Pod can properly retrieve the expected
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE115]'
  prefs: []
  type: TYPE_PRE
- en: The same as with the environment variable, the files in the mounted volume are
    created upon Pod creation time. It won't change dynamically when the Secret value
    is updated after the Pod creation time.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting a Secret
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To delete a Secret, simply use the `kubectl delete secret` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE116]'
  prefs: []
  type: TYPE_PRE
- en: 'If a Secret is deleted when a Secret volume is attached, it''ll show an error
    message whenever the volume reference disappears:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE117]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to reduce the risk of leaking the Secrets' content, Secret is not landed
    to the disk. Instead, kubelet creates a `tmpfs` filesystem on the node to store
    the Secret. The Kubernetes API server pushes the Secret to the node on which the
    demanded container is running. The data will be flashed when the container is
    destroyed.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Secrets hold small amounts of sensitive data. For application configuration,
    consider using `ConfigMaps` to hold non-sensitive information.
  prefs: []
  type: TYPE_NORMAL
- en: Using ConfigMaps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here is an example of using `ConfigMaps`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE118]'
  prefs: []
  type: TYPE_PRE
- en: 'Similar to Secret, `ConfigMaps` can be retrieved with environment variables
    or volumes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE119]'
  prefs: []
  type: TYPE_PRE
- en: 'Alternatively, you can use `ConfigMaps` volume to retrieve the configuration
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE120]'
  prefs: []
  type: TYPE_PRE
- en: Mounting Secrets and ConfigMap in the same volume
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Projected volume is a way to group multiple volume sources into the same mount
    point. Currently, it supports Secrets, `ConfigMap`, and `downwardAPI`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of how we group the examples of Secrets and `ConfigMaps` that
    we used in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE121]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check `stdout` to see if it works properly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE122]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Working with Volumes* section in [*Chapter 2*](e9a51674-078b-4ffc-a76c-98774150bfa3.xhtml)*, Walking
    through Kubernetes Concepts*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Working with configuration files * section in *[Chapter 3](51ca5358-d5fe-4eb2-a52d-65a399617fcf.xhtml),
    Playing with Containers*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The Moving monolithic to microservices* and *Working with the private Docker
    registry * sections in *[Chapter 5](669edaf0-c274-48fa-81d8-61150fa36df5.xhtml),
    Building Continuous Delivery Pipeline*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Advanced settings in kubeconfig * section in *[Chapter 7](d82d7591-b68a-42e7-ae48-5ee5a468975e.xhtml),
    Building Kubernetes on GCP*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with names
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you create any Kubernetes object, such as a Pod, Deployment, and Service,
    you can assign a name to it. The names in Kubernetes are spatially unique, which
    means you cannot assign the same name in the Pods.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes allows us to assign a name with the following restrictions:'
  prefs: []
  type: TYPE_NORMAL
- en: Up to 253 characters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lowercase of alphabet and numeric characters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: May contain special characters in the middle, but only dashs (-) and dots (.)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For assigning a name to the Pod, follow the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example is the Pod YAML configuration that assigns the Pod name
    as `my-pod` to the container name as `my-container`; you can successfully create
    it as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE123]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use the `kubectl describe` command to see the container named `my-container`
    as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE124]'
  prefs: []
  type: TYPE_PRE
- en: 'On the other hand, the following example contains two containers, but assigns
    the same name, `my-container`; therefore, the `kubectl create` command returns
    an error and can''t create the Pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE125]'
  prefs: []
  type: TYPE_PRE
- en: You can add the `--validate` flag.
  prefs: []
  type: TYPE_NORMAL
- en: For example, the command `kubectl create -f duplicate.yaml --validate` uses
    a schema to validate the input before sending it.
  prefs: []
  type: TYPE_NORMAL
- en: 'In another example, the YAML contains a ReplicationController and Service,
    both of which are using the same name, `my-nginx`, but it is successfully created
    because the Deployment and Service are different objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE126]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A name is just a unique identifier, and all naming conventions are good; however,
    it is recommended to look up and identify the container image. For example:'
  prefs: []
  type: TYPE_NORMAL
- en: '`memcached-pod1`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`haproxy.us-west`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`my-project1.mysql`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'On the other hand, the following examples do not work because of Kubernetes
    restrictions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Memcache-pod1` (contains uppercase)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`haproxy.us_west` (contains underscore)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`my-project1.mysql.` (dot in the last)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note that Kubernetes supports a label that allows assigning a `key=value` style
    identifier. It also allows duplication. Therefore, if you want to assign something
    like the following information, use a label instead:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Environment (for example: staging, production)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Version (for example: v1.2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Application role (for example: frontend, worker)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In addition, Kubernetes also supports names that have different Namespaces.
    This means that you can use the same name in different Namespaces (for example:
    `nginx`). Therefore, if you want to assign just an application name, use Namespaces
    instead.'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This section from the chapter described how to assign and find the name of
    objects. This is just a basic methodology, but Kubernetes has more powerful naming
    tools, such as Namespace and selectors, to manage clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Working with Pods*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Deployment API*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with Services*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with Namespaces*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with labels and selectors*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with Namespaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In a Kubernetes cluster, the name of a resource is a unique identifier within
    a Namespace. Using a Kubernetes Namespace could separate user spaces for different
    environments in the same cluster. It gives you the flexibility of creating an
    isolated environment and partitioning resources to different projects and teams.
    You may consider Namespace as a virtual cluster. Pods, Services, and Deployments
    are contained in a certain Namespace. Some low-level resources, such as nodes
    and `persistentVolumes`, do not belong to any Namespace.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we dig into the resource Namespace, let''s understand `kubeconfig` and
    some keywords first:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b1dc5384-97c8-4a7b-af9b-ddbdc62e60c0.png)'
  prefs: []
  type: TYPE_IMG
- en: The relationship of kubeconfig components
  prefs: []
  type: TYPE_NORMAL
- en: '`kubeconfig` is used to call the file which configures the access permission
    of Kubernetes clusters. As the original configuration of the system, Kubernetes
    takes `$HOME/.kube/config` as a `kubeconfig` file. Some concepts that are illustrated
    by the preceding diagram are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**kubeconfig defines user, cluster, and context**: `kubeconfig` lists multiple
    users for defining authentication, and multiple clusters for indicating the Kubernetes
    API server. Also, the context in `kubeconfig` is the combination of a user and
    a cluster: accessing a certain Kubernetes cluster with what kind of authentication.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Users and clusters are sharable between contexts**: In the previous diagram,
    both **Context 1** and **Context 3** take **User** **1** as their user content.
    However, each context can only have a single user and single cluster definition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Namespace can be attached to context**: Every context can be assigned to
    an existing Namespace. If there are none, like **Context 3**, it is along with
    the default Namespace, named `default`, as well.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The current context is the default environment for client**: We may have
    several contexts in `kubeconfig`, but only one for the current context. The current
    context and the Namespace attached on it will construct the default computing
    environment for users.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now you will get the idea that, as Namespace works with `kubeconfig`, users
    can easily switch default resources for usage by switching the current context
    in `kubeconfig`. Nevertheless, users can still start any resource in a different
    Namespace with a specified one. In this recipe, you will learn how to create your
    own Namespace and how to work with it.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'By default, Kubernetes has created a Namespace named `default`. All the objects
    created without specifying Namespaces will be put into the `default` Namespace.
    Kubernetes will also create another initial Namespace called `kube-system` for
    locating Kubernetes system objects, such as an add-on or overlay network. Try
    to list all the Namespaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE127]'
  prefs: []
  type: TYPE_PRE
- en: You may find an additional Namespace, `kube-public`, listed at the initial stage.
    It is designed for presenting some public configurations for even users without
    permission to access the Kubernetes system. Both of the provisioning tools, minikube
    and kubeadm, will create it while booting the system up.
  prefs: []
  type: TYPE_NORMAL
- en: 'The name of a Namespace must be a DNS label and follow the following rules:'
  prefs: []
  type: TYPE_NORMAL
- en: At most, 63 characters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matching regex [a-z0-9]([-a-z0-9]*[a-z0-9])
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will demonstrate how to create a Namespace, change the default
    Namespace, and delete the Namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Namespace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For creating a Namespace, following are the steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'After deciding on our desired name for Namespace, let''s create it with a configuration
    file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE128]'
  prefs: []
  type: TYPE_PRE
- en: 'You can now see that we have an additional namespace called `my-namespace`.
    Next, let''s run a Kubernetes Deployment in this new Namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE129]'
  prefs: []
  type: TYPE_PRE
- en: 'While trying to check the newly created resource, we cannot easily find them
    as usual:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE130]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead, the Deployment is shown with a flag related to the Namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE131]'
  prefs: []
  type: TYPE_PRE
- en: Now you can find the resource that was just created.
  prefs: []
  type: TYPE_NORMAL
- en: Changing the default Namespace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As in the previous introduction, we can change the default Namespace by switching
    the current context in `kubeconfig` to another one:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we may check the current context with the subcommand `config`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE132]'
  prefs: []
  type: TYPE_PRE
- en: You may feel unfamiliar with the output when checking the current context. The
    value of the preceding current context is defined and created by `kubeadm`. You
    could get `minikube` shown on screen if you leveraged `minikube` as your Kubernetes
    system management tool.
  prefs: []
  type: TYPE_NORMAL
- en: 'No matter what you got from checking the current context in `kubeconfig`, use
    the subcommand `config set-context` to create a new context:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE133]'
  prefs: []
  type: TYPE_PRE
- en: 'The preceding command is based on `kubeadm` managed Kubernetes; you may fire
    a similar one for `minikube`, with the names of the default cluster and user in
    `kubeconfig`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE134]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, check `kubeconfig` to verify the changes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE135]'
  prefs: []
  type: TYPE_PRE
- en: When checking the configuration of `kubeconfig`, in the section of contexts,
    you can find a context named exactly as what we defined and which also takes our
    newly created Namespace.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fire the following command to switch to using the new context:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE136]'
  prefs: []
  type: TYPE_PRE
- en: Now the current context is our customized one, which is along with the Namespace
    `my-namespace`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the default Namespace is changed to `my-namespace`, it is possible that
    we can get the Deployment without specifying the Namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE137]'
  prefs: []
  type: TYPE_PRE
- en: Deleting a Namespace
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you followed the previous pages for the Kubernetes resource, you may have
    gotten the idea that the subcommand `delete` is used to remove resources. It is
    workable in the case of removing a Namespace. At the same time, if we try to delete
    a Namespace, the resources under it will be removed, as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE138]'
  prefs: []
  type: TYPE_PRE
- en: 'To solve this issue, you may attach another Namespace to the current context,
    or just change your current context to the previous one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE139]'
  prefs: []
  type: TYPE_PRE
- en: How it works…
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Although we discussed the Namespaces and context of `kubeconfig` together, they
    are independent objects in the Kubernetes system. The context of `kubeconfig`
    is a client concept which can only be controlled by certain users, and it makes
    it easier to work with Namespaces and clusters. On the other hand, Namespace is
    the concept of the server side, working for resource isolation in clusters, and
    it is able to be shared between clients.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We not only leverage Namespace to separate our resources, but also to realize
    finer computing resource provisioning. By restricting the usage amount of the
    computing power of a Namespace, the system manager can avoid the client creating
    too many resources and making servers overload.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a LimitRange
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To set the resource limitation of each Namespace, the admission controller `LimitRanger`
    should be added in the Kubernetes API server. Do not worry about this setting
    if you have `minikube` or `kubeadm` as your system manager.
  prefs: []
  type: TYPE_NORMAL
- en: '**The admission controller in the Kubernetes API server** Admission controller
    is a setting in the Kubernetes API server which defines more advanced functionality
    in the API server. There are several functions that can be set in the admission
    controller. Users can add the functions when starting the API server through the
    configuration file or using CLI with the flag `--admission-control`. Relying on
    `minikube` or `kubeadm` for system management, they have their own initial settings
    in the admission controller:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Default admission controller in** **kubeadm**: `Initializers`, `NamespaceLifecycle`,
    `LimitRanger`, `ServiceAccount`, `PersistentVolumeLabel`, `DefaultStorageClass`,
    `DefaultTolerationSeconds`, `NodeRestriction`, `ResourceQuota`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Default admission controller in minikube**: `NamespaceLifecycle`, `LimitRanger`,
    `ServiceAccount`, `DefaultStorageClass, ResourceQuota`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on the version of your API server, there is a recommended list in an official
    document at [https://kubernetes.io/docs/admin/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use](https://kubernetes.io/docs/admin/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use).
    Check for more ideas!
  prefs: []
  type: TYPE_NORMAL
- en: 'A plain new Namespace has no limitation on the resource quota. At the beginning,
    we start a Namespace and take a look at its initial settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE140]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we create a resource called `LimitRange` for specifying the resource
    limitation of a Namespace. The following is a good example of creating a limit
    in a Namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE141]'
  prefs: []
  type: TYPE_PRE
- en: We will then limit the resources in a Pod with the values of `2` as `max` and
    `200m` as a `min` for CPU, and `1Gi` as max and `6Mi` as a min for memory. For
    the container, the CPU is limited between `100m - 2` and the memory is between
    `3Mi` - `1Gi`. If the max is set, then you have to specify the limit in the Pod/container
    spec during the resource creation; if the min is set, then the request has to
    be specified during the Pod/container creation. The `default` and `defaultRequest`
    section in LimitRange is used to specify the default limit and request in the
    container spec.
  prefs: []
  type: TYPE_NORMAL
- en: '**The value of CPU limitation in LimitRange** What do the values of `2` and
    `200m` mean in the Pod limitation in the file `my-first-limitrange.yaml`? The
    integer value means the number of CPU; the "m" in the value means millicpu, so
    `200m` means 0.2 CPU (200 * 0.001). Similarly, the default CPU limitation of the
    container is 0.2 to 0.3, and the real limitation is 0.1 to 2.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Afterwards, we create the LimitRange in our plain Namespace and check what
    will happen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE142]'
  prefs: []
  type: TYPE_PRE
- en: 'When you query the detail description of `my-namespace`, you will see the constraint
    attached to the Namespace directly. There is not any requirement to add the LimitRange.
    Now, all the Pods and containers created in this Namespace have to follow the
    resource limits listed here. If the definitions violate the rule, a validation
    error will be thrown accordingly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE143]'
  prefs: []
  type: TYPE_PRE
- en: Deleting a LimitRange
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We can delete the LimitRange resource with the subcommand `delete`. Like creating
    the `LimitRange`, deleting a `LimitRange` in a Namespace would remove the constraints
    in the Namespace automatically:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE144]'
  prefs: []
  type: TYPE_PRE
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Many Kubernetes resources are able to run under a Namespace. To achieve good
    resource management, check out the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Working with Pods*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Deployment API*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Working with names*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Setting resources in nodes* section in *[Chapter 7](e9a51674-078b-4ffc-a76c-98774150bfa3.xhtml),
    Building Kubernetes on GCP*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with labels and selectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Labels** are a set of key/value pairs, which are attached to object metadata.
    We could use labels to select, organize, and group objects, such as Pods, ReplicaSets,
    and Services. Labels are not necessarily unique. Objects could carry the same
    set of labels.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Label selectors are used to query objects with labels of the following types:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Equality-based:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use equal (`=` or `==`) or not-equal (`!=`) operators
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Set-based:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `in` or `notin` operators
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before you get to setting labels in the objects, you should consider the valid
    naming convention of key and value.
  prefs: []
  type: TYPE_NORMAL
- en: 'A valid key should follow these rules:'
  prefs: []
  type: TYPE_NORMAL
- en: A name with an optional prefix, separated by a slash.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A prefix must be a DNS subdomain, separated by dots, no longer than 253 characters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A name must be less than 63 characters with the combination of [a-z0-9A-Z] and
    dashes, underscores, and dots. Note that symbols are illegal if put at the beginning
    and the end.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A valid value should follow the following rules:'
  prefs: []
  type: TYPE_NORMAL
- en: A name must be less than 63 characters with the combination of [a-z0-9A-Z] and
    dashes, underscores, and dots. Note that symbols are illegal if put at the beginning
    and the end.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You should also consider the purpose, too. For example, there are two projects, `pilot`
    and `poc`. Also, those projects are under different environments, such as `develop`
    and `production`. In addition, some contain multiple tiers, such as `frontend`,
    `cache`, and `backend`. We can make our labels key and value pair combination
    like follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE145]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s try to create several Pods with the previous labels to distinguish different
    projects, environments, and tiers, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '| **YAML Filename** | **Pod Image** | **Project** | **Environment** | **Tier**
    |'
  prefs: []
  type: TYPE_TB
- en: '| `pilot-dev.yaml` | `nginx` | pilot | develop | `frontend` |'
  prefs: []
  type: TYPE_TB
- en: '| `pilot-dev.yaml` | `memcached` | `cache` |'
  prefs: []
  type: TYPE_TB
- en: '| `pilot-prod.yaml` | `nginx` | production | `frontend` |'
  prefs: []
  type: TYPE_TB
- en: '| `pilot-prod.yaml` | `memcached` | `cache` |'
  prefs: []
  type: TYPE_TB
- en: '| `poc-dev.yaml` | `httpd` | poc | develop | `frontend` |'
  prefs: []
  type: TYPE_TB
- en: '| `poc-dev.yaml` | `memcached` | `cache` |'
  prefs: []
  type: TYPE_TB
- en: 'For convenience, we will prepare three YAML files that contain two Pods each,
    with a `YAML separator ---` between Pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`pilot-dev.yaml`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE146]'
  prefs: []
  type: TYPE_PRE
- en: '`pilot-prod.yaml`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE147]'
  prefs: []
  type: TYPE_PRE
- en: '`poc-dev.yaml`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE148]'
  prefs: []
  type: TYPE_PRE
- en: 'Create those six Pods with the `kubectl create` command, as follows, to see
    how labels are defined:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE149]'
  prefs: []
  type: TYPE_PRE
- en: 'Run `kubectl describe <Pod name>` to check labels, as follows. It looks good,
    so let''s use the label selector to query these Pods by different criteria:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE150]'
  prefs: []
  type: TYPE_PRE
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As mentioned earlier in this section, there are two types of label selectors:
    either equality-based or set-based. Those types have different operators to specify
    criteria.'
  prefs: []
  type: TYPE_NORMAL
- en: Equality-based label selector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The equality-based selector can specify equal or not equal, and also uses commas
    to add more criteria. Use the `-l` or `--selector` option to specify these criteria
    to filter the name of the object; for example:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Query Pods which belong to the pilot project:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE151]'
  prefs: []
  type: TYPE_PRE
- en: 'Query Pods which belong to the frontend tier:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE152]'
  prefs: []
  type: TYPE_PRE
- en: 'Query Pods which belong to the frontend tier AND the under develop environment:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE153]'
  prefs: []
  type: TYPE_PRE
- en: 'Query Pods which belong to the frontend tier and NOT the under develop environment:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE154]'
  prefs: []
  type: TYPE_PRE
- en: Set-based label selector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'With the set-based selector, you can use either the `in` or `notin` operator,
    which is similar to the `SQL IN` clause that can specify multiple keywords, as
    in the following examples:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Query `Pods` which belong to the `pilot` project:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE155]'
  prefs: []
  type: TYPE_PRE
- en: 'Query `Pods` which belong to the pilot project and `frontend` tier:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE156]'
  prefs: []
  type: TYPE_PRE
- en: 'Query `Pods` which belong to the pilot project and either the `frontend` or
    `cache` tier:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE157]'
  prefs: []
  type: TYPE_PRE
- en: 'Query `Pods` which belong to the pilot project and not the `frontend` or `backend`
    tier (note, we didn''t create the `backend` tier object):'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE158]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see in the preceding examples for both the equality-based and set-based
    label selector, equality-based is simpler and set-based is more expressive. Note
    that you can mix both operator as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Query Pods which do not belong to the pilot project and develop environment:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE159]'
  prefs: []
  type: TYPE_PRE
- en: So, you can use the most efficient way to filter out the Kubernetes objects.
    In addition, you can also use either or both types of selectors to configure the
    Kubernetes Service, Deployments, and so on. However, some objects support the
    equality-based selector and some objects support both. So, let's take a look at
    how to define it.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Label selectors are useful to not only list an object, but also to specify the
    Kubernetes Service and Deployment to bind objects.
  prefs: []
  type: TYPE_NORMAL
- en: Linking Service to Pods or ReplicaSets using label selectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As of Kubernetes version 1.9, Service only supports the equality-based selector
    to bind to Pods or ReplicaSet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create one Service that binds to `nginx`, which belongs to the production
    environment and the pilot project. Remember that `nginx` also belongs to the frontend
    tier:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE160]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the equivalent, where you can use the `kubectl expose` command to specify
    the label selector:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE161]'
  prefs: []
  type: TYPE_PRE
- en: 'Based on your Kubernetes environment, if you are using minikube, it is easier
    to check your Service with `minikube service <Service name>`, as in the following
    screenshot. If you are not using minikube, access to any Kubernetes node and assigned
    Service port number. For the following screenshot, it would be `<node ip>:31981
    or <node ip>:31820`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f0be9472-e1c0-4b61-9224-5af359c3be14.png)'
  prefs: []
  type: TYPE_IMG
- en: Access to Service which is running on minikube
  prefs: []
  type: TYPE_NORMAL
- en: Linking Deployment to ReplicaSet using the set-based selector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Deployment supports not only the equality-based selector, but also the set-based
    selector, to specify `ReplicaSet`. To do that, you can write `spec.selector.matchExpressions[]`
    to specify the key and `in`/`notin` operator. For example, if you want to specify `project
    in (poc), environment in (staging), tier notn (backend,cache)`, then `matchExpressions`
    would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE162]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the YAML array is represented as `*-*`, and the map object as
    `{}`, to specify the key, operator, and values. Note that values would also be
    an array, so use the square bracket `[]` to specify one or more values.
  prefs: []
  type: TYPE_NORMAL
- en: 'One thing you need to aware of is one label, called the `pod-template-hash`
    label, which is created by Deployment. When you create a Deployment, it will also
    create a `ReplicaSet` object. At this time, Deployment will also assign the `pod-template-hash`
    label to the `ReplicaSet`. Let''s see how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE163]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the `ReplicaSet` `my-nginx2-764d7cfff` has an equality-based
    selector, as `pod-template-hash=320837999` is appended to the Selector and Pod
    template. It will be used to generate a `ReplicaSet` and Pod name with a particular
    hash function (for example, `my-nginx2-764d7cfff`).
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you learned how flexible it is to assign a label to your Kubernetes
    object. In addition, equality-based and set-based selectors allow us to filter
    out an object by label. Selector is important that loosely couple an object such
    as Service and ReplicaSet/Pod as well as Deployment and ReplicaSet.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following sections will also use labels and the concept of selectors to
    utilize container management:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Updating live containers* section in *[Chapter 3](51ca5358-d5fe-4eb2-a52d-65a399617fcf.xhtml),
    Playing with Containers*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Managing the Kubernetes* *cluster on GKE* section in *[Chapter 7](dfc46490-f109-4f07-ba76-1a381b006d76.xhtml),
    Building Kubernetes on GCP*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
