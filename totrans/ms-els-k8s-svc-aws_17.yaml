- en: '17'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: EKS Observability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout the book, we’ve looked at how you build EKS clusters and deploy workloads.
    However, a critical part of any EKS deployment is observability. Observability
    is the ability to interpret logs and metrics from your cluster/workloads without
    which you can’t troubleshoot/resolve issues or understand capacity or performance.
    Observability also includes tracing, which allows you to follow a request as it
    moves through different EKS workloads (microservices), simplifying troubleshooting
    in a distributed system.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we are going to discuss the tools and techniques you can use
    to monitor your clusters and workloads natively on AWS or using third-party tools.
    We will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring clusters and Pods using native AWS tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building dashboards with Managed Service for Prometheus and Grafana
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracing with OpenTelemetry
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using machine learning with DevOps Guru
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You should have a familiarity with YAML, AWS IAM, and EKS architecture. Before
    getting started with this chapter, please ensure the following:'
  prefs: []
  type: TYPE_NORMAL
- en: You have network connectivity to your EKS cluster API endpoint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AWS CLI, Docker, and `kubectl` binary are installed on your workstation
    and you have administrator access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring clusters and Pods using native AWS tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the key advantages of an AWS deployment of Kubernetes (EKS) over an on-premises
    deployment of Kubernetes is it comes pre-integrated into CloudWatch, which is
    the main logging and monitoring platform for AWS. With a standard EKS cluster,
    you will automatically get control plane logs, EC2 worker node and load balancer
    (Network or Application Load Balancer) logs and metrics, along with metrics and
    logs from other AWS services such as databases, message queues, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at how we can create a basic CloudWatch dashboard using standard
    EC2 metrics to understand the work nodes for our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a basic CloudWatch dashboard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll use Terraform to create a simple dashboard that shows an aggregated view
    of all instances that are tagged with a specific cluster name, and a second one
    that shows each individual node. The code snippet shown next illustrates the basic
    structure, a `data` object (which retrieves all the current AWS credential data)
    and an `aws_cloudwatch_dashboard` object that consists of two objects (shown further
    down):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You need to replace the `{widget1|2}` markers with the actual code shown next.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the first widget, we will collect two metrics (CPU and network traffic
    out) and aggregate them based on the node group name, and use the `eks:cluster-name`
    tag to select nodes that are part of our `myipv4cluster` cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: The following figure shows the widget in the AWS dashboard with two metrics
    aggregated per node group; `ipv4mng` is the only node group in this cluster.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.1 – Aggregated CloudWatch dashboard widget](img/B18129_Figure_17.01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.1 – Aggregated CloudWatch dashboard widget
  prefs: []
  type: TYPE_NORMAL
- en: The second widget is exactly the same but doesn’t contain the `aggregateBy`
    key in the widget definition and so generates the following visualization, which
    shows the same data but also shows the individual instances.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.2 – CloudWatch instance dashboard widget](img/B18129_Figure_17.02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.2 – CloudWatch instance dashboard widget
  prefs: []
  type: TYPE_NORMAL
- en: As AWS manages the EKS control plane, we won’t see Kubernetes control plane
    metrics by default. Let’s see how we can look at control plane metrics and add
    them to our dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at the control plane logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'An EKS cluster generates the following cluster control plane log. Each log
    corresponds to a specific component of the EKS control plane:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Audit Logs**: These logs contain a set of records that describe the users’
    or systems’ actions when using the K8s API. They are a very valuable source of
    data when you want to understand what happened on your cluster, when it happened,
    and who made it happen.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Authenticator Logs**: These logs contain a set of records that describe the
    authentication of users and systems using IAM credentials and are useful in understanding
    who authenticated and uses the cluster in more detail.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API Server Logs**: These logs contain a set of records that describe the
    flags being used on the different components and are useful for understanding
    how the cluster is being used and configured.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Controller Logs**: These logs contain a set of records that describe the
    control loops used by the cluster to perform actions such as scheduling, and are
    useful in understanding how the control plane is operating.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scheduler Logs**: These logs contain a set of records that describe the actions
    taken by the scheduler to deploy, replace, and delete Pods and K8s resources,
    and are useful in understanding how this critical component is working.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: More details can be found in the main debugging and logging section of the K8s
    documentation found at [https://kubernetes.io/docs/tasks/debug/](https://kubernetes.io/docs/tasks/debug/).
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical best practice would be to enable audit and authenticator logs for
    all clusters and, by default, these would be sent to CloudWatch logs, which can
    be used for debugging, incident investigation, and forensics. The easiest way
    to check what logs are enabled for a cluster is to use the AWS console and browse
    to your cluster under the Amazon EKS. An example of a **Logging** screen with
    no API logging enabled is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.3 – Verifying EKS cluster logging in the AWS console](img/B18129_Figure_17.03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.3 – Verifying EKS cluster logging in the AWS console
  prefs: []
  type: TYPE_NORMAL
- en: 'We can modify the cluster configuration to allow audit and authenticator logging
    with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We can verify the update was successful using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If we now look at the CloudWatch service, in the AWS console, we will see a
    new log group has been created for our cluster, which we can use as a data source
    for queries and other CloudWatch functions. An illustration of the log group for
    `myipv4cluster` is shown next.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.4 – CloudWatch cluster log groups](img/B18129_Figure_17.04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.4 – CloudWatch cluster log groups
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we have a data source, EKS control plane logs, we can use `aws-auth` ConfigMap,
    which controls access to the EKS cluster. We can also add this to our simple dashboard
    using the **Add to dashboard** button on the **Log** **Insights** screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.5 – Using Log Insights to generate insights into EKS audit data](img/B18129_Figure_17.05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.5 – Using Log Insights to generate insights into EKS audit data
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'Because the control plane logging is relying on the Amazon CloudWatch log to
    store the data streams, visualization, and insights, additional costs will apply.
    To get more details, please refer to the CloudWatch pricing page: [https://aws.amazon.com/cloudwatch/pricing/](https://aws.amazon.com/cloudwatch/pricing/).'
  prefs: []
  type: TYPE_NORMAL
- en: By default, CloudWatch keeps your logs indefinitely and they never expire. It
    means that they won’t be deleted unless you manually clean them up. This can potentially
    increase your data storage cost if the CloudWatch log group keeps the old control
    plane logs that you don’t want to save.
  prefs: []
  type: TYPE_NORMAL
- en: To optimize the storage cost, there is a little tip to save your money by configuring
    the retention policy for each CloudWatch log group. By setting the log group retention
    period, any log streams within this log group older than the retention settings
    will be deleted automatically. You can choose a retention period for your EKS
    control plane log from 1 day to 10 years.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can follow these steps to configure the log retention policy for your CloudWatch
    log group:'
  prefs: []
  type: TYPE_NORMAL
- en: To find the CloudWatch log group for your cluster, go to **CloudWatch** | **Log
    groups** and search for your cluster name.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the **Actions** drop-down menu, select **Edit retention setting** (a sample
    is shown in the following figure):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 17.6 – Edit retention setting of your log group](img/B18129_Figure_17.06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.6 – Edit retention setting of your log group
  prefs: []
  type: TYPE_NORMAL
- en: Select the log retention value in the drop-down menu and save the setting. A
    typical value would be keeping logs for *30 days/1 month* and deleting them after
    that, but it will depend on what you need the logs for, as some logs may need
    to be stored for regulatory or security purposes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Shrinking the old log streams can make sure it only keeps the data you really
    care about. This is another useful tip to help you reduce the storage cost for
    storing EKS control plane logs in Amazon CloudWatch log groups.
  prefs: []
  type: TYPE_NORMAL
- en: Now we’ve looked at what we get “out of the box” with EKS, let’s look at what
    we need to add to enhance the overall observability experience, starting with
    the control plane and Pod metrics and logs.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring control plane and Pod metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Kubernetes control plane components expose metrics on the `/metrics` endpoints
    in the Prometheus Metrics format. You can access these metrics using `kubectl`
    or by *scraping* the `/metrics` endpoint. An example is using `kubectl` to extract
    node data and using the `jq` utility to format the data and filter it to the first
    (`0`) node. At the end of the output, you can see node `usage` data for CPU and
    RAM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We will now install AWS `/metrics` data to CloudWatch as well as application
    logs. It does this by installing two agents, the CloudWatch agent (metrics) and
    either Fluent Bit or FluentD for logs. We will use the QuickStart guide, which
    uses Fluent Bit (which is a more efficient agent).
  prefs: []
  type: TYPE_NORMAL
- en: The first thing to do is grant the worker permission to access the CloudWatch
    API. We will add `CloudWatchAgentServerPolicy` to the worker node IAM policy.
    An example is shown next. This will allow any of the CloudWatch agent or FluentBit
    Pods to communicate with the CloudWatch API.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.7 – Additional permissions needed for CI](img/B18129_Figure_17.07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.7 – Additional permissions needed for CI
  prefs: []
  type: TYPE_NORMAL
- en: Once we have the permissions applied, we can install the two agents (CW and
    FluentBit).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now install the agents using the instructions shown at this URL: [https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-setup-EKS-quickstart.html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-setup-EKS-quickstart.html).
    The configuration and output are shown next, and we’ve modified `ClusterName`
    and `RegionName` to match our cluster configuration. When we execute, the CloudWatch
    and FluentBit agents are installed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We can verify the deployment of the agents using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Logging with FluentBit
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Now that we have the agents running, we can look in CloudWatch to see the logs
    and metrics being generated. Firstly, if we look at CloudWatch logs and filter
    on `containerinsights`, we see four new log groups. An example is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.8 – New log groups created by CI](img/B18129_Figure_17.08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.8 – New log groups created by CI
  prefs: []
  type: TYPE_NORMAL
- en: These logs extract data from the node logs. The following table shows which
    node logs and journal files are used on each host. The `application` log group
    contains logs written to `stdout` from the containers.
  prefs: []
  type: TYPE_NORMAL
- en: '| `/``aws/containerinsights/Cluster_Name/ application` | All log files in`/``var/log/containers`
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `/``aws/containerinsights/Cluster_Name/ host` | All log files in`/``var/log/dmesg`,`/var/log/secure`,
    and `/var/log/messages` |'
  prefs: []
  type: TYPE_TB
- en: '| `/``aws/containerinsights/Cluster_Name/ dataplane` | The logs in `/``var/log/journal`
    for`kubelet.service``kubeproxy.service``docker.service` |'
  prefs: []
  type: TYPE_TB
- en: '| `/``aws/containerinsights/Cluster_Name/ performance` | Contains K8s performance
    events detailed at [https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-reference-performance-logs-EKS.html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/Container-Insights-reference-performance-logs-EKS.html)
    |'
  prefs: []
  type: TYPE_TB
- en: Table 17.1 – CI log group configuration
  prefs: []
  type: TYPE_NORMAL
- en: 'We use the following manifest to create a Pod that generates log messages and
    then terminates itself:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'We can use the following commands to create the namespace, deploy the Pod,
    and validate that it generates the log messages:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'If we now look at the `application` log group, you will see a log entry for
    the `logger` Pod, in the `logger-app` namespace running on one of your hosts.
    In the example shown next, it is host `192.168.32.216`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.9 – CloudWatch container logging output](img/B18129_Figure_17.09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.9 – CloudWatch container logging output
  prefs: []
  type: TYPE_NORMAL
- en: From this point on, you can visualize your logs as we did in the *Looking at
    the control plane logs* section. You can also turn the logs into metrics and visualize
    them in the dashboard we created previously or you could forward them to another
    logging service such as OpenSearch, Loki, or Splunk.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics with CloudWatch
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CloudWatch CI uses a combination of metrics and logs to create different views
    and dashboards using the data from FluentBit and the CloudWatch agents. One of
    the most useful views is the map view, which provides a graphical view of the
    resources deployed in your cluster on top of which you can overlay CPU or memory
    heat maps. An example is shown next for our cluster, which shows the `logger`
    Pod we deployed previously and has a green status for all CPU stats.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.10 – CI map view](img/B18129_Figure_17.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.10 – CI map view
  prefs: []
  type: TYPE_NORMAL
- en: 'We can change the view from a map to a performance dashboard to deep dive into
    any issue with CPU/RAM, and so on. The following example shows a breakdown of
    CPU, RAM, and so on segregated by namespace (each of the lines):'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 17.11 – CI performance per \uFEFFnamespace](img/B18129_Figure_17.11.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 17.11 – CI performance per namespace
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'CloudWatch CI is charged, with log storage charges and CloudWatch custom metrics:
    [https://aws.amazon.com/cloudwatch/pricing/](https://aws.amazon.com/cloudwatch/pricing/).'
  prefs: []
  type: TYPE_NORMAL
- en: Now we’ve seen how we can use native AWS tools, let’s look at using some standard
    K8s third-party tools.
  prefs: []
  type: TYPE_NORMAL
- en: Building dashboards with Managed Service for Prometheus and Grafana
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Prometheus and Grafana are the de facto monitoring tools for K8s. Prometheus
    is a graduated project from the `/metrics` endpoint) and can generate alerts and
    store/forward the data. Grafana is an open source tool that can visualize metrics
    (time series), and log and trace data (discussed in the *Tracing with OpenTelemetry*
    section). Together, Prometheus and Grafana provide equivalent functionality to
    CloudWatch, so why use them?
  prefs: []
  type: TYPE_NORMAL
- en: As Grafana is open source, it has wide community adoption, which means it has
    lots of reusable dashboards created for it, is integrated into a variety of data
    sources (not just AWS), and arguably, has a more complete set of visualizations
    than CloudWatch. Prometheus supports any sort of health endpoint and so can be
    used easily for your applications as well as the general Pod/cluster metrics.
    So, Grafana and Prometheus provide a flexible solution for which, if running on
    EKS or EC2, you will only pay the running costs. The main challenge with these
    tools is you need to manage the infrastructure and, in some cases, use additional
    products for managing long-term storage of metric or log data. This is where **AWS
    Managed Prometheus** (**AMP**) and **AWS Managed Grafana** (**AMG**) come in,
    offering flexibility without the management overhead.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up AMP and AWS Distro for OpenTelemetry (ADOT)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The first thing we will do is create an AMP to capture our metrics; AWS will
    create an area to store and query metrics (time series data). The Terraform code
    shown next will create a `myamp` workspace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following AWS SDK commands can be used to describe the workspace and get
    the endpoint for the workspace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: AMP can ingest metrics from two main sources, which, in turn, “scrape” metrics
    from Prometheus-enabled endpoints such as the K8s `/metrics` endpoint. You can
    use either existing Prometheus servers or **ADOT** to remotely write metrics to
    the AMP workspace.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use ADOT, as it will be used later for tracing:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing we need to do is create the `prometheus` namespace to host
    ADOT and create a service account with IAM mappings (IRSA). Example commands are
    shown next:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We need to install `cert-manager` (if it’s not already installed) as ADOT will
    use it during operations such as sidecar injection. The commands needed are shown
    next:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will install ADOT as an add-on to allow simpler upgrades and management,
    so we now need to give permission to EKS add-ons to install ADOT using the following
    commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We will now deploy and verify the ADOT deployment using the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can now download and configure the ADOT deployment using the following commands,
    modifying `REGION` and `prometheusEndpoint`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, we can install and verify ADOT using the `otel-collector-prometheus.yaml`
    manifest we downloaded and modified using the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We now have ADOT set up and configured to send metrics to our AMP. We can query
    this directly through the AMS Prometheus API or by using Grafana. As a quick check,
    let’s install and use `awscurl` (which allows us to use the AWS credentials to
    curl APIs directly) to test whether metrics are being received by AMP:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: To access the Prometheus API, either to send metrics or make queries, we need
    network access to the public AWS Prometheus API, through a NAT or internet gateway,
    or using a VPC endpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Now we have installed ADOT and verified that metrics are being sent and stored
    in Prometheus, we can look at how we can visualize them graphically using AMG.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up AMG and creating a dashboard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'AMG needs to have a user identity store, which is different from AWS IAM. It
    will integrate through AWS Identity Center (the successor to AWS Single Sign-On)
    or through SAML. **Security Assertion Markup Language** (**SAML**) is an open
    standard used for authentication, which will transfer authentication data between
    two parties: the **identity provider** (**IdP**) and the **service provider**
    (**SP**). We will use **AWS Identity Center** (**AIC**) as it’s simpler to set
    up. Through the AWS console, select the Identity Center service and click on the
    **Enable** button. The console splash screen is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.12 – AWS Identity Center splash screen](img/B18129_Figure_17.12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.12 – AWS Identity Center splash screen
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You will be asked to create an organization, which is used to group and control
    multiple accounts. Accept this action and you will also be sent an email, which
    you will need to verify in order for the organization and, ultimately, Identity
    Center to be created.
  prefs: []
  type: TYPE_NORMAL
- en: Once AIC is enabled, you will be able to add a user through the console by clicking
    on the **Add user** button and entering some general information such as name
    and email. Once you have verified your user email and set a password, you will
    be able to log in through the AIC console.
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 17.13 – Example AIC \uFEFFUsers admin screen](img/B18129_Figure_17.13.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 17.13 – Example AIC Users admin screen
  prefs: []
  type: TYPE_NORMAL
- en: If we click on the user shown in the preceding figure, we can get the unique
    user identity (**User ID**). This is shown in the following screenshot as **73847832-1031-70a6-d142-6fbb72a512f0**.
    We will use this later on in this example when we configure AMG.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.14 – AIC user details](img/B18129_Figure_17.14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.14 – AIC user details
  prefs: []
  type: TYPE_NORMAL
- en: 'Like AMP, AMG is organized around a workspace. The first thing we need to do
    is set up the IAM policies for the workspace to be able to communicate with the
    data sources (in our case, AMP). We will create a role that can be assumed by
    AMG and attach the Prometheus permission to it. An example using Terraform is
    shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have the right IAM permissions for AMG to query Prometheus, we
    can create the workspace and assign the user we created previously (AIC) as an
    admin user. We will set the authentication provider to `AWS_SSO`, and also configure
    Prometheus and CloudWatch references. An example using Terraform is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: This can take several minutes to provision, and you will need to change `user_ids`
    to one you created in your AIC.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we now go to the AMG service in AWS, we will see the new workspace, and
    clicking on the URL under **Grafana workspace URL** will launch the Grafana splash
    page, which we can log in to using the AIC credentials we created and associated
    in the previous steps. An example is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.15 – Grafana workspace launch screen](img/B18129_Figure_17.15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.15 – Grafana workspace launch screen
  prefs: []
  type: TYPE_NORMAL
- en: 'While we have configured the Grafana service to support both Prometheus and
    CloudWatch, we need to configure the data source inside Grafana before we can
    see any metrics. The first step is to click on the AWS icon on the left-hand sidebar
    and click on the **Data sources** link. An example is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.16 – Selecting AWS data sources](img/B18129_Figure_17.16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.16 – Selecting AWS data sources
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, select `myapm` instance we created with Terraform in the *Setting up
    AMP and* *ADOT* section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.17 – Adding an AMP data source](img/B18129_Figure_17.17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.17 – Adding an AMP data source
  prefs: []
  type: TYPE_NORMAL
- en: 'As we now have a data source, we can now use an open source dashboard; we will
    use Kubernetes cluster monitoring (via Prometheus), which has an ID of `3119`.
    If you click the `3119` in the ID and then load and save the dashboards. An example
    is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.18 – Importing open source dashboards from Grafana.com](img/B18129_Figure_17.18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.18 – Importing open source dashboards from Grafana.com
  prefs: []
  type: TYPE_NORMAL
- en: One of the great advantages of Grafana is we can easily consume work from the
    community. The dashboard we just imported, in the example shown next, gives a
    comprehensive view of the cluster, and we can even drill down into individual
    nodes if we want to.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.19 – Kubernetes cluster dashboard](img/B18129_Figure_17.19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.19 – Kubernetes cluster dashboard
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Please make sure you have selected the data source for the AMP instance we added
    previously in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Now we’ve seen how to visualize these metrics with AMG with a community dashboard,
    let’s look at how we can use ADOT to send application trace information.
  prefs: []
  type: TYPE_NORMAL
- en: Tracing with OpenTelemetry
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**OpenTelemetry** (**OTel**) is a CNCF project that provides a standard way
    to send application trace information. Traces become important as you begin to
    build a distributed system as you need to be able to trace a request and response
    through multiple systems. OTel provides a vendor-agnostic instrumentation library
    that can be used to forward trace data to a backend to visualize or analyze the
    data.'
  prefs: []
  type: TYPE_NORMAL
- en: In this book, we will use ADOT as the trace forwarder and AWS X-Ray to analyze
    and visualize the trace data.
  prefs: []
  type: TYPE_NORMAL
- en: Modifying our ADOT configuration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As X-Ray is an AWS service, we first need to modify the service account permissions
    to allow it to send traces to X-Ray, as currently it only has AMP permissions.
    If we view the current `ServiceAccount`, we can get the IAM role, `arn`, as shown
    next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: We can then add X-Ray permission directly to the IAM role, as shown in the next
    figure. We will add the `AWSXRayDaemonWriteAccess` managed policy to allow ADOT
    to write traces and segments.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.20 – Adding X-Ray permissions to ADOT IRSA](img/B18129_Figure_17.20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.20 – Adding X-Ray permissions to ADOT IRSA
  prefs: []
  type: TYPE_NORMAL
- en: 'We now need to modify the ADOT configuration to support OTel and X-Ray. A full
    configuration can be found at [https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/operator/collector-config-xray.yaml](https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/operator/collector-config-xray.yaml),
    with the new receivers, processors, exporters, and pipelines added to the `otel-collector-prometheus.yaml`
    file in the *Setting up AMP and* *ADOT* section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now redeploy the ADOT collector or simply delete it and recreate it,
    but if we check the logs, we can see the new elements have successfully started
    and we will see an `Everything is ready` message. The command and some sample
    output texts are shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Instrumenting your applications to send OTel-based traces can be a complex task
    and as such, is outside the scope of this book. Instead, we will use a simple
    trace emitter provided by OTel to explore what you can do with X-Ray.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to create a K8s namespace to host our emitter; an example
    is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will download, modify, and deploy the sample applications (emitter)
    from [https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/sample-app.yaml](https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/sample-app.yaml).
    You will need to change the elements in the manifest shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we’ve made the changes to the `AWS_REGION`, `OTEL_EXPORTER_OTLP_ENDPOINT`,
    and `OTEL_RESOURCE_ATTRIBUTES` environment variables to point to our modified
    ADOT instance, we can deploy the manifest and validate it is running using the
    commands shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'We now need to generate some traffic. Handily, OTel also provides a traffic
    generator, which is a Pod that runs in the same namespace as the sample application
    and will make queries to the application API, which, in turn, makes calls out
    to `amazon.com`. The command used in the traffic generator Pod is shown next,
    and the full manifest can be downloaded from [https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/traffic-generator.yaml](https://raw.githubusercontent.com/aws-observability/aws-otel-community/master/sample-configs/traffic-generator.yaml):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'We can run this unchanged as long as we haven’t changed the name of the sample
    application service. The commands shown next will deploy the traffic generator
    and start making calls to the sample application API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'If we now go to the X-Ray service in the AWS console, we will be presented
    with a service map that shows our client (the traffic generator Pod) making calls
    to the `emitter` service, which, in turn, makes calls to the remote [aws.amazon.com](http://aws.amazon.com)
    service. The service map can have telemetry for health with health (latency) applied
    on top, which will adjust the size and color of the individual rings. The service
    map gives a very easy way to visualize your services. An example is shown next
    for our emitter/traffic generator deployments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.21 – X-Ray service map](img/B18129_Figure_17.21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.21 – X-Ray service map
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: As the client (traffic generator) code is not instrumented with OTel, we don’t
    have any visibility of its latency, so our trace starts when it reaches the emitter
    service.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can drill down into individual traces to see the different segments to troubleshoot
    or understand the traffic flows in more detail. In the example shown next, we
    can see the two requests/responses – the initial request from the traffic request,
    `GET /outgoing-http-call`, and the time taken for the `aws.amazon.com` response:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.22 – X-Ray trace details](img/B18129_Figure_17.22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.22 – X-Ray trace details
  prefs: []
  type: TYPE_NORMAL
- en: Now we have explored tracing using OTel and X-Ray, we can look at one of the
    more advanced services, DevOps Guru, which uses machine learning models to drive
    into EKS node-level issues.
  prefs: []
  type: TYPE_NORMAL
- en: Using machine learning with DevOps Guru
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DevOps Guru is a fully managed service that uses pre-trained machine learning
    models to baseline resources and gains insights into their use. As it’s fully
    managed, you just need to set it up and allow it to run. To do this, choose the
    **Amazon DevOps Guru** service and click the **Get Started** button. We will choose
    the option to monitor the current account and analyze all the resources and enable
    the service. The screen shown next illustrates the options that were chosen:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.23 – DevOps Guru options](img/B18129_Figure_17.23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.23 – DevOps Guru options
  prefs: []
  type: TYPE_NORMAL
- en: 'We also need to tell DevOps Guru what resources are in scope, as shown in the
    next figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.24 – DevOps Guru setup options](img/B18129_Figure_17.24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.24 – DevOps Guru setup options
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You may need to wait anywhere between 20 and 90 minutes for DevOps Guru to collect
    and review the data.
  prefs: []
  type: TYPE_NORMAL
- en: Once the analysis is complete, the dashboard will be updated with any findings.
    In the example shown next, you can see a service view that shows our EKS cluster
    as healthy.
  prefs: []
  type: TYPE_NORMAL
- en: It’s hard to generate resource issues but DevOps Guru will detect EKS hosts
    that have high memory, CPU, or filesystem utilization, as well as Pod-level metrics
    such as CPU/RAM Pod limit issues, identifying resources that are at risk of producing
    errors due to resource exhaustion. Amazon DevOps Guru also tracks container restarts,
    issues with pulling images, or issues with application startup, which can help
    identify poor code or manifest configurations.
  prefs: []
  type: TYPE_NORMAL
- en: Amazon DevOps Guru has very low operational overhead as you simply enable it
    and let it run, and AWS continues to enhance the underlying ML models to provide
    greater insights, but it does cost, so please review [https://aws.amazon.com/devops-guru/pricing/](https://aws.amazon.com/devops-guru/pricing/)
    before using it.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 17.25 – DevOps Guru summary dashboard](img/B18129_Figure_17.25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 17.25 – DevOps Guru summary dashboard
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have looked at EKS observability, and how you can use a
    variety of AWS services and open source tools to get better insights into your
    clusters, nodes, and applications. We’ll now revisit the key learning points from
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we looked at the different ways to collect and analyze EKS
    logs, metrics, and traces, commonly known as observability. We initially looked
    at how we can install logging and metric agents (fluentBit and CloudWatch, respectively)
    that can easily integrate with the AWS CloudWatch service and Container Insights
    to provide a detailed analysis of this data without deploying any monitoring servers
    or software licenses.
  prefs: []
  type: TYPE_NORMAL
- en: While CloudWatch provides a complete monitoring platform, we also discussed
    how some people want to use open source or non-AWS services for greater flexibility
    and less platform lock-in. Prometheus and Grafana are open source projects that
    offer similar functionality to CloudWatch, and have the advantage of being supported
    by a large community as well, but need to be installed and managed.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we reviewed how we can deploy and configure AMP and AMG to get the flexibility
    of these services but without the operational overhead, and how we can deploy
    ADOT into our cluster to forward K8s /metrics data to AMP. We also deployed a
    community-developed K8s monitoring dashboard from [Grafana.com](http://Grafana.com)
    that can visualize standard K8s metrics, demonstrating how easy it can be to build
    complex visualizations.
  prefs: []
  type: TYPE_NORMAL
- en: We then extended the ADOT configuration to support the collection of OTel traces
    and the forwarding of these to the AWS X-Ray service. We deployed a simple trace
    emitter and traffic generator service in EKS and reviewed the service map and
    segment information in X-Ray to allow us to understand the traffic flow through
    our small microservice architecture from a traffic volume, latency, and error
    perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we enabled Amazon DevOps Guru to provide better analysis, with zero
    operational overhead, in our cluster and nodes within our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at how you can increase resilience and performance
    with cluster scaling tools and approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'EKS observability tools: [https://docs.aws.amazon.com/eks/latest/userguide/eks-observe.html](https://docs.aws.amazon.com/eks/latest/userguide/eks-observe.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Prometheus metrics format: https://prometheus.io/docs/instrumenting/exposition_formats/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More information on Prometheus: [https://prometheus.io/](https://prometheus.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OpenTelemetry in Python: [https://opentelemetry.io/docs/instrumentation/python/](https://opentelemetry.io/docs/instrumentation/python/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
