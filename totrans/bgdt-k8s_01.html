<html><head></head><body>
		<div id="_idContainer013">
			<h1 class="chapter-number" id="_idParaDest-15"><a id="_idTextAnchor015"/>1</h1>
			<h1 id="_idParaDest-16"><a id="_idTextAnchor016"/>Getting Started  with Containers</h1>
			<p>The world is rapidly generating massive amounts of data from a variety of sources – mobile devices, social media, e-commerce transactions, sensors, and more. This data explosion<a id="_idIndexMarker000"/> is often referred to as “big data.” While big data presents immense opportunities for businesses and organizations to gain valuable insights, it also brings tremendous complexity in how to store, process, analyze, and extract value from huge volumes of <span class="No-Break">diverse data.</span></p>
			<p>This is where Kubernetes comes in. Kubernetes is an open source container orchestration system that helps automate the deployment, scaling, and management of containerized applications. Kubernetes brings important advantages for building big data systems. It provides a standard way to deploy containerized big data applications on any infrastructure. This makes it easy to migrate applications across on-premises servers or cloud providers. It also makes it simple to scale big data applications up or down based on demand. Additional containers can be spun up or shut down automatically based <span class="No-Break">on usage.</span></p>
			<p>Kubernetes helps ensure the high availability of big data applications through features such as self-healing and auto-restarting of failed containers. It also provides a unified way to deploy, monitor, and manage different big data components. This reduces operational complexity compared to managing each <span class="No-Break">system separately.</span></p>
			<p>This book aims to provide you with practical skills for leveraging Kubernetes to build robust and scalable big data pipelines. You will learn how to containerize and deploy popular big data tools such as Spark, Kafka, Airflow, and more on Kubernetes. The book covers architectural best practices and hands-on examples for building batch and real-time <span class="No-Break">data pipelines.</span></p>
			<p>By the end, you will gain an end-to-end view of running big data workloads on Kubernetes and be equipped to build efficient data platforms that power analytics and artificial intelligence applications. The knowledge you will gain will be of immense value whether you are a data engineer, data scientist, DevOps engineer, or technology leader driving digital transformation in <span class="No-Break">your organization.</span></p>
			<p>The foundation of Kubernetes is containers. Containers are one of the most used technologies in data engineering today. They allow engineers to package software into standardized units for development, shipment, and deployment. By the end of this chapter, you will understand the basics of containers and be able to build and run your own containers <span class="No-Break">using Docker.</span></p>
			<p>In this chapter, we will cover what containers are, why they are useful, and how to create and run containers on your local machine using Docker. Containers solve many problems that developers face when moving applications between environments. They ensure that the application and its dependencies are packaged together and isolated from the underlying infrastructure. This allows the application to run quickly and reliably from one computing environment <span class="No-Break">to another.</span></p>
			<p>We will start by installing Docker, a platform for building and running containers, on your local system. We will run simple Docker images and learn the basic Docker commands. We will then build our first Docker image containing a simple Python application. We will learn how to define a Dockerfile to efficiently specify the environment and dependencies for our application. We will then run our image as a container and explore how to access the application and check <span class="No-Break">its logs.</span></p>
			<p>Containers are a key technology for modern software deployment. They are lightweight, portable, and scalable, allowing you to build and ship applications faster. The concepts and skills you will learn in this chapter will provide a strong foundation for working with containers and deploying data applications. By the end of this chapter, you will be ready to start building and deploying your own containerized data processing jobs, APIs, and data <span class="No-Break">engineering tools.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li><span class="No-Break">Container architecture</span></li>
				<li><span class="No-Break">Installing Docker</span></li>
				<li>Getting started with <span class="No-Break">Docker images</span></li>
				<li>Building your <span class="No-Break">own image</span></li>
			</ul>
			<h1 id="_idParaDest-17"><a id="_idTextAnchor017"/>Technical requirements</h1>
			<p>For this chapter, you should have Docker installed. Also, a computer with a minimum of 4 GB of RAM (8 GB is recommended) is required, as Docker can really consume a <span class="No-Break">computer’s memory.</span></p>
			<p>The code for this chapter is available on GitHub. Please refer to <a href="https://github.com/PacktPublishing/Bigdata-on-Kubernetes">https://github.com/PacktPublishing/Bigdata-on-Kubernetes</a> and access the <span class="No-Break"><strong class="source-inline">Chapter01</strong></span><span class="No-Break"> folder.</span></p>
			<h1 id="_idParaDest-18"><a id="_idTextAnchor018"/>Container architecture</h1>
			<p>Containers are an operating system-level virtualization<a id="_idIndexMarker001"/> method that we can use to run multiple isolated processes on a single host machine. Containers allow applications to run in an isolated environment with their own dependencies, libraries, and configuration files <a id="_idIndexMarker002"/>without the overhead of a full <strong class="bold">virtual machine</strong> (<strong class="bold">VM</strong>), which makes them lighter and <span class="No-Break">more efficient.</span></p>
			<p>If we compare containers to traditional VMs, they differ in a few ways. VMs virtualize at the hardware level, creating a full virtual operating system. Containers, on the other hand, virtualize at the operating system level. Because of that, containers share the host system’s kernel, whereas VMs each have their own kernel. This allows containers to have much faster startup times, typically in milliseconds compared to minutes for VMs (it is worth noting that in a Linux environment, Docker can leverage the capabilities of a Linux kernel directly. While running in a Windows system, however, it runs in a lightweight Linux VM that is still lighter than a <span class="No-Break">full VM).</span></p>
			<p>Also, containers have better resource isolation as they only isolate the application layer, whereas VMs isolate an entire operating system. Containers are immutable infrastructure, making them more portable and consistent as updates create new container images (versions) rather than updating <span class="No-Break">in place.</span></p>
			<p>Due to these differences, containers allow higher density, faster startup times, and lower resource usage compared to VMs. A single server can run dozens or hundreds of containerized applications isolated from <span class="No-Break">each other.</span></p>
			<p>Docker is one of the most popular container platforms that provides tools to build, run, deploy, and manage containers. Docker architecture consists of the Docker client, Docker daemon, Docker registry, and <span class="No-Break">Docker images.</span></p>
			<p>The Docker client is a <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>) client used to interact<a id="_idIndexMarker003"/> with the Docker daemon to build, run, and manage containers. This interaction occurs through a <span class="No-Break">REST API.</span></p>
			<p>The Docker daemon is a background service that runs on the host machine and manages building, running, and distributing containers. It is the base for all the containers to <span class="No-Break">run on.</span></p>
			<p>The Docker registry<a id="_idIndexMarker004"/> is a repository to host, distribute, and download Docker images. Docker Hub is the default public registry with many pre-built images, but cloud providers usually have their own private container registry <span class="No-Break">as well.</span></p>
			<p>Finally, Docker images are read-only templates used to create Docker containers. Images define the container environment, dependencies, operating system, environment variables, and everything that a container needs <span class="No-Break">to run.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 1</em></span><em class="italic">.1</em> shows the difference between an application running in a VM and an application running in <span class="No-Break">a container.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer010">
					<img alt="Figure 1.1 – VMs versus containers" src="image/B21927_01_01.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – VMs versus containers</p>
			<p><span class="No-Break"><em class="italic">Figure 1</em></span><em class="italic">.2</em> shows how<a id="_idIndexMarker005"/> a container<a id="_idIndexMarker006"/> runs with separate layer<a id="_idIndexMarker007"/> levels. There is the shared kernel at the bottom. On top of that, we have as many operating systems as we need. On top of the Debian OS layer, we see a Java 8 image and an NGINX image. The Java 8 layer is shared by three containers, one of them with only the image information and two using another image, Wildfly. The figure demonstrates why the container architecture is so efficient in sharing resources and lightweight because it is built upon layers of libraries, dependencies, and applications that will run isolated <a id="_idIndexMarker008"/>from <span class="No-Break">each other.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer011">
					<img alt="Figure 1.2 – Container layers" src="image/B21927_01_02.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – Container layers</p>
			<p>Now, let’s get to it. In the next section, you will learn how to install Docker and run your first Docker <span class="No-Break">CLI commands.</span></p>
			<h1 id="_idParaDest-19"><a id="_idTextAnchor019"/>Installing Docker</h1>
			<p>To get started with Docker, you<a id="_idIndexMarker009"/> can install it by using the package manager for your Linux distribution or install Docker Desktop for <span class="No-Break">Mac/Windows machines.</span></p>
			<h2 id="_idParaDest-20"><a id="_idTextAnchor020"/>Windows</h2>
			<p>To use Docker Desktop<a id="_idIndexMarker010"/> on Windows, you<a id="_idIndexMarker011"/> must turn on the WSL 2 feature. Refer to this link<a id="_idIndexMarker012"/> for detailed <span class="No-Break">instructions: </span><a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10"><span class="No-Break">https://docs.microsoft.com/en-us/windows/wsl/install-win10</span></a><span class="No-Break">.</span></p>
			<p>After that, you can install Docker Desktop <span class="No-Break">as follows:</span></p>
			<ol>
				<li>Go to <a href="https://www.docker.com/products/docker-desktop">https://www.docker.com/products/docker-desktop</a> and download <span class="No-Break">the installer.</span></li>
				<li>When the download is ready, double-click the installer and follow <span class="No-Break">the prompts.</span><p class="list-inset">You should ensure that the <strong class="bold">Use WSL 2 instead of Hyper-V</strong> option is selected on the <strong class="bold">Configuration</strong> page. This is the recommended usage. (If your system does not support WSL 2, this option will not be available. You can still run Docker with <span class="No-Break">Hyper-V, though.)</span></p></li>
				<li>After the installation<a id="_idIndexMarker013"/> is finished, close to complete and start<a id="_idIndexMarker014"/> <span class="No-Break">Docker Desktop.</span></li>
			</ol>
			<p>If you have any doubts, refer<a id="_idIndexMarker015"/> to the official <span class="No-Break">documentation: </span><a href="https://docs.docker.com/desktop/install/windows-install/"><span class="No-Break">https://docs.docker.com/desktop/install/windows-install/</span></a><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-21"><a id="_idTextAnchor021"/>macOS</h2>
			<p>The installation<a id="_idIndexMarker016"/> of Docker Desktop<a id="_idIndexMarker017"/> on macOS is <span class="No-Break">quite simple:</span></p>
			<ol>
				<li>Go to <a href="https://www.docker.com/products/docker-desktop">https://www.docker.com/products/docker-desktop</a> and download the installer <span class="No-Break">for macOS.</span></li>
				<li>Double-click the installer and follow the prompts to install <span class="No-Break">Docker Desktop.</span></li>
				<li>Once the installation completes, Docker Desktop will <span class="No-Break">start automatically.</span></li>
			</ol>
			<p>Docker Desktop runs natively on macOS using the HyperKit VM and does not need additional configuration. When Docker Desktop starts for the first time, it will prompt you to authorize it for drive access. Authorize Docker Desktop to allow it to access files on <span class="No-Break">your filesystem.</span></p>
			<h2 id="_idParaDest-22"><a id="_idTextAnchor022"/>Linux</h2>
			<p>Installing Docker on Linux-based systems<a id="_idIndexMarker018"/> is very straightforward. You can use<a id="_idIndexMarker019"/> your Linux distribution package manager to do that with just a few commands. For Ubuntu, for instance, the first thing is to remove any older versions of Docker that you previously had on <span class="No-Break">the machine:</span></p>
			<pre class="console">
$ sudo apt-get remove docker docker-engine docker.io containerd runc</pre>			<p>You can install Docker from the default <strong class="source-inline">apt</strong> repository using <span class="No-Break">the following:</span></p>
			<pre class="source-code">
$ sudo apt install docker.io</pre>			<p>This will install a slightly older version of Docker. If you want<a id="_idIndexMarker020"/> the latest version, check the official Docker website (<a href="https://docs.docker.com/desktop/install/linux-install/">https://docs.docker.com/desktop/install/linux-install/</a>) and follow <span class="No-Break">the instructions.</span></p>
			<p>If you want to use Docker without having to <strong class="source-inline">sudo</strong> commands, run the <span class="No-Break">following commands:</span></p>
			<pre class="console">
$ sudo groupadd docker
$ sudo usermod –aG docker &lt;YOUR_USERNAME&gt;</pre>			<p>Now, let’s get hands-on practice <span class="No-Break">with Docker.</span></p>
			<h1 id="_idParaDest-23"><a id="_idTextAnchor023"/>Getting started with Docker images</h1>
			<p>The very first Docker image<a id="_idIndexMarker021"/> we can run is the <strong class="source-inline">hello-world</strong> image. It is often used to test whether Docker is correctly installed <span class="No-Break">and running.</span></p>
			<h2 id="_idParaDest-24"><a id="_idTextAnchor024"/>hello-world</h2>
			<p>After the installation, open<a id="_idIndexMarker022"/> the terminal (Command Prompt in Windows) and run <span class="No-Break">the following:</span></p>
			<pre class="console">
$ docker run hello-world</pre>			<p>This command will pull the <strong class="source-inline">hello-world</strong> image from the Docker Hub public repository and run the application in it. If you can run it successfully, you will see <span class="No-Break">this output:</span></p>
			<pre class="console">
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
70f5ac315c5a: Pull complete
Digest: sha256:88ec0acaa3ec199d3b7eaf73588f4518c25 f9d34f58ce9a0df68429c5af48e8d
Status: Downloaded newer image for hello-world:latest
Hello from Docker!
This message shows that your installation appears to be working correctly.
To generate this message, Docker took the following steps:
 1. The Docker client contacted the Docker daemon.
 2. The Docker daemon pulled the "hello-world" image from the Docker Hub.
 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading.
 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.
To try something more ambitious, you can run an Ubuntu container with:
 $ docker run -it ubuntu bash
Share images, automate workflows, and more with a free Docker ID:
 https://hub.docker.com/
For more examples and ideas, visit:
 https://docs.docker.com/get-started/</pre>			<p>Congratulations! You just<a id="_idIndexMarker023"/> ran your first Docker image!  Now, let’s try something a little <span class="No-Break">more ambitious.</span></p>
			<h2 id="_idParaDest-25"><a id="_idTextAnchor025"/>NGINX</h2>
			<p>NGINX is a well-known open<a id="_idIndexMarker024"/> source software<a id="_idIndexMarker025"/> for web serving, reverse proxying, and caching. It is widely used in <span class="No-Break">Kubernetes-based architectures.</span></p>
			<p>Different from the <strong class="source-inline">hello-world</strong> application (which behaves like a job execution), NGINX behaves like a service. It opens a port and keeps listening for user requests. We can start by searching for the available NGINX images in Docker Hub using <span class="No-Break">the following:</span></p>
			<pre class="source-code">
$ docker search nginx</pre>			<p>The output will show several available images. Usually, the first in the list is the official image. Now, to set up a running NGINX container, we can use the <span class="No-Break">following command:</span></p>
			<pre class="source-code">
$ docker pull nginx:latest</pre>			<p>This will download the current latest version of the image. The <strong class="source-inline">latest</strong> keyword after the colon stands for the “tag” of this image. To install a specific version (recommended), specify the tag <span class="No-Break">like this:</span></p>
			<pre class="source-code">
$ docker pull nginx:1.25.2-alpine-slim</pre>			<p>You can visit <a href="https://hub.docker.com/_/nginx">https://hub.docker.com/_/nginx</a> to check for all the <span class="No-Break">available tags.</span></p>
			<p>Now, to run the container, you should specify which version of the image you want to use. The following command will do <span class="No-Break">the trick:</span></p>
			<pre class="source-code">
$ docker run --name nginxcontainer –p 80:80 nginx:1.25.2-alpine-slim</pre>			<p>You will start to see NGINX logs in the terminal. Then, open your preferred browser and type <strong class="source-inline">http://localhost/</strong>. You should see this message (<span class="No-Break"><em class="italic">Figure 1</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">):</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer012">
					<img alt="Figure 1.3 – The nginx default output in the browser" src="image/B21927_01_3.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – The nginx default output in the browser</p>
			<p>The <strong class="source-inline">docker run</strong> command has a few important parameters. <strong class="source-inline">--name</strong> defines the name of the container that will run. If you don’t define a name, Docker will automatically choose a name for it (trust me, it can be very creative). <strong class="source-inline">-p</strong> connects a port on your machine (port <strong class="source-inline">80</strong>) to a port inside the container (also <strong class="source-inline">80</strong>). If you do not open this port, you won’t be able to reach the container’s <span class="No-Break">running application.</span></p>
			<p>After your test is successful, get back to the terminal running the container and press “CTRL + C” to stop the container. After it stops, it will still be there, although not running. To remove the container, use <span class="No-Break">the following:</span></p>
			<pre class="source-code">
$ docker rm nginxcontainer</pre>			<p>If you are in doubt, you can see all the running and stopped containers with <span class="No-Break">this command:</span></p>
			<pre class="source-code">
$ docker ps –a</pre>			<p>We also can see all the locally available images with <span class="No-Break">this command:</span></p>
			<pre class="source-code">
$ docker images</pre>			<p>In my case, the output shows three<a id="_idIndexMarker026"/> images: <strong class="source-inline">hello-world</strong> and two NGINX images, one of <a id="_idIndexMarker027"/>them with the <strong class="source-inline">latest</strong> tag and the other with the <strong class="source-inline">1.25.2-alpine-slim</strong> tag. All images and their respective versions <span class="No-Break">will show.</span></p>
			<h2 id="_idParaDest-26"><a id="_idTextAnchor026"/>Julia</h2>
			<p>In this last example, we will<a id="_idIndexMarker028"/> learn how<a id="_idIndexMarker029"/> to use technology that is not installed in our machine by interacting with running containers. We will run a container with a new and efficient programming language for data science called Julia. To do that, execute the <span class="No-Break">following command:</span></p>
			<pre class="source-code">
$ docker run -it --rm julia:1.9.3-bullseye</pre>			<p>Note that the <strong class="source-inline">docker run</strong> command looks for a local image. If it’s not downloaded, Docker will automatically pull the image from Docker Hub. With the preceding command, we will start an interactive session in a Julia 1.9.3 container. The <strong class="source-inline">-it</strong> parameters allow us to use it interactively. The <strong class="source-inline">--rm</strong> parameter states that the container will automatically be removed after it is stopped, so we don’t have to manually <span class="No-Break">remove it.</span></p>
			<p>After the container is up and running, let’s play with a simple custom function to calculate two descriptive statistics: a mean and a standard deviation. You will see a Julia’s logo in the terminal, and you can use <span class="No-Break">the following:</span></p>
			<pre class="source-code">
$ using Statistics
$ function descriptive_statistics(x)
    m = mean(x)
    sd = std(x)
    return Dict("mean" =&gt; m, "std_dev" =&gt; sd)
  end</pre>			<p>After defining the function, we will run it with a small array of <span class="No-Break">random numbers:</span></p>
			<pre class="source-code">
$ myvector = rand(5)
$ descriptive_statistics(myvector)</pre>			<p>You should see the proper output on the screen. Congratulations! You have just used the Julia programming language without having to install or configure it on your computer with Docker! To exit the container, use <span class="No-Break">the following:</span></p>
			<pre class="source-code">
$ exit()</pre>			<p>As we used the <strong class="source-inline">--rm</strong> parameter, if we run<a id="_idIndexMarker030"/> the <strong class="source-inline">docker ps -a</strong> command, we will see that<a id="_idIndexMarker031"/> it has been <span class="No-Break">automatically removed.</span></p>
			<h1 id="_idParaDest-27"><a id="_idTextAnchor027"/>Building your own image</h1>
			<p>Now, we will customize<a id="_idIndexMarker032"/> our own container images for running a simple data processing job and an <span class="No-Break">API service.</span></p>
			<h2 id="_idParaDest-28"><a id="_idTextAnchor028"/>Batch processing job</h2>
			<p>Here is a simple<a id="_idIndexMarker033"/> Python code<a id="_idIndexMarker034"/> for a batch <span class="No-Break">processing job:</span></p>
			<p><span class="No-Break"><strong class="bold">run.py</strong></span></p>
			<pre class="source-code">
import pandas as pd
url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'
df = pd.read_csv(url, header=None)
df["newcolumn"] = df[5].apply(lambda x: x*2)
print(df.columns)
print(df.head())
print(df.shape)</pre>			<p>This Python code loads a CSV dataset from a URL into a pandas DataFrame, adding a new column by multiplying an existing column by 2 and then printing out some information about the DataFrame (column names, first five rows, and size of the DataFrame). Type this code using your favorite code editor and save the file with the <span class="No-Break">name </span><span class="No-Break"><strong class="source-inline">run.py</strong></span><span class="No-Break">.</span></p>
			<p>Normally, we test our code locally (whenever possible) to be sure it is working. To do that, first, you need to install the <span class="No-Break"><strong class="source-inline">pandas</strong></span><span class="No-Break"> library:</span></p>
			<pre class="source-code">
pip3 install pandas</pre>			<p>Then, run the code with <span class="No-Break">the following:</span></p>
			<pre class="source-code">
python3 run.py</pre>			<p>If all goes well, you should see an output <span class="No-Break">like this:</span></p>
			<pre class="console">
Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 'newcolumn'], dtype='object')
   0    1   2   3    4     5      6   7  8  newcolumn
0  6  148  72  35    0  33.6  0.627  50  1       67.2
1  1   85  66  29    0  26.6  0.351  31  0       53.2
2  8  183  64   0    0  23.3  0.672  32  1       46.6
3  1   89  66  23   94  28.1  0.167  21  0       56.2
4  0  137  40  35  168  43.1  2.288  33  1       86.2
(768, 10)</pre>			<p>Now, we are ready<a id="_idIndexMarker035"/> to package<a id="_idIndexMarker036"/> our simple processing job into a container. Let’s start by defining <span class="No-Break">a Dockerfile:</span></p>
			<p><span class="No-Break"><strong class="bold">Dockerfile_job</strong></span></p>
			<pre class="source-code">
FROM python:3.11.6-slim
RUN pip3 install pandas
COPY run.py /run.py
CMD python3 /run.py</pre>			<p>Those are the only four lines we need to define a working container. The first line specifies the base image to use, which is a slim version of <strong class="source-inline">Python 3.11.6</strong>. This is a Debian-based OS that already has <strong class="source-inline">Python 3.11.6</strong> installed, which can save us a lot of time. Using a slim image is very important to keep the container size small and optimize transfer time and storage costs (when it’s <span class="No-Break">the case).</span></p>
			<p>The second line installs the <strong class="source-inline">pandas</strong> library. The third line copies the local <strong class="source-inline">run.py</strong> file into the container. Finally, the last line sets the default command to run when the container starts to execute the <strong class="source-inline">/run.py</strong> script. After you are done defining the code, save it as <strong class="source-inline">Dockerfile_job</strong> (no <strong class="source-inline">.extension</strong>). Now, it’s time to build our <span class="No-Break">Docker image:</span></p>
			<pre class="source-code">
docker build -f Dockerfile_job -t data_processing_job:1.0 .</pre>			<p>The <strong class="source-inline">docker build</strong> command<a id="_idIndexMarker037"/> builds an image according to the Dockerfile<a id="_idIndexMarker038"/> instructions. Usually, this command expects a file named <strong class="source-inline">Dockerfile</strong>. Since we are working with a filename different from expected, we must tell Docker which file to use with the <strong class="source-inline">-f</strong> flag. The <strong class="source-inline">-t</strong> flag defines a tag for the image. It is composed of a name and a version, separated by a colon (<strong class="source-inline">:</strong>). In this case, the name we set for the image is <strong class="source-inline">data_processing_job</strong> and a <strong class="source-inline">1.0</strong> version. The last parameter to this command is the path where code files are located. Here, we set the current folder with a dot (<strong class="source-inline">.</strong>). This dot is very easy to forget, so <span class="No-Break">be careful!</span></p>
			<p>After the build is finished, we can check the locally available images with <span class="No-Break">this command:</span></p>
			<pre class="source-code">
docker images</pre>			<p>You should see the first line of the output showing your recently built data <span class="No-Break">processing image:</span></p>
			<pre class="source-code">
REPOSITORY       TAG  IMAGE ID      CREATED        SIZE
data_process...  1.0  39bae1eb068c  6 minutes ago  351MB</pre>			<p>Now, to run our data processing job from inside the container, use <span class="No-Break">this command:</span></p>
			<pre class="source-code">
docker run --name data_processing data_processing_job:1.0</pre>			<p>The <strong class="source-inline">docker run</strong> command runs the specified image. The <strong class="source-inline">--name</strong> flag defines the name of the container as <strong class="source-inline">data_processing</strong>. After you start running the container, you should see the same output <span class="No-Break">as before:</span></p>
			<pre class="source-code">
Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 'newcolumn'], dtype='object')
   0    1   2   3    4     5      6   7  8  newcolumn
0  6  148  72  35    0  33.6  0.627  50  1       67.2
1  1   85  66  29    0  26.6  0.351  31  0       53.2
2  8  183  64   0    0  23.3  0.672  32  1       46.6
3  1   89  66  23   94  28.1  0.167  21  0       56.2
4  0  137  40  35  168  43.1  2.288  33  1       86.2
(768, 10)</pre>			<p>Finally, don’t forget to remove the exited containers from <span class="No-Break">your environment:</span></p>
			<pre class="source-code">
docker ps –a
docker rm data_processing</pre>			<p>Congrats! You have run<a id="_idIndexMarker039"/> your first job<a id="_idIndexMarker040"/> using containers. Now, let’s move to another type of containerized application: <span class="No-Break">a service.</span></p>
			<h2 id="_idParaDest-29"><a id="_idTextAnchor029"/>API service</h2>
			<p>In this section, we will use <strong class="bold">FastAPI</strong> to develop a simple<a id="_idIndexMarker041"/> API <a id="_idIndexMarker042"/>with Python. Open a Python<a id="_idIndexMarker043"/> script in your favorite code editor, create a folder named <strong class="source-inline">app</strong>, and create a Python script <span class="No-Break">named </span><span class="No-Break"><strong class="source-inline">main.py</strong></span><span class="No-Break">.</span></p>
			<p>In the script, first, we import FastAPI and the <span class="No-Break">random module:</span></p>
			<pre class="source-code">
from fastapi import FastAPI
import random</pre>			<p>Next, we create an instance of the <span class="No-Break">FastAPI app:</span></p>
			<pre class="source-code">
app = FastAPI()</pre>			<p>The next code block defines a route using the <strong class="source-inline">@</strong><span class="No-Break"><strong class="source-inline">app.get</strong></span><span class="No-Break"> decorator:</span></p>
			<pre class="source-code">
@app.get("/api")
async def root():
    return {"message": "You are doing great with FastAPI..."}</pre>			<p>The <strong class="source-inline">@app.get</strong> decorator indicates<a id="_idIndexMarker044"/> that this is a <strong class="source-inline">GET</strong> endpoint. This function is defined<a id="_idIndexMarker045"/> to answer at the <strong class="source-inline">"/api"</strong> route. It just returns a pleasant message on request of <span class="No-Break">the route.</span></p>
			<p>The next code chunk defines a route, <strong class="source-inline">"/api/{name}"</strong>, where <strong class="source-inline">name</strong> is a parameter that will be received in the request. It returns a greeting message with the <span class="No-Break">given name:</span></p>
			<pre class="source-code">
@app.get("/api/{name}")
async def return_name(name):
    return {
        "name": name,
        "message": f"Hello, {name}!"
    }</pre>			<p>The last code block defines a <strong class="source-inline">"/joke"</strong> route. This function returns a (very funny!) random joke from the list of jokes previously defined. Feel free to replace them with your own <span class="No-Break">cool jokes:</span></p>
			<pre class="source-code">
@app.get("/joke")
async def return_joke():
    jokes = [
        "What do you call a fish wearing a bowtie? Sofishticated.",
        "What did the ocean say to the beach? Nothing. It just waved",
        "Have you heard about the chocolate record player? It sounds pretty sweet."
    ]
    return {
        "joke": random.choice(jokes)
    }</pre>			<p>It is important to notice that every function returns a response in JSON format. This is a very common pattern with APIs. For the whole Python code, refer to the book’s GitHub <span class="No-Break">repository (</span><a href="https://github.com/PacktPublishing/Bigdata-on-Kubernetes"><span class="No-Break">https://github.com/PacktPublishing/Bigdata-on-Kubernetes</span></a><span class="No-Break">).</span></p>
			<p>Before we build<a id="_idIndexMarker046"/> the Docker<a id="_idIndexMarker047"/> image, it is advised to test the code locally (whenever possible). To do this, you must install the <strong class="source-inline">fastapi</strong> and <strong class="source-inline">uvicorn</strong> packages. Run this command in <span class="No-Break">the terminal:</span></p>
			<pre class="source-code">
pip3 install fastapi uvicorn</pre>			<p>To run the API, use <span class="No-Break">the following:</span></p>
			<pre class="source-code">
uvicorn app.main:app --host 0.0.0.0 --port 8087</pre>			<p>If all goes well, you will see an output like this in <span class="No-Break">the terminal:</span></p>
			<pre class="console">
INFO:  Started server process [14417]
INFO:  Waiting for application startup.
INFO:  Application startup complete.
INFO:  Uvicorn running on http://0.0.0.0:8087 (Press CTRL+C to quit)</pre>			<p>This command runs the API service locally on port <strong class="source-inline">8087</strong>. To test it, open a browser and access <strong class="source-inline">http://localhost:8087/api</strong>. You should see the programmed message on the screen. Test the <strong class="source-inline">http://localhost:8087/api/&lt;YOUR_NAME&gt;</strong> and <strong class="source-inline">http://localhost:8087/joke</strong> endpoints <span class="No-Break">as well.</span></p>
			<p>Now that we know everything<a id="_idIndexMarker048"/> is working<a id="_idIndexMarker049"/> fine, let’s package the API in a Docker image. To do that, we will build a simple Dockerfile. To optimize it, we will use the <strong class="source-inline">alpine</strong> linux distribution, an extremely lightweight base OS. In the root folder of your project, create a new file named <strong class="source-inline">Dockerfile</strong> (no <strong class="source-inline">.extension</strong>). This is the code we will use for <span class="No-Break">this image:</span></p>
			<p><span class="No-Break"><strong class="bold">Dockerfile</strong></span></p>
			<pre class="source-code">
FROM python:3.11-alpine
RUN pip3 --no-cache-dir install fastapi uvicorn
EXPOSE 8087
COPY ./app /app
CMD uvicorn app.main:app --host 0.0.0.0 --port 8087</pre>			<p>The first line imports a Python container based on the <strong class="source-inline">alpine</strong> Linux distribution. The second line installs <strong class="source-inline">fastapi</strong> and <strong class="source-inline">uvicorn</strong>. The third line informs Docker that the container will listen on port <strong class="source-inline">8087</strong> at runtime. Without this command, we would not be able to access the API service. The fourth line copies all the code inside our local <strong class="source-inline">/app</strong> folder to a <strong class="source-inline">/app</strong> folder inside the container. Finally, the <strong class="source-inline">CMD</strong> command specifies the command to run when the container starts. Here, we are starting the <strong class="source-inline">uvicorn</strong> server to run our FastAPI application. After <strong class="source-inline">uvicorn</strong>, we state a location pattern of <strong class="source-inline">folder.script_name:FastAPI_object_name</strong> to tell FastAPI where to look for the API <span class="No-Break">process object.</span></p>
			<p>When this Dockerfile is built into an image, we will have a containerized Python application configured to run a FastAPI web server on port <strong class="source-inline">8087</strong>. The Dockerfile allows us to package up the application and its dependencies into a standardized unit for deployment. To build the image, run <span class="No-Break">the following:</span></p>
			<pre class="source-code">
docker build -t my_api:1.0 .</pre>			<p>No need to specify the <strong class="source-inline">-f</strong> flag here since we are using a Dockerfile with the default name. And remember the dot at the end of <span class="No-Break">the line!</span></p>
			<p>Now, we run the container with a slightly different set <span class="No-Break">of parameters:</span></p>
			<pre class="source-code">
docker run -p 8087:8087 -d --rm --name api my_api:1.0</pre>			<p>The <strong class="source-inline">-p</strong> parameter sets that we will open port <strong class="source-inline">8087</strong> in the server (in this case, your computer) to port <strong class="source-inline">8087</strong> in the container. If we don’t set this parameter, there is no way to communicate with the container whatsoever. The <strong class="source-inline">-d</strong> parameter runs the container in <em class="italic">detached</em> mode. The terminal will not be showing container logs but it will be available for use while the container is running in the background. The <strong class="source-inline">--rm</strong> parameter sets the container to be automatically removed after it is finished (very handy). Finally, <strong class="source-inline">--name</strong> sets the name for the container <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">api</strong></span><span class="No-Break">.</span></p>
			<p>We can check whether<a id="_idIndexMarker050"/> the container<a id="_idIndexMarker051"/> is correctly running with <span class="No-Break">the following:</span></p>
			<pre class="source-code">
docker ps –a</pre>			<p>If you need to check the logs to a container, use <span class="No-Break">the following:</span></p>
			<pre class="source-code">
docker logs api</pre>			<p>You should see an output similar <span class="No-Break">to this:</span></p>
			<pre class="source-code">
INFO:  Started server process [1]
INFO:  Waiting for application startup.
INFO:  Application startup complete.
INFO:  Uvicorn running on http://0.0.0.0:8087 (Press CTRL+C to quit)</pre>			<p>Now, we can test our API endpoints in the browser with the same links shown before (<strong class="source-inline">http://localhost:8087/api, http://localhost:8087/api/&lt;YOUR_NAME&gt;</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">http://localhost:8087/joke</strong></span><span class="No-Break">).</span></p>
			<p>Congrats! You are running your API service from inside a container. This is a completely portable and self-contained application that can be <span class="No-Break">deployed anywhere.</span></p>
			<p>To stop the API service, use <span class="No-Break">the following:</span></p>
			<pre class="source-code">
docker stop api</pre>			<p>To check that the stopped<a id="_idIndexMarker052"/> container has been automatically<a id="_idIndexMarker053"/> removed, use <span class="No-Break">the following:</span></p>
			<pre class="source-code">
docker ps -a</pre>			<p><span class="No-Break">Nicely done!</span></p>
			<h1 id="_idParaDest-30"><a id="_idTextAnchor030"/>Summary</h1>
			<p>In this chapter, we covered the fundamentals of containers and how to build and run them using Docker. Containers provide a lightweight and portable way to package applications and their dependencies so they can run reliably <span class="No-Break">across environments.</span></p>
			<p>You learned about key concepts such as images, containers, Dockerfiles, and registries. We installed Docker and ran simple containers such as NGINX and Julia to get hands-on experience. You built your own containers for a batch processing job and API service, defining Dockerfiles to <span class="No-Break">package dependencies.</span></p>
			<p>These skills allow you to develop applications and containerize them for smooth deployment anywhere. Containers are super useful as they ensure your software runs exactly as intended <span class="No-Break">every time.</span></p>
			<p>In the next chapter, we will look at orchestrating containers using Kubernetes to easily scale, monitor, and manage containerized applications. We will take a look at the most important Kubernetes concepts and components and learn how to implement them with YAML <span class="No-Break">files (manifests).</span></p>
		</div>
	</body></html>