- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: K3s Homelab for Edge Computing Experiments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, we have explored essential topics to create your own edge computing
    cluster. The previous chapters covered how to configure and install a K3s cluster.
    Building small and big solutions at home involves experimenting. In this chapter,
    we are going to start building a simple but real cluster, using the knowledge
    acquired in the previous chapters. We will refer to this environment as the K3s
    homelab. Once this cluster is created, we are going to deploy a simple application.
    We will use this as a quickstart method of using Kubernetes with your cluster.
    In the last part of this chapter, we are going to use the Kubernetes dashboard
    as a simple UI to manage Kubernetes clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing a multi-node K3s cluster on your local network
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying your first application with `kubectl`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a simple NGINX server using YAML files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adding persistence to your applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a Kubernetes dashboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you need the following hardware to create your K3s homelab
    for your edge computing applications or experiments:'
  prefs: []
  type: TYPE_NORMAL
- en: Two or more Raspberry Pi 4 B models with a minimum of 4 GB RAM and a 32 GB microSD
    card with Ubuntu version 20.04 or later. The SanDisk Extreme microSDHC 32 GB UHS-1
    A1 V30 or similar is recommended as the microSD card.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ethernet cables to connect your Raspberries.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An Ethernet internet connection for the Raspberries with **Dynamic Host Configuration
    Protocol** (**DHCP**) activated.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: One switch to connect your Raspberry to your local network.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this hardware, we are ready to start building our K3s homelab. So, let's
    get started.
  prefs: []
  type: TYPE_NORMAL
- en: 'For more detail and code snippets, check out this resource on GitHub: [https://github.com/PacktPublishing/Edge-Computing-Systems-with-Kubernetes/tree/main/ch5](https://github.com/PacktPublishing/Edge-Computing-Systems-with-Kubernetes/tree/main/ch5)'
  prefs: []
  type: TYPE_NORMAL
- en: Installing a multi-node K3s cluster on your local network
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To start creating this homelab, let''s understand the network topology that
    we are going to use. Each component in the following diagram is used in the homelab:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Homelab architecture'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16945_Figure_5.1.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.1 – Homelab architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a small explanation of each component in the figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '`192.168.0.0/24`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Switch**: A switch is also a network connecting device that connects various
    devices in the same network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Router**: A router connects devices across multiple networks. Typically,
    home routers are hybrid devices that give local computers access to the internet.
    It also has small switch capabilities to connect local computers, using wireless
    or Ethernet ports for your wired devices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Public Interface**: This is the interface of your router that has a public
    IP.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Gateway**: This is an IP address that is used as the gateway in your private
    network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`8.8.8.8` and `1.1.1.1`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Master**: This is the master node of your K3s cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Agent**: This is the agent node that acts as a worker in your K3s cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubectl` command.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now – a small explanation about how these pieces interact with each other. All
    your machines will use the `192.168.0.0/24` network; in this case, let's think
    that your client will use the `192.168.0.2` IP. Using the config files or parameters
    to install your cluster, you can choose an IP range inside the previous network
    for your nodes. In this case, the master is using the `192.168.0.11` IP and your
    agents are using the `192.168.0.12` and `192.168.0.13` IP addresses. Remember
    that your configuration has set static IP private addresses to your nodes to prevent
    errors in your nodes if the IP address changes. We assume that the nodes are using
    IP addresses starting from `192.168.0.11` to `192.168.0.13`. We are going to use
    the `192.168.0.240` to `192.168.0.250` IP address range for load balancers. This
    is just a simple example of how to organize your IPs for your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: We are assuming that your router is in the `192.168.0.0/24` network. As we mentioned,
    home routers have some switch capabilities to auto-assign dynamic IP addresses
    using a DHCP service configured inside the router, but this isn't healthy for
    your nodes. That's the main reason for using static IPs for your nodes. We are
    assuming some public IP to use as an example. We are assuming that we are going
    to use the `8.8.8.8` and `1.1.1.1` DNS servers.
  prefs: []
  type: TYPE_NORMAL
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: All these IP ranges can change, depending on your internet provider or the router
    device that you are using. We set these values to provide an example of how to
    organize the network for your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create your homelab, we have to complete the following tasks:'
  prefs: []
  type: TYPE_NORMAL
- en: Install Ubuntu image on your Raspberry device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure your device to run the K3s installer.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure the K3s master node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure the K3s agent nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install **MetalLB** as the load balancing service.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install **Longhorn** as the default storage class.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configure `kubectl` in an external client to access the cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy your first application using `kubectl` and YAML files.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install and configure **Lens** to manage your cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: So, let's now quickly recap the concepts, starting with how to install Ubuntu
    on your device.
  prefs: []
  type: TYPE_NORMAL
- en: Installing an Ubuntu image on your Raspberry device
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we are going to install an Ubuntu image on a Raspberry device.
    You can skip this section or refer to previous chapters for more information.
    As a quick summary, you can follow the next steps to install Ubuntu on a Raspberry
    device:'
  prefs: []
  type: TYPE_NORMAL
- en: Open *Raspberry Pi Imager*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **CHOOSE OS** button to choose the Ubuntu Server 20.04 64-bit for
    ARM64 operating system, which is located in the **Other general purpose OS** |
    **Ubuntu** menu.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, insert your microSD card (you may have to buy an adapter to read microSD
    cards); your device appears when you select the **CHOOSE STORAGE** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Click on the **WRITE** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Accept to write the device; then, Raspberry Pi Imager will ask you for your
    username and password in order to continue writing to the microSD card.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Wait until the writing and verifying process finishes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Extract your microSD card.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Insert the microSD card into your Raspberry Pi and turn it on.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Repeat these steps for each Raspberry Pi device that will be part of your cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, let's move to configure the network settings and the container support
    for your device.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring your Raspberry Pi to run the K3s installer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we are going to configure the network settings, including
    your static IP address, DNS, hostname, and hosts files, finalizing with activating
    the support of the cgroups necessary to use **containerd**. Now, follow the next
    steps to perform the final setup before installing K3s in your nodes; remember
    that you can customize all these configurations to fit your own network:'
  prefs: []
  type: TYPE_NORMAL
- en: Turn on your device.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When Ubuntu asks you for your username and password, enter the username and
    `ubuntu` as the password this is the default password for the first login.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, Ubuntu will ask you to change the default password; let's use `k3s123-`
    as our password.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let''s configure the network; by default, Ubuntu uses `cloud-init` to
    configure the network. Let''s deactivate this by creating the `99-disable-network-config.cfg`
    file with the following commands and content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is an example of the content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'If you execute `ifconfig`, you will see that your device is `eth0`, but it
    can be named `es3` or something similar, so let''s modify the `50-cloud-init`
    file with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, modify the content of the file; it has to look something like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, apply the configuration and reboot your device to see whether your IP
    address is set when the **Operating System** (**OS**) starts. To do this, execute
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, configure the kernel parameters for the boot by editing the `/boot/firmware/cmdline.txt`
    file with the following command and content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add this content to the end of the line:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Edit `/etc/hostname` using the `master` name for your master node. Use `node01`
    and `node02` for the hostnames of your agent nodes; let''s edit the file using
    `nano`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is an example of the content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Edit the `/etc/hosts` file, adding the hostname; at a minimum, you need to
    have a line like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Here is an example of the content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: 'You can also use `master.local` instead of `master` to follow **Internet Engineering
    Task Force** (**IETF**) naming conventions for local networks. This may also help
    with zero-configuration **multicast DNS** (**mDNS**) setups. For more information,
    you can check out this link: [http://www.zeroconf.org](http://www.zeroconf.org).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, reboot your device:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This configuration is required to prepare your device to configure a K3s master
    or agent nodes. You can also follow IETF recommendations for local network design.
    In the next section, you will see how to install K3s for your master nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the K3s master node
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section explains how to install your master node for your K3s cluster;
    for this, you have to follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Turn on your device and log in with your `ubuntu` user.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Run the following commands to install your master node using `MASTER_IP` as
    `192.168.0.11`, as shown in *Figure 5.1*, for your K3s cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, we have installed the master node. This will be the node with the `192.168.0.11`
    IP address. Now, let's go ahead and add agent nodes to the cluster in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the K3s agent nodes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section explains how to complete our initial cluster diagram by repeating
    this section twice to complete the configuration of two agent nodes. Agent nodes
    will use the `192.168.0.12` and `192.168.0.13` IP addresses. Complete the following
    steps to configure each agent node:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to your master node:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We are going to extract the servicer node token to connect the agent nodes.
    In this case, the master node will be `192.168.0.11`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Extract and copy the token to join your agent nodes in the cluster, running
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Log out from your master node. Now, you have the token to join additional nodes
    to the cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each agent node to join the cluster, follow the next steps (the easy way):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to your agent node that you want to add to the cluster. In this case,
    `AGENT_IP` will be `192.168.0.12` or `192.168.0.13`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set an environment variable with the token that your master generated:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Register your node with the following command; in this case, `MASTER_IP` will
    be `192.168.0.11`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Exit from your agent node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Now, we have configured our agent nodes. Let's install MetalLB to start using
    load balancers for our applications.
  prefs: []
  type: TYPE_NORMAL
- en: Installing MetalLB as the load balancing service
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'MetalLB is a bare metal load balancer that can help when using the load balancing
    service of a regular Kubernetes cluster, with the capabilities of networking designed
    for bare metal, such as IP address assignment. So, let''s get started by installing
    MetalLB by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a MetalLB namespace (`metallb-system`) with the official manifests,
    executing the following lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Before running the command to install MetalLB, you have to create a `ConfigMap`
    resource called `metallb-config` inside the `metallb-system` namespace. Let''s
    call this file `config.yaml`, with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, create `ConfigMap`, executing the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install MetalLB with the official manifests by executing the following lines:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, you have installed MetalLB. You are ready to install services that use
    load balancers. These load balancers are commonly found in a lot of Kubernetes
    software. Now, it is time to add Longhorn for our storage.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Longhorn with ReadWriteMany mode
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'K3s includes basic storage support. Sometimes, this storage can cause errors
    when you are installing software. To prevent this, you will need another storage
    driver instead of the default one that comes with K3s. In this case, you can use
    Longhorn. With Longhorn, you can install Kubernetes software that looks for regular
    storage drivers. So, let''s install Longhorn in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to your **virtual machine** (**VM**) or device:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you want to install `nfs-common` on each VM with Ubuntu installed in your
    cluster. To do this, execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the official Longhorn manifests, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, you have Longhorn installed and running. Let's move on to learn how to
    configure `kubectl` on your personal computer to manage your K3s.
  prefs: []
  type: TYPE_NORMAL
- en: Extracting the K3s kubeconfig file to access your cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, it''s time to configure the `kubeconfig` file to access your K3s cluster
    from your computer, using the `kubectl` command. To configure the connection of
    your new K3s cluster from the outside, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install `kubectl`, following the instructions of the official documentation
    of Kubernetes ([https://kubernetes.io/docs](https://kubernetes.io/docs)); in this
    case, we are going to use the instructions for Macintosh:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Or you can install `kubectl` using `brew` on macOS, using the next command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'For other custom installations, such as `kubectl` for Apple''s new silicon
    processors, Linux, or Windows, visit the Kubernetes official documentation: [https://kubernetes.io/docs/tasks/tools/install-kubectl-macos](https://kubernetes.io/docs/tasks/tools/install-kubectl-macos).'
  prefs: []
  type: TYPE_NORMAL
- en: From the master node, copy the content inside `/etc/rancher/k3s/k3s.yaml` to
    your local `~/.kube/config` file.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Change the permissions of the file with the next command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Change part of the server value from `127.0.0.1` to the `MASTER_IP` address
    of your master node; in this case, it will be `192.168.0.11`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This changes to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Remember to install `kubectl` before you copy the Rancher `kubeconfig` file
    onto your computer. Remember that the content of the `k3s.yaml` file has to be
    stored inside `~/.kube/config` and needs the `0400` permissions. To check how
    to install the `kubectl` command, go to [https://kubernetes.io/docs/tasks/tools/install-kubectl-macos](https://kubernetes.io/docs/tasks/tools/install-kubectl-macos).
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are ready to use the cluster. In the next section, we are going to deploy
    a basic application with `kubectl` and YAML files, using MetalLB and Longhorn.
    So, let's start deploying applications, using `kubectl` in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying your first application with kubectl
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section covers the basics of Kubernetes. We are going to deploy an application
    using `kubectl` first. But before that, let me give you a quick introduction about
    how Kubernetes works with its basic objects.
  prefs: []
  type: TYPE_NORMAL
- en: Basic Kubernetes objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Kubernetes works with objects that provide different functionalities for your
    application using containers. The goal of Kubernetes is to orchestrate your containers.
    Kubernetes uses two ways to create objects. One is using imperative commands –
    in the case of Kubernetes, the `kubectl` command. The other is using declarative
    files, where the state of an object is defined, and Kubernetes ensures that this
    state stays as it was defined throughout its lifetime:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Kubernetes objects'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16945_Figure_5.2.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.2 – Kubernetes objects
  prefs: []
  type: TYPE_NORMAL
- en: 'This diagram represents how some of the basic objects interact with each other
    to deploy and manage an application. So, let''s explain each of these objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Pod** contains one or more containers, where your application lives; all
    the containers inside a Pod share the same network, memory, and CPU.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ReplicaSet** controls the number of pods to be the same.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment** is an advanced kind of **ReplicaSet** object that not only controls
    the number of Pods and versions but also the changes of the Pods, providing a
    way to perform rollbacks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service** is a way to expose your services. There are different types. **NodePort**
    opens a random port on all the nodes, **ClusterIP** creates a DNS that you can
    use to communicate with your Pod or deploy with other Pods or deployments, and
    **LoadBalancer** creates an exclusive endpoint to publish your app to the outside.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Persistent Volume Claim** is the object in charge of requesting persistent
    storage and creating stateful deployments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage Class** is the object that defines how you are going to request storage
    for an application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With these pretty basic concepts, let's move on to the practical aspects to
    understand how each component works. In the next section, we are going to deploy
    a simple NGINX server using `kubectl`.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a simple NGINX server with pods using kubectl
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we are going to deploy an NGINX server, step by step, using
    `kubectl`. To do this, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a pod with the `nginx` image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `LoadBalancer` type of service for this Pod to expose and access the
    NGINX pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Assign the IP address to your load balancer with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Access the next URL using your browser or the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, you have an NGINX service up and running. So, let's move to deploy a **Redis**
    database that you can access to store data in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a Redis NoSQL database with pods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, we are going to deploy a Redis NoSQL key-value database that you can access
    to store some data. We chose Redis as a basic example as it is quick and easy
    to use. So, let''s deploy Redis using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a pod with a `redis` image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `ClusterIP` service that you can use to connect to Redis using the
    name of the service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s create an `ubuntu` client with the next command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, you are inside the client, so let''s install the Redis client to get connected
    to the Redis pods with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Store the variable with the value `1` and get the value from the client, using
    the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The last command returns the value of the `a` variable, which is `1`.
  prefs: []
  type: TYPE_NORMAL
- en: Write `exit` and then press *Enter* to exit the client. The client will be automatically
    deleted because of the `--rm` parameter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let''s expose Redis, using `NodePort` as an example of how to expose a
    pod using the IPs of your nodes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, you can access your Redis database using the IP of the host where Redis
    was deployed.
  prefs: []
  type: TYPE_NORMAL
- en: You have finished installing a simple database – in this case, Redis. Now, let's
    explore the deployment objects and storage in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying and scaling an NGINX server with deployments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the advantages of using deployments is that you manage the changes of
    your deployment if the version or the configuration changes. Let''s deploy a simple
    NGINX server, scale the deployment, change the image, and then perform a rollback
    to see the power of deployments. Deploy the NGINX server by following these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a deployment with two replicas using the `nginx` image:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a `LoadBalancer` service to expose your deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the IP for `mywebserver`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Access the web server using `curl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Scale `mywebserver` with `0` replicas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Try to access `mywebserver` again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Scale `mywebserver` with two replicas and wait until the deployment is ready;
    you can check this with the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Try to access `mywebserver` again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s change the `nginx` version of the deployment with the wrong version:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the changes in the description of the object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the current pod status for the `mywebserver` deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will see some pods from `mywebserver` with errors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s roll back to the previous version:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the current pod status for the `mywebserver` deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will see that the pods with errors have disappeared because you returned
    to the previous image that the deployment was using – in this case, the correct
    image name.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you have deployed your application using the deployment object. Let's do
    something similar using YAML files and add some persistence. To do this, let's
    move on to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a simple NGINX server using YAML files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: At this point, our examples don't store data and the objects are created using
    imperative commands. To use declarative files, you can use the `kubectl` command
    to generate the files. Remember to deploy your application, using pods or deployments
    – just choose one of these options. To start, let's create an NGINX pod using
    YAML files.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying an NGINX server using a Pod
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let''s create an NGINX pod using YAML files. To do this, follow these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to use pods, you can use the next YAML file. To generate the file,
    use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `nginx-pod.yaml` file will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the generated file using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Let's move on to create an NGINX deployment in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying an NGINX server using deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, let''s get started creating an NGINX server using deployment with YAML
    files. To do this, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate the YAML file for deployment using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The file `nginx-deployment.yaml` will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the generated file using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have learned how to create a pod and deployment in Kubernetes, let's
    move on to the next section to expose these objects using services with YAML files.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing your pods using the ClusterIP service and YAML files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To communicate your pod or deployment with other applications, you may need
    a DNS record. The `ClusterIP` service type creates a DNS A record for your pod
    or deployment. Using this DNS, other objects in your cluster can access your application.
    So, let''s create a `ClusterIP` service for your application, following these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To expose your application using YAML files, generate the YAML file for the
    `ClusterIP` service type:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `nginx-service.yaml` file will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the generated file using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that you have learned how to create a `ClusterIP` service using YAML files,
    let's move on to creating a `NodePort` service for your application in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing your pods using the NodePort service and YAML files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create a NodePort service for a previously created pod, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For `NodePort`, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `nginx-nodeport.yaml` file will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the generated file using the next command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that you have learned how to create a `NodePort` service for your application
    in a pod, it's time to learn how to use `LoadBalancer` services in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing your pods using a LoadBalancer service and YAML files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create a `LoadBalancer` service to expose your application inside a pod,
    follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For `LoadBalancer`, use the next command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The generated `nginx-lb.yaml` file will look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the generated file using the next command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You have learned how to create a `LoadBalancer` service. With this, we have
    covered all the basic services in Kubernetes. Now, we are ready to learn how to
    create stateful applications. Let's move on to the next section to add persistence
    to your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Adding persistence to your applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, it is time to add storage to your applications; we are going to use the
    storage classes installed with Longhorn to provide persistence to your applications.
    In this section, we are going to explore two examples using persistent volumes.
    In this part of the book, we are going to discuss the persistent volumes and the
    process of creating storage for a Pod. But first, we need a persistent volume
    claim definition to provision this storage.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an NGINX pod with a storage volume
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create your NGINX application using a storage volume that uses the Longhorn
    storage class, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create `pvc.yaml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the `pvc.yaml` YAML file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, it''s time to create a pod using this PVC that uses the Longhorn storage
    class. To do this, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create and apply the `pod.yaml` file to create a pod using the previously created
    PVC:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This example has created a pod using a persistent volume, with the Longhorn
    storage class. Let's continue with a second example that shows a database using
    a storage volume.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the database using a persistent volume
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, is time to use a persistent volume for a database; in this example, you
    are going to learn how to create a Redis database with a persistent volume. So,
    let''s get started with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `redis.yaml` file to create a pod that uses the previous `longhorn-volv-pvc`
    PVC:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the `pod.yaml` YAML file to create the pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check and Apply the `pod.yaml` YAML file to create the pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the `pod.yaml` YAML file to create the pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Troubleshooting Your Deployments
  prefs: []
  type: TYPE_NORMAL
- en: 'Remember that you can use the `kubectl logs` command to troubleshoot your deployments.
    For more information, you can check the next link: [https://kubernetes.io/docs/tasks/debug-application-cluster/debug-running-pod/](https://kubernetes.io/docs/tasks/debug-application-cluster/debug-running-pod/).'
  prefs: []
  type: TYPE_NORMAL
- en: Now, your Redis database is running and using a persistent volume to prevent
    the loss of data. In the last section, we are going to explore how to install
    a simple Kubernetes dashboard to manage your cluster using a UI.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a Kubernetes dashboard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, it''s time to install a Kubernetes dashboard. The next steps are based
    on the official K3s documentation. To start installing the dashboard, follow these
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the dashboard using the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This is going to install the dashboard, but you need to configure how to access
    this dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `dashboard-admin-user.yaml` file to create a service account that
    provides access to your dashboard. The content of this file will be as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now create the file `dashboard-admin-user-role.yaml`. The content of this file
    will be the next:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, apply the YAML files with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Get the token inside the service account that will be used to access the dashboard:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Copy the token content only.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use `kubectl proxy` to expose the Kubernetes API in your localhost, using the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Access your browser with the following URL:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/`'
  prefs: []
  type: TYPE_NORMAL
- en: 'Sign in with the admin user bearer token that you got. Choose the **Token**
    option and enter the token. You will see a screen like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Kubernetes Dashboard sign-in screen'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16945_Figure_5.3.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.3 – Kubernetes Dashboard sign-in screen
  prefs: []
  type: TYPE_NORMAL
- en: 'After clicking on the **Sign In** button, you will see the dashboard. Explore
    the different menus to see the state of your objects, or click on the plus icon
    at the lower-right corner to create objects using the YAML files:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4  – Kubernetes Dashboard showing CPU and memory usage'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16945_Figure_5.4.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 5.4 – Kubernetes Dashboard showing CPU and memory usage
  prefs: []
  type: TYPE_NORMAL
- en: We have now completed all the necessary concepts, giving you a quick introduction
    to how to use basic objects in Kubernetes with K3s.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to set up a K3s cluster with Raspberry Pi devices
    for our homelab. We also covered how to use basic Kubernetes objects to deploy
    an application. We deployed sample applications in an imperative way using the
    `kubectl` command. We also deployed sample applications using YAML files too.
    At the end of the chapter, we covered how to install a Kubernetes dashboard to
    manage your cluster. In the next chapter, we are going to continue adding more
    pieces to this deployment; we are going to use ingress controllers to deploy applications
    at the edge.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are a few questions to validate your new knowledge:'
  prefs: []
  type: TYPE_NORMAL
- en: What are the basic Kubernetes objects that I need to create an application?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can I install a K3s cluster for my homelab?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can I use `kubectl` to create my applications?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can I use YAML files to create my applications?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can I use persistent volumes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: How can I troubleshoot my applications?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can refer to the following references for more information on the topics
    covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'K3s installation options to add custom parameters to your config files: [https://rancher.com/docs/k3s/latest/en/installation/install-options](https://rancher.com/docs/k3s/latest/en/installation/install-options)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Longhorn official page: [https://longhorn.io](https://longhorn.io)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MetalLB official page: [https://metallb.universe.tf](https://metallb.universe.tf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Official Kubernetes documentation: [https://kubernetes.io/docs](https://kubernetes.io/docs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kubernetes Dashboard installation guide: [https://rancher.com/docs/k3s/latest/en/installation/kube-dashboard](https://rancher.com/docs/k3s/latest/en/installation/kube-dashboard)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kubernetes Dashboard installation using Helm: [https://artifacthub.io/packages/helm/k8s-dashboard/kubernetes-dashboard](https://artifacthub.io/packages/helm/k8s-dashboard/kubernetes-dashboard)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 2: Cloud Native Applications at the Edge'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Here you will learn how to deploy your applications at the edge using GitOps,
    service meshes, serverless and event-driven architectures, and different types
    of databases.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part of the book comprises the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B16945_06_Final_PG.xhtml#_idTextAnchor127), *Exposing Your Applications
    Using Ingress Controllers and Certificates*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B16945_07_Final_PG.xhtml#_idTextAnchor144), *GitOps with Flux
    for Edge Applications*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B16945_08_Final_PG.xhtml#_idTextAnchor163), *Observability and
    Traffic Splitting Using Linkerd*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B16945_09_Final_PG.xhtml#_idTextAnchor181), *Edge Serverless
    and Event-Driven Architectures with Knative and Cloud Events*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B16945_10_Final_PG.xhtml#_idTextAnchor198), *SQL and NoSQL Databases
    at the Edge*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
