- en: 3\. Application deployment on AKS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will deploy two applications on **Azure Kubernetes Service** (**AKS**).
    An application consists of multiple parts, and you will build the applications
    one step at a time while the conceptual model behind them is explained. You will
    be able to easily adapt the steps in this chapter to deploy any other application
    on AKS.
  prefs: []
  type: TYPE_NORMAL
- en: To deploy the applications and make changes to them, you will be using **YAML**
    files. YAML is a recursive acronym for **YAML Ain't Markup Language**. YAML is
    a language that is used to create configuration files to deploy to Kubernetes.
    Although you can use either JSON or YAML files to deploy applications to Kubernetes,
    YAML is the most commonly used language to do so. YAML became popular because
    it is easier for a human to read when compared to JSON or XML. You will see multiple
    examples of YAML files throughout this chapter and throughout the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'During the deployment of the sample guestbook application, you will see Kubernetes
    concepts in action. You will see how a **deployment** is linked to a **ReplicaSet**,
    and how that is linked to the **pods** that are deployed. A deployment is an object
    in Kubernetes that is used to define the desired state of an application. A **deployment**
    will create a ReplicaSet. A **ReplicaSet** is an object in Kubernetes that guarantees
    that a certain number of **pods** will always be available. Hence, a ReplicaSet
    will create one or more pods. A pod is an object in Kubernetes that is a group
    of one or more containers. Let''s revisit the relationship between deployments,
    ReplicaSets, and pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Relationship showing that a deployment creates a replicaset, which in turn
    creates multiple pods](img/B17338_01_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.1: Relationship between a deployment, a ReplicaSet, and pods'
  prefs: []
  type: TYPE_NORMAL
- en: While deploying the sample applications, you will use the **service** object
    to connect to the application. A service in Kubernetes is an object that is used
    to provide a static IP address and DNS name to an application. Since a pod can
    be killed and moved to different nodes in the cluster, a service ensures you can
    connect to a static endpoint for your application.
  prefs: []
  type: TYPE_NORMAL
- en: You will also edit the sample applications to provide configuration details
    using a **ConfigMap**. A ConfigMap is an object that is used to provide configuration
    details to pods. It allows you to keep configuration settings outside of the actual
    container. You can then provide these configuration details to your application
    by connecting the ConfigMap to your deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, you will be introduced to Helm. Helm is a package manager for Kubernetes
    that helps to streamline the deployment process. You will deploy a WordPress site
    using Helm and gain an understanding of the value Helm brings to Kubernetes. This
    WordPress installation makes use of persistent storage in Kubernetes and you will
    learn how persistent storage in AKS is set up.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following topics will be covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the sample guestbook application step by step
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Full deployment of the sample guestbook application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Helm to install complex Kubernetes applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We'll begin with the sample guestbook application.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the sample guestbook application step by step
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you will deploy the classic guestbook sample Kubernetes application.
    You will be mostly following the steps from [https://kubernetes.io/docs/tutorials/stateless-application/guestbook/](https://kubernetes.io/docs/tutorials/stateless-application/guestbook/)
    with some modifications. You will employ these modifications to show additional
    concepts, such as ConfigMaps, that are not present in the original sample.
  prefs: []
  type: TYPE_NORMAL
- en: The sample guestbook application is a simple, multi-tier web application. The
    different tiers in this application will have multiple instances. This is beneficial
    for both high availability and scalability. The guestbook's front end is a stateless
    application because the front end doesn't store any state. The Redis cluster in
    the back end is stateful as it stores all the guestbook entries.
  prefs: []
  type: TYPE_NORMAL
- en: You will be using this application as the basis for testing out the scaling
    of the back end and the front end, independently, in the next chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Before we get started, let's consider the application that we'll be deploying.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the application
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The application stores and displays guestbook entries. You can use it to record
    the opinion of all the people who visit your hotel or restaurant, for example.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 3.2* shows you a high-level overview of the application. The application
    uses PHP as a front end. The front end will be deployed using multiple replicas.
    The application uses Redis for its data storage. Redis is an in-memory key-value
    database. Redis is most often used as a cache.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Architecture of the multi-tier guestbook application](img/B17338_03_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.2: High-level overview of the guestbook application'
  prefs: []
  type: TYPE_NORMAL
- en: We will begin deploying this application by deploying the Redis master.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Redis master
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, you are going to deploy the Redis master. You will learn about
    the YAML syntax that is required for this deployment. In the next section, you
    will make changes to this YAML. Before making changes, let's start by deploying
    the Redis master.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to complete the task:'
  prefs: []
  type: TYPE_NORMAL
- en: Open your friendly Azure Cloud Shell, as highlighted in *Figure 3.3*:![Opening
    Cloud Shell from the Azure portal](img/B17338_03_03.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 3.3: Opening the Cloud Shell'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'If you have not cloned the GitHub repository for this book, please do so now
    by using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Change into the directory for Chapter 3 using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Enter the following command to deploy the master:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'It will take some time for the application to download and start running. While
    you wait, let''s understand the command you just typed and executed. Let''s start
    by exploring the content of the YAML file that was used (the line numbers are
    used for explaining key elements from the code snippets):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s dive deeper into the code line by line to understand the provided parameters:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`deployment` is given a name, which is `redis-master`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`app: redis, role: master, and tier: backend`). The preceding label exactly
    matches the labels provided in lines *14-19*.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`master`. In the case of a multi-container pod, each container in a pod requires
    a unique name.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`redis` image tagged with `e2e` (the latest Redis image that successfully passed
    its end-to-end [`e2e`] tests).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cpu/memory` resources requested for the container. A request in Kubernetes
    is a reservation of resources that cannot be used by other pods. If those resources
    are not available in the cluster, the pod will not start. In this case, the request
    is 0.1 CPU, which is equal to `100m` and is also often referred to as 100 millicores.
    The memory requested is `100Mi`, or 104,857,600 bytes, which is equal to ~105
    MB. CPU and memory limits are set in a similar way. Limits are caps on what a
    container can use. If your pod hits the CPU limit, it''ll get throttled, whereas
    if it hits the memory limits, it''ll get restarted. Setting requests and limits
    is a best practice in Kubernetes. For more info, refer to [https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/](https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/).'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`6379`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, the YAML definition for the deployment contains several settings
    and parameters that Kubernetes will use to deploy and configure your application.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Kubernetes YAML definition is similar to the arguments given to Docker
    to run a particular container image. If you had to run this manually, you would
    define this example in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '`# Run a container named master, listening on port 6379, with 100M memory and
    100m CPU using the redis:e2e image.`'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker run --name master -p 6379:6379 -m 100M -c 100m -d k8s.gcr.io/redis:e2e`'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you have deployed the Redis master and learned about the syntax
    of the YAML file that was used to create this deployment. In the next section,
    you will examine the deployment and learn about the different elements that were
    created.
  prefs: []
  type: TYPE_NORMAL
- en: Examining the deployment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The `redis-master` deployment should be complete by now. Continue in the Azure
    Cloud Shell that you opened in the previous section and type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: You should get an output similar to the one displayed in *Figure 3.4*. In your
    case, the name of the pod and the ReplicaSet might contain different IDs at the
    end of the name. If you do not see a pod, a deployment, and a ReplicaSet, please
    run the code as explained in step 4 in the previous section again.
  prefs: []
  type: TYPE_NORMAL
- en: '![A list of objects that were created by your deployment](img/B17338_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.4: Objects that were created by your deployment'
  prefs: []
  type: TYPE_NORMAL
- en: You can see that you created a deployment named `redis-master`. It controls
    a ReplicaSet named `redis-master-f46ff57fd`. On further examination, you will
    also find that the ReplicaSet is controlling a pod, `redis- master-f46ff57fd-b8cjp`.
    *Figure 3.1* has a graphical representation of this relationship.
  prefs: []
  type: TYPE_NORMAL
- en: 'More details can be obtained by executing the `kubectl describe <object> <instance-name>`
    command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate an output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the kubectl describe command to fetch the details of the deployment](img/B17338_03_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.5: Description of the deployment'
  prefs: []
  type: TYPE_NORMAL
- en: You have now launched a Redis master with the default configuration. Typically,
    you would launch an application with an environment-specific configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next section, you will get acquainted with a new concept called ConfigMaps
    and then recreate the Redis master. So, before proceeding, clean up the current
    version, which you can do by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Executing this command will produce the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: In this section, you examined the Redis master deployment you created. You saw
    how a deployment relates to a ReplicaSet and how a ReplicaSet relates to pods.
    In the following section, you will recreate this Redis master with an environment-specific
    configuration provided via a ConfigMap.
  prefs: []
  type: TYPE_NORMAL
- en: Redis master with a ConfigMap
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There was nothing wrong with the previous deployment. In practical use cases,
    it would be rare that you would launch an application without some configuration
    settings. In this case, you are going to set the configuration settings for `redis-master`
    using a ConfigMap.
  prefs: []
  type: TYPE_NORMAL
- en: A ConfigMap is a portable way of configuring containers without having specialized
    images for each environment. It has a key-value pair for data that needs to be
    set on a container. A ConfigMap is used for non-sensitive configuration. Kubernetes
    has a separate object called a **Secret**. A Secret is used for configurations
    that contain critical data such as passwords. This will be explored in detail
    in *Chapter 10, Storing Secrets in AKS* of this book.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, you are going to create a ConfigMap. In this ConfigMap, you
    will configure `redis-config` as the key and the value will be the following two
    lines:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let''s create this ConfigMap. There are two ways to create a ConfigMap:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a ConfigMap from a file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a ConfigMap from a YAML file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the following two sections, you'll explore both.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a ConfigMap from a file
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following steps will help us create a ConfigMap from a file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the Azure Cloud Shell code editor by typing `code redis-config` in the
    terminal. Copy and paste the following two lines and save the file as `redis-config`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now you can create the ConfigMap using the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get an output as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can use the same command to describe this ConfigMap:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output will be as shown in *Figure 3.6*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Using the kubectl describe command to fetch the description of the ConfigMap](img/B17338_03_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.6: Description of the ConfigMap'
  prefs: []
  type: TYPE_NORMAL
- en: In this example, you created the ConfigMap by referring to a file on disk. A
    different way to deploy ConfigMaps is by creating them from a YAML file. Let's
    have a look at how this can be done in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a ConfigMap from a YAML file
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, you will recreate the ConfigMap from the previous section
    using a YAML file:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, delete the previously created ConfigMap:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Copy and paste the following lines into a file named `example-redis-config.yaml`,
    and then save the file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can now create your ConfigMap via the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get an output as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This command returns the same output as the previous one, as shown in *Figure 3.6*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As you can see, using a YAML file, you were able to create the same ConfigMap.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '`kubectl get` has the useful `-o` option, which can be used to get the output
    of an object in either YAML or JSON. This is very useful in cases where you have
    made manual changes to a system and want to see the resulting object in YAML format.
    You can get the current ConfigMap in YAML using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl get -o yaml configmap/example-redis-config`'
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have the ConfigMap defined, let's use it.
  prefs: []
  type: TYPE_NORMAL
- en: Using a ConfigMap to read in configuration data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, you will reconfigure the `redis-master` deployment to read
    configuration from the ConfigMap:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To start, modify `redis-master-deployment.yaml` to use the ConfigMap as follows.
    The changes you need to make will be explained after the source code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: If you downloaded the source code accompanying this book, there is a file in
    *Chapter 3, Application deployment on AKS*, called `redis-master-deployment_Modified.yaml`,
    that has the necessary changes applied to it.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s dive deeper into the code to understand the different sections:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`redis-server` pointing to a specific configuration file.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker run -e "MASTER=true". --name master -p 6379:6379 -m 100M -c 100m -d
    Kubernetes /redis:v1`. This sets the environment variable `MASTER` to `true`.
    Your application can read the environment variable settings for its configuration.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`config` (this volume is defined in lines 39-45) on the `/redis-master` path
    on the running container. It will hide whatever exists on `/redis-master` on the
    original container.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In Docker terms, it would be equivalent to `docker run -v config:/redis-master.
    -e "MASTER=TRUE" --name master -p 6379:6379 -m 100M -c 100m -d Kubernetes /redis:v1`.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`config`. This name will be used within the context of this pod.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`example-redis-config` ConfigMap. This ConfigMap should already exist in the
    system. You have already defined this, so you are good.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`redis-config` key (the two-line `maxmemory` settings) as a `redis.conf` file.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By adding the ConfigMap as a volume and mounting the volume, you are able to
    load dynamic configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s create this updated deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should output the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s now make sure that the configuration was successfully applied. First,
    get the pod''s name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should return an output similar to *Figure 3.7*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Fetching the details of the Redis-master pod using the kubectl get pods command](img/B17338_03_07.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.7: Details of the pod'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Then `exec` into the pod and verify that the settings were applied:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This open a `redis-cli` session with the running pod. Now you can get the `maxmemory`
    configuration:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'And then you can get the `maxmemory-policy` configuration:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should give you an output similar to *Figure 3.8*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Verifying the maxmemoery and maxmemory-policy custom configuration](img/B17338_03_08.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.8: Verifying the Redis configuration in the pod'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To leave the Redis shell, type the `exit` command.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To summarize, you have just performed an important part of configuring cloud-native
    applications, namely providing dynamic configuration data to an application. You
    will have also noticed that the apps have to be configured to read config dynamically.
    After you set up your app with configuration, you accessed a running container
    to verify the running configuration. You will use this methodology frequently
    throughout this book to verify the functionality of running applications.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Connecting to a running container by using the `kubectl exec` command is useful
    for troubleshooting and doing diagnostics. Due to the ephemeral nature of containers,
    you should never connect to a container to do additional configuration or installation.
    This should either be part of your container image or configuration you provide
    via Kubernetes (as you just did).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you configured the Redis master to load configuration data
    from a ConfigMap. In the next section, we will deploy the end-to-end application.
  prefs: []
  type: TYPE_NORMAL
- en: Complete deployment of the sample guestbook application
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Having taken a detour to understand the dynamic configuration of applications
    using a ConfigMap, you will now return to the deployment of the rest of the guestbook
    application. You will once again come across the concepts of deployment, ReplicaSets,
    and pods. Apart from this, you will also be introduced to another key concept,
    called a service.
  prefs: []
  type: TYPE_NORMAL
- en: To start the complete deployment, we are going to create a service to expose
    the Redis master service.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing the Redis master service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When exposing a port in plain Docker, the exposed port is constrained to the
    host it is running on. With Kubernetes networking, there is network connectivity
    between different pods in the cluster. However, pods themselves are ephemeral
    in nature, meaning they can be shut down, restarted, or even moved to other hosts
    without maintaining their IP address. If you were to connect to the IP of a pod
    directly, you might lose connectivity if that pod was moved to a new host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes provides the `service` object, which handles this exact problem.
    Using label-matching selectors, it sends traffic to the right pods. If there are
    multiple pods serving traffic to a service, it will also do load balancing. In
    this case, the master has only one pod, so it just ensures that the traffic is
    directed to the pod independent of the node the pod runs on. To create the service,
    run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'The `redis-master-service.yaml` file has the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now see what you have created using the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '`redis-master`, which has the same labels as our `redis-master` server pod.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`6379` and forward it to port `6379` of the pods that match the selector defined
    between lines 13 and 16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`app: redis, role: master and tier: backend`) is expected to handle port `6379`
    traffic. If you look back at the previous example, those are the exact labels
    we applied to that deployment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can check the properties of the service by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This will give you an output as shown in *Figure 3.9*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Obtaining the properties of the Redis-master service using the kubectl get
    service command](img/B17338_03_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.9: Properties of the created service'
  prefs: []
  type: TYPE_NORMAL
- en: You see that a new service, named `redis-master`, has been created. It has a
    Cluster-IP of `10.0.106.207` (in your case, the IP will likely be different).
    Note that this IP will work only within the cluster (hence the `ClusterIP` type).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: You are now creating a service of type `ClusterIP`. There are other types of
    service as well, which will be introduced later in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'A service also introduces a `<service-name>.<namespace>.svc.cluster.local`;
    in this case, it would be `redis-master.default.svc.cluster.local`. To see this
    in action, we''ll do a name resolution on our `redis-master` pod. The default
    image doesn''t have `nslookup` installed, so we''ll bypass that by running a `ping`
    command. Don''t worry if that traffic doesn''t return; this is because you didn''t
    expose `ping` on your service, only the `redis` port. The command is, however,
    useful to see the full DNS name and the name resolution work. Let''s have a look:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This should output the resulting name resolution, showing you the `exit` command,
    as shown in *Figure 3.10*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using a ping command to view the FQDN of your service](img/B17338_03_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.10: Using a ping command to view the FQDN of your service'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you exposed the Redis master using a service. This ensures
    that even if a pod moves to a different host, it can be reached through the service's
    IP address. In the next section, you will deploy the Redis replicas, which help
    to handle more read traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the Redis replicas
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Running a single back end on the cloud is not recommended. You can configure
    Redis in a leader-follower (master-slave) setup. This means that you can have
    a master that will serve write traffic and multiple replicas that can handle read
    traffic. It is useful for handling increased read traffic and high availability.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s set this up:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the deployment by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s check all the resources that have been created now:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output would be as shown in *Figure 3.11*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Using the kubectl get all command to show all objects created](img/B17338_03_11.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.11: Deploying the Redis replicas creates a number of new objects'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Based on the preceding output, you can see that you created two replicas of
    the `redis-replica` pods. This can be confirmed by examining the `redis-replica-
    deployment.yaml` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Everything is the same except for the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '`GET_HOSTS_FROM` to `dns`. This is a setting that specifies that Redis should
    get the hostname of the master using DNS.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, this is similar to the Redis master you created earlier.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Like the master service, you need to expose the replica service by running
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The only difference between this service and the `redis-master` service is that
    this service proxies traffic to pods that have the `role:replica` label.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Check the `redis-replica` service by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should give you the output shown in *Figure 3.12*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Redis master and Redis replica configuration details](img/B17338_03_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.12: Redis-master and redis-replica service'
  prefs: []
  type: TYPE_NORMAL
- en: You now have a Redis cluster up and running, with a single master and two replicas.
    In the next section, you will deploy and expose the front end.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying and exposing the front end
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Up to now, you have focused on the Redis back end. Now you are ready to deploy
    the front end. This will add a graphical web page to your application that you'll
    be able to interact with.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can create the front end using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'To verify the deployment, run this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'This will display the output shown in *Figure 3.13*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Details of the frontend deployment](img/B17338_03_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.13: Verifying the front end deployment'
  prefs: []
  type: TYPE_NORMAL
- en: 'You will notice that this deployment specifies `3` replicas. The deployment
    has the usual aspects with minor changes, as shown in the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see these changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Line 11**: The replica count is set to 3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`app: guestbook` and `tier: frontend`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gb-frontend:v4` is used as the image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have now created the front-end deployment. You now need to expose it as
    a service.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing the front-end service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are multiple ways to define a Kubernetes service. The two Redis services
    we created were of the type `ClusterIP`. This means they are exposed on an IP
    that is reachable only from the cluster, as shown in *Figure 3.14*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Kubernetes service of type ClusterIP](img/B17338_03_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.14: Kubernetes service of type ClusterIP'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another type of service is the type `NodePort`. A service of type NodePort
    is accessible from outside the cluster, by connecting to the IP of a node and
    the specified port. This service is exposed on a static port on each node as shown
    in *Figure 3.15*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Kubernetes service of type NodePort](img/B17338_03_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.15: Kubernetes service of type NodePort'
  prefs: []
  type: TYPE_NORMAL
- en: 'A final type – which will be used in this example – is the `LoadBalancer` type.
    This will create an **Azure Load Balancer** that will get a public IP that you
    can use to connect to, as shown in *Figure 3.16*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Kubernetes service of type LoadBalancer](img/B17338_03_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.16: Kubernetes service of type LoadBalancer'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code will help you to understand how the frontend service is
    exposed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'This definition is similar to the services you created earlier, except that
    in *line 9* you defined `type: Load Balancer`. This will create a service of that
    type, which will cause AKS to add rules to the Azure load balancer.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have seen how a front-end service is exposed, let''s make the
    guestbook application ready for use with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create the service, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This step takes some time to execute when you run it for the first time. In
    the background, Azure must perform a couple of actions to make it seamless. It
    has to create an Azure load balancer and a public IP and set the port-forwarding
    rules to forward traffic on port `80` to internal ports of the cluster.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Run the following until there is a value in the `EXTERNAL-IP` column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should display the output shown in *Figure 3.17*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Fetching the external IP value of the front-end deployment](img/B17338_03_17.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 3.17: External IP value'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the Azure portal, if you click on All Resources and filter on Load balancer,
    you will see a kubernetes Load balancer. Clicking on it shows you something similar
    to *Figure 3.18*. The highlighted sections show you that there is a load balancing
    rule accepting traffic on `port 80` and you have two public IP addresses:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Azure load balancer showing the load balancing rule accepting traffic on
    port 80 ](img/B17338_03_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.18: kubernetes Load balancer in the Azure portal'
  prefs: []
  type: TYPE_NORMAL
- en: If you click through on the two public IP addresses, you'll see both IP addresses
    linked to your cluster. One of those will be the IP address of your actual front-end
    service; the other one is used by AKS to make outbound connections.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Azure has two types of load balancers: basic and standard.'
  prefs: []
  type: TYPE_NORMAL
- en: Virtual machines behind a basic load balancer can make outbound connections
    without any specific configuration. Virtual machines behind a standard load balancer
    (which is the default for AKS now) need an outbound rule on the load balancer
    to make outbound connections. This is why you see a second IP address configured.
  prefs: []
  type: TYPE_NORMAL
- en: You're finally ready to see your guestbook app in action!
  prefs: []
  type: TYPE_NORMAL
- en: The guestbook application in action
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Type the public IP of the service in your favorite browser. You should get
    the output shown in *Figure 3.19*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Using the public IP address to see the Guestbook application in action](img/B17338_03_19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.19: The guestbook application in action'
  prefs: []
  type: TYPE_NORMAL
- en: Go ahead and record your messages. They will be saved. Open another browser
    and type the same IP; you will see all the messages you typed.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations – you have completed your first fully deployed, multi-tier,
    cloud-native Kubernetes application!
  prefs: []
  type: TYPE_NORMAL
- en: 'To conserve resources on your free-trial virtual machines, it is better to
    delete the created deployments to run the next round of the deployments by using
    the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Over the course of the preceding sections, you have deployed a Redis cluster
    and deployed a publicly accessible web application. You have learned how deployments,
    ReplicaSets, and pods are linked, and you have learned how Kubernetes uses the
    `service` object to route network traffic. In the next section of this chapter,
    you will use Helm to deploy a more complex application on top of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Installing complex Kubernetes applications using Helm
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, you used static YAML files to deploy an application.
    When deploying more complicated applications, across multiple environments (such
    as dev/test/prod), it can become cumbersome to manually edit YAML files for each
    environment. This is where the Helm tool comes in.
  prefs: []
  type: TYPE_NORMAL
- en: Helm is the package manager for Kubernetes. Helm helps you deploy, update, and
    manage Kubernetes applications at scale. For this, you write something called
    Helm Charts.
  prefs: []
  type: TYPE_NORMAL
- en: You can think of Helm Charts as parameterized Kubernetes YAML files. If you
    think about the Kubernetes YAML files we wrote in the previous section, those
    files were static. You would need to go into the files and edit them to make changes.
  prefs: []
  type: TYPE_NORMAL
- en: Helm Charts allow you to write YAML files with certain parameters in them, which
    you can dynamically set. This setting of the parameters can be done through a
    values file or as a command-line variable when you deploy the chart.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, with Helm, you don't necessarily have to write Helm Charts yourself;
    you can also use a rich library of pre-written Helm Charts and install popular
    software in your cluster through a simple command such as `helm install --name
    my-release stable/mysql`.
  prefs: []
  type: TYPE_NORMAL
- en: This is exactly what you are going to do in the next section. You will install
    WordPress on your cluster by issuing only two commands. In the next chapters,
    you'll also dive into custom Helm Charts that you'll edit.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: On November 13, 2019, the first stable release of Helm v3 was released. We will
    be using Helm v3 in the following examples. The biggest difference between Helm
    v2 and Helm v3 is that Helm v3 is a fully client-side tool that no longer requires
    the server-side tool called **Tiller**.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start by installing WordPress on your cluster using Helm. In this section,
    you'll also learn about persistent storage in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Installing WordPress using Helm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As mentioned in the introduction, Helm has a rich library of pre-written Helm
    Charts. To access this library, you''ll have to add a repo to your Helm client:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the repo that contains the stable Helm Charts using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To install WordPress, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This execution will cause Helm to install the chart detailed at [https://github.com/bitnami/charts/tree/master/bitnami/wordpress](https://github.com/bitnami/charts/tree/master/bitnami/wordpress).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It takes some time for Helm to install and the site to come up. Let's look at
    a key concept, `PersistentVolumeClaims`, while the site is loading. After covering
    this, we'll go back and look at your site that got created.
  prefs: []
  type: TYPE_NORMAL
- en: PersistentVolumeClaims
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A typical process requires compute, memory, network, and storage. In the guestbook
    example, we saw how Kubernetes helps us abstract the compute, memory, and network.
    The same YAML files work across all cloud providers, including a cloud-specific
    setup of public-facing load balancers. The WordPress example shows how the last
    piece, namely storage, is abstracted from the underlying cloud provider.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the WordPress Helm Chart depends on the MariaDB helm chart ([https://github.com/bitnami/charts/tree/master/bitnami/mariadb](https://github.com/bitnami/charts/tree/master/bitnami/mariadb))
    for its database installation.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike stateless applications, such as our front ends, MariaDB requires careful
    handling of storage. To make Kubernetes handle stateful workloads, it has a specific
    object called a `<pod-name>-#`, where `#` starts from `0` for the first pod, and
    `1` for the second pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the following command, you can see that MariaDB has a predictable number
    attached to it, whereas the WordPress deployment has a random number attached
    to the end:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate the output shown in *Figure 3.20*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Naming of pods using a StatefulSet](img/B17338_03_20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.20: Numbers attached to MariaDB and WordPress pods'
  prefs: []
  type: TYPE_NORMAL
- en: The numbering reinforces the ephemeral nature of the deployment pods versus
    the StatefulSet pods.
  prefs: []
  type: TYPE_NORMAL
- en: Another difference is how pod deletion is handled. When a deployment pod is
    deleted, Kubernetes will launch it again anywhere it can, whereas when a StatefulSet
    pod is deleted, Kubernetes will relaunch it only on the node it was running on.
    It will relocate the pod only if the node is removed from the Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Often, you will want to attach storage to a StatefulSet. To achieve this, a
    StatefulSet requires a **PersistentVolume** (**PV**). This volume can be backed
    by many mechanisms (including blocks, such as Azure Blob, EBS, and iSCSI, and
    network filesystems, such as AFS, NFS, and GlusterFS). StatefulSets require either
    a pre-provisioned volume or a dynamically provisioned volume handled by a **PersistentVolumeClaim**
    (**PVC**). A PVC allows a user to dynamically request storage, which will result
    in a PV being created.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to [https://kubernetes.io/docs/concepts/storage/persistent-volumes/](https://kubernetes.io/docs/concepts/storage/persistent-volumes/)
    for more detailed information.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this WordPress example, you are using a PVC. A PVC provides an abstraction
    over the underlying storage mechanism. Let''s look at what the MariaDB Helm Chart
    did by running the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'In the preceding command, you got the YAML definition of the StatefulSet that
    was created and stored it in a file called `mariadbss.yaml`. Let''s look at the
    most relevant parts of that YAML file. The code has been truncated to only show
    the most relevant parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'Most of the elements of the preceding code have been covered earlier in the
    deployment. In the following points, we will highlight the key differences, to
    take a look at just the PVC:'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: PVC can be used by any pod, not just StatefulSet pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s discuss the different elements of the preceding code in detail:'
  prefs: []
  type: TYPE_NORMAL
- en: '`StatefulSet` declaration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data` and mount it under the `/bitnami/mariadb` path.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data`, which is reused at *line 285*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ReadWriteOnce`, which will create block storage, which on Azure is a disk.
    There are other access modes as well, namely `ReadOnlyMany` and `ReadWriteMany`.
    As the name suggests, a `ReadWriteOnce` volume can only be attached to a single
    pod, while a `ReadOnlyMany` or `ReadWriteMany` volume can be attached to multiple
    pods at the same time. These last two types require a different underlying storage
    mechanism such as Azure Files or Azure Blob.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Line 321**: This line defines the size of the disk.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Based on the preceding information, Kubernetes dynamically requests and binds
    an 8 GiB volume to this pod. In this case, the default dynamic-storage provisioner
    backed by the Azure disk is used. The dynamic provisioner was set up by Azure
    when you created the cluster. To see the storage classes available on your cluster,
    you can run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'This will show you an output similar to *Figure 3.21*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![List of storage classes available on your cluster](img/B17338_03_21.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.21: Different storage classes in your cluster'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can get more details about the PVC by running the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The output generated is displayed in *Figure 3.22*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A list of PVCs in the created cluster](img/B17338_03_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.22: Different PVCs in the cluster'
  prefs: []
  type: TYPE_NORMAL
- en: 'When we asked for storage in the StatefulSet description (*lines 128-143*),
    Kubernetes performed Azure-disk-specific operations to get the Azure disk with
    8 GiB of storage. If you copy the name of the PVC and paste that in the Azure
    search bar, you should find the disk that was created:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Getting the disk linked to a PVC](img/B17338_03_23.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.23: Getting the disk linked to a PVC'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of a PVC abstracts cloud provider storage specifics. This allows
    the same Helm template to work across Azure, AWS, or GCP. On AWS, it will be backed
    by **Elastic Block Store** (**EBS**), and on GCP it will be backed by Persistent
    Disk.
  prefs: []
  type: TYPE_NORMAL
- en: Also, note that PVCs can be deployed without using Helm.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, the concept of storage in Kubernetes using **PersistentVolumeClaim**
    (**PVC**) was introduced. You saw how they were created by the WordPress Helm
    deployment, and how Kubernetes created an Azure disk to support the PVC used by
    MariaDB. In the next section, you will explore the WordPress application on Kubernetes
    in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: Checking the WordPress deployment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After our analysis of the PVCs, let''s check back in with the Helm deployment.
    You can check the status of the deployment using:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'This should return the output shown in *Figure 3.24*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Checking status of the WordPress application deployment in Helm](img/B17338_03_24.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.24: WordPress application deployment status'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can get more info from our deployment in Helm using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'This will return the output shown in *Figure 3.25*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Fetching further details of the WordPress deployment using the helm status
    command](img/B17338_03_25.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.25: Getting more details about the deployment'
  prefs: []
  type: TYPE_NORMAL
- en: 'This shows you that your chart was deployed successfully. It also shows more
    info on how you can connect to your site. You won''t be using these steps for
    now; you will revisit these steps in *Chapter 5, Handling common failures in AKS*,
    in the section where we cover fixing storage mount issues. For now, let''s look
    into everything that Helm created for you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'This will generate an output similar to *Figure 3.26*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![List of objects created by Helm](img/B17338_03_26.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.26: List of objects created by Helm'
  prefs: []
  type: TYPE_NORMAL
- en: If you don't have an external IP yet, wait for a couple of minutes and retry
    the command.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can then go ahead and connect to your external IP and access your WordPress
    site. *Figure 3.27* is the resulting output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Connecting to the WordPress site using the external IP](img/B17338_03_27.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3.27: WordPress site being displayed on connection with the external
    IP'
  prefs: []
  type: TYPE_NORMAL
- en: 'To make sure you don''t run into issues in the following chapters, let''s delete
    the WordPress site. This can be done in the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'By design, the PVCs won''t be deleted. This ensures persistent data is kept.
    As you don''t have any persistent data, you can safely delete the PVCs as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Be very careful when executing `kubectl delete <object> --all` as it will delete all
    the objects in a namespace. This is not recommended on a production cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you have deployed a full WordPress site using Helm. You also
    learned how Kubernetes handles persistent storage using PVCs.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you deployed two applications. You started the chapter by deploying
    the guestbook application. During that deployment, the details of pods, ReplicaSets,
    and deployments were explored. You also used dynamic configuration using ConfigMaps.
    Finally, you looked into how services are used to route traffic to the deployed
    applications.
  prefs: []
  type: TYPE_NORMAL
- en: The second application you deployed was a WordPress application. You deployed
    it via the Helm package manager. As part of this deployment, PVCs were used, and
    you explored how they were used in the system and how they were linked to disks
    on Azure.
  prefs: []
  type: TYPE_NORMAL
- en: In *Chapter 4, Building scalable applications*, you will look into scaling applications
    and the cluster itself. You will first learn about the manual and automatic scaling
    of the application, and afterward, you'll learn about the manual and automatic
    scaling of the cluster itself. Finally, different ways in which applications can
    be updated on Kubernetes will be explained.
  prefs: []
  type: TYPE_NORMAL
