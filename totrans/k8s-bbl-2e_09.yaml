- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Persistent Storage in Kubernetes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes中的持久化存储
- en: In the previous chapters, we learned about Kubernetes’ key concepts, and this
    chapter is going to be the last one about that. So far, we’ve discovered that
    Kubernetes is about representing a desired state for all the traditional IT layers
    by creating an object in its `etcd` datastore that will be converted into actual
    computing resources within your clusters.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们学习了Kubernetes的关键概念，而本章将是关于这些概念的最后一章。到目前为止，我们已经发现Kubernetes的核心目标是通过在其`etcd`数据存储中创建一个对象，表示所需的状态，从而将所有传统的IT层转化为集群中的实际计算资源。
- en: This chapter will focus on persistent storage for stateful applications. As
    with any other resource abstraction, this will be another set of objects that
    we will master to get persistent storage on your clusters. Persistent storage
    is achieved in Kubernetes by using the `PersistentVolume` resource type, which
    has its own mechanics. Honestly, these can be relatively difficult to approach
    at first, but we are going to discover all of them and cover them in depth!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将重点讨论有状态应用的持久化存储。与其他资源抽象一样，这将是我们需要掌握的一组对象，用以在集群中获得持久化存储。Kubernetes通过使用`PersistentVolume`资源类型来实现持久化存储，它有其自己的机制。说实话，这些内容最初可能相对难以理解，但我们将逐一探索并深入讲解它们！
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要主题：
- en: Why use persistent storage?
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为什么要使用持久化存储？
- en: Understanding how to mount `PersistentVolume` to your Pod
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解如何将`PersistentVolume`挂载到你的Pod中
- en: Understanding the life cycle of the `PersistentVolume` object in Kubernetes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Kubernetes中`PersistentVolume`对象的生命周期
- en: Understanding static and dynamic `PersistentVolume` provisioning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解静态和动态`PersistentVolume`配置
- en: Advanced storage topics
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级存储主题
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: A working Kubernetes cluster (either local or cloud-based)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个可用的Kubernetes集群（无论是本地集群还是云端集群）
- en: A working `kubectl` CLI configured to communicate with the cluster
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置好的工作`kubectl`命令行工具，用于与集群通信
- en: If you do not meet these technical requirements, you can follow *Chapter 2*,
    *Kubernetes Architecture – from Container Images to Running Pods*, and *Chapter
    3*, *Installing Your Kubernetes Cluster*, to get these two prerequisites.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有满足这些技术要求，可以参考*第二章*，*Kubernetes架构——从容器镜像到运行的Pod*，以及*第三章*，*安装Kubernetes集群*，以获取这两个先决条件。
- en: You can download the latest code samples for this chapter from the official
    GitHub repository at [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter09](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter09).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从官方GitHub仓库下载本章的最新代码示例，地址为[https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter09](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter09)。
- en: Why use persistent storage?
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么要使用持久化存储？
- en: Storage is an important resource within the IT world, as it provides a logical
    way to **create**, **read**, **update**, and **delete** (**CRUD**) information
    ranging from employee payslips in a PDF file format to petabytes of healthcare
    records. While storage is a key element in providing relevant information to the
    users, containers and microservices should be stateless. In other words, no information
    saved within a running container will be available when rescheduled or moved to
    a different cluster. The same goes for microservices; the data component should
    be decoupled, allowing the microservice to stay micro and not care about the data
    state and availability when being rescheduled.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 存储是IT世界中的一个重要资源，因为它提供了一种逻辑方式来**创建**、**读取**、**更新**和**删除**（**CRUD**）信息，从员工工资单的PDF文件格式到PB级的医疗记录。虽然存储是向用户提供相关信息的关键元素，但容器和微服务应该是无状态的。换句话说，在运行的容器中保存的信息在重新调度或迁移到其他集群时将不可用。微服务也同理；数据组件应该解耦，允许微服务保持微型，不关心数据的状态和可用性，也不关心在重新调度时的情况。
- en: So, where do we save the application data? In any sort of datastore, and from
    a business continuity perspective, if the related datastore runs on the same Kubernetes
    cluster as the microservices, it should have an application-aware replication
    mechanism. But remember, Kubernetes is a resource orchestrator that will act on
    the desired state you have defined for your application. When you’re configuring
    your Pods, you have the opportunity to define the storage component to be used,
    providing your containers with a way to create, read, update, and delete data.
    Let’s explore the different options Kubernetes has to offer to persist data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们将应用数据保存在哪里呢？可以保存到任何类型的数据存储中，从业务连续性的角度来看，如果相关的数据存储运行在与微服务相同的 Kubernetes
    集群中，它应该具有与应用相关的复制机制。但请记住，Kubernetes 是一个资源协调器，它会根据你为应用定义的期望状态进行操作。当你配置 Pods 时，你可以定义将要使用的存储组件，给容器提供创建、读取、更新和删除数据的方式。让我们探索
    Kubernetes 提供的持久化数据的不同选项。
- en: Introducing Volumes
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入卷
- en: 'The first layer of storage abstraction is to access Kubernetes objects and
    mount them within a container like a data volume. This can be done for:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 存储抽象的第一层是访问 Kubernetes 对象并将它们挂载到容器中，像数据卷一样。这可以为以下内容完成：
- en: A ConfigMap
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 ConfigMap
- en: A Secret
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Secret
- en: A ServiceAccount token (identical to a Secret)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 ServiceAccount 令牌（与 Secret 相同）
- en: This allows an application team to decouple the configuration of a microservice
    from the container or the deployment definition. If we consider the lifetime of
    an application, the credentials, certificates, or tokens to external services
    might need to be refreshed or a configuration parameter might need to be updated.
    We don’t want these to be hardcoded in the deployment manifests or the container
    images for obvious security reasons.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这使得应用团队能够将微服务的配置与容器或部署定义解耦。如果我们考虑到应用的生命周期，外部服务的凭证、证书或令牌可能需要刷新，或者配置参数可能需要更新。出于明显的安全原因，我们不希望这些信息被硬编码在部署清单或容器镜像中。
- en: 'Let’s have a look at a configMap example with the manifest `nginx-configmap.yaml`:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一下一个带有清单 `nginx-configmap.yaml` 的 configMap 示例：
- en: '[PRE0]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This `ConfigMap` has two definitions for two different files, which we will
    mount within the NGINX Pod with the manifest `nginx-pod.yaml`:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 `ConfigMap` 有两个定义，分别对应两个不同的文件，我们将使用清单 `nginx-pod.yaml` 将它们挂载到 NGINX Pod 中：
- en: '[PRE1]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s apply these two manifests:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们应用这两个清单：
- en: '[PRE2]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Let’s verify the status of the two objects:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们验证这两个对象的状态：
- en: '[PRE3]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Verify the files are available within the folder `/usr/share/nginx/hello` that
    we provided as a mount path:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 验证我们提供的挂载路径 `/usr/share/nginx/hello` 中是否有文件：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let’s verify that the data is being served by NGINX via a `port-forward` to
    avoid setting up a service:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过 `port-forward` 验证数据是否通过 NGINX 提供，以避免设置服务：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'In a second terminal, you can then `curl` the two URLs:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二个终端中，你可以使用 `curl` 请求这两个 URL：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: While this is a great start, one limitation of these objects is the amount of
    data you can store. Since it depends on the `etcd` datastore, to avoid performance
    issues, the limitation is 1.5 MB (refer to [https://etcd.io/docs/v3.5/dev-guide/limit](https://etcd.io/docs/v3.5/dev-guide/limit)).
    So, the next set of objects will allow your application to store much more data,
    in fact, as much data as the system hosting those volume objects can.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一个很好的开始，但这些对象的一个限制是你可以存储的数据量。由于它依赖于 `etcd` 数据存储系统，为避免性能问题，限制为 1.5 MB（参见
    [https://etcd.io/docs/v3.5/dev-guide/limit](https://etcd.io/docs/v3.5/dev-guide/limit)）。因此，下一组对象将允许你的应用存储更多的数据，实际上，可以存储与托管这些卷对象的系统能够存储的所有数据。
- en: 'Let’s consider a Kubernetes cluster with two worker nodes on which Pods can
    be scheduled, and explore the following five types of volumes:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑一个具有两个工作节点的 Kubernetes 集群，在这些节点上可以调度 Pods，并探索以下五种卷类型：
- en: An `emptyDir`
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 `emptyDir`
- en: A `hostPath`
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 `hostPath`
- en: A local volume
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地卷
- en: A **Fiber Channel** (**FC**) block disk
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**光纤通道** (**FC**) 块磁盘
- en: A **Network File System** (**NFS**) volume export
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个**网络文件系统** (**NFS**) 卷导出
- en: 'The first three types, `emptyDir`, `hostPath`, and local volumes, have two
    major limitations:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 前三种类型，`emptyDir`、`hostPath` 和本地卷，有两个主要的限制：
- en: They are limited to the disk space available on the worker node they are provisioned
    on.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们仅限于它们所在工作节点上可用的磁盘空间。
- en: They are bound to the node on which the Pod will be deployed. If your Pod is
    provisioned on worker node 1, the data will only be stored on worker node 1.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它们绑定到 Pod 将要部署的节点。如果你的 Pod 部署在工作节点 1 上，数据将只存储在工作节点 1 上。
- en: These volume types could potentially lead to a degradation of service or worse,
    like a split-brain scenario. If worker node 1 becomes unhealthy, triggering a
    rescheduling of the Pod to worker node 2, the application will start without its
    data and could lead to a major outage.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这些卷类型可能会导致服务降级，甚至更糟，例如出现脑裂（split-brain）情形。如果工作节点 1 变得不健康，导致 Pod 被重新调度到工作节点 2，则应用程序将在没有数据的情况下启动，可能会导致严重的服务中断。
- en: Note that some applications have a native replication engine. A typical deployment
    for such an application would have two replicas running and creating a `hostPath`
    volume on each node. In this scenario, if one worker node becomes unhealthy, then
    the application becomes degraded but only from a high availability and performance
    perspective.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，有些应用程序具有原生的复制引擎。此类应用程序的典型部署会运行两个副本，并在每个节点上创建一个 `hostPath` 卷。在这种情况下，如果一个工作节点变得不健康，应用程序会出现降级，但只是在高可用性和性能方面。
- en: 'Being external to any of the compute resources of your Kubernetes cluster,
    the last two types, FC block disk and an NFS volume, address the above weaknesses
    but introduce a bit more complexity. While the first three types of volumes do
    not require you to interact with your storage administrators, the last two do.
    Without getting into too many details, your storage administrators will have:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 作为 Kubernetes 集群的计算资源之外的外部资源，最后两种类型的卷，FC 块存储和 NFS 卷，解决了上述的弱点，但引入了更多的复杂性。虽然前三种类型的卷不需要与存储管理员交互，但最后两种类型需要。简单来说，您的存储管理员将需要：
- en: To provision a **Logical Unit Number** (**LUN** – the FC block disk) on their
    **Storage Area Network** (**SAN**) connected via an FC fabric to your Kubernetes
    worker nodes and allow access via a zoning configuration.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在**存储区域网络**（**SAN**）中提供一个**逻辑单元号**（**LUN** – FC 块存储磁盘），并通过 FC 光纤网络连接到 Kubernetes
    工作节点，并允许通过 zoning 配置进行访问。
- en: To provision a data space on **Network Attached Storage** (**NAS**) connected
    to the corporate network and reachable by your Kubernetes worker nodes and allow
    access via an export policy.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在连接到企业网络并且可以被您的 Kubernetes 工作节点访问的**网络附加存储** (**NAS**) 上提供数据空间，并允许通过导出策略进行访问。
- en: 'Note that testing these two types of volumes requires specialized equipment
    with a nontrivial setup, although NAS is more and more popular within home labs.
    However, from a Kubernetes standpoint, these volumes can be configured as easily
    as with the configMap example. Here are the modified versions of the NGINX Pod
    definition:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，测试这两种类型的卷需要专用设备，并且设置过程并不简单，尽管 NAS 在家庭实验室中越来越受欢迎。然而，从 Kubernetes 的角度来看，这些卷的配置与
    configMap 示例一样简单。以下是修改后的 NGINX Pod 定义版本：
- en: 'For an FC volume (`nginx-pod-fiberchannel.yaml`):'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 FC 卷（`nginx-pod-fiberchannel.yaml`）：
- en: '[PRE7]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The `fc` part is where your SAN and LUN must be configured.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '`fc` 部分是您的 SAN 和 LUN 必须配置的地方。'
- en: 'For an NFS volume (`nginx-pod-nfs-volume.yaml`):'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于 NFS 卷（`nginx-pod-nfs-volume.yaml`）：
- en: '[PRE8]'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: The `nfs` part is where your NAS and exported volume must be configured.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '`nfs` 部分是您的 NAS 和导出卷必须配置的地方。'
- en: 'Please note the following points:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意以下几点：
- en: These two types of volumes, FC block disk and NFS, will be attached to the nodes
    as required by the Pod presence.
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这两种类型的卷，FC 块存储和 NFS，将根据 Pod 的存在需求附加到节点。
- en: While these two types of volumes can solve a series of challenges, they represent
    an anti-pattern to the decoupling of configurations and resources.
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然这两种类型的卷可以解决一系列挑战，但它们代表了配置与资源解耦的反模式。
- en: While the configMap is mounted as a volume with the two HTML files on the container,
    the other types of volumes will require a different approach to have the data
    injected.
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 虽然 configMap 作为卷挂载在容器上，并包含两个 HTML 文件，但其他类型的卷需要不同的方法来注入数据。
- en: 'There are other volume types available: [https://kubernetes.io/docs/concepts/storage/volumes/](https://kubernetes.io/docs/concepts/storage/volumes/).'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还有其他类型的存储卷可供选择：[https://kubernetes.io/docs/concepts/storage/volumes/](https://kubernetes.io/docs/concepts/storage/volumes/)。
- en: The concept of volume within Kubernetes is an amazing starting point for deploying
    stateful applications. However, with the limitation of some, the complexity of
    others, and the storage knowledge it requires, it seems to be rather difficult
    to scale hundreds or thousands of microservices with such object definition. Thanks
    to an additional layer of abstraction, Kubernetes provides an agnostic approach
    to consume storage at scale with the usage of the `PersistentVolume` object, which
    we’ll cover in the next section.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，卷的概念是部署有状态应用程序的一个很好的起点。然而，由于某些卷的限制、其他卷的复杂性以及所需的存储知识，似乎很难通过这种对象定义来扩展数百个或数千个微服务。幸运的是，通过增加一个抽象层，Kubernetes
    提供了一种无关存储的方式，通过使用 `PersistentVolume` 对象来按规模消耗存储，我们将在下一节中介绍这一点。
- en: Introducing PersistentVolumes
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入 PersistentVolumes
- en: Just like the `Pod` or `ConfigMap`, `PersistentVolume` is a resource type that
    is exposed through `kube-apiserver`; you can create, update, and delete **persistent
    volumes** (**PVs**) using YAML and `kubectl` just like any other Kubernetes objects.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 就像 `Pod` 或 `ConfigMap`，`PersistentVolume` 是通过 `kube-apiserver` 暴露的资源类型；你可以像操作其他
    Kubernetes 对象一样，使用 YAML 和 `kubectl` 来创建、更新和删除**持久卷**（**PVs**）。
- en: 'The following command will demonstrate how to list the `PersistentVolume` resource
    type currently provisioned within your Kubernetes cluster:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将演示如何列出当前在 Kubernetes 集群中已配置的 `PersistentVolume` 资源类型：
- en: '[PRE9]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `persistentvolume` object is also accessible with the plural form of `persistentvolumes`
    along with the alias of `pv`. The following three commands are essentially the
    same:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '`persistentvolume` 对象也可以通过复数形式 `persistentvolumes` 和别名 `pv` 访问。以下三个命令本质上是相同的：'
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You’ll find that the `pv` alias is very commonly used in the Kubernetes world,
    and a lot of people refer to PVs as simply `pv`, so be aware of that. As of now,
    no `PersistentVolume` object has been created within our Kubernetes cluster, and
    that is why we don’t see any resource listed in the output of the preceding command.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现，在 Kubernetes 世界中，`pv` 别名被广泛使用，很多人直接称持久卷为 `pv`，所以请注意这一点。到目前为止，我们的 Kubernetes
    集群中尚未创建任何 `PersistentVolume` 对象，这也是我们在前一个命令的输出中没有看到任何资源的原因。
- en: '`PersistentVolume` is the object and, essentially, represents a piece of storage
    that you can attach to your Pod. That piece of storage is referred to as a *persistent*
    one because it is not supposed to be tied to the lifetime of a Pod.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '`PersistentVolume` 是一个对象，本质上代表一个你可以附加到 Pod 的存储。这个存储被称为*持久性*存储，因为它不应该与 Pod 的生命周期绑定。'
- en: Indeed, as mentioned in *Chapter 5*, *Using Multi-Container Pods and Design
    Patterns*, Kubernetes Pods use the notion of volumes. Additionally, we discovered
    the `emptyDir` volumes, which initiate an empty directory that your Pods can share.
    It also defines a path within the worker node filesystem that will be exposed
    to your Pods. Both volumes were supposed to be attached to the life cycle of the
    Pod. This means that once the Pod is destroyed, the data stored within the volumes
    will be destroyed as well.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，正如*第5章*《使用多容器Pod和设计模式》中提到的，Kubernetes Pods 使用了卷的概念。此外，我们还发现了 `emptyDir`
    卷，它初始化一个空目录，Pod 可以共享这个目录。它还定义了一个在工作节点文件系统中的路径，该路径将暴露给你的 Pods。两个卷都应该与 Pod 的生命周期绑定。这意味着，一旦
    Pod 被销毁，存储在卷中的数据也会被销毁。
- en: 'However, sometimes, you don’t want the volume to be destroyed. You just want
    it to have its life cycle to keep both the volume and its data alive even if the
    Pod fails. That’s where `PersistentVolumes` come into play: essentially, they
    are volumes that are not tied to the life cycle of a Pod. Since they are a resource
    type just like the Pods themselves, they can live on their own! In essence, PVs
    ensure that your storage remains available beyond the Pod’s existence, which is
    crucial for maintaining data integrity in stateful applications. Now, let’s break
    down `PersistentVolume`s objects: they consist of two key elements – a backend
    technology (the `PersistentVolume` type) and an access mode (like **ReadWriteOnce**
    (**RWO**)). Understanding these concepts is essential for effectively utilizing
    PVs within your Kubernetes environment.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，有时候，你并不希望卷被销毁。你只是希望它有自己的生命周期，即使 Pod 失败，卷和其数据依然能够保持存活。这时，`PersistentVolumes`就派上用场了：本质上，它们是与
    Pod 生命周期无关的卷。由于它们是像 Pod 一样的资源类型，它们可以独立存在！从本质上讲，PV 确保了你的存储在 Pod 存在之外仍然可用，这对于在有状态应用中保持数据完整性至关重要。现在，让我们来分解一下`PersistentVolume`对象：它们由两个关键元素组成——后端技术（`PersistentVolume`类型）和访问模式（如**ReadWriteOnce**
    (**RWO**)）。理解这些概念对于在 Kubernetes 环境中有效利用 PV 至关重要。
- en: Bear in mind that `PersistentVolumes` objects are just entries within the `etcd`
    datastore, and they are not actual disks on their own.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，`PersistentVolumes`对象仅仅是`etcd` 数据存储中的条目，它们本身并不是实际的磁盘。
- en: '`PersistentVolume` is just a kind of pointer within Kubernetes to a piece of
    storage, such as an NFS, a disk, an Amazon **Elastic Block Store** (**EBS**) volume,
    and more. This is so that you can access these technologies from within Kubernetes
    and in a Kubernetes way.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`PersistentVolume`仅仅是 Kubernetes 中指向某个存储资源的指针，比如 NFS、磁盘、Amazon **弹性块存储** (**EBS**)
    卷等。这样，你就可以通过 Kubernetes 以 Kubernetes 的方式访问这些技术。'
- en: In the next section, we’ll begin by explaining what `PersistentVolume` types
    are.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将首先解释什么是`PersistentVolume`类型。
- en: Introducing PersistentVolume types
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入 PersistentVolume 类型
- en: 'As you already know, the simplest Kubernetes setup consists of a simple `minikube`
    installation, whereas the most complex Kubernetes setup can be made of dozens
    of servers on a massively scalable infrastructure. All of these different setups
    will forcibly have different ways in which to manage persistent storage. For example,
    the three well-known public cloud providers have a lot of different solutions.
    Let’s name a few, as follows:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你已经知道的，最简单的 Kubernetes 配置只包含一个简单的`minikube`安装，而最复杂的 Kubernetes 配置则可能由数十台服务器组成，运行在一个大规模可扩展的基础设施上。所有这些不同的配置必然会有不同的方式来管理持久化存储。例如，三大著名的公共云提供商提供了许多不同的解决方案。我们来列举几个，如下所示：
- en: Amazon EBS volumes
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon EBS 卷
- en: Amazon **Elastic File System** (**EFS**) filesystems
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amazon **弹性文件系统** (**EFS**) 文件系统
- en: Google GCE **Persistent Disk** (**PD**)
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Google GCE **持久磁盘** (**PD**)
- en: Microsoft Azure disks
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Microsoft Azure 磁盘
- en: These solutions have their own design and set of principles, along with their
    own logic and mechanics. Kubernetes was built with the principle that all of these
    setups should be abstracted using just one object to abstract all of the different
    technologies; that single object is the `PersistentVolume` resource type. The
    `PersistentVolume` resource type is the object that is going to be attached to
    a running Pod. Indeed, a Pod is a Kubernetes resource and does not know what an
    EBS or a PD is; Kubernetes Pods only play well with `PersistentVolumes`, which
    is also a Kubernetes resource.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 这些解决方案都有自己独特的设计和原则，并且有各自的逻辑和机制。Kubernetes 的构建原则是，所有这些配置应当通过一个对象进行抽象，以便处理所有不同的技术；这个单一的对象就是`PersistentVolume`资源类型。`PersistentVolume`资源类型是将附加到运行中的
    Pod 上的对象。事实上，Pod 是 Kubernetes 的一种资源，并不知道 EBS 或 PD 是什么；Kubernetes Pod 只与`PersistentVolumes`协同工作，而`PersistentVolumes`也是一种
    Kubernetes 资源。
- en: Whether your Kubernetes cluster is running on Google GKE or Amazon EKS, or whether
    it is a single minikube cluster on your local machine has no importance. When
    you wish to manage persistent storage, you are going to create, use, and deploy
    `PersistentVolumes` objects, and then bind them to your Pods!
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你的 Kubernetes 集群是在 Google GKE、Amazon EKS 上运行，还是在本地机器上的单个 minikube 集群上运行，都没有关系。当你希望管理持久化存储时，你需要创建、使用并部署`PersistentVolumes`对象，并将它们绑定到你的
    Pods！
- en: 'Here are some of the backend technologies supported by Kubernetes out of the
    box:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Kubernetes 开箱即用的一些后端技术：
- en: '`csi`: **Container Storage Interface** (**CSI**)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`csi`：**容器存储接口** (**CSI**)'
- en: '`fc`: FC storage'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`fc`：FC 存储'
- en: '`iscsi`: SCSI over IP'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`iscsi`：通过 IP 的 SCSI'
- en: '`local`: Using local storage'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`local`：使用本地存储'
- en: '`hostPath`: HostPath volumes'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hostPath`：HostPath 卷'
- en: '`nfs`: Regular network file storage'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nfs`：常规网络文件存储'
- en: 'The preceding list is not exhaustive: Kubernetes is extremely versatile and
    can be used with many storage solutions that can be abstracted as `PersistentVolume`
    objects in your cluster.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 上述列表并不详尽：Kubernetes 非常灵活，可以与许多存储解决方案一起使用，这些解决方案可以在您的集群中抽象为 `PersistentVolume`
    对象。
- en: Please note that in recent versions of Kubernetes, several `PersistentVolume`
    types have been deprecated or removed, indicating a shift in how storage is managed
    within Kubernetes environments. This change is part of the ongoing evolution of
    Kubernetes to streamline its APIs and improve compatibility with modern storage
    solutions.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在 Kubernetes 的最新版本中，几个 `PersistentVolume` 类型已经被弃用或删除，这表明存储管理方式发生了变化。这一变化是
    Kubernetes 持续演进的一部分，旨在简化其 API 并提高与现代存储解决方案的兼容性。
- en: 'For example, the following `PersistentVolume` types are either removed or deprecated
    in Kubernetes 1.29 onwards:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，从 Kubernetes 1.29 起，以下 `PersistentVolume` 类型已被删除或弃用：
- en: '`awsElasticBlockStore` – Amazon EBS'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`awsElasticBlockStore` – 亚马逊 EBS'
- en: '`azureDisk` – Azure Disk'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`azureDisk` – Azure 磁盘'
- en: '`azureFile` – Azure File'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`azureFile` – Azure 文件'
- en: '`portworxVolume` – Portworx volume'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`portworxVolume` – Portworx 卷'
- en: '`flexVolume` – FlexVolume'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`flexVolume` – FlexVolume'
- en: '`vsphereVolume` – vSphere VMDK volume'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`vsphereVolume` – vSphere VMDK 卷'
- en: '`cephfs` – CephFS volume'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cephfs` – CephFS 卷'
- en: '`cinder`'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cinder`'
- en: These changes reflect a broader trend toward standardized storage interfaces
    and an emphasis on more portable, cloud-agnostic solutions. For detailed guidance
    and updated information on PVs and supported types, you can refer to the official
    Kubernetes documentation at https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 这些变化反映了朝着标准化存储接口的更广泛趋势，并强调了更具可移植性和云中立的解决方案。如需详细指南和有关 PV 和支持类型的更新信息，您可以参考官方的
    Kubernetes 文档：[https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes)。
- en: Benefits brought by PersistentVolume
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PersistentVolume 带来的好处
- en: PVs are an essential component in Kubernetes when managing stateful applications.
    Unlike ephemeral storage, PVs ensure data persists beyond the life cycle of individual
    Pods, making them ideal for applications requiring data retention and consistency.
    These storage resources bring flexibility and reliability to the Kubernetes ecosystem,
    enhancing both performance and resilience.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: PV 是 Kubernetes 中管理有状态应用程序的关键组件。与短暂存储不同，PVs 确保数据超越单个 Pod 的生命周期，因此它们非常适合需要数据保留和一致性的应用程序。这些存储资源为
    Kubernetes 生态系统带来了灵活性和可靠性，提升了性能和弹性。
- en: 'There are three major benefits of `PersistentVolume`:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '`PersistentVolume` 有三个主要的好处：'
- en: 'A PV in Kubernetes continues to exist independently of the Pod that uses it.
    This means that if you delete or recreate a Pod attached to a `PersistentVolume`,
    the data stored on that volume remains intact. The data’s persistence depends
    on the reclaim policy of the `PersistentVolume`: with a retain policy, the data
    stays available for future use, while a delete policy removes both the volume
    and its data when the Pod is deleted. Thus, you can manage your Pods without worrying
    about losing data stored on `PersistentVolumes`.'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 中的 PV 独立于使用它的 Pod 存在。这意味着，如果您删除或重新创建一个附加到 `PersistentVolume` 的 Pod，该卷上存储的数据将保持不变。数据的持久性取决于
    `PersistentVolume` 的回收策略：在保留策略下，数据将继续保留供未来使用，而删除策略则在 Pod 被删除时同时删除该卷及其数据。因此，您可以管理您的
    Pod，而无需担心丢失存储在 `PersistentVolumes` 上的数据。
- en: When a Pod crashes, the `PersistentVolume` object will survive the fault and
    not be removed from the cluster.
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当 Pod 崩溃时，`PersistentVolume` 对象将继续存在，不会从集群中删除。
- en: '`PersistentVolume` is cluster-wide; this means that it can be attached to any
    Pod running on any node. (You will learn about restrictions and methods later
    in this chapter.)'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PersistentVolume` 是集群级别的；这意味着它可以附加到任何节点上运行的任何 Pod。（您将在本章后面了解有关限制和方法的内容。）'
- en: Bear in mind that these three statements are not always 100% valid. Indeed,
    sometimes, a `PersistentVolume` object can be affected by its underlying technology.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，这三个声明并不总是 100% 有效。事实上，有时，`PersistentVolume` 对象可能会受到其底层技术的影响。
- en: To demonstrate this, let’s consider a `PersistentVolume` object that is, for
    example, a pointer to a `hostPath` storage on the compute node. In such a setup,
    `PersistentVolume` won’t be available to any other nodes.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示这一点，假设有一个 `PersistentVolume` 对象，它是指向计算节点上 `hostPath` 存储的指针。在这样的设置中，`PersistentVolume`
    不会对其他节点可用。
- en: However, if you take another example, such as an NFS setup, it wouldn’t be the
    same. Indeed, you can access an NFS from multiple machines at once. Therefore,
    a `PersistentVolume` object that is backed by an NFS would be accessible from
    several different Pods running on different nodes without much problem. To understand
    how to make a `PersistentVolume` object on several different nodes at a time,
    we need to consider the concept of access modes, which we’ll be diving into in
    the next section.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你考虑另一个例子，比如NFS设置，情况就不一样了。实际上，你可以从多个机器同时访问NFS。因此，一个由NFS支持的`PersistentVolume`对象可以从运行在不同节点的多个Pod访问，而不会出现太大问题。为了理解如何在多个不同节点上同时创建`PersistentVolume`对象，我们需要考虑访问模式的概念，接下来我们将深入探讨这个话题。
- en: Introducing PersistentVolume access modes
  id: totrans-115
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入PersistentVolume访问模式
- en: As the name suggests, access modes are an option you can set when you create
    a `PersistentVolume` type that will tell Kubernetes how the volume should be mounted.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 顾名思义，访问模式是你在创建`PersistentVolume`类型时可以设置的选项，它将告诉Kubernetes该如何挂载卷。
- en: '`PersistentVolumes` supports four access modes, as follows:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`PersistentVolumes`支持四种访问模式，分别如下：'
- en: '**ReadWriteOnce** (**RWO**): This volume allows read/write by only one node
    at the same time.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ReadWriteOnce**（**RWO**）：此卷仅允许一个节点同时进行读写操作。'
- en: '**ReadOnlyMany** (**ROX**): This volume allows read-only mode by many nodes
    at the same time.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ReadOnlyMany**（**ROX**）：此卷允许多个节点同时以只读模式访问。'
- en: '**ReadWriteMany** (**RWX**): This volume allows read/write by multiple nodes
    at the same time.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ReadWriteMany**（**RWX**）：此卷允许多个节点同时进行读写操作。'
- en: '**ReadWriteOncePod**: This is a new mode introduced recently and is already
    stable in the Kubernetes 1.29 version. In this access mode, the volume is mountable
    as read-write by a single Pod. Employ the `ReadWriteOncePod` access mode when
    you want only one Pod throughout the entire cluster to have the capability to
    read from or write to the **Persistent Volume Claim** (**PVC**).'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ReadWriteOncePod**：这是最近引入的一种新模式，并且在Kubernetes 1.29版本中已稳定。在此访问模式下，卷可以被单个Pod以读写方式挂载。当你希望整个集群中只有一个Pod可以读取或写入**持久卷声明**（**PVC**）时，请使用`ReadWriteOncePod`访问模式。'
- en: It is necessary to set at least one access mode to a `PersistentVolume` type,
    even if said volume supports multiple access modes. Indeed, not all `PersistentVolume`
    types will support all access modes, as shown in the below table.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 即使某个`PersistentVolume`类型支持多种访问模式，仍然必须至少设置一种访问模式。事实上，并非所有`PersistentVolume`类型都支持所有访问模式，具体如下面的表格所示。
- en: '![](img/B22019_09_01.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_09_01.png)'
- en: 'Table 9.1: Access modes supported by different PersistentVolume types (Image
    source: kubernetes.io/docs/concepts/storage/persistent-volumes)'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 表9.1：不同PersistentVolume类型支持的访问模式（图片来源：kubernetes.io/docs/concepts/storage/persistent-volumes）
- en: 'In Kubernetes, the access modes of a `PersistentVolume` type are closely tied
    to the underlying storage technology and how it handles data. Here’s why different
    PV types support specific modes:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，`PersistentVolume`类型的访问模式与底层存储技术及其数据处理方式密切相关。这就是为什么不同的PV类型只支持特定模式的原因：
- en: '**File vs. block storage:**'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '**文件存储与块存储：**'
- en: File storage (like **Network File System** (**NFS**) or **Common Internet File
    System** (**CIFS**)) allows multiple clients to access the same files concurrently.
    This is why file storage systems can support a variety of access modes, such as
    RWO, ROX, and RWX. They are built to handle multi-client access over a network,
    enabling several nodes to read and write from the same volume without data corruption.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件存储（如**网络文件系统**（**NFS**）或**常见互联网文件系统**（**CIFS**））允许多个客户端同时访问相同的文件。这就是为什么文件存储系统能够支持多种访问模式，如RWO、ROX和RWX。它们设计用于处理网络上的多客户端访问，使得多个节点能够从同一卷读取和写入，而不会导致数据损坏。
- en: Block storage (like local storage or hostPath) is fundamentally different. Block
    storage is designed for one client to access at a time because it deals with raw
    disk sectors rather than files. Concurrent access by multiple clients would lead
    to data inconsistency or corruption. For this reason, block storage supports only
    the RWO mode, where a single node can both read and write to the volume.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 块存储（如本地存储或hostPath）本质上有所不同。块存储设计用于一次只能由一个客户端访问，因为它处理的是原始磁盘扇区，而不是文件。多个客户端的并发访问会导致数据不一致或损坏。因此，块存储仅支持RWO模式，在该模式下，单个节点可以对卷进行读写操作。
- en: '**Internal vs. external storage:**'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '**内部存储与外部存储：**'
- en: hostPath volumes, which refer to storage on the same node as the workload, are
    inherently restricted to that node. Since this storage is tied to the physical
    node, it cannot be accessed by other nodes in the cluster. This makes it only
    compatible with the RWO mode.
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`hostPath`卷，指的是与工作负载位于同一节点上的存储，天生受到该节点的限制。由于此存储与物理节点绑定，它不能被集群中的其他节点访问。这使得它仅与RWO模式兼容。'
- en: NFS or other external storage solutions, on the other hand, are designed to
    allow access over a network, enabling multiple nodes to share the same storage.
    This flexibility allows them to support additional modes like RWX.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一方面，NFS或其他外部存储解决方案被设计为允许通过网络访问，使多个节点能够共享相同的存储。这种灵活性使它们能够支持额外的模式，如RWX。
- en: Understanding this distinction helps to clarify why some `PersistentVolume`
    types support more flexible access modes, while others are constrained.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 理解这一区分有助于澄清为什么某些`PersistentVolume`类型支持更灵活的访问模式，而其他类型则受限。
- en: Now, let’s create our first `PersistentVolume` object.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建我们的第一个`PersistentVolume`对象。
- en: Creating our first PersistentVolume object
  id: totrans-134
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建我们的第一个PersistentVolume对象
- en: Let’s create a `PersistentVolume` on the Kubernetes cluster using the declarative
    approach. Since `PersistentVolume`s are more complex resources, it’s highly recommended
    to avoid using the imperative method. The declarative approach allows you to define
    and manage resources consistently in YAML files, making it easier to track changes,
    version control your configurations, and ensure repeatability across different
    environments. This approach also makes it simpler to manage large or complex resources
    like `PersistentVolume`s, where precise configurations and careful planning are
    essential.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用声明式方法在Kubernetes集群上创建一个`PersistentVolume`。由于`PersistentVolume`是更复杂的资源，强烈建议避免使用命令式方法。声明式方法允许你在`YAML`文件中一致地定义和管理资源，使得跟踪更改、版本控制配置，并确保在不同环境中重复执行变得更加容易。这个方法也使得管理像`PersistentVolume`这样的大型或复杂资源变得更简单，因为精确的配置和细致的规划至关重要。
- en: 'See the example YAML definition below for creating a `PersistentVolume` object:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅下面的示例YAML定义，用于创建`PersistentVolume`对象：
- en: '[PRE11]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This is the simplest form of `PersistentVolume`. Essentially, this `YAML` file
    creates a `PersistentVolume` entry within the Kubernetes cluster. So, this `PersistentVolume`
    will be a `hostPath` type.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 这是`PersistentVolume`的最简单形式。本质上，这个`YAML`文件在Kubernetes集群中创建了一个`PersistentVolume`条目。因此，这个`PersistentVolume`将是`hostPath`类型。
- en: The `hostPath` type `PersistentVolume` is not recommended for production or
    critical workloads. We are using it here for demonstration purposes only.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '`hostPath`类型的`PersistentVolume`不建议用于生产或关键工作负载。我们在这里仅用于演示目的。'
- en: 'Let’s apply the PV configuration to the cluster as follows:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们按如下方式将PV配置应用到集群中：
- en: '[PRE12]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: It could be a more complex volume, such as a cloud-based disk or an NFS, but
    in its simplest form, a `PersistentVolume` can simply be a `hostPath` type on
    the node running your Pod.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以是更复杂的卷，比如基于云的磁盘或NFS，但在最简单的形式下，`PersistentVolume`可以仅仅是运行Pod的节点上的`hostPath`类型。
- en: How does Kubernetes PersistentVolumes handle storage?
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes的PersistentVolumes如何处理存储？
- en: As we learned earlier, the `PersistentVolume` resource type is a pointer to
    a storage location and that can be, for example, a disk, an NFS drive, or a disk
    volume controlled by a storage operator. All of these different technologies are
    managed differently. However, fortunately for us, in Kubernetes, they are all
    represented by the `PersistentVolume` object.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前学到的，`PersistentVolume`资源类型是指向一个存储位置的指针，这个位置可以是磁盘、NFS驱动器，或者是由存储操作员控制的磁盘卷。所有这些不同的技术都以不同的方式进行管理。然而，幸运的是，在Kubernetes中，它们都由`PersistentVolume`对象表示。
- en: 'Simply put, the `YAML` file to create a `PersistentVolume` will be a little
    bit different depending on the backend technology that the `PersistentVolume`
    is backed by. For example, if you want your `PersistentVolume` to be a pointer
    to an NFS share, you have to meet the following two conditions:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，创建`PersistentVolume`的`YAML`文件会根据`PersistentVolume`背后的后端技术有所不同。例如，如果你希望你的`PersistentVolume`指向NFS共享，你需要满足以下两个条件：
- en: The NFS share is already configured and reachable from the Kubernetes nodes.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NFS共享已经配置好，并且可以从Kubernetes节点访问。
- en: The `YAML` file for your `PersistentVolume` must include the NFS server details
    and NFS share information.
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于创建`PersistentVolume`的`YAML`文件必须包含NFS服务器的详细信息和NFS共享信息。
- en: 'The following YAML definition is a sample for creating a `PersistentVolume`
    using NFS as the backend:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 以下YAML定义是使用NFS作为后端创建`PersistentVolume`的示例：
- en: '[PRE13]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: For a `PersistentVolume` to work properly, it needs to be able to link Kubernetes
    and the actual storage. So, you need to create a piece of storage or provision
    it outside of Kubernetes and then create the `PersistentVolume` entry by including
    the unique ID of the disk, or the volume, that is backed by a storage technology
    that is external to Kubernetes. Next, let’s take a closer look at some examples
    of `PersistentVolume` YAML files in the next section.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让`PersistentVolume`正常工作，它需要能够将Kubernetes与实际的存储进行连接。所以，你需要在Kubernetes外部创建一个存储资源或进行存储资源的供应，然后通过包含由外部存储技术支持的磁盘或卷的唯一ID来创建`PersistentVolume`条目。接下来，让我们在下一节详细了解一些`PersistentVolume`的YAML文件示例。
- en: Creating PersistentVolume with raw block volume
  id: totrans-151
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用原始块存储卷创建PersistentVolume
- en: 'This example displays a `PersistentVolume` object that is pointing to raw block
    volume:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 这个示例展示了一个指向原始块存储卷的`PersistentVolume`对象：
- en: '[PRE14]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: As you can see, in this `YAML` file, the fc section contains the FC volume details
    that this `PersistentVolume` object is pointing to. The exact raw volume is identified
    by the `targetWWNs` key. That’s pretty much it. With this YAML file, Kubernetes
    is capable of finding the proper **World Wide Name** (**WWN**) and maintaining
    a pointer to it.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，在这个`YAML`文件中，fc部分包含了这个`PersistentVolume`对象所指向的FC存储卷的详细信息。具体的原始卷通过`targetWWNs`键来识别。就是这么简单。通过这个YAML文件，Kubernetes能够找到合适的**全球唯一名称**（**WWN**）并保持指向它的指针。
- en: Now, let’s discuss a little bit about the provisioning of storage resources.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们稍微讨论一下存储资源的供应。
- en: Can Kubernetes handle the provisioning or creation of the resource itself?
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes能否处理资源本身的供应或创建？
- en: The fact that you need to create the actual storage resource separately and
    then create a `PersistentVolume` in Kubernetes might be tedious.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 需要单独创建实际的存储资源，然后在Kubernetes中创建`PersistentVolume`这一事实可能有些繁琐。
- en: Fortunately for us, Kubernetes is also capable of communicating with the **APIs**
    of your cloud provider or other storage backends in order to create volumes or
    disks on the fly. There is something called **dynamic provisioning** that you
    can use when it comes to managing `PersistentVolume`. It makes things a lot simpler
    when dealing with `PersistentVolume` provisioning, but it only works on supported
    storage backends or cloud providers.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，Kubernetes也能够与云提供商或其他存储后端的**API**进行通信，以便动态创建卷或磁盘。这里有一个叫做**动态供应**的功能，专门用于管理`PersistentVolume`。当涉及到`PersistentVolume`供应时，它让事情变得更加简单，但仅在受支持的存储后端或云提供商上有效。
- en: However, this is an advanced topic, so we will discuss it in more detail later
    in this chapter.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这是一个高级话题，我们将在本章稍后详细讨论。
- en: Now that we know how to provision `PersistentVolume` objects inside our cluster,
    we can try to mount them. Indeed, in Kubernetes, once you create a `PersistentVolume`,
    you need to mount it to a Pod so that it can be used. Things will get slightly
    more advanced and conceptual here; Kubernetes uses an intermediate object in order
    to mount a `PersistentVolume` to Pods. This intermediate object is called `PersistentVolumeClaim`.
    Let’s focus on it in the upcoming section.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经知道如何在集群内部署`PersistentVolume`对象，接下来可以尝试将它们挂载到Pod上。实际上，在Kubernetes中，一旦你创建了一个`PersistentVolume`，你需要将它挂载到Pod上才能使用。在这里，事情会稍微变得更为复杂和概念化；Kubernetes使用一个中间对象来将`PersistentVolume`挂载到Pod上。这个中间对象叫做`PersistentVolumeClaim`。接下来我们将专注于它。
- en: Understanding how to mount a PersistentVolume to your Pod
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解如何将PersistentVolume挂载到你的Pod
- en: We can now try to mount a `PersistentVolume` object to a Pod. To do that, we
    will need to use another object, which is the second object we need to explore
    in this chapter, called `PersistentVolumeClaim`.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以尝试将一个`PersistentVolume`对象挂载到Pod。为了实现这一点，我们需要使用另一个对象，这也是本章需要探索的第二个对象，叫做`PersistentVolumeClaim`。
- en: Introducing PersistentVolumeClaim
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍PersistentVolumeClaim
- en: Just like `PersistentVolume` or `ConfigMap`, `PersistentVolumeClaim` is another
    independent resource type living within your Kubernetes cluster.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 就像`PersistentVolume`或`ConfigMap`一样，`PersistentVolumeClaim`也是在你的Kubernetes集群中存在的另一种独立资源类型。
- en: First, bear in mind that even if both names are almost the same, `PersistentVolume`
    and `PersistentVolumeClaim` are two distinct resources that represent two different
    things.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，请记住，即使这两个名字几乎相同，`PersistentVolume`和`PersistentVolumeClaim`是两个不同的资源，代表着两种不同的事物。
- en: 'You can list the `PersistentVolumeClaim` resource type created within your
    cluster using `kubectl`, as follows:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`kubectl`列出在集群内创建的`PersistentVolumeClaim`资源类型，如下所示：
- en: '[PRE15]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The following output tells us that we don’t have any `PersistentVolumeClaim`
    resources created within my cluster. Please note that the `pvc` alias works, too:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 以下输出告诉我们，在我的集群中没有创建任何`PersistentVolumeClaim`资源。请注意，`pvc`别名同样有效：
- en: '[PRE16]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: You’ll quickly find that a lot of people working with Kubernetes refer to the
    `PersistentVolumeClaim` resources simply with `pvc`. So, don’t be surprised if
    you see the term `pvc` here and there while working with Kubernetes. That being
    said, let’s explain what `PersistentVolumeClaim` resources are in Kubernetes.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 你会很快发现，很多使用Kubernetes的人简单地将`PersistentVolumeClaim`资源称为`pvc`。所以，在使用Kubernetes时，如果看到`pvc`这个术语，不要感到惊讶。话虽如此，接下来让我们来解释一下Kubernetes中的`PersistentVolumeClaim`资源。
- en: Splitting storage creation and storage consumption
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 存储创建与存储消费的分离
- en: The key to understanding the difference between `PersistentVolume` and `PersistentVolumeClaim`
    is to understand that one is meant to represent the storage itself, whereas the
    other one represents the request for storage that a Pod makes to get the actual
    storage.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 理解`PersistentVolume`和`PersistentVolumeClaim`之间区别的关键在于理解：一个是用来表示存储本身，而另一个则表示Pod请求实际存储的需求。
- en: 'The reason is that Kubernetes is typically supposed to be used by two types
    of people:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 原因在于Kubernetes通常是由两类人使用：
- en: '**Kubernetes administrator**: This person is supposed to maintain the cluster,
    operate it, and also add computation resources and persistent storage.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes管理员**：这个人负责维护集群、操作集群，并添加计算资源和持久存储。'
- en: '**Kubernetes application developer**: This person is supposed to develop and
    deploy an application, so, put simply, consume the computation resource and storage
    offered by the administrator.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes应用开发者**：这个人负责开发和部署应用程序，简单来说，就是消费管理员提供的计算资源和存储。'
- en: In fact, there is no problem if you handle both roles in your organization;
    however, this information is crucial to understand the workflow to mount `PersistentVolume`
    to Pods.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，如果你在你的组织中同时承担这两个角色也是没有问题的；然而，这个信息对于理解如何将`PersistentVolume`挂载到Pods的工作流程至关重要。
- en: Kubernetes was built with the idea that a `PersistentVolume` object should belong
    to the cluster administrator scope, whereas `PersistentVolumeClaim` objects belong
    to the application developer scope. It is up to the cluster administrator to add
    `PersistentVolumes` (or dynamic volume operators) since they might be hardware
    resources, whereas developers have a better understanding of what amount of storage
    and what kind of storage is needed, and that’s why the `PersistentVolumeClaim`
    object was built.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes的设计理念是，`PersistentVolume`对象应该属于集群管理员的范围，而`PersistentVolumeClaim`对象属于应用开发者的范围。集群管理员负责添加`PersistentVolumes`（或动态卷操作器），因为它们可能是硬件资源，而开发者更清楚需要多少存储以及需要什么样的存储，这就是为什么构建了`PersistentVolumeClaim`对象。
- en: Essentially, a Pod cannot mount a `PersistentVolume` object directly. It needs
    to explicitly ask for it. This *asking* action is achieved by creating a `PersistentVolumeClaim`
    object and attaching it to the Pod that needs a `PersistentVolume` object.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，Pod无法直接挂载`PersistentVolume`对象。它需要明确地请求它。这种*请求*操作是通过创建`PersistentVolumeClaim`对象并将其附加到需要`PersistentVolume`对象的Pod上来实现的。
- en: This is the only reason why this additional layer of abstraction exists. Now,
    let’s understand the `PersistentVolume` workflow summarized in the next section.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么存在额外抽象层的唯一原因。现在，让我们理解下一部分总结的`PersistentVolume`工作流程。
- en: Understanding the PersistentVolume workflow
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解PersistentVolume的工作流程
- en: 'Once the developer has built the application, it is their responsibility to
    ask for a `PersistentVolume` object if needed. To do that, the developer will
    write two `YAML` manifests:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦开发者构建好应用程序，如果需要，他们有责任请求一个`PersistentVolume`对象。为此，开发者将编写两个`YAML`清单：
- en: One manifest will be written for the Pod or deployment.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个清单将会写为Pod或部署。
- en: The other manifest will be written for `PersistentVolumeClaim`.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 另一个清单将会写为`PersistentVolumeClaim`。
- en: The Pod must be written so that the `PersistentVolumeClaim` object is mounted
    as a `volumeMount` configuration key in the YAML file. Please note that for it
    to work, the `PersistentVolumeClaim` object needs to be in the same namespace
    as the application Pod that is mounting it. When both YAML files are applied and
    both resources are created in the cluster, the `PersistentVolumeClaim` object
    will look for a `PersistentVolume` object that matches the criteria required in
    the claim. Supposing that a `PersistentVolume` object capable of fulfilling the
    claim is created and ready in the Kubernetes cluster, the `PersistentVolume` object
    will be attached to the `PersistentVolumeClaim` object.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 必须按如下方式编写，以便 `PersistentVolumeClaim` 对象作为 `volumeMount` 配置键挂载在 YAML 文件中。请注意，为了使其工作，`PersistentVolumeClaim`
    对象需要与挂载它的应用程序 Pod 在同一命名空间中。当两个 YAML 文件都应用并且资源都在集群中创建时，`PersistentVolumeClaim`
    对象将查找一个符合声明要求的 `PersistentVolume` 对象。假设在 Kubernetes 集群中创建并准备了一个能够满足声明的 `PersistentVolume`
    对象，那么该对象将被附加到 `PersistentVolumeClaim` 对象上。
- en: 'If everything is okay, the claim is considered fulfilled, and the volume is
    correctly mounted to the Pod: if you understand this workflow, essentially, you
    understand everything related to `PersistentVolume` usage.'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一切正常，声明被认为已完成，卷被正确挂载到 Pod 上：如果你理解这个工作流程，基本上你就理解了与 `PersistentVolume` 使用相关的一切。
- en: The following diagram illustrates the workflow in static storage provisioning
    in Kubernetes.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了 Kubernetes 中静态存储供应的工作流程。
- en: '![](img/B22019_09_02.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_09_02.png)'
- en: 'Figure 9.1: Static storage provisioning in Kubernetes'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9.1：Kubernetes 中的静态存储供应
- en: You will learn about dynamic storage provisioning in a later section of this
    chapter, *Introducing dynamic provisioning*.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在本章的后续部分学习动态存储供应，*介绍动态供应*。
- en: 'Imagine a developer needs persistent storage for their application running
    in Kubernetes. Here’s the choreography that ensues:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下，一个开发者需要为其在 Kubernetes 中运行的应用程序提供持久存储。以下是接下来发生的流程：
- en: 'The administrator prepares `PersistentVolume`: The Kubernetes administrator
    prepares the backend storage and creates a `PersistentVolume` object. This PV
    acts like a storage declaration, specifying details like capacity, access mode
    (read-write, read-only), and the underlying storage system (e.g., hostPath, NFS).'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 管理员准备 `PersistentVolume`：Kubernetes 管理员准备后端存储并创建一个 `PersistentVolume` 对象。该 PV
    类似于存储声明，指定容量、访问模式（读写、只读）以及底层存储系统（例如，hostPath、NFS）等细节。
- en: 'The developer makes a claim using `PersistentVolumeClaim`: The developer creates
    a `PersistentVolumeClaim` object. This PVC acts like a storage request, outlining
    the developer’s needs. It specifies the size, access mode, and any storage class
    preferences (think of it as a wishlist for storage). The developer also defines
    a volume mount in the Pod’s YAML file, specifying how the Pod should access the
    persistent storage volume.'
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开发者使用 `PersistentVolumeClaim` 发出请求：开发者创建一个 `PersistentVolumeClaim` 对象。这个 PVC
    就像一个存储请求，列出了开发者的需求。它指定了大小、访问模式和任何存储类的偏好（可以将其视为存储的愿望清单）。开发者还在 Pod 的 YAML 文件中定义了一个卷挂载，指定了
    Pod 如何访问持久存储卷。
- en: 'Kubernetes fulfills the request: After the Pod and PVC are created, Kubernetes
    searches for a suitable PV that matches the requirements listed in the PVC. It’s
    like a match-making service, ensuring the requested storage aligns with what’s
    available.'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes 执行请求：在 Pod 和 PVC 创建后，Kubernetes 会查找一个合适的 PV，匹配 PVC 中列出的要求。这就像一个配对服务，确保请求的存储与可用的存储相符。
- en: 'The Pod leverages the storage using `volumeMount`: Once Kubernetes finds a
    matching PV, it binds it to the PVC. This makes the storage accessible to the
    Pod.'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pod 使用 `volumeMount` 利用存储：一旦 Kubernetes 找到一个匹配的 PV，它会将其绑定到 PVC 上。这使得存储对 Pod
    可访问。
- en: 'Data flow begins (**read/write operations**): Now, the Pod can interact with
    the persistent storage based on the access mode defined in the PV. It can perform
    read or write operations on the data stored in the volume, ensuring data persistence
    even if the Pod restarts.'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 数据流开始（**读/写操作**）：现在，Pod 可以根据 PV 中定义的访问模式与持久存储进行交互。它可以对存储在卷中的数据执行读写操作，即使 Pod
    重启也能确保数据持久性。
- en: Please note that `PersistentVolume` is cluster-scoped, while `PersistentVolumeClaim`,
    Pod, and `volumeMount` are namespace-scoped objects.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`PersistentVolume` 是集群范围的，而 `PersistentVolumeClaim`、Pod 和 `volumeMount`
    是命名空间范围的对象。
- en: This collaboration between PVs, PVCs, and Kubernetes ensures that the developers
    have access to persistent storage for their applications, enabling them to store
    and retrieve data across Pod life cycles.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: PV、PVC和Kubernetes之间的协作确保了开发人员可以访问持久存储，以支持他们的应用程序，从而使他们能够在Pod生命周期之间存储和检索数据。
- en: This setup might seem complex to understand at first, but you will quickly get
    used to it.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这种设置可能一开始看起来有些复杂，但你很快就会习惯它。
- en: In the following section, we will learn how to use the storage in Pods using
    `PersistentVolume` and `PersistentVolumeClaim`.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将学习如何使用`PersistentVolume`和`PersistentVolumeClaim`在Pod中使用存储。
- en: Creating a Pod with a PersistentVolumeClaim object
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个带有PersistentVolumeClaim对象的Pod
- en: In this section, we will create a Pod that mounts `PersisentVolume` within a
    `minikube` cluster. This is going to be a kind of `PersisentVolume` object, but
    this time, it will not be bound to the life cycle of the Pod. Indeed, since it
    will be managed as a real `PersisentVolume` object, the `hostPath` type will get
    its life cycle independent of the Pod.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将创建一个Pod，该Pod会在`minikube`集群中挂载`PersistentVolume`。这将是一个`PersistentVolume`对象，但这次它不会绑定到Pod的生命周期。实际上，由于它将作为一个真正的`PersistentVolume`对象进行管理，`hostPath`类型将使其生命周期独立于Pod。
- en: 'The very first thing to do is create the `PersisentVolume` object that will
    be a `hostPath` type. Here is the YAML file to do that. Please note that we created
    this `PersisentVolume` object with some arbitrary labels in the `metadata` section.
    This is so that it will be easier to fetch it from the `PersistentVolumeClaim`
    object later:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 第一件事是创建一个`PersistentVolume`对象，它将是一个`hostPath`类型。以下是实现该操作的YAML文件。请注意，我们在`metadata`部分为这个`PersistentVolume`对象创建了一些任意标签。这样，稍后从`PersistentVolumeClaim`对象中获取它时会更容易。
- en: '[PRE17]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Please note the following items in the YAML, which we will use for matching
    the PVC later:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意YAML中的以下项目，我们稍后将用于匹配PVC：
- en: '`labels`'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`'
- en: '`capacity`'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`capacity`'
- en: '`accessModes`'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`accessModes`'
- en: '`StorageClassName`'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`StorageClassName`'
- en: 'We can now create and list the `PersisentVolume` entries available in our cluster,
    and we should observe that this one exists. Please note that the `pv` alias works,
    too:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以创建并列出我们集群中可用的`PersistentVolume`条目，并且应该看到这个条目已存在。请注意，`pv`别名同样有效：
- en: '[PRE18]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: We can see that the `PersisentVolume` was successfully created, and the status
    is `Available`.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，`PersistentVolume`已经成功创建，状态为`Available`。
- en: 'Now, we need to create two things to mount the `PersisentVolume` object:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要创建两个东西来挂载`PersistentVolume`对象：
- en: A `PersistentVolumeClaim` object that targets this specific `PersisentVolume`
    object
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个针对特定`PersistentVolume`对象的`PersistentVolumeClaim`对象
- en: A Pod to use the `PersistentVolumeClaim` object
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个使用`PersistentVolumeClaim`对象的Pod
- en: 'To demonstrate the namespace scoped items and cluster scoped items, let us
    create a namespace for the PVC and Pod (refer to the `pv-ns.yaml` file):'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示命名空间范围的项目和集群范围的项目，让我们为PVC和Pod创建一个命名空间（请参阅`pv-ns.yaml`文件）：
- en: '[PRE19]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Let’s proceed, in order, with the creation of the `PersistentVolumeClaim` object:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们按顺序创建`PersistentVolumeClaim`对象：
- en: '[PRE20]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Let’s create the PVC and check that it was successfully created in the cluster.
    Please note that the `pvc` alias also works here:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建PVC，并检查它是否在集群中成功创建。请注意，`pvc`别名在这里也能正常工作：
- en: '[PRE21]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Please note the PVC status now – `Bound` – which means the PVC is already matched
    with a PV and ready to consume the storage.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，现在PVC的状态是`Bound`，这意味着PVC已经与PV匹配，并准备好使用存储。
- en: Now that the `PersisentVolume` object and the `PersistentVolumeClaim` object
    exist, we can create a Pod that will mount the PV using the PVC.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，`PersistentVolume`对象和`PersistentVolumeClaim`对象已经存在，我们可以创建一个Pod，该Pod将使用PVC挂载PV。
- en: 'Let’s create an NGINX Pod that will do the job:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建一个NGINX Pod来完成这个任务：
- en: '[PRE22]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: As you can see, in the `volumeMounts` section, the `PersistentVolumeClaim` object
    is referenced as a volume, and we reference the PVC by its name. Note that the
    PVC must live in the same namespace as the Pod that mounts it. This is because
    PVCs are **namespace-scoped** resources, whereas PVs are not. There are no labels
    and selectors for this one; to bind a PVC to a Pod, you simply need to use the
    PVC name.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，在`volumeMounts`部分，`PersistentVolumeClaim`对象被作为一个卷引用，我们通过其名称来引用PVC。请注意，PVC必须与挂载它的Pod位于同一命名空间。这是因为PVC是**命名空间范围**的资源，而PV不是。这个资源没有标签和选择器；要将PVC绑定到Pod，只需使用PVC的名称即可。
- en: That way, the Pod will become attached to the `PersistentVolumeClaim` object,
    which will find the corresponding `PersisentVolume` object. This, in the end,
    will make the host path available and mounted on my NGINX Pod.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，Pod 将会附加到 `PersistentVolumeClaim` 对象上，该对象会找到对应的 `PersistentVolume` 对象。最终，这将使主机路径在我的
    NGINX Pod 上可用并挂载。
- en: 'Create the Pod and test the status:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 创建 Pod 并测试状态：
- en: '[PRE23]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The Pod is up and running with the hostPath `/tmp/test` mounted inside via the
    PV and PVC. So far, we have learned what `PersistentVolume` and `PersistentVolumeClaim`
    objects are and how to use them to mount persistent storage on your Pods.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 启动并运行，主机路径 `/tmp/test` 通过 PV 和 PVC 挂载在里面。到目前为止，我们已经了解了 `PersistentVolume`
    和 `PersistentVolumeClaim` 对象是什么，以及如何使用它们在 Pod 上挂载持久存储。
- en: Next, we must continue our exploration of the `PersistentVolume` and `PersistentVolumeClaim`
    mechanics by explaining the life cycle of these two objects. Because they are
    independent of the Pods, their life cycles have some dedicated behaviors that
    you need to be aware of.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们必须继续探索 `PersistentVolume` 和 `PersistentVolumeClaim` 的机制，解释这两个对象的生命周期。由于它们独立于
    Pod，它们的生命周期具有一些特定的行为，需要你特别关注。
- en: Understanding the life cycle of a PersistentVolume object in Kubernetes
  id: totrans-231
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 中 PersistentVolume 对象的生命周期
- en: '`PersistentVolume` objects are good if you want to maintain the state of your
    app without being constrained by the life cycle of the Pods or containers that
    are running them.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '`PersistentVolume` 对象非常适合用来维护应用的状态，而不受运行它们的 Pods 或容器生命周期的限制。'
- en: However, since `PersistentVolume` objects get their very own life cycle, they
    have some very specific mechanics that you need to be aware of when you’re using
    them. We’ll take a closer look at them next.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，由于 `PersistentVolume` 对象有自己的生命周期，它们具有一些你在使用时需要注意的特定机制。我们接下来会更详细地探讨它们。
- en: Understanding why PersistentVolume objects are not bound to namespaces
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解为什么 PersistentVolume 对象不绑定到命名空间
- en: The first thing to be aware of when you’re using `PersistentVolume` objects
    is that they are not `namespaced` resources, but `PersistentVolumeClaim` objects
    are.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 `PersistentVolume` 对象时需要注意的第一件事是，它们不是 `namespaced`（命名空间限定的）资源，而 `PersistentVolumeClaim`
    对象是。
- en: '[PRE24]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: So, if the Pod wants to use the `PersistentVolume`, then the `PersistentVolumeClaim`
    must be created in the same namespace as the Pod.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果 Pod 想要使用 `PersistentVolume`，那么 `PersistentVolumeClaim` 必须与 Pod 在同一个命名空间内创建。
- en: 'The `PersistentVolume` will have the following life cycle stages typically:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '`PersistentVolume` 通常会有以下生命周期阶段：'
- en: '**Provisioning**: Admin creates the PV, defining capacity, access modes, and
    optional details like storage class and reclaim policy.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**供应**：管理员创建 PV，定义容量、访问模式以及可选的详细信息，如存储类和回收策略。'
- en: '**Unbound state**: Initially, the PV is available but not attached to any Pod
    (unbound).'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**未绑定状态**：最初，PV 可用但未附加到任何 Pod（未绑定）。'
- en: '**Claiming**: The developer creates a PVC, specifying size, access mode, and
    storage class preference (request for storage).'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**声明**：开发者创建 PVC，指定大小、访问模式和存储类偏好（请求存储）。'
- en: '**Matching and binding**: Kubernetes finds an unbound PV that matches the PVC
    requirements and binds them together.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**匹配和绑定**：Kubernetes 查找一个未绑定的 PV，该 PV 满足 PVC 的要求，并将它们绑定在一起。'
- en: '**Using**: Pod accesses the bound PV through a volume mount defined in its
    YAML file.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用**：Pod 通过其 YAML 文件中定义的卷挂载访问绑定的 PV。'
- en: '**Releasing**: When the Pod using the PVC is deleted, the PVC becomes unbound
    (the PV state depends on the reclaim policy).'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**释放**：当使用 PVC 的 Pod 被删除时，PVC 变为未绑定（PV 状态取决于回收策略）。'
- en: '**Deletion**: The PV object itself can be deleted by the administrator, following
    the configured reclaim policy for the storage resource.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**删除**：管理员可以根据存储资源的回收策略删除 PV 对象本身。'
- en: Now, let’s examine another important aspect of `PersistentVolume`, known as
    reclaiming a policy. This is something that is going to be important when you
    want to unmount a PVC from a running Pod.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查一下 `PersistentVolume` 的另一个重要方面，称为回收策略。这在你想要卸载运行中的 Pod 上的 PVC 时非常重要。
- en: Reclaiming a PersistentVolume object
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回收 PersistentVolume 对象
- en: When it comes to `PersistentVolume`, there is a very important option that you
    need to understand, which is the reclaim policy. But what does this option do?
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及到`PersistentVolume`时，有一个非常重要的选项是你需要理解的，那就是回收策略。那么这个选项具体有什么作用呢？
- en: This option will tell Kubernetes what treatment it should give to your `PersistentVolume`
    object when you delete the corresponding `PersistentVolumeClaim` object that was
    attaching it to the Pods.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这个选项会告诉 Kubernetes 在删除与之关联的 `PersistentVolumeClaim` 对象时，应该对你的 `PersistentVolume`
    对象执行何种操作。
- en: Indeed, deleting a `PersistentVolumeClaim` object consists of deleting the link
    between the Pods and your `PersistentVolume` object, so it’s like you unmount
    the volume and then the volume becomes available again for another application
    to use.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，删除 `PersistentVolumeClaim` 对象就是删除 Pods 与 `PersistentVolume` 对象之间的连接，所以这就像是卸载卷，然后该卷可以再次被其他应用程序使用。
- en: However, in some cases, you don’t want that behavior; instead, you want your
    `PersistentVolume` object to be automatically removed when its corresponding `PersistentVolumeClaim`
    object has been deleted. That’s why the reclaim policy option exists, and it is
    what you should configure.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在某些情况下，你可能不希望这种行为；相反，你希望在删除相应的 `PersistentVolumeClaim` 对象后，`PersistentVolume`
    对象会被自动移除。这就是回收策略选项存在的原因，也是你应该配置的内容。
- en: 'Let’s explain these three reclaim policies:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来解释这三种回收策略：
- en: '**Delete**: This is the simplest of the three. When you set your reclaim policy
    to delete, the `PersistentVolume` object will be wiped out and the `PersistentVolume`
    entry will be removed from the Kubernetes cluster when the corresponding `PersistentVolumeClaim`
    object is deleted. You can use this when you want your data to be deleted and
    not used by any other application. Bear in mind that this is a permanent option,
    so you might want to build a backup strategy with your underlying storage provider
    if you need to recover anything.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**删除**：这是三者中最简单的一种。当你将回收策略设置为删除时，在删除对应的 `PersistentVolumeClaim` 对象时，`PersistentVolume`
    对象会被清除，并且 `PersistentVolume` 记录将从 Kubernetes 集群中移除。你可以在希望删除数据并不让其他应用程序使用时使用这种策略。请记住，这是一个永久性选项，所以如果你需要恢复任何内容，可能需要与底层存储提供商建立备份策略。'
- en: In our example, the PV was created manually with hostPath and the path is `/tmp/`.
    The deletion operation will work without any issues here. However, the delete
    operation may not work for all PV types when you create it manually. It is highly
    recommended to use dynamic PV provisioning, which you will learn about later in
    this chapter.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，PV 是通过 hostPath 手动创建的，路径为`/tmp/`。删除操作在这里将没有任何问题。然而，当你手动创建 PV 时，删除操作可能并不适用于所有
    PV 类型。强烈建议使用动态 PV 配置，稍后在本章中你将学习到它。
- en: '**Retain**: This is the second policy and is contrary to the delete policy.
    If you set this reclaim policy, the `PersistentVolume` object won’t be deleted
    if you delete its corresponding `PersistentVolumeClaim` object. Instead, the `PersistentVolume`
    object will enter the released status, which means it is still available in the
    cluster, and all of its data can be manually retrieved by the cluster administrator.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**保留**：这是第二种策略，与删除策略相反。如果你设置了这个回收策略，那么在删除对应的 `PersistentVolumeClaim` 对象时，`PersistentVolume`
    对象不会被删除。相反，`PersistentVolume` 对象会进入释放状态，这意味着它仍然可在集群中使用，且集群管理员可以手动取回所有数据。'
- en: '**Recycle**: This is a kind of combination of the previous two policies. First,
    the volume is wiped of all its data, such as a basic `rm -rf volume/*` volume.
    However, the volume itself will remain accessible in the cluster, so you can mount
    it again on your application.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回收**：这是一种结合前两种策略的策略。首先，卷会被清空所有数据，例如基本的 `rm -rf volume/*` 操作。然而，卷本身仍然会在集群中可访问，因此你可以将它重新挂载到你的应用程序上。'
- en: The recycle reclaim policy has been deprecated. It is now advised to utilize
    dynamic provisioning as the preferred approach.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 回收策略中的回收模式已经被弃用。现在建议采用动态配置作为首选方法。
- en: The reclaim policy can be set in your cluster directly in the YAML definition
    file at the `PersistentVolume` level.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 回收策略可以在集群中直接通过 `PersistentVolume` 的 YAML 定义文件进行设置。
- en: Updating a reclaim policy
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更新回收策略
- en: The good news with a reclaim policy is that you can change it after the `PersistentVolume`
    object has been created; it is a mutable setting.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 回收策略的好消息是，你可以在创建 `PersistentVolume` 对象后更改它；这是一个可变的设置。
- en: 'To demonstrate the reclaim policy differences, let us use the previously created
    Pod, PV, and PVC as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示回收策略的差异，让我们使用之前创建的 Pod、PV 和 PVC，如下所示：
- en: '[PRE25]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Delete the Pod first as it is using the PVC:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 先删除 Pod，因为它正在使用 PVC：
- en: '[PRE26]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, check the status of the PV:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，检查 PV 的状态：
- en: '[PRE27]'
  id: totrans-266
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: You can see from the output that the PV is in a `Released` state but not yet
    in an `Available` state for the next PVC to use.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出中可以看出，PV处于`Released`状态，但尚未进入`Available`状态，无法供下一个PVC使用。
- en: 'Let us update the reclaim policy to `Delete` using the `kubectl patch` command
    as follows:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`kubectl patch`命令更新回收策略为`Delete`，如下所示：
- en: '[PRE28]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: As you can see in the preceding output, we have updated the reclaim policy of
    the PV and then the PV has been deleted from the Kubernetes cluster.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的输出所示，我们更新了PV的回收策略，然后PV被从Kubernetes集群中删除。
- en: Now, let’s discuss the different statuses that PVs and PVCs can have.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们讨论一下PV和PVC可能具有的不同状态。
- en: Understanding PersistentVolume and PersistentVolumeClaim statuses
  id: totrans-272
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解PersistentVolume和PersistentVolumeClaim的状态
- en: Just like Pods can be in a different state, such as `Pending`, `ContainerCreating`,
    `Running`, and more, `PersistentVolume` and `PersistentVolumeClaim` can also hold
    different states. You can identify their state by issuing the `kubectl get pv`
    and `kubectl get pvc` commands.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 就像Pods可以处于不同的状态，如`Pending`、`ContainerCreating`、`Running`等，`PersistentVolume`和`PersistentVolumeClaim`也可以有不同的状态。你可以通过执行`kubectl
    get pv`和`kubectl get pvc`命令来查看它们的状态。
- en: '`PersistentVolume` has the following different states that you need to be aware
    of:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '`PersistentVolume`有以下不同的状态，你需要了解：'
- en: '`Available`: This is the initial state for a newly created PV. It indicates
    the PV is ready to be bound to a PVC.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Available`：这是新创建的PV的初始状态，表示该PV已准备好绑定到PVC。'
- en: '`Bound`: This status signifies that the PV is currently claimed by a specific
    PVC and is in use by a Pod. Essentially, it indicates that the volume is currently
    in use. When this status is applied to a `PersistentVolumeClaim` object, this
    indicates that the PVC is currently in use: that is, a Pod is using it and has
    access to a PV through it.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Bound`：该状态表示PV当前已被特定的PVC声明，并且正在Pod中使用。基本上，它表示该卷目前正在使用中。当此状态应用于`PersistentVolumeClaim`对象时，表示该PVC当前正在使用：即，Pod正在使用它并通过它访问PV。'
- en: '`Terminating`: The `Terminating` status applies to a `PersistentVolumeClaim`
    object. This is the status the PVC enters after you issue a `kubectl delete pvc`
    command.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Terminating`：`Terminating`状态适用于`PersistentVolumeClaim`对象。这是当你执行`kubectl delete
    pvc`命令后，PVC进入的状态。'
- en: '`Released`: If a PVC using the PV is deleted (and the reclaim policy for the
    PV is set to “Retain”), the PV will transition to this state. It’s essentially
    unbound but still available for future PVCs to claim.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Released`：如果使用该PV的PVC被删除（并且PV的回收策略设置为“Retain”），则PV将转为此状态。它本质上是未绑定的，但仍然可以供未来的PVC使用。'
- en: '`Failed`: This status indicates an issue with the PV, preventing it from being
    used. Reasons could be storage provider errors, access issues, or problems with
    the provisioner (if applicable).'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Failed`：该状态表示PV出现问题，无法使用。可能的原因包括存储提供商错误、访问问题或供给器的问题（如果适用）。'
- en: '`Unknown`: In rare cases, the PV status might be unknown due to communication
    failures with the underlying storage system.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Unknown`：在少数情况下，由于与底层存储系统的通信失败，PV状态可能为未知。'
- en: We now have all the basics relating to `PersistentVolume` and `PersistentVolumeClaim`,
    which should be enough to start using persistent storage in Kubernetes. However,
    there’s still something important to know about this topic, and it is called dynamic
    provisioning. This is a very impressive aspect of Kubernetes that makes it able
    to communicate with cloud provider APIs to create persistent storage on the cloud.
    Additionally, it can make this storage available on the cluster by dynamically
    creating PV objects. In the next section, we will compare static and dynamic provisioning.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经掌握了与`PersistentVolume`和`PersistentVolumeClaim`相关的基础知识，这些足以开始在Kubernetes中使用持久存储。然而，还有一个重要的概念需要了解，那就是动态供给。这是Kubernetes的一个非常令人印象深刻的功能，它能够与云服务提供商的API进行交互，在云端创建持久存储。此外，它还可以通过动态创建PV对象，将这些存储提供给集群。在下一节中，我们将对比静态和动态供给。
- en: Understanding static and dynamic PersistentVolume provisioning
  id: totrans-282
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解静态与动态PersistentVolume供给
- en: So far, we’ve only provisioned `PersistentVolume` by doing static provisioning.
    Now, we’re going to discover dynamic `PersistentVolume` provisioning, which enables
    `PersistentVolume` provisioning directly from the Kubernetes cluster.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们仅通过静态供给来配置了`PersistentVolume`。现在，我们将探索动态`PersistentVolume`供给，它允许直接从Kubernetes集群进行`PersistentVolume`供给。
- en: Static versus dynamic provisioning
  id: totrans-284
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 静态与动态供给
- en: 'So far, when using static provisioning, you have learned that you must follow
    this workflow:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，使用静态配置时，您已经学会了必须遵循以下工作流程：
- en: You create the piece of storage against the cloud provider or the backend technology.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您针对云提供商或后端技术创建存储部分。
- en: Then, you create the `PersistentVolume` object to serve as a Kubernetes pointer
    to this actual storage.
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接着，您创建`PersistentVolume`对象，作为指向实际存储的Kubernetes指针。
- en: Following this, you create a Pod and a PVC to bind the PV to the Pod.
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随后，您创建一个Pod和一个PVC，将PV绑定到Pod。
- en: 'That is called static provisioning. It is static because you have to create
    the piece of storage before creating the PV and the PVC in Kubernetes. It works
    well; however, at scale, it can become more and more difficult to manage, especially
    if you are managing hundreds of PVs and PVCs. Let’s say you are creating an Amazon
    EBS volume to mount it as a `PersistentVolume` object, and you would do it like
    this with static provisioning:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是静态配置。它是静态的，因为您必须在创建Kubernetes中的PV和PVC之前创建存储部分。它工作得很好；但是，在规模上，尤其是在管理数百个PV和PVC时，管理起来可能变得越来越困难。假设您要创建一个Amazon
    EBS卷，并将其挂载为`PersistentVolume`对象，您可以像这样使用静态配置：
- en: Authenticate against the AWS console.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对AWS控制台进行身份验证。
- en: Create an EBS volume.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个EBS卷。
- en: Copy/paste its unique ID to a `PersistentVolume` YAML definition file.
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制/粘贴其唯一ID到`PersistentVolume` YAML定义文件中。
- en: Create the PV using your YAML file.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用您的YAML文件创建PV。
- en: Create a PVC to fetch this PV.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个PVC来获取此PV。
- en: Mount the PVC to the Pod object.
  id: totrans-295
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将PVC挂载到Pod对象。
- en: Again, it should work in a manual or automated way, but it would become complex
    and extremely time-consuming to do at scale, with possibly dozens and dozens of
    PVs and PVCs.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，它应该以手动或自动化的方式工作，但如果在规模上进行操作，特别是处理可能有数十个PV和PVC时，操作可能变得复杂且极其耗时。
- en: That’s why Kubernetes developers decided that it would be better if Kubernetes
    was capable of provisioning the piece of actual storage on your behalf along with
    the `PersistentVolume` object to serve as a pointer to it. This is known as dynamic
    provisioning.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么Kubernetes开发人员决定，如果Kubernetes能够代表您配置实际存储部分，并创建`PersistentVolume`对象来作为指向它的指针，那将会更好。这就是所谓的动态配置。
- en: Introducing dynamic provisioning
  id: totrans-298
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入动态配置
- en: When using dynamic provisioning, you configure your Kubernetes cluster so that
    it authenticates against the backend storage provider (such as AWS, Azure, or
    other storage devices). Then, you issue a command to provision a storage disk
    or volume and automatically create a `PersistentVolume` so that the PVC can use
    it. That way, you can save a huge amount of time by getting things automated.
    Dynamic provisioning is so useful because Kubernetes supports a wide range of
    storage technologies. We already introduced a few of them earlier in this chapter,
    when we mentioned NFS and other types of storage.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 当使用动态配置时，您需要配置您的Kubernetes集群，以便对接后端存储提供商（如AWS、Azure或其他存储设备）。然后，您发出一个命令来提供存储磁盘或卷，并自动创建`PersistentVolume`，以便PVC可以使用它。这样，通过自动化可以节省大量时间。动态配置非常有用，因为Kubernetes支持各种存储技术。在本章的前面部分，我们已经介绍了其中一些，例如NFS和其他类型的存储。
- en: But how does Kubernetes achieve this versatility? Well, the answer is that it
    makes use of a third resource type, the `StorageClass` object, which we’re going
    to learn about in this chapter.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，Kubernetes如何实现这种多功能性呢？答案是它利用第三种资源类型，即`StorageClass`对象，我们将在本章中学习它。
- en: Introduction to CSI
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: CSI简介
- en: Before we talk about `StorageClass`, let us learn about CSI, which acts as a
    bridge between Kubernetes and various storage solutions. It defines a standard
    interface for exposing the storage to container workloads. CSI provides an abstraction
    layer to interact with Kubernetes primitives like `PersistentVolume`, enabling
    the integration of diverse storage solutions into Kubernetes, while maintaining
    a vendor-neutral approach.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们讨论`StorageClass`之前，让我们了解一下CSI，它充当Kubernetes与各种存储解决方案之间的桥梁。它定义了一种标准接口，用于将存储公开给容器工作负载。CSI为与Kubernetes原语（如`PersistentVolume`）交互提供了抽象层，使得可以将各种存储解决方案集成到Kubernetes中，并保持供应商中立的方法。
- en: 'Kubernetes dynamic storage provisioning involves the following steps typically:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes动态存储配置通常涉及以下步骤：
- en: 'Install and configure `StorageClass` and provisioner: The administrator installs
    a CSI driver (or in-tree provisioner) and configures a `StorageClass`, which defines
    the storage type, parameters, and reclaim policy.'
  id: totrans-304
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装并配置`StorageClass`和提供者：管理员安装CSI驱动程序（或内置提供者）并配置`StorageClass`，该类定义了存储类型、参数和回收策略。
- en: 'Developer creates PVC with `StorageClass` information: The developer creates
    a `PersistentVolumeClaim`, specifying the desired size and access mode and referencing
    the `StorageClass` to request dynamic provisioning.'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 开发人员创建包含`StorageClass`信息的PVC：开发人员创建`PersistentVolumeClaim`，指定所需的大小和访问模式，并引用`StorageClass`以请求动态配置。
- en: 'The `StorageClass`/CSI driver triggers a request to the backend provisioner:
    Kubernetes automatically triggers the CSI driver (or provisioner) when it detects
    the PVC, sending the request to provision storage from the backend storage system.'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`StorageClass`/CSI驱动程序触发向后端提供者的请求：当Kubernetes检测到PVC时，自动触发CSI驱动程序（或提供者），将请求发送给后端存储系统以进行存储配置。'
- en: 'Provisioner communicates with backend storage and creates the volume: The provisioner
    communicates with the backend storage system, creates the volume, and generates
    a `PersistentVolume` in Kubernetes that binds to the PVC.'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供者与后端存储通信并创建卷：提供者与后端存储系统通信，创建卷，并在Kubernetes中生成与PVC绑定的`PersistentVolume`。
- en: 'The PVC is mounted to the Pod, allowing storage access: The PVC is mounted
    to the requesting Pod, allowing the Pod to access the storage as specified by
    the `volumeMount` in the Pod’s configuration.'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: PVC挂载到Pod，允许访问存储：PVC挂载到请求的Pod，使Pod能够访问根据Pod配置中的`volumeMount`指定的存储。
- en: The following diagram illustrates the dynamic PV provisioning workflow.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了动态PV配置工作流。
- en: '![](img/B22019_09_03.png)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_09_03.png)'
- en: 'Figure 9.2: Dynamic PV provisioning in Kubernetes'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 图9.2：Kubernetes中的动态PV配置
- en: '**CSI drivers** are containerized implementations by storage vendors that adhere
    to the CSI specification and provide functionalities for provisioning, attaching,
    detaching, and managing storage volumes.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '**CSI驱动程序**是存储供应商提供的容器化实现，符合CSI规范，提供存储卷的配置、附加、分离和管理等功能。'
- en: CSI node and controller services are Kubernetes services that run the CSI driver
    logic on worker nodes and a control plane respectively, facilitating communication
    between Pods and the storage system.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: CSI节点和控制器服务是Kubernetes服务，分别在工作节点和控制平面上运行CSI驱动程序逻辑，促进Pod与存储系统之间的通信。
- en: 'Once a CSI-compatible volume driver is deployed on a Kubernetes cluster, users
    can leverage the `csi` volume type. (Refer to the documentation at [https://kubernetes-csi.github.io/docs/drivers.html](https://kubernetes-csi.github.io/docs/drivers.html)
    to see the set of CSI drivers that can be used with Kubernetes). This allows them
    to attach or mount volumes exposed by the CSI driver. There are three ways to
    utilize a `csi` volume within a Pod:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦在Kubernetes集群上部署了支持CSI的卷驱动程序，用户可以利用`csi`卷类型。（参考文档：[https://kubernetes-csi.github.io/docs/drivers.html](https://kubernetes-csi.github.io/docs/drivers.html)，了解可以与Kubernetes一起使用的CSI驱动程序集合）。这使得用户可以附加或挂载由CSI驱动程序暴露的卷。在Pod中使用`csi`卷有三种方法：
- en: 'Referencing a `PersistentVolumeClaim`: This approach links the Pod to persistent
    storage managed by Kubernetes.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 引用`PersistentVolumeClaim`：这种方法将Pod与由Kubernetes管理的持久存储连接起来。
- en: 'Utilizing a generic ephemeral volume: This method provides temporary storage
    that doesn’t persist across Pod restarts.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用通用临时卷：此方法提供不在Pod重启之间保持的临时存储。
- en: 'Leveraging a CSI ephemeral volume (if supported by the driver): This offers
    driver-specific ephemeral storage options beyond the generic version.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用CSI临时卷（如果驱动程序支持）：这为驱动程序提供了特定的临时存储选项，超出了通用版本的范畴。
- en: Remember, you don’t directly interact with CSI. `StorageClasses` can reference
    CSI drivers by name in the `provisioner` field, leveraging CSI for volume provisioning.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，您不会直接与CSI交互。`StorageClass`可以通过`provisioner`字段按名称引用CSI驱动程序，利用CSI进行卷配置。
- en: Introducing StorageClasses
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引入StorageClasses
- en: '`StorageClass` is another resource type exposed by `kube-apiserver`. You might
    already have noticed this field earlier in the `kubectl get pv` command output.
    This resource type is the one that grants Kubernetes the ability to deal with
    several underlying technologies transparently.'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '`StorageClass`是由`kube-apiserver`暴露的另一种资源类型。您可能已经在`kubectl get pv`命令输出中注意到了此字段。此资源类型使Kubernetes能够透明地处理多种底层技术。'
- en: '`StorageClasses` act as a user-facing interface for defining storage requirements.
    **CSI drivers**, referenced by `StorageClasses`, provide the actual implementation
    details for provisioning and managing storage based on the specific storage system.
    `StorageClasses` essentially bridge the gap between your storage needs and the
    capabilities exposed by CSI drivers.'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '`StorageClasses`充当用户接口，用于定义存储需求。**CSI 驱动程序**，由`StorageClasses`引用，提供了基于特定存储系统来供应和管理存储的实际实现细节。`StorageClasses`本质上弥合了存储需求与CSI驱动程序所提供的能力之间的差距。'
- en: 'You can access and list the `storageclasses` resources created within your
    Kubernetes cluster by using `kubectl`. Here is the command to list the storage
    classes:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用`kubectl`来访问并列出在Kubernetes集群中创建的`storageclasses`资源。以下是列出存储类的命令：
- en: '[PRE29]'
  id: totrans-323
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'We can also check the details about the `StorageClass` using the `-o yaml`
    option:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以使用`-o yaml`选项查看关于`StorageClass`的详细信息：
- en: '[PRE30]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Additionally, you can use the plural form of `storageclasses` along with the
    `sc` alias. The following three commands are essentially the same:'
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还可以使用`storageclasses`的复数形式以及`sc`别名。以下三个命令本质上是相同的：
- en: '[PRE31]'
  id: totrans-327
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Note that we haven’t included the output of the command for simplicity, but
    it is essentially the same for the three commands. There are two fields within
    the command output that are important to us:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，为了简化起见，我们没有包含命令的输出，但对于这三个命令来说，它们的输出本质上是相同的。命令输出中有两个对我们来说很重要的字段：
- en: '`NAME`: This is the name and the unique identifier of the `storageclass` object.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NAME`：这是`storageclass`对象的名称和唯一标识符。'
- en: '`PROVISIONER`: This is the name of the underlying storage technology: this
    is basically a piece of code the Kubernetes cluster uses to interact with the
    underlying technology.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PROVISIONER`：这是底层存储技术的名称：这基本上是Kubernetes集群用来与底层技术交互的代码。'
- en: Note that you can create multiple `StorageClass` objects that use the same `provisioner`.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，你可以创建多个使用相同`provisioner`的`StorageClass`对象。
- en: As we are currently using a `minikube` cluster in our lab environment, we have
    a `storageclass` resource called `standard` that is using the `k8s.io/minikube-hostpath`
    provisioner.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们当前在实验室环境中使用的是`minikube`集群，我们有一个名为`standard`的`storageclass`资源，它使用了`k8s.io/minikube-hostpath`供应器。
- en: This provider deals with my host filesystem to automatically create provisioned
    host path volumes for my Pods, but it could be the same for Amazon EBS volumes
    or Google PDs.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 这个提供程序处理我的主机文件系统，为我的Pod自动创建预配置的主机路径卷，但对于Amazon EBS卷或Google PD也可以是相同的。
- en: 'In GKE, Google built a storage class with a provisioner that was capable of
    interacting with the Google PD’s API, which is a pure Google Cloud feature, and
    you can implement it with `StorageClass` as follows:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在GKE中，Google构建了一个存储类，具有一个能够与Google PD API交互的供应器，这是一个纯Google Cloud功能，你可以通过`StorageClass`来实现，方法如下：
- en: '[PRE32]'
  id: totrans-335
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: In contrast, in AWS, we have a `storageclass` object with a provisioner that
    is capable of dealing with EBS volume APIs. These provisioners are just libraries
    that interact with the APIs of these different cloud providers.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，在AWS中，我们有一个`storageclass`对象，其供应器能够处理EBS卷API。这些供应器只是与不同云提供商的API交互的库。
- en: The `storageclass` objects are the reason why Kubernetes can deal with so many
    different storage technologies. From a Pod perspective, no matter if it is an
    EBS volume, NFS drive, or GKE volume, the Pod will only see a `PersistentVolume`
    object. All the underlying logic dealing with the actual storage technology is
    implemented by the provisioner the `storageclass` object uses.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '`storageclass`对象使得Kubernetes能够处理如此多不同的存储技术。从Pod的角度来看，无论它是EBS卷、NFS驱动器，还是GKE卷，Pod只会看到一个`PersistentVolume`对象。所有与实际存储技术相关的底层逻辑都由`storageclass`对象使用的供应器实现。'
- en: The good news is that you can add as many `storageclass` objects with their
    provisioner as you want to your Kubernetes cluster in a plugin-like fashion.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，你可以像插件一样向Kubernetes集群中添加任意多个`storageclass`对象及其供应器。
- en: By the way, nothing is preventing you from expanding your cluster by adding
    `storageclasses` to your cluster. You’ll simply add the ability to deal with different
    storage technologies from your cluster. For example, we can add an Amazon EBS
    `storageclass` object to our `minikube` cluster. However, while it is possible,
    it’s going to be completely useless. Indeed, if your `minikube` setup is not running
    on an EC2 instance but on your local machine, it won’t be able to attach an EBS.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 顺便说一下，什么也不妨碍你通过向集群添加`storageclasses`来扩展你的集群。你只需要为你的集群添加处理不同存储技术的能力。例如，我们可以将一个Amazon
    EBS `storageclass`对象添加到我们的`minikube`集群中。然而，尽管这是可能的，但它将完全没用。事实上，如果你的`minikube`设置不是运行在EC2实例上，而是在本地机器上，它将无法附加EBS。
- en: That said, for a more practical approach, you can consider using CSI drivers
    from providers that support local deployment, such as OpenEBS, TopoLVM, or Portworx.
    These allow you to work with persistent storage locally, even on minikube. Additionally,
    most cloud providers offer free tiers for small Kubernetes deployments, which
    could be useful for testing out storage solutions in a cloud environment without
    incurring significant costs.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 话虽如此，若采用更实用的方法，你可以考虑使用支持本地部署的CSI驱动程序，例如OpenEBS、TopoLVM或Portworx。这些驱动程序允许你即使在minikube上，也能使用本地的持久存储。此外，大多数云服务提供商提供免费层，适用于小规模的Kubernetes部署，这对于在云环境中测试存储解决方案非常有用，并且不会产生过多成本。
- en: In the next section, we will learn about the difference in dynamic storage provisioning
    with PVC.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分中，我们将了解在使用PVC时动态存储供应的区别。
- en: Understanding the role of PersistentVolumeClaim for dynamic storage provisioning
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解PersistentVolumeClaim在动态存储供应中的角色
- en: When using dynamic storage provisioning, the `PersistentVolumeClaim` object
    will get an entirely new role. Since `PersistentVolume` is gone in this use case,
    the only object that will be left for you to manage is the `PersistentVolumeClaim`
    one because the `PersistentVolume` object will be managed by the `StorageClass`.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 使用动态存储供应时，`PersistentVolumeClaim`对象将会有一个全新的角色。由于在这种使用情况下`PersistentVolume`已被移除，你将只需要管理`PersistentVolumeClaim`对象，因为`PersistentVolume`对象将由`StorageClass`管理。
- en: Let’s demonstrate this by creating an NGINX Pod that will mount a `hostPath`
    type dynamically. In this example, the administrator won’t have to provision a
    `PersistentVolume` object at all. This is because the `PersistentVolumeClaim`
    object and the `StorageClass` object will be able to create and provision the
    `PersistentVolume` together.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过创建一个NGINX Pod来动态挂载一个`hostPath`类型来展示这一点。在这个例子中，管理员根本不需要预配置`PersistentVolume`对象。这是因为`PersistentVolumeClaim`对象和`StorageClass`对象将能够一起创建并供应`PersistentVolume`。
- en: 'Let’s start by creating a new namespace called `dynamicstorage`, where we will
    run our examples:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从创建一个名为`dynamicstorage`的新命名空间开始，在这里我们将运行我们的示例：
- en: '[PRE33]'
  id: totrans-346
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Now, let’s run a `kubectl get sc` command to check that we have a storage class
    that is capable of dealing with the `hostPath` that is provisioned in our cluster.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们运行`kubectl get sc`命令，检查我们是否有一个能够处理在集群中配置的`hostPath`的存储类。
- en: For this specific `storageclass` object in this specific Kubernetes setup (`minikube`),
    we don’t have to do anything to get the `storageclass` object, as it is created
    by default at cluster installation. However, this might not be the case depending
    on your Kubernetes distribution.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这个特定的`storageclass`对象，在这个特定的Kubernetes设置（`minikube`）中，我们无需做任何事情来获取`storageclass`对象，因为它在集群安装时默认创建。然而，根据你的Kubernetes发行版，这种情况可能有所不同。
- en: 'Bear this in mind because it is very important: clusters that have been set
    up on GKE might have default storage classes that are capable of dealing with
    Google’s storage offerings, whereas an AWS-based cluster might have `storageclass`
    to communicate with Amazon’s storage offerings and more. With `minikube`, we have
    at least one default `storageclass` object that is capable of dealing with a `hostPath`-based
    `PersistentVolume` object. If you understand that, you should understand that
    the output of the `kubectl get sc` command will be different depending on where
    your cluster has been set up:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 记住这一点，因为它非常重要：在GKE上设置的集群可能有默认的存储类，能够处理Google的存储产品，而基于AWS的集群可能有`storageclass`来与Amazon的存储产品进行通信等等。对于`minikube`，我们至少有一个默认的`storageclass`对象，能够处理基于`hostPath`的`PersistentVolume`对象。如果你理解这一点，你应该明白`kubectl
    get sc`命令的输出会根据你的集群所在的位置而有所不同：
- en: '[PRE34]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: As you can see, we do have a storage class called `standard` on our cluster
    that is capable of dealing with `hostPath`.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: Some complex clusters spanning across multiple clouds and or on-premises might
    be provisioned with a lot of different `storageclass` objects to be able to communicate
    with a lot of different storage technologies. Bear in mind that Kubernetes is
    not tied to any cloud provider and, therefore, does not force or limit you in
    your usage of backing storage solutions.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will create a `PersistentVolumeClaim` object that will dynamically
    create a `hostPath` type. Here is the YAML file to create the PVC. Please note
    that `storageClassName` is set to `standard`:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-354
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Following this, we can create it in the proper namespace:'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-356
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Let us check the status of the PV and PVC now:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: We can see that the PV has been created by the `StorageClass` and bound to the
    PVC as per the request.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that this PVC has been created, we can add a new Pod that will mount this
    `PersistentVolumeClaim` object. Here is a YAML definition file of a Pod that will
    mount the `PersistentVolumeClaim` object that was created earlier:'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-361
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Now, let’s create it in the correct namespace:'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: Everything is OK! We’re finally done with dynamic provisioning! Please note
    that, by default, the reclaim policy will be set to `delete` so that the PV is
    removed when the PVC that created it is removed, too. Don’t hesitate to change
    the reclaim policy if you need to retain sensitive data.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
- en: 'You can test it by deleting the Pod and PVC; the PV will be removed automatically
    by the `StorageClass`:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-366
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We can see from the above snippet that the PV is also deleted automatically
    when the PVC gets deleted.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: We’ve covered the basics of PVs, PVCs, `StorageClasses`, and the differences
    between static and dynamic provisioning. In the next section, we’ll dive into
    some advanced storage topics in Kubernetes, exploring how to optimize and extend
    your storage strategies.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: Advanced storage topics
  id: totrans-369
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In addition to understanding the basics of PVs, PVCs, and `StorageClasses`,
    it’s beneficial to delve into some advanced storage topics in Kubernetes. While
    not mandatory, having knowledge of these concepts can significantly enhance your
    expertise as a Kubernetes practitioner. In the following sections, we will introduce
    advanced topics such as ephemeral volumes for temporary storage, CSI Volume Cloning
    for flexible volume management, and expanding `PersistentVolumeClaims` to accommodate
    increased storage needs. These topics will provide you with a broader perspective
    on Kubernetes storage capabilities and practical applications.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: Ephemeral volumes for temporary storage in Kubernetes
  id: totrans-371
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ephemeral volumes offer a convenient way to provide temporary storage for Pods
    in Kubernetes. They’re perfect for applications that need scratch space for caching
    or require read-only data, like configuration files or Secrets. Unlike PVs, ephemeral
    volumes are automatically deleted when the Pod terminates, simplifying deployment
    and management.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are a few key benefits of ephemeral volumes for temporary storage:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: Temporary storage for Pods
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic deletion with Pod termination
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simplified deployment and management
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'There are multiple types of ephemeral storage available in Kubernetes, as follows:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: 'emptyDir: This creates an empty directory on the node’s local storage'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ConfigMap, downwardAPI, Secret: This injects data from Kubernetes objects into
    the Pod'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CSI ephemeral volumes: These are provided by external CSI drivers (requires
    specific driver support)'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Generic ephemeral volumes: These are offered by storage drivers supporting
    PVs'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have learned some details with regard to ephemeral volumes, let’s
    move on to gain some understanding of CSI volume cloning and volume snapshots.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: CSI volume cloning and volume snapshots
  id: totrans-383
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'CSI introduces a powerful feature: volume cloning. This functionality allows
    you to create an exact copy of an existing `PersistentVolumeClaim` as a new PVC.'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: 'The following YAML snippet illustrates a typical PVC cloning declaration:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Here are a few key benefits of CSI Volume Cloning:'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: '**Simplified workflows**: CSI Volume Cloning automates data replication, eliminating
    the need for manual copying and streamlining storage management.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhanced efficiency**: Easily create replicas of existing volumes, optimizing
    deployments and resource utilization.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Troubleshooting live data**: Instead of touching the production data, you
    can take a copy and use it for QA, troubleshooting, etc.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Refer to the documentation to learn more about CSI volume cloning: [https://kubernetes.io/docs/concepts/storage/volume-pvc-datasource](https://kubernetes.io/docs/concepts/storage/volume-pvc-datasource).'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: Like volume cloning, Kubernetes also offers another mechanism via CSI drivers
    to take data backups called volume snapshots. `VolumeSnapshot` provides a standardized
    way to create a point-in-time copy of a volume’s data. Similar to `PersistentVolume`
    and `PersistentVolumeClaim` resources, Kubernetes uses VolumeSnapshot, `VolumeSnapshotContent`,
    and `VolumeSnapshotClass` resources to manage volume snapshots. VolumeSnapshots
    are user requests for snapshots, while VolumeSnapshotContent represents the actual
    snapshots on the storage system. These resources enable users to capture the state
    of their volumes without provisioning an entirely new volume, making it useful
    for scenarios such as database backups before performing critical updates or deletions.
    Unlike regular PVs, these snapshot resources are **Custom Resource Definitions**
    (**CRDs**) and require a CSI driver that supports snapshot functionality. The
    CSI driver uses a sidecar container called `csi-snapshotter` to handle `CreateSnapshot`
    and `DeleteSnapshot` operations.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: When a user creates a snapshot, it can be either pre-provisioned by an administrator
    or dynamically provisioned from an existing PVC. The snapshot controller binds
    the VolumeSnapshot and VolumeSnapshotContent in both scenarios, ensuring that
    the snapshot content matches the user request. Snapshots can be easily deleted
    or retained based on the set `DeletionPolicy`, allowing flexibility in how data
    is managed. Furthermore, Kubernetes provides the option to convert a snapshot’s
    volume mode (e.g., from filesystem to block) and restore data from a snapshot
    to a new PVC. This capability makes VolumeSnapshot a powerful tool in data protection,
    which can be complemented by CSI volume cloning to create efficient backups or
    test environments, adding another layer of flexibility to storage management in
    Kubernetes.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: Volume cloning in Kubernetes is ideal for creating identical copies of `PersistentVolumes`,
    often used for development and testing environments. Snapshots, on the other hand,
    capture the point-in-time state of a volume, making them useful for backup and
    restore purposes.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: Refer to the documentation (https://kubernetes.io/docs/concepts/storage/volume-snapshots/)
    to learn more about volume snapshots.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will learn how to expand a PVC.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: Learning how to expand PersistentVolumeClaim
  id: totrans-397
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes offers built-in support for expanding PVCs, allowing you to seamlessly
    increase storage capacity for your applications. This functionality is currently
    limited to volumes provisioned by CSI drivers (as of version 1.29, other volume
    types are deprecated).
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable PVC expansion for a specific `StorageClass`, you need to set the
    `allowVolumeExpansion` field to `true` within the `StorageClass` definition. This
    flag controls whether PVCs referencing this `StorageClass` can request more storage
    space:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: '**Example StorageClass Configuration:**'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: When your application requires additional storage, simply edit the PVC object
    and specify a larger size in the `resources.requests.storage` field. Kubernetes
    will then initiate the expansion process, resizing the underlying volume managed
    by the CSI driver. This eliminates the need to create a new volume and migrate
    data, streamlining storage management.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: Refer to the documentation (https://kubernetes.io/docs/concepts/storage/persistent-volumes/#expanding-persistent-volumes-claims)
    to learn more.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-404
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have arrived at the end of this chapter, which taught you how to manage persistent
    storage on Kubernetes. You discovered that `PersistentVolume` is a resource type
    that acts as a point to an underlying resource technology, such as `hostPath`
    and NFS, along with cloud-based solutions such as Amazon EBS and Google PDs.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, you discovered the relationship between `PersistentVolume`, `PersistentVolumeClaim`,
    and `storageClass`. You learned that `PersistentVolume` can hold different reclaim
    policies, which makes it possible to remove, recycle, or retain them when their
    corresponding `PersistentVolumeClaim` object gets removed.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we discovered what dynamic provisioning is and how it can help us.
    Bear in mind that you need to be aware of this feature because if you create and
    retain too many volumes, it can have a negative impact on your cloud bill at the
    end of the month, even though you can restrict storage usage using resource quotas
    for the namespaces.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: We’re now done with the basics of Kubernetes, and this chapter is also the end
    of this section. In the next section, you’re going to discover Kubernetes controllers,
    which are objects designed to automate certain tasks in Kubernetes, such as maintaining
    a number of replicas of your Pods, either using the Deployment resource type or
    the StatefulSet resource type. There are still a lot of things to learn!
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-409
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Persistent Volumes: https://kubernetes.io/docs/concepts/storage/persistent-volumes/'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Types of Persistent Volumes: [https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes
    )'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dynamic Volume Provisioning: https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Expanding Persistent Volumes Claims: https://kubernetes.io/docs/concepts/storage/persistent-volumes/#expanding-persistent-volumes-claims'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CSI Volume Cloning: https://kubernetes.io/docs/concepts/storage/volume-pvc-datasource/'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  id: totrans-415
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code119001106479081656.png)'
  id: totrans-418
  prefs: []
  type: TYPE_IMG
