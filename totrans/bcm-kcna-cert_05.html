<html><head></head><body>
		<div id="_idContainer033">
			<h1 id="_idParaDest-60" class="chapter-number"><a id="_idTextAnchor059"/>5</h1>
			<h1 id="_idParaDest-61"><a id="_idTextAnchor060"/>Orchestrating Containers with Kubernetes</h1>
			<p>In this and the following few chapters, we will cover the most important and perhaps the hardest part of the KCNA certification – <em class="italic">Kubernetes Fundamentals</em>. It makes up almost half (46%) of the total exam questions, so it’s crucial to understand all the details. We’ll take it one step at a time, and we’ll also get practical experience with Kubernetes that will help you to memorize everything you need to pass <span class="No-Break">the exam.</span></p>
			<p>In this chapter, we’ll learn about the features and the basics of the K8s architecture, its API, components, and the smallest deployable unit called a <strong class="bold">Pod</strong>. We will install and run Kubernetes locally with the help of the <strong class="bold">minikube</strong> project to support us along <span class="No-Break">the way.</span></p>
			<p>The topics we’re going to cover are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><span class="No-Break">Kubernetes architecture</span></li>
				<li><span class="No-Break">Kubernetes API</span></li>
				<li>K8s – the Swiss Army knife of <span class="No-Break">container orchestration</span></li>
				<li>Installing and exploring Kubernetes <span class="No-Break">with minikube</span></li>
			</ul>
			<p>Let’s <span class="No-Break">get started!</span></p>
			<h1 id="_idParaDest-62"><a id="_idTextAnchor061"/>Kubernetes architecture</h1>
			<p>As you already know, Kubernetes <a id="_idIndexMarker243"/>is used to orchestrate fleets of containers that run on multiple servers that make up a Kubernetes cluster. Those servers are often called <em class="italic">nodes</em>, and <a id="_idIndexMarker244"/>nodes can be virtual machines running on-premises, in the cloud, or bare-metal servers. You can even combine different nodes in one Kubernetes cluster (for example, several nodes represented by VMs plus a few others as <span class="No-Break">bare-metal servers).</span></p>
			<p>There are two distinguished node types <span class="No-Break">in Kubernetes:</span></p>
			<ul>
				<li><em class="italic">Control plane</em> nodes (sometimes also called <span class="No-Break"><em class="italic">master</em></span><span class="No-Break"> nodes)</span></li>
				<li><span class="No-Break"><em class="italic">Worker</em></span><span class="No-Break"> nodes</span></li>
			</ul>
			<p>It is <a id="_idIndexMarker245"/>the <em class="italic">worker</em> nodes <a id="_idIndexMarker246"/>where the containerized applications run, and<a id="_idIndexMarker247"/> it is the <em class="italic">control plane</em> nodes<a id="_idIndexMarker248"/> where the K8s cluster management components run. We can see this in more detail in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.1.</em></span></p>
			<div>
				<div id="_idContainer028" class="IMG---Figure">
					<img src="image/B18970_05_01.jpg" alt="Figure 5.1 – Kubernetes components"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.1 – Kubernetes components</p>
			<p>Control plane nodes run several <a id="_idIndexMarker249"/>specialized K8s services and make global decisions about the Kubernetes cluster, such as scheduling containerized applications. Control plane nodes are also responsible for managing worker nodes in <span class="No-Break">the cluster.</span></p>
			<p>The following five services run on control <span class="No-Break">plane nodes:</span></p>
			<ul>
				<li><em class="italic">API server</em> (<strong class="bold">kube-apiserver</strong>): The <a id="_idIndexMarker250"/>core service that exposes the Kubernetes HTTP API for internal and external cluster communication. All operations within the cluster are performed through an API server – for example, when you query the state of the cluster or a particular application or start a <span class="No-Break">new container.</span></li>
				<li><em class="italic">Cluster data store</em> (<strong class="bold">etcd</strong>): A place <a id="_idIndexMarker251"/>where all information about the Kubernetes cluster state and configuration is kept. <em class="italic">etcd</em> is an open source, distributed key-value store used for this purpose and it is the only <span class="No-Break">stateful component.</span></li>
				<li><em class="italic">Scheduler</em> (<strong class="bold">kube-scheduler</strong>): A <a id="_idIndexMarker252"/>component that picks where, and on which worker node, the application containers will run in the cluster. The factors that can affect scheduling decisions include individual application requirements, load on the nodes, hardware or policy constraints, <span class="No-Break">and more.</span></li>
				<li><em class="italic">Controller manager</em> (<strong class="bold">kube-controller-manager</strong>): A component that runs various controller <a id="_idIndexMarker253"/>processes, such as <em class="italic">Node</em>, <em class="italic">Job</em>, or <em class="italic">Deployment</em> controllers. Those controllers watch the current state of respective resources in the cluster and take action if the current state differs from the <span class="No-Break">desired state.</span></li>
				<li>An optional <em class="italic">Cloud controller manager</em> (<strong class="bold">cloud-controller-manager</strong>): A component <a id="_idIndexMarker254"/>that lets you integrate the Kubernetes cluster with a cloud provider by running controller processes specific to your provider. For example, it allows you to create load balancers for containerized applications or determine if a worker node cloud instance has been deleted. <em class="italic">Cloud controller manager</em> is a component that you do not need when K8s is <span class="No-Break">running on-premises.</span></li>
			</ul>
			<p>Let’s move on to the components of <span class="No-Break">worker nodes:</span></p>
			<ul>
				<li><strong class="bold">Kubelet</strong>: An agent<a id="_idIndexMarker255"/> that ensures that containers assigned to the node are running and healthy. Kubelet <a id="_idIndexMarker256"/>also reports the status to the <span class="No-Break">API server.</span></li>
				<li><strong class="bold">Proxy</strong> (<strong class="bold">kube-proxy</strong>): This<a id="_idIndexMarker257"/> is a network proxy that helps to implement Kubernetes <em class="italic">Service</em> functionality. Proxy maintains network rules on nodes to allow container communication from inside or outside of your <span class="No-Break">K8s cluster.</span></li>
				<li><strong class="bold">Container runtime</strong>: This is<a id="_idIndexMarker258"/> a piece of software that’s responsible for basic container operations. Thanks to <em class="italic">CRI</em>, Kubernetes can use different container runtimes. One of the most popular runtimes today <span class="No-Break">is </span><span class="No-Break"><em class="italic">containerd</em></span><span class="No-Break">.</span></li>
			</ul>
			<p class="callout-heading">Note</p>
			<p class="callout">Kubelet does not manage containers that were not created via the Kubernetes API. For example, containers created by other means on the worker nodes won’t be known <span class="No-Break">to Kubernetes.</span></p>
			<p>Today, the worker node components <strong class="bold">also run on the control plane nodes</strong>. That’s right – on the Kubernetes control plane, you’ll have not just the <em class="italic">scheduler</em>, <em class="italic">kube-apiserver</em>, <em class="italic">etcd</em>, and <em class="italic">kube-controller-manager</em>, but also <em class="italic">kubelet</em>, <em class="italic">kube-proxy</em>, and a <em class="italic">runtime</em>. This means that worker components are run on all Kubernetes nodes in <span class="No-Break">the cluster.</span></p>
			<p>Why is that? The reason is that control plane components are deployed in containers themselves and therefore can be managed by Kubernetes with so-called static <strong class="bold">pods</strong>. Alternatively, control plane components can be started and managed <a id="_idIndexMarker259"/>with <strong class="bold">systemd</strong>, but this approach is becoming less <span class="No-Break">popular today.</span></p>
			<p class="callout-heading">What is a pod?</p>
			<p class="callout">A pod is<a id="_idIndexMarker260"/> the smallest deployable unit that can be created in Kubernetes. A pod is a group of one or multiple containers that share storage, network, and a specification of how to run containers within <span class="No-Break">the pod.</span></p>
			<p>You can think of a pod as a Kubernetes wrapper for containers, and you’ll always deal with pods when deploying any application in a K8s cluster. Even if you need to run a small simple application consisting of only one container, you’ll need to define a pod with that single container. In other words, <strong class="bold">it is not possible to run containers on Kubernetes without a </strong><span class="No-Break"><strong class="bold">pod wrapper</strong></span><span class="No-Break">.</span></p>
			<p>It is also rather <a id="_idIndexMarker261"/>common to have two or more containers in one pod where the second or third container in the pod acts as a <em class="italic">helper</em> to<a id="_idIndexMarker262"/> the <em class="italic">main</em> container. This happens when multiple containers need to work together and share resources. Such <em class="italic">helper</em> containers <a id="_idIndexMarker263"/>are called <em class="italic">sidecars</em>. In <a id="_idIndexMarker264"/>the previous chapter, we learned about the <em class="italic">Service Mesh</em>, which<a id="_idIndexMarker265"/> utilizes sidecars to deploy a proxy together with the application containers. Another example where you might run multiple containers in one pod is to collect monitoring metrics from the application running in the main container. A sidecar container may also be used for log aggregation – for example, a sidecar container might collect and ship logs for long-term storage from the main application in the same pod, as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/B18970_05_02.jpg" alt="Figure 5.2 – Pod example with two containers"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.2 – Pod example with two containers</p>
			<p class="callout-heading">Note</p>
			<p class="callout">Containers of one pod are always co-located and co-scheduled on the <span class="No-Break">same node.</span></p>
			<p>Other than the <em class="italic">sidecar</em>, there<a id="_idIndexMarker266"/> is yet another type called <strong class="bold">Init Containers</strong>. They are handy for running setup scripts and initialization utilities that are needed for the <span class="No-Break">containerized application.</span></p>
			<p class="callout-heading">initContainers</p>
			<p class="callout">These are containers that are executed in order before the other containers in the pod are started. Until all <strong class="source-inline">initContainers</strong> have finished, no other containers are going to start and initContainers will run every time a <span class="No-Break">pod starts.</span></p>
			<p>Besides allowing you to run co-located and individual containers on Kubernetes, pods have more features, including <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Shared storage</strong>: All <a id="_idIndexMarker267"/>the containers in a pod can access shared volumes, allowing containers to <span class="No-Break">share data.</span></li>
				<li><strong class="bold">Shared networking</strong>: All <a id="_idIndexMarker268"/>the containers in a Pod share the <em class="italic">network namespace</em> with an IP address and network ports. Containers don’t have individual IP addresses, but the pod does, and containers in one pod can communicate with each other simply via <em class="italic">localhost</em>. Also, because of shared networking, two containers in one pod cannot listen on the same <span class="No-Break">network port.</span></li>
				<li><strong class="bold">Shared memory</strong>: Containers<a id="_idIndexMarker269"/> in a pod can use standard Linux inter-process<a id="_idIndexMarker270"/> communication <a id="_idIndexMarker271"/>such as <strong class="bold">SystemV semaphores</strong> or <strong class="bold">POSIX </strong><span class="No-Break"><strong class="bold">shared memory</strong></span><span class="No-Break">.</span></li>
			</ul>
			<p>Now, we’ve already mentioned Kubernetes <em class="italic">clusters</em> many times, meaning that we need at least two nodes. Technically, you could run Kubernetes on a single node while combining both the control plane and worker node functionality at the same time. <strong class="bold">However, you should never do this for production environments. This is only acceptable for learning or </strong><span class="No-Break"><strong class="bold">development purposes</strong></span><span class="No-Break">.</span></p>
			<p>In real-life scenarios, we would run at least three control plane nodes with several worker nodes. The nodes should be spread across multiple <strong class="bold">failure domains</strong> (typically called <strong class="bold">availability zones</strong> by cloud providers) that <a id="_idIndexMarker272"/>might be represented by individual data centers interconnected with high bandwidth networks. In the case of an outage of a single server or an availability zone, such a Kubernetes cluster will <span class="No-Break">remain operational.</span></p>
			<p>Having just one control plane node in the cluster is not sufficient for production environments because, in the case of an outage, you won’t able to query the state of your cluster and applications, start new pods with containers, or make any changes. Also, you don’t want to lose your <em class="italic">etcd</em> data store, which keeps all the information about <span class="No-Break">your cluster.</span></p>
			<p>Therefore, like with many clustered systems, the best practice is <strong class="bold">to run an odd number of control plane nodes</strong>; for example, three or five. Having an odd number helps to prevent <em class="italic">split-brain</em> scenarios where, in the event of a network failure, two parts of the cluster won’t be able to establish a majority (for example, four nodes split into two parts can lead to inconsistencies or an <span class="No-Break">inoperable state).</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">This practice does not apply to worker nodes, and it is fine to run two, four, seven, or even 200 worker nodes in <span class="No-Break">a cluster.</span></p>
			<p>I know this is a lot to digest, but when we get our hands on Kubernetes and deploy our first few pods, things will become much clearer and easier. Later in this chapter, we will have a closer look at the pod specification, but for now, let’s learn more about the Kubernetes API and how we can <span class="No-Break">use it.</span></p>
			<h1 id="_idParaDest-63"><a id="_idTextAnchor062"/>The Kubernetes API</h1>
			<p>As we learned previously, the Kubernetes API <a id="_idIndexMarker273"/>server is the main gateway for all cluster operations. When we want to know the state of the cluster, the number of nodes or pods or other resources, and their state, we need to use the Kubernetes API. The same is valid for all operations, such as creating new pods or making changes in the specifications of other resources. In a nutshell, the API server is the <em class="italic">brain</em> <span class="No-Break">of K8s.</span></p>
			<p>There are multiple ways to interact with the <span class="No-Break">Kubernetes API:</span></p>
			<ul>
				<li><strong class="bold">Kubectl</strong>: A <a id="_idIndexMarker274"/>command-line interface tool available for all common platforms, including Linux, Windows, and macOS. Operators very often use <strong class="source-inline">kubectl</strong> to interact with K8s clusters and manage or debug applications running <span class="No-Break">in Kubernetes.</span></li>
				<li><strong class="bold">dashboard (kube-dashboard)</strong>: A <a id="_idIndexMarker275"/>popular web-based graphical user interface. It allows you to view, create, and modify resources, as well as troubleshoot applications running in K8s. <strong class="source-inline">dashboard</strong>, however, does not support all functionality that <span class="No-Break"><strong class="source-inline">kubectl</strong></span><span class="No-Break"> does.</span></li>
				<li><strong class="bold">Client libraries</strong>: Available<a id="_idIndexMarker276"/> in many programming languages, including <em class="italic">Golang</em>, <em class="italic">Java</em>, <em class="italic">Python</em>, <em class="italic">JavaScript</em>, and more. They allow you to write software that uses the Kubernetes API and helps handle common tasks such <span class="No-Break">as authentication.</span></li>
				<li><strong class="bold">HTTP REST calls</strong>: Using <a id="_idIndexMarker277"/>any common HTTP client such as <strong class="source-inline">curl</strong> or <strong class="source-inline">wget</strong>, you can directly access the Kubernetes API. This is not a very commonly used method but it can be <span class="No-Break">helpful sometimes.</span></li>
			</ul>
			<p>This list is not exhaustive, and today, you can find many<a id="_idIndexMarker278"/> other tools (<strong class="bold">Lens</strong>, <strong class="bold">Octant</strong>) developed <a id="_idIndexMarker279"/>by third parties that allow you to use the Kubernetes API. However, they are outside the scope of this book and the KCNA exam. To successfully pass the exam, you only need to have experience <span class="No-Break">with </span><span class="No-Break"><strong class="source-inline">kubectl</strong></span><span class="No-Break">.</span></p>
			<p>In the previous chapters, we mentioned that the<a id="_idIndexMarker280"/> Kubernetes API <span class="No-Break">is </span><span class="No-Break"><strong class="bold">declarative</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Declarative API</p>
			<p class="callout">A declarative API <a id="_idIndexMarker281"/>means you declare the <em class="italic">desired state</em> of your Kubernetes resources and Kubernetes controllers, constantly ensuring that the current state of Kubernetes objects (for example, the number of pods for a certain app) is in sync with the declared <span class="No-Break">desired state.</span></p>
			<p>Thus, the Kubernetes API is different from an imperative approach where you instruct the server on what to do. After you have defined the desired state via the API, Kubernetes, using its <em class="italic">kube-controller-manager</em>, will instruct the controllers running in infinite control loops to check the resource state to be the same as the desired state and <em class="italic">reconcile</em> if not. For example, we have instructed K8s to run our application with three replicas and one of the replicas eventually crashed. Kubernetes will automatically detect that only two replicas <a id="_idIndexMarker282"/>are running and will spawn one new pod with <span class="No-Break">our application:</span></p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B18970_05_03.jpg" alt="Figure 5.3 – Kubernetes control loops"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.3 – Kubernetes control loops</p>
			<p class="callout-heading">Note</p>
			<p class="callout">The infinite control loops of controller managers are sometimes also called <span class="No-Break">reconciliation loops.</span></p>
			<p>Because Kubernetes is developed at high velocity, its APIs are constantly evolving. New API resources can be added frequently, and old resources or fields are removed over several release cycles following Kubernetes’s depreciation policy. To make it easier to make such changes, K8s supports multiple API versions and API grouping and maintains compatibility with existing API clients for an extended period. For example, there can be two API versions for the same resource: <strong class="source-inline">v1</strong> and <strong class="source-inline">v1beta1</strong>. You may have first created a resource using its <strong class="source-inline">v1beta1</strong> version, but you’ll still be able to make changes to this resource using either the <strong class="source-inline">v1</strong> or <strong class="source-inline">v1beta1</strong> API version for a <span class="No-Break">few releases.</span></p>
			<p>Each new feature of Kubernetes follows a defined life cycle and the respective API evolves from alpha to beta to the generally available state over several K8s releases, as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B18970_05_04.jpg" alt="Figure 5.4 – Kubernetes feature life cycle"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.4 – Kubernetes feature life cycle</p>
			<p>It’s worth mentioning that <a id="_idIndexMarker283"/>the alpha features of Kubernetes are usually <em class="italic">disabled</em>. However, you can enable them by setting so-called <strong class="bold">feature gates</strong>. Beta <a id="_idIndexMarker284"/>and stable Kubernetes features are enabled <span class="No-Break">by default.</span></p>
			<p>The implementation of new and major changes to existing features in Kubernetes typically starts <a id="_idIndexMarker285"/>with <strong class="bold">Kubernetes Enhancement Proposal</strong> (<strong class="bold">KEP</strong>). Those are detailed specification documents that outline the motivation, goals, and design of the changes. You can find existing KEPs in Kubernetes GitHub <span class="No-Break">repositories (</span><a href="https://github.com/kubernetes/enhancements/tree/master/keps"><span class="No-Break">https://github.com/kubernetes/enhancements/tree/master/keps</span></a><span class="No-Break">).</span></p>
			<p>Because Kubernetes is a complex project with many components, it has multiple operational areas, including storage, networking, scaling, and more. Those areas are typically covered by <a id="_idIndexMarker286"/>Kubernetes <strong class="bold">Special Interest Groups</strong> (<strong class="bold">SIGs</strong>). SIGs are smaller communities of developers that focus on particular parts of K8s. Since K8s is an open source project, anybody can become a part of SIG to fix issues, review code, and make <span class="No-Break">enhancement proposals.</span></p>
			<p>Last, but not least, the Kubernetes API is highly extensible in one of <span class="No-Break">two ways:</span></p>
			<ul>
				<li>With <strong class="bold">Custom Resource Definitions</strong> (<strong class="bold">CRDs</strong>): A<a id="_idIndexMarker287"/> method that does not require <span class="No-Break">any programming</span></li>
				<li>With <strong class="bold">aggregation layers</strong>: A<a id="_idIndexMarker288"/> method that requires programming but allows you to have more control over the <span class="No-Break">API behavior</span></li>
			</ul>
			<p>Both methods allow you to add extra functionality to Kubernetes, beyond what is offered by the standard Kubernetes APIs. You don’t need to know many details for the scope of the KCNA exam, but as you gain more hands-on experience, you’ll see that the extensible API is a very powerful feature of Kubernetes that allows us to add unique features without the need to know or modify existing K8s <span class="No-Break">source code.</span></p>
			<p>Now that we’ve learned about the Kubernetes API, let’s understand more about the features of Kubernetes that made it the number one orchestrator <span class="No-Break">of containers.</span></p>
			<h1 id="_idParaDest-64"><a id="_idTextAnchor063"/>K8s – the Swiss Army knife of container orchestration</h1>
			<p>We’ve mentioned a <a id="_idIndexMarker289"/>few times that Kubernetes is great for running cloud-native applications that consist of many microservices packaged in containers. But <span class="No-Break">why exactly?</span></p>
			<p>Kubernetes offers many features that enormously simplify the operation of large container fleets. We already know that it is possible to automatically scale the number of containers with Kubernetes or restart failing containers. What about the other features Kubernetes has <span class="No-Break">to offer?</span></p>
			<ul>
				<li><strong class="bold">Automated rollouts and rollbacks</strong>: Allows<a id="_idIndexMarker290"/> you to deploy new versions and changes of your application (or its configuration) in a controlled way, monitoring the application’s health status and ensuring it is always running. K8s also allows you to roll back to the previous versions of the application, its image, or its configuration if something <span class="No-Break">goes wrong.</span></li>
				<li><strong class="bold">Service discovery and load balancing</strong>: Allows different microservices in a cluster to <a id="_idIndexMarker291"/>easily find each other. In a set of pods representing the same microservice, each pod will have an IP address, but the set will have a single DNS name, allowing simple service discovery and <span class="No-Break">load distribution.</span></li>
				<li><strong class="bold">Secret and configuration management</strong>: Allows you to handle microservice configuration<a id="_idIndexMarker292"/> and secrets without the need to rebuild container images or expose sensitive credentials – for example, when a service needs to access a database or has many configuration parameters <span class="No-Break">that change.</span></li>
				<li><strong class="bold">Self-healing</strong>: Allows <a id="_idIndexMarker293"/>you to automatically restart containers that fail for any reason, automatically reschedule containers to another node if a worker node stops responding, restart containers that fail predefined health checks, and route requests to containers when only the applications inside are fully started and ready <span class="No-Break">to serve.</span></li>
				<li><strong class="bold">Horizontal scaling</strong>: Allows<a id="_idIndexMarker294"/> you to scale a containerized application up or down by adding or reducing the number of pods running the application. This can be done manually or automatically, for example, based on <span class="No-Break">CPU usage.</span></li>
				<li><strong class="bold">Batch execution</strong>: Allows<a id="_idIndexMarker295"/> you to schedule the execution of containers and flexibly manage batch processing or <span class="No-Break">CI workloads.</span></li>
				<li><strong class="bold">Automatic bin packing</strong>: Allows<a id="_idIndexMarker296"/> you to automatically determine the best worker node to start the container based on requested resources, current cluster utilization, or other requirements. It also allows you to define workload priorities to handle different critical and <span class="No-Break">non-critical applications.</span></li>
				<li><strong class="bold">Storage orchestration</strong>: Allows you to integrate and manage storage systems of your choice. Kubernetes <a id="_idIndexMarker297"/>can automatically provision and mount storage volumes when a pod is spawned and re-mount volumes to different nodes <span class="No-Break">as needed.</span></li>
			</ul>
			<p>This is a <a id="_idIndexMarker298"/>long list and yet not 100% complete. In the previous section, we saw that it is possible to extend the Kubernetes API to add new features. Today, Kubernetes has a rich ecosystem with numerous projects that extend Kubernetes and even allow you to manage other workloads besides containers. That’s right – Kubernetes can be used to orchestrate not just containers. There are several projects we <span class="No-Break">should mention:</span></p>
			<ul>
				<li><strong class="bold">KubeVirt</strong>: A project<a id="_idIndexMarker299"/> that’s used to provision and manage virtual machines with Kubernetes alongside containers. This is used for cases when a workload cannot be easily containerized or for an ongoing process of application containerization where some applications still run <span class="No-Break">in VMs.</span></li>
				<li><strong class="bold">Kubeless</strong>: A<a id="_idIndexMarker300"/> serverless computing framework that runs on top of Kubernetes. It adds FaaS capabilities to your K8s cluster and can serve as an alternative to cloud provider <span class="No-Break">FaaS offerings.</span></li>
				<li><strong class="bold">Knative</strong>: Another <a id="_idIndexMarker301"/>serverless computing framework for Kubernetes that has recently been accepted to the CNCF. It was originally founded by Google and has been actively developed <span class="No-Break">since 2018.</span></li>
				<li><strong class="bold">OpenFaas</strong>: Another<a id="_idIndexMarker302"/> serverless framework that can be used with Kubernetes or without in a standalone mode. Like the other two serverless frameworks, it supports many programming languages that can be used to write functions, including <em class="italic">Golang</em>, <em class="italic">Java</em>, <em class="italic">Python</em>, <em class="italic">Ruby</em>, <em class="italic">C#</em>, <span class="No-Break">and others.</span></li>
			</ul>
			<p>You don’t need to know further details about those projects for the KCNA exam or any other Kubernetes certification from CNCF. Just remember that it is possible to orchestrate VMs with the help of KubeVirt and offer FaaS on top of Kubernetes with projects such as Knative. If you’d like to learn more about these projects, you’ll find links in the <em class="italic">Further reading</em> section at the end of <span class="No-Break">this chapter.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Even though it is possible to manage VMs with the help of Kubernetes, it is still primarily used to orchestrate containers most of <span class="No-Break">the time.</span></p>
			<p>Before we jump into installing Kubernetes and trying its numerous features out, let’s look at an example of how K8s can be a part of the development workflow, as shown in <span class="No-Break"><em class="italic">Figure 5</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B18970_05_05.jpg" alt="Figure 5.5 – Simple development workflow example with Kubernetes"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 5.5 – Simple development workflow example with Kubernetes</p>
			<p>The simplified <a id="_idIndexMarker303"/>workflow may look <span class="No-Break">like this:</span></p>
			<ol>
				<li>A developer writes code for a new microservice and commits it to a GitHub repository. As you may recall, developers don’t need to learn a new programming language to run applications <span class="No-Break">in containers.</span></li>
				<li>There should be a <strong class="source-inline">Dockerfile</strong> that defines the steps needed to package the application into a container image. Before the container image is built, automated tests are executed in the CI pipeline. If the tests are successful, a Docker image is built and pushed into the <span class="No-Break">image registry.</span></li>
				<li>Next, the deployment of the container is triggered in the Kubernetes cluster. To run containers on Kubernetes, we need a pod spec definition in either <strong class="bold">YAML</strong> or <strong class="bold">JSON</strong> format. The easiest way to apply a spec is simply by using the <strong class="source-inline">kubectl</strong> tool, which must be configured to work with our <span class="No-Break">K8s cluster.</span></li>
				<li>As the spec is applied, Kubernetes will take care of finding a suitable worker node to download the container image from the registry and start the pod with our containerized application. We can define it to run multiple replicas of applications for high availability requirements and to balance <span class="No-Break">the load.</span></li>
				<li>This process can be repeated many times and Kubernetes can handle deploying the new image with a new application version in a rolling update manner where, for instance, only <a id="_idIndexMarker304"/>one replica will be replaced at <span class="No-Break">a time.</span></li>
			</ol>
			<p>A pod is <a id="_idIndexMarker305"/>just one example of a Kubernetes object, and it is the smallest deployable unit. In the next chapter, we’ll get to know other, more advanced resources that use Kubernetes controllers and provide more <span class="No-Break">advanced features.</span></p>
			<p class="callout-heading">Kubernetes objects</p>
			<p class="callout">Kubernetes objects <a id="_idIndexMarker306"/>are persistent entries that represent the state of the cluster, including information about which containerized applications run and on which nodes, resources available to these applications, and their associated policies (for example, restart policies, scheduling requirements, and <span class="No-Break">so on).</span></p>
			<p>Kubernetes objects are created the moment we apply a spec definition, and they are essentially a <em class="italic">record of intent</em>. Once the object has been created, Kubernetes will work to ensure that the object exists and is in the <em class="italic">desired state</em>. The time it might take to reach the desired state depends on many factors and might take as little as a second or as much as several minutes if, for instance, the container image that’s downloaded from the image registry is large and the network performance <span class="No-Break">is poor.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">Kubernetes spec definition files are also known as Kubernetes manifests. It is a specification of API objects in JSON or <span class="No-Break">YAML format.</span></p>
			<p>Now that we are familiar with some of the basics, let’s try things out ourselves. In the next section, we are going to install a single node Kubernetes to gain <span class="No-Break">hands-on experience.</span></p>
			<h1 id="_idParaDest-65"><a id="_idTextAnchor064"/>Installing and exploring K8s with minikube</h1>
			<p>Today, many<a id="_idIndexMarker307"/> projects allow you to quickly bootstrap a simple K8s cluster or a single node Kubernetes for learning or local development purposes. We will be using <strong class="bold">minikube</strong>, a project supported by an official Kubernetes SIG that <a id="_idIndexMarker308"/>focuses on cluster deployment and its<a id="_idIndexMarker309"/> life cycle. Other projects let you get similar<a id="_idIndexMarker310"/> results, such as <strong class="bold">Kind</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="bold">CRC</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">miniKube, Kind, and some other projects are not designed to set up production-ready Kubernetes clusters. Do not use these setups to run <span class="No-Break">important workloads!</span></p>
			<p>Quickly make <a id="_idIndexMarker311"/>sure that your <a id="_idIndexMarker312"/>system meets <span class="No-Break"><em class="italic">minikube’s</em></span><span class="No-Break"> requirements:</span></p>
			<ul>
				<li>A recent version of Linux, macOS, <span class="No-Break">or Windows</span></li>
				<li>2+ <span class="No-Break">CPU cores</span></li>
				<li>2+ GB of <span class="No-Break">free RAM</span></li>
				<li>20+ GB of free <span class="No-Break">disk space</span></li>
				<li><span class="No-Break">Internet connection</span></li>
				<li><span class="No-Break">Administrator/superuser privileges</span></li>
				<li>Container or VM manager (our Docker Engine installation from previous chapters can <span class="No-Break">be used)</span></li>
			</ul>
			<p>First, open the <a id="_idIndexMarker313"/>minikube start documentation (<a href="https://minikube.sigs.k8s.io/docs/start/">https://minikube.sigs.k8s.io/docs/start/</a>) in <a id="_idIndexMarker314"/>your browser and select your operating system under the <em class="italic">Installation</em> section. Make sure that you select the <em class="italic">Stable</em> release type and the correct CPU architecture if you’re running on macOS <span class="No-Break">or Linux.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you don’t have the <strong class="source-inline">curl</strong> tool installed, you can also simply copy the URL from the documentation, paste it into a new browser tab, and save it to your computer, just like any other downloadable. In such a case, the <strong class="source-inline">installation</strong> command should be executed in the same path where the <strong class="source-inline">minikube</strong> binary <span class="No-Break">was saved.</span></p>
			<p>Open your Terminal and execute the command for your OS, and enter the password if requested. For example, on macOS with an x86-64 CPU, the output might look <span class="No-Break">like this:</span></p>
			<pre class="source-code">
$ curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64
  % Total    % Received % Xferd  Average Speed   Time     Time     Time  Current
                                 Dload  Upload   Total    Spent    Left  Speed
100 68.6M  100 68.6M    0     0  38.5M      0  0:00:01   0:00:01 --:--:-- 38.7M
$ sudo install minikube-darwin-amd64 /usr/local/bin/minikube
Password:</pre>
			<p>At this<a id="_idIndexMarker315"/> point, we<a id="_idIndexMarker316"/> are ready to start our local Kubernetes with the help of the <strong class="source-inline">minikube </strong><span class="No-Break"><strong class="source-inline">start</strong></span><span class="No-Break"> command:</span></p>
			<pre class="source-code">
$ minikube start
😄  minikube v1.25.2 on Darwin 12.4
✨  Automatically selected the docker driver. Other choices: hyperkit, ssh
👍  Starting control plane node minikube in cluster minikube
🚜  Pulling base image ...
💾  Downloading Kubernetes v1.23.3 preload ...
    &gt; preloaded-images-k8s-v17-v1...: 505.68 MiB / 505.68 MiB  100.00% 40.26 Mi
    &gt; gcr.io/k8s-minikube/kicbase: 379.06 MiB / 379.06 MiB  100.00% 14.81 MiB p
🔥  Creating docker container (CPUs=2, Memory=4000MB) ...
🐳  Preparing Kubernetes v1.23.3 on Docker 20.10.12 ...
    ▪ kubelet.housekeeping-interval=5m
    ▪ Generating certificates and keys ...
    ▪ Booting up control plane ...
    ▪ Configuring RBAC rules ...
🌟  Enabled addons: storage-provisioner, default-storageclass
🏄  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">You might have a newer version of Kubernetes and a slightly different output from <strong class="source-inline">minikube start</strong>. If you encounter an error, there likely will be a link to a related issue in the output that should help you to resolve the problem. If you are using another system than in the previous chapters, you’ll need to install Docker Engine first. Refer to <a href="B18970_03.xhtml#_idTextAnchor038"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Getting Started with Containers</em>, for details and the drivers’ documentation page of minikube (<a href="https://minikube.sigs.k8s.io/docs/drivers/">https://minikube.sigs.k8s.io/docs/drivers/</a>). For other problems, check the minikube troubleshooting guide linked in the <em class="italic">Further reading</em> section of <span class="No-Break">this chapter.</span></p>
			<p>Now that we have <a id="_idIndexMarker317"/>Kubernetes up and running, we should be able to access its API using the <strong class="source-inline">kubectl</strong> CLI tool. You can go and download <strong class="source-inline">kubectl</strong> yourself, but minikube can do this for you. It is recommended to let <strong class="source-inline">minikube</strong> do this as it will automatically pick the correct version. All you need to do is run any command with <strong class="source-inline">kubectl</strong> for the first time – for example, a command to list all Kubernetes nodes in <span class="No-Break">the cluster:</span></p>
			<pre class="source-code">
$ minikube kubectl get nodes
    &gt; kubectl.sha256: 64 B / 64 B [--------------------------] 100.00% ? p/s 0s
    &gt; kubectl: 50.65 MiB / 50.65 MiB [-------------] 100.00% 54.17 MiB p/s 1.1s
NAME       STATUS   ROLES                  AGE   VERSION
minikube   Ready    control-plane,master   18m   v1.23.3</pre>
			<p>Minikube has<a id="_idIndexMarker318"/> downloaded the K8s CLI for us and ran<a id="_idIndexMarker319"/> the command. At no surprise, we only have one node that is called <strong class="source-inline">minikube</strong> and has roles of <strong class="source-inline">control-plane</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">master</strong></span><span class="No-Break">.</span></p>
			<p>Let’s see what is currently running in Kubernetes. You can list the pods using the <strong class="source-inline">kubectl get </strong><span class="No-Break"><strong class="source-inline">pods</strong></span><span class="No-Break"> command:</span></p>
			<pre class="source-code">
$ minikube kubectl get pods
No resources found in default namespace.</pre>
			<p>As we can see, nothing is running at the moment because we’ve just bootstrapped a new cluster. Let’s run the same command with an extra option – that is, <strong class="source-inline">--all-namespaces</strong> (mind the two extra dashes between <strong class="source-inline">kubectl</strong> and <strong class="source-inline">get</strong>; they are needed to separate the <strong class="source-inline">kubectl</strong> from <strong class="source-inline">minikube</strong> arguments since both have their own sets <span class="No-Break">of arguments):</span></p>
			<pre class="source-code">
$ minikube kubectl -- get pods --all-namespaces
NAMESPACE     NAME                               READY   STATUS    RESTARTS   AGE
kube-system   coredns-64897985d-x28hm            1/1     Running   0          31m
kube-system   etcd-minikube                      1/1     Running   0          32m
kube-system   kube-apiserver-minikube            1/1     Running   0          32m
kube-system   kube-controller-manager-minikube   1/1     Running   0          32m
kube-system   kube-proxy-hwv2p                   1/1     Running   0          32m
kube-system   kube-scheduler-minikube            1/1     Running   0          32m
kube-system   storage-provisioner                1/1     Running   0          32m</pre>
			<p>The output<a id="_idIndexMarker320"/> has changed quite a bit and we can now <a id="_idIndexMarker321"/>see all those components of Kubernetes that we learned about at the beginning of this chapter: <strong class="source-inline">kube-apiserver</strong>, <strong class="source-inline">kube-controller-manager</strong>, <strong class="source-inline">kube-proxy</strong>, <strong class="source-inline">kube-scheduler</strong>, <strong class="source-inline">etcd</strong>, and a couple of other running in individual pods in the <span class="No-Break"><strong class="source-inline">kube-system</strong></span><span class="No-Break"> namespace.</span></p>
			<p class="callout-heading">Kubernetes namespaces</p>
			<p class="callout">Kubernetes namespaces<a id="_idIndexMarker322"/> provide a grouping mechanism to separate Kubernetes objects within a cluster. It is common to use Kubernetes namespaces to group workloads per team, project, or application. The <strong class="source-inline">kube-system</strong> namespace is reserved for <span class="No-Break">Kubernetes’s components.</span></p>
			<p>Now, let’s see which namespaces we have in our new <span class="No-Break">shiny Kubernetes:</span></p>
			<pre class="source-code">
$ minikube kubectl -- get namespaces
NAME              STATUS   AGE
default           Active   56m
kube-node-lease   Active   56m
kube-public       Active   56m
kube-system       Active   56m</pre>
			<p>The <strong class="source-inline">default</strong> namespace, as its name suggests, is simply a standard namespace where container workloads will be created by default. <strong class="source-inline">kube-node-lease</strong> is another reserved Kubernetes namespace for node heartbeats (checks that determine that the node is running) and <strong class="source-inline">kube-public</strong> is an automatically created namespace for public resources such as those required for <span class="No-Break">cluster discovery.</span></p>
			<p>Normal practice is to create new namespaces either per application, group of microservices working together, or per team. Let’s create a new namespace and call it <strong class="source-inline">kcna</strong> by executing <strong class="source-inline">kubectl -- create </strong><span class="No-Break"><strong class="source-inline">namespace kcna</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
$ minikube kubectl -- create namespace kcna
namespace/kcna created</pre>
			<p class="callout-heading">Note</p>
			<p class="callout">You can also set up an alias for <strong class="source-inline">minikube kubectl</strong>, as suggested in the minikube documentation (<strong class="source-inline">$ alias kubectl="minikube kubectl --"</strong>) to skip writing <strong class="source-inline">minikube</strong> every time. (Make sure that you remove it when you’re not using <span class="No-Break"><strong class="source-inline">minikube</strong></span><span class="No-Break"> anymore.)</span></p>
			<p>Now, let’s <a id="_idIndexMarker323"/>deploy a containerized <em class="italic">Nginx</em> web server into our new <strong class="source-inline">kcna</strong> namespace. We can always set the namespace where we want to<a id="_idIndexMarker324"/> execute the <strong class="source-inline">kubectl</strong> command by adding the <strong class="source-inline">--</strong><span class="No-Break"><strong class="source-inline">namespace</strong></span><span class="No-Break"> argument:</span></p>
			<pre class="source-code">
$ minikube kubectl -- create -f https://k8s.io/examples/pods/simple-pod.yaml --namespace kcna
pod/nginx created</pre>
			<p>Here, we provided a pod spec file that is located in the examples shown on the <a href="https://k8s.io/">https://k8s.io/</a> web page. The Kubernetes CLI is smart enough to download the file, validate the spec, and apply it to create the objects it defines – in this case, a single pod with Nginx. If we were to write this simple pod specification ourselves in YAML format, it would look <span class="No-Break">like this:</span></p>
			<pre class="source-code">
$ cat simple-pod.yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80</pre>
			<p>Let’s see what each line of this spec <span class="No-Break">file means.</span></p>
			<p><strong class="source-inline">apiVersion: v1</strong> defines <a id="_idIndexMarker325"/>which version of the Kubernetes API we are using to create this object. As you know, Kubernetes APIs evolve from alpha to<a id="_idIndexMarker326"/> beta to stable versions. <strong class="source-inline">v1</strong> is the stable version in <span class="No-Break">this example:</span></p>
			<ul>
				<li><strong class="source-inline">kind: Pod</strong> – Defines the kind of object we <span class="No-Break">are describing.</span></li>
				<li><strong class="source-inline">metadata:</strong> – Defines metadata for the object, such as <strong class="source-inline">name</strong> or <span class="No-Break">further annotations.</span></li>
				<li><strong class="source-inline">name: nginx</strong> – Defines the name of <span class="No-Break">the pod.</span></li>
				<li><strong class="source-inline">spec:</strong> – Defines the block where we describe the desired state of <span class="No-Break">the object.</span></li>
				<li><strong class="source-inline">containers:</strong> – Defines the list of containers that are part of <span class="No-Break">this pod.</span></li>
				<li><strong class="source-inline">-</strong> <strong class="source-inline">name:</strong> <strong class="source-inline">nginx</strong> – The name of the first container in the Pod. Multiple containers can run together in <span class="No-Break">one pod.</span></li>
				<li><strong class="source-inline">image: nginx:1.14.2</strong> – The name of the image (<strong class="source-inline">nginx</strong>) that can be optionally preceded by the image registry URL and followed by the image tag (<strong class="source-inline">1.14.2</strong>). If you run multiple containers in one pod, you’ll need to define the image and name for <span class="No-Break">each one.</span></li>
				<li><strong class="source-inline">ports:</strong> – This is an optional informational block that tells us about which ports are to be exposed. Those are the ports where the process in the container is listening on. However, not specifying this block does not prevent ports from <span class="No-Break">being exposed.</span></li>
				<li><strong class="source-inline">- containerPort: 80</strong> – This is port <strong class="source-inline">80</strong> in <span class="No-Break">this example.</span></li>
			</ul>
			<p class="callout-heading">Note</p>
			<p class="callout">The indentation is very important in YAML format and one missing space or an extra space can make it invalid. <strong class="source-inline">kubectl</strong> will complain if there are parsing errors when applying a specification. It is recommended to copy example files from this book’s GitHub repository to avoid typos and <span class="No-Break">formatting mistakes.</span></p>
			<p>Alright, so, what<a id="_idIndexMarker327"/> happened with our <span class="No-Break">Nginx pod?</span></p>
			<pre class="source-code">
$ minikube kubectl -- get pods --namespace kcna
NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          10m</pre>
			<p>It is in a <strong class="source-inline">Running</strong> status and <strong class="source-inline">1/1</strong> (one out of one) containers in the pod are ready. There are several <a id="_idIndexMarker328"/>statuses the pod might <span class="No-Break">be in:</span></p>
			<ul>
				<li><strong class="source-inline">Pending</strong>: The specification has been accepted by Kubernetes and, currently, the pod is waiting to be scheduled or for a requested container image to be downloaded from the <span class="No-Break">image registry.</span></li>
				<li><strong class="source-inline">Running</strong>: The pod is assigned to a certain node and all containers in the pod have been created. At least one container <span class="No-Break">is running.</span></li>
				<li><strong class="source-inline">Succeeded</strong>: All the containers in the pod have successfully finished/exited with a <em class="italic">good</em> exit code (for example zero). This happens when, for example, an application in a container has gracefully <span class="No-Break">shut down.</span></li>
				<li><strong class="source-inline">Failed</strong>: All the containers in the pod terminated and at least one has failed; for example, it has exited with a non-zero <span class="No-Break">exit code.</span></li>
				<li><strong class="source-inline">Unknown</strong>: The state of the pod cannot be obtained. This might happen when a node where the pod should be running is unreachable, for example, due to <span class="No-Break">network issues.</span></li>
				<li><strong class="source-inline">ErrImagePull</strong> : The image specified in the manifest cannot be retrieved (pulled). This might be due to a wrong image name or wrong tag that does not exist in <span class="No-Break">the registry.</span></li>
			</ul>
			<p>Additionally, you <a id="_idIndexMarker329"/>might encounter a <strong class="source-inline">ContainerCreating</strong> or <strong class="source-inline">Terminating</strong> status describing the startup or termination phase of pod <span class="No-Break">containers, respectively.</span></p>
			<p>Currently, our Nginx pod does nothing; it does not serve any applications or content except for its default static page. In the next chapter, we will learn how to expose and access applications in Kubernetes with<a id="_idIndexMarker330"/> the <strong class="bold">Service</strong> concept. For now, try to get more details about our <strong class="source-inline">nginx</strong> pod using the <strong class="source-inline">kubectl </strong><span class="No-Break"><strong class="source-inline">describe</strong></span><span class="No-Break"> command:</span></p>
			<pre class="source-code">
$ minikube kubectl -- describe pods nginx --namespace kcna</pre>
			<p>You’ll find a lot <a id="_idIndexMarker331"/>of information about the pod, such as the node where it runs, its start time, IP address, environment variables, recent events, and much more. This information is very helpful for cases when we need to debug failing pods <span class="No-Break">or applications.</span></p>
			<p>Now that we have used <strong class="source-inline">kubectl</strong> a bit, let’s try the Kubernetes dashboard as well. Minikube offers a convenient one-command dashboard installation with <span class="No-Break"><strong class="source-inline">minikube dashboard</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
$ minikube dashboard
🔌  Enabling dashboard ...
    ▪ Using image kubernetesui/dashboard:v2.3.1
    ▪ Using image kubernetesui/metrics-scraper:v1.0.7
🤔  Verifying dashboard health ...
🚀  Launching proxy ...
🤔  Verifying proxy health ...
🎉  Opening http://127.0.0.1:55089/api/v1/namespaces/kubernetes-dashboard/services/http:kubernetes-dashboard:/proxy/ in your default browser...</pre>
			<p>At this point, the dashboard will be installed into a new <strong class="source-inline">kubernetes-dashboard</strong> namespace and your browser should automatically open it in a new tab (in case it did not, try executing <strong class="source-inline">minikube dashboard --url</strong> to get the URL of the dashboard). You’ll need to switch to another namespace in the top-left corner drop-down menu as there is nothing<a id="_idIndexMarker332"/> currently running in the <strong class="source-inline">default</strong> namespace. If you switch to the <strong class="source-inline">kcna</strong> namespace, you’ll be able to see our <strong class="source-inline">nginx</strong> pod, whereas if you switch to <strong class="source-inline">kube-system</strong>, you’ll see the Kubernetes control plane components that we described previously in this chapter. You may notice that, besides pods, there are <strong class="bold">Deployment</strong>, <strong class="bold">Daemon Set</strong> and <strong class="bold">Replica Set</strong> workloads. Those will be the topic of the next chapter, where we will see how these can be used to create pods and learn about the features of those <span class="No-Break">K8s resources.</span></p>
			<p>Feel free to explore <a id="_idIndexMarker333"/>the dashboard a little more by yourself; when you’re done, delete our Nginx pod using the dashboard or via the <strong class="source-inline">kubectl delete</strong> command. To interrupt <strong class="source-inline">minikube dashboard</strong>, you can use <em class="italic">Ctrl</em> + <span class="No-Break"><em class="italic">C</em></span><span class="No-Break"> shortcut:</span></p>
			<pre class="source-code">
$  minikube kubectl -- delete pods nginx --namespace kcna
pod "nginx" deleted</pre>
			<p class="callout-heading">Note</p>
			<p class="callout"><strong class="source-inline">kubectl</strong> is <a id="_idIndexMarker334"/>a user-friendly tool that allows you to type <strong class="source-inline">pod</strong>, <strong class="source-inline">pods</strong>, or simply <strong class="source-inline">po</strong>, all of which mean the same thing. It also has a lot of convenient short names, such as <strong class="source-inline">ns</strong>, for namespaces. To list all short names, run <strong class="source-inline">minikube </strong><span class="No-Break"><strong class="source-inline">kubectl api-resources</strong></span><span class="No-Break">.</span></p>
			<p>If you are about to shut down your workstation before moving on to the next chapter, you can also temporarily stop your Kubernetes node by executing the <strong class="source-inline">minikube </strong><span class="No-Break"><strong class="source-inline">stop</strong></span><span class="No-Break"> command:</span></p>
			<pre class="source-code">
$ minikube stop
✋  Stopping node "minikube"  ...
🛑  Powering off "minikube" via SSH ...
🛑  1 node stopped.</pre>
			<p>This has been a long and very intense chapter, so congrats on making it this far! Take a break before moving on to the next chapter and make sure you answer the <span class="No-Break">questions provided.</span></p>
			<h1 id="_idParaDest-66"><a id="_idTextAnchor065"/>Summary</h1>
			<p>In this chapter, we finally got our hands on Kubernetes. We learned a lot about its architecture, components, and API. Kubernetes clusters consist of control plane (also known as the master) and worker nodes, where control plane nodes run K8s management components and worker nodes run the actual containerized applications with the help of <em class="italic">kubelet</em>, <em class="italic">container runtime</em>, and <em class="italic">kube-proxy</em>. Among the master node components, there’s <em class="italic">kube-apiserver</em>, <em class="italic">etcd</em>, <em class="italic">kube-scheduler</em>, <em class="italic">kube-controller-manager</em>, and, <span class="No-Break">optionally, </span><span class="No-Break"><em class="italic">cloud-controller-manager</em></span><span class="No-Break">.</span></p>
			<p>We saw that a <em class="italic">pod</em> is the smallest deployable unit of Kubernetes and that it allows us to run individual containers as well as multiple containers together on K8s. Containers inside one pod are coupled and can share storage, network, and memory. The secondary container in the pod is typically called the <em class="italic">sidecar</em> and can help the container run the main application by doing log aggregation, <span class="No-Break">for example.</span></p>
			<p>The Kubernetes API is <em class="italic">declarative</em>. When we work with K8s, we describe the desired state of resources in the cluster; Kubernetes ensures that the current state reaches the desired state after object creation. Due to rapid development, Kubernetes APIs are grouped and multi-versioned, and by default only enable <em class="italic">beta</em> and <em class="italic">stable</em> (GA) features. There are several ways to access the Kubernetes API, with the <em class="italic">kubectl</em> CLI and <em class="italic">dashboard</em> being the most popular ones. One of the specialties of K8s is its ability to extend its APIs through CRDs and <span class="No-Break">aggregation layers.</span></p>
			<p>When it comes to features, Kubernetes has a lot to offer, ranging from automatic rollouts, service discovery, and secret management to auto-scaling, self-healing, and even storage orchestration. We will try many of those features in practice in the next few chapters. It is also possible to use Kubernetes to manage virtual machines or provide FaaS with the help of separate projects such as <em class="italic">KubeVirt</em> <span class="No-Break">and </span><span class="No-Break"><em class="italic">Knative</em></span><span class="No-Break">.</span></p>
			<p>In the last section, we installed a simple one-node Kubernetes deployment using the <em class="italic">minikube</em> project and learned about the concept of Kubernetes <em class="italic">namespaces</em> for resource separation and grouping. We also created a pod with a single Nginx container and explored the minimal pod spec definition in <span class="No-Break">YAML format.</span></p>
			<p>In the next chapter, we will learn about other Kubernetes resources and their usage. We will learn how to configure and scale multi-container applications with Kubernetes, how to run stateful workloads with Kubernetes, and learn about exposing applications running <span class="No-Break">in K8s.</span></p>
			<h1 id="_idParaDest-67"><a id="_idTextAnchor066"/>Questions</h1>
			<p>As we conclude, here is a list of questions for you to test your knowledge regarding this chapter’s material. You will find the answers in the <em class="italic">Assessments</em> section of <span class="No-Break">the </span><span class="No-Break"><em class="italic">Appendix</em></span><span class="No-Break">:</span></p>
			<ol>
				<li value="1">Which of the following is the smallest schedulable unit <span class="No-Break">in Kubernetes?</span><ol><li><span class="No-Break">Container</span></li><li><span class="No-Break">Sidecar</span></li><li><span class="No-Break">Pod</span></li><li><span class="No-Break">Deployment</span></li></ol></li>
				<li>Containers running in one pod share which of the following options (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">Name</span></li><li><span class="No-Break">Storage</span></li><li><span class="No-Break">Networking</span></li><li><span class="No-Break">Memory</span></li></ol></li>
				<li>Which of the following types of nodes does Kubernetes have (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">Secondary</span></li><li><span class="No-Break">Master</span></li><li><span class="No-Break">Worker</span></li><li><span class="No-Break">Primary</span></li></ol></li>
				<li>Which of the following are components of control plane nodes (<span class="No-Break">pick multiple)?</span><ol><li>Docker, <span class="No-Break">kube-scheduler, cloud-controller-manager</span></li><li>kube-master-server, <span class="No-Break">kubelet, kube-proxy</span></li><li><span class="No-Break">kube-scheduler, kube-controller-manager</span></li><li><span class="No-Break">kube-api-server, etcd</span></li></ol></li>
				<li>Which of the following K8s cluster configuration can <span class="No-Break">be recommended?</span><ol><li>1 master node, 5 <span class="No-Break">worker nodes</span></li><li>2 master nodes, 3 <span class="No-Break">worker nodes</span></li><li>2 master nodes, 20 <span class="No-Break">worker nodes</span></li><li>3 master nodes, 10 <span class="No-Break">worker nodes</span></li></ol></li>
				<li>Which of the following components are used to store cluster state <span class="No-Break">in Kubernetes?</span><ol><li><span class="No-Break">kube-api-server</span></li><li><span class="No-Break">kube-volume</span></li><li><span class="No-Break">kubelet</span></li><li><span class="No-Break">etcd</span></li></ol></li>
				<li>Which of the following components is used by Kubernetes to download images and <span class="No-Break">start containers?</span><ol><li><span class="No-Break">Kubelet</span></li><li><span class="No-Break">Container runtime</span></li><li><span class="No-Break">etcd</span></li><li><span class="No-Break">kube-proxy</span></li></ol></li>
				<li>Which of the following components is responsible for Kubernetes <span class="No-Break">controller processes?</span><ol><li><span class="No-Break">kube-api-server</span></li><li><span class="No-Break">kube-proxy</span></li><li><span class="No-Break">kube-controller-manager</span></li><li><span class="No-Break">kube-scheduler</span></li></ol></li>
				<li>What can be used to access the Kubernetes API (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">kubeadmin</span></li><li><span class="No-Break">kubectl</span></li><li><span class="No-Break">kubelet</span></li><li><span class="No-Break">dashboard</span></li></ol></li>
				<li>Kubernetes has a declarative API. What does <span class="No-Break">this mean?</span><ol><li>We always need to declare a YAML spec file to use the <span class="No-Break">K8s API</span></li><li>We declare the desired state and K8s will reach <span class="No-Break">it once</span></li><li>We tell Kubernetes exactly what to do with <span class="No-Break">which resource</span></li><li>We declare the desired state and K8s will constantly try to <span class="No-Break">reach it</span></li></ol></li>
				<li>Which of the following Kubernetes API versions are enabled by default (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">Alpha</span></li><li><span class="No-Break">Beta</span></li><li><span class="No-Break">Gamma</span></li><li><span class="No-Break">Stable</span></li></ol></li>
				<li>How can you extend the Kubernetes API with new features (<span class="No-Break">pick multiple)?</span><ol><li>Code <span class="No-Break">Resource Definitions</span></li><li><span class="No-Break">Aggregation layers</span></li><li><span class="No-Break">Extension layers</span></li><li>Custom <span class="No-Break">Resource Definitions</span></li></ol></li>
				<li>Which of the following projects allows you to extend Kubernetes beyond container orchestration (<span class="No-Break">pick multiple)?</span><ol><li>Knative <span class="No-Break">for FaaS</span></li><li>Linkerd <span class="No-Break">for IPAM</span></li><li>Kvirt for <span class="No-Break">VM orchestration</span></li><li>KubeVirt for <span class="No-Break">VM orchestration</span></li></ol></li>
				<li>What helps detect the difference between the current and desired state of <span class="No-Break">Kubernetes resources?</span><ol><li><span class="No-Break">Container runtime</span></li><li><span class="No-Break">Kubernetes scheduler</span></li><li>Custom <span class="No-Break">Resource Definition</span></li><li><span class="No-Break">Reconciliation loop</span></li></ol></li>
				<li>What are secondary containers running in <span class="No-Break">pod called?</span><ol><li><span class="No-Break">Flatcars</span></li><li><span class="No-Break">Sidecars</span></li><li><span class="No-Break">Podcars</span></li><li><span class="No-Break">Helpcars</span></li></ol></li>
				<li>Which of the following formats is used to write Kubernetes <span class="No-Break">spec files?</span><ol><li><span class="No-Break">CSV</span></li><li><span class="No-Break">Protobuf</span></li><li><span class="No-Break">YAML</span></li><li><span class="No-Break">Marshal</span></li></ol></li>
				<li>Which of the following Kubernetes components is responsible for allocating new pods <span class="No-Break">to nodes?</span><ol><li><span class="No-Break">kube-api</span></li><li><span class="No-Break">kube-proxy</span></li><li><span class="No-Break">kube-scheduler</span></li><li><span class="No-Break">kube-controller-manager</span></li></ol></li>
				<li>Which of the following K8s CLI commands can be used to list pods in the <span class="No-Break"><strong class="source-inline">development</strong></span><span class="No-Break"> namespace?</span><ol><li><strong class="source-inline">kubectl list pods -</strong><span class="No-Break"><strong class="source-inline">n development</strong></span></li><li><strong class="source-inline">kubectl get pods --</strong><span class="No-Break"><strong class="source-inline">namespace development</strong></span></li><li><strong class="source-inline">kubectl show pods --</strong><span class="No-Break"><strong class="source-inline">namespace development</strong></span></li><li><strong class="source-inline">kubectl get </strong><span class="No-Break"><strong class="source-inline">pods --all-namespaces</strong></span></li></ol></li>
				<li>Which of the following K8s CLI commands can be used to list all the namespaces in <span class="No-Break">the cluster?</span><ol><li><strong class="source-inline">kubectl list </strong><span class="No-Break"><strong class="source-inline">namespaces --all-namespaces</strong></span></li><li><strong class="source-inline">kubectl </strong><span class="No-Break"><strong class="source-inline">show namespaces</strong></span></li><li><strong class="source-inline">kubectl </strong><span class="No-Break"><strong class="source-inline">get namespaces</strong></span></li><li><strong class="source-inline">kubectl </strong><span class="No-Break"><strong class="source-inline">get all</strong></span></li></ol></li>
				<li>Which of the following pod statuses means its container(s) are <span class="No-Break">currently executing?</span><ol><li><span class="No-Break">Executing</span></li><li><span class="No-Break">Succeeded</span></li><li><span class="No-Break">Running</span></li><li><span class="No-Break">ContainerCreated</span></li></ol></li>
				<li>Which of the following pod statuses means all its containers are running (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">100%</span></li><li><span class="No-Break">1/2</span></li><li><span class="No-Break">2/2</span></li><li><span class="No-Break">1/1</span></li></ol></li>
			</ol>
			<h1 id="_idParaDest-68"><a id="_idTextAnchor067"/>Further reading</h1>
			<p>To learn more about the topics that were covered in this chapter, take a look at the <span class="No-Break">following resources:</span></p>
			<ul>
				<li>Minikube troubleshooting <span class="No-Break">guide: </span><a href="https://minikube.sigs.k8s.io/docs/handbook/troubleshooting/"><span class="No-Break">https://minikube.sigs.k8s.io/docs/handbook/troubleshooting/</span></a></li>
				<li>Commonly used <strong class="source-inline">kubectl</strong> <span class="No-Break">commands: </span><a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/"><span class="No-Break">https://kubernetes.io/docs/reference/kubectl/cheatsheet/</span></a></li>
				<li>K8s pods <span class="No-Break">concept: </span><a href="https://kubernetes.io/docs/concepts/workloads/pods/"><span class="No-Break">https://kubernetes.io/docs/concepts/workloads/pods/</span></a></li>
				<li>K8s namespace <span class="No-Break">concept:</span><span class="No-Break"> </span><a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"><span class="No-Break">https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/</span></a></li>
			</ul>
		</div>
	</body></html>