- en: '*Chapter 10*: Building, Deploying, and Monitoring Your Model'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, you built the data pipeline and created a basic flight
    dataset that can be used by your data science team. In this chapter, your data
    science team will use the flight dataset to build a **machine learning** (**ML**)
    model. The model will be used to predict the on-time performance of the flights.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will see how the platform assists you in visualizing and
    experimenting with the data to build the right model. You will see how to tune
    hyperparameters and compare the results of different runs of model training. You
    will see how to register and version models using the components provided by the
    platform. You will deploy the model as a REST service and start monitoring the
    deployed model using the components provided by the platform.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that this book is not about data science, instead, the focus is on
    enabling teams to work autonomously and efficiently. You may see some concepts
    and steps being repeated from earlier chapters. This is intentional to show you
    how the concepts provided in the previous chapters help you build a full life
    cycle.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keeping the goal in mind, you will learn about the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing and exploring data using JupyterHub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building and tuning your model using JupyterHub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tracking model experiments and versioning using MLflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying your model as a service via Seldon and Airflow
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring your model using Prometheus and Grafana
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter includes some hands-on setup and exercises. You will need a running
    Kubernetes cluster configured with the **Operator Lifecycle Manager** (**OLM**).
    Building such a Kubernetes environment is covered in [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040),
    *Exploring Kubernetes*. Before attempting the technical exercises in this chapter,
    please make sure that you have a working Kubernetes cluster and **Open Data Hub**
    (**ODH**) is installed on your Kubernetes cluster. Installing ODH is covered in
    [*Chapter 4*](B18332_04_ePub.xhtml#_idTextAnchor055), *The Anatomy of a Machine
    Learning Platform*.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing and exploring data using JupyterHub
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recall from [*Chapter 9*](B18332_09_ePub.xhtml#_idTextAnchor132), *Building
    Your Data Pipeline*, that the data engineer has worked with the SME of the business
    and prepared the flight data that can be used to predict the flights' on-time
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you will understand the data produced by the data engineering
    team. This is the role of the data scientist who is responsible for building the
    model. You will see how the platform enables your data science and data engineering
    teams to collaborate and how the data scientist can use the platform to build
    a model for the given problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s do some base data exploring using the platform. Keep in mind that the
    focus of this book is to enable your team to work efficiently. The focus is not
    on data science or data engineering but on building and using the platform:'
  prefs: []
  type: TYPE_NORMAL
- en: Launch JupyterHub, but this time select the image that is relative to the data
    science life cycle. SciKit is one such image available on the platform. Do not
    click on the **Start server** button just yet.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.1 – JupyterHub landing page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_001.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.1 – JupyterHub landing page
  prefs: []
  type: TYPE_NORMAL
- en: On the JupyterHub landing page, add an `AWS_SECRET_ACCESS_KEY` variable and
    populate it with the password for your S3 environment. The value for this key
    for this exercise would be `minio123`. Notice that we have used the **Medium**
    container size to accommodate the dataset. Now, hit the **Start server** button
    to start your JupyterHub IDE.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.2 – JupyterHub landing page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_002.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.2 – JupyterHub landing page
  prefs: []
  type: TYPE_NORMAL
- en: Open the `chapter10/visualize.ipynb` file notebook in your JupyterHub IDE.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The first step is to read the data provided by the data engineering team. Note
    that the data is available on the same platform, which improves the velocity of
    the teams. *Cell 2* in the notebook is using the `PyArrow` library to read the
    data as a pandas data frame. You will read the data from the `flights-data` bucket,
    where data is placed by the data team. You can see the data read code as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Cell 2 for the chapter10/visualize notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_003.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.3 – Cell 2 for the chapter10/visualize notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'The first thing you will do is to look at the data. Trying to make sense of
    it and familiarizing yourself with what is available can be the ideal take here.
    You can see in *Cell 3* that the DataFrame''s `head` function has been used to
    see the first few rows. You will notice the field names and the data in them and
    see whether you can understand one record. Notice that some fields are `NaN` and
    some are `None`. This gives you a clue that the dataset may not yet be ready for
    building models. The following screen captures partial output, and it is expected
    that you run this code in your environment to get the full picture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Cell 3 for the chapter10/visualize notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_004.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.4 – Cell 3 for the chapter10/visualize notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'The next stage is to do a simple verification to see how much data is available
    for you and if you are reading all the records. You can see in *Cell 4* that the
    DataFrame''s `count` function has been used for this. The following screen captures
    partial output, and it is expected that you run this code in your environment
    to get the full picture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Cell 4 for the chapter10/visualize notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_005.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.5 – Cell 4 for the chapter10/visualize notebook
  prefs: []
  type: TYPE_NORMAL
- en: '*Cells 5* and *6* are using the DataFrame''s shape and the columns'' functions
    are self-explanatory.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Cell 7* is using the DataFrame''s `describe` function to generate some basic
    statistics for the dataset. You may use this to verify whether there is some data
    that may not make sense. An example could be an exceedingly high value as maximum
    for the `taxi_in` time. In such cases, you will work with your SME to clarify
    and adjust the records as needed. The following screen captures partial output,
    and it is expected that you run this code in your environment to get the full
    picture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.6 – Cell 7 for the chapter10/visualize notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_006.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.6 – Cell 7 for the chapter10/visualize notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, you want to see whether the data has null values. You have seen in *Step
    3*, that there are some `NaN` and `None` values in the data. You have found out
    that there are many columns with missing data problems. The following screen captures
    partial output, and it is expected that you run this code in your environment
    to get the full picture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Cell 8 for the chapter10/visualize notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_007.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.7 – Cell 8 for the chapter10/visualize notebook
  prefs: []
  type: TYPE_NORMAL
- en: You will use the Dataframe's `isnull` function to find out how many records
    have this missing data. Using the output from the `df.isnull().sum().sort_values(ascending
    = False)` code, there are two different groups. The first six rows of the output
    show column names that have a very high missing data rate and for these columns,
    you may talk to data engineering and the SME to find resources from where you
    can fetch the data for them. For our example, we will just drop these columns.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.8 – Cell 9 for the chapter10/visualize notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_008.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.8 – Cell 9 for the chapter10/visualize notebook
  prefs: []
  type: TYPE_NORMAL
- en: In the second group, starting from the `wheels_on` column, you may either choose
    to drop the rows containing no data or try to fill the data with a suitable statistics
    function. For example, the missing `taxi_in` columns could be the mean for the
    same airport and same time. The strategy must be discussed with the team. For
    this exercise, we will just drop the rows.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.9 – Cell 9 for the chapter10/visualize notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_009.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.9 – Cell 9 for the chapter10/visualize notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'Often, it is a good idea to investigate sample rows where a particular column
    has no data. You may find a pattern in the data that could be extremely useful
    in further understanding the data. You have chosen to see the rows where the `tail_number`
    field has no value and see whether you can find any patterns. The following screen
    captures partial output, and it is expected that you run this code in your environment
    to get the full picture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.10 – Cell 10 for the chapter10/visualize notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_010.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.10 – Cell 10 for the chapter10/visualize notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'You will then run the Dataframe''s `info` function to find out the data types
    of the columns. A lot of times, the data types of columns are not the ones that
    you are expecting. You will then talk to the SME and data teams to improve the
    data quality. The following screen captures partial output, and it is expected
    that you run this code in your environment to get the full picture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.11 – Cell 11 for the chapter10/visualize notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_011.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.11 – Cell 11 for the chapter10/visualize notebook
  prefs: []
  type: TYPE_NORMAL
- en: Visualization is one particularly important tool to understand data. You can
    use any of the libraries that you feel comfortable with. For example, in the last
    cell of this notebook, you build a graph to find out the data distribution for
    the `DELAYED` column. Imagine that 99% of the records are with the `DELAYED` column
    as `0`. If that is the case, the data may not be enough to predict the flights'
    on-time performance and you will need to engage the SME and data teams to get
    more data. For this exercise, we will use the existing data distribution.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.12 – Cell 12 for the chapter10/visualize notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_012.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.12 – Cell 12 for the chapter10/visualize notebook
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand flight data a bit better, let's start building our model.
    In the real world, you would invest a lot more time to understand the data. The
    focus of this book is to show you how to execute the model development life cycle
    and so we kept the examples to a minimum.
  prefs: []
  type: TYPE_NORMAL
- en: Building and tuning your model using JupyterHub
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As a data scientist, you will want to try different models with different parameters
    to find the right fit. Before you start building the model, recall from [*Chapter
    8*](B18332_08_ePub.xhtml#_idTextAnchor116), *Building a Complete ML Project Using
    the Platform*, that you need to define the evaluation criteria, and that **accuracy**
    may be a misleading criterion for a lot of use cases.
  prefs: []
  type: TYPE_NORMAL
- en: For the flight use case, let's assume that your team and the SME agree on the
    **PRECISION** metric. Note that precision measures the portion of correct positive
    identification in the provided dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start writing our model and see how the platform enables data scientists
    to perform their work efficiently:'
  prefs: []
  type: TYPE_NORMAL
- en: Open the `chapter10/experiments.ipynb` file notebook in your JupyterHub environment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In *Cell 2*, add the connection information to MLflow. Recall that MLflow is
    the component in the platform that records the model experiments and works as
    the model registry. In the code, you will configure `EXPERIMENT_NAME`, which provides
    a name for your experiment runs. The last line of this cell mentions how MLflow
    will record the experiment run. The `autolog` feature enables MLflow to register
    automatic callbacks during training to record the parameters for later use.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You also provide the configuration for the S3 bucket, which will be used by
    MLflow to store the artifacts of your experiments:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.13 – Cell 2 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_013.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.13 – Cell 2 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: '*Cell 3* reads the data available from the data engineering team, and *Cell
    4* is again providing the information on the missing data from multiple columns.
    In this notebook, you will use this information to drop the columns that you do
    not find useful. The following screen captures partial output, and it is expected
    that you run this code in your environment to get the full picture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.14 – Cell 3 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_014.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.14 – Cell 3 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: '*Cell 5* is dropping two sets of columns. The first set drops the columns for
    which you do not have data in most of the rows. You selected these columns based
    on the previous step. We kept it simple here and dropped the columns; however,
    it is highly recommended that you work with data teams to find the reason for
    this anomaly and aim to get as much data as possible. The columns you are dropping
    are `"cancellation_reason"`, `"late_aircraft_delay"`, `"weather_delay"`, `"airline_delay"`,
    `"security_delay"`, and `"air_system_delay"`, and are shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.15 – Cell 5 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_015.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.15 – Cell 5 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'The second `drop` statement is dropping the `tail_number` column. This column
    may not play any role in flights getting delayed. In a real-world scenario, you
    will need to discuss this with the SMEs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.16 – Cell 5 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_016.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.16 – Cell 5 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: '*Cell 6* is dropping rows for which the data is not available using the Dataframe''s
    `dropna` function. Recall, from *Step 3*, that the number of rows where data is
    missing from these columns is less compared to the total rows available. `air_time`,
    `arrival_delay`, and `elapsed_time` are examples of such columns from *Step 5*.
    We have adopted this approach to keep things simple; a better way would be to
    find a way to get the missing data or to create this data from existing values.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.17 – Cell 6 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_017.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.17 – Cell 6 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: In *Cell 7*, you are dropping columns for which you do not have data for future
    flights. Recall that the model aims to predict the future flight on-time performance.
    However, columns such as `departure_time` and `arrival_time` contain the actual
    departure and arrival times. For predicting future flights, you will not have
    such data available at the time of prediction, and so you need to drop these columns
    while training your model.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.18 – Cell 7 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_018.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.18 – Cell 7 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: In the dataset, the scheduled departure and arrival time is available in HHMM
    format, where HH is hours and MM is minutes. In *Cell 8*, as a data scientist,
    you may choose to split this data into two different columns where one column
    represents the hours and the other one represents the minutes. Doing this may
    simplify the dataset and improve the model performance if some correlation exists
    between the expected classification and split data. You may do it out of your
    intuition, or you may discuss this option with the SMEs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You have chosen to split the `scheduled_departure` and `scheduled_arrival`
    columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.19 – Cell 8 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_019.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.19 – Cell 8 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Cell 9*, you drop a few more columns. The first set contains columns for
    which we have to split the time into hours and minutes, such as `scheduled_arrival`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.20 – Cell 9 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_020.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.20 – Cell 9 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'The second set contains the columns that are represented in other columns.
    For example, the `origin_airport` column has a key for the airport, and the `ORIG_AIRPORT`
    column is a descriptive name. Both these columns represent the same information:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.21 – Cell 9 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_021.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.21 – Cell 9 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Cell 10*, you visually see the dataset again using the `head` statement.
    You have noticed that you have some data in string format, such as the `airline`
    column:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.22 – Cell 10 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_022.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.22 – Cell 10 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'You choose to encode that data to convert it into numbers. There are many techniques
    available, such as `OrdinalEncoder`. This encoder encodes categorical values as
    an integer array. In *Cell 12*, you have applied the category encoding to the
    selected fields such as `airline` and `origin_airport`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.23 – Cell 12 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_023.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.23 – Cell 12 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that the input string data for these fields will be converted into
    integers. This is good for training; however, at inferencing time, the caller
    may not know about this encoding that you have just performed. One way is to save
    this encoder and use it at inferencing time to convert the value from string to
    integers. So, your inferencing pipeline would consist of two steps. The first
    step is to apply the encoding and the second step is to predict the response using
    the saved mode. In the last four lines of *Cell 12*, you have saved the encoder
    and have to register it with MLflow:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.24 – Cell 12 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_024.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.24 – Cell 12 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Cell 13*, you validate the data using the `head` statement. Notice that
    the `airline` column (one of the columns that you have applied the category encoding
    to) has changed. For example, compare the value of the `airline` column from *Cell
    10* and *Cell 13* and notice that the value of `airline` column has been changed
    to `1`. This confirms that the encoding has been applied to the dataset successfully:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.25 – Cell 13 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_025.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.25 – Cell 13 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: In *Cell 14*, you used the `dftype` statement to validate the data types of
    each column in the dataset. Many algorithms need data to be in a numerical format
    and, based on the available models, you may need to move all the fields to a numerical
    format.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In *Cell 15*, you have split your data into training and testing sets. You will
    train the model using the `X_Train` and `y_train` set and use the `X_Test` and
    `y_test` for validation of your model performance. You can perform cross-validation
    to further assess the model performance on unseen data. We assume that you, as
    a data scientist, are aware of such concepts and, therefore, will not provide
    more details on this.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.26 – Cell 15 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_026.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.26 – Cell 15 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Cell 16*, you visualize the data distribution of the dataset. The following
    screenshot captures partial output, and it is expected that you run this code
    in your environment to get the full picture:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.27 – Cell 16 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_027.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.27 – Cell 16 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: You can see from the preceding chart that the data is biased towards the on-time
    flights. This may impact the performance of the model. Luckily, the `RandomForestClassifier`
    object of the `SciKit` library provides a `class_weight` parameter. It can take
    a Python `dictionary` object where we can provide the desired weights for respective
    labels. One such example would be to allocate less weight for a value of `0` in
    the `DELAYED` column, which represents the on-time flight. A different value for
    `class_weight` could be `balanced`, which will direct the algorithm to weigh the
    labels as per the inverse proportion to their occurrence frequency. Simply, for
    our case, the `balanced` value will put more weight on the value of `1` as compared
    to the value of `0` in the `DELAYED` column.
  prefs: []
  type: TYPE_NORMAL
- en: In *Cell 19*, you define a random forest classification model and in *Cell 20*,
    you train the model. You have noticed that we have defined very minimal hyperparameters
    and then used `GridSearchCV` to find the best estimator for the given dataset.
    We have placed a separate set of hyperparameters in the comments of this cell.
    You are encouraged to try different combinations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.28 – Cell 19 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_028.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.28 – Cell 19 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10.29* shows how the model training is performed by executing the `model.fit()`
    function:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.29 – Cell 20 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_029.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.29 – Cell 20 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: The training will take some time to complete, so for *Cell 20*, where you are
    training your model, be patient.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Cell 21*, you have used the `predict` method to capture the model prediction
    for the test data. Note that the `rf_best_model` model is the output of the `GridSearchCV`
    object:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.30 – Cell 21 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_030.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.30 – Cell 21 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Cell 22*, you have used the `confusion_matrix` function to calculate the
    matrix and validate the performance of your model:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.31 – Cell 22 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_031.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.31 – Cell 22 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: 'In *Cell 23*, you have used the `precision_score` function to calculate `recallscore`
    for your model on the test dataset. You can see that you have achieved 72% precision,
    which is good for the first experiment run. You can run more experiments and improve
    the metrics for your model using the platform:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.32 – Cell 23 for the chapter10/experiments notebook'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_032.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.32 – Cell 23 for the chapter10/experiments notebook
  prefs: []
  type: TYPE_NORMAL
- en: You have completed one experiment run with multiple parameters and the `RandomForestClassifier`
    model. At this stage, you may want to check MLflow and see all the runs the grid
    search has performed, captured parameters, and model performance data.
  prefs: []
  type: TYPE_NORMAL
- en: Typically, data scientists try multiple algorithms to find the right fit for
    the given problem. It is up to you to execute and enhance the code and use MLflow
    to compare different algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Let's see what MLflow has recorded for us.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking model experiments and versioning using MLflow
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will use MLflow to track your experiment and version your
    model. This small section is a review of the capabilities highlighted to you in
    [*Chapter 6*](B18332_06_ePub.xhtml#_idTextAnchor086), *Machine Learning Engineering*,
    where we discussed MLflow in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Tracking model experiments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you will see the data recorded by MLflow for your experiment.
    Note that you have just registered the MLflow and called the `autolog` function,
    and MLflow automatically records all your data. This is a powerful capability
    in your platform through which you can compare multiple runs and share your findings
    with your team members.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps shows you how experiment tracking is performed in MLflow:'
  prefs: []
  type: TYPE_NORMAL
- en: Log in to the MLflow UI of the platform.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'On the left-hand side, you will see the **Experiments** section and it contains
    your experiment named **FlightsDelay-mluser**. Click on it and you will see the
    following screen. The right-hand side shows all the runs. Recall that we have
    used GridSearchCV so there will be multiple runs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.33 – The model tracking details in MLflow'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_033.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.33 – The model tracking details in MLflow
  prefs: []
  type: TYPE_NORMAL
- en: Click on the `autolog` feature and MLflow will capture the bulk of the metrics
    automatically. Select all four runs and hit the **Compare** button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Figure 10.34* shows the comparison of each run and the hyperparameters associated
    with the run:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.34 – Comparing models in MLflow'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_034.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.34 – Comparing models in MLflow
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the run next to the `FlightsDelayOrdinalEncoder.pkl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.35 – Files and data captured by MLflow'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_035.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.35 – Files and data captured by MLflow
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you have seen that MLflow captured all the metrics from your
    training run and assisted you in selecting the right model by providing a comparison
    function.
  prefs: []
  type: TYPE_NORMAL
- en: The next stage is to version your model.
  prefs: []
  type: TYPE_NORMAL
- en: Versioning models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After giving some thought to the model performance and sharing the data with
    other team members, you have selected the model that can be used for this project.
    In this section, you will version your model to be used. Refer to [*Chapter 6*](B18332_06_ePub.xhtml#_idTextAnchor086),
    *Machine Learning Engineering*, where we discussed model versioning in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps will guide you on how to version your model:'
  prefs: []
  type: TYPE_NORMAL
- en: Go to MLflow and click on the **FlightDelay-mluser** experiment on the left-hand
    side.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Then, on the right-hand side of the screen, click on the **+** icon for your
    run. You will see the following screen:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.36 – Files and data captured by MLflow'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_036.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.36 – Files and data captured by MLflow
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **model** folder under artifacts and a blue button with the **Register
    Model** label will appear:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.37 – Versioning your models in MLflow'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_037.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.37 – Versioning your models in MLflow
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the `flights-ontime`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.38 – Model registration in MLflow'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_038.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.38 – Model registration in MLflow
  prefs: []
  type: TYPE_NORMAL
- en: As a data scientist, you have registered your model for predicting flight delays
    onto the model registry. The next step is to deploy your model.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the model as a service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, you will deploy your model as a REST service. You will see
    that using the details mentioned in [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098),
    *Model Deployment and Automation*, the team can package and deploy the model as
    a service. This service will then be consumed by users of your model. We highly
    encourage you to refresh your knowledge from [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098),
    *Model Deployment and Automation* before proceeding to this section.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098), *Model Deployment and
    Automation*, you have deployed the model with a `Predictor` class, which exposes
    the model as a REST service. You will use the same class here, however, in the
    flight project, you applied categorical encoding to the data before it was used
    for model training. This means that you will need to apply the same encoding to
    the input data at the inferencing time. Recall that, earlier in this chapter,
    you saved the file as `FlightsDelayOrdinalEncoder.pkl` and it is available in
    the MLflow repository.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to write a simple class that can apply the transformation to
    the input data. Once this class is defined, you will define your inference pipeline
    using Seldon and then package your model as a container. So, your inference pipeline
    will consist of two stages; the first stage is to apply the encoding and the second
    stage is to use the model to predict the class.
  prefs: []
  type: TYPE_NORMAL
- en: Sounds difficult? You will see that the platform abstracts most of the details,
    and you will provide a few configuration parameters to package and deploy your
    model as a service.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s first see the `Transformer` class, which will load the `FlightsDelayOrdinalEncoder.pkl`
    file and apply the encoding to the input data. Open the `chapter10/model_deploy_pipeline/model_build_push/Transformer.py`
    file. You will see that the `__init__` function loads the encoder file and the
    `transform_input` function applies the transformation to the input data using
    the standard `transform` function. This is the same function you have used during
    the model training. *Figure 10.39* shows the code file:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.39 – Transformer class'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_039.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.39 – Transformer class
  prefs: []
  type: TYPE_NORMAL
- en: The second artifact is to define the model inference graph. Recall from [*Chapter
    7*](B18332_07_ePub.xhtml#_idTextAnchor098), *Model Deployment and Automation*,
    that you have defined a container and one stage in your inference graph using
    the `SeldonDeploy.yaml` file. In this section, you will extend the inference graph
    to cater to the transformation and the prediction part of the inference pipeline.
    Naturally, when you define a new component in your graph, you will also need to
    define the corresponding container that will be the service for the graph node.
  prefs: []
  type: TYPE_NORMAL
- en: Note that you may choose to execute the transformation logic in `Predict.py`
    to keep things simple. However, we wanted to show how Seldon can build complicated
    graphs and each graph could be a separate instance of a container. This approach
    brings versatility to running your production models in an elastic fashion.
  prefs: []
  type: TYPE_NORMAL
- en: So, let's look into the `chapter10/model_deploy_pipeline/model_deploy/SeldonDeploy.yaml`
    file. This file has been copied from [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098),
    *Model Deployment and Automation*, and the following changes have been made to
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The first change is to build the inference graph. You need to apply the transformation
    first and then run the model prediction. *Figure 10.40* displays this graph. Note
    that the root element for the graph is of the `TRANSFORMER` type with the name
    `transformer`, and there is a `children` node in the graph. The `children` node
    will be executed after the root node. This setup allows you to have different
    graphs as per your model requirements. The child node in this example is the actual
    prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.40 – Seldon deployment YAML'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_040.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.40 – Seldon deployment YAML
  prefs: []
  type: TYPE_NORMAL
- en: The second change to the `chapter10/model_deploy_pipeline/model_deploy/SeldonDeploy.yaml`
    file is registering the containers for both the root and the child node. The `name`
    field in the graph is the one that associates the container to the graph node.
    So, we will have two instances of a container, one for `transformer` and the second
    for `predictor`. The `transformer` instance will execute the `Transformer.py`
    file and the `predictor` instance will execute the `Predictor.py` file. What we
    have done is create a single container image with all these files, so our container
    image is the same. You can examine the `chapter10/model_deploy_pipeline/model_build_push/Dockerfile.py`
    file where you package all the files into a container image. *Figure 10.41* highlights
    the part of `SeldonDeploy.yaml` where the containers have been configured.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the first container is with the name `transformer`. The `MODEL_NAME`
    variable mentions the name of the Python file and the `SERVICE_TYPE` variable
    mentions the type of callback to call by Seldon. Recall that `Transformer.py`
    has a `transform_input` method, and `SERVICE_TYPE` guides the Seldon system to
    call the right function. The same is applied to the `predictor` container instance,
    and note how `MODEL_NAME` and `SERVICE_TYPE` are different for the `predictor`
    instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.41 – Seldon deployment YAML'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_041.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.41 – Seldon deployment YAML
  prefs: []
  type: TYPE_NORMAL
- en: That is it! For some of you, this may be a little overwhelming, but once you
    have defined the structure for your projects, these files can be standardized,
    and the data scientists will not need to change them for every project. You have
    seen how the ML platform allows you to be self-sufficient in not only building
    the models but also packaging them.
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to write a simple Airflow pipeline to deploy your model. Before
    you start this section, we recommend refreshing your knowledge of deploying the
    models using Airflow as detailed in [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098),
    *Model Deployment and Automation*. There is no change required in the pipeline
    that you have built, and you will just be changing a few configuration parameters
    to provide the right model name and version to the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: We have prebuilt this pipeline for you, so, open the `chapter10/model_deploy_pipeline/flights_model.pipeline`
    file. Open this file and validate that it has the same two stages as mentioned
    in [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098)*, Model Deployment and
    Automation*. The first stage builds and pushes the container image to a container
    registry and the second stage deploys the model using Seldon.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10.42* displays the first stage with the parameters used for building
    and pushing the container image. **Runtime Image** and **File Dependencies** have
    the same values as shown earlier. Notice the **Environment Variables** section,
    where you have the same variable names but different values:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.42 – Flights model deploy pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_042.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.42 – Flights model deploy pipeline
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see each of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '`MODEL_NAME` has a value of `flights-ontime`. This is the name of the model
    you were given when you registered the model with MLflow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MODEL_VERSION` has a value of `1`. This is the version of the model you would
    like to deploy. This version is recorded in the MLflow system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CONTAINER_DETAILS` has a value of `flights-ontime`. This is the name of the
    model you were given when you registered the model with MLflow.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CONTAINER_REGISTRY` is the container registry API endpoint. For DockerHub,
    this is at [https://index.docker.io/v1](https://index.docker.io/v1). Set the value
    of this variable to [https://index.docker.io/v1/](https://index.docker.io/v1/).
    In this example, we have used [quay.io](http://quay.io) as the registry. This
    is another free registry that you can use.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CONTAINER_REGISTRY_USER` is the username of the user that will push images
    to the image registry. Set this to your DockerHub username or Quay username.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CONTAINER_REGISTRY_PASSWORD` is the password of your container registry user.
    In production, you do not want to do this. You may use secret management tools
    to serve your password.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CONTAINER_DETAILS` is also the name of the repository to where the image will
    be pushed and the image name and image tag. *Figure 10.43* displays the second
    stage with the parameters used for deploying the container image using Seldon.
    `MODEL_NAME`, `MODEL_VERSION`, `CONTAINER_DETAILS`, and `CLUSTER_DOMAIN`. You
    have seen all the variables in the preceding paragraph, but `CLUSTER_DOMAIN` is
    the DNS name of your Kubernetes cluster. In this case, the IP address of minikube
    is `<Minikube IP>.nip.io`.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.43 – Flights model deploy pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_043.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.43 – Flights model deploy pipeline
  prefs: []
  type: TYPE_NORMAL
- en: Save and deploy this DAG to your Airflow environment and the model will be available
    for consumption when the Airflow DAG has finished execution. Validate that this
    DAG has been executed correctly by logging into Airflow and checking the status
    of the DAG. *Figure 10.44* shows the Airflow UI where you have validated the DAG's
    status. Notice that we have saved the DAG under the name `flights-model-deploy`;
    if you have chosen some other name, your DAG name will reflect accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.44 – Airflow DAG for the flights pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_044.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.44 – Airflow DAG for the flights pipeline
  prefs: []
  type: TYPE_NORMAL
- en: Recall that MLflow associates a run ID for each of the experiments. You register
    one of these experiments in the model registry so it can be deployed. Refer to
    *Figure 10.34*, which shows a screenshot of the run ID for this model.
  prefs: []
  type: TYPE_NORMAL
- en: 'This model run will be associated with the deployed model, so your team can
    track the models running in the environment to an individual run. This capability
    provides a trace back on what version of the model is running in different environments.
    Run the following command to see the resources created by the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You should get the following response. As you can see, the Kubernetes service
    and ingress have a run ID that starts with `bf32` for this example. Note that
    it will have a different value for your case, and you will need to adjust the
    run ID in the preceding command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.45 – Kubernetes objects created by the platform'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_045.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.45 – Kubernetes objects created by the platform
  prefs: []
  type: TYPE_NORMAL
- en: Now, the model is deployed; you now test the model by running a RESTful call
    to your model.
  prefs: []
  type: TYPE_NORMAL
- en: Calling your model
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Recall that the model is exposed via the Kubernetes Ingress, which is created
    by automation. In order to test whether the model is running properly as a RESTful
    API, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the following command to get the `ingress` object. Note that the name of
    the `ingress` object will be different for your setup:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, make an HTTP call to the location where your model is available for inference.
    Run the following commands. The `chapter10/inference` folder contains a payload
    for the flight data and in return, the model will predict the probability of the
    flight getting delayed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'First, change the directory to the `chapter10/inference` folder:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, run a `curl` command to send the payload to the model. Note to change
    the HTTP address as per your setup:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Windows users may choose to use the excellent Postman application ([https://www.postman.com/](https://www.postman.com/))
    to make an HTTP call.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the `chapter10/inference/data.json` file to see the payload that we are
    sending to the model. You will notice that there are two sections of the `json`
    payload. The first part is with the `names` key, which captures the feature columns
    that you have used to train the model. Notice that there is no `DELAYED` column
    here because the model will predict the probability of the `DELAYED` column. The
    second part is with the `ndarrray` key, which has the values for the feature columns.
    Note that the values for the categorical columns are in the original form and
    the inference pipeline will convert them into the categorical values before executing
    the model. *Figure 10.46* shows the following file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.46 – Sample payload for flights model inferencing'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_046.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.46 – Sample payload for flights model inferencing
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have successfully performed an inference call over HTTP, let's
    see how the information has been captured by the monitoring system.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring your model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this last section, you will see how the platform automatically starts capturing
    the typical performance metrics of your model. The platform also helps you visualize
    the performance of the inference. The platform uses Seldon to package the model,
    and Seldon exposes default metrics to be captured. Seldon also allows you to write
    custom metrics for specific models; however, it is out of the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start by understanding how the metrics capture and visualization work.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding monitoring components
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The way metrics capture works is that your model is wrapped by Seldon. Seldon
    then exposes the metrics to a well-defined URL endpoint, which was detailed in
    [*Chapter 7*](B18332_07_ePub.xhtml#_idTextAnchor098), *Model Deployment and Automation*.
    Prometheus harvests this information and stores it in its database. The platform's
    Grafana connects to Prometheus and helps you visualize the recorded metrics.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 10.47* summarizes the relationship between the model and monitoring
    components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.47 – ML platform monitoring components'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_047.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.47 – ML platform monitoring components
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s understand each component of this diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Open Data Hub (ODH) Operator**: This is the base operator for our platform.
    Its role is to provision all the different components for your platform. We have
    discussed this operator in various chapters of this book and so we do not describe
    it in this section.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`manifests/prometheus/base/subscription.yaml`. The following snippet shows
    that it uses the OLM mechanism to install the Prometheus operator:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.48 – Subscription for Prometheus operator'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_048.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.48 – Subscription for Prometheus operator
  prefs: []
  type: TYPE_NORMAL
- en: '`manifests/prometheus/base/prometheus.yaml`. The following snippet shows the
    file:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.49 – Prometheus server configuration'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_049.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.49 – Prometheus server configuration
  prefs: []
  type: TYPE_NORMAL
- en: '`manifests/prometheus/base/prometheus.yaml`. The following snippet shows the
    file. Note that the configuration uses port `8000`, which is the port at which
    Seldon exposes the metrics information. The `selector` object defines the filter
    by which Prometheus will decide what pods to scrape data from:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 10.50 – Prometheus server monitors for Seldon pods'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_050.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.50 – Prometheus server monitors for Seldon pods
  prefs: []
  type: TYPE_NORMAL
- en: '`manifests/grafana/base/deployment.yaml` file.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, you have seen how the platform provides and wires different
    components to provide you with a visualization framework for your observability
    requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Next is to configure Grafana.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Grafana and a dashboard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you will configure Grafana to connect to Prometheus and build
    a dashboard to visualize the model's metrics. What is a dashboard? It is a set
    of graphs, tables, and other visualizations of your model. You will create a dashboard
    for the flight model.
  prefs: []
  type: TYPE_NORMAL
- en: Note that this is a one-time configuration, and it does not need to be repeated
    for every model. This means that once you have a dashboard, you can use it for
    multiple models. Your team may create a few standard dashboards and as soon as
    a new model is deployed, the platform will automatically find it and make it available
    for monitoring.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s start with the configuration of the Grafana instance:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in to Grafana using https://grafna.192.128.36.219.nip.io. Notice that you
    will need to change the IP address as per your setup. On the login page, click
    the **Sign in With KeyCloak** button, which is at the bottom of the login window:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.51 – Grafana login page'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_051.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.51 – Grafana login page
  prefs: []
  type: TYPE_NORMAL
- en: 'First, you will need to add a data source. A data source is a system that will
    provide the data that Grafana will help you visualize. The data provider in Prometheus
    scrapes the metrics data from your models. Select the **Configuration** | **Data
    sources** option from the left-hand menu:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.52 – Grafana Data sources menu option'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_052.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.52 – Grafana Data sources menu option
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the **Add data source** button, as shown in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.53 – Add new Grafana data source'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_053.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.53 – Add new Grafana data source
  prefs: []
  type: TYPE_NORMAL
- en: Select the data source type, which will be Prometheus for your case. You may
    notice that Grafana can talk to a variety of data sources, including InfluxDB
    and YYYY, to name a couple.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.54 – Add new Prometheus Grafana data source'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_054.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.54 – Add new Prometheus Grafana data source
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you need to add the details for the Prometheus server. Grafana will use
    these details to connect and fetch data from the Prometheus server. Add the following
    properties in the screen mentioned:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Prometheus`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**URL**: http://prometheus-operated:9090'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Then click the **Save & test** button. The URL is the location of the Prometheus
    service created by the platform. Because the Grafana pod will talk to the Prometheus
    pod using the internal Kubernetes network, this URL will be the same for your
    setup too:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.55 – Configuration for the Prometheus Grafana data source'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_055.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.55 – Configuration for the Prometheus Grafana data source
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find the `prometheus` service details by issuing the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'After you configure Grafana to connect to Prometheus, the next step is to build
    the dashboard. As mentioned earlier, a dashboard is a set of visualizations, and
    each visualization is backed by a query. Grafana runs those queries and plots
    the data for you. Building dashboards is out of the scope of this book, but we
    have provided a dashboard that you can use. Select the **Import** option from
    the left-hand menu:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.56 – Adding a new dashboard in Grafana'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_056.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.56 – Adding a new dashboard in Grafana
  prefs: []
  type: TYPE_NORMAL
- en: 'On the `chapter10/grafana-dashboard/sample-seldon-dashboard.json` file and
    paste it into the **Import via panel json** textbox. Click on the **Load** button
    to import the dashboard:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.57 – Importing a Seldon dashboard in Grafana'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_057.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.57 – Importing a Seldon dashboard in Grafana
  prefs: []
  type: TYPE_NORMAL
- en: 'Set the name for your imported dashboard and click on the `Flights Prediction
    Analytics`, as you can see in the following screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.58 – Importing Seldon dashboard in Grafana'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_058.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.58 – Importing Seldon dashboard in Grafana
  prefs: []
  type: TYPE_NORMAL
- en: After you import the dashboard, Grafana will start displaying the dashboard
    immediately. You can see a few metrics such as response times, success rate, and
    other relative metrics for your deployed model. You may need to hit your model
    a few times to start populating this board. Refer to the *Calling your model*
    section earlier in this chapter on how to make calls to your deployed models.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.59 – Dashboard for Seldon models'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_10_059.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 10.59 – Dashboard for Seldon models
  prefs: []
  type: TYPE_NORMAL
- en: You can see that the board captures the metrics that have been emitted by your
    model wrapped in Seldon. As more models get deployed, they will be available in
    this dashboard, and you can filter the models through the filters provided in
    the top bar of the dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Your flights on-time prediction service is now available for consumption. You
    will now work with the product development team and the website team of your organization
    so that they can integrate this functionality and provide a better service for
    your customers. Your work does not finish here; you will need to continuously
    see how the model is performing and bring on improvements via new data and/or
    optimizing your models further. The platform will help you to perform this cycle
    with higher velocity and continuously improve the offerings to your customers.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This was another long chapter that covered the model development and deployment
    life cycle for the flights on-time performance project. You have seen how the
    platform enables you and your team to become autonomous in EDA, model experimentation
    and tracking, model registry, and model deployment.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a step back and summarize our journey of the
    overall platform and how you can use it as your own solution that fits your vertical.
    You can use the concepts and tools to build a platform for your team and enable
    your business to realize the power of AI.
  prefs: []
  type: TYPE_NORMAL
