<html><head></head><body>
  <div class="Basic-Text-Frame" id="_idContainer115">
    <h1 class="chapterNumber">5</h1>
    <h1 class="chapterTitle" id="_idParaDest-188">Using Multi-Container Pods and Design Patterns</h1>
    <p class="normal">Running complex applications on Kubernetes will require that you run not one but several containers in the same Pods. The strength of Kubernetes also lies in its ability to create Pods made up of several containers. We will focus on those Pods in this chapter by studying the different aspects of hosting several containers in the same Pod, as well as having these different containers communicate with each other.</p>
    <p class="normal">So far, we’ve only created Pods running a single container: those were the simplest forms of Pods, and you’ll use these Pods to manage the simplest of applications. We also discovered how to update and delete them by running simple <strong class="keyWord">create</strong>, <strong class="keyWord">read</strong>, <strong class="keyWord">update, and delete</strong> (<strong class="keyWord">CRUD</strong>) operations against those Pods using the <code class="inlineCode">kubectl</code> command-line tool.</p>
    <p class="normal">Besides mastering the basics of<a id="_idIndexMarker436"/> CRUD operations, you have also learned how to access a running Pod inside a Kubernetes cluster.</p>
    <p class="normal">While single-container Pods are more common, there are situations where using multiple containers in a single Pod is beneficial. For example, using a dedicated container to handle log gathering with the main container inside a Pod or another dedicated container to enable proxy communication between services. In this chapter, we will push all of this one step forward and discover how to manage Pods when they are meant to launch not one but several containers. The good news is that everything you learned previously will also be valid for multi-container Pods. Things won’t differ much in terms of raw Pod management because updating and deleting Pods is not different, no matter how many containers the Pod contains.</p>
    <p class="normal">Besides those basic operations, we are also going to cover how to access a specific container inside a multi-container Pod and how to access its logs. When a given Pod contains more than one container, you’ll have to run some specific commands with specific arguments to access it, and that’s something we are going to cover in this chapter.</p>
    <p class="normal">We will also discover some important design patterns such as Ambassador, Sidecar, and Adapter containers. You’ll need to learn these architectures to effectively manage multi-container Pods. You’ll also learn how to deal with volumes from Kubernetes. Docker also provides volumes, but in Kubernetes, they are used to share data between containers launched by the same Pod, and this is going to be an important part of this chapter. After this chapter, you’re going to be able to launch complex applications inside Kubernetes Pods.</p>
    <p class="normal">In this chapter, we’re going to cover the following main topics:</p>
    <ul>
      <li class="bulletList">Understanding what multi-container Pods are</li>
      <li class="bulletList">Sharing volumes between containers in the same Pod</li>
      <li class="bulletList">The Ambassador Design Pattern</li>
      <li class="bulletList">The Sidecar Design Pattern</li>
      <li class="bulletList">The Adapter Design Pattern</li>
      <li class="bulletList">Sidecars versus Kubernetes Native Sidecars</li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-189">Technical requirements</h1>
    <p class="normal">You will require the following prerequisites for this chapter:</p>
    <ul>
      <li class="bulletList">A working <code class="inlineCode">kubectl</code> command-line utility.</li>
      <li class="bulletList">A local or cloud-based Kubernetes cluster to practice with.</li>
    </ul>
    <p class="normal">You can download the latest code samples for this chapter from the official GitHub repository: <a href="https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter05"><span class="url">https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter05</span></a>.</p>
    <h1 class="heading-1" id="_idParaDest-190">Understanding what multi-container Pods are</h1>
    <p class="normal">Multi-container Pods <a id="_idIndexMarker437"/>are a way to package tightly coupled applications together in Kubernetes. This allows multiple containers to share resources and easily communicate with each other, which is ideal for scenarios like sidecars and service mesh. In this section, we’ll learn about the core concepts of Pods for managing multiple containers at once by discussing some concrete examples of multi-container Pods.</p>
    <h2 class="heading-2" id="_idParaDest-191">Concrete scenarios where you need multi-container Pods</h2>
    <p class="normal">You should<a id="_idIndexMarker438"/> group your containers into a Pod when they need to be tightly linked. More broadly, a Pod must correspond to an application or a process running in your Kubernetes cluster. If your application requires multiple containers to function properly, then those containers should be launched and managed through a single Pod.</p>
    <p class="normal">When the containers are supposed to work together, you should group them into a single Pod. Keep in mind that a Pod cannot span across multiple compute nodes. So, if you create a Pod containing several containers, then all these containers will be created on the same compute node. To understand where and when to use multi-container Pods, take the example of two simple applications:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">A log forwarder</strong>: In this example, imagine that you have deployed a web server such as NGINX that stores its logs in a dedicated directory. You might want to collect and forward these logs. For that, you could deploy something like a Splunk forwarder as a container within the same Pod as your NGINX server. </li>
    </ul>
    <p class="normal-one">These log forwarding tools are used to forward logs from a source to a destination location, and it is very common to deploy agents such as Splunk, Fluentd, or Filebeat to grab logs from a container and forward them to a central location such as an Elasticsearch cluster. In the Kubernetes world, this is generally achieved by running a multi-container Pod with one container dedicated to running the application, and another one dedicated to grabbing the logs and sending them elsewhere. Having these two containers managed by the same Pod would ensure that they are launched on the same node as the log forwarder and at the same time.</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">A proxy server</strong>: Imagine an NGINX reverse proxy container in the same Pod as your main application, efficiently handling traffic routing and security with custom rules. This concept extends to <strong class="keyWord">service mesh</strong>, where a dedicated proxy like Envoy can be deployed alongside your application container, enabling features like load balancing and service discovery within a microservices architecture. (We will learn about service mesh in detail in <em class="chapterRef">Chapter 8</em>, <em class="italic">Exposing Your Pods with Services</em>.) By bundling the two containers in the same Pod, you’ll get two Pods running in the same node. You could also run a third container in the same Pod to forward the logs that are emitted by the two others to a central logging location! This is because Kubernetes has no limit on the number of containers you can have in the same Pod, as long as you have enough computing resources to run them all.</li>
    </ul>
    <figure class="mediaobject"><img alt="" src="image/B22019_05_01.png"/></figure>
    <p class="packt_figref">Figure 5.1: Sample multi-container Pod scenario</p>
    <p class="normal">In general, every<a id="_idIndexMarker439"/> time several of your containers work together and are tightly coupled, you should have them in a multi-container Pod.</p>
    <p class="normal">Now, let’s discover how to create multi-container Pods.</p>
    <h2 class="heading-2" id="_idParaDest-192">Creating a Pod made up of two containers</h2>
    <p class="normal">In the<a id="_idIndexMarker440"/> previous chapter, we discovered two syntaxes for manipulating Kubernetes:</p>
    <ul>
      <li class="bulletList">The imperative syntax</li>
      <li class="bulletList">The declarative syntax</li>
    </ul>
    <p class="normal">Most of the Kubernetes objects we are going to discover in this book can be created or updated using these two methods, but unfortunately, this is not the case for multi-container Pods.</p>
    <p class="normal">When you need<a id="_idIndexMarker441"/> to create a Pod containing multiple containers, you will need to go through the declarative syntax. This means that you will have to create a YAML file containing the declaration of your Pods and all the containers it will manage, and then apply it through <code class="inlineCode">kubectl apply -f file.yaml</code>.</p>
    <p class="normal">Consider the following YAML manifest file stored in <code class="inlineCode">~/multi-container-pod.yaml</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># multi-container-pod.yaml</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">multi-container-pod</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">restartPolicy:</span> <span class="hljs-string">Never</span>
  <span class="hljs-attr">containers:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:latest</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">debian-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">debian</span>
      <span class="hljs-attr">command:</span> [<span class="hljs-string">"/bin/sh"</span>]
      <span class="hljs-attr">args:</span> [<span class="hljs-string">"-c"</span>, <span class="hljs-string">"while true; do date;echo debian-container; sleep 5 ; done"</span>]
</code></pre>
    <p class="normal">This YAML manifest will create a Kubernetes Pod made up of two containers: one based on the <code class="inlineCode">nginx:latest</code> image and the other one based on the <code class="inlineCode">debian</code> image.</p>
    <p class="normal">To create it, use the following command:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f multi-container-pod.yaml
pod/multi-container-pod created
</code></pre>
    <p class="normal">This will result in the Pod being created. The kubelet on the elected node will have the container runtime (e.g., containerd, CRI-O, or Docker daemon) to pull both images and instantiate two containers.</p>
    <p class="normal">To check whether the Pod was correctly created, we can run <code class="inlineCode">kubectl get pods</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get pods
NAME                  READY   STATUS    RESTARTS   AGE
multi-container-pod   2/2     Running   0          2m7s
</code></pre>
    <p class="normal">Do you remember the role of <code class="inlineCode">kubelet</code> from <em class="chapterRef">Chapter 2</em>,<em class="italic"> Kubernetes Architecture – from Container Images to Running Pods</em>? This component runs on each node that is part of your Kubernetes cluster and is responsible for converting Pod manifests received from <code class="inlineCode">kube-apiserver</code> into actual containers.</p>
    <div class="note">
      <p class="normal">All the containers that are declared in the same Pod will be scheduled, or launched, on the same node and Pods cannot span multiple machines.</p>
      <p class="normal">Containers in the same Pod are meant to live together. If you terminate a Pod, all its containers will be killed together, and when you create a Pod, the kubelet will, at the very least, attempt to create all its containers together.</p>
      <p class="normal">High availability is generally achieved by replicating multiple Pods over multiple nodes, which you will learn about later in this book.</p>
    </div>
    <p class="normal">From a<a id="_idIndexMarker442"/> Kubernetes perspective, applying this file results in a fully working multi-container Pod made up of two containers, and we can make sure that the Pod is running with the two containers by running a standard <code class="inlineCode">kubectl get pods</code> command to fetch the Pod list from <code class="inlineCode">kube-apiserver</code>.</p>
    <p class="normal">Do you see the column that states <code class="inlineCode">2/2</code> in the previous <code class="inlineCode">kubectl</code> command output? This is the number of containers inside the Pod. Here, this is saying that the two containers that are part of this Pod were successfully launched! We can see the logs from different containers as follows.</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl logs multi-container-pod -c debian-container
Mon Jan  8 01:33:23 UTC 2024
debian-container
Mon Jan  8 01:33:28 UTC 2024
debian-container
...&lt;removed for brevity&gt;...
<span class="hljs-con-meta">$ </span>kubectl logs multi-container-pod -c nginx-container
/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
...&lt;removed for brevity&gt;...
2024/01/08 01:33:20 [notice] 1#1: start worker process 39
2024/01/08 01:33:20 [notice] 1#1: start worker process 40
</code></pre>
    <p class="normal">We learned how to create and manage multi-container Pods, and in the next section, we will learn how to troubleshoot when a multi-container Pod fails.</p>
    <h2 class="heading-2" id="_idParaDest-193">What happens when Kubernetes fails to launch one container in a Pod?</h2>
    <p class="normal">Kubernetes<a id="_idIndexMarker443"/> keeps track of all the containers that are launched in the same Pod. But it often happens that a specific container cannot be launched. Let’s introduce a typo in the YAML manifest to demonstrate how Kubernetes reacts when some containers of a specific Pod cannot be launched.</p>
    <p class="normal">In the following example, we have defined a container image that does not exist at all for the NGINX container; note the <code class="inlineCode">nginx:i-do-not-exist</code> tag:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># failed-multi-container-pod.yaml</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">multi-container-pod</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">restartPolicy:</span> <span class="hljs-string">Never</span>
  <span class="hljs-attr">containers:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:i-do-not-exist</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">debian-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">debian</span>
      <span class="hljs-attr">command:</span> [<span class="hljs-string">"/bin/sh"</span>]
      <span class="hljs-attr">args:</span> [<span class="hljs-string">"-c"</span>, <span class="hljs-string">"while true; do date;echo debian-container; sleep 5 ; done"</span>]
</code></pre>
    <p class="normal">Now, we can apply the following container using the <code class="inlineCode">kubectl apply -f failed-multi-container-pod.yaml</code> command:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f failed-multi-container-pod.yaml
pod/failed-multi-container-pod created
</code></pre>
    <p class="normal">Here, you can see that the Pod was effectively created. This is because even if there’s a non-existent image, the YAML remains valid from a Kubernetes perspective. So, Kubernetes simply creates the Pod and persists the entry into <code class="inlineCode">etcd</code>, but we can easily imagine that the kubelet will encounter an error when it launches the container to retrieve the image from the container registry (e.g., Docker Hub).</p>
    <p class="normal">Let’s check the status of the Pod using <code class="inlineCode">kubectl get pod</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get pod
NAME                         READY   STATUS             RESTARTS   AGE
failed-multi-container-pod   1/2     ImagePullBackOff   0          93s
</code></pre>
    <p class="normal">As you can see, the <a id="_idIndexMarker444"/>status of the Pod is <code class="inlineCode">ImagePullBackOff</code>. This means that Kubernetes is trying to launch the Pod but failing with an image access issue. To find out why it’s failing, you have to describe the Pod using the <code class="inlineCode">kubectl describe pod failed-multi-container-pod</code> command as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span> kubectl describe pod failed-multi-container-pod
Name:             failed-multi-container-pod
Namespace:        default
...&lt;removed for brevity&gt;...
Events:
  Type     Reason     Age                    From               Message
  ----     ------     ----                   ----               -------
...&lt;removed for brevity&gt;...
  Warning  Failed     5m23s (x3 over 6m13s)  kubelet            Error: ErrImagePull
  Warning  Failed     4m55s (x5 over 6m10s)  kubelet            Error: ImagePullBackOff
  Normal   Pulling    4m42s (x4 over 6m17s)  kubelet            Pulling image "nginx:i-do-not-exist"
  <span class="code-highlight"><strong class="hljs-slc">Warning  Failed     4m37s (x4 over 6m13s)  kubelet            Failed to pull image "nginx:i-do-not-exist": Error response from daemon: manifest for nginx:i-do-not-exist not found: manifest unknown: manifest unknown</strong></span>
  Normal   BackOff    75s (x19 over 6m10s)   kubelet            Back-off pulling image "nginx:i-do-not-exist"
</code></pre>
    <p class="normal">It’s a little bit hard to read, but by following this log, you can see that <code class="inlineCode">debian-container</code> is okay since <code class="inlineCode">kubelet</code> has succeeded in creating it, as shown by the last line of the preceding output. But there’s a problem with the other container; that is, <code class="inlineCode">nginx-container</code>.</p>
    <p class="normal">Here, you can<a id="_idIndexMarker445"/> see that the output error is <code class="inlineCode">ErrImagePull</code> and, as you can guess, it’s saying that the container cannot be launched because the image pull fails to retrieve the <code class="inlineCode">nginx:i-do-not-exist</code> image tag.</p>
    <p class="normal">So, Kubernetes does the following:</p>
    <ol>
      <li class="numberedList" value="1">First, it creates the entry in <code class="inlineCode">etcd</code> if the Pod of the YAML file is valid.</li>
      <li class="numberedList">Then, it simply tries to launch the container.</li>
      <li class="numberedList">If an error is encountered, it will try to launch the failing container again and again.</li>
    </ol>
    <p class="normal">If any other container works properly, it’s fine. However, your Pod will never enter the <code class="inlineCode">Running</code> status because of the failed container. After all, your app certainly needs the failing container to work properly; otherwise, that container should not be there at all!</p>
    <p class="normal">Now, let’s learn how to delete a multi-container Pod.</p>
    <h2 class="heading-2" id="_idParaDest-194">Deleting a multi-container Pod</h2>
    <p class="normal">When<a id="_idIndexMarker446"/> you want to delete a Pod containing multiple containers, you have to go through the <code class="inlineCode">kubectl delete</code> command, just like you would for a single-container Pod.</p>
    <p class="normal">Then, you have two choices:</p>
    <ul>
      <li class="bulletList">You can specify the path to the YAML manifest file that’s used by using the <code class="inlineCode">-f</code> option.</li>
      <li class="bulletList">You can delete the Pod without using its YAML path if you know its name.</li>
    </ul>
    <p class="normal">The first way consists of specifying the path to the YAML manifest file. You can do so using the following command:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl delete -f multi-container-pod.yaml
</code></pre>
    <p class="normal">Otherwise, if you already know the Pod’s name, you can do this as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl delete pods/multi-pod
<span class="hljs-con-meta">$ </span><span class="hljs-con-comment"># or equivalent</span>
<span class="hljs-con-meta">$ </span>kubectl delete pods multi-pod
</code></pre>
    <p class="normal">To figure out the name of the Pods, you can use the <code class="inlineCode">kubectl get</code> commands:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get pod
NAME                         READY   STATUS             RESTARTS   AGE
failed-multi-container-pod   1/2     ImagePullBackOff   0          13m
</code></pre>
    <p class="normal">When we ran them, only <code class="inlineCode">failed-multi-container-pod</code> was created in the cluster, so that’s why you can just see one line in the output.</p>
    <p class="normal">Here is how<a id="_idIndexMarker447"/> you can delete <code class="inlineCode">failed-multi-container-pod</code> imperatively without specifying the YAML file that created it:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl delete -f failed-multi-container-pod.yaml
pod "failed-multi-container-pod" deleted
</code></pre>
    <p class="normal">After a few seconds, the Pod is removed from the Kubernetes cluster, and all its containers are removed from the container daemon and the Kubernetes cluster node.</p>
    <p class="normal">The amount of time that’s spent before the command is issued and the Pod’s name is deleted and released is called the <strong class="keyWord">grace period</strong>. Let’s discover how to deal with it!</p>
    <h2 class="heading-2" id="_idParaDest-195">Understanding the Pod deletion grace period</h2>
    <p class="normal">One<a id="_idIndexMarker448"/> important concept related to deleting Pods is what is called the grace period. Both single-container Pods and multi-container Pods have this grace period, which can be observed when you delete them. This grace period can be ignored by passing the <code class="inlineCode">--grace-period=0 --force</code> option to the <code class="inlineCode">kubectl delete</code> command.</p>
    <p class="normal">During the deletion of a Pod, certain <code class="inlineCode">kubectl</code> commands display its status as <code class="inlineCode">Terminating</code>. Notably, this <code class="inlineCode">Terminating</code> status is not categorized within the standard Pod phases. Pods are allocated a designated grace period for graceful termination, typically set to 30 seconds. To forcefully terminate a Pod, the <code class="inlineCode">--force</code> flag can be employed. When the deletion is forced by setting <code class="inlineCode">--grace-period=0</code> with the <code class="inlineCode">--force</code> flag, the Pod’s name is immediately released and becomes available for another Pod to take it. During an unforced deletion, the grace period is respected, and the Pod’s name is released <a id="_idIndexMarker449"/>after it is effectively deleted.</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl delete pod failed-multi-container-pod --grace-period=0 --force
Warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.
pod "failed-multi-container-pod" force deleted
</code></pre>
    <div class="note">
      <p class="normal">This command should be used carefully if you don’t know what you are doing. Forcefully deleting a Pod shouldn’t be seen as the norm because, as the output states, you cannot be sure that the Pod was effectively deleted. If, for some reason, the Pod cannot be deleted, it might run indefinitely, so do not run this command if you are not sure of what to do.</p>
    </div>
    <p class="normal">Now, let’s discover how to access a specific container that is running inside a multi-container Pod.</p>
    <h2 class="heading-2" id="_idParaDest-196">Accessing a specific container inside a multi-container Pod</h2>
    <p class="normal">When<a id="_idIndexMarker450"/> you have several containers in the same Pod, you can access each of them individually. Here, we will access the NGINX container of our multi-container Pods. Let’s start by recreating it because we deleted it in our previous example:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f multi-container-pod.yaml
pod/multi-container-pod created
</code></pre>
    <p class="normal">To access a running container, you need to use the <code class="inlineCode">kubectl exec</code> command, just like you need to use <code class="inlineCode">docker exec</code> to launch a command in an already created container when using Docker without Kubernetes.</p>
    <p class="normal">This command will ask for two important parameters:</p>
    <ul>
      <li class="bulletList">The Pod that wraps the container you want to target</li>
      <li class="bulletList">The name of the container itself, as entered in the YAML manifest file</li>
    </ul>
    <p class="normal">We already know the name of the Pod because we can easily retrieve it with the <code class="inlineCode">kubectl get</code> command. In our case, the Pod is named <code class="inlineCode">multi-container-pod</code>.</p>
    <p class="normal">However, we don’t have the container’s name because there is no <code class="inlineCode">kubectl get</code> containers command that would allow us to list the running containers. This is why we will have to <a id="_idIndexMarker451"/>use the <code class="inlineCode">kubectl describe pods/multi-container-pod</code> command to find out what is contained in this Pod:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl describe pods/multi-container-pod
</code></pre>
    <p class="normal">This command will show the names of all the containers contained in the targeted Pod. Here, we can see that our Pod is running two containers, one called <code class="inlineCode">debian-container</code> and another called <code class="inlineCode">nginx-container</code>.</p>
    <p class="normal">Additionally, the following is a command for listing all the container names contained in a dedicated Pod:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get pod/multi-container-pod -o jsonpath=<span class="hljs-con-string">"{.spec.containers[*].name}"</span>
nginx-container debian-container
</code></pre>
    <p class="normal">This command will spare you from using the <code class="inlineCode">describe</code> command. However, it makes use of <code class="inlineCode">jsonpath</code>, which is an advanced feature of <code class="inlineCode">kubectl</code>: this command might look strange but it mostly consists of a sort filter that’s applied against the command. The <code class="inlineCode">jsonpath</code> expression <code class="inlineCode">{.spec.containers[*].name}</code> can be used with the <code class="inlineCode">kubectl get pod</code> command to retrieve the names of all containers within a specific Pod. The <code class="inlineCode">.</code> denotes the entire response object, while <code class="inlineCode">spec.containers</code> targets the containers section within the Pod specification. The <code class="inlineCode">[*]</code> operator instructs <code class="inlineCode">jsonpath</code> to iterate through all elements within the containers list, and <code class="inlineCode">.name</code> extracts the <code class="inlineCode">name</code> property from each container object. Essentially, this expression provides a comma-separated list of container names within the specified Pod.</p>
    <p class="normal"><code class="inlineCode">jsonpath</code> filters are not easy to get right, so, feel free to add this command as a bash alias or note it somewhere because it’s a useful one.</p>
    <p class="normal">In any case, we can now see that we have these two containers inside the <code class="inlineCode">multi-container-pod</code> Pod:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">nginx-container</code></li>
      <li class="bulletList"><code class="inlineCode">busybox-container</code></li>
    </ul>
    <p class="normal">Now, let’s access <code class="inlineCode">nginx-container</code>. You have the name of the targeted container in the targeted Pod, so use the following command to access the Pod:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> -it multi-container-pod --container nginx-container -- /bin/bash
root@multi-container-pod:/# hostname
multi-container-pod
root@multi-container-pod:/#
</code></pre>
    <p class="normal">After running<a id="_idIndexMarker452"/> this command, you will find yourself inside <code class="inlineCode">nginx-container</code>. Let’s explain this command a little bit. <code class="inlineCode">kubectl exec</code> does the same as <code class="inlineCode">docker exec</code>:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">kubectl exec</code>: This is the command to execute commands in a Kubernetes container.</li>
      <li class="bulletList"><code class="inlineCode">-it</code>: These are options for the execution. <code class="inlineCode">-t</code> allocates a pseudo-TTY, and <code class="inlineCode">-i</code> allows interaction with the container.</li>
      <li class="bulletList"><code class="inlineCode">multi-container-pod</code>: This is the name of the Pod in which you want to execute the command.</li>
      <li class="bulletList"><code class="inlineCode">--container nginx-container</code>: This specifies the container within the Pod where the command should be executed. In Pods with multiple containers, you need to specify the container you want to interact with.</li>
      <li class="bulletList"><code class="inlineCode">-- /bin/bash</code>: This is the actual command that will be executed in the specified container. It launches a Bash shell (<code class="inlineCode">/bin/bash</code>) in interactive mode, allowing you to interact with the container’s command line.</li>
    </ul>
    <p class="normal">When you run this command, you get the shell of the container, inside the multi-container Pod, at a point at which you will be ready to run commands inside this very specific container on your Kubernetes cluster.</p>
    <p class="normal">The main difference from the single container Pod situation is the <code class="inlineCode">--container</code> option (the <code class="inlineCode">-c</code> short option works, too). You need to pass this option to tell <code class="inlineCode">kubectl</code> what container you want to reach.</p>
    <p class="normal">Now, let’s discover how to run commands in the containers running in your Pods!</p>
    <h2 class="heading-2" id="_idParaDest-197">Running commands in containers</h2>
    <p class="normal">One <a id="_idIndexMarker453"/>powerful aspect of Kubernetes is that you can, at any time, access the containers running on your Pods to execute some commands. We did this previously, but did you know you can also execute any command you want directly from the <code class="inlineCode">kubectl</code> command-line tool?</p>
    <p class="normal">First, we are going to recreate the multi-container Pod:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f multi-container-pod.yaml
pod/multi-container-pod created
</code></pre>
    <p class="normal">To run a command in a container, you need to use <code class="inlineCode">kubectl exec</code>, just like we did previously. But this time, you have to remove the <code class="inlineCode">-ti</code> parameter to prevent <code class="inlineCode">kubectl</code> from attaching to your running terminal session.</p>
    <p class="normal">Here, we are <a id="_idIndexMarker454"/>running the <code class="inlineCode">ls</code> command to list files in <code class="inlineCode">nginx-container</code> from the <code class="inlineCode">multi-container-pod</code> Pod:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> pods/multi-container-pod -c nginx-container -- <span class="hljs-con-built_in">ls</span>
bin
boot
dev
docker-entrypoint.d
docker-entrypoint.sh
...&lt;removed for brevity&gt;
</code></pre>
    <p class="normal">You can omit the container name but if you do so, <code class="inlineCode">kubectl</code> will use the default first one.</p>
    <p class="normal">Next, we will discover how to override the commands that are run by your containers.</p>
    <h2 class="heading-2" id="_idParaDest-198">Overriding the default commands run by the containers</h2>
    <p class="normal">Overriding <a id="_idIndexMarker455"/>default commands is important in multi-container Pods because it lets you control each container’s behavior individually. This means you can customize how each container works within the Pod. For example, a web server container might normally run a <code class="inlineCode">start server</code> command, but you could override a sidecar container’s command to handle logging instead. This approach can also help with resource management. If a container usually runs a heavy process, you can change it to a lighter one in the Pod to ensure other containers have enough resources. Finally, it helps with managing dependencies. For instance, a database container might typically start right away, but you could override its command to wait until a related application container is ready.</p>
    <p class="normal">When using Docker, you have the opportunity to write files called <code class="inlineCode">Dockerfiles</code> to build container images. <code class="inlineCode">Dockerfiles</code> make use of two keywords to tell us what commands and arguments the containers that were built with this image will launch when they’re created using the <code class="inlineCode">docker run</code> command. These two keywords are <code class="inlineCode">ENTRYPOINT</code> and <code class="inlineCode">CMD</code>:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">ENTRYPOINT</code> is the main command the container will launch.</li>
      <li class="bulletList"><code class="inlineCode">CMD</code> is used to replace the parameters that are passed to the <code class="inlineCode">ENTRYPOINT</code> command.</li>
    </ul>
    <p class="normal">For <a id="_idIndexMarker456"/>example, a classic <code class="inlineCode">Dockerfile</code> that should be launched to run the <code class="inlineCode">sleep</code> command for <code class="inlineCode">30</code> seconds would be written like this:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta"># </span>~/Dockerfile
FROM busybox:latest
ENTRYPOINT ["sleep"]
CMD ["30"]
</code></pre>
    <div class="note">
      <p class="normal"><strong class="keyWord">Containerfile and Podman</strong></p>
      <p class="normal">A Containerfile acts as<a id="_idIndexMarker457"/> a recipe for building a container image similar to Dockerfiles. It contains a series of instructions specifying the operating system, installing dependencies, copying application code, and configuring settings. Podman, a tool similar <a id="_idIndexMarker458"/>to Docker, can interpret this Containerfile and construct the image based on the instructions.</p>
    </div>
    <p class="normal">The previous code snippet is just plain old Docker and you should be familiar with these concepts. The <code class="inlineCode">CMD</code> argument is what you can pass to the <code class="inlineCode">docker run</code> command. If you build this image with this <code class="inlineCode">Dockerfile</code> using the <code class="inlineCode">docker build</code> command, you’ll end up with a BusyBox image that just runs the <code class="inlineCode">sleep</code> command (<code class="inlineCode">ENTRYPOINT</code>) when the <code class="inlineCode">docker run</code> command is run for <code class="inlineCode">30</code> seconds (the <code class="inlineCode">CMD</code> argument).</p>
    <p class="normal">Thanks to the <code class="inlineCode">CMD</code> instruction, you can override the default <code class="inlineCode">30</code> seconds like so:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>docker run my-custom-ubuntu:latest 60
<span class="hljs-con-meta">$ </span>docker run my-custom-ubuntu:latest <span class="hljs-con-comment"># Just sleep for 30 seconds</span>
</code></pre>
    <p class="normal">Kubernetes, on the other hand, allows us to override both <code class="inlineCode">ENTRYPOINT</code> and <code class="inlineCode">CMD</code> thanks to YAML Pod definition files. To do so, you must append two optional keys to your YAML configuration file: <code class="inlineCode">command</code> and <code class="inlineCode">args</code>.</p>
    <p class="normal">This is a very big benefit that Kubernetes brings you because you can decide to append arguments to the command that’s run by your container’s <code class="inlineCode">Dockerfile</code>, just like the <code class="inlineCode">CMD</code> arguments do with bare Docker, or completely override <code class="inlineCode">ENTRYPOINT</code>!</p>
    <p class="normal">Here, we are going to write a new manifest file that will override the default <code class="inlineCode">ENTRYPOINT</code> and <code class="inlineCode">CMD</code> parameters of the <code class="inlineCode">busybox</code> image to make the <code class="inlineCode">busybox</code> container sleep for 60 seconds. Here is how to proceed:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># nginx-debian-with-custom-command-and-args</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-debian-with-custom-command-and-args</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">restartPolicy:</span> <span class="hljs-string">Never</span>
  <span class="hljs-attr">containers:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:latest</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">debian-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">debian</span>
      <span class="hljs-attr">command:</span> [<span class="hljs-string">"sleep"</span>] <span class="hljs-comment"># Corresponds to the ENTRYPOINT</span>
      <span class="hljs-attr">args:</span> [<span class="hljs-string">"60"</span>] <span class="hljs-comment"># Corresponds to CMD</span>
</code></pre>
    <p class="normal">This is a <a id="_idIndexMarker459"/>bit tricky to understand because what <code class="inlineCode">Dockerfile</code> calls <code class="inlineCode">ENTRYPOINT</code> corresponds<a id="_idIndexMarker460"/> to the <code class="inlineCode">command</code> argument in the YAML manifest file, and what <code class="inlineCode">Dockerfile</code> calls <code class="inlineCode">CMD</code> corresponds to the <code class="inlineCode">args</code> configuration key in the YAML manifest file.</p>
    <p class="normal">What if you omit one of them? Kubernetes will default to what is inside the container image. If you omit the <code class="inlineCode">args</code> key in the YAML, then Kubernetes will go for the <code class="inlineCode">CMD</code> provided in the <code class="inlineCode">Dockerfile</code>, while if you omit the <code class="inlineCode">command</code> key, Kubernetes will go for the <code class="inlineCode">ENTRYPOINT</code> declared in the <code class="inlineCode">Dockerfile</code>. Most of the time, or at least if you’re comfortable with your container’s <code class="inlineCode">ENTRYPOINT</code>, you’re just going to override the <code class="inlineCode">args</code> file (the <code class="inlineCode">CMD Dockerfile</code> instruction).</p>
    <p class="normal">When we create the Pod, we can check the output as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f nginx-debian-with-custom-command-and-args.yaml
pod/nginx-debian-with-custom-command-and-args created
<span class="hljs-con-meta">$ </span>kubectl get po -w
NAME                                        READY   STATUS     RESTARTS   AGE
nginx-debian-with-custom-command-and-args   0/2     ContainerCreating   0          2s
nginx-debian-with-custom-command-and-args   2/2     Running             0          6s
nginx-debian-with-custom-command-and-args   1/2     NotReady            0          66s
</code></pre>
    <p class="normal">Therefore, overriding default commands offers granular control over container behavior within multi-container Pods. This enables tailored functionality, resource optimization, and dependency <a id="_idIndexMarker461"/>management for seamless Pod operation. In this section, we learned <a id="_idIndexMarker462"/>that Kubernetes allows overriding defaults through the <code class="inlineCode">command</code> and <code class="inlineCode">args</code> fields in Pod YAML definitions.</p>
    <p class="normal">Now, let’s look at another feature: <code class="inlineCode">initContainers</code>! In the next section, you’ll see another way to execute some additional side containers in your Pod to configure the main ones.</p>
    <h2 class="heading-2" id="_idParaDest-200">Introducing initContainers</h2>
    <p class="normal"><code class="inlineCode">initContainers</code> is a <a id="_idIndexMarker463"/>feature provided by Kubernetes Pods to run setup scripts before the actual containers start. You can think of them as additional side containers you can define in your Pod YAML manifest file: they will first run when the Pod is created. Then, once they complete, the Pod starts creating its main containers.</p>
    <p class="normal">You can execute not one but several <code class="inlineCode">initContainers</code> in the same Pod, but when you define lots of them, keep in mind that they will run one after another, not in parallel. Once an <code class="inlineCode">initContainer</code> completes, the next one starts, and so on. In general, <code class="inlineCode">initContainers</code> are used for preparation tasks; some of them are outlined in the following list:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Database initialization</strong>: Set up and configure databases before the main application starts.</li>
      <li class="bulletList"><strong class="keyWord">Configuration file download</strong>: Download essential configuration files from remote locations.</li>
      <li class="bulletList"><strong class="keyWord">Package installation</strong>: Install dependencies required by the main application.</li>
      <li class="bulletList"><strong class="keyWord">Waiting for external service</strong>: Ensure external services are available before starting the main container.</li>
      <li class="bulletList"><strong class="keyWord">Running pre-checks</strong>: Perform any necessary checks or validations before starting the main application.</li>
      <li class="bulletList"><strong class="keyWord">Secret management</strong>: Download and inject secrets securely into the main container’s environment.</li>
      <li class="bulletList"><strong class="keyWord">Data migration</strong>: Migrate data to a database or storage system before the main application starts.</li>
      <li class="bulletList"><strong class="keyWord">Customizing file permissions</strong>: Set appropriate file permissions for the main application.</li>
    </ul>
    <p class="normal">Since <code class="inlineCode">initContainers</code> can have their own container images. You can offload some configuration to them by keeping the main container images as small as possible, thus increasing the<a id="_idIndexMarker464"/> whole security of your setup by removing unnecessary tools from your main container images. Here is a YAML manifest that introduces an <code class="inlineCode">initContainer</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># nginx-with-init-container.yaml</span>
<span class="hljs-meta">---</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-with-init-container</span>
  <span class="hljs-attr">labels:</span>
    <span class="hljs-attr">environment:</span> <span class="hljs-string">prod</span>
    <span class="hljs-attr">tier:</span> <span class="hljs-string">frontend</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">restartPolicy:</span> <span class="hljs-string">Never</span>
  <span class="hljs-attr">volumes:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">website-volume</span>
      <span class="hljs-attr">emptyDir:</span> {}
  <span class="hljs-attr">initContainers:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">download-website</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">busybox</span>
      <span class="hljs-attr">command:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-string">sh</span>
        <span class="hljs-bullet">-</span> <span class="hljs-string">-c</span>
        <span class="hljs-bullet">-</span> <span class="hljs-string">|</span>
          <span class="hljs-string">wget</span> <span class="hljs-string">https://github.com/iamgini/website-demo-one-page/archive/refs/heads/main.zip</span> <span class="hljs-string">-O</span> <span class="hljs-string">/tmp/website.zip</span> <span class="hljs-string">&amp;&amp;</span> <span class="hljs-string">\</span>
          <span class="hljs-string">mkdir</span> <span class="hljs-string">/tmp/website</span> <span class="hljs-string">&amp;&amp;</span> <span class="hljs-string">\</span>
          <span class="hljs-string">unzip</span> <span class="hljs-string">/tmp/website.zip</span> <span class="hljs-string">-d</span> <span class="hljs-string">/tmp/website</span> <span class="hljs-string">&amp;&amp;</span> <span class="hljs-string">\</span>
          <span class="hljs-string">cp</span> <span class="hljs-string">-r</span> <span class="hljs-string">/tmp/website/website-demo-one-page-main/*</span> <span class="hljs-string">/usr/share/nginx/html</span>
      <span class="hljs-attr">volumeMounts:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">website-volume</span>
          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/usr/share/nginx/html</span>
  <span class="hljs-attr">containers:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:latest</span>
      <span class="hljs-attr">volumeMounts:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">website-volume</span>
          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/usr/share/nginx/html</span>
</code></pre>
    <p class="normal">As you can see from this YAML file, <code class="inlineCode">initContainer</code> runs the BusyBox image, which will download the application (in this case, simple website content from <a href="https://github.com/iamgini/website-demo-one-page"><span class="url">https://github.com/iamgini/website-demo-one-page</span></a>) and copy the same application to a shared volume <a id="_idIndexMarker465"/>called <code class="inlineCode">website-volume</code>. (You will learn about volumes and persistent storage in <em class="chapterRef">Chapter 9</em>, <em class="italic">Persistent Storage in Kubernetes</em>, later in this book.) The same volume is also configured to mount under the NGINX container so that NGINX will use it as the default <a id="_idIndexMarker466"/>website content. Once the execution of <code class="inlineCode">initContainer</code> is complete, Kubernetes will create the <code class="inlineCode">nginx-container</code> container.</p>
    <div class="note">
      <p class="normal">Keep in mind that if <code class="inlineCode">initContainer</code> fails, Kubernetes won’t initiate the primary containers. It’s crucial not to perceive <code class="inlineCode">initContainer</code> as an optional component or one that can afford to fail. If included in the YAML manifest file, they are mandatory and their failure prevents the launch of the main containers!</p>
    </div>
    <p class="normal">Let’s create the Pod. After this, we will run the <code class="inlineCode">kubectl get Pods -w</code> command for <code class="inlineCode">kubectl</code> to watch for a change in the Pod list. The output of the command will be updated regularly, showing the change in the Pod’s status. Please take note of the <code class="inlineCode">status</code> column, which says that an <code class="inlineCode">initContainer</code> is running:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f nginx-with-init-container.yaml
pod/nginx-with-init-container created
<span class="hljs-con-meta">$ </span>kubectl get po -w
NAME                        READY   STATUS     RESTARTS   AGE
nginx-with-init-container   0/1     Init:0/1   0          3s
nginx-with-init-container   0/1     Init:0/1   0          4s
nginx-with-init-container   0/1     PodInitializing   0          19s
nginx-with-init-container   1/1     Running           0          22s
</code></pre>
    <p class="normal">As you can see, <code class="inlineCode">Init:0/1</code> indicates that <code class="inlineCode">initContainer</code> is being launched. After its completion, the <code class="inlineCode">Init:</code> prefix disappears for the next statuses, indicating that we are done with <code class="inlineCode">initContainer</code> and that Kubernetes is now creating the main container – in our case, the NGINX one!</p>
    <p class="normal">If you want to explore this further, you can expose the Pod with a NodePort service as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl expose pod nginx-with-init-container --port=80 --<span class="hljs-con-built_in">type</span>=NodePort
service/nginx-with-init-container exposed
</code></pre>
    <p class="normal">Now, start a port forwarding service using <code class="inlineCode">kubectl port-forward</code> command as follows so that we can access the service outside of the cluster:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl port-forward pod/nginx-with-init-container 8080:80
Forwarding from 127.0.0.1:8080 -&gt; 80
Forwarding from [::1]:8080 -&gt; 80
</code></pre>
    <p class="normal">Now, access <code class="inlineCode">http://localhost:8080</code> and you will <a id="_idIndexMarker467"/>see a one-page website with content copied from <a href="https://github.com/iamgini/website-demo-one-page"><span class="url">https://github.com/iamgini/website-demo-one-page</span></a>. We will learn about exposing services in <em class="chapterRef">Chapter 8</em>, <em class="italic">Exposing Your Pods with Services</em>. Also remember to stop the port forward by pressing the <em class="keystroke">ctrl + c</em> to in your console before proceeding to the next section.</p>
    <p class="normal">Use <code class="inlineCode">initContainer</code> wisely when you’re building your Pods! You are not forced to use <code class="inlineCode">init</code> containers, but they can be really helpful for running configuration scripts or pulling something from external servers before you launch your actual containers!</p>
    <p class="normal">Now, let’s learn how to access the logs of a specific container inside a running Pod!</p>
    <h2 class="heading-2" id="_idParaDest-201">Accessing the logs of a specific container</h2>
    <p class="normal">When using <a id="_idIndexMarker468"/>multiple containers in a single Pod, you can retrieve the logs of a dedicated container inside the Pod. The proper way to proceed is by using the <code class="inlineCode">kubectl logs</code> command.</p>
    <p class="normal">The most common way a containerized application exposes its logs is by sending them to <code class="inlineCode">stdout</code>. The <code class="inlineCode">kubectl logs</code> command is capable of streaming the <code class="inlineCode">stdout</code> property of a dedicated container in a dedicated Pod and retrieving the application logs from the container. For it to work, you will need to know the name of both the precise container and its parent Pod, just like when we used <code class="inlineCode">kubectl exec</code> to access a specific container.</p>
    <p class="normal">Please read the previous section, <em class="italic">Accessing a specific container inside a multi-container Pod</em>, to discover how to do this:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl logs -f pods/multi-container-pod --container nginx-container
</code></pre>
    <p class="normal">Please note the <code class="inlineCode">--container</code> option (the <code class="inlineCode">-c</code> short option works, too), which specifies the container you want to retrieve the logs for. Note that it also works the same for <code class="inlineCode">initContainers</code>: you have to pass its name to this option to retrieve its logs.</p>
    <div class="note">
      <p class="normal">Remember that if you do not pass the <code class="inlineCode">--container</code> option, you will retrieve all the logs from all the containers that have been launched inside the Pod. Not passing this option is useful in the case of a single-container Pod, but you should consider this option every time you use a multi-container Pod.</p>
    </div>
    <p class="normal">There are<a id="_idIndexMarker469"/> other multiple useful options you need to be aware of when it comes to accessing the logs of a container in a Pod. You can decide to retrieve the logs written in the last two hours by using the following command:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl logs --since=2h pods/multi-container-pod --container nginx-container
</code></pre>
    <p class="normal">Also, you can use the <code class="inlineCode">--tail</code> option to retrieve the most recent lines of a log’s output. Here’s how to do this:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl logs --<span class="hljs-con-built_in">tail</span>=30 pods/multi-container-pod --container nginx-container
</code></pre>
    <p class="normal">Here, we are retrieving the 30 most recent lines in the log output of <code class="inlineCode">nginx-container</code>.</p>
    <p class="normal">Now, you are ready to read and retrieve the logs from your Kubernetes Pods, regardless of whether they are made up of one or several containers!</p>
    <p class="normal">In this section, we discovered how to create, update, and delete multi-container Pods. We also discovered how to force the deletion of a Pod. We then discovered how to access a specific container in a Pod, as well as how to retrieve the logs of a specific container in a Pod. Though we created an NGINX and a Debian container in our Pod, they are relatively poorly linked since they don’t do anything together. To remediate that, we will now learn how to deal with volumes so that we can share files between our two containers.</p>
    <h1 class="heading-1" id="_idParaDest-202">Sharing volumes between containers in the same Pod</h1>
    <p class="normal">In this section, we’ll learn what volumes are from a Kubernetes point of view and how to use them. Docker also has volumes, but they differ from Kubernetes volumes: they answer the same need but they are not the same.</p>
    <p class="normal">We will discover what Kubernetes volumes are, why they are useful, and how they can help us when it comes to Kubernetes volumes.</p>
    <h2 class="heading-2" id="_idParaDest-203">What are Kubernetes volumes?</h2>
    <p class="normal">We are going<a id="_idIndexMarker470"/> to answer a simple problem. Our multi-container Pods are currently made up of two containers: an NGINX one and a Debian one. We are going to try sharing the log directory in the NGINX container with the Debian container by mounting the log directory of NGINX in the directory of the Debian container. This way, we will create a relationship between the two containers to have them share a directory.</p>
    <p class="normal">Kubernetes has two kinds of volumes:</p>
    <ul>
      <li class="bulletList">Volumes, which we will discuss here.</li>
      <li class="bulletList"><code class="inlineCode">PersistentVolume</code>, which is a more advanced feature we will discuss later, in<strong class="keyWord"> </strong><em class="chapterRef">Chapter 9</em>, <em class="italic">Persistent Storage in Kubernetes</em>.</li>
    </ul>
    <p class="normal">Keep in mind that these two are not the same. <code class="inlineCode">PersistentVolume</code> is a resource of its own, whereas “volumes” is a Pod configuration. As the name suggests, <code class="inlineCode">PersistentVolume</code> is persistent, whereas volumes are not supposed to be. But keep in mind that this is not always the case!</p>
    <p class="normal">In straightforward terms, volumes in Kubernetes are intricately linked to the life cycle of a Pod. When you instantiate a Pod, you can define and connect volumes to the containers within it. Essentially, volumes represent storage tied to the existence of the Pod. Once the Pod is removed, any associated volumes are also deleted.</p>
    <p class="normal">While volumes serve a broader range of purposes beyond this scenario, it’s worth noting that this description doesn’t universally apply. However, you can view volumes as an especially effective method for facilitating the sharing of directories and files among containers coexisting within a Pod.</p>
    <div class="note">
      <p class="normal">Remember that volumes are bound to the Pod’s life cycle, not the container’s life cycle. If a container crashes, the volume will survive because if a container crashes, it won’t cause its parent Pod to crash, and thus, no volume will be deleted. So long as a Pod is alive, its volumes are, too.</p>
    </div>
    <p class="normal">Volumes are a core concept for managing data in containerized applications. They provide a way to persist data independent of the container’s life cycle. Kubernetes supports various volume types, including those mounted from the host file system, cloud providers, and network storage systems.</p>
    <p class="normal">However, Kubernetes<a id="_idIndexMarker471"/> expanded on this by introducing support for various drivers, enabling integration of Pod volumes with external solutions. For instance, an AWS EBS (Elastic Block Store) volume seamlessly serves as a Kubernetes volume. Some widely utilized solutions include the following:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">hostPath</code></li>
      <li class="bulletList"><code class="inlineCode">emptyDir</code></li>
      <li class="bulletList"><code class="inlineCode">nfs</code></li>
      <li class="bulletList"><code class="inlineCode">persistentVolumeClaim</code> (when you need to use a <code class="inlineCode">PersistentVolume</code>, which is outside the scope of this chapter)</li>
    </ul>
    <p class="normal">Please note that some of the old volume types are removed or deprecated in the latest Kubernetes version; refer to the documentation to learn more (<a href="https://kubernetes.io/docs/concepts/storage/volumes/"><span class="url">https://kubernetes.io/docs/concepts/storage/volumes/</span></a>). Refer to the following list for examples:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">azureDisk</code> (removed)</li>
      <li class="bulletList"><code class="inlineCode">gcePersistentDisk</code> (removed)</li>
      <li class="bulletList"><code class="inlineCode">glusterfs</code> (removed)</li>
      <li class="bulletList"><code class="inlineCode">azureFile</code> (deprecated)</li>
    </ul>
    <div class="note">
      <p class="normal">Please note that using external solutions to manage the Kubernetes volumes will require you to follow those external solutions’ requirements. For example, using an AWS EBS volume as a Kubernetes volume will require your Pods to be executed on a Kubernetes worker node, which would be an EC2 instance. The reason for this is that AWS EBS volumes can only be attached to EC2 instances. Thus, a Pod exploiting such a volume would need to be launched on an EC2 instance. Refer to <a href="https://kubernetes.io/docs/concepts/storage/volumes/"><span class="url">https://kubernetes.io/docs/concepts/storage/volumes/</span></a> to learn more.</p>
    </div>
    <p class="normal">The following diagram shows the high-level idea about the <code class="inlineCode">hostPath</code> and <code class="inlineCode">emptyDir</code> volumes.</p>
    <figure class="mediaobject"><img alt="" src="image/B22019_05_02.png"/></figure>
    <p class="packt_figref">Figure 5.2: hostPath and emptyDir volumes</p>
    <p class="normal">We are going <a id="_idIndexMarker472"/>to discover the two basic volume drivers here: <code class="inlineCode">emptyDir</code> and <code class="inlineCode">hostPath</code>. We will also talk about <code class="inlineCode">persistentVolumeClaim</code> because this one is going to be a little special in comparison to the other volumes and will be fully discovered in <em class="chapterRef">Chapter 9</em>, <em class="italic">Persistent Storage in Kubernetes</em>.</p>
    <p class="normal">Now, let’s start discovering how to share files between containers in the same Pod using volumes with the <code class="inlineCode">emptyDir</code> volume type!</p>
    <h2 class="heading-2" id="_idParaDest-204">Creating and mounting an emptyDir volume</h2>
    <p class="normal">As the name <a id="_idIndexMarker473"/>suggests, it is simply an empty directory that is initialized at Pod creation that you can mount to the location of each container running in the Pod.</p>
    <p class="normal">It is certainly <a id="_idIndexMarker474"/>the easiest and simplest way to have your containers share data between them. Let’s create a Pod that will manage two containers.</p>
    <p class="normal">In the following example, we are creating a Pod that will launch two containers, and just like we had previously, it’s going to be an NGINX container and a Debian container. We are going to override the command that’s run by the Debian container when it starts to prevent it from completing. That way, we will get it running indefinitely as a long process and we will be able to launch additional commands to check whether our <code class="inlineCode">emptyDir</code> has been initialized correctly.</p>
    <p class="normal">Both <a id="_idIndexMarker475"/>containers <a id="_idIndexMarker476"/>will have a common volume mounted at <code class="inlineCode">/var/i-am-empty-dir-volume/</code>, which will be our <code class="inlineCode">emptyDir</code> volume, initialized in the same Pod. Here is the YAML file for creating the Pod:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># multi-container-with-emptydir-pod.yaml</span>
<span class="hljs-meta">---</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">multi-container-with-emptydir-pod</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">containers:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:latest</span>
      <span class="hljs-attr">volumeMounts:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/i-am-empty-dir-volume</span>
        <span class="hljs-attr">name:</span> <span class="hljs-string">empty-dir-volume</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">debian-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">debian</span>
      <span class="hljs-attr">command:</span> [<span class="hljs-string">"/bin/sh"</span>]
      <span class="hljs-attr">args:</span> [<span class="hljs-string">"-c"</span>, <span class="hljs-string">"while true; do sleep 30; done;"</span>] <span class="hljs-comment"># Prevents container from exiting after completion</span>
      <span class="hljs-attr">volumeMounts:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/i-am-empty-dir-volume</span>
        <span class="hljs-attr">name:</span> <span class="hljs-string">empty-dir-volume</span>
  <span class="hljs-attr">volumes:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">empty-dir-volume</span> <span class="hljs-comment"># name of the volume</span>
    <span class="hljs-attr">emptyDir:</span> {} <span class="hljs-comment"># Initialize an empty directory # The path on the worker node.</span>
</code></pre>
    <p class="normal">Note that the object we will create in our Kubernetes cluster will become more complex as we go through this example, and, as you can imagine, most complex things cannot be achieved with just imperative commands. That’s why you are going to see more and more examples relying on the YAML manifest file: you should start a habit of trying to read them to figure out what they do.</p>
    <p class="normal">We can now apply the manifest file using the following <code class="inlineCode">kubectl apply -f</code> command:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f multi-container-with-emptydir-pod.yaml
pod/multi-container-with-emptydir-pod created
</code></pre>
    <p class="normal">Now, we can check that the Pod is successfully running by issuing the <code class="inlineCode">kubectl get Pods</code> command:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get po
NAME                                READY   STATUS    RESTARTS   AGE
multi-container-with-emptydir-pod   2/2     Running   0          25s
</code></pre>
    <p class="normal">Now that we<a id="_idIndexMarker477"/> are sure the Pod is running and that both the NGINX and <a id="_idIndexMarker478"/>Debian containers have been launched, we can check that the directory can be accessed in both containers by issuing the <code class="inlineCode">ls</code> command.</p>
    <p class="normal">If the command is not failing, as we saw previously, we can run the <code class="inlineCode">ls</code> command in the containers by simply running the <code class="inlineCode">kubectl exec</code> command. As you may recall, the command takes the Pod’s name and the container’s name as arguments. We are going to run it twice to make sure the volume is mounted in both containers:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> multi-container-with-emptydir-pod -c debian-container -- <span class="hljs-con-built_in">ls</span> /var
backups
cache
i-am-empty-dir-volume
lib
local
lock
log
mail
opt
run
spool
tmp
<span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> multi-container-with-emptydir-pod -c nginx-container  -- <span class="hljs-con-built_in">ls</span> /var
backups
cache
i-am-empty-dir-volume
lib
local
lock
log
mail
opt
run
spool
tmp
</code></pre>
    <p class="normal">As you can see, the <code class="inlineCode">ls /var</code> command is showing the name in both containers! This means that <code class="inlineCode">emptyDir</code> was initialized and mounted in both containers correctly.</p>
    <p class="normal">Now, let’s create a<a id="_idIndexMarker479"/> file in one of the two containers. The file should<a id="_idIndexMarker480"/> be immediately visible in the other container, proving that the volume mount is working properly!</p>
    <p class="normal">In the following command, we are simply creating a <code class="inlineCode">.txt</code> file called <code class="inlineCode">hello-world.txt</code> in the mounted directory:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> multi-container-with-emptydir-pod -c debian-container -- bin/sh -c <span class="hljs-con-string">"echo 'hello world' &gt;&gt; /var/i-am-empty-dir-volume/hello-world.txt"</span>
<span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> multi-container-with-emptydir-pod -c nginx-container -- <span class="hljs-con-built_in">cat</span> /var/i-am-empty-dir-volume/hello-world.txt
hello world
<span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> multi-container-with-emptydir-pod -c debian-container -- <span class="hljs-con-built_in">cat</span> /var/i-am-empty-dir-volume/hello-world.txt
hello world
</code></pre>
    <p class="normal">As you can see, we used <code class="inlineCode">debian-container</code> to create the <code class="inlineCode">/var/i-am-empty-dir-volume/hello-world.txt</code> file, which contains the <code class="inlineCode">hello-world</code> string. Then, we simply used the <code class="inlineCode">cat</code> command to access the file from both containers; you can see that the file is accessible in both cases. Again, remember that <code class="inlineCode">emptyDir</code> volumes are completely tied to the life cycle of the Pod. If the Pod declares it is destroyed, then the volume is destroyed, too, along with all its content, and it will become impossible to recover!</p>
    <p class="normal">Now, we will discover another volume type: the <code class="inlineCode">hostPath</code> volume. As you can imagine, it’s going to be a directory that you can mount on your containers that is backed by a path on the host machine – the Kubernetes node running the Pod!</p>
    <h2 class="heading-2" id="_idParaDest-205">Creating and mounting a hostPath volume</h2>
    <p class="normal">As the <a id="_idIndexMarker481"/>name suggests, hostPath will allow you to mount a directory <a id="_idIndexMarker482"/>in the host machine to containers in your Pod! The host machine is the Kubernetes compute node (or controller node) executing the Pod. Here are some examples:</p>
    <ul>
      <li class="bulletList">If your cluster is based on minikube (a single-node cluster), the host is your local machine.</li>
      <li class="bulletList">On Amazon EKS, the host machine will be an EC2 instance.</li>
      <li class="bulletList">In a <code class="inlineCode">kubeadm</code> cluster, the host machine is generally a standard Linux machine.</li>
    </ul>
    <p class="normal">The host <a id="_idIndexMarker483"/>machine is the machine running the Pod, and you can mount a directory from the file system of the host machine to the Kubernetes Pod!</p>
    <p class="normal">In the following example, we <a id="_idIndexMarker484"/>will be working on a Kubernetes cluster based on minikube, so <code class="inlineCode">hostPath</code> will be a directory that’s been created on your computer that will then be mounted in a Kubernetes Pod.</p>
    <div class="note">
      <p class="normal">Using the <code class="inlineCode">hostPath</code> volume type can be useful, but in the Kubernetes world, you can consider it an anti-pattern. The <code class="inlineCode">hostPath</code> volume type, while convenient, is discouraged in Kubernetes due to reduced portability and potential security risks. It can also be incompatible with advanced security features <a id="_idIndexMarker485"/>like SELinux <strong class="keyWord">multi-category security</strong> (<strong class="keyWord">MCS</strong>), now supported by many Kubernetes distributions. For a more portable, secure, and future-proof approach, leverage <strong class="keyWord">persistent volumes</strong> (<strong class="keyWord">PVs</strong>) and <a id="_idIndexMarker486"/><strong class="keyWord">persistent volume claims</strong> (<strong class="keyWord">PVCs</strong>) to manage persistent <a id="_idIndexMarker487"/>data within your containerized applications.</p>
    </div>
    <p class="normal">The whole idea behind Pods is that they are supposed to be easy to delete and reschedule on another worker node without problems. Using <code class="inlineCode">hostPath</code> will create a tight relationship between the Pod and the worker node, and that could lead to major issues if your Pod were to fail and be rescheduled on a node where the required path on the host machine is not present.</p>
    <p class="normal">Now, let’s discover how to create <code class="inlineCode">hostPath</code>.</p>
    <p class="normal">Let’s imagine that we have a file on the worker node on <code class="inlineCode">worker-node/nginx.conf</code> and we want to mount it on <code class="inlineCode">/var/config/nginx.conf</code> on the <code class="inlineCode">nginx</code> container.</p>
    <p class="normal">Here is the YAML file to create the setup. As you can see, we declared a <code class="inlineCode">hostPath</code> volume at the bottom of the file that defines a path that should be present on the host machine. Now, we can mount it on any container that needs to deal with the volume in the <code class="inlineCode">containers</code> block:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># multi-container-with-hostpath.yaml</span>
<span class="hljs-meta">---</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">multi-container-with-hostpath</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">containers:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:latest</span>
      <span class="hljs-attr">volumeMounts:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/foo</span>
        <span class="hljs-attr">name:</span> <span class="hljs-string">my-host-path-volume</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">debian-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">debian</span>
      <span class="hljs-attr">command:</span> [<span class="hljs-string">"/bin/sh"</span>]
      <span class="hljs-attr">args:</span> [<span class="hljs-string">"-c"</span>, <span class="hljs-string">"while true; do sleep 30; done;"</span>] <span class="hljs-comment"># Prevents container from exiting after completion</span>
  <span class="hljs-attr">volumes:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">my-host-path-volume</span>
    <span class="hljs-attr">hostPath:</span>
      <span class="hljs-attr">path:</span> <span class="hljs-string">/tmp</span> <span class="hljs-comment"># The path on the worker node.</span>
      <span class="hljs-attr">type:</span> <span class="hljs-string">Directory</span>
</code></pre>
    <p class="normal">As you<a id="_idIndexMarker488"/> can see, mounting the value is just like what we did with the <code class="inlineCode">emptyDir</code> volume in the previous section regarding the <code class="inlineCode">emptyDir</code> volume type. By using a <a id="_idIndexMarker489"/>combination of volumes at the Pod level and <code class="inlineCode">volumeMounts</code> at the container level, you can mount a volume on your containers.</p>
    <div class="note">
      <p class="normal">In the previous YAML snippet, we mentioned <code class="inlineCode">type: Directory</code>, which means the directory already exists on the host machine. If you want to create the directory or file on the host machine, then use <code class="inlineCode">DirectoryOrCreate</code> and <code class="inlineCode">FileOrCreate</code> respectively.</p>
    </div>
    <p class="normal">You can also mount the directory on the Debian container so that it gets access to the directory on the host.</p>
    <p class="normal">Before running the YAML manifest file, though, you need to create the path on your host and create the necessary file:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span><span class="hljs-con-built_in">echo</span> <span class="hljs-con-string">"Hello World"</span> &gt;&gt; /tmp/hello-world.txt
</code></pre>
    <p class="normal">If you are using a minikube cluster, remember to do this step inside the minikube VM as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>minikube ssh
docker@minikube:~$ echo "Hello World" &gt; /tmp/hello-world.txt
docker@minikube:~$ exit
Logout
</code></pre>
    <p class="normal">If your minikube <a id="_idIndexMarker490"/>cluster is created using Podman containers (e.g., <code class="inlineCode">minikube start --profile cluster2-podman --driver=podman</code>), then log in to the minikube Pod and create the file:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span><span class="hljs-con-built_in">sudo</span> podman <span class="hljs-con-built_in">exec</span> -it minikube /bin/bash
root@minikube:/# cat /tmp/hello-world.txt
</code></pre>
    <p class="normal">Now that<a id="_idIndexMarker491"/> the path exists on the host machine, we can apply the YAML file to our Kubernetes cluster and, immediately after, launch a <code class="inlineCode">kubectl get Pod</code> command to check that the Pod was created correctly:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f multi-container-with-hostpath.yaml
pod/multi-container-with-hostpath created
<span class="hljs-con-meta">$ </span>kubectl get pod
NAME                            READY   STATUS    RESTARTS   AGE
multi-container-with-hostpath   2/2     Running   0          11
</code></pre>
    <p class="normal">Everything seems good! Now, let’s echo the file that should be mounted at <code class="inlineCode">/foo/hello-world.txt</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> multi-container-with-hostpath -c nginx-container -- <span class="hljs-con-built_in">cat</span> /foo/hello-world.txt
Hello World
</code></pre>
    <p class="normal">We can see the local file (on the Kubernetes node) is available inside the container via the hostPath volume mount.</p>
    <p class="normal">At the beginning of this chapter, we discovered the different aspects of multi-container Pods! We discovered how to create, update, and delete multi-container Pods, as well as how to use <code class="inlineCode">initContainers</code>, access logs, override command-line arguments passed to containers directly from the Pod’s resources, and share directories between containers using the two basic volumes. </p>
    <p class="normal">Now, we are going to put a few architecting principles together and discover some notions related to multi-container Pods called “patterns.”</p>
    <h1 class="heading-1" id="_idParaDest-206">The ambassador design pattern</h1>
    <p class="normal">When<a id="_idIndexMarker492"/> designing a multi-container Pod, you can decide to follow some architectural principles to build your Pod. Some typical needs are answered by these design principles, and the ambassador pattern is one of them.</p>
    <p class="normal">Here, we are going to discover what the ambassador design pattern is, learn how to build an ambassador container in Kubernetes Pods, and look at a concrete example of them.</p>
    <h2 class="heading-2" id="_idParaDest-207">What is the ambassador design pattern?</h2>
    <p class="normal">In essence, the ambassador design pattern applies to multi-container Pods. We can define two containers in the same Pod:</p>
    <ul>
      <li class="bulletList">The first container will be called the main container.</li>
      <li class="bulletList">The other container will be called the ambassador container.</li>
    </ul>
    <p class="normal">In this design pattern, we assume that the main container might have to access external services to communicate with them. For example, you can have an application that must interact with an SQL database that is living outside of your Pod, and you need to reach this database to retrieve data from it.</p>
    <figure class="mediaobject"><img alt="" src="image/B22019_05_03.png"/></figure>
    <p class="packt_figref">Figure 5.3: Ambassador design pattern in Kubernetes</p>
    <p class="normal">This is the <a id="_idIndexMarker493"/>typical use case where you can deploy an adapter container alongside the main container, next to it, in the same Pod. The whole idea is to get the ambassador container to proxy the requests run by the main container to the database server. </p>
    <p class="normal">In this case, the ambassador container will be essentially an SQL proxy. Every time the main container wants to access the database, it won’t access it directly but rather create a connection to the ambassador container that will play the role of a proxy.</p>
    <div class="note">
      <p class="normal">Running an ambassador container is fine, but only if the external API is not living in the same Kubernetes cluster. To run requests on another Pod, Kubernetes provides strong mechanics called Services. We will have the opportunity to discover them in <em class="chapterRef">Chapter 8</em>, <em class="italic">Exposing Your Pods with Services</em>.</p>
    </div>
    <p class="normal">But why would you need a proxy to access external databases? Here are some concrete benefits this design pattern can bring you:</p>
    <ul>
      <li class="bulletList">Offloading SQL configuration</li>
      <li class="bulletList">Management of <strong class="keyWord">Secure Sockets Layer</strong>/<strong class="keyWord">Transport Layer Security</strong> (<strong class="keyWord">SSL</strong>/<strong class="keyWord">TLS</strong>) certificates</li>
    </ul>
    <p class="normal">Please note that having an ambassador proxy is not limited to an SQL proxy but this example is demonstrative of what this design pattern can bring you. Note that the ambassador proxy is only supposed to be called for outbound connections from your main container to something else, such as data storage or an external API. It should not be seen as an entry point to your cluster! Now, let’s quickly discover how to create an ambassador SQL proxy with a YAML file.</p>
    <h2 class="heading-2" id="_idParaDest-208">Ambassador multi-container Pod – an example</h2>
    <p class="normal">Now that we know about <a id="_idIndexMarker494"/>ambassador containers, let’s learn how to create one with Kubernetes. The following YAML manifest file creates a Pod that creates two containers:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">nginx-app</code>, derived from the <code class="inlineCode">nginx:latest</code> image</li>
      <li class="bulletList"><code class="inlineCode">sql-ambassador-proxy</code>, created from the <code class="inlineCode">mysql-proxy:latest</code> container image</li>
    </ul>
    <p class="normal">The following example is only to demonstrate the concept of the ambassador SQL proxy. If you want to test the full functionality, you should have a working AWS <strong class="keyWord">RDS</strong> (<strong class="keyWord">Relational Database Service</strong>) instance reachable from your Kubernetes cluster and a proper application to test the database operations.</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta"># </span>~/ nginx-with-ambassador.yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-with-ambassador
spec:
  containers:
    - name: mysql-proxy-ambassador-container
      image: mysql-proxy:latest
      ports:
         - containerPort: 3306
      env:
      - name: DB_HOST
        value: mysql.xxx.us-east-1.rds.amazonaws.com
    - name: nginx-container
      image: nginx:latest
</code></pre>
    <p class="normal">As you can <a id="_idIndexMarker495"/>imagine, it’s going to be the developer’s job to get the application code running in the NGINX container to query the ambassador instead of the Amazon RDS endpoint. As the ambassador container can be configured from environment variables, it’s going to be easy for you to just input the configuration variables in <code class="inlineCode">ambassador-container</code>.</p>
    <div class="note">
      <p class="normal">Do not get tricked by the order of the containers in the YAML file. The fact that the ambassador container appears first does not make it the <em class="italic">main</em> container of the Pod. This notion of the <em class="italic">main</em> container does not exist at all from a Kubernetes perspective – both are plain containers that run in parallel with no concept of a hierarchy between them. Here, we just access the Pod from the NGINX container, which makes it the most important one.</p>
    </div>
    <p class="normal">Remember that the ambassador running in the same Pod as the NGINX container makes it accessible from NGINX on <code class="inlineCode">localhost:3306.</code></p>
    <p class="normal">In the next section, we will learn about the sidecar pattern, another important concept in multi-container Pods.</p>
    <h1 class="heading-1" id="_idParaDest-209">The sidecar design pattern</h1>
    <p class="normal">The sidecar design pattern<a id="_idIndexMarker496"/> is good when you want to extend the features of your main container with features it would normally not be able to achieve on its own.</p>
    <p class="normal">Just like we did for the ambassador container, we’re going to explain exactly what the sidecar design pattern is by covering some examples.</p>
    <h2 class="heading-2" id="_idParaDest-210">What is the sidecar design pattern?</h2>
    <p class="normal">Think of the sidecar container as an extension or a helper for your main container. Its main purpose is to extend the main container to bring it a new feature, but without changing anything about it. Unlike the ambassador design pattern, the main container may even not be aware of the presence of a sidecar.</p>
    <p class="normal">Just like the ambassador design pattern, the sidecar design pattern makes use of a minimum of two containers:</p>
    <ul>
      <li class="bulletList">The main container – the one that is running the application</li>
      <li class="bulletList">The sidecar container – the one that is bringing something additional to the first one</li>
    </ul>
    <p class="normal">You may have already guessed, but this pattern is especially useful when you want to run monitoring or log forwarder agents. The following figure shows a simple sidecar design with a main app container and a sidecar container to collect the application logs.</p>
    <figure class="mediaobject"><img alt="" src="image/B22019_05_04.png"/></figure>
    <p class="packt_figref">Figure 5.4: Sidecar design pattern in Kubernetes</p>
    <p class="normal">There are <a id="_idIndexMarker497"/>three things to understand when you want to build a sidecar that is going to forward your logs to another location:</p>
    <ul>
      <li class="bulletList">You must locate the directory where your main containers write their data (e.g., logs).</li>
      <li class="bulletList">You must create a volume to make this directory accessible to the sidecar container (e.g., a log forwarder sidecar).</li>
      <li class="bulletList">You must launch the sidecar container with the proper configuration.</li>
    </ul>
    <p class="normal">Based on these concepts, the main container remains unchanged, and even if the sidecar fails, it wouldn’t have an impact on the main container, which could continue to work.</p>
    <h2 class="heading-2" id="_idParaDest-211">When to use a Sidecar design pattern?</h2>
    <p class="normal">When considering<a id="_idIndexMarker498"/> the usage of sidecar containers, they prove particularly beneficial in the following scenarios:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Network proxies</strong>: Network proxies can be configured to initialize before other containers in the Pod, ensuring their services are available immediately. The Istio “Envoy” proxy is a great example of a sidecar container used as a proxy.</li>
      <li class="bulletList"><strong class="keyWord">Enhanced logging</strong>: Log collection sidecars can start early and persist until the Pod terminates, capturing logs reliably even in case of Pod crashes.</li>
      <li class="bulletList"><strong class="keyWord">Jobs</strong>: Sidecars can be deployed alongside Kubernetes Jobs without affecting Job completion. No additional configuration is required for sidecars to run within Jobs.</li>
      <li class="bulletList"><strong class="keyWord">Credential management</strong>: Many third-party credential management platforms utilize sidecar Pods to inject and manage credentials within workloads. They can also facilitate secure credential rotation and revocation.</li>
    </ul>
    <h2 class="heading-2" id="_idParaDest-212">Sidecar multi-container Pod – an example</h2>
    <p class="normal">Just like the<a id="_idIndexMarker499"/> ambassador design pattern, the sidecar makes use of multi-container Pods. We will define two containers in the same Pod as follows – an NGINX container, which acts as the application container, and a <code class="inlineCode">Fluentd container</code>, which acts as the sidecar to collect the logs from<a id="_idIndexMarker500"/> the NGINX web server:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># nginx-with-fluentd-sidecar.yaml</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-with-sidecar</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">containers:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-container</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">nginx:latest</span>
      <span class="hljs-attr">ports:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">80</span>
      <span class="hljs-attr">volumeMounts:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">log-volume</span>
          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/log/nginx</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">fluentd-sidecar</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">fluent/fluentd:v1.17</span>
      <span class="hljs-attr">volumeMounts:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">log-volume</span>
          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/log/nginx</span>
  <span class="hljs-attr">volumes:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">log-volume</span>
      <span class="hljs-attr">emptyDir:</span> {}
</code></pre>
    <p class="normal">Please note, for the Fluentd to work properly, we need to pass the configuration via ConfigMap; a typical configuration can be found in the following code (you will learn more about ConfigMaps in <em class="chapterRef">Chapter 7</em>, <em class="italic">Configuring your Pods using ConfigMaps and Secrets):</em></p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-meta">---</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">ConfigMap</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">fluentd-config-map</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">default</span>
<span class="hljs-attr">data:</span>
  <span class="hljs-attr">fluentd.conf:</span> <span class="hljs-string">|</span>
    <span class="hljs-string">&lt;source&gt;</span>
      <span class="hljs-string">@type</span> <span class="hljs-string">tail</span>
      <span class="hljs-string">path</span> <span class="hljs-string">/var/log/nginx/*.log</span>
      <span class="hljs-string">pos_file</span> <span class="hljs-string">/var/log/nginx/nginx.log.pos</span>
      <span class="hljs-string">tag</span> <span class="hljs-string">nginx</span>
      <span class="hljs-string">&lt;parse&gt;</span>
        <span class="hljs-string">@type</span> <span class="hljs-string">nginx</span>
      <span class="hljs-string">&lt;/parse&gt;</span>
    <span class="hljs-string">&lt;/source&gt;</span>
    <span class="hljs-string">&lt;match</span> <span class="hljs-string">nginx.**&gt;</span>
      <span class="hljs-string">@type</span> <span class="hljs-string">elasticsearch</span>
      <span class="hljs-string">host</span> <span class="hljs-string">elastic.lab.example.com</span>
      <span class="hljs-string">port</span> <span class="hljs-number">9200</span>
      <span class="hljs-string">logstash_format</span> <span class="hljs-literal">true</span>
      <span class="hljs-string">logstash_prefix</span> <span class="hljs-string">fluentd</span>
      <span class="hljs-string">logstash_dateformat</span> <span class="hljs-string">%Y.%m.%d</span>
    <span class="hljs-string">&lt;/match&gt;</span>
</code></pre>
    <div class="note">
      <p class="normal"><strong class="keyWord">Fluentd</strong> is a <a id="_idIndexMarker501"/>popular open-source log collection and forwarding agent, often used as a sidecar container in Kubernetes deployments. It efficiently collects logs from various sources, parses them for structure, and forwards them to centralized logging platforms like Elasticsearch, Google Cloud Logging, or Amazon CloudWatch Logs. This allows for streamlined log management, improved observability, and easier analysis of application health and performance. While this example demonstrates sending logs to a dummy Elasticsearch server (e.g., <code class="inlineCode">elastic.lab.example.com</code>), Fluentd offers flexibility to integrate with various external logging solutions depending on your specific needs.</p>
    </div>
    <p class="normal">In the following <a id="_idIndexMarker502"/>section of this chapter, we will discuss the adapter design pattern.</p>
    <h1 class="heading-1" id="_idParaDest-213">The adapter design pattern</h1>
    <p class="normal">As its<a id="_idIndexMarker503"/> name suggests, the adapter design pattern is going to <em class="italic">adapt</em> an entry from a source format to a target format.</p>
    <p class="normal"> As with the ambassador and sidecar design patterns, this one expects that you run at least two containers:</p>
    <ul>
      <li class="bulletList">The first one is the main container.</li>
      <li class="bulletList">The second one is the adapter container.</li>
    </ul>
    <p class="normal">This design pattern is helpful and should be used whenever the main containers emit data in a format, A, that should be sent to another application that is expecting the data in another format, B. As the name suggests, the adapter container is here to <em class="italic">adapt</em>.</p>
    <p class="normal">Again, this <a id="_idIndexMarker504"/>design pattern is especially well suited for log or monitoring management. Imagine a Kubernetes cluster where you have dozens of applications running; they are writing logs in Apache format, which you need to convert into JSON so that they can be indexed by a search engine. This is exactly where the adapter design pattern comes into play. Running an adapter container next to the application containers will help you get these logs adapted to the source format before they are sent somewhere else.</p>
    <p class="normal">Just like for the sidecar design pattern, this one can only work if both the containers in your Pod are accessing the same directory using volumes.</p>
    <h2 class="heading-2" id="_idParaDest-214">Adapter multi-container Pod – an example</h2>
    <p class="normal">In this<a id="_idIndexMarker505"/> example, we are going to use a Pod that uses an adapter container with a shared directory mounted as a Kubernetes volume.</p>
    <figure class="mediaobject"><img alt="" src="image/B22019_05_05.png"/></figure>
    <p class="packt_figref">Figure 5.5: Adapter design pattern in Kubernetes</p>
    <p class="normal">This Pod is going to run two containers:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">alpine-writer</code>: Main app container, which writes logs to <code class="inlineCode">/var/log/app</code>.</li>
      <li class="bulletList"><code class="inlineCode">log-adapter</code>: Adapter container, which will read the log and convert it to another <a id="_idIndexMarker506"/>format (e.g., append a <code class="inlineCode">PROCESSED</code> string at the end of each log).</li>
    </ul>
    <p class="normal">The following YAML file contains the definition for an adapter multi-container Pod with multiple containers:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># alpine-with-adapter.yaml</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">pod-with-adapter</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">containers:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">alpine-writer</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">alpine:latest</span>
      <span class="hljs-attr">command:</span> [ <span class="hljs-string">"sh"</span>, <span class="hljs-string">"-c"</span>, <span class="hljs-string">"i=1; while true; do echo \"$(date) - log $i\" &gt;&gt; /var/log/app/app.log; i=$((i+1)); sleep 5; done"</span> ]
      <span class="hljs-attr">volumeMounts:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">log-volume</span>
          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/log/app</span>
      <span class="hljs-comment"># adapter container</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">log-adapter</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">alpine:latest</span>
      <span class="hljs-attr">command:</span> [ <span class="hljs-string">"sh"</span>, <span class="hljs-string">"-c"</span>, <span class="hljs-string">"while true; do cat /logs/app.log | sed 's/$/ PROCESSED/' &gt; /logs/processed_app.log; cat /logs/processed_app.log; sleep 10; done"</span> ]
      <span class="hljs-attr">volumeMounts:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">log-volume</span>
          <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/logs</span>
  <span class="hljs-attr">volumes:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">log-volume</span>
      <span class="hljs-attr">emptyDir:</span> {}
</code></pre>
    <p class="normal">Apply the YAML and check the Pod status as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f nginx-with-adapter.yaml
pod/pod-with-adapter created
</code></pre>
    <p class="normal">Once the Pod is created, the logs will be generated, and we can verify the logs from both containers. The following command will display the logs by the <code class="inlineCode">alpine-writer</code> container:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> -it pod-with-adapter -c alpine-writer -- <span class="hljs-con-built_in">head</span> -5 /var/log/app/app.log
Sun Jun 30 15:05:26 UTC 2024 - log 1
Sun Jun 30 15:05:31 UTC 2024 - log 2
Sun Jun 30 15:05:36 UTC 2024 - log 3
Sun Jun 30 15:05:41 UTC 2024 - log 4
Sun Jun 30 15:05:46 UTC 2024 - log 5
</code></pre>
    <p class="normal">We can<a id="_idIndexMarker507"/> also check the converted logs by using <code class="inlineCode">log-adapter</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> -it pod-with-adapter -c log-adapter -- <span class="hljs-con-built_in">head</span> -5 /logs/processed_app.log
Sun Jun 30 15:05:26 UTC 2024 - log 1 PROCESSED
Sun Jun 30 15:05:31 UTC 2024 - log 2 PROCESSED
Sun Jun 30 15:05:36 UTC 2024 - log 3 PROCESSED
Sun Jun 30 15:05:41 UTC 2024 - log 4 PROCESSED
Sun Jun 30 15:05:46 UTC 2024 - log 5 PROCESSED
</code></pre>
    <p class="normal">By using the adapter containers, it is possible to handle complex operations without modifying your original application containers.</p>
    <p class="normal">Before we conclude the chapter, in the next section, let us learn about one more feature in Kubernetes related to multi-container Pods.</p>
    <h1 class="heading-1" id="_idParaDest-215">Sidecars versus Kubernetes Native Sidecars</h1>
    <p class="normal">Traditionally, sidecars in Kubernetes have been regular containers deployed alongside the main <a id="_idIndexMarker508"/>application in a Pod, as we learned in the previous sections. This approach offers additional functionalities but has limitations. For instance, sidecars might continue running even after the main application exits, wasting resources. Additionally, Kubernetes itself isn’t inherently aware of sidecars and their relationship with the primary application.</p>
    <p class="normal">To address these limitations, Kubernetes v1.28 introduced a new concept: native sidecars. These leverage existing <code class="inlineCode">init</code> containers with special configurations. This allows you to define a <code class="inlineCode">restartPolicy</code> for containers within the Pod’s <code class="inlineCode">initContainers</code> section. These special sidecar containers can be independently started, stopped, or restarted without affecting the main application or other init containers, offering more granular control over their life cycle.</p>
    <p class="normal">The following Deployment definition file explains how native sidecar containers can be configured in Kubernetes:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-string">...&lt;removed</span> <span class="hljs-string">for</span> <span class="hljs-string">brevity&gt;...</span>
    <span class="hljs-attr">spec:</span>
      <span class="hljs-attr">containers:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">myapp</span>
          <span class="hljs-attr">image:</span> <span class="hljs-string">alpine:latest</span>
          <span class="hljs-attr">command:</span> [<span class="hljs-string">'sh'</span>, <span class="hljs-string">'-c'</span>, <span class="hljs-string">'while true; do echo "logging" &gt;&gt; /opt/logs.txt; sleep 1; done'</span>]
          <span class="hljs-attr">volumeMounts:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">data</span>
              <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/opt</span>
      <span class="hljs-attr">initContainers:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">logshipper</span>
          <span class="hljs-attr">image:</span> <span class="hljs-string">alpine:latest</span>
          <span class="code-highlight"><strong class="hljs-attr-slc">restartPolicy:</strong><strong class="hljs-slc"> </strong><strong class="hljs-string-slc">Always</strong></span>
          <span class="hljs-attr">command:</span> [<span class="hljs-string">'sh'</span>, <span class="hljs-string">'-c'</span>, <span class="hljs-string">'tail -F /opt/logs.txt'</span>]
          <span class="hljs-attr">volumeMounts:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">data</span>
              <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/opt</span>
      <span class="hljs-attr">volumes:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">data</span>
          <span class="hljs-attr">emptyDir:</span> {}
</code></pre>
    <p class="normal">This<a id="_idIndexMarker509"/> approach ensures synchronized startup and shutdown of the sidecar with the main container, optimizing resource usage. More importantly, Kubernetes gains awareness of the sidecar’s role in the Pod, potentially enabling future features for tighter integration.</p>
    <p class="normal">By leveraging multi-container Pods with init containers, sidecars, and the adapter or ambassador patterns, Kubernetes empowers you to build complex applications as modular units. This streamlines deployments and promotes efficient resource utilization within your containerized environment.</p>
    <h1 class="heading-1" id="_idParaDest-216">Summary</h1>
    <p class="normal">This chapter was quite a long one, but you should now have a good understanding of what Pods are and how to use them, especially when it comes to managing multiple containers in the same Pod.</p>
    <p class="normal">We recommend that you focus on mastering the declarative way of creating Kubernetes resources. As you have noticed in this chapter, the key to achieving the most complex things with Kubernetes resides in writing YAML files. One example is that you simply cannot easily create a multi-container Pod without writing YAML files.</p>
    <p class="normal">This chapter complements the previous one: <em class="chapterRef">Chapter 4</em>, <em class="italic">Running Your Containers in Kubernetes</em>. You need to understand that everything we will do with Kubernetes will be Pod management because everything in Kubernetes revolves around them. Keep in mind that containers are never created directly, but always through a Pod object, and that all the containers within the same Pod are created on the same Kubernetes node. If you understand that, then you can continue to the next chapter!</p>
    <p class="normal">In the next chapter, we’re going to cover another important aspect of Kubernetes called namespaces.</p>
    <h1 class="heading-1" id="_idParaDest-217">Further reading</h1>
    <ul>
      <li class="bulletList">How Pods manage multiple containers: <span class="url">https://kubernetes.io/docs/concepts/workloads/pods/#how-pods-manage-multiple-containers</span></li>
      <li class="bulletList">Kubernetes volumes: <a href="https://kubernetes.io/docs/concepts/storage/volumes/"><span class="url">https://kubernetes.io/docs/concepts/storage/volumes/</span></a></li>
      <li class="bulletList">Sidecar containers: <a href="https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/ "><span class="url">https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/</span></a></li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-218">Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussions with the authors and other readers:</p>
    <p class="normal"><a href="https://packt.link/cloudanddevops"><span class="url">https://packt.link/cloudanddevops</span></a></p>
    <p class="normal"><img alt="" src="image/QR_Code1190011064790816561.png"/></p>
  </div>
</body></html>