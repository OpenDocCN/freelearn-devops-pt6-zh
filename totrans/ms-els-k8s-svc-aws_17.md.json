["```\ndata \"aws_caller_identity\" \"current\" {}\nresource \"aws_cloudwatch_dashboard\" \"simple_Dashboard\" {\n  dashboard_name = \"EKS-Dashboard\"\n  dashboard_body = <<EOF\n{\"widgets\": [{widget1},{widget2}]}\nEOF }\n```", "```\n{ \"type\": \"explorer\",\n  \"width\": 24,\n   \"height\": 2,\n   \"x\": 0,\n   \"y\": 0,\n            \"properties\": {\n                \"metrics\": [\n                    { \"metricName\": \"CPUUtilization\",\n                        \"resourceType\": \"AWS::EC2::Instance\",\n                        \"stat\": \"Average\"\n                    },\n                    {. \"metricName\": \"NetworkOut\",\n                        \"resourceType\": \"AWS::EC2::Instance\",\n                        \"stat\": \"Average\"\n                    }],\n                \"region\":\"eu-central-1\",\n                \"aggregateBy\": {\n                    \"key\": \"eks:nodegroup-name\",\n                    \"func\": \"MAX\"\n                },\n                \"labels\": [\n                    {\n                        \"key\": \"eks:cluster-name\",\n                        \"value\": \"myipv4cluster\"\n                    }\n                ],\n                \"widgetOptions\": {\n                    \"legend\": {\n                        \"position\": \"bottom\"\n                    },\n                    \"view\": \"timeSeries\",\n                    \"rowsPerPage\": 1,\n                    \"widgetsPerRow\": 2\n                },\n                \"period\": 60,\n                \"title\": \"Cluster EC2 Instances (aggregated)\"\n            }}\n```", "```\n$ aws eks update-cluster-config --region eu-central-1 --name myipv4cluster --logging\n'{\"clusterLogging\":[{\"types\":[\"audit\",\"authenticator\"],\"enabled\":true}]}'\n{\n    \"update\": {\n        \"status\": \"InProgress\",\n        \"errors\": [],\n……\n        \"type\": \"LoggingUpdate\",\n        \"id\": \"223148bb-8ec1-4e58-8b0e-b1c681c765a3\",\n        \"createdAt\": 1679304779.614}}\n```", "```\n$ aws eks describe-update --region eu-central-1 --name myipv4cluster \\\n    --update-id 223148bb-8ec1-4e58-8b0e-b1c681c765a3\n{\n    \"update\": {\n        \"status\": \"Successful\",\n        \"errors\": [],\n…..\n        \"type\": \"LoggingUpdate\",\n        \"id\": \"223148bb-8ec1-4e58-8b0e-b1c681c765a3\",\n        \"createdAt\": 1679304779.614\n    }}\n```", "```\n$ kubectl get --raw \"/apis/metrics.k8s.io/v1beta1/nodes\" | jq '.items[0]'\n{\"metadata\": {\n    \"name\": \"ip-1.2.3.4.eu-central-1.compute.internal\",\n    \"creationTimestamp\": \"2023-03-18T15:23:51Z\",\n    \"labels\": {\n      ….\n      \"failure-domain.beta.kubernetes.io/region\": \"..1\",\n    }\n  },\n  \"timestamp\": \"2023-03-18T15:23:40Z\",\n  \"window\": \"20.029s\",\n  \"usage\": {\n    \"cpu\": \"48636622n\",\n    \"memory\": \"1562400Ki\"\n  }}\n```", "```\n$ ClusterName=myipv4cluster\n$ RegionName=eu-central-1\n$ FluentBitHttpPort='2020'\n$ FluentBitReadFromHead='Off'\n$ [[ ${FluentBitReadFromHead} = 'On' ]] && FluentBitReadFromTail='Off'|| FluentBitReadFromTail='On'\n[$ [ -z ${FluentBitHttpPort} ]] && FluentBitHttpServer='Off' || FluentBitHttpServer='On'\n$ curl https://raw.githubusercontent.com/aws-samples/amazon-cloudwatch-container-insights/latest/k8s-deployment-manifest-templates/deployment-mode/daemonset/container-insights-monitoring/quickstart/cwagent-fluent-bit-quickstart.yaml | sed 's/{{cluster_name}}/'${ClusterName}'/;s/{{region_name}}/'${RegionName}'/;s/{{http_server_toggle}}/\"'${FluentBitHttpServer}'\"/;s/{{http_server_port}}/\"'${FluentBitHttpPort}'\"/;s/{{read_from_head}}/\"'${FluentBitReadFromHead}'\"/;s/{{read_from_tail}}/\"'${FluentBitReadFromTail}'\"/' | kubectl apply -f –\n% Total%Received%Xferd Average Speed Time Time Time  Current\n100 16784  100 16784    0     0  95087      0 … 95363\n…\ndaemonset.apps/fluent-bit created\n```", "```\n$ kubectl get po -n amazon-cloudwatch\nNAME                     READY   STATUS    RESTARTS   AGE\ncloudwatch-agent-6zl6c   1/1     Running   0          3m32s\ncloudwatch-agent-xp45k   1/1     Running   0          3m32s\nfluent-bit-vl29d         1/1     Running   0          3m32s\nfluent-bit-vpswx         1/1     Running   0          3m32s\n```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: logger\n  namespace: logger-app\nspec:\n  containers:\n  - image: busybox\n    command: [\"/bin/sh\"]\n    args: [\"-c\", \"for i in `seq 4`; do echo 'Logging Message';done\"]\n    imagePullPolicy: IfNotPresent\n    name: busybox\n  restartPolicy: Never\n```", "```\n$ kubectl create namespace logger-app\n$ kubectl create -f logger.yaml\n$ kubectl logs logger -n logger-app\nLogging Message\nLogging Message\nLogging Message\nLogging Message\n```", "```\nresource \"aws_prometheus_workspace\" \"myamp\" {\n  alias = \"myamp\"\n}\n```", "```\n$ aws amp list-workspaces\n{    \"workspaces\": [{..\n            \"alias\": \"myamp\",\n            \"workspaceId\": \"ws-503025bc-01d5-463c-9157-11\",\n            \"createdAt\": 1679741187.4,\n            \"arn\": \"arn:aws:aps:eu-central-1:22:workspace/ws-503025bc-..}]\n$ aws amp describe-workspace --workspace-id ws-503025bc-01d5-463c-9157-11\n{..\n        \"prometheusEndpoint\": \"https://aps-workspaces.eu-central-1.amazonaws.com/workspaces/ws-503025bc-01d5-463c-9157-11/\",\n        \"alias\": \"myamp\",\n        \"workspaceId\": \"ws-503025bc-01d5-463c-9157-11\",\n        \"arn\": \"arn:aws:aps:eu-central-1:22:workspace/ws-503025bc-01d5-463c-9157-11\",\n        \"createdAt\": 1679741187.4\n}}}\n```", "```\n    $ kubectl create ns prometheus\n    namespace/prometheus created\n    $ eksctl create iamserviceaccount --name amp-iamproxy-ingest-role \\\n    --namespace prometheus --cluster myipv4cluster \\\n    --attach-policy-arn arn:aws:iam::aws:policy/AmazonPrometheusRemoteWriteAccess \\\n    --approve --override-existing-serviceaccounts\n    …..\n    2023-03-25 16:02:19 created serviceaccount \"prometheus/amp-iamproxy-ingest-role\"\n    ```", "```\n    $ kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.8.2\n    …..\n    validatingwebhookconfiguration.admissionregistration.k8s.io/cert-manager-webhook created\n    $ kubectl get po -n cert-manager\n    NAME            READY   STATUS    RESTARTS   AGE\n    cert-manager-12-5k4kx    1/1    Running   0          47s\n    cert-manager-cainjector-12-kj8w5   1/1  Running       47s\n    cert-manager-webhook-12-bptdx      1/1  Running       47s\n    ```", "```\n    $ kubectl apply -f https://amazon-eks.s3.amazonaws.com/docs/addons-otel-permissions.yaml\n    namespace/opentelemetry-operator-system created\n    clusterrole.rbac.authorization.k8s.io/eks:addon-manager-otel created\n    clusterrolebinding.rbac.authorization.k8s.io/eks:addon-manager-otel created\n    role.rbac.authorization.k8s.io/eks:addon-manager created\n    rolebinding.rbac.authorization.k8s.io/eks:addon-manager created\n    ```", "```\n    $ CLUSTER_NAME=myipv4cluster\n    $ aws eks create-addon --addon-name adot --addon-version v0.51.0-eksbuild.1 --cluster-name $CLUSTER_NAME\n    {\"addon\": {\n            \"status\": \"CREATING\",\n    ..\n            \"createdAt\": 1679761283.129}}\n    $ aws eks describe-addon --addon-name adot --cluster-name $CLUSTER_NAME | jq .addon.status\n    \"ACTIVE\"\n    ```", "```\n    $ AMP_REMOTE_WRITE_URL=https://aps-workspaces.eu-central-1.amazonaws.com/workspaces/ws-503025bc-01d5-463c-9157-11/api/v1/remote_write\n    $ AWS_REGION=eu-central-1\n    $ curl -O https://raw.githubusercontent.com/aws-samples/one-observability-demo/main/PetAdoptions/cdk/pet_stack/resources/otel-collector-prometheus.yaml\n      % Total    % Received % Xferd  Average Speed   …\n    100 12480  100 12480    0     0  …\n    $ sed -i -e s/AWS_REGION/$AWS_REGION/g otel-collector-prometheus.yaml\n    $ sed -i -e s^AMP_WORKSPACE_URL^$AMP_REMOTE_WRITE_URL^g otel-collector-prometheus.yamls\n    ```", "```\n    $ kubectl apply -f ./otel-collector-prometheus.yaml\n    opentelemetrycollector.opentelemetry.io/observability created\n    clusterrole.rbac.authorization.k8s.io/otel-prometheus-role created\n    clusterrolebinding.rbac.authorization.k8s.io/otel-prometheus-role-binding created\n    $ kubectl get all -n prometheus\n    NAME     READY   STATUS    RESTARTS   AGE\n    pod/observability-collector-123   1/1     Running      110s\n    NAME  TYPE  CLUSTER-IP  EXTERNAL-IP   PORT(S)    AGE\n    service/observability-collector-monitoring   ClusterIP   10.100.154.149   <none>        8888/TCP   110s\n    NAME   READY   UP-TO-DATE   AVAILABLE   AGE\n    deployment.apps/observability-collector   1/1 110s\n    NAME        DESIRED   CURRENT   READY   AGE\n    replicaset.apps/observability-collector-123   1   1 110s\n    ```", "```\n    $ pip3 install awscurl\n    Defaulting to user installation because normal site-packages is not writeable\n    Collecting awscurl\n      Downloading awscurl-0.26-py3-none\n    ….\n    $ export AMP_QUERY_ENDPOINT=https://aps-workspaces.eu-central-1.amazonaws.com/workspaces/ws-503025bc-01d5-463c-9157-11/api/v1/query\n    $ awscurl -X POST --region eu-central-1  --service aps \"$AMP_QUERY_ENDPOINT?query=up\"  | jq .\n    {\"status\": \"success\",\n      \"data\": {\n        \"resultType\": \"vector\",\n        \"result\": [\n          {\n            \"metric\": {\n              \"__name__\": \"up\",\n              \"app\": \"cert-manager\",\n              \"app_kubernetes_io_component\": \"controller\",\n              \"app_kubernetes_io_instance\": \"cert-manager\",\n              \"app_kubernetes_io_name\": \"cert-manager\",\n              \"app_kubernetes_io_version\": \"v1.8.2\",\n              \"instance\": \"192.168.68.6:9402\",\n              \"job\": \"kubernetes-pods\",\n              \"kubernetes_namespace\": \"cert-manager\",\n              \"kubernetes_pod_name\": \"cert-manager-12-5k4kx\",\n              \"pod_template_hash\": \"66b646d76\"},\n            \"value\": [\n              1679763539.307,\n              \"1\"]},\n          {\n            \"metric\": {\n              \"__name__\": \"up\",\n    …\n           ]}]}}\n    ```", "```\nresource \"aws_iam_role\" \"assume\" {\n  name = \"grafana-assume\"\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      { Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Sid    = \"\"\n        Principal = {\n          Service = \"grafana.amazonaws.com\"\n        }\n      },\n    ]\n  })\n}\nresource \"aws_iam_policy\" \"policy\" {\n  name        = \"amgadditional\"\n  path        = \"/\"\n  description = \"additional policies\"\n  policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = [\n          \"aps:ListWorkspaces\",\n          \"aps:DescribeWorkspace\",\n          \"aps:QueryMetrics\",\n          \"aps:GetLabels\",\n          \"aps:GetSeries\",\n          \"aps:GetMetricMetadata\"\n        ]\n        Effect   = \"Allow\"\n        Resource = \"*\"\n      },]})}\nresource \"aws_iam_role_policy_attachment\" \"amgattachement\" {\n  role       = aws_iam_role.assume.name\n  policy_arn = aws_iam_policy.policy.arn\n}\n```", "```\nresource \"aws_grafana_workspace\" \"myamg\" {\n  account_access_type      = \"CURRENT_ACCOUNT\"\n  authentication_providers = [\"AWS_SSO\"]\n  permission_type          = \"SERVICE_MANAGED\"\n  role_arn                 = aws_iam_role.assume.arn\n  data_sources              = [\"PROMETHEUS\",\"CLOUDWATCH\"]\n}\nresource \"aws_grafana_role_association\" \"admin\" {\n  role         = \"ADMIN\"\n  user_ids     = [\"73847832-1031-70a6-d142-6fbb72a512f0\"]\n  workspace_id = aws_grafana_workspace.myamg.id\n}\n```", "```\n$ kubectl get sa amp-iamproxy-ingest-role -n prometheus -o json\n{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"ServiceAccount\",\n    \"metadata\": {\n        \"annotations\": {\n            \"eks.amazonaws.com/role-arn\": \"arn:aws:iam::112233:role/eksctl-myipv4cluster-addon-iamserviceaccount-Role1-1V5TZL1L6J58X\"\n….\n}\n```", "```\nreceivers:\n      otlp:\n        protocols:\n          grpc:\n            endpoint: 0.0.0.0:4317\n          http:\n            endpoint: 0.0.0.0:4318\nprocessors:\n      batch/traces:\n        timeout: 1s\n        send_batch_size: 50\nexporters:\n      awsxray:\n        region: eu-central-1\npipelines:\n      traces:\n        receivers: [otlp]\n        processors: [batch/traces]\n        exporters: [awsxray]\n```", "```\n$ kubectl logs observability-collector-11 -n prometheus\n2023/03/26 17:05:54 AWS OTel Collector version: v0.20.0\n….\n2023-03-26T17:05:54.973Z        info    pipelines/pipelines.go:82       Exporter started.       {\"kind\": \"exporter\", \"data_type\": \"traces\", \"name\": \"awsxray\"}\n…\n2023-03-26T17:05:54.973Z        info    pipelines/pipelines.go:82       Exporter started.\n2023-03-26T17:05:54.974Z        info    pipelines/pipelines.go:102      Receiver is starting... {\"kind\": \"receiver\", \"name\": \"otlp\", \"pipeline\": \"traces\"}\n2023-03-26T17:05:54.974Z        info    otlpreceiver/otlp.go:70 Starting GRPC server on endpoint 0.0.0.0:4317   {\"kind\": \"receiver\", \"name\": \"otlp\", \"pipeline\": \"traces\"}\n2023-03-26T17:05:54.974Z        info    otlpreceiver/otlp.go:88 Starting HTTP server on endpoint 0.0.0.0:4318   {\"kind\": \"receiver\", \"name\": \"otlp\", \"pipeline\": \"traces\"}\n…..\n2023-03-26T17:05:54.975Z        info    service/collector.go:128        Everything is ready. Begin running and processing data.\n```", "```\n$ kubectl create ns adot\nnamespace/adot created\n```", "```\n….\n---\napiVersion: apps/v1\nkind: Deployment\n…\n    spec:\n      containers:\n        - env:\n            - name: AWS_REGION\n              value: eu-central-1\n            - name: LISTEN_ADDRESS\n              value: 0.0.0.0:4567\n            - name: OTEL_EXPORTER_OTLP_ENDPOINT\n              value: http://observability-collector.prometheus:4317\n            - name: OTEL_RESOURCE_ATTRIBUTES\n              value: service.namespace=adot,service.name=emitter\n          image: public.ecr.aws/aws-otel-test/aws-otel-java-spark:1.17.0\n…..\n```", "```\n$ kubectl create -f sample-app-modified.yaml -n adot\nservice/sample-app created\ndeployment.apps/sample-app created\n$ kubectl get po -n adot\nNAME                         READY   STATUS    RESTARTS   AGE\nsample-app-7cbb94b84-ckhdc   1/1     Running   0          8s\n```", "```\n….\n- args:\n            - /bin/bash\n            - -c\n            - sleep 10; while :; do curl sample-app:4567/outgoing-http-call > /dev/null 1>&1; sleep 2; curl ot-sample-app:4567/aws-sdk-call > /dev/null 2>&1; sleep 5; done\n```", "```\n$ kubectl create  -f traffic-generator.yaml -n adot\nservice/traffic-generator created\ndeployment.apps/traffic-generator created\n$ kubectl get all  -n adot\nNAME                  READY   STATUS    RESTARTS   AGE\npod/sample-app-7cbb94b84-ckhdc    1/1     Running   0    18m\npod/traffic-generator-123-ch4x2   1/1     Running   0    10m\n```"]