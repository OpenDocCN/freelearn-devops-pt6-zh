- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying Real-World Projects with GitOps on Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you will embark on a practical journey that bridges the gap
    between theoretical knowledge and real-world knowledge application. As you delve
    into the intricate process of setting up a GitOps and Kubernetes-based development
    environment, you will gain firsthand experience in designing, developing, and
    deploying an application within this innovative framework. Through detailed guidance
    on architectural design, **Continuous Integration and Continuous Delivery** (**CI/CD**)
    processes, application scaling, and security, this chapter aims to equip you with
    the essential skills and insights needed to implement these cutting-edge technologies
    effectively in your projects. Whether you’re looking to enhance your organizational
    capabilities or to refine your personal technical expertise, the comprehensive
    real-life example provided here will serve as an invaluable resource for anyone
    aspiring to master GitOps and Kubernetes in practical settings.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, our focus will be on the following key areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Establishing a GitOps and Kubernetes development environment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing CI/CD with GitOps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Designing for scalability and efficiency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resource management and scalability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring and securing your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter builds on your existing knowledge of Git, Kubernetes, and GitOps
    tools such as **Argo CD** and Flux CD, which you acquired in earlier chapters.
    We will use an **Azure AKS** cluster deployed by Terraform using a GitHub workflow.
    Ensure that you have access to a Kubernetes setup and are familiar with CI/CD
    principles to fully benefit from the exercises.
  prefs: []
  type: TYPE_NORMAL
- en: 'All necessary code and resources are provided in the [*Chapter 11*](B22100_11.xhtml#_idTextAnchor209)
    folder of our dedicated GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/PacktPublishing/Implementing-GitOps-with-Kubernetes](https://github.com/PacktPublishing/Implementing-GitOps-with-Kubernetes)'
  prefs: []
  type: TYPE_NORMAL
- en: Establishing a GitOps and Kubernetes development environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Establishing a proper development environment is crucial for the successful
    implementation of GitOps practices. This environment serves as the backbone for
    both development and operations teams, enabling seamless integration and continuous
    delivery of applications. A well-configured development environment ensures that
    all changes to applications and infrastructure are version-controlled, traceable,
    and aligned with the declarative configurations stored in Git. This consistency
    between the development environment and production setups reduces the likelihood
    of errors and deployment failures, fostering a more reliable and robust delivery
    pipeline. By emphasizing the importance of a correct setup from the outset, teams
    can leverage GitOps to its fullest potential, ensuring that automated processes
    govern deployments and infrastructure management efficiently and effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Installing and configuring Kubernetes for GitOps involves setting up your Kubernetes
    cluster in a way that integrates seamlessly with GitOps tools such as Flux CD
    (see the *Flux integration with Kubernetes* section in [*Chapter 4*](B22100_04.xhtml#_idTextAnchor065))
    or Argo CD (see the *Argo CD integration with Kubernetes* section in [*Chapter
    4*](B22100_04.xhtml#_idTextAnchor065)). What follows is a step-by-step guide that
    covers the setup process, ensuring that your Kubernetes environment is ready for
    a GitOps workflow:'
  prefs: []
  type: TYPE_NORMAL
- en: Install a Kubernetes cluster and choose your environment. For learning and development,
    consider using **K3s** (refer to the *Exploring K3s as a lightweight Kubernetes
    distribution* section in [*Chapter 2*](B22100_02.xhtml#_idTextAnchor027)) or **minikube**.
    Both are suitable for running Kubernetes locally on your machine. For production
    or more scalable environments, consider cloud solutions such as **Amazon EKS**,
    Azure AKS, or **Google GKE**. To install minikube, follow the official minikube
    installation guide at [https://minikube.sigs.k8s.io](https://minikube.sigs.k8s.io).
    For deploying Kubernetes on cloud platforms, refer to the specific setup guides
    provided by the respective cloud providers. For the real-world scenario described
    in this chapter, we will use an AKS cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Verify installation. Ensure that `kubectl`, the Kubernetes command-line tool,
    is installed and configured to communicate with your cluster. You can verify this
    by running the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This command should return the cluster details confirming that Kubernetes is
    up and running:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set up your namespace. It’s good practice to create a dedicated namespace for
    your GitOps tools:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Set up permissions. Set up **Role-Based Access Control** (**RBAC**) rules to
    ensure that your GitOps tools have the necessary permissions to manage resources.
    Most GitOps tools have specific RBAC configurations outlined in their setup guides.
    We will see a concrete example of how to set up RBAC in the *Configuring Kubernetes
    RBAC for user and role management* section of this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install your GitOps tool. Depending on your preference, select from tools such
    as Flux CD, Argo CD, Helm, or Kustomize. Each tool has unique strengths and supportive
    community backing. For more details about the mentioned GitOps tools, refer to
    the *Overview of popular GitOps tools* section in [*Chapter 4*](B22100_04.xhtml#_idTextAnchor065).
    Additionally, you can explore the *A deep dive into Helm and Kustomize*, *Argo
    CD integration with Kubernetes*, and *Flux CD integration with Kubernetes* sections
    of the same chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up a Git repository. Configure the GitOps tool to track your Git repository
    where your Kubernetes manifests are stored. For guidance, refer to the *Kubernetes
    deployment with Azure DevOps* or the *Kubernetes deployment with AWS CodePipeline*
    section, both in [*Chapter 4*](B22100_04.xhtml#_idTextAnchor065). This setup process
    involves pointing the tool to your repository and specifying which branch and
    path to monitor for changes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Validate and test. Start by deploying a simple application using your GitOps
    tool to confirm that changes in your Git repository automatically trigger deployments
    in your Kubernetes cluster. Monitor the deployment using the GitOps tool’s dashboard
    or CLI to ensure that the application is deployed and running as expected. Test
    updates and rollbacks by modifying the application’s manifest in your Git repository
    and noting whether the changes are automatically implemented.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Most of the pipeline points have already been covered in more detail in previous
    chapters. They will be revisited in the next section, where will see how to implement
    a real-world scenario for CI/CD with GitOps.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing CI/CD with GitOps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To implement a real-world CI/CD GitOps scenario, we need an application that
    no longer uses mocked data but instead utilizes concrete data.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we will expose a backend service for a weather application
    that fetches data from a real weather service, such as **OpenWeatherMap** ([https://openweathermap.org/](https://openweathermap.org/)),
    to the public internet.
  prefs: []
  type: TYPE_NORMAL
- en: Given that the requirements for setting up our GitOps environment (installing
    a Kubernetes cluster and choosing your environment, verifying installation, and
    installing your GitOps tool) have already been met in the previous section of
    this chapter, the next step is to create a new GitHub repository. For example,
    you might create `gitops-for-real-world`, with a directory named `Step-01`. This
    directory will be used to add the code and files for subsequent steps.
  prefs: []
  type: TYPE_NORMAL
- en: Before proceeding, you need to create a free account with the `OpenWeatherMap`
    service or another similar service of your choice. Services like these typically
    require a token to query their API, which is used for authentication and billing
    purposes. It’s crucial to keep this token *confidential* and not share it. Please
    refer to the `OpenWeatherMap` documentation to create a new token. Soon, we will
    add this token as a **secret** in the Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Final objective and implementation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To achieve our final objective, this section and the ones that follow will demonstrate
    the use of a **Python Flask application**, packaged as a **Docker image**. This
    image is built with a new tag at each commit and deployed on an Azure AKS cluster,
    which is provisioned automatically by the pipeline using Terraform for the **Infrastructure
    as Code** (**IaC**) component. Initially, the entire deployment chain—both IaC
    and the application—will be managed entirely by our GitHub CI/CD pipeline. Later,
    we will transition to using Argo CD for the deployment while keeping the CI processes
    within the GitHub workflow.
  prefs: []
  type: TYPE_NORMAL
- en: Ultimately, to test our service after it has been exposed to the public internet,
    we will perform **weather** requests for a specified city via the query string
    in a URL, such as [http://public-ip/weather?city=zurich](http://public-ip/weather?city=zurich).
    The response will be in JSON format, which can be rendered directly in the browser
    or with tools such as **curl**.
  prefs: []
  type: TYPE_NORMAL
- en: Our pipeline will be developed as a GitHub workflow and will be composed as
    illustrated in *Figure 11**.1*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – A GitHub workflow pipeline](img/B22100_11_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 – A GitHub workflow pipeline
  prefs: []
  type: TYPE_NORMAL
- en: CI/CD pipeline using GitHub Actions and Terraform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The pipeline in *Figure 11**.1* leverages Terraform for infrastructure management
    and deploys a Dockerized application to an AKS cluster, providing a practical
    example of modern DevOps practices. The code of the pipeline is too long to be
    explicitly added as content in this chapter. What follows are some important aspects
    that should be considered for a better understanding of that. The workflow description
    is contained in the `gitops-for-real-ci-cd-pipeline.yml` file in the `.github/workflows/`
    directory of the repository accompanying this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Workflow trigger conditions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The pipeline is configured to trigger on any push or pull request to the main
    branch with one exception: changes exclusively in the `Step-01/deployment` directory
    do not initiate the workflow. This precaution prevents redundant runs when only
    Kubernetes manifest files are updated, ensuring efficient use of resources and
    avoiding potential conflicts in continuous deployment scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: Terraform plan and apply
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The workflow begins with the `terraform-plan` job. This job executes several
    critical steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Environment setup**: The job initializes by checking out the repository and
    setting up the Azure CLI with credentials stored securely as GitHub secrets. This
    step ensures that the workflow has access to manage resources in Azure.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: All the passwords, tokens, and other sensitive information used in the pipeline
    need to be configured as GitHub Actions Secrets, as illustrated in *Figure 11**.2*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 11.2 – GitHub secrets on the Actions secrets and variables page](img/B22100_11_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.2 – GitHub secrets on the Actions secrets and variables page
  prefs: []
  type: TYPE_NORMAL
- en: '`terraform init` to prepare the Terraform environment, configuring backend
    storage for Terraform state files in Azure Blob Storage. The following code is
    extracted from the main pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`terraform plan`), which is reviewed automatically to determine whether there
    are changes to apply. The plan is saved as an `terraform-apply` job.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: GitHub artifacts
  prefs: []
  type: TYPE_NORMAL
- en: An artifact in GitHub Actions is a file or a collection of files produced during
    a workflow run. Artifacts can include binary files, logs, test results, or any
    other type of data that needs to be stored after a job is completed. These artifacts
    are typically used for storing build and test outputs to be used for debugging,
    deployment, or further processing in subsequent steps or future runs. GitHub stores
    these artifacts for a specified period, allowing them to be downloaded or shared
    across different jobs within the same workflow. This feature facilitates effective
    CI/CD practices by ensuring that outputs from one part of a workflow can easily
    be accessed and utilized in other parts, enhancing automation and continuity throughout
    the software development life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Following planning, the `terraform-apply` job applies the approved changes to
    the infrastructure, ensuring that the actual state matches the expected state
    defined in the Terraform configurations. This part can take a few minutes due
    to the provisioning of the resources to Azure. Opening the Azure portal, the final
    provisioning should be similar to what is illustrated in *Figure 11**.3*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – Azure resources automatically provisioned by the GitHub workflow](img/B22100_11_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.3 – Azure resources automatically provisioned by the GitHub workflow
  prefs: []
  type: TYPE_NORMAL
- en: Docker image build and push
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Parallel to infrastructure management, the `docker-build-and-push` job handles
    the application side:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Docker preparation**: The job sets up Docker environments using QEMU and
    Buildx, tools that enhance Docker’s capabilities on CI environments.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Step-01` directory and pushes it to Docker Hub, tagging it with the **commit
    SHA** for immutability and traceability, as illustrated in *Figure 11**.4*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.4 – A Docker repository containing the built images with tags corresponding
    to the SHA number](img/B22100_11_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.4 – A Docker repository containing the built images with tags corresponding
    to the SHA number
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes deployment
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After the Docker image is pushed and the infrastructure is ready, the `deploy-to-kubernetes`
    job proceeds:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl` with the credentials for the Kubernetes cluster managed in Azure,
    ensuring that commands are executed against the correct cluster, as reported in
    the following code:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Secrets and configurations**: It then deploys necessary Kubernetes secrets
    and configurations, such as API keys needed by the application, using best practices
    for secret management. The following code is extracted from the pipeline:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Idempotency
  prefs: []
  type: TYPE_NORMAL
- en: Idempotency, in the context of deploying resources, means that running the same
    deployment command multiple times will result in the same state without causing
    unintended changes or side effects after the initial application.
  prefs: []
  type: TYPE_NORMAL
- en: '`Step-01/deployment/backend-api-deployment.yaml`), which references the newly
    built Docker image, ensuring that the latest version of the application is deployed:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Beware!
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to access the remote AKS cluster from your local development, you
    need to login Azure and execute the following command: `az aks get-credentials
    --resource-group gitops-real-rg --``name gitops-real-aks`'
  prefs: []
  type: TYPE_NORMAL
- en: '**Testing**: Unlike local development, for this real-world example, we specified
    a **LoadBalancer** port in the deployment file, so AKS is automatically using
    a public IP address to expose our service to the public internet, as illustrated
    in *Figure 11**.5*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.5 – A public IP address used to expose the backand-api-service
    to the public internet](img/B22100_11_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.5 – A public IP address used to expose the backand-api-service to
    the public internet
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we can query our service using a URL like the one shown in *Figure
    11**.6* to obtain a response:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.6 – An example of querying the service for Zurich city using real
    weather data](img/B22100_11_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.6 – An example of querying the service for Zurich city using real
    weather data
  prefs: []
  type: TYPE_NORMAL
- en: What we have obtained so far is a fully working CI/CD pipeline that exposes
    a service to the real world. We want to take it a step further by separating the
    CI pipeline from the CD pipeline using ArgoCD, as described in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Using Argo CD for the continuous deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the world of modern software delivery, it’s crucial to ensure that our deployment
    practices are as reliable and scalable as possible. Argo CD, a declarative GitOps
    continuous delivery tool for Kubernetes, significantly enhances these aspects
    by automating deployment processes and syncing the desired application state defined
    in a Git repository with the production environment.
  prefs: []
  type: TYPE_NORMAL
- en: Transitioning to Argo CD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we will evolve our GitHub Actions workflow by transitioning
    the `deploy-app-to-kubernetes` stage to an `argo-cd-deployment` stage. The `argo-cd-deployment`
    stage in our GitHub Actions workflow encapsulates the following key operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Argo CD setup**: First, the workflow initializes Argo CD in the Kubernetes
    cluster if it’s not already installed. This includes setting up the necessary
    namespaces and applying the Argo CD installation manifests directly from the official
    sources.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Repository configuration**: The workflow then adds the Git repository containing
    the Kubernetes manifests to Argo CD. This step involves configuring Argo CD to
    monitor changes in the repository, which hosts the deployment definitions for
    the application.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Application deployment via Argo CD**: It then ensures that the specific namespace
    for the application is created and ready for deployment.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`argocd_deployment.yaml` file, which defines the Argo CD application. This
    manifest specifies the path to the Kubernetes deployment manifests within the
    Git repository, the revision target (e.g., `branch`), and synchronization policies.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Sync trigger**: Optionally, this step triggers a manual sync if immediate
    deployment is required, though typically Argo CD would automatically detect changes
    based on its polling strategy.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Managing downtime and ensuring continuity with Argo CD
  prefs: []
  type: TYPE_NORMAL
- en: When Argo CD experiences temporary downtime, the primary impact is on the synchronization
    and automated reconciliation of deployments in Kubernetes environments. During
    this period, any changes committed to the Git repository will not be synchronized
    with Kubernetes clusters, which means that updates, fixes, and new feature deployments
    are postponed. The automated reconciliation process, which ensures that the actual
    state of the Kubernetes environment matches the desired state specified in the
    Git repository, is also interrupted. This means that any discrepancies or configuration
    drifts that occur during the downtime will not be addressed until Argo CD is back
    online. Upon restoring Argo CD, it will automatically begin to process and apply
    all changes made during its downtime. The system will fetch the latest configurations
    from Git and proceed with the necessary reconciliations to align the Kubernetes
    clusters with the desired states from the repository. It’s important to note that
    the running applications themselves are not directly affected by Argo CD’s downtime;
    they will continue to operate as configured prior to the outage. However, to manage
    critical updates during such downtimes, teams might need to perform manual interventions,
    which should be handled carefully to avoid further complications once Argo CD
    resumes normal operation. Robust monitoring and alert systems are recommended
    to quickly detect any issues with Argo CD and to minimize the impact of such downtimes.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see the new workflow in action, we need to replace the contents of the `gitops-for-real-ci-cd-pipeline.yml`
    file in the `Step-02-ArgoCD-Deployment` folder with the contents of the file named
    in the same manner located in the `.github/workflows` subdirectory. We must then
    commit and push the updated code to trigger a workflow run, as illustrated in
    *Figure 11**.7*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.7 – A new workflow run is triggered after the commit and push of
    the new workflow definition](img/B22100_11_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.7 – A new workflow run is triggered after the commit and push of the
    new workflow definition
  prefs: []
  type: TYPE_NORMAL
- en: 'The external IP and the admin password that were automatically generated during
    the setup process can be found in the log of the `Setup ArgoCD on AKS` task, as
    illustrated in *Figure 11**.8*. Be careful: this kind of information should not
    be exposed in real production environments. It is just a shortcut for the scope
    of this example.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.8 – The Setup ArgoCD on AKS task log containing sensitive information](img/B22100_11_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.8 – The Setup ArgoCD on AKS task log containing sensitive information
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, we can log in to the admin UI of the deployed instance of Argo
    CD by typing [https://4.226.41.44/](https://4.226.41.44/) into your preferred
    browser (see *Figure 11**.9*):'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.9 – The Argo CD home page after logging in, showing the deployment
    of the backend-api-weather-app pod](img/B22100_11_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.9 – The Argo CD home page after logging in, showing the deployment
    of the backend-api-weather-app pod
  prefs: []
  type: TYPE_NORMAL
- en: Voilà! For this example, we didn’t activate **auto-sync**, so we just need to
    click on the **Sync Apps** button to synchronize our weather app application,
    as illustrated in *figure 11.10*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.10 – The Argo CD application is correctly synchronized with the
    GitHub repository](img/B22100_11_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.10 – The Argo CD application is correctly synchronized with the GitHub
    repository
  prefs: []
  type: TYPE_NORMAL
- en: 'To test the Argo CD synchronization process, try changing the number of replicas
    from `1` to `5` (for instance) in the `backend-api-deployment.yaml` file and pushing
    the change to GitHub. The workflow will not be triggered because we specified
    the following value:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: However, Argo CD will notice the out-of-sync state and a new synchronization
    will be needed. Now that we have our CI/CD pipeline in place and working perfectly,
    it is time to introduce the topics of scalability and efficiency in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Designing for scalability and efficiency
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will delve into designing for scalability and efficiency.
    These traits are essential in the architecture of modern applications, exemplified
    by our weather app. Scalability ensures that the application can handle growth,
    whether it’s an increasing number of users, data volume, or transaction frequency,
    without compromising performance. Efficiency involves optimizing resource use,
    which is crucial for minimizing costs and enhancing response times. We will explore
    architectural principles that support scalability, such as **microservices** and
    load balancing, and discuss how to manage compute, storage, and networking resources
    effectively. Additionally, we will look at tools and strategies to test scalability
    to ensure that the architecture can withstand real-world demands. By mastering
    these elements, you’ll learn how to design a scalable and efficient architecture
    that is well-suited for deployment on Kubernetes, enhancing the overall performance
    and reliability of applications such as our weather app.
  prefs: []
  type: TYPE_NORMAL
- en: Architectural principles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Architectural principles for designing scalable and efficient systems are critical
    in modern application development, especially as demands for performance and reliability
    increase. Key strategies include decoupling components to minimize dependencies,
    which facilitates easier maintenance and scaling. Emphasizing statelessness allows
    for the replication and distribution of components, enhancing the application’s
    resilience and responsiveness.
  prefs: []
  type: TYPE_NORMAL
- en: Load balancing is essential to distribute incoming network loads evenly across
    multiple systems, preventing any single server from becoming overwhelmed and increasing
    the application’s availability. Horizontal scaling, or scaling out by adding more
    instances rather than adding resources to a single instance, is more cost-effective
    and increases fault tolerance.
  prefs: []
  type: TYPE_NORMAL
- en: Database sharding partitions data into smaller, more manageable segments, which
    is particularly beneficial for large datasets or high throughput demands. Sharding
    is great for improving performance. Caching frequently accessed data reduces latency
    and backend load by serving common requests without redundant data processing.
  prefs: []
  type: TYPE_NORMAL
- en: Asynchronous processing of tasks enhances throughput and user experience by
    handling operations in a non-blocking manner. Adopting a microservices architecture
    allows for independent deployment, scaling, and management of each service. This
    modular approach not only boosts performance but also simplifies management as
    applications evolve, making it ideal for cloud-native environments managed by
    platforms such as Kubernetes. Although microservices architecture has been mentioned,
    it will not be part of the example discussed in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Microservices architecture
  prefs: []
  type: TYPE_NORMAL
- en: Microservices architecture is an architectural style that structures an application
    as a collection of loosely coupled services, each of which implements a specific
    business capability. This approach enables developers to build and deploy services
    independently, which enhances flexibility and accelerates development cycles.
    By breaking down an application into small, manageable components, microservices
    allow for more granular scaling and efficient resource utilization. Each service
    can be developed, deployed, and scaled independently, often using different programming
    languages and technologies that best suit the task at hand. This modularity improves
    fault isolation, making it easier to identify and fix issues without affecting
    the entire system. Moreover, microservices facilitate CI/CD practices, promoting
    a more agile and resilient development process. Overall, microservice architecture
    fosters a more robust and scalable application environment that is capable of
    adapting to evolving business needs and technological advancements.
  prefs: []
  type: TYPE_NORMAL
- en: Resource management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Effective resource management is crucial in application design and operation,
    especially in environments that aim to maximize efficiency and performance while
    minimizing costs. Managing compute, storage, and networking resources involves
    careful planning and orchestration to ensure that each component of an application
    has the necessary resources to perform optimally without wastage:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Compute management**: This involves provisioning the right amount of CPU
    and memory resources to meet the application’s requirements. Techniques such as
    **auto-scaling** and load balancing help distribute compute workloads evenly across
    the available infrastructure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage management**: This ensures that data storage resources are allocated
    efficiently, keeping data accessibility and redundancy in mind. This includes
    choosing appropriate storage types and implementing data partitioning strategies
    to enhance performance and scalability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Networking management**: This focuses on efficiently configuring network
    resources to ensure fast and secure data transfer between application components.
    Proper network configuration reduces latency and prevents bottlenecks, making
    it essential for real-time data processing and delivery.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Together, these resource management practices ensure that applications can scale
    effectively and remain robust under varying operational conditions. Implementing
    resource management strategies also involves monitoring and analyzing resource
    usage to make informed decisions about adjustments and improvements, ensuring
    that resources are utilized in the most efficient way possible.
  prefs: []
  type: TYPE_NORMAL
- en: Testing for scalability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Testing for scalability is crucial for ensuring that applications perform well
    under expected loads and can handle growth in users, transactions, and data efficiently.
    Scalability testing involves a variety of techniques to simulate different environments
    and stresses on the system to uncover potential issues before they impact users:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Load testing**: Simulates a specific expected number of concurrent users
    or transactions to assess how the application behaves under normal conditions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stress testing**: Pushes the application beyond its normal operational limits
    to discover its maximum capacity and understand its behavior under extreme conditions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Soak testing**: Runs the application under a heavy load for a prolonged period
    to identify issues such as memory leaks or slow degradation of performance'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Spike testing**: Checks the application’s ability to handle sudden and large
    spikes in traffic'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability testing**: Tests whether the application can scale up or down
    based on demand by gradually increasing the load and observing how additional
    resources affect the application’s capacity'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These tests often utilize automated testing tools and are conducted in staged
    environments that closely mimic real-world traffic patterns. Tools such as **Apache
    JMeter**, **LoadRunner**, and **Gatling**, along with cloud services such as **AWS
    CloudWatch** and **Google Cloud Monitoring**, are commonly employed to facilitate
    these tests. Through regular scalability testing across development and deployment
    phases, teams can ensure that their applications are robust, scalable, and ready
    to handle real-world operational demands.
  prefs: []
  type: TYPE_NORMAL
- en: Resources management and scalability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will continue to use the weather app to see how resource
    management, horizontal scaling, and scalability testing work in a real-world scenario.
    We can start with the optimization of resource usage.
  prefs: []
  type: TYPE_NORMAL
- en: Optimizing resource usage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To optimize resource usage in Kubernetes, setting up resource requests and
    limits is crucial. These settings ensure that pods receive the right amount of
    CPU and memory resources to function properly while also preventing any single
    application from consuming excessive cluster resources, which could affect other
    applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Requests**: These are the amount of resources Kubernetes guarantees for a
    container. If a container requires more resources than its request and they are
    available on the node, it can consume more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Limits**: This is the maximum amount of resources a container can use. If
    a container tries to exceed this limit, the system will throttle its CPU usage.
    If the container exceeds its memory limit, Kubernetes might terminate it, depending
    on the situation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To test the use of requests and limits, we can try to update the `Step-01/deployment/backend-api-deployment.yaml`
    file by adding the following code block immediately after `key:` `WEATHER_API_KEY
    row`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The previously mentioned code block specifies the resource requests and limits
    for a container. Here’s what each line means:'
  prefs: []
  type: TYPE_NORMAL
- en: '`requests`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cpu: "100m"`: This requests 100 millicores (where 1,000 m equals 1 CPU core)
    for the container'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`memory: "100Mi"`: This requests 100 mebibytes of memory'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`limits`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`cpu: "150m"`: This sets a limit of 150 millicores for CPU usage by the container'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`memory: "150Mi"`: This sets a memory limit of 150 mebibytes'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have defined requests and limits, in the next section, we will see
    how to implement the **Horizontal Pod Autoscaler** (**HPA**) in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing the HPA
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Implementing an HPA in Kubernetes is an effective way to automatically scale
    the number of pod replicas in a deployment, replication controller, or replica
    set based on observed CPU utilization or other select metrics such as memory usage
    or custom metrics. Here’s a step-by-step guide to setting up an HPA:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Ensure that the **Metrics Server**, which collects resource metrics from Kubelets
    and exposes them in Kubernetes through the Metrics API, is installed in the cluster.
    This is crucial for the HPA to make scaling decisions. We can install it with
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Setup will take a few minutes. At completion, verify the correct installation
    with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This command should return the deployment details confirming that the Metrics
    Server is up and running:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create an HPA that scales based on CPU utilization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This HPA is configured to maintain between `1` and `5` replicas of the pod,
    scaling up or down when the CPU utilization reaches 50%.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create a new `hpa.yaml` file in the `Step-01/deployment` folder with the content
    that we have described. Commit and push the code, then wait for the Argo CD application
    synchronization or force it if auto-sync is off.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.11– The Argo CD application synchronized with the HPA configuration
    in place](img/B22100_11_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.11– The Argo CD application synchronized with the HPA configuration
    in place
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following command to monitor the status and effectiveness of your HPA:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will show the current number of replicas and whether the HPA is in the
    process of scaling up or down based on the current CPU utilization against the
    target set.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Testing for scalability – an example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we have implemented the HPA and set up monitoring for it, our next
    step is to observe how Kubernetes dynamically scales the number of pods in response
    to changes in CPU utilization. By simulating varying loads, we can watch the HPA
    adjust the pod count to maintain optimal performance. This process ensures that
    our application scales efficiently, handling increases or decreases in demand
    without manual intervention. Understanding this behavior is crucial for optimizing
    resource management and cost-effectiveness within our Kubernetes environment.
    What follows is a guided step-by-step testing scenario:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Bash script for testing HPA. Use the `curl` command to make requests
    to the exposed weather service using various cities and include a random value
    in the query string to avoid caching. You can use the `hpa-testing.sh` script
    present in the repository accompanying this chapter as reference. Before executing
    the script, update `$baseUrl` to match your weather service’s URL. This might
    look as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run this Bash script:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Open a new terminal and make the script executable with the following:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the HPA status (see the sixth point in the *Implementing the HPA* section
    of this chapter). Use the following command to check the HPA status:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should see the current number of replicas and their scaling activities
    based on the CPU utilization:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The HPA monitors the CPU utilization of the deployment and adjusts the number
    of pods accordingly to ensure optimal performance.
  prefs: []
  type: TYPE_NORMAL
- en: Initially, the CPU utilization is marked as `<unknown>`, likely due to metrics
    not being available or still being initialized. When the utilization stabilizes
    at 5%, which matches the target set in the HPA, there’s no change in the number
    of replicas and they remain at one. As CPU usage increases to 20%—well above the
    5% target—the HPA reacts by scaling up the number of replicas from `1` to `4`
    to handle the increased load.
  prefs: []
  type: TYPE_NORMAL
- en: This elevated level of resource use persists briefly, keeping the replicas at
    `4`. However, when the utilization drops significantly to 3% and further down
    to 1%, the HPA initially doesn’t scale down immediately, possibly due to stabilization
    settings that prevent oscillations in pod count. Ultimately, as the low utilization
    continues, the HPA scales the number of pods back down to `1`.
  prefs: []
  type: TYPE_NORMAL
- en: This sequence demonstrates the HPA’s capability to dynamically scale application
    resources based on real-time data, thus ensuring that the deployment scales efficiently
    in response to workload changes. This dynamic adjustment helps manage resources
    effectively, maintaining application responsiveness and optimizing operational
    costs. The responsiveness of the HPA to changes in CPU utilization exemplifies
    how Kubernetes can automate scaling to maintain performance and resource efficiency
    without manual intervention.
  prefs: []
  type: TYPE_NORMAL
- en: As we ensure efficient resource management and scalability, it is equally important
    to turn our attention to monitoring and securing your application. In the next
    section, we will explore these crucial aspects of operational excellence.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring and securing your application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Operational excellence in software deployment and management is a crucial factor
    for the success of any technology-driven organization. The keys to achieving this
    excellence are monitoring, scaling, and security, each serving as foundational
    pillars that ensure the smooth and efficient operation of applications in production
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring is vital as it provides the visibility needed to understand the behavior
    of applications and systems in real time. Effective monitoring strategies help
    in identifying performance bottlenecks, predicting system failures, and gathering
    valuable data to aid in decision-making processes. This continuous oversight allows
    teams to respond proactively to issues before they affect the user experience
    or lead to more significant disruptions.
  prefs: []
  type: TYPE_NORMAL
- en: Security practices are critical to safeguard sensitive data and protect infrastructures
    from breaches and attacks. In an era where cyber threats are evolving rapidly,
    ensuring that robust security measures are in place is non-negotiable. Security
    protocols help in maintaining trust with customers, complying with regulatory
    requirements, and avoiding the financial and reputational damage associated with
    data breaches.
  prefs: []
  type: TYPE_NORMAL
- en: Together, monitoring, scaling, and security form the backbone of operational
    excellence, supporting a stable, efficient, and secure environment for deploying
    and managing applications. Organizations that master these aspects are better
    positioned to leverage technology for business success, ensuring that they can
    deliver continuous value to users while adapting to the ever-changing digital
    landscape.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Grafana and Prometheus are powerful tools that are widely used in the monitoring
    and observability landscape. They are particularly valuable for managing cloud-native
    applications deployed in dynamic environments such as Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Prometheus**: Prometheus is an open source monitoring system with a robust
    query language. It collects and stores its metrics as time-series data, meaning
    that each metric is stored with its exact time of recording. Prometheus is highly
    effective for recording real-time metrics in a high-availability environment.
    It supports a pull model for fetching data from monitored services, allowing it
    to actively scrape data from registered targets at specified intervals. This data
    can then be queried and analyzed to monitor the health and performance of applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Grafana**: Grafana is an open source analytics and visualization platform
    that integrates seamlessly with a multitude of data sources, including Prometheus.
    Grafana is used to create comprehensive dashboards that provide visualizations
    of metrics data. These dashboards allow developers and operations teams to visually
    interpret complex data to understand application behavior and resource usage,
    making it easier to spot trends, patterns, and potential problems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Together, Prometheus and Grafana offer a powerful combination for data gathering,
    storage, and visualization, enhancing the ability to observe system behaviors,
    troubleshoot issues, and ensure that system performance aligns with user expectations
    and business objectives. This duo is particularly effective in a DevOps context,
    where continuous monitoring and feedback loops are critical to the software development
    and deployment life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Prometheus and Grafana
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following are the necessary steps to set up Prometheus and Grafana on the
    AKS cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Add the Prometheus and Grafana Helm chart repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Update the Helm repository. Ensure that we are using the most up-to-date version:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: $ helm install prometheus \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: prometheus-community/kube-prometheus-stack \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --namespace gitops-real-monitoring \
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: --create-namespace
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the entire deployment by typing the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: admin username the password defined for the prom-operator.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Expose Prometheus using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After logging in, you should be able to see the Grafana homepage. Click on
    the **Dashboards** menu item as illustrated in *Figure 11**.12*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.12 – The Grafana home page, with the Dashboards menu item highlighted](img/B22100_11_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.12 – The Grafana home page, with the Dashboards menu item highlighted
  prefs: []
  type: TYPE_NORMAL
- en: Click on `weather-app-for-real`. You will see some interesting metrics on the
    Pods that are running there, as illustrated in *Figure 11**.13*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 11.13 – CPU, memory, and other metrics for the backend-api-weather
    pod](img/B22100_11_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.13 – CPU, memory, and other metrics for the backend-api-weather pod
  prefs: []
  type: TYPE_NORMAL
- en: 'At this point, you have correctly and successfully set up Grafana and Prometheus.
    Now, you can see interesting statistics about the usage of `backend-api-weather-app`,
    which can be used to fine-tune the resource limits and requests, as discussed
    in the *Optimize resource usage* section of this chapter. In the next section,
    we will introduce another important aspect of Kubernetes management in the real
    world: Kubernetes security.'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Kubernetes security
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Kubernetes, while robust and scalable, presents a unique set of security challenges
    that stem from its dynamic and distributed nature. Securing a Kubernetes cluster
    involves safeguarding the infrastructure, the applications running on it, and
    the data that it processes. Given the complexity of Kubernetes environments, security
    must be integrated into every layer of the cluster. Key aspects of Kubernetes
    security include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Authentication and authorization**: This ensures that only verified users
    can access the cluster with methods such as certificates and tokens. It also controls
    user actions using mechanisms such as RBAC and **Attributed-Based Access** **Control**
    (**ABAC**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API security**: Protecting the Kubernetes API server, which acts as the central
    control unit for the cluster, is crucial. Securing access to the API involves
    using SSL/TLS encryption, API request auditing, and limiting IP access through
    network policies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network security**: Enforcing policies that control the flow of traffic between
    pods and external networks helps prevent unauthorized access and limits the potential
    for lateral movement within the cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pod security admission**: This is a Kubernetes admission controller that
    enforces security settings on pods at creation time, using predefined security
    profiles (**privileged**, **baseline**, and **restricted**) to ensure compliance
    with best security practices and prevent privilege escalations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secrets management**: Kubernetes manages sensitive data (such as passwords
    and tokens) using secrets. Proper handling and security of secrets, including
    encryption at rest and in transit, is vital to protect sensitive information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The importance of a layered security approach
  prefs: []
  type: TYPE_NORMAL
- en: Given the complexities of Kubernetes, a single security measure is often not
    enough. A layered security approach that includes network segmentation, threat
    detection, secure access controls, and ongoing vulnerability management is crucial
    for protecting Kubernetes environments from threats.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will see a practical example of how to manage access
    to the weather app’s resources within a specific namespace using RBAC.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Kubernetes RBAC for user and role management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Here is a step-by-step guide to configuring RBAC for the weather app:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define a role that specifies the permissions for managing specific resources
    related to the weather app, such as deployments, services, and pods within a designated
    namespace. The following are the definitions for the `weather-app-manager` role:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'apiVersion: rbac.authorization.k8s.io/v1'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'kind: Role'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'metadata:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'namespace: weather-app-for-real'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'name: weather-app-user'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'rules:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '- apiGroups: ["", "apps"]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'resources: ["pods", "services"]'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'verbs: [RoleBinding resource to grant the specified role to a user. This binding
    will apply the weather-app-manager role to a user named weather-app-user:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create another `RoleBinding` resource to grant the `weather-app-user` role
    to a user named `weather-app-operator`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Move the YAML files to the `Step-01/deployment` folder, push the changes to
    GitHub, and synchronize the Argo CD app.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Verify that the `weather-app-user` and `weather-app-operator` users have the
    necessary permissions using the `kubectl auth` `can-i` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The expected output should be as follows:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can list all roles and role bindings in the namespace, or cluster roles
    affecting the user, with commands such as the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: For reference, the `Step-03-Security` directory in the repository accompanying
    this chapter contains the YAML files with the role and role-binding definitions
    described so far.
  prefs: []
  type: TYPE_NORMAL
- en: Beware!
  prefs: []
  type: TYPE_NORMAL
- en: To avoid incurring unexpected expenses due to Azure resources, please remember
    to destroy any undesired Azure provisioned resources.
  prefs: []
  type: TYPE_NORMAL
- en: This section concludes our journey through a real-world GitOps pipeline and
    deployment. While an entire book might not be enough to delve deeply into every
    aspect of GitOps with Kubernetes, security, and deployments, we believe that the
    sections covered so far provide a comprehensive overview. They offer valuable
    insights into setting up an effective GitOps pipeline for your future Kubernetes
    projects.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter provided a comprehensive guide to deploying real-world projects
    on Kubernetes with GitOps. By following the detailed instructions and examples,
    you learned how to set up a GitOps and Kubernetes development environment, implement
    CI/CD processes, design for scalability and efficiency, manage resources, and
    secure your application. This practical knowledge equipped you with the skills
    needed to effectively implement these cutting-edge technologies in your projects,
    enhancing your organizational capabilities and personal technical expertise.
  prefs: []
  type: TYPE_NORMAL
- en: As you now have a solid foundation in deploying and managing applications with
    GitOps on Kubernetes, the next chapter will delve into observability with GitOps,
    providing essential strategies to monitor and gain insights into your applications’
    performance and health.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 4: Operational Excellence Through GitOps Best Practices'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this part, you will focus on achieving operational excellence through best
    practices in GitOps. You will learn about integrating observability, enhancing
    security, managing financial operations, and preparing for future trends in GitOps.
    This section aims to provide a comprehensive guide to maintaining high standards
    of operational efficiency and security, while also addressing sustainability and
    financial considerations, thus ensuring that your GitOps practices are both cutting
    edge and sustainable.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part includes the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 12*](B22100_12.xhtml#_idTextAnchor231), Observability with GitOps'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 13*](B22100_13.xhtml#_idTextAnchor257), Security with GitOps'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 13*](B22100_13.xhtml#_idTextAnchor257), FinOps, Sustainability, AI,
    and Future Trends for GitOps'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
