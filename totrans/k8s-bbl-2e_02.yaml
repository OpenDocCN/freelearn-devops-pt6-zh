- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Kubernetes Architecture – from Container Images to Running Pods
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 架构 – 从容器镜像到运行的 Pods
- en: In the previous chapter, we laid the groundwork regarding what Kubernetes is
    from a functional point of view. You should now have a better idea of how Kubernetes
    can help you manage clusters of machines running containerized microservices.
    Now, let’s go a little deeper into the technical details. In this chapter, we
    will examine how Kubernetes enables you to manage containers that are distributed
    on different machines. Following this chapter, you should have a better understanding
    of the anatomy of a Kubernetes cluster. In particular, you will have a better
    understanding of Kubernetes components and know the responsibility of each of
    them in the execution of your containers.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章节中，我们从功能角度铺垫了关于 Kubernetes 的基础知识。现在你应该更清楚 Kubernetes 如何帮助你管理运行容器化微服务的机器集群。接下来，让我们深入探讨一些技术细节。在本章节中，我们将研究
    Kubernetes 如何使你能够管理分布在不同机器上的容器。在本章节结束后，你应该能够更好地理解 Kubernetes 集群的构成，特别是你将更清楚每个
    Kubernetes 组件的职责，以及它们在执行容器时的作用。
- en: 'Kubernetes is made up of several distributed components, each of which plays
    a specific role in the execution of containers. To understand the role of each
    Kubernetes component, we will follow the life cycle of a container as it is created
    and managed by Kubernetes: that is, from the moment you execute the command to
    create the container to the point when it is actually executed on a machine that
    is part of your Kubernetes cluster.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 由多个分布式组件组成，每个组件在容器执行过程中都扮演着特定角色。为了理解每个 Kubernetes 组件的角色，我们将跟随容器的生命周期，看看它是如何由
    Kubernetes 创建和管理的：即，从你执行创建容器命令的那一刻，到容器最终在你的 Kubernetes 集群中的某台机器上执行的时刻。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节将涵盖以下主要内容：
- en: The name – Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 名称 – Kubernetes
- en: Understanding the difference between the control plane nodes and compute nodes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解控制平面节点和计算节点之间的区别
- en: Kubernetes components
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 组件
- en: The control plane components
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制平面组件
- en: The compute node components
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算节点组件
- en: Exploring the `kubectl` command-line tool and YAML syntax
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索 `kubectl` 命令行工具和 YAML 语法
- en: How to make Kubernetes highly available
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使 Kubernetes 高可用
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'The following are the technical requirements to proceed with this chapter:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是继续本章节的技术要求：
- en: A basic understanding of the Linux OS and how to handle basic operations in
    Linux
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本了解 Linux 操作系统以及如何在 Linux 中处理基本操作
- en: One or more Linux machines
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台或多台 Linux 机器
- en: The code and snippets used in the chapter are tested on the Fedora workstation.
    All the code, commands, and other snippets for this chapter can be found in the
    GitHub repository at [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter02](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter02).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章节中使用的代码和片段已经在 Fedora 工作站上测试过。所有本章节的代码、命令和其他片段都可以在 GitHub 仓库中找到，链接：[https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter02](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter02)。
- en: The name – Kubernetes
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 名称 – Kubernetes
- en: Kubernetes derives its name from Greek origins, specifically from the word “**kubernētēs**,”
    which translates to helmsman or pilot. This nautical term signifies someone skilled
    in steering and navigating a ship. The choice of this name resonates with the
    platform’s fundamental role in guiding and orchestrating the deployment and management
    of containerized applications, much like a helmsman steering a ship through the
    complexities of the digital landscape.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 源自希腊语，特别是来自单词“**kubernētēs**”，意思是舵手或驾驶员。这个海事术语指的是擅长驾驶和导航船只的人。选择这个名字与平台在引导和编排容器化应用程序的部署和管理方面的基本角色相契合，就像舵手在复杂的数字世界中引导船只一样。
- en: In addition to its formal name, Kubernetes is commonly referred to as “K8s”
    within the community. This nickname cleverly arises from the technique of abbreviating
    the word by counting the eight letters between the “K” and the “s.” This shorthand
    not only streamlines communication but also adds a touch of informality to discussions
    within the Kubernetes ecosystem.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 除了正式名称，Kubernetes 在社区中通常被称为“K8s”。这个昵称巧妙地源于通过计算“K”和“s”之间的八个字母来缩写这个词。这种缩写不仅简化了沟通，还为
    Kubernetes 生态系统中的讨论增添了一丝非正式感。
- en: Understanding the difference between the control plane nodes and compute nodes
  id: totrans-20
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解控制平面节点和计算节点之间的区别
- en: 'To run Kubernetes, you will require Linux machines, which are called nodes
    in Kubernetes. A node could be a physical machine or a virtual machine on a cloud
    provider, such as an EC2 instance. There are two types of node in Kubernetes:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要运行Kubernetes，您将需要Linux机器，这些机器在Kubernetes中被称为节点。节点可以是物理机器，也可以是云提供商上的虚拟机器，例如EC2实例。Kubernetes中有两种类型的节点：
- en: Control plane nodes (also known as master nodes)
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制平面节点（也称为主节点）
- en: Compute nodes (also known as worker nodes)
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算节点（也称为工作节点）
- en: The master and worker nodes
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主节点和工作节点
- en: In various contexts, you might encounter the terms “master nodes” and “worker
    nodes,” which were previously used to describe the conventional hierarchical distribution
    of roles in a distributed system. In this setup, the “master” node oversaw and
    assigned tasks to the “worker” nodes. However, these terms may carry historical
    and cultural connotations that could be perceived as insensitive or inappropriate.
    In response to this concern, the Kubernetes community has chosen to replace these
    terms with “control plane nodes” (or controller nodes), denoting the collection
    of components responsible for managing the overall state of the cluster. Likewise,
    the term “node” or “compute node” is now used in lieu of “worker” to identify
    the individual machines in the cluster executing the requested tasks or running
    the application workloads. The control plane is responsible for maintaining the
    state of the Kubernetes cluster, whereas compute nodes are responsible for running
    containers with your applications.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在不同的上下文中，您可能会遇到“主节点”和“工作节点”这些术语，这些术语以前用来描述分布式系统中传统的角色层次分配。在这种设置中，“主”节点负责监督并分配任务给“工作”节点。然而，这些术语可能带有历史和文化上的含义，可能被认为是不敏感或不合适的。针对这一问题，Kubernetes社区决定用“控制平面节点”（或控制器节点）来替代这些术语，指代负责管理集群整体状态的组件集合。同样，术语“节点”或“计算节点”现在取代了“工作”节点，用于标识集群中执行请求任务或运行应用工作负载的单独机器。控制平面负责维护Kubernetes集群的状态，而计算节点负责运行容器和应用程序。
- en: Linux and Windows containers
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Linux和Windows容器
- en: You have the flexibility to leverage Windows-based nodes to launch containers
    tailored for Windows within your Kubernetes cluster. It’s worth noting that your
    cluster can harmoniously accommodate both Linux and Windows machines; however,
    attempting to initiate a Windows container on a Linux worker node, and vice versa,
    is not feasible. Striking the right balance between Linux and Windows machines
    in your cluster ensures optimal performance.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以灵活地利用基于Windows的节点在Kubernetes集群中启动适用于Windows的容器。值得注意的是，您的集群可以和谐地容纳Linux和Windows机器；然而，尝试在Linux工作节点上启动Windows容器，反之亦然，是不可行的。在集群中找到Linux和Windows机器之间的平衡，以确保最佳性能。
- en: In the next sections of this chapter, we will learn about different Kubernetes
    components and their responsibilities.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章接下来的章节中，我们将学习不同的Kubernetes组件及其职责。
- en: Kubernetes components
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes组件
- en: Kubernetes, by its inherent design, functions as a distributed application.
    When we refer to Kubernetes, it’s not a standalone, large-scale application released
    in a single build for installation on a dedicated machine. Instead, Kubernetes
    embodies a compilation of small projects, each crafted in Go (language), collectively
    constituting the overarching Kubernetes project.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Kubernetes的固有设计，它作为一个分布式应用程序运行。当我们提到Kubernetes时，它并不是一个独立的、在单个构建中发布并安装到专用机器上的大型应用程序。相反，Kubernetes是由多个小型项目组成，每个项目都用Go语言编写，共同构成了Kubernetes这个整体项目。
- en: To establish a fully operational Kubernetes cluster, it’s necessary to individually
    install and configure each of these components, ensuring seamless communication
    among them. Once these prerequisites are fulfilled, you can commence running your
    containers using the Kubernetes orchestrator.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 要建立一个完全可操作的Kubernetes集群，您需要单独安装和配置这些组件，确保它们之间的无缝通信。完成这些先决条件后，您可以开始使用Kubernetes调度器运行您的容器。
- en: 'For development or local testing, it is fine to install all of the Kubernetes
    components on the same machine. However, in production, to meet requirements like
    high availability, load balancing, distributed computing, scaling, and so on,
    these components should be spread across different hosts. By spreading the different
    components across multiple machines, you gain two benefits:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 对于开发或本地测试，将所有 Kubernetes 组件安装在同一台机器上是可以的。然而，在生产环境中，为了满足高可用性、负载均衡、分布式计算、扩展性等需求，这些组件应该分布在不同的主机上。通过将不同组件分布在多台机器上，你将获得两个好处：
- en: You make your cluster highly available and fault-tolerant.
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以使你的集群高度可用和容错。
- en: You make your cluster a lot more scalable. Components have their own life cycle;
    they can be scaled without impacting others.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以让集群更具可扩展性。每个组件都有自己的生命周期，它们可以独立扩展而不会影响其他组件。
- en: In this way, having one of your servers down will not break the entire cluster
    but just a small part of it, and adding more machines to your servers becomes
    easy.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，即使你的某台服务器宕机，也不会影响整个集群，只会影响其中的一小部分，增加更多机器到你的服务器也变得很容易。
- en: Each Kubernetes component has its own clearly defined responsibility. It is
    important for you to understand each component’s responsibility and how it articulates
    with the other components to understand the overall working of Kubernetes.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 Kubernetes 组件都有自己明确的责任。了解每个组件的职责以及它如何与其他组件协调运作，对于理解 Kubernetes 的整体工作原理非常重要。
- en: 'Depending on its role, a component will have to be deployed on a control plane
    node or a compute node. While some components are responsible for maintaining
    the state of a whole cluster and operating the cluster itself, others are responsible
    for running our application containers by interacting with the container runtime
    directly (e.g., `containerd` or Docker daemons). Therefore, the components of
    Kubernetes can be grouped into two families: control plane components and compute
    node components.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 根据其角色，组件需要部署在控制平面节点或计算节点上。虽然一些组件负责维护整个集群的状态并操作集群本身，但其他组件则负责通过与容器运行时（例如，`containerd`
    或 Docker 守护进程）直接交互来运行我们的应用容器。因此，Kubernetes 的组件可以分为两类：控制平面组件和计算节点组件。
- en: You are not supposed to launch your containers by yourself, and therefore, you
    do not interact directly with the compute nodes. Instead, you send your instructions
    to the control plane. Then, it will delegate the actual container creation and
    maintenance to the compute node on your behalf.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你不应该自己启动容器，因此，你不会直接与计算节点交互。相反，你将指令发送给控制平面。然后，控制平面会代表你委派实际的容器创建和维护工作给计算节点。
- en: '![](img/B22019_02_01.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_02_01.png)'
- en: 'Figure 2.1: A typical Kubernetes workflow'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1：一个典型的 Kubernetes 工作流
- en: 'Due to the distributed nature of Kubernetes, the control plane components can
    be spread across multiple machines. There are two ways to set up the control plane
    components:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Kubernetes 的分布式特性，控制平面组件可以分布在多台机器上。设置控制平面组件有两种方式：
- en: You can run all the control planes on the same machine or on different machines.
    To achieve maximum fault tolerance, it’s a good idea to spread the control plane
    components across different machines. The idea is that Kubernetes components must
    be able to communicate with each other, and this still can be achieved by installing
    them on different hosts.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以将所有控制平面组件运行在同一台机器上，也可以运行在不同的机器上。为了实现最大的容错能力，最好将控制平面组件分布在不同的机器上。其核心思想是，Kubernetes
    组件必须能够相互通信，即使它们安装在不同的主机上，这一点也能得到保证。
- en: Things are simpler when it comes to compute nodes (or worker nodes). In these,
    you start from a standard machine running a supported container runtime, and you
    install the compute node components next to the container runtime. These components
    will interface with the local container engine that is installed on said machine
    and execute containers based on the instructions you send to the control plane
    components. Adding more computing power to your cluster is easy; you just need
    to add more worker nodes and have them join the cluster to make room for more
    containers.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在计算节点（或工作节点）方面，事情变得更简单。在这些节点上，你从一台运行支持的容器运行时的标准机器开始，然后将计算节点组件安装到该容器运行时旁边。这些组件将与已安装在该机器上的本地容器引擎进行交互，并根据你发送到控制平面组件的指令执行容器。向集群添加更多计算能力很简单；你只需要添加更多的工作节点，并让它们加入集群，以便为更多容器腾出空间。
- en: By splitting the control plane and compute node components of different machines,
    you are making your cluster highly available and scalable. Kubernetes was built
    with all of the cloud-native concerns in mind; its components are stateless, easy
    to scale, and built to be distributed across different hosts. The whole idea is
    to avoid having a single point of failure by grouping all the components on the
    same host.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将控制平面和计算节点的组件分布到不同的机器上，你可以使你的集群具备高度可用性和可扩展性。Kubernetes 的设计考虑了所有云原生相关问题；它的组件是无状态的，易于扩展，并且可以分布在不同的主机上。整体思路是通过将所有组件分散在不同的主机上，避免出现单点故障。
- en: 'Here is a simplified diagram of a full-featured Kubernetes cluster with all
    the components listed. In this chapter, we’re going to explain all of the components
    listed in this diagram, their roles, and their responsibilities. Here, all of
    the control plane components are installed on a single master node machine:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个简化的图示，展示了一个具有所有组件的完整功能 Kubernetes 集群。在本章中，我们将解释这个图中列出的所有组件，它们的角色和职责。在此，所有控制平面组件都安装在单一的主节点机器上：
- en: '![](img/B22019_02_02.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_02_02.png)'
- en: 'Figure 2.2: A full-featured Kubernetes cluster with one control plane node
    and three compute nodes'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2：一个完整功能的 Kubernetes 集群，包含一个控制平面节点和三个计算节点。
- en: The preceding diagram displays a four-node Kubernetes cluster with all the necessary
    components.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 上图展示了一个四节点的 Kubernetes 集群，包含所有必要的组件。
- en: Bear in mind that Kubernetes is modified and, therefore, can be modified to
    fit a given environment. When Kubernetes is deployed and used as part of a distribution
    such as Amazon EKS or Red Hat OpenShift, additional components could be present,
    or the behavior of the default ones might differ. In this book, for the most part,
    we will discuss bare or vanilla Kubernetes. The components discussed in this chapter
    are the default ones and you will find them everywhere as they are the backbone
    of Kubernetes.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，Kubernetes 是可修改的，因此可以根据特定的环境进行修改。当 Kubernetes 部署并作为某些发行版的一部分使用时，例如 Amazon
    EKS 或 Red Hat OpenShift，可能会有额外的组件，或者默认组件的行为可能会有所不同。在本书中，大部分情况下，我们将讨论裸 Kubernetes。
    本章讨论的组件是默认组件，你会在任何地方看到它们，因为它们是 Kubernetes 的核心组成部分。
- en: The following diagram shows the basic and core components of a Kubernetes cluster.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了 Kubernetes 集群的基本核心组件。
- en: '![](img/B22019_02_03.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_02_03.png)'
- en: 'Figure 2.3: The components of a Kubernetes cluster (image source: https://kubernetes.io/docs/concepts/overview/components)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3：Kubernetes 集群的组件（图片来源：[https://kubernetes.io/docs/concepts/overview/components](https://kubernetes.io/docs/concepts/overview/components)）
- en: 'You might have noticed that most of these components have a name starting with
    `kube`: these are the components that are part of the Kubernetes project. Additionally,
    you might have noticed that there are two components with a name that does not
    start with `kube`. The other two components (`etcd` and `Container Engine`) are
    two external dependencies that are not strictly part of the Kubernetes project,
    but which Kubernetes needs to work:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能注意到，这些组件中的大多数名称都以 `kube` 开头：这些是 Kubernetes 项目的一部分。此外，你可能注意到，有两个组件的名称并没有以
    `kube` 开头。其他两个组件（`etcd` 和 `容器引擎`）是两个外部依赖，它们并不是严格意义上的 Kubernetes 项目一部分，但 Kubernetes
    的正常运行依赖于它们：
- en: '`etcd` is a third-party data store used by the Kubernetes project. Don’t worry;
    you won’t have to master it to use Kubernetes.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`etcd` 是 Kubernetes 项目使用的第三方数据存储。别担心，你不需要精通它就能使用 Kubernetes。'
- en: The container engine is also a third-party engine.
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器引擎也是一个第三方引擎。
- en: Rest assured, you will not have to install and configure these components all
    by yourself. Almost no one bothers with managing the components by themselves,
    and, in fact, it’s super easy to get a working Kubernetes without having to install
    the components.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 请放心，你不需要自己安装和配置这些组件。几乎没有人会自己管理这些组件，事实上，获得一个正常工作的 Kubernetes 集群是非常容易的，不需要单独安装组件。
- en: For development purposes, you can use **minikube**, which is a tool that enables
    developers to run a single-node Kubernetes cluster locally on their machine. It’s
    a lightweight and easy-to-use solution for testing and developing Kubernetes applications
    without the need for a full-scale cluster. minikube is absolutely NOT recommended
    for production.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于开发目的，你可以使用 **minikube**，它是一个允许开发者在本地机器上运行单节点 Kubernetes 集群的工具。它是一个轻量级且易于使用的解决方案，可以在不需要完整集群的情况下测试和开发
    Kubernetes 应用。绝对不推荐将 minikube 用于生产环境。
- en: For production deployment, cloud offerings like Amazon EKS or Google GKE provide
    an integrated, scalable Kubernetes cluster. Alternatively, **kubeadm**, a Kubernetes
    installation utility, is suitable for platforms without cloud access.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生产部署，像 Amazon EKS 或 Google GKE 这样的云服务提供了集成的、可扩展的 Kubernetes 集群。或者，**kubeadm**
    作为一个 Kubernetes 安装工具，适用于没有云访问的平台。
- en: For educational purposes, a renowned tutorial known as *Kubernetes the Hard
    Way* by *Kelsey Hightower* guides users through manual installations, covering
    PKI management, networking, and computing provisioning on bare Linux machines
    in Google Cloud. While this tutorial may feel difficult for beginners, it is still
    recommended to practice, offering a valuable opportunity to comprehend the internals
    of Kubernetes. Note that establishing and managing a production-grade Kubernetes
    cluster, as demonstrated in *Kubernetes the Hard Way*, is intricate and time-consuming.
    It’s advised against using its results in a production environment. You will observe
    many references to this tutorial on the internet because it’s very famous.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 出于教育目的，著名的教程 *Kubernetes the Hard Way* 由 *Kelsey Hightower* 提供，指导用户通过手动安装，涵盖了
    PKI 管理、网络配置和 Google Cloud 中裸机 Linux 机器上的计算资源配置。虽然这个教程对于初学者来说可能会感觉困难，但仍然推荐实践，它提供了一个理解
    Kubernetes 内部机制的宝贵机会。需要注意的是，建立和管理一个生产级的 Kubernetes 集群，如 *Kubernetes the Hard Way*
    中所示，是复杂且耗时的。建议不要在生产环境中使用该教程的结果。你会在互联网上看到许多对该教程的引用，因为它非常有名。
- en: We will learn about the Kubernetes control plane and compute node components
    in the next section.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节学习 Kubernetes 控制平面和计算节点组件。
- en: Control plane components
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 控制平面组件
- en: 'These components are responsible for maintaining the state of the cluster.
    They should be installed on a control plane node. These are the components that
    will keep the list of containers executed by your Kubernetes cluster or the number
    of machines that are part of the cluster. As an administrator, when you interact
    with Kubernetes, you interact with the control plane components and the following
    are the major components in the control plane:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件负责维护集群的状态。它们应该安装在控制平面节点上。这些组件会记录由 Kubernetes 集群执行的容器列表或集群中的机器数量。作为管理员，当你与
    Kubernetes 交互时，你实际上是与控制平面组件交互，以下是控制平面的主要组件：
- en: '`kube-apiserver`'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-apiserver`'
- en: '`etcd`'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`etcd`'
- en: '`kube-scheduler`'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-scheduler`'
- en: '`kube-controller-manager`'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-controller-manager`'
- en: '`cloud-controller-manager`'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cloud-controller-manager`'
- en: Compute node components
  id: totrans-68
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 计算节点组件
- en: 'These components are responsible for interacting with the container runtime
    in order to launch containers according to the instructions they receive from
    the control plane components. Compute node components must be installed on a Linux
    machine running a supported container runtime and you are not supposed to interact
    with these components directly. It’s possible to have hundreds or thousands of
    compute nodes in a Kubernetes cluster. The following are the major component parts
    of the compute nodes:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件负责与容器运行时进行交互，以根据它们从控制平面组件接收到的指令启动容器。计算节点组件必须安装在运行受支持容器运行时的 Linux 机器上，且不应直接与这些组件进行交互。在
    Kubernetes 集群中可能有数百或数千个计算节点。以下是计算节点的主要组件部分：
- en: '`kubelet`'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubelet`'
- en: '`kube-proxy`'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-proxy`'
- en: Container runtime
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器运行时
- en: Add-on components
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附加组件
- en: 'Add-ons utilize Kubernetes resources such as DaemonSet, Deployment, and others
    to implement cluster features. As these features operate at the cluster level,
    resources for add-ons that are namespaced are located within the `kube-system`
    namespace. The following are some of the add-on components you will see commonly
    in your Kubernetes clusters:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 附加组件利用 Kubernetes 资源，如 DaemonSet、Deployment 等，来实现集群特性。由于这些特性在集群级别运行，因此具有命名空间的附加组件资源位于
    `kube-system` 命名空间内。以下是你在 Kubernetes 集群中常见的一些附加组件：
- en: DNS
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DNS
- en: Web UI (dashboard)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Web UI（仪表盘）
- en: Container resource monitoring
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器资源监控
- en: Cluster-level logging
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群级别日志记录
- en: Network plugins
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络插件
- en: Control plane in managed Kubernetes clusters
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 托管 Kubernetes 集群中的控制平面
- en: In contrast to self-managed Kubernetes clusters, cloud services like Amazon
    EKS, Google GKE, and similar offerings handle the installation and configuration
    of most Kubernetes control plane components. They provide access to a Kubernetes
    endpoint, or optionally, the `kube-apiserver` endpoint, without exposing intricate
    details about the underlying machines or provisioned load balancers. This holds
    true for components such as `kube-scheduler`, `kube-controller-manager`, `etcd`,
    and others.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 与自管理的 Kubernetes 集群相比，像 Amazon EKS、Google GKE 等云服务会处理大部分 Kubernetes 控制平面组件的安装和配置。它们提供对
    Kubernetes 端点的访问，或者可选地，`kube-apiserver` 端点，而无需暴露底层机器或已配置负载均衡器的复杂细节。这适用于 `kube-scheduler`、`kube-controller-manager`、`etcd`
    等组件。
- en: 'Here is a screenshot of a Kubernetes cluster created on the Amazon EKS service:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个在 Amazon EKS 服务上创建的 Kubernetes 集群截图：
- en: '![](img/B22019_02_04.png)'
  id: totrans-83
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_02_04.png)'
- en: 'Figure 2.4: The UI console showing details of a Kubernetes cluster provisioned
    on Amazon EKS'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4：UI 控制台显示在 Amazon EKS 上配置的 Kubernetes 集群详细信息
- en: We have detailed chapters to learn about EKS, GKE, and AKS later in this book.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 本书后续章节将详细介绍 EKS、GKE 和 AKS。
- en: We will learn about control plane components that are responsible for maintaining
    the state of the cluster in the next sections.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将学习控制平面组件，它们负责维护集群的状态。
- en: The Control Plane Components
  id: totrans-87
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 控制平面组件
- en: In the following sections, let us explore the different control plane components
    and their responsibilities.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，让我们探索不同的控制平面组件及其职责。
- en: kube-apiserver
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kube-apiserver
- en: Kubernetes’ most important component is a **Representational State Transfer**
    (**REST**) API called `kube-apiserver`, which exposes all the Kubernetes features.
    You will be interacting with Kubernetes by calling this REST API through the `kubectl`
    command-line tool, direct API calls, or the Kubernetes dashboard (Web UI) utilities.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 最重要的组件是一个 **表述性状态转移** (**REST**) API，称为 `kube-apiserver`，它暴露了 Kubernetes
    的所有功能。你将通过 `kubectl` 命令行工具、直接 API 调用或 Kubernetes 仪表盘（Web UI）工具与 Kubernetes 进行交互。
- en: The role of kube-apiserver
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: kube-apiserver 的角色
- en: '`kube-apiserver` is a part of the control plane in Kubernetes. It’s written
    in Go, and its source code is open and available on GitHub under the Apache 2.0
    license. To interact with Kubernetes, the process is straightforward. Whenever
    you want to instruct Kubernetes, you send an HTTP request to `kube-apiserver`.
    Whether it’s creating, deleting, or updating a container, you always make these
    calls to the appropriate `kube-apiserver` endpoint using the right HTTP verb.
    This is the routine with Kubernetes—`kube-apiserver` serves as the sole entry
    point for all operations directed to the orchestrator. It’s considered a good
    practice to avoid direct interactions with container runtimes (unless it is some
    troubleshooting activity).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-apiserver` 是 Kubernetes 控制平面的一部分。它是用 Go 编写的，源代码开源并可以在 GitHub 上通过 Apache
    2.0 许可证获取。与 Kubernetes 交互的过程非常简单。每当你想指示 Kubernetes 时，你只需要发送一个 HTTP 请求到 `kube-apiserver`。无论是创建、删除还是更新容器，你总是通过正确的
    HTTP 动词向相应的 `kube-apiserver` 端点发出这些请求。这就是 Kubernetes 的常规操作—`kube-apiserver` 是所有指向调度器的操作的唯一入口点。避免直接与容器运行时交互是一个良好的实践（除非是进行故障排除活动）。'
- en: '`kube-apiserver` is constructed following the REST standard. REST proves highly
    efficient in showcasing functionalities through HTTP endpoints, accessible by
    employing different methods of the HTTP protocol like `GET`, `POST`, `PUT`, `PATCH`,
    and `DELETE`. When you combine HTTP methods and paths, you can perform various
    operations specified by the method on resources identified by the path.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-apiserver` 是按照 REST 标准构建的。REST 通过 HTTP 端点展示功能非常高效，使用 HTTP 协议的不同方法（如 `GET`、`POST`、`PUT`、`PATCH`
    和 `DELETE`）可以访问这些端点。当你将 HTTP 方法和路径结合时，可以对通过路径标识的资源执行方法指定的各种操作。'
- en: The REST standard provides considerable flexibility, allowing easy extension
    of any REST API by adding new resources through the addition of new paths. Typically,
    REST APIs employ a datastore to manage the state of objects or resources.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: REST 标准提供了相当大的灵活性，允许通过添加新的路径轻松扩展任何 REST API，添加新的资源。通常，REST API 使用数据存储来管理对象或资源的状态。
- en: 'Data retention in such an API can be approached in several ways, including
    the following:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在此类 API 中，数据保留可以通过多种方式处理，包括以下几种：
- en: '**REST API memory storage**:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '**REST API 内存存储**：'
- en: Keeps data in its own memory.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将数据保存在自己的内存中。
- en: However, this results in a stateful API, making scaling impossible.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 然而，这会导致一个有状态的 API，使得扩展变得不可能。
- en: Kubernetes uses `etcd` to store state and it is pronounced /ˈɛtsiːdiː/, which
    means distributed `etc` directory. The `etcd` is an open source distributed key-value
    store used to hold and manage the critical information that distributed systems
    need to keep running.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes使用`etcd`来存储状态，`etcd`的发音是/ˈɛtsiːdiː/，意思是分布式的`etc`目录。`etcd`是一个开源的分布式键值存储，用于保存和管理分布式系统所需的关键信息，以保持系统运行。
- en: '**Database engine usage**:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**数据库引擎使用**：'
- en: Utilizes full-featured database engines like MariaDB or PostgreSQL.
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用像MariaDB或PostgreSQL这样的全功能数据库引擎。
- en: Delegating storage to an external engine makes the API stateless and horizontally
    scalable.
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将存储委托给外部引擎使得API无状态并且具有水平扩展性。
- en: 'Any REST API can be easily upgraded or extended to do more than its initial
    intent. To sum up, here are the essential properties of a REST API:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 任何REST API都可以轻松升级或扩展，以实现比最初设计更多的功能。总结来说，REST API的基本属性如下：
- en: Relies on the HTTP protocol
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 依赖于HTTP协议
- en: Defines a set of resources identified by URL paths
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义由URL路径标识的一组资源
- en: Specifies a set of actions identified by HTTP methods
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指定一组由HTTP方法标识的操作
- en: Executes actions against resources based on a properly forged HTTP request
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于正确构造的HTTP请求对资源执行操作
- en: Maintains the state of their resources on a datastore
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在数据存储上维护其资源的状态
- en: In summary, `kube-apiserver` is nothing more than a REST API, which is at the
    heart of any Kubernetes cluster you will set up, no matter if it’s local, on the
    cloud, or on-premises. It is also stateless; that is, it keeps the state of the
    resources by relying on a database engine called `etcd`. This means you can horizontally
    scale the `kube-apiserver` component by deploying it onto multiple machines and
    load balance request issues to it using a layer 7 load balancer without losing
    data.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，`kube-apiserver`只不过是一个REST API，它是你将要设置的任何Kubernetes集群的核心，无论是本地的、云上的，还是本地部署的。它也是无状态的；也就是说，它通过依赖名为`etcd`的数据库引擎来保持资源的状态。这意味着你可以通过将`kube-apiserver`部署到多台机器上，使用七层负载均衡器来负载均衡请求，并且不会丢失数据，从而实现`kube-apiserver`组件的水平扩展。
- en: As HTTP is supported almost everywhere, it is very easy to communicate with
    and issue instructions to a Kubernetes cluster. However, most of the time, we
    interact with Kubernetes via the command-line utility named `kubectl`, which is
    the HTTP client that is officially supported as part of the Kubernetes project.
    When you download `kube-apiserver`, you’ll end up with a Go-compiled binary that
    is ready to be executed on any Linux machine. The Kubernetes developers defined
    a set of resources for us that are directly bundled within the binary. So, do
    expect the resources in `kube-apiserver` related to container management, networking,
    and computing in general.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于HTTP几乎被所有地方支持，因此与Kubernetes集群进行通信并向其发出指令非常容易。然而，我们大多数时候是通过名为`kubectl`的命令行工具与Kubernetes互动，它是Kubernetes项目官方支持的HTTP客户端。当你下载`kube-apiserver`时，你将得到一个用Go语言编译的二进制文件，能够在任何Linux机器上执行。Kubernetes开发者为我们定义了一组资源，这些资源直接打包在该二进制文件中。因此，可以预期在`kube-apiserver`中涉及容器管理、网络和计算的一般资源。
- en: 'A few of these resources are as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是其中一些资源：
- en: '`Pod`'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pod`'
- en: '`ReplicaSet`'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReplicaSet`'
- en: '`PersistentVolume`'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PersistentVolume`'
- en: '`NetworkPolicy`'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NetworkPolicy`'
- en: '`Deployment`'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Deployment`'
- en: Of course, this list of resources is not exhaustive. If you want a full list
    of the Kubernetes components, you can access it from the official Kubernetes documentation
    API reference page at [https://kubernetes.io/docs/reference/kubernetes-api/](https://kubernetes.io/docs/reference/kubernetes-api/).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这个资源列表并不详尽。如果你想查看完整的Kubernetes组件列表，可以从Kubernetes官方文档的API参考页面访问：[https://kubernetes.io/docs/reference/kubernetes-api/](https://kubernetes.io/docs/reference/kubernetes-api/)。
- en: You might be wondering why there are no *container* resources here. As mentioned
    in *Chapter 1*, *Kubernetes Fundamentals*, Kubernetes makes use of a resource
    called a Pod to manage the containers. For now, you can think of pods as though
    they were containers.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会想，为什么这里没有*容器*资源？正如在*第1章*，*Kubernetes基础*中提到的，Kubernetes使用一种名为Pod的资源来管理容器。目前，你可以将Pod视为容器。
- en: Although pods can hold multiple containers, it’s common to have a pod with just
    one container inside. If you’re interested in using multiple containers within
    a pod, we’ll explore patterns like `sidecar` and `init` `containers` in *Chapter
    5*, *Using Multi-Container Pods and Design Patterns*.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Pod可以容纳多个容器，但通常一个Pod中只有一个容器。如果你有兴趣在一个Pod内使用多个容器，我们将在*第5章*，*使用多容器Pod和设计模式*中探讨如`sidecar`和`init`
    `containers`等模式。
- en: We will learn a lot about them in the coming chapters. Each of these resources
    is associated with a dedicated URL path, and changing the HTTP method when calling
    the URL path will have a different effect. All of these behaviors are defined
    in `kube-apiserver`. Note that these behaviors are not something you have to develop;
    they are directly implemented as part of `kube-apiserver`.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中深入学习它们。每个资源都与一个专用的URL路径关联，调用该URL路径时，改变HTTP方法会产生不同的效果。所有这些行为都在`kube-apiserver`中定义。请注意，这些行为不是你需要开发的；它们是`kube-apiserver`的一部分，已经直接实现。
- en: After the Kubernetes objects are stored on the `etcd` database, other Kubernetes
    components will *convert* these objects into raw container instructions.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes对象存储到`etcd`数据库后，其他Kubernetes组件会*转换*这些对象为原始的容器指令。
- en: Remember, `kube-apiserver` is the central hub and the definitive source for
    the entire Kubernetes cluster. All actions in Kubernetes revolve around it. Other
    components, including administrators, interact with `kube-apiserver` via HTTP,
    avoiding direct interaction with cluster components in most cases.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，`kube-apiserver`是整个Kubernetes集群的中央枢纽和最终源。Kubernetes中的所有操作都围绕它展开。其他组件，包括管理员，通过HTTP与`kube-apiserver`交互，在大多数情况下避免直接与集群组件交互。
- en: This is because `kube-apiserver` not only manages the cluster’s state but also
    incorporates numerous mechanisms for authentication, authorization, and HTTP response
    formatting. Consequently, manual interventions are strongly discouraged due to
    the complexity of these processes.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 这是因为`kube-apiserver`不仅管理集群的状态，还包括许多身份验证、授权和HTTP响应格式化机制。因此，强烈建议避免手动干预，因为这些过程非常复杂。
- en: How do you run kube-apiserver?
  id: totrans-124
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 如何运行kube-apiserver？
- en: In *Chapter 3*, *Installing Your First Kubernetes Cluster*, we will focus on
    how to install and configure a Kubernetes cluster locally.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第三章*，*安装你的第一个Kubernetes集群*中，我们将重点介绍如何在本地安装和配置Kubernetes集群。
- en: 'Essentially, there are two ways to run `kube-apiserver` (and other components),
    as follows:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，有两种方式可以运行`kube-apiserver`（以及其他组件），如下所示：
- en: By running `kube-apiserver` as a container image
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过将`kube-apiserver`作为容器镜像运行
- en: By downloading and installing `kube-apiserver` and running it using a `systemd`
    unit file
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过下载并安装`kube-apiserver`并使用`systemd`单元文件运行它
- en: Since the recommended method is to run the containerized `kube-apisever`, let’s
    put aside the `systemd` method. Depending on the Kubernetes cluster deployment
    mechanisms, `kube-apiserver` and other components will be configured as containers
    by downloading the appropriate images from the container registry (e.g., `registry.k8s.io`).
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 由于推荐的方法是运行容器化的`kube-apiserver`，我们暂时放下`systemd`方法。根据Kubernetes集群的部署机制，`kube-apiserver`和其他组件将通过从容器注册表（例如`registry.k8s.io`）下载相应的镜像，作为容器进行配置。
- en: Where do you run kube-apiserver?
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你在哪里运行kube-apiserver？
- en: '`kube-apiserver`should be run on the control plane node(s) as it is part of
    the control plane. Ensure that the `kube-apiserver` component is installed on
    a robust machine solely dedicated to the control plane operations. This component
    is crucial, and if it becomes inaccessible, your containers will persist but lose
    connectivity with Kubernetes. They essentially turn into “orphan” containers on
    isolated machines, no longer under Kubernetes management.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-apiserver`应在控制平面节点上运行，因为它是控制平面的一部分。确保`kube-apiserver`组件安装在专门用于控制平面操作的强大机器上。这个组件至关重要，如果它变得无法访问，尽管你的容器仍然存在，但它们将失去与Kubernetes的连接。本质上，它们会变成“孤立”容器，处于独立的机器上，不再受Kubernetes管理。'
- en: Also, the other Kubernetes components from all cluster nodes constantly send
    HTTP requests to `kube-apiserver` to understand the state of the cluster or to
    update it. And the more compute nodes you have, the more HTTP requests will be
    issued against `kube-apiserver`. That’s why `kube-apiserver` should be independently
    scaled as the cluster itself scales out.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，来自所有集群节点的其他Kubernetes组件会不断向`kube-apiserver`发送HTTP请求，以了解集群的状态或更新状态。而且，计算节点越多，向`kube-apiserver`发出的HTTP请求就越多。因此，`kube-apiserver`应该随着集群的扩展而进行独立扩展。
- en: As mentioned earlier, `kube-apiserver` is a stateless component that does not
    directly maintain the state of the Kubernetes cluster itself and relies on a third-party
    database to do so. You can scale it horizontally by hosting it on a group of machines
    that are behind a load balancer such as an HTTP API. When using such a setup,
    you interact with `kube-apiserver` by calling your API load balancer endpoint.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，`kube-apiserver`是一个无状态组件，它本身并不直接维护Kubernetes集群的状态，而是依赖于第三方数据库来实现这一点。你可以通过将其托管在一组机器上并放置在负载均衡器后面（如HTTP
    API）来横向扩展它。在这种设置下，你通过调用API负载均衡器的端点与`kube-apiserver`进行交互。
- en: In the next section, we will learn how Kubernetes stores the cluster and resource
    information using `etcd`.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将学习Kubernetes如何使用`etcd`存储集群和资源信息。
- en: The etcd datastore
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: etcd数据存储
- en: We explained that `kube-apiserver` can be scaled horizontally. We also mentioned
    that to store the state of the cluster status and details, `kube-apiserver` uses
    `etcd`, an open source, distributed key-value store. Strictly speaking, `etcd`
    is not a part of the Kubernetes project but a separate project that is maintained
    by the `etcd-io` community.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前解释过，`kube-apiserver`可以横向扩展。我们还提到，`kube-apiserver`使用`etcd`来存储集群状态和详细信息，`etcd`是一个开源的分布式键值存储。严格来说，`etcd`不是Kubernetes项目的一部分，而是由`etcd-io`社区维护的独立项目。
- en: While `etcd` is the commonly used datastore for Kubernetes clusters, some distributions
    like **k3s** leverage alternatives by default, such as SQLite or even external
    databases like MySQL or PostgreSQL ([https://docs.k3s.io/datastore](https://docs.k3s.io/datastore)).
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然`etcd`是Kubernetes集群中常用的数据存储，但一些发行版，如**k3s**，默认使用其他替代方案，例如SQLite，甚至是像MySQL或PostgreSQL这样的外部数据库（[https://docs.k3s.io/datastore](https://docs.k3s.io/datastore)）。
- en: '`etcd` is also an open source project (written in Go just like Kubernetes),
    which is available on GitHub ([https://github.com/etcd-io/etcd](https://github.com/etcd-io/etcd))
    under license Apache 2.0\. It’s also a project incubated (in 2018 and graduated
    in 2020) by the **Cloud Native Computing Foundation** (**CNCF**), which is the
    organization that maintains Kubernetes.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '`etcd`也是一个开源项目（像Kubernetes一样用Go编写），可以在GitHub上找到（[https://github.com/etcd-io/etcd](https://github.com/etcd-io/etcd)），并采用Apache
    2.0许可证。它还是一个由**云原生计算基金会**（**CNCF**）孵化的项目（2018年孵化，2020年毕业），该基金会是Kubernetes的维护组织。'
- en: When you call `kube-apiserver`, each time you implement a read or write operation
    by calling the Kubernetes API, you will read or write data from or to `etcd`.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 当你调用`kube-apiserver`时，每次通过调用Kubernetes API进行读写操作时，都会从`etcd`中读取或写入数据。
- en: 'Let’s zoom into what is inside the master node now:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入了解主节点内部的内容：
- en: '![](img/B22019_02_05.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_02_05.png)'
- en: 'Figure 2.5: The kube-apiserver component is in front of the etcd datastore
    and acts as a proxy in front of it; kube-apiserver is the only component that
    can read or write from and to etcd'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5：kube-apiserver组件位于etcd数据存储前面，充当其代理；kube-apiserver是唯一可以从etcd读取或写入数据的组件。
- en: '`etcd` is like the heart of your cluster. If you lose the data in `etcd`, your
    Kubernetes cluster won’t work anymore. It’s even more crucial than `kube-apiserver`.
    If `kube-apiserver` crashes, you can restart it. But if `etcd` data is lost or
    messed up without a backup, your Kubernetes cluster is done for.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '`etcd`就像你集群的“心脏”。如果丢失了`etcd`中的数据，你的Kubernetes集群将无法再正常工作。它比`kube-apiserver`还要关键。如果`kube-apiserver`崩溃，你可以重启它。但如果`etcd`数据丢失或损坏且没有备份，你的Kubernetes集群就完了。'
- en: Fortunately, you do not need to master `etcd` in depth to use Kubernetes. It
    is even strongly recommended that you do not touch it at all if you do not know
    what you are doing. This is because a bad operation could corrupt the data stored
    in `etcd` and, therefore, the state of your cluster.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，你不需要深入掌握`etcd`才能使用Kubernetes。如果你不知道自己在做什么，强烈建议你完全不要接触它。因为操作不当可能会破坏`etcd`中存储的数据，从而影响集群的状态。
- en: Remember, the general rule in Kubernetes architecture says that every component
    has to go through `kube-apiserver` to read or write in `etcd`. This is because,
    from a technical point of view, `kubectl` authenticates itself against `kube-apiserver`
    through a TLS client certificate that only `kube-apiserver` has. Therefore, it
    is the only component of Kubernetes that has the right to read or write in `etcd`.
    This is a very important notion in the architecture of Kubernetes. All of the
    other components won’t be able to read or write anything to or from `etcd` without
    calling the `kube-apiserver` endpoints through HTTP.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，Kubernetes架构中的一般规则是，每个组件都必须通过`kube-apiserver`来读取或写入`etcd`。这是因为，从技术角度看，`kubectl`通过TLS客户端证书对`kube-apiserver`进行身份验证，而只有`kube-apiserver`拥有该证书。因此，它是唯一有权读取或写入`etcd`的Kubernetes组件。这在Kubernetes的架构中是一个非常重要的概念。所有其他组件都无法在没有通过HTTP调用`kube-apiserver`端点的情况下，读取或写入`etcd`中的任何内容。
- en: Please note that `etcd` is also designed as a REST API. By default, it listens
    to port `2379`.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`etcd`也被设计为一个REST API。默认情况下，它监听`2379`端口。
- en: 'Let’s explore a simple `kubectl` command, as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨一个简单的`kubectl`命令，如下所示：
- en: '[PRE0]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: When you execute the preceding command, the `kubectl` tool will forge an HTTP
    `POST` request that will be executed against the `kube-apiserver` component specified
    in the `kubeconfig` file. `kube-apiserver` will write a new entry in `etcd`, which
    will be persistently stored on disk.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 当你执行上述命令时，`kubectl`工具将创建一个HTTP `POST`请求，该请求将执行针对`kube-apiserver`组件的操作，该组件在`kubeconfig`文件中指定。`kube-apiserver`会在`etcd`中写入一个新条目，该条目将持久化存储在磁盘上。
- en: 'At that point, the state of Kubernetes changes: it will then be the responsibility
    of the other Kubernetes components to reconcile the actual state of the cluster
    to the desired state of the cluster (that is, the one in `etcd`).'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，Kubernetes的状态发生了变化：接下来，将由其他Kubernetes组件来协调集群的实际状态与目标状态（即`etcd`中的状态）。
- en: Unlike Redis or Memcached, `etcd` is not in-memory storage. If you reboot your
    machine, you do not lose the data because it is kept on disk.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 与Redis或Memcached不同，`etcd`不是内存存储。如果你重启机器，你不会丢失数据，因为它保存在磁盘上。
- en: Where do you run etcd?
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你在哪里运行`etcd`？
- en: In a self-managed Kubernetes setup, you can operate `etcd` either within a container
    or as part of a `systemd` unit file. `etcd` can naturally expand horizontally
    by distributing its dataset across several servers, making it an independent clustering
    solution.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 在自我管理的Kubernetes环境中，你可以在容器内或作为`systemd`单元文件的一部分操作`etcd`。`etcd`可以通过将数据集分布到多个服务器上，天然地进行水平扩展，成为一个独立的集群解决方案。
- en: 'Also, you have two places to run `etcd` for Kubernetes, as follows:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你有两个地方可以运行Kubernetes的`etcd`，如下所示：
- en: '`etcd` can be deployed together with `kube-apiserver` (and other control plane
    components) on the control plane nodes – this is the default and simple setup
    (in most Kubernetes clusters, components like `etcd` and `kube-apiserver` are
    initially deployed using static manifests. We’ll explore this approach and alternatives
    in more detail later in the book).'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`etcd`可以与`kube-apiserver`（以及其他控制平面组件）一起部署在控制平面节点上——这是默认且简单的设置（在大多数Kubernetes集群中，像`etcd`和`kube-apiserver`这样的组件通常使用静态清单进行初始化部署。我们将在本书后面更详细地探讨这种方法及其替代方案）。'
- en: You can configure to use a dedicated `etcd` cluster – this is a more complex
    approach but more reliable if your environment is demanding for such reliability.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以配置使用专用的`etcd`集群——这是一种更复杂的方法，但如果你的环境对可靠性有较高要求，它会更可靠。
- en: Operating etcd clusters for Kubernetes
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 操作Kubernetes的`etcd`集群
- en: The details about single-node or multi-node dedicated `etcd` clusters can be
    found in the official Kubernetes documentation at [https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/).
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 有关单节点或多节点专用`etcd`集群的详细信息，请参见Kubernetes官方文档：[https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/)。
- en: Learning more about etcd
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 了解更多关于`etcd`的信息
- en: If you are interested in learning how `etcd` works and want to play with the
    `etcd` dataset, there is a free playground available online. Visit [http://play.etcd.io/play](http://play.etcd.io/play)
    and learn how to manage `etcd` clusters and data inside.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有兴趣了解`etcd`的工作原理，并想尝试`etcd`数据集，可以访问一个免费的在线游乐场。访问[http://play.etcd.io/play](http://play.etcd.io/play)，学习如何管理`etcd`集群和其中的数据。
- en: Let us explore and learn about `kube-scheduler` in the next section.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在下一节中探讨并了解`kube-scheduler`。
- en: kube-scheduler
  id: totrans-162
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kube-scheduler
- en: '`kube-scheduler` is responsible for electing a worker node out of those available
    to run a newly created pod.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-scheduler`负责从可用的工作节点中选举出一个节点来运行新创建的Pod。'
- en: Upon creation, pods are unscheduled, indicating that no worker node has been
    designated for their execution. An unscheduled pod is recorded in `etcd` without
    any assigned worker node. Consequently, no active `kubelet` will be informed of
    the need to launch this pod, leading to the non-execution of any container outlined
    in the pod specification.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建时，Pods是未调度的，表示尚未指定任何工作节点来执行它们。未调度的Pod会被记录在`etcd`中，但没有分配工作节点。因此，任何活动的`kubelet`都不会收到启动此Pod的通知，导致Pod规范中列出的容器无法执行。
- en: Internally, the pod object, as it is stored in `etcd`, has a property called
    `nodeName`. As the name suggests, this property should contain the name of the
    worker node that will host the pod. When this property is set, we say that the
    pod has been *scheduled*; otherwise, the pod is *pending* for schedule.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在内部，Pod对象在`etcd`中存储时有一个属性叫做`nodeName`。顾名思义，这个属性应该包含将托管Pod的工作节点的名称。当这个属性被设置时，我们称该Pod已被*调度*；否则，Pod仍处于*挂起*状态，等待调度。
- en: '`kube-scheduler` queries `kube-apiserver` at regular intervals in order to
    list the pods that have not been *scheduled* or with an empty `nodeName` property.
    Once it finds such pods, it will execute an algorithm to elect a worker node.
    Then, it will update the `nodeName` property in the pod by issuing an HTTP request
    to the `kube-apiserver` component. While electing a worker node, the `kube-scheduler`
    component will take into account some configuration values that you can pass:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-scheduler`会定期查询`kube-apiserver`，列出那些尚未被*调度*或`nodeName`属性为空的Pods。一旦找到这些Pods，它将执行一个算法来选举一个工作节点。然后，它会通过向`kube-apiserver`组件发出HTTP请求来更新Pod中的`nodeName`属性。在选举工作节点时，`kube-scheduler`组件会考虑一些配置值，这些配置值是你可以传递的：'
- en: '![](img/B22019_02_06.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_02_06.png)'
- en: 'Figure 2.6: The kube-scheduler component polls the kube-apiserver component
    to find unscheduled pods'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.6：`kube-scheduler`组件轮询`kube-apiserver`组件以查找未调度的Pod
- en: 'The `kube-scheduler` component will take into account some configuration values
    that you can pass optionally. By using these configurations, you can precisely
    control how the `kube-scheduler` component will elect a worker node. Here are
    some of the features to bear in mind when scheduling pods on your preferred node:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-scheduler`组件将考虑你可以选择传递的一些配置值。通过使用这些配置，你可以精确控制`kube-scheduler`组件如何选举工作节点。以下是调度Pods到你首选节点时需要注意的一些特性：'
- en: Node selector
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点选择器
- en: Node affinity and anti-affinity
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点亲和性和反亲和性
- en: Taint and toleration
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 污点和容忍度
- en: There are also advanced techniques for scheduling that will completely bypass
    the `kube-scheduler` component. We will examine these features later.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 也有一些高级调度技术可以完全绕过`kube-scheduler`组件。我们稍后将讨论这些特性。
- en: The `kube-scheduler` component can be replaced by a custom one. You can implement
    your own `kube-scheduler` component with your custom logic to select a node and
    use it on your cluster. It’s one of the strengths of the distributed nature of
    Kubernetes components.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-scheduler`组件可以被自定义组件替代。你可以实现自己的`kube-scheduler`组件，使用自定义逻辑选择节点并在集群中使用它。这是Kubernetes组件分布式特性的一大优势。'
- en: Where do you install kube-scheduler?
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你应该将`kube-scheduler`安装在哪里？
- en: You can choose to install `kube-scheduler` on a dedicated machine or the same
    machine as `kube-apiserver`. It’s a short process and won’t consume many resources,
    but there are some things to pay attention to.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以选择将`kube-scheduler`安装在一台专用机器上，或与`kube-apiserver`安装在同一台机器上。这是一个简短的过程，不会消耗太多资源，但有一些事项需要注意。
- en: The `kube-scheduler` component should be highly available. That’s why you should
    install it on more than one machine. If your cluster does not have a working `kube-scheduler`
    component, new pods won’t be scheduled, and the result will be a lot of pending
    pods. Also note that if no `kube-scheduler` component is present, it won’t have
    an impact on the already scheduled pods.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-scheduler`组件应该是高可用的。这就是为什么你应该在多台机器上安装它。如果你的集群没有一个正常工作的`kube-scheduler`组件，新的Pods将无法被调度，结果就是会有大量挂起的Pods。同时请注意，如果没有`kube-scheduler`组件，它不会对已经调度的Pods产生影响。'
- en: In the next section, we will learn about another important control plane component
    called `kube-controller-manager`.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习另一个重要的控制平面组件，叫做`kube-controller-manager`。
- en: kube-controller-manager
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kube-controller-manager
- en: '`kube-controller-manager` is a substantial single binary that encompasses various
    functionalities, essentially embedding what is referred to as a controller. It
    is the component that runs what we call the reconciliation loop. `kube-controller-manager`
    tries to maintain the actual state of the cluster with the one described in `etcd`
    so that there are no differences between the states.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-controller-manager` 是一个重要的单一二进制文件，包含了各种功能，实质上嵌入了所谓的控制器。它是执行我们所称的协调循环的组件。`kube-controller-manager`
    尝试保持集群的实际状态与 `etcd` 中描述的状态一致，以确保两者之间没有差异。'
- en: In certain instances, the actual state of the cluster may deviate from the desired
    state stored in `etcd`. This discrepancy can result from pod failures or other
    factors. Consequently, the `kube-controller-manager` component plays a crucial
    role in reconciling the actual state with the desired state. As an illustration,
    consider the replication controller, one of the controllers operating within the
    `kube-controller-manager` component. In practical terms, Kubernetes allows you
    to specify and maintain a specific number of pods across different compute nodes.
    If, for any reason, the actual number of pods varies from the specified count,
    the replication controller initiates requests to the `kube-apiserver` component.
    This aims to recreate a new pod in `etcd`, thereby replacing the failed one on
    a compute node.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，集群的实际状态可能会偏离存储在 `etcd` 中的期望状态。这种差异可能由 Pod 故障或其他因素引起。因此，`kube-controller-manager`
    组件在协调实际状态和期望状态方面发挥着至关重要的作用。例如，考虑到复制控制器，这是 `kube-controller-manager` 组件内运行的控制器之一。实际上，Kubernetes
    允许你在不同的计算节点上指定并维护一定数量的 Pod。如果由于任何原因，实际的 Pod 数量与指定的数量不符，复制控制器会向 `kube-apiserver`
    组件发起请求，试图在 `etcd` 中重建一个新的 Pod，从而替换在计算节点上失败的 Pod。
- en: 'Here is a list of a few controllers that are part of `kube-controller-manager`:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 `kube-controller-manager` 中的一些控制器：
- en: '**Node Controller**: Handles the life cycle of nodes, overseeing their addition,
    removal, and updates within the cluster'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点控制器**：处理节点的生命周期，负责节点的添加、删除和在集群中的更新'
- en: '**Replication Controller**: Ensures that the specified number of replicas for
    a pod specification is consistently maintained'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**复制控制器**：确保始终保持指定数量的副本，以符合 Pod 规格'
- en: '**Endpoints Controller**: Populates the endpoints objects for services, reflecting
    the current pods available for each service'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端点控制器**：为服务填充端点对象，反映每个服务可用的当前 Pod'
- en: '**Service Account Controller**: Oversees the management of ServiceAccounts
    within namespaces, ensuring the presence of a ServiceAccount named `default` in
    each currently active namespace'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务账户控制器**：管理命名空间中的 ServiceAccount，确保每个当前活跃的命名空间中都存在名为 `default` 的 ServiceAccount'
- en: '**Namespace Controller**: Manages the lifecycle of namespaces, encompassing
    creation, deletion, and isolation'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**命名空间控制器**：管理命名空间的生命周期，包括创建、删除和隔离'
- en: '**Deployment Controller**: Manages the lifecycle of deployments, ensuring that
    the desired pod count for each deployment is maintained'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**部署控制器**：管理部署的生命周期，确保每个部署的 Pod 数量保持在所需状态'
- en: '**StatefulSet Controller**: Manages the lifecycle of stateful sets, preserving
    the desired replica count, pod order, and identity'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**StatefulSet 控制器**：管理有状态集的生命周期，保持所需的副本数、Pod 顺序和身份'
- en: '**DaemonSet Controller**: Manages the lifecycle of daemon sets, guaranteeing
    that a copy of the daemon pod is active on each cluster node'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DaemonSet 控制器**：管理守护进程集的生命周期，确保每个集群节点上都有一个守护进程 Pod 副本处于活动状态'
- en: '**Job Controller**: Manages the lifecycle of jobs, ensuring the specified pod
    count for each job is maintained until job completion'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**任务控制器**：管理任务的生命周期，确保每个任务的 Pod 数量保持在指定数量，直到任务完成'
- en: '**Horizontal Pod Autoscaler (HPA) Controller**: Dynamically scales the number
    of replicas for a deployment or stateful set based on resource utilization or
    other metrics'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**水平 Pod 自动扩展器 (HPA) 控制器**：根据资源利用率或其他指标动态调整部署或有状态集的副本数量'
- en: '**Pod Garbage Collector**: Removes pods no longer under the control of an owner,
    such as a replication controller or deployment'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pod 垃圾回收器**：移除不再由所有者（如复制控制器或部署）控制的 Pod'
- en: As you can gather, the `kube-controller-manager` component is quite big. But
    essentially, it’s a single binary that is responsible for reconciling the actual
    state of the cluster with the desired state of the cluster that is stored in `etcd`.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所理解的，`kube-controller-manager`组件相当庞大。但本质上，它是一个单一的二进制文件，负责将集群的实际状态与存储在`etcd`中的期望状态进行调节。
- en: Where do you run kube-controller-manager?
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你在哪里运行kube-controller-manager？
- en: The `kube-controller-manager` component can run as a container or a `systemd`
    service similar to `kube-apiserver` on the control plane nodes. Additionally,
    you can decide to install the `kube-controller-manager` component on a dedicated
    machine. Let’s now talk about `cloud-controller-manager`.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube-controller-manager`组件可以像`kube-apiserver`一样，作为容器或`systemd`服务运行在控制平面节点上。此外，你还可以选择将`kube-controller-manager`组件安装在专用的机器上。现在，让我们来谈谈`cloud-controller-manager`。'
- en: cloud-controller-manager
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: cloud-controller-manager
- en: '`cloud-controller-manager` is a component in the Kubernetes control plane that
    manages the interactions between Kubernetes and the underlying cloud infrastructure.
    `cloud-controller-manager` handles the provisioning and administration of cloud
    resources, including nodes and volumes, to facilitate Kubernetes workloads. It
    exclusively operates controllers tailored to your cloud provider. In cases where
    Kubernetes is self-hosted, within a learning environment on a personal computer,
    or on-premises, the cluster does not feature a cloud controller manager.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '`cloud-controller-manager`是Kubernetes控制平面中的一个组件，负责管理Kubernetes与底层云基础设施之间的交互。`cloud-controller-manager`处理云资源的供应和管理，包括节点和卷，以促进Kubernetes工作负载。它专门操作针对云提供商定制的控制器。在Kubernetes是自托管的、在个人计算机上的学习环境中，或在本地部署时，集群不会拥有云控制器管理器。'
- en: Similar to `kube-controller-manager`, `cloud-controller-manager` consolidates
    multiple logically independent control loops into a unified binary, executed as
    a single process. Horizontal scaling, achieved by running multiple copies, is
    an option to enhance performance or enhance fault tolerance.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于`kube-controller-manager`，`cloud-controller-manager`将多个逻辑上独立的控制循环整合为一个统一的二进制文件，并作为一个单独的进程执行。通过运行多个副本来实现水平扩展，这是提高性能或增强容错性的一种选择。
- en: 'Controllers with potential cloud provider dependencies include:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 具有潜在云提供商依赖的控制器包括：
- en: '**Node Controller**: Verifies if a node has been deleted in the cloud after
    it stops responding'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点控制器**：验证节点在停止响应后是否已被云中删除'
- en: '**Route Controller**: Establishes routes in the underlying cloud infrastructure'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**路由控制器**：在底层云基础设施中建立路由'
- en: '**Service Controller**: Manages the creation, updating, and deletion of cloud
    provider load balancers'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务控制器**：管理云提供商负载均衡器的创建、更新和删除'
- en: Where do you run cloud-controller-manager?
  id: totrans-204
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你在哪里运行cloud-controller-manager？
- en: The `cloud-controller-manager` component can run as a container or a systemd
    service similar to `kube-apiserver` on the control plane nodes.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '`cloud-controller-manager`组件可以像`kube-apiserver`一样，作为容器或`systemd`服务运行在控制平面节点上。'
- en: In the next sections, we will discuss the component parts of the compute nodes
    (also known as worker nodes) in the Kubernetes cluster.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将讨论Kubernetes集群中计算节点（也称为工作节点）的组成部分。
- en: The compute node components
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算节点组件
- en: 'We will dedicate this part of the chapter to explaining the anatomy of a compute
    node by explaining the three components running on it:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章的这一部分中，详细解释计算节点的组成，介绍运行在其上的三个组件：
- en: Container engine and container runtime
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器引擎和容器运行时
- en: '`kubelet`'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubelet`'
- en: The `kube-proxy` component
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-proxy`组件'
- en: '`kubelet`, `kube-proxy`, and container runtime are essential components for
    both control plane (master) nodes and worker nodes. We’ll cover them in this section
    to highlight their functionalities in both contexts.'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`kubelet`、`kube-proxy`和容器运行时是控制平面（主节点）和工作节点的必备组件。我们将在本节中介绍它们，以突出它们在这两种环境中的功能。'
- en: Container engine and container runtime
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器引擎和容器运行时
- en: A **container engine** is a software platform designed to oversee the creation,
    execution, and lifecycle of containers. It offers a more abstract layer compared
    to a **container runtime**, streamlining container management and enhancing accessibility
    for developers. Well-known container engines are Podman, Docker Engine, and CRI-O.
    In contrast, **container runtime** is a foundational software component responsible
    for the creation, execution, and administration of containers in the backend when
    instructed by a container engine or container orchestrator. It furnishes essential
    functionality for container operation, encompassing tasks such as image loading,
    container creation, resource allocation, and container lifecycle management. `Containerd`,
    `runc`, `dockerd`, and Mirantis Container Runtime are some of the well-known container
    runtimes.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '**容器引擎**是一个旨在监督容器创建、执行和生命周期的软件平台。与**容器运行时**相比，它提供了一个更抽象的层次，简化了容器管理并提高了开发者的可访问性。知名的容器引擎包括Podman、Docker
    Engine和CRI-O。相对而言，**容器运行时**是一个基础的软件组件，负责在容器引擎或容器编排器的指示下创建、执行和管理容器。它为容器操作提供必要的功能，包括镜像加载、容器创建、资源分配和容器生命周期管理等任务。`Containerd`、`runc`、`dockerd`和Mirantis
    Container Runtime是一些知名的容器运行时。'
- en: 'The terms “container engine” and “container runtime” can sometimes be used
    interchangeably, leading to confusion. Container runtime (low-level) is the core
    engine responsible for executing container images, managing their lifecycles (start,
    stop, pause), and interacting with the underlying operating system. Examples include
    `runc` and CRI-O (when used as a runtime). Container engine (high-level) builds
    upon the container runtime, offering additional features like image building,
    registries, and management tools. Think Docker, Podman, or CRI-O (when used with
    Kubernetes). Remember, the key is understanding the core functionalities: low-level
    runtimes handle container execution, while high-level engines add a layer of management
    and user-friendliness.'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: “容器引擎”和“容器运行时”这两个术语有时可以互换使用，这可能会导致混淆。容器运行时（低层次）是负责执行容器镜像、管理其生命周期（启动、停止、暂停）并与底层操作系统交互的核心引擎。例子包括`runc`和CRI-O（当用作运行时时）。容器引擎（高层次）建立在容器运行时之上，提供额外的功能，如镜像构建、注册表和管理工具。可以参考Docker、Podman或CRI-O（当与Kubernetes一起使用时）。记住，关键在于理解核心功能：低层次的运行时处理容器执行，而高层次的引擎则添加了一层管理和用户友好性。
- en: 'Docker was the default option for running containers in the backend of Kubernetes
    in earlier days. But Kubernetes is not limited to Docker now; it can utilize several
    other container runtimes such as `containerd`, CRI-O (with `runc`), Mirantis Container
    Runtime, etc. However, in this book, we will be using Kubernetes with `containerd`
    or CRI-O for several reasons, including the following:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期，Docker是Kubernetes后台运行容器的默认选项。但现在Kubernetes不再仅限于Docker；它可以使用多个其他容器运行时，如`containerd`、CRI-O（与`runc`一起使用）、Mirantis
    Container Runtime等。然而，在本书中，我们将使用`containerd`或CRI-O与Kubernetes结合，原因包括以下几点：
- en: '**Focus and Flexibility**: `containerd` and CRI-O specialize in container runtime
    functionality, making them more lightweight and potentially more secure compared
    to Docker’s broader feature set. This focus also allows for seamless integration
    with container orchestration platforms like Kubernetes. Unlike Docker, you don’t
    require additional components like `cri-dockerd` for Kubernetes compatibility.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**专注与灵活性**：`containerd`和CRI-O专注于容器运行时功能，使它们相比于Docker更轻量，且在安全性上可能更具优势。这种专注还使它们能更无缝地与Kubernetes等容器编排平台集成。与Docker不同，您不需要像`cri-dockerd`这样的额外组件来确保与Kubernetes的兼容性。'
- en: '**Alignment with Kubernetes**: Kubernetes is actively moving away from Docker
    as the default runtime. Previously (pre-v1.24), Docker relied on a component called
    `dockershim` for integration with Kubernetes.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**与Kubernetes的对齐**：Kubernetes正在积极地将默认运行时从Docker迁移出去。之前（v1.24之前），Docker依赖一个名为`dockershim`的组件与Kubernetes进行集成。'
- en: However, this approach has been deprecated, and Kubernetes now encourages the
    use of runtimes adhering to the **Container Runtime Interface** (**CRI**) standard
    specifically designed for the platform. By choosing `containerd` or CRI-O, you
    ensure a more native and efficient integration with your Kubernetes environment.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种方法已经被弃用，Kubernetes现在鼓励使用符合**容器运行时接口**（**CRI**）标准的运行时，专门为该平台设计。通过选择`containerd`或CRI-O，可以确保与Kubernetes环境的更加本地化和高效的集成。
- en: '**Kubernetes-Centric Design**: CRI-O, in particular, is designed as a lightweight
    container runtime specifically for Kubernetes. It closely follows Kubernetes release
    cycles with respect to its minor versions (e.g., 1.x.y), simplifying version management.
    When a Kubernetes release reaches its end of life, the corresponding CRI-O version
    can likely be considered deprecated as well, streamlining the decision-making
    process for maintaining a secure and up-to-date Kubernetes environment.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**以 Kubernetes 为中心的设计**：特别是 CRI-O，作为一个轻量级容器运行时，专为 Kubernetes 设计。它严格遵循 Kubernetes
    版本发布周期（如 1.x.y），简化了版本管理。当 Kubernetes 版本达到生命周期结束时，相应的 CRI-O 版本也可能被视为废弃，从而简化了维护安全且最新的
    Kubernetes 环境的决策过程。'
- en: Container Runtime Interface
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 容器运行时接口
- en: Kubernetes employs a container runtime to execute containers within Pods. By
    default, Kubernetes utilizes the CRI to establish communication with the selected
    container runtime. The CRI was first introduced in Kubernetes version 1.5, released
    in December 2016.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 使用容器运行时在 Pod 内执行容器。默认情况下，Kubernetes 利用 CRI 与选定的容器运行时建立通信。CRI 最早在
    Kubernetes 1.5 版本中引入，该版本于 2016 年 12 月发布。
- en: The CRI serves as a plugin interface, empowering the kubelet to seamlessly integrate
    with a diverse range of container runtimes. This flexibility enables the selection
    of an optimal container runtime tailored to specific environmental requirements,
    such as `containerd`, Docker Engine, or CRI-O.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: CRI 作为一个插件接口，使得 kubelet 能够与各种容器运行时无缝集成。这种灵活性使得可以根据特定的环境需求选择最优的容器运行时，如 `containerd`、Docker
    Engine 或 CRI-O。
- en: Within the CRI, a set of defined APIs allows the kubelet to engage with the
    container runtime efficiently. These APIs cover essential operations like creating,
    starting, stopping, and deleting containers, along with managing pod sandboxes
    and networking.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在 CRI 内，一组已定义的 API 使得 kubelet 可以高效地与容器运行时进行交互。这些 API 涵盖了基本操作，如创建、启动、停止和删除容器，以及管理
    Pod 沙箱和网络。
- en: The following table shows the known endpoints for Linux machines.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格展示了适用于 Linux 机器的已知端点。
- en: '| **Runtime** | **Path to Unix domain socket** |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| **运行时** | **Unix 域套接字路径** |'
- en: '| `containerd` | `unix:///var/run/containerd/containerd.sock` |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| `containerd` | `unix:///var/run/containerd/containerd.sock` |'
- en: '| CRI-O | `unix:///var/run/crio/crio.sock` |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| CRI-O | `unix:///var/run/crio/crio.sock` |'
- en: '| Docker Engine (using `cri-dockerd`) | `unix:///var/run/cri-dockerd.sock`
    |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| Docker Engine（使用 `cri-dockerd`） | `unix:///var/run/cri-dockerd.sock` |'
- en: 'Table 2.1: Known container runtime endpoints for Linux machines'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.1：适用于 Linux 机器的已知容器运行时端点
- en: Refer to the documentation ([https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm))
    to learn more.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 请参考文档（[https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm)）了解更多信息。
- en: Kubernetes and Docker
  id: totrans-232
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Kubernetes 与 Docker
- en: In Kubernetes releases prior to v1.24, there was a direct integration with Docker
    Engine facilitated by a component called **dockershim**. However, this specific
    integration has been discontinued, and its removal was communicated with the v1.20
    release. The deprecation of Docker as the underlying runtime is underway, and
    Kubernetes is now encouraging the use of runtimes aligned with the CRI designed
    for Kubernetes.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 在 v1.24 版本之前的 Kubernetes 版本中，通过一个名为 **dockershim** 的组件实现了与 Docker Engine 的直接集成。然而，这种集成已经停止，并且在
    v1.20 版本中宣布移除。Docker 作为基础运行时的弃用正在进行中，Kubernetes 现在鼓励使用与 Kubernetes 设计的 CRI 对应的运行时。
- en: Despite these changes, Docker-produced images will persistently function in
    your cluster with any runtime, ensuring compatibility as it has been previously.
    Refer to [https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/](https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/)
    to learn more.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管发生了这些变化，Docker 生成的镜像仍然会在任何运行时中持续正常工作，确保与之前的兼容性。如需了解更多信息，请参考 [https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/](https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/)。
- en: Therefore, any Linux machine running `containerd` can be used as a base on which
    to build a Kubernetes worker node. (We will discuss Windows compute nodes in the
    later chapters of this book.)
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，任何运行 `containerd` 的 Linux 机器都可以用作构建 Kubernetes 工作节点的基础。（我们将在本书后续章节中讨论 Windows
    计算节点。）
- en: Open Container Initiative
  id: totrans-236
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 开放容器倡议
- en: The **Open Container Initiative** (**OCI**) is an open-source initiative that
    defines standards for container images, containers, container runtimes, and container
    registries. This effort aims to establish interoperability and compatibility across
    container systems, ensuring consistent container execution in diverse environments.
    Additionally, the CRI collaborates with OCI, providing a standardized interface
    for the `kubelet` to communicate with container runtimes. The OCI defines standards
    for container images and runtimes supported by the CRI, fostering efficient container
    management and deployment in Kubernetes.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '**开放容器倡议**（**OCI**）是一个开源倡议，定义了容器镜像、容器、容器运行时和容器注册表的标准。这个努力旨在建立跨容器系统的互操作性和兼容性，确保在不同环境中容器的一致执行。此外，CRI与OCI合作，提供了一个标准化的接口，使得`kubelet`能够与容器运行时进行通信。OCI定义了由CRI支持的容器镜像和运行时的标准，从而促进了Kubernetes中容器管理和部署的高效性。'
- en: Container RuntimeClass
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 容器运行时RuntimeClass
- en: Kubernetes **RuntimeClass** allows you to define and assign different container
    runtime configurations to Pods. This enables balancing performance and security
    for your applications. Imagine high-security workloads scheduled with a hardware
    virtualization runtime for stronger isolation, even if it means slightly slower
    performance. RuntimeClass also lets you use the same runtime with different settings
    for specific Pods. To leverage this, you’ll need to configure the CRI on your
    nodes (installation varies) and create corresponding RuntimeClass resources within
    Kubernetes.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes **RuntimeClass**允许你为Pods定义并分配不同的容器运行时配置。这使得你可以在应用程序的性能和安全性之间取得平衡。想象一下，使用硬件虚拟化运行时调度高安全性的工作负载，以便提供更强的隔离性，即使这意味着稍微降低性能。RuntimeClass还允许你为特定的Pods使用相同的运行时，但具有不同的设置。要利用这一点，你需要在节点上配置CRI（安装过程有所不同），并在Kubernetes中创建相应的RuntimeClass资源。
- en: In the next section, we will learn about the `kubelet` agent, another important
    component of a Kubernetes cluster node.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习`kubelet`代理，这是Kubernetes集群节点的另一个重要组件。
- en: kubelet
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kubelet
- en: The `kubelet` is the most important component of the compute node since it is
    the one that will interact with the local container runtime installed on the compute
    node.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubelet`是计算节点中最重要的组件，因为它是与计算节点上安装的本地容器运行时进行交互的组件。'
- en: The `kubelet` functions solely as a system daemon and cannot operate within
    a container. Its execution is mandatory directly on the host system, often facilitated
    through `systemd`. This distinguishes the `kubelet` from other Kubernetes components,
    emphasizing its exclusive requirement to run on the host machine.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubelet`仅作为系统守护进程运行，不能在容器内操作。它的执行必须直接在主机系统上进行，通常通过`systemd`来实现。这使得`kubelet`与其他Kubernetes组件有所区别，突出了它必须在主机机器上运行的独特要求。'
- en: When the kubelet gets started, by default, it reads a configuration file located
    at `/etc/kubernetes/kubelet.conf`.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 当`kubelet`启动时，默认情况下，它会读取位于`/etc/kubernetes/kubelet.conf`的配置文件。
- en: 'This configuration specifies two values that are really important for the `kubelet`
    to work:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 该配置指定了两个对`kubelet`工作至关重要的值：
- en: The endpoint of the `kube-apiserver` component
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-apiserver`组件的端点'
- en: The local container runtime Unix socket
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 本地容器运行时UNIX套接字
- en: Once the compute node has joined the cluster, the `kubelet` will act as a bridge
    between `kube-apiserver` and the local container runtime. The `kubelet` is constantly
    running HTTP requests against `kube-apiserver` to retrieve information about pods
    it has to launch.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦计算节点加入集群，`kubelet`将充当`kube-apiserver`与本地容器运行时之间的桥梁。`kubelet`会不断向`kube-apiserver`发送HTTP请求，以获取有关它必须启动的pods的信息。
- en: By default, **every 20 seconds**, the `kubelet` runs a GET request against the
    `kube-apiserver` component to list the pods created on `etcd` that are destined
    to it.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，**每20秒**，`kubelet`会对`kube-apiserver`组件发出一个GET请求，以列出在`etcd`上创建并指向它的pods。
- en: Once it receives a pod specification in the body of an HTTP response from `kube-apiserver`,
    it can convert this into a container specification that will be executed against
    the specified UNIX socket. The result is the creation of your containers on your
    compute node using the local container runtime (e.g., `containerd`).
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦它从`kube-apiserver`接收到HTTP响应体中的pod规格，它就可以将其转换为容器规格，并在指定的UNIX套接字上执行。结果是在计算节点上使用本地容器运行时（例如`containerd`）创建容器。
- en: Remember that, like any other Kubernetes components, `kubelet` does not read
    directly from `etcd`; rather it interacts with `kube-apiserver`, which exposes
    what is inside the `etcd` data layer. The kubelet is not even aware that an `etcd`
    server runs behind the `kube-apiserver` it polls.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，像其他 Kubernetes 组件一样，`kubelet` 并不会直接从 `etcd` 中读取数据；它是通过与 `kube-apiserver`
    交互来暴露 `etcd` 数据层中的内容。kubelet 甚至不知道它所轮询的 `kube-apiserver` 后面运行着一个 `etcd` 服务器。
- en: 'The polling mechanisms, called **watch** mechanisms in Kubernetes terminology,
    are precisely to define how Kubernetes proceeds to run and delete containers against
    your worker nodes at scale. There are two things to pay attention to here:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 中的轮询机制，术语中称为 **watch** 机制，正是为了定义 Kubernetes 如何在规模化地对工作节点执行容器的运行和删除。这里有两点需要注意：
- en: The `kubelet` and `kube-apiserver` must be able to communicate with each other
    through HTTP. That’s why HTTPS port `6443` must be opened between the compute
    and control plane nodes.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kubelet` 和 `kube-apiserver` 必须能够通过 HTTP 相互通信。这就是为什么计算节点和控制平面节点之间必须开放 HTTPS
    端口 `6443`。'
- en: As they are running on the same machine, the kubelet, CRI, and container runtimes
    are interfaced through the usage of UNIX sockets.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 由于它们运行在同一台机器上，kubelet、CRI 和容器运行时是通过使用 UNIX 套接字进行接口通信的。
- en: Each worker node in the Kubernetes cluster needs its own kubelet, causing heightened
    HTTP polling against `kube-apiserver` with additional nodes. In larger clusters,
    particularly those with hundreds of machines, this increased activity can adversely
    affect `kube-apiserver`’s performance and potentially lead to a situation that
    may impact API availability. Efficient scaling is essential to ensure the high
    availability of the `kube-apiserver` and other control plane components.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群中的每个工作节点都需要自己的 kubelet，导致对 `kube-apiserver` 的 HTTP 轮询在增加节点后更加频繁。在较大的集群中，尤其是那些有数百台机器的集群，这种增加的活动可能会影响
    `kube-apiserver` 的性能，甚至可能导致影响 API 可用性的情况。高效的扩展非常重要，以确保 `kube-apiserver` 和其他控制平面组件的高可用性。
- en: Also note that you can completely bypass Kubernetes and create containers on
    your worker nodes without having to use the kubelet, and the sole job of the kubelet
    is that its local container runtime reflects the configuration that is stored
    in `etcd`. So, if you create containers manually on a worker node, the kubelet
    won’t be able to manage it. However, exposing the container runtime socket to
    containerized workloads is a security risk. It bypasses Kubernetes’ security mechanisms
    and is a common target for attackers. A key security practice is to prevent containers
    from mounting this socket, safeguarding your Kubernetes cluster.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 另外，请注意，您可以完全绕过 Kubernetes，在工作节点上创建容器而不使用 kubelet，而 kubelet 的唯一工作就是确保其本地容器运行时反映存储在
    `etcd` 中的配置。因此，如果您手动在工作节点上创建容器，kubelet 将无法管理它。然而，将容器运行时套接字暴露给容器化工作负载是一个安全风险。它绕过了
    Kubernetes 的安全机制，是攻击者常常瞄准的目标。一项重要的安全实践是防止容器挂载此套接字，从而保护您的 Kubernetes 集群。
- en: Please note that the container engine running on the worker node has no clue
    that it is managed by Kubernetes through a local kubelet agent. A compute node
    is nothing more than a Linux machine running a container runtime with a kubelet
    agent installed next to it, executing container management instructions.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，运行在工作节点上的容器引擎并不知道它是通过本地 kubelet 代理由 Kubernetes 管理的。计算节点不过是运行容器运行时的 Linux
    机器，旁边安装了 kubelet 代理，执行容器管理指令。
- en: We will learn about the `kube-proxy` component in the next section.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中学习 `kube-proxy` 组件。
- en: The kube-proxy component
  id: totrans-259
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kube-proxy 组件
- en: An important part of Kubernetes is networking. We will have the opportunity
    to dive into networking later; however, you need to understand that Kubernetes
    has tons of mechanics when it comes to exposing pods to the outside world or exposing
    pods to one another in the Kubernetes cluster.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的一个重要部分是网络。我们将在后续深入学习网络；然而，您需要理解，Kubernetes 在暴露 Pod 给外界或暴露 Pod 之间相互通信时有着许多机制。
- en: These mechanics are implemented at the kube-proxy level; that is, each worker
    node requires an instance of a running kube-proxy so that the pods running on
    them are accessible. We will explore a Kubernetes feature called **Service**,
    which is implemented at the level of the kube-proxy component. Just like the kubelet,
    the kube-proxy component also communicates with the `kube-apiserver` component.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 这些机制在kube-proxy级别实现；也就是说，每个工作节点都需要运行一个kube-proxy实例，以便可以访问运行在其上的Pod。我们将探讨一个称为**Service**的Kubernetes特性，该特性在kube-proxy组件的级别实现。就像kubelet一样，kube-proxy组件还与`kube-apiserver`组件通信。
- en: Several other sub-components or extensions operate at the compute node level,
    such as **cAdvisor** or **Container Network Interface** (**CNI**). However, they
    are advanced topics that we will discuss later.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 其他几个子组件或扩展在计算节点级别操作，如**cAdvisor**或**容器网络接口**（**CNI**）。但它们是我们稍后会讨论的高级主题。
- en: Now we have learned about the different Kubernetes components and concepts,
    let us learn about the `kubectl` client utility and how it interacts with the
    Kubernetes API in the next section.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了不同的Kubernetes组件和概念，让我们在下一节学习`kubectl`客户端实用程序以及它如何与Kubernetes API交互。
- en: Exploring the kubectl command-line tool and YAML syntax
  id: totrans-264
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索kubectl命令行工具和YAML语法
- en: '`kubectl` is the official command-line tool used to manage the Kubernetes platform.
    This is an HTTP client that is fully optimized to interact with Kubernetes and
    allows you to issue commands to your Kubernetes cluster.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl`是官方的命令行工具，用于管理Kubernetes平台。这是一个完全优化的HTTP客户端，可与Kubernetes进行交互，并允许您向Kubernetes集群发出命令。'
- en: '**Kubernetes and Linux-Based Learning Environment**'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '**基于Kubernetes和Linux的学习环境**'
- en: For effective learning in Linux containers and related topics, it’s best to
    use workstations or lab machines with a Linux OS. A good understanding of Linux
    basics is essential for working with containers and Kubernetes. Using a Linux
    OS on your workstation automatically places you in the Linux environment, making
    your learning experience better. You can choose the Linux distribution you prefer,
    like Fedora, Ubuntu, or another. We’re committed to inclusivity and will offer
    alternative steps for Windows and macOS users when needed, ensuring a diverse
    and accessible learning experience for everyone. However, it is not mandatory
    to have a Linux OS-installed workstation to learn Kubernetes. If you are using
    a Windows machine, then you can use alternatives such as **Windows Subsystem for
    Linux** (**WSL**) ([https://learn.microsoft.com/en-us/windows/wsl/](https://learn.microsoft.com/en-us/windows/wsl/)).
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在Linux容器和相关主题中进行有效学习，最好使用安装有Linux操作系统的工作站或实验机器。对Linux基础知识的良好理解对于处理容器和Kubernetes至关重要。在工作站上使用Linux操作系统会自动将您置于Linux环境中，从而提升学习体验。您可以选择自己喜欢的Linux发行版，如Fedora、Ubuntu或其他发行版。我们致力于包容性，并将在必要时为Windows和macOS用户提供替代步骤，确保每个人都能获得多样化且无障碍的学习体验。但是，并不需要在安装有Linux操作系统的工作站上学习Kubernetes。如果您使用的是Windows机器，则可以使用**Windows子系统用于Linux**（**WSL**）([https://learn.microsoft.com/en-us/windows/wsl/](https://learn.microsoft.com/en-us/windows/wsl/))等替代方案。
- en: Installing the kubectl command-line tool
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装kubectl命令行工具
- en: The `kubectl` command-line tool can be installed on your Linux, Windows, or
    macOS workstations. You need to ensure that your `kubectl` client version stays
    within one minor version of your Kubernetes cluster for optimal compatibility.
    This means a v1.30 `kubectl` can manage clusters at v1.29, v1.30, and v1.31\.
    Sticking to the latest compatible version helps avoid potential issues.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl`命令行工具可以安装在您的Linux、Windows或macOS工作站上。您需要确保您的`kubectl`客户端版本与您的Kubernetes集群的次要版本兼容，以获得最佳兼容性。这意味着v1.30的`kubectl`可以管理v1.29、v1.30和v1.31的集群。坚持使用最新的兼容版本有助于避免潜在问题。'
- en: Since you are going to need the `kubectl` utility in the coming chapter, you
    can install it right now, as explained in the following sections.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 由于您将在接下来的章节中需要kubectl实用程序，请立即按照以下部分的说明安装它。
- en: Kubernetes Legacy Package Repositories
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes遗留包存储库
- en: 'As of January 2024, the legacy Linux package repositories – namely, `apt.kubernetes.io`
    and `yum.kubernetes.io` (also known as `packages.cloud.google.com`) – have been
    frozen since September 13, 2023, and are no longer available. Users are advised
    to migrate to the new community-owned package repositories for Debian and RPM
    packages at `pkgs.k8s.io`, which were introduced on August 15, 2023\. These repositories
    serve as replacements for the now-deprecated Google-hosted repositories (`apt.kubernetes.io`
    and `yum.kubernetes.io`). This change impacts users directly installing upstream
    versions of Kubernetes and those who have installed `kubectl` using the legacy
    package repositories. For further details, refer to the official announcement:
    Legacy Package Repository Deprecation ([https://kubernetes.io/blog/2023/08/31/legacy-package-repository-deprecation/](https://kubernetes.io/blog/2023/08/31/legacy-package-repository-deprecation/)).'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 截至 2024 年 1 月，遗留的 Linux 包仓库——即 `apt.kubernetes.io` 和 `yum.kubernetes.io`（也称为
    `packages.cloud.google.com`）——自 2023 年 9 月 13 日起被冻结，现已不可用。建议用户迁移到新的社区维护的 Debian
    和 RPM 包仓库 `pkgs.k8s.io`，该仓库于 2023 年 8 月 15 日推出。这些仓库取代了现在已废弃的 Google 托管的仓库（`apt.kubernetes.io`
    和 `yum.kubernetes.io`）。此变更直接影响那些安装上游版本 Kubernetes 的用户，以及通过遗留包仓库安装 `kubectl` 的用户。详细信息请参见官方公告：遗留包仓库弃用（[https://kubernetes.io/blog/2023/08/31/legacy-package-repository-deprecation/](https://kubernetes.io/blog/2023/08/31/legacy-package-repository-deprecation/)）。
- en: Installing kubectl on Linux
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Linux 上安装 kubectl
- en: 'To install `kubectl` on Linux, you need to download the `kubectl` utility and
    copy it to an executable path as follows:'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Linux 上安装 `kubectl` 时，你需要下载 `kubectl` 工具并将其复制到可执行路径，具体操作如下：
- en: '[PRE1]'
  id: totrans-275
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Ignore the connection error here as you do not have a Kubernetes cluster configured
    to access using `kubectl`.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 忽略此处的连接错误，因为你没有配置 Kubernetes 集群供 `kubectl` 访问。
- en: The path `/usr/local/bin/kubectl` could be different in your case. You need
    to ensure appropriate **PATH** variables are configured to ensure the `kubectl`
    utility is under a detectable path. You can also use `/etc/profile` to configure
    the `kubectl` utility path.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 路径 `/usr/local/bin/kubectl` 在你的环境中可能不同。你需要确保配置了合适的 **PATH** 变量，确保 `kubectl`
    工具处于可检测路径下。你也可以使用 `/etc/profile` 来配置 `kubectl` 工具路径。
- en: To download a particular version, substitute the `$(curl -L -s https://dl.k8s.io/release/stable.txt)`
    section of the command with the desired version.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 要下载特定版本，可以将命令中的`$(curl -L -s https://dl.k8s.io/release/stable.txt)`部分替换为所需版本。
- en: 'For instance, if you wish to download version 1.28.4 on Linux x86-64, enter:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果你希望在 Linux x86-64 上下载版本 1.28.4，请输入：
- en: '[PRE2]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This command will download the specific version of the `kubectl` utility, and
    you can copy it to your preferred path.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将下载特定版本的 `kubectl` 工具，你可以将其复制到你希望的路径。
- en: Let us learn how to install the `kubectl` utility on macOS now.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们学习如何在 macOS 上安装 `kubectl` 工具。
- en: Installing kubectl on macOS
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 macOS 上安装 kubectl
- en: 'Installation is pretty similar on macOS except for the different `kubectl`
    packages for Intel and Apple versions:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 安装过程与 macOS 上相似，唯一不同的是针对 Intel 和 Apple 版本的 `kubectl` 包：
- en: '[PRE3]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Installing kubectl on Windows
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Windows 上安装 kubectl
- en: 'Download the `kubectl.exe` ([https://dl.k8s.io/release/v1.28.4/bin/windows/amd64/kubectl.exe](https://dl.k8s.io/release/v1.28.4/bin/windows/amd64/kubectl.exe))
    using the browser or using curl (if you have curl or an equivalent command tool
    installed on Windows):'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 使用浏览器或 curl 下载 `kubectl.exe` （[https://dl.k8s.io/release/v1.28.4/bin/windows/amd64/kubectl.exe](https://dl.k8s.io/release/v1.28.4/bin/windows/amd64/kubectl.exe)）（如果你在
    Windows 上安装了 curl 或等效的命令工具）：
- en: '[PRE4]'
  id: totrans-288
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Finally, append or prepend the `kubectl` binary folder to your **PATH** environment
    variable and test to ensure the version of `kubectl` matches the downloaded one.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，将 `kubectl` 二进制文件夹添加到或前置到你的 **PATH** 环境变量中，并进行测试，确保 `kubectl` 的版本与下载的版本匹配。
- en: You can also install `kubectl` using the native package manager, such as apt-get,
    yum, Zypper, brew (macOS), or Chocolatey (Windows). Refer to the documentation
    ([https://kubernetes.io/docs/tasks/tools/install-kubectl-linux](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux))
    to learn more.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用本地包管理器安装 `kubectl`，如 apt-get、yum、Zypper、brew（macOS）或 Chocolatey（Windows）。参考文档（[https://kubernetes.io/docs/tasks/tools/install-kubectl-linux](https://kubernetes.io/docs/tasks/tools/install-kubectl-linux)）了解更多信息。
- en: We will learn about the usage of the `kubectl` command in the next section.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中学习如何使用 `kubectl` 命令。
- en: The role of kubectl
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kubectl 的作用
- en: Since `kube-apiserver` is nothing more than an HTTP API, any HTTP client will
    work to interact with a Kubernetes cluster. You can even use curl to manage your
    Kubernetes cluster, but of course, there is a better way to do that.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `kube-apiserver` 本质上只是一个 HTTP API，任何 HTTP 客户端都可以用来与 Kubernetes 集群进行交互。你甚至可以使用
    curl 来管理 Kubernetes 集群，但当然，有更好的方式来做到这一点。
- en: So, why would you want to use such a client and not go directly with curl calls?
    Well, the reason is simplicity. Indeed, `kube-apiserver` manages a lot of different
    resources and each of them has its own URL path.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么你要使用这样的客户端而不是直接使用 curl 命令呢？原因就是简便性。实际上，`kube-apiserver` 管理着许多不同的资源，每个资源都有其独立的
    URL 路径。
- en: Calling `kube-apiserver` constantly through curl would be possible but extremely
    time-consuming. This is because remembering the path of each resource and how
    to call it is not user-friendly. Essentially, curl is not the way to go since
    `kubectl` also manages different aspects related to authentication against the
    Kubernetes authentication layer, managing cluster contexts, and more.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 curl 不断调用 `kube-apiserver` 是可行的，但极其耗时。这是因为记住每个资源的路径以及如何调用它并不友好。实际上，curl 并不是最佳选择，因为
    `kubectl` 还管理与 Kubernetes 认证层的身份验证、集群上下文等多个方面。
- en: You would have to constantly go to the documentation to remember the URL path,
    HTTP header, or query string. `kubectl` will do that for you by letting you call
    `kube-apiserver` through commands that are easy to remember, secure, and entirely
    dedicated to Kubernetes management.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要不断查阅文档来记住 URL 路径、HTTP 头或查询字符串。`kubectl` 会通过让你调用 `kube-apiserver` 来为你处理这些，它的命令易于记忆、安全，并且专门用于
    Kubernetes 管理。
- en: 'When you call `kubectl`, it reads the parameters you pass to it and, based
    on them, will create and issue HTTP requests to the `kube-apiserver` component
    of your Kubernetes cluster:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 当你调用 `kubectl` 时，它会读取你传递给它的参数，并基于这些参数创建并发送 HTTP 请求给 Kubernetes 集群中的 `kube-apiserver`
    组件。
- en: '![](img/B22019_02_07.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_02_07.png)'
- en: 'Figure 2.7: The kubectl command line will call kube-apiserver with the HTTP
    protocol; you’ll interact with your Kubernetes cluster through kubectl all of
    the time'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.7：kubectl 命令行将通过 HTTP 协议调用 kube-apiserver；你将通过 kubectl 与 Kubernetes 集群进行交互。
- en: Once the `kube-apiserver` component receives a valid HTTP request coming from
    you, it will read or update the state of the cluster in `etcd` based on the request
    you submitted. If it’s a write operation – for example, to update the image of
    a running container – `kube-apiserver` will update the state of the cluster in
    `etcd`. Then, the components running on the worker node where said container is
    being hosted will issue the proper container management commands in which to launch
    a new container based on the new image. This is so that the actual state of the
    container reflects what’s in `etcd`.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 `kube-apiserver` 组件接收到来自你的有效 HTTP 请求，它将根据你提交的请求读取或更新 `etcd` 中集群的状态。如果是写操作——例如，更新正在运行的容器的镜像——`kube-apiserver`
    将在 `etcd` 中更新集群的状态。然后，托管该容器的工作节点上的组件将发出适当的容器管理命令，以根据新的镜像启动一个新的容器。这是为了确保容器的实际状态与
    `etcd` 中的状态一致。
- en: Given that you won’t have to interact with the container engine by yourself,
    or with `etcd`, we can say that the mastery of Kubernetes is largely based on
    your knowledge of the `kubectl` commands. To be effective with Kubernetes, you
    must master the Kubernetes API and details as much as possible. You won’t have
    to interact with any other components than `kube-apiserver` and the `kubectl`
    command-line tool that allows you to call it.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 由于你不需要直接与容器引擎或 `etcd` 进行交互，我们可以说，掌握 Kubernetes 很大程度上依赖于你对 `kubectl` 命令的了解。要有效使用
    Kubernetes，你必须尽可能掌握 Kubernetes API 和相关细节。你只需要与 `kube-apiserver` 和允许你调用它的 `kubectl`
    命令行工具进行交互，其他组件则无需直接操作。
- en: As the `kube-apiserver` component is reachable via the HTTP(S) protocol, you
    can engage with any Kubernetes cluster using an HTTP-based library or programmatically
    with your preferred programming language. Numerous alternatives to `kubectl` are
    available, but `kubectl`, recognized as the official tool of the Kubernetes project,
    is consistently demonstrated in the documentation. The majority of examples you
    encounter will utilize `kubectl`.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 `kube-apiserver` 组件可以通过 HTTP(S) 协议访问，你可以使用任何基于 HTTP 的库或通过你喜欢的编程语言与 Kubernetes
    集群进行交互。虽然有许多替代 `kubectl` 的工具，但作为 Kubernetes 项目的官方工具，`kubectl` 一直是文档中的主要示例。你遇到的大多数示例都会使用
    `kubectl`。
- en: How does kubectl work?
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '`kubectl` 是如何工作的？'
- en: 'When you call the `kubectl` command, it will try to read a configuration file
    called `kubeconfig` from the default location `$HOME/.kube/config`. The `kubeconfig`
    file should contain the following information so that `kubectl` can use it and
    authenticate against `kube-apiserver`:'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 当你调用`kubectl`命令时，它将尝试从默认位置`$HOME/.kube/config`读取名为`kubeconfig`的配置文件。`kubeconfig`文件应包含以下信息，以便`kubectl`可以使用它并对`kube-apiserver`进行身份验证：
- en: The URL of the `kube-apiserver` endpoint and the port
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kube-apiserver`端点的URL和端口'
- en: The user account
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户账户
- en: Client certificates (if any) used to authenticate against `kube-apiserver`
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于验证`kube-apiserver`的客户端证书（如果有的话）
- en: User-to-cluster mapping, known as context
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户与集群的映射，也就是上下文
- en: It is also possible to pass the details (such as cluster information, user authentication
    details, etc.) to the `kubectl` command as arguments but this is not a handy method
    when you have an environment with multiple clusters to manage.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 也可以将详细信息（例如集群信息、用户认证信息等）作为参数传递给`kubectl`命令，但当你有多个集群需要管理时，这种方法并不方便。
- en: A typical `kubeconfig` file and details are depicted in the following diagram.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个典型的`kubeconfig`文件及其详细信息。
- en: '![](img/B22019_02_08.png)'
  id: totrans-311
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_02_08.png)'
- en: 'Figure 2.8: kubeconfig context and structure'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8：kubeconfig 上下文和结构
- en: 'In the preceding diagram, there are multiple clusters, users, and contexts
    configured:'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的图示中，配置了多个集群、用户和上下文：
- en: '**Clusters**: This section defines the Kubernetes clusters you can interact
    with. It contains information like the server address, API version, and certificate
    authority details for each cluster, allowing `kubectl` to connect and send commands
    to them.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群**：该部分定义了你可以与之交互的Kubernetes集群。它包含了每个集群的服务器地址、API版本、证书授权信息等，允许`kubectl`连接并向它们发送命令。'
- en: '**Users**: This section stores your credentials for accessing the Kubernetes
    clusters. It typically includes a username and a secret (like a token or client
    certificate) used for authentication with the API server. `kubeconfig` files can
    also reference certificates in the `user` section to securely authenticate users
    with the Kubernetes API server. This two-way verification ensures that only authorized
    users with valid certificates can access the cluster, preventing unauthorized
    access and potential security breaches.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户**：该部分存储你访问Kubernetes集群的凭证。通常包括用户名和用于与API服务器进行身份验证的密钥（如令牌或客户端证书）。`kubeconfig`文件还可以在`用户`部分引用证书，以便安全地验证用户与Kubernetes
    API服务器的身份。这种双向验证确保只有具有有效证书的授权用户才能访问集群，从而防止未经授权的访问和潜在的安全漏洞。'
- en: '**Contexts**: This section acts as a bridge between clusters and users. Each
    context references a specific cluster and a specific user within that cluster.
    By choosing a context, you define which cluster and user credentials `kubectl`
    will use for subsequent commands.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**上下文**：该部分充当集群与用户之间的桥梁。每个上下文引用一个特定的集群和该集群中的特定用户。通过选择一个上下文，你可以定义`kubectl`在后续命令中使用哪个集群和用户凭证。'
- en: With multiple clusters, users, and contexts configured inside the `kubeconfig`
    file, it is easy to switch to different Kubernetes clusters with different user
    credentials.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在`kubeconfig`文件中配置了多个集群、用户和上下文后，切换到不同的Kubernetes集群并使用不同的用户凭证变得很容易。
- en: 'The path of `kubeconfig` can be overridden on your system by setting an environment
    variable, called `KUBECONFIG`, or by using the `--kubeconfig` parameter when calling
    `kubectl`:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过设置名为`KUBECONFIG`的环境变量，或在调用`kubectl`时使用`--kubeconfig`参数，来覆盖系统中的`kubeconfig`路径：
- en: '[PRE5]'
  id: totrans-319
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Each time you run a `kubectl` command, the `kubectl` command-line tool will
    look for a `kubeconfig` file in which to load its configuration in the following
    order:'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 每次运行`kubectl`命令时，`kubectl`命令行工具会按照以下顺序查找`kubeconfig`文件以加载其配置：
- en: First, it checks whether the `--kubeconfig` parameter has been passed and loads
    the config file.
  id: totrans-321
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，它检查是否传递了`--kubeconfig`参数，并加载配置文件。
- en: At that point, if no `kubeconfig` file is found, `kubectl` looks for the `KUBECONFIG`
    environment variable.
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果在此时没有找到`kubeconfig`文件，`kubectl`会查找`KUBECONFIG`环境变量。
- en: Ultimately, it falls back to the default one in `$HOME/.kube/config`.
  id: totrans-323
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最终，它会回退到`$HOME/.kube/config`中的默认位置。
- en: 'To view the config file currently used by your local `kubectl` installation,
    you can run this command:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看本地`kubectl`安装当前使用的配置文件，你可以运行以下命令：
- en: '[PRE6]'
  id: totrans-325
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Then, the HTTP request is sent to `kube-apiserver`, which produces an HTTP response
    that `kubectl` will reformat in a human-readable format and output to your Terminal.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，HTTP请求被发送到`kube-apiserver`，该组件生成HTTP响应，`kubectl`将其重新格式化为人类可读的格式并输出到终端。
- en: 'The following command is probably one that you’ll type almost every day when
    working with Kubernetes:'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令可能是你在使用Kubernetes时几乎每天都会输入的命令：
- en: '[PRE7]'
  id: totrans-328
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This command lists the *Pods*. Essentially, it will issue a `GET` request to
    `kube-apiserver` to retrieve the list of containers (Pods) on your cluster. Internally,
    `kubectl` associates the `Pods` parameter passed to the command to the `/api/v1/pods`
    URL path, which is the path that `kube-apiserver` uses to expose the pod resource.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令列出了*Pods*。本质上，它会向`kube-apiserver`发出`GET`请求，以检索集群中容器（Pod）的列表。在内部，`kubectl`将命令中传递的`Pods`参数与`/api/v1/pods`URL路径关联，这是`kube-apiserver`用来公开Pod资源的路径。
- en: 'Here is another command:'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个命令：
- en: '[PRE8]'
  id: totrans-331
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: This one is slightly trickier because `run` is not an HTTP method. This command
    will issue a **POST** request against the `kube-apiserver` component, which will
    result in the creation of a container called `nginx`, based on the `nginx` image
    hosted on the container registry (e.g., Docker Hub or quay.io).
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 这个命令稍微复杂一点，因为`run`不是一个HTTP方法。此命令会向`kube-apiserver`组件发出一个**POST**请求，最终会创建一个名为`nginx`的容器，该容器基于容器注册表中托管的`nginx`镜像（例如，Docker
    Hub或quay.io）。
- en: In fact, this command won’t create a container but a Pod. We will discuss the
    pod resource extensively in *Chapter 4*, *Running Your Containers in Kubernetes*.
    Let’s try not to talk about containers anymore; instead, let’s move on to pods
    and familiarize ourselves with Kubernetes concepts and wordings. From now on,
    if you come across the word *container*, it means a real container from a container
    perspective. Additionally, pods refer to the Kubernetes resource.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，这个命令不会创建一个容器，而是创建一个Pod。我们将在*第4章*，*在Kubernetes中运行你的容器*中详细讨论Pod资源。让我们尽量不再谈论容器，而是转向Pod，并熟悉Kubernetes的概念和术语。从现在开始，如果你看到*容器*一词，它指的是从容器角度来看一个真正的容器。此外，Pod指的是Kubernetes资源。
- en: We will learn how to enable `kubectl` completion in the next section.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节学习如何启用`kubectl`的补全功能。
- en: kubectl auto-completion
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kubectl自动补全
- en: '`kubectl` offers a built-in auto-completion feature for various shells, saving
    you precious time and frustration. `kubectl` supports autocompletion for popular
    shells like:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl`为各种Shell提供了内置的自动补全功能，节省了你宝贵的时间和避免了沮丧。`kubectl`支持常用Shell的自动补全，如：'
- en: Bash
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bash
- en: Zsh
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zsh
- en: Fish
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fish
- en: PowerShell
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PowerShell
- en: 'To enable the autocompletion in Linux Bash, as an example:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 以Linux Bash为例，启用自动补全的方法如下：
- en: '[PRE9]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Now, when you start typing a `kubectl` command, magic happens! `kubectl` will
    suggest completions based on available resources and options. Simply press *Tab*
    to accept suggestions or keep typing to narrow down the options.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当你开始输入`kubectl`命令时，魔法就会发生！`kubectl`将根据可用的资源和选项建议补全。只需按*Tab*键接受建议，或者继续输入以缩小选项范围。
- en: 'The process for enabling autocompletion might differ slightly for other shells
    like Zsh or Fish. Refer to the official `kubectl` documentation for specific instructions:
    [https://kubernetes.io/docs/reference/kubectl/generated/kubectl_completion/](https://kubernetes.io/docs/reference/kubectl/generated/kubectl_completion/)'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 启用自动补全的过程可能会因其他Shell（如Zsh或Fish）而略有不同。请参阅官方`kubectl`文档以获取具体说明：[https://kubernetes.io/docs/reference/kubectl/generated/kubectl_completion/](https://kubernetes.io/docs/reference/kubectl/generated/kubectl_completion/)
- en: This setup ensures that autocompletion works every time you open a new Terminal
    session.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 这个设置确保每次你打开新的终端会话时，自动补全都能正常工作。
- en: In the next section, we will start with the `kubectl` command and how to use
    imperative and declarative syntaxes.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将从`kubectl`命令开始，介绍如何使用命令式和声明式语法。
- en: The imperative syntax
  id: totrans-347
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 命令式语法
- en: 'Almost every instruction that you send to `kube-apiserver` through `kubectl`
    can be written using two types of syntax: **imperative** and **declarative**.
    The imperative syntax focuses on issuing commands that directly modify the state
    of the cluster based on the arguments and parameters you passed to the `kubectl`
    command.'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 你发送给`kube-apiserver`的几乎每一条指令都可以使用两种语法编写：**命令式**和**声明式**。命令式语法侧重于发出直接修改集群状态的命令，这些命令基于你传递给`kubectl`命令的参数和选项。
- en: 'Let us see some of the imperative style operations, as follows:'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一些命令式风格的操作，具体如下：
- en: '[PRE10]'
  id: totrans-350
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The imperative syntax has multiple benefits. If you already understand what
    kind of instructions to send to Kubernetes and the proper command to achieve this,
    you are going to be incredibly fast. The imperative syntax is easy to type, and
    you can do a lot with just a few commands. Some operations are only accessible
    with the imperative syntax, too. For example, listing existing resources in the
    cluster is only possible with the imperative syntax.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 命令式语法有很多优点。如果你已经理解了要向 Kubernetes 发送什么样的指令以及如何正确地执行这些指令，那么你将非常迅速。命令式语法容易输入，而且你可以用少数几个命令做很多事。有些操作只有在命令式语法下才能进行。例如，列出集群中的现有资源，只有通过命令式语法才能实现。
- en: However, the imperative syntax has a big problem. It is very complicated having
    to keep records of what you did previously in the cluster. If, for some reason,
    you were to lose the state of your cluster and need to recreate it from scratch,
    it’s going to be incredibly hard to remember all of the imperative commands that
    you typed in earlier to bring your cluster back to the state you want. You could
    read your `.bash_history` file but, of course, there is a better way to do this,
    and we will learn about that declarative method in the next section.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，命令式语法有一个大问题。如果你需要记住之前在集群中做的操作记录，这将变得非常复杂。如果由于某些原因，你丢失了集群的状态并且需要从头开始重建，那么你会发现很难记得之前输入的所有命令，来使集群恢复到你想要的状态。你可以查看
    `.bash_history` 文件，但显然还有更好的方法，我们将在下一节学习声明式方法。
- en: The declarative syntax
  id: totrans-353
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 声明式语法
- en: “Declarative” is exactly what the name suggests. We “declare” the state we want
    the cluster to be, and then Kubernetes creates the required resources to achieve
    that state. Both JSON and YAML formats are supported; however, by convention,
    Kubernetes users prefer YAML syntax because of its simplicity.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: “声明式”正如其名所示。我们“声明”我们希望集群的状态，然后 Kubernetes 创建所需的资源来达到该状态。JSON 和 YAML 格式都被支持；然而，根据约定，Kubernetes
    用户更喜欢 YAML 语法，因为它简单易懂。
- en: YAML (“YAML Ain’t Markup Language” or “Yet Another Markup Language”) is a human-readable
    data serialization format widely used in Kubernetes. It allows you to define configuration
    for Kubernetes resources like Deployments, Services and Pods in a clear and concise
    way. This format makes it easy to manage and version control your Kubernetes configurations,
    promoting collaboration and repeatability. Also note, YAML is not a programming
    language and there is no real logic behind it. It’s simply a kind of `key:value`
    configuration syntax that is used by a lot of projects nowadays, and Kubernetes
    is one of them.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: YAML（“YAML Ain’t Markup Language” 或 “Yet Another Markup Language”）是一种广泛用于 Kubernetes
    的人类可读的数据序列化格式。它允许你以清晰简洁的方式定义 Kubernetes 资源的配置，如 Deployments、Services 和 Pods。该格式使得管理和版本控制
    Kubernetes 配置变得简单，促进了协作和可重复性。同时需要注意，YAML 不是一种编程语言，它背后没有真正的逻辑。它仅仅是一种 `key:value`
    配置语法，许多项目现在都在使用这种语法，Kubernetes 就是其中之一。
- en: Each `key:value` pair represents the configuration data that you want to set
    to the Kubernetes resource you want to create.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 `key:value` 对表示你想要设置到 Kubernetes 资源的配置数据。
- en: 'The following is the imperative command that created the pod named `my-pod`
    using the `busybox:latest` container image we used earlier:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用之前我们使用过的 `busybox:latest` 容器镜像创建名为 `my-pod` 的 pod 的命令：
- en: '[PRE11]'
  id: totrans-358
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We will now do the same but with the declarative syntax instead:'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们将使用声明式语法做相同的操作：
- en: '[PRE12]'
  id: totrans-360
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let’s say this file is saved with the name `pod.yaml`. To create the actual
    pod, you’ll need to run the following command:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 假设这个文件被保存为 `pod.yaml`。要创建实际的 pod，你需要运行以下命令：
- en: '[PRE13]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This result will be the equivalent of the previous command.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 这个结果将等同于之前的命令。
- en: 'Each YAML file that is created for Kubernetes must contain four mandatory keys:'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 每个为 Kubernetes 创建的 YAML 文件必须包含四个必需的键：
- en: '`apiVersion`: This field tells you in which API version the resource is declared.
    Each resource type has an `apiVersion` key that must be set in this field. The
    pod resource type is in API version `v1`.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apiVersion`：此字段告诉你资源声明的 API 版本。每种资源类型都有一个 `apiVersion` 键，必须在此字段中设置。pod 资源类型使用
    API 版本 `v1`。'
- en: '`kind`: This field indicates the resource type the YAML file will create. Here,
    it is a **pod** that is going to be created.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kind`：此字段表示 YAML 文件将创建的资源类型。在这里，它将创建一个**pod**。'
- en: '`metadata`: This field tells Kubernetes about the name of the actual resource.
    Here, the pod is named `my-pod`. This field describes the Kubernetes resource,
    not the container one. This metadata is for Kubernetes, not for container engines
    like Docker Engine or Podman.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata`：此字段告诉 Kubernetes 关于实际资源的名称。在这里，pod 的名称是 `my-pod`。此字段描述的是 Kubernetes
    资源，而不是容器资源。该元数据是为 Kubernetes 提供的，而不是为像 Docker Engine 或 Podman 这样的容器引擎提供的。'
- en: '`spec`: This field tells Kubernetes what the object is made of. In the preceding
    example, the pod is made of one container that will be named `busybox-container`
    based on the `busybox:latest` container image. These are the containers that are
    going to be created in the backend container runtime.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`spec`：此字段告诉 Kubernetes 对象的组成。在前面的示例中，pod 由一个容器组成，该容器将基于 `busybox:latest` 容器镜像命名为
    `busybox-container`。这些是将在后台容器运行时创建的容器。'
- en: 'Another important aspect of the declarative syntax is that it enables you to
    declare multiple resources in the same file using three dashes as a separator
    between the resources. Here is a revised version of the YAML file, which will
    create two pods:'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 声明式语法的另一个重要方面是，它允许你在同一个文件中声明多个资源，并使用三个破折号作为资源之间的分隔符。下面是修订版的 YAML 文件，它将创建两个 pods：
- en: '[PRE14]'
  id: totrans-370
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You should be able to read this file by yourself and understand it; it just
    creates two pods. The first one uses the `busybox` image, and the second one uses
    the `nginx` image.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够自己阅读这个文件并理解它；它仅创建了两个 pods。第一个使用 `busybox` 镜像，第二个使用 `nginx` 镜像。
- en: 'Of course, you don’t have to memorize all of the syntaxes and what value to
    set for each key. You can always refer to the official Kubernetes documentation
    for the sample declaration YAML files. If the documentation is not enough or does
    not explain particular details, you can use the `kubectl explain` command to understand
    the resource details, as follows:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，你不必记住所有语法以及为每个键设置什么值。你可以随时参考官方的 Kubernetes 文档，获取示例声明的 YAML 文件。如果文档不足或没有解释某些细节，你可以使用
    `kubectl explain` 命令来理解资源的详细信息，如下所示：
- en: '[PRE15]'
  id: totrans-373
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: You will get a very clear explanation and field information from the `kubectl`
    `explain` output.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: 你将从 `kubectl` 的 `explain` 输出中获得非常清晰的解释和字段信息。
- en: 'The declarative syntax offers a lot of benefits, too. With it, you’ll be slower
    because writing these YAML files is a lot more time-consuming than just issuing
    a command in an imperative way. However, it offers two major benefits:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 声明式语法也带来了许多好处。使用它，你的速度可能会变慢，因为编写这些 YAML 文件比直接以命令式方式执行命令要耗时得多。然而，它有两个主要好处：
- en: '**Infrastructure as Code (IaC) management**: You’ll be able to keep the configuration
    stored somewhere and use Git (source code management) to version your Kubernetes
    resources, just as you would do with IaC. If you were to lose the state of your
    cluster, keeping the YAML files versioned in Git will enable you to recreate it
    cleanly and effectively.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施即代码（IaC）管理**：你可以将配置存储在某个地方，并使用 Git（源代码管理）对 Kubernetes 资源进行版本控制，就像处理 IaC
    一样。如果你丢失了集群的状态，保持 YAML 文件在 Git 中的版本化将使你能够清洁有效地重新创建它。'
- en: '**Create multiple resources at the same time**: Since you can declare multiple
    resources in the same YAML file, you can have entire applications and all of their
    dependencies in the same place. Additionally, you get to create and recreate complex
    applications with just one command. Later, you’ll discover a tool called Helm
    that can achieve templating on top of the Kubernetes YAML files.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**同时创建多个资源**：由于你可以在同一个 YAML 文件中声明多个资源，因此可以将整个应用及其所有依赖项放在同一个地方。此外，你可以通过一个命令创建并重新创建复杂的应用程序。稍后，你将发现一个叫做
    Helm 的工具，它可以在 Kubernetes YAML 文件的基础上实现模板化。'
- en: There is no *better* way to use `kubectl`; these are just two ways to interact
    with it, and you need to master both. This is because some features are not available
    with the imperative syntax, while others are not available with the declarative
    syntax. Remember that, in the end, both call the `kube-apiserver` component by
    using the HTTP protocol.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 没有*更好的*方式来使用 `kubectl`；这些只是与其交互的两种方式，你需要掌握这两种方式。因为某些功能在命令式语法中不可用，而另一些功能在声明式语法中不可用。请记住，最终，两者都通过
    HTTP 协议调用 `kube-apiserver` 组件。
- en: '`kubectl` should be installed on any machine that needs to interact with the
    cluster.'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl` 应该安装在任何需要与集群交互的机器上。'
- en: From a technical point of view, you must install and configure a `kubectl` command-line
    tool whenever and wherever you want to interact with a Kubernetes cluster.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术角度来看，每当你想与 Kubernetes 集群进行交互时，必须安装并配置 `kubectl` 命令行工具。
- en: Of course, it can be your local machine or a server from where you are accessing
    the Kubernetes cluster. However, in larger projects, it’s also a good idea to
    install `kubectl` in the agent/runner of your continuous integration platform.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，这台机器可以是你的本地机器或你访问 Kubernetes 集群的服务器。不过，在较大的项目中，将 `kubectl` 安装到持续集成平台的代理/运行器中也是一个好主意。
- en: Indeed, you will probably want to automate maintenance or deployment tasks to
    run against your Kubernetes cluster, and you will probably use a **continuous
    integration** (**CI**) platform such as GitLab CI, Tekton, or Jenkins to do that.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你可能会希望自动化维护或部署任务，以便对 Kubernetes 集群进行操作，并且你可能会使用 **持续集成** (**CI**) 平台，如 GitLab
    CI、Tekton 或 Jenkins 来完成这些任务。
- en: If you want to be able to run Kubernetes commands in a CI pipeline, you will
    need to install `kubectl` on your CI agents and have a properly configured `kubeconfig`
    file written on the CI agent filesystem. This way, your CI/CD pipelines will be
    able to issue commands against your Kubernetes cluster and update the state of
    your cluster, too.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望能够在 CI 管道中运行 Kubernetes 命令，你需要在 CI 代理上安装 `kubectl`，并且在 CI 代理的文件系统中写入正确配置的
    `kubeconfig` 文件。这样，你的 CI/CD 管道就能够向 Kubernetes 集群发出命令，并更新集群的状态。
- en: 'Just to add, `kubectl` should not be seen as a Kubernetes client for *human*
    users only. It should be viewed as a generic tool to communicate with Kubernetes:
    install it wherever you want to communicate with your cluster.'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
  zh: 需要补充的是，`kubectl` 不应仅仅被视为*人类*用户使用的 Kubernetes 客户端。它应被视为与 Kubernetes 通信的通用工具：将其安装在你希望与集群通信的任何地方。
- en: How to make Kubernetes highly available
  id: totrans-385
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何使 Kubernetes 高可用
- en: As you’ve observed earlier, Kubernetes is a clustering solution. Its distributed
    nature allows it to run on multiple machines. By splitting the different components
    across different machines, you’ll be able to make your Kubernetes cluster highly
    available. Next, we will have a brief discussion on the different Kubernetes setups.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你之前观察到的，Kubernetes 是一种集群解决方案。它的分布式特性使得它能够在多台机器上运行。通过将不同的组件分配到不同的机器上，你可以使 Kubernetes
    集群具备高可用性。接下来，我们将简要讨论不同的 Kubernetes 配置。
- en: The single-node cluster
  id: totrans-387
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单节点集群
- en: 'Installing all Kubernetes components on the same machine is the worst possible
    idea if you want to deploy Kubernetes in production. However, it is perfectly
    fine for testing your development. The single-node way consists of grouping all
    of the different Kubernetes components on the same host or a virtual machine:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想在生产环境中部署 Kubernetes，将所有 Kubernetes 组件安装在同一台机器上是最糟糕的选择。然而，对于测试开发来说，这是完全可以接受的。单节点方式是将所有不同的
    Kubernetes 组件聚集在同一主机或虚拟机上的方式：
- en: '![](img/B22019_02_09.png)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_02_09.png)'
- en: 'Figure 2.9: All of the components are working on the same machine'
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.9：所有组件都运行在同一台机器上
- en: Typically, this arrangement is seen as a solid beginning for getting into Kubernetes
    through local testing. There’s a tool called minikube that makes it easy to set
    up single-node Kubernetes on your computer. It runs a virtual machine with all
    the necessary components already configured. While minikube is handy for local
    tests and running minikube as a multi-node cluster is possible, keep in mind that
    minikube is definitely not recommended for production. The following table provides
    some of the pros and cons of using single-node Kubernetes clusters.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，这种配置被认为是通过本地测试入门 Kubernetes 的坚实起点。有一个名为 minikube 的工具，使你可以轻松地在计算机上设置单节点 Kubernetes。它运行一个虚拟机，并且所有必要的组件已经配置好。虽然
    minikube 对于本地测试非常方便，并且运行 minikube 作为多节点集群也是可能的，但请记住，minikube 绝对不推荐用于生产环境。下表提供了一些使用单节点
    Kubernetes 集群的优缺点。
- en: '| **Pros** | **Cons** |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
  zh: '| **优点** | **缺点** |'
- en: '| Good for testing | Impossible to scale |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| 适合测试 | 无法扩展 |'
- en: '| Easy to set up locally | Not highly available |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| 本地设置简单 | 不具备高可用性 |'
- en: '| Supported natively by minikube | Not recommended for production |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| minikube 原生支持 | 不推荐用于生产环境 |'
- en: 'Table 2.2: Pros and cons of single-node kubernetes clusters'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.2：单节点 Kubernetes 集群的优缺点
- en: Single-node Kubernetes is a well-suited option for resource-constrained edge
    environments. It offers a lightweight footprint while still enabling robust deployments
    with disaster recovery strategies in place.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: 单节点 Kubernetes 是一个非常适合资源受限边缘环境的选项。它提供了轻量级的占用空间，同时仍然支持具有灾难恢复策略的强大部署。
- en: The single-master cluster
  id: totrans-398
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 单主节点集群
- en: 'This setup consists of having one node executing all of the control plane components
    with as many compute nodes as you want:'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: 这种配置包含了一个执行所有控制平面组件的节点，以及你想要的多个计算节点：
- en: '![](img/B22019_02_10.png)'
  id: totrans-400
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_02_10.png)'
- en: 'Figure 2.10: A single control plane node rules all of the compute nodes (here,
    it is three)'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.10：单一控制平面节点管理所有计算节点（这里是三个）
- en: 'This setup is quite good compared to single-node clusters and the fact that
    there are multiple compute nodes will enable high availability for your containerized
    application. However, there is still room for improvement:'
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 这种配置相比于单节点集群已经很好，且由于有多个计算节点，将能为容器化应用提供高可用性。然而，仍然有改进的空间：
- en: There is a single point of failure since there is only one control plane node.
    If this single node fails, you won’t be able to manage your running containers
    in a Kubernetes way anymore. Your containers will become orphans, and the only
    way to stop/update them would be to SSH on the worker node and run plain old container
    management commands (e.g., `ctr`, `crictl`, or Docker commands depending on the
    container runtime you are using).
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存在单点故障，因为只有一个控制平面节点。如果这个节点发生故障，你将无法以 Kubernetes 的方式管理你的运行容器。你的容器将成为孤儿，唯一的停止/更新方法是通过
    SSH 进入工作节点，执行传统的容器管理命令（例如 `ctr`、`crictl` 或 Docker 命令，取决于你使用的容器运行时）。
- en: 'Also, there is a major problem here: by using a single `etcd` instance, there
    is a huge risk that you’ll lose your dataset if the control plane node gets corrupted.
    If this happens, your cluster will be impossible to recover.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，这里有一个重大问题：通过使用单个 `etcd` 实例，如果控制平面节点损坏，将会有巨大的风险丢失你的数据集。如果发生这种情况，你的集群将无法恢复。
- en: Lastly, your cluster will encounter an issue if you start scaling your worker
    nodes. Each compute node brings its own kubelet agent, and periodically, the kubelet
    polls `kube-apiserver` every 20 seconds. If you start adding dozens of servers,
    you might impact the availability of your `kube-apiserver`, resulting in an outage
    of your control plane. Remember that your control plane must be able to scale
    and handle such traffic.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，如果你开始扩展工作节点，你的集群将会遇到一个问题。每个计算节点都会带有自己的 kubelet 代理，且 kubelet 每 20 秒会周期性地向
    `kube-apiserver` 发送请求。如果你开始添加几十台服务器，可能会影响 `kube-apiserver` 的可用性，导致控制平面宕机。记住，控制平面必须能够扩展并处理这样的流量。
- en: '| **Pros** | **Cons** |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| **优点** | **缺点** |'
- en: '| It has high-availability compute nodes | The control plane is a single point
    of failure |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| 拥有高可用计算节点 | 控制平面是单点故障 |'
- en: '| It supports multi-node features | A single `etcd` instance is running |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| 支持多节点功能 | 运行单个 `etcd` 实例 |'
- en: '| It is possible to run it locally with projects such as kind or minikube but
    it is not perfect | It cannot scale effectively |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
  zh: '| 可以与 kind 或 minikube 等项目一起在本地运行，但并不完美 | 无法有效扩展 |'
- en: 'Table 2.3: Pros and cons of a single-controller multi-compute Kubernetes cluster'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.3：单控制器多计算节点 Kubernetes 集群的优缺点
- en: Overall, this setup will always be better than single-node Kubernetes; however,
    it’s still not highly available.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 总体来说，这种配置总是优于单节点 Kubernetes；然而，它仍然不是高可用的。
- en: The multi-master multi-node cluster
  id: totrans-412
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多主节点多计算节点集群
- en: This is the best way to achieve a highly available Kubernetes cluster. Both
    your running containers and your control plane are replicated to avoid a single
    point of failure.
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 这是实现高可用 Kubernetes 集群的最佳方式。你的运行容器和控制平面都会被复制，以避免单点故障。
- en: '![](img/B22019_02_11.png)'
  id: totrans-414
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_02_11.png)'
- en: 'Figure 2.11: Multi-control plane node Kubernetes cluster'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.11：多控制平面节点 Kubernetes 集群
- en: By using such a cluster, you are eliminating many of the risks we learned in
    the earlier cluster architectures because you are running multiple instances of
    your compute nodes and your control plane nodes. You will need a load balancer
    on top of your `kube-apiserver` instances in order to spread the load evenly between
    all of them, which will require a little bit more planning. Cloud providers such
    as Amazon EKS or Google GKE are provisioning Kubernetes clusters that are multi-controller
    and multi-compute clusters. If you wish to take it a step further, you can also
    split all of the different control plane components across a dedicated host. It’s
    better but not mandatory, though. The cluster described in the preceding diagram
    is perfectly fine.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用这样的集群，你消除了我们在早期集群架构中学到的许多风险，因为你正在运行多个计算节点和控制平面节点的实例。你需要在 `kube-apiserver`
    实例上使用负载均衡器，以便在它们之间均匀分配负载，这需要稍微更多的规划。像 Amazon EKS 或 Google GKE 这样的云服务提供商正在提供多控制器和多计算节点的
    Kubernetes 集群。如果你希望进一步提升，可以将所有不同的控制平面组件拆分到专用主机上。这样更好，但不是强制的。前面图示的集群完全可以使用。
- en: Managing etcd in Kubernetes with multiple control plane nodes
  id: totrans-417
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中管理具有多个控制平面节点的 etcd
- en: In a multi-control plane cluster, each control plane node runs an `etcd` instance.
    This ensures that the cluster has a high availability `etcd` store, even if some
    of the control plane nodes are unavailable. The `etcd` instances in a multi-control
    plane Kubernetes cluster will form an `etcd` cluster internally. This means that
    the `etcd` instances will communicate with each other to replicate the cluster
    state and ensure that all of the instances have the same data. The `etcd` cluster
    will use a consensus algorithm, known as Raft, to ensure that there is a single
    leader at all times. The leader is responsible for accepting writes to the cluster
    state and replicating the changes to the other instances. If the leader becomes
    unavailable, the other instances will elect a new leader.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个多控制平面集群中，每个控制平面节点都运行一个 `etcd` 实例。这确保了即使某些控制平面节点不可用，集群仍然具有高可用性的 `etcd` 存储。在一个多控制平面
    Kubernetes 集群中，`etcd` 实例将在内部形成一个 `etcd` 集群。这意味着 `etcd` 实例会相互通信，以复制集群状态，并确保所有实例具有相同的数据。`etcd`
    集群将使用一种共识算法，称为 Raft，以确保始终只有一个领导者。领导者负责接受对集群状态的写操作，并将更改复制到其他实例。如果领导者变得不可用，其他实例将选举一个新的领导者。
- en: We will learn about `etcd` member management and `etcd` backup/restore mechanisms
    in the later chapters of this book.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的后续章节中，我们将学习 `etcd` 成员管理和 `etcd` 备份/恢复机制。
- en: 'Before we end this chapter, we would like to sum up all the Kubernetes components.
    The following table will help you to memorize all of their responsibilities:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们结束本章之前，我们想总结一下所有 Kubernetes 组件。以下的表格将帮助你记住它们的所有职责：
- en: '| **Component name** | **Communicates with** | **Role** |'
  id: totrans-421
  prefs: []
  type: TYPE_TB
  zh: '| **组件名称** | **通信对象** | **角色** |'
- en: '| `kube-apiserver` | `kubectl clients, etcd, kube-scheduler, kube-controller-manager,
    kubelet, kube-proxy` | The HTTP REST API. It reads and writes the state stored
    in `etcd`. The only component that is able to communicate with `etcd` directly.
    |'
  id: totrans-422
  prefs: []
  type: TYPE_TB
  zh: '| `kube-apiserver` | `kubectl clients, etcd, kube-scheduler, kube-controller-manager,
    kubelet, kube-proxy` | HTTP REST API。它读取和写入存储在 `etcd` 中的状态。是唯一能够直接与 `etcd` 通信的组件。|'
- en: '| `etcd` | `kube-apiserver` | This stores the state of the Kubernetes cluster.
    |'
  id: totrans-423
  prefs: []
  type: TYPE_TB
  zh: '| `etcd` | `kube-apiserver` | 这个存储了 Kubernetes 集群的状态。|'
- en: '| kube-scheduler | `kube-apiserver` | This reads the API every 20 seconds to
    list unscheduled pods (an empty nodeName property), elects a worker node, and
    updates the nodeName property in the pod entry by calling `kube-apiserver`. |'
  id: totrans-424
  prefs: []
  type: TYPE_TB
  zh: '| kube-scheduler | `kube-apiserver` | 它每20秒读取一次API，列出未调度的pod（一个空的 nodeName
    属性），选择一个工作节点，并通过调用 `kube-apiserver` 更新 pod 条目的 nodeName 属性。|'
- en: '| kube-controller- manager | `kube-apiserver` | This polls the API and runs
    the reconciliation loops. |'
  id: totrans-425
  prefs: []
  type: TYPE_TB
  zh: '| kube-controller-manager | `kube-apiserver` | 它轮询API并运行协调循环。|'
- en: '| kubelet | `kube-apiserver` and container runtime | This reads the API every
    20 seconds to get pods scheduled to the node it’s running on and translates the
    pod specs into running containers by calling the local container runtime operations.
    |'
  id: totrans-426
  prefs: []
  type: TYPE_TB
  zh: '| kubelet | `kube-apiserver` 和容器运行时 | 它每20秒读取一次API，获取调度到其运行节点的pods，并通过调用本地容器运行时操作将pod规范转换为正在运行的容器。|'
- en: '| kube-proxy | `kube-apiserver` | This implements the networking layer of Kubernetes.
    |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
  zh: '| kube-proxy | `kube-apiserver` | 它实现了 Kubernetes 的网络层。|'
- en: '| Container engine | kubelet | This runs the containers by receiving instructions
    from the local kubelet. |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
  zh: '| 容器引擎 | kubelet | 通过接收来自本地 kubelet 的指令来运行容器。|'
- en: 'Table 2.4: Kubernetes components and connectivity'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2.4：Kubernetes 组件及其连接性
- en: These components are the default ones and are officially supported as part of
    the Kubernetes project. Remember that other Kubernetes distributions might bring
    additional components, or they might change the behavior of these.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件是默认组件，且作为 Kubernetes 项目的一部分被官方支持。请记住，其他 Kubernetes 发行版可能会带来额外的组件，或改变这些组件的行为。
- en: These components are the strict minimum that you need to have a working Kubernetes
    cluster.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件是你需要的最基本组件，用于构建一个可工作的 Kubernetes 集群。
- en: Summary
  id: totrans-432
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: 'This was quite a big chapter, but at least you now have a list of all the Kubernetes
    components. Everything we will do later will be related to these components: they
    are the core of Kubernetes. This chapter was full of technical details too, but
    it was still relatively theoretical. Don’t worry if things are still not very
    clear to you. You will gain a better understanding through practice.'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 这一章内容相当庞大，但至少你现在已经列出了所有 Kubernetes 组件。我们接下来的所有操作都会与这些组件相关，它们是 Kubernetes 的核心。虽然这一章充满了技术细节，但依然偏向理论。如果你还感到不太清楚，不用担心，通过实践你将更好地理解。
- en: The good news is that you are now completely ready to install your first Kubernetes
    cluster locally, and things are going to be a lot more practical from now on.
    That is the next step, and that’s what we will do in the next chapter. After the
    next chapter, you’ll have a Kubernetes cluster running locally on your workstation,
    and you will be ready to run your first pods using Kubernetes!
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，你现在已经完全准备好在本地安装你的第一个 Kubernetes 集群，从现在开始，一切将变得更加实用。这是下一步，我们将在下一章进行。在下一章之后，你将在本地的工作站上运行一个
    Kubernetes 集群，并且你将准备好使用 Kubernetes 运行你的第一个 Pods！
- en: Further reading
  id: totrans-435
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 若要了解更多本章中涉及的主题，请查看以下资源：
- en: 'Kubernetes components: [https://kubernetes.io/docs/concepts/overview/components/](https://kubernetes.io/docs/concepts/overview/components/
    )'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 组件：[https://kubernetes.io/docs/concepts/overview/components/](https://kubernetes.io/docs/concepts/overview/components/)
- en: 'Cloud controller manager: [https://kubernetes.io/docs/concepts/architecture/cloud-controller/](https://kubernetes.io/docs/concepts/architecture/cloud-controller/
    )'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云控制器管理器：[https://kubernetes.io/docs/concepts/architecture/cloud-controller/](https://kubernetes.io/docs/concepts/architecture/cloud-controller/)
- en: 'Installing Kubernetes utilities (kubectl, kind, kubeadm, and minikube): [https://kubernetes.io/docs/tasks/tools/](https://kubernetes.io/docs/tasks/tools/
    )'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装 Kubernetes 工具（kubectl, kind, kubeadm, 和 minikube）：[https://kubernetes.io/docs/tasks/tools/](https://kubernetes.io/docs/tasks/tools/)
- en: 'Kubernetes legacy package repository changes on September 13, 2023: [https://kubernetes.io/blog/2023/08/31/legacy-package-repository-deprecation/](https://kubernetes.io/blog/2023/08/31/legacy-package-repository-deprecation/
    )'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 旧版包仓库变更（2023年9月13日）：[https://kubernetes.io/blog/2023/08/31/legacy-package-repository-deprecation/](https://kubernetes.io/blog/2023/08/31/legacy-package-repository-deprecation/)
- en: '`pkgs.k8s.io`: Introducing Kubernetes Community-Owned Package Repositories:
    [https://kubernetes.io/blog/2023/08/15/pkgs-k8s-io-introduction/](https://kubernetes.io/blog/2023/08/15/pkgs-k8s-io-introduction/
    )'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pkgs.k8s.io`：介绍 Kubernetes 社区拥有的包仓库：[https://kubernetes.io/blog/2023/08/15/pkgs-k8s-io-introduction/](https://kubernetes.io/blog/2023/08/15/pkgs-k8s-io-introduction/)'
- en: 'Operating etcd clusters for Kubernetes: [https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/
    )'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作 Kubernetes 的 etcd 集群：[https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/](https://kubernetes.io/docs/tasks/administer-cluster/configure-upgrade-etcd/)
- en: 'kubectl completion: [https://kubernetes.io/docs/reference/kubectl/generated/kubectl_completion/](https://kubernetes.io/docs/reference/kubectl/generated/kubectl_completion/
    )'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kubectl 完成： [https://kubernetes.io/docs/reference/kubectl/generated/kubectl_completion/](https://kubernetes.io/docs/reference/kubectl/generated/kubectl_completion/)
- en: 'Runtime class: [https://kubernetes.io/docs/concepts/containers/runtime-class/](https://kubernetes.io/docs/concepts/containers/runtime-class/
    )'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行时类：[https://kubernetes.io/docs/concepts/containers/runtime-class/](https://kubernetes.io/docs/concepts/containers/runtime-class/)
- en: Join our community on Discord
  id: totrans-445
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的 Discord 社区
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者进行讨论：
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
- en: '![](img/QR_Code119001106479081656.png)'
  id: totrans-448
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code119001106479081656.png)'
