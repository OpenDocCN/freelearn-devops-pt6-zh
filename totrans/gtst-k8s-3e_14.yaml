- en: Hardening Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we'll look at considerations for moving to production. We will
    also show you some helpful tools and third-party projects that are available in
    the Kubernetes community at large and where you can go to get more help.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will discuss the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Production characteristics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lessons learned from Kubernetes production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hardening the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kubernetes ecosystem
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where can you get help?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ready for production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this book, we have walked through a number of typical operations using
    Kubernetes. As we have been, K8s offers a variety of features and abstractions
    that ease the burden of day-to-day management for container deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are many characteristics that define a production-ready system for containers.
    The following diagram provides a high-level view of the major concerns for production-ready
    clusters. This is by no means an exhaustive list, but it''s meant to provide some
    solid ground for heading into production operations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/8bb4fd04-edf2-4be7-ad9e-f996021c0426.png)'
  prefs: []
  type: TYPE_IMG
- en: Production characteristics for container operations
  prefs: []
  type: TYPE_NORMAL
- en: We saw how the core concepts and abstractions of Kubernetes address a few of
    these concerns. The service abstraction has built-in service discovery and health
    checking at both the service and application level. We also get seamless application
    updates and scalability from the replication controller and deployment constructs.
    All of the core abstractions of services, replication controllers, replica sets,
    and pods work with a core scheduling and affinity rulesets and give us easy service
    and application composition.
  prefs: []
  type: TYPE_NORMAL
- en: There is built-in support for a variety of persistent storage options, and the
    networking model provides manageable network operations with options to work with
    other third-party providers. We also took a brief look at CI/CD integration with
    some of the popular tools in the marketplace.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, we have built-in system events tracking, and with the major cloud
    providers, an out-of-the-box setup for monitoring and logging. We also saw how
    this can be extended to third-party providers such as Stackdriver and Sysdig.
    These services also address overall node health and proactive trend deviation
    alerts.
  prefs: []
  type: TYPE_NORMAL
- en: The core constructs also help us address high availability in our application
    and service layers. The scheduler can be used with autoscaling mechanisms to provide
    this at a node level. Then, there is support for making the Kubernetes master
    itself highly available. In [Chapter 12](92883e26-5c4a-466e-bfe6-1a5e0d0997f9.xhtml),
    *Cluster Federation and Multi-Tenancy*, we took a brief look at the new federation
    capabilities that promise a multi-cloud and multi-data center model for the future.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we explored a new breed of operating systems that give us a slim base
    to build on and secure update mechanisms for patching and updates. The slim base,
    together with scheduling, can help us with efficient resource utilization. In
    addition, we looked at some hardened concerns and explored the image trust and
    verification tools available. Security is a wide topic and capability matrices
    exist for this topic alone.
  prefs: []
  type: TYPE_NORMAL
- en: Ready, set, go
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: While there are still some gaps, a variety of the remaining security and operation
    concerns are actively being addressed by third-party companies, as we will see
    in the following section. Going forward, the Kubernetes project will continue
    to evolve, and the community of projects and partners around K8s and Docker will
    also grow. The community is closing the remaining gaps at a phenomenal pace.
  prefs: []
  type: TYPE_NORMAL
- en: Lessons learned from production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes has been around long enough now that there are a number of companies
    running Kubernetes. In our day jobs, we''ve seen Kubernetes run in production
    across a number of different industry verticals and in numerous configurations.
    Let''s explore what folks across the industry are doing when providing customer-facing
    workloads. At a high level, there are several key areas:'
  prefs: []
  type: TYPE_NORMAL
- en: Make sure to set limits in your cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the appropriate workload types for your application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Label everything! Labels are very flexible and can contain a lot of information
    that can help identify an object, route traffic, or determine placement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Don't use default values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tweak the default values for the core Kubernetes components.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use load balancers as opposed to exposing services directly on a node's port.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Build your Infrastructure as Code and use provisioning tools such as CloudFormation
    or Terraform, and configuration tools such as Chef, Ansible, or Puppet.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider not running stateful workloads in production clusters until you build
    up expertise in Kubernetes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Investigate higher-function templating languages to maintain the state of your
    cluster. We'll explore a few options for an immutable infrastructure in the following
    chapter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use RBAC, the principle of least privilege, and separation of concerns wherever
    possible.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use TLS-enabled communications for all inter-cluster chatter. You can set up
    TLS and certificate rotation for the `kubelet` communication in your cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Until you're comfortable with managing Kubernetes, build lots of small clusters.
    It's more operational overhead, but it will get you into the deep end of experience
    faster so that you see more failure and experience the operator burden more heavily.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you get better at Kubernetes, build bigger clusters that use namespaces,
    network segmentation, and the authorization features to break up your cluster
    into pieces.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you're running a few large clusters, manage them with `kubefed`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you can, use the features of your given cloud service provider's built-in
    high availability on a Kubernetes platform. For example, run Regional Clusters
    on GCP, with GKE. This feature spreads your nodes across several availability
    zones in a region. This allows for resilience against a single zone failure, and
    provides the conceptual building blocks for the zero downtime upgrades of your
    master nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we'll explore one of these concepts – limits – in more
    detail.
  prefs: []
  type: TYPE_NORMAL
- en: Setting limits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you''ve done work with containers before, you will know that one of the
    first and easiest things to set up for your containers is resource limits in the
    form of the following metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: CPU
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Memory
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requests
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You may be familiar with setting runtime limits on resources with Docker''s
    CLI, which specify flags to limit these items and more:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we''re setting a runtime parameter, creating a `ulimit`, and setting
    memory and CPU quotas. The story evolves a bit in Kubernetes, as you can create
    these limits to a specific namespace, which allows you to characterize your limits
    by the domains of your cluster. You have four overarching parameters so that you
    can work resource limits in Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Scheduling limits
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When you create a pod with a memory limit, Kubernetes looks for a node with
    the right labels and selectors that has enough of the resource types, CPU, and
    memory, that the pod requires. Kubernetes is in charge of ensuring that the total
    memory request of the pods on a node is not less than the pod's total resources.
    This can sometimes result in unexpected outcomes, as you can have node limitations
    reached in terms of capacity, even if the net utilization of a pod is low. This
    is a design of the system in order to accommodate varying load levels.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can look through pod logs to find out when this has occurred:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You can address these issues by removing unneeded pods, ensuring that your pod
    isn't larger as a whole than any one available node, or simply add more resources
    to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Memory limit example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s walk through an example. First, we''ll create a namespace to house our
    memory limit:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we''ve created the namespace, we can create a file that sets a `LimitRange`
    object, which will allow us to enforce a default for memory limits and requests.
    Create a file called `memory-default.yaml` with the following contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'And now, we can create it in the namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Let's create a pod without a memory limit, in the low-memory-area namespace,
    and see what happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the following `low-memory-pod.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can create the pod with this command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see if our resource constraints were added to the pod''s configuration
    for containers, without having to explicitly specify it in the pod configuration.
    Notice the memory limits in place! We''ve removed some of the informational output
    for readability:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here''s the output of the preceding code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'You can delete the pod with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'There are a lot of options for configuring resource limits. If you create a
    memory limit, but don''t specify the default request, the request will be set
    to the maximum available memory, which will correspond to the memory limit. That
    will look like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: In a cluster with diverse workloads and API-driven relationships, it's incredibly
    important to set memory limits with your containers and their corresponding applications
    in order to prevent misbehaving applications from disrupting your cluster. Services
    don't implicitly know about each other, so they're very susceptible to resource
    exhaustion if you don't configure limits correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduling CPU constraints
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s look at another type of resource management, the constraint. We''ll
    use the CPU dimension here, and we''ll explore how to set the maximum and minimum
    values for available resources for a given container and pod in a namespace. There
    are a number of reasons you might want to limit CPU on a Kubernetes cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: If you have a namespaced cluster that has different levels of production and
    non-production workloads, you may want to specify higher limits for your production
    workloads. You can allow quad-core CPU consumption for production; put pin development,
    staging, or UAT-type workloads to a single CPU; or stagger them according to environment
    needs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also ban requests from pods that require more CPU resources than your
    nodes have available. If you're running a certain type of machine on a cloud service
    provider, you can ensure that workloads that require X cores aren't scheduled
    on machines with <X cores.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: CPU constraints example
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s go ahead and create another namespace in which to hold our example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Now, let's set up a `LimitRange` for CPU constraints, which uses the measurement
    of millicpus. If you're requesting 500 m, it means that you're asking for 500
    millicpus or millicores, which is equivalent to 0.5 in notational form. When you
    request 0.5 or 500 m, you're asking for half of a CPU in whatever form your platform
    provides (vCPU, Core, Hyper Thread, vCore, or vCPU).
  prefs: []
  type: TYPE_NORMAL
- en: 'As we did previously, let''s create a `LimitRange` for our CPU constraints:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can create the `LimitRange`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Once we create the `LimitRange`, we can inspect it. What you''ll notice is
    that the `defaultRequest` is specified as the same as the maximum, because we
    didn''t specify it. Kubernetes sets the `defaultRequest` to max:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: This is the intended behavior. When further containers are scheduled in this
    namespace, Kubernetes first checks to see whether the pod specifies a request
    and limit. If it doesn't, the defaults are applied. Next, the controller confirms
    that the CPU request is more than the lower bound in the `LimitRange`, 300 m.
    Additionally, it checks for the upper bound to make sure that the object is not
    asking for more than 500 m.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check the container constraints again by looking at the YAML output
    of the pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, don''t forget to delete the pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Securing a cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let's look at some other common recommendations for hardening your cluster in
    production. These use cases cover both intentional, malicious actions against
    your cluster, as well as accidental misuse. Let's take a look at what we can do
    to secure things.
  prefs: []
  type: TYPE_NORMAL
- en: 'First off, you want to ensure that access to the Kubernetes API is controlled.
    Given that all actions in Kubernetes are API-driven, we should secure this interface
    first. We can control access to this API with several settings:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Encode all traffic**: In order to keep communication secure, you should make
    sure that **Transport Level Security** (**TLS**) is set up for API communication
    in the cluster. Most of the installation methods we''ve reviewed in this book
    create the necessary component certificates, but it''s always on the cluster operators
    to identify all in-use local ports that may not use the more secure settings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Authenticate your access**: Just as with any large scale computer system,
    you want to ensure that the identity of a user is established. For small clusters,
    you can use certs or tokens, while larger production clusters should use OpenID
    or LDAP.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Control your access**: After you''ve established the identity of the role
    accessing your API, you always want to ensure that you pass your authenticated
    access request through an authorization filter with Kubernetes'' built-in **role-based-access-control** (**RBAC**),
    which helps operators limit control and access by roles and users. There are two
    authorizer plugins, node and RBAC, that can be used, along with the `NodeRestriction`
    admission plugin. A key point to keep in mind is that role granularity should
    increase as cluster size increases, and even more so from non-production environments
    toward production environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, authentication to use the `kubelet` is turned off. You can enable
    authorization/authentication on the `kubelet` by turning on certificate rotation.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about certificate rotation here: [https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-authentication-authorization/](https://kubernetes.io/docs/reference/command-line-tools-reference/kubelet-authentication-authorization/).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can also modify the usage of Kubernetes at runtime:'
  prefs: []
  type: TYPE_NORMAL
- en: Long-time operators of Kubernetes in production will recognize this as a reference
    point to our previous discussions on limits and policies. As discussed previously,
    resource quotas limit the number of resources provided within a namespace, while
    limits ranges between restrict minimum and maximum sizes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can determine the privileges of your pods by defining a security context.
    Here, you can specify things like a particular Linux user, group, volume mount
    access, allowing privilege escalation, and more.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can also restrict access to logical partitions of your cluster by using
    network policies. You can ensure that certain namespaces are off limits to users,
    or determine whether or not they're able to set up services with specific load
    balancer configuration or open ports on host nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'While the preceding patterns are useful for operations inside of Kubernetes,
    there are also several actions that you should take when securing your cluster
    from an external perspective:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First off, enable and monitor your logs! While this seems like a no-brainer,
    we see a lot of problems cropping up from people that aren''t watching their logs,
    or who haven''t created alerts based off these logs. Another hint: don''t store
    logs inside of your cluster! If your cluster is breached, then those logs will
    be an invaluable source of information for malicious agents.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make double sure that you restrict access to your etcd cluster. This can come
    in the form of setting up security groups or firewalls and ensuring that your
    etcd cluster nodes have the appropriate identity and access management from an
    infrastructure perspective. From a cluster perspective, make sure that you're
    always using TLS certificates for authentication and strong credentials. In no
    case should any components inside your cluster have read/write access to the full
    etcd key/value space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make sure to vet alpha/beta components and review third-party integrations.
    Make sure that you know what you're using when you enable it, and what it does
    when you turn it on! Emerging features or third-party tools may create attack
    surfaces or threat models where you're not aware of what dependencies they have.
    Beware of any tools that need to do work inside the kube-system, as it's a particularly
    powerful portion of the cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encrypt your secrets at rest in etcd. This is good advice for any computerized
    system, and Kubernetes is no different here. The same goes for your backups to
    ensure that an attacker can't gain access to your cluster via inspection of those
    resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For your production cluster, you should also be doing things such as scanning
    your container images, running static analysis of your YAML files, running containers
    as non-root users where possible, and running an **intrusion detection system**
    (**IDS**). Once you have all of this in place, you can begin to explore the functional
    capabilities of the service meshes out in the wild.
  prefs: []
  type: TYPE_NORMAL
- en: Third-party companies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since the Kubernetes project's initial release, there has been a growing ecosystem
    of partners. We looked at CoreOS, Sysdig, and many others in the previous chapters,
    but there are a variety of projects and companies in this space. We will highlight
    a few that may be useful as you move toward production. This is by no means an
    exhaustive list and it is merely meant to provide some interesting starting points.
  prefs: []
  type: TYPE_NORMAL
- en: Private registries
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In many situations, organizations will not want to place their applications
    and/or intellectual property in public repositories. For those cases, a private
    registry solution is helpful in securely integrating deployments end to end.
  prefs: []
  type: TYPE_NORMAL
- en: Google Cloud offers the Google Container Registry at [https://cloud.google.com/container-registry/](https://cloud.google.com/container-registry/).
  prefs: []
  type: TYPE_NORMAL
- en: Docker has its own trusted registry offering at [https://www.docker.com/docker-trusted-registry](https://www.docker.com/docker-trusted-registry).
  prefs: []
  type: TYPE_NORMAL
- en: Quay also provides secure private registries, vulnerability scanning, and comes
    from the CoreOS team, and can be found at [https://quay.io/](https://quay.io/).
  prefs: []
  type: TYPE_NORMAL
- en: Google Kubernetes Engine
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Google was the main author of the original Kubernetes project and is still a
    major contributor. Although this book has mostly focused on running Kubernetes
    on our own, Google also offers a fully managed container service through the Google
    Cloud Platform.
  prefs: []
  type: TYPE_NORMAL
- en: Find more information on the **Google Kubernetes Engine** (**GKE**) website
    at [https://cloud.google.com/container-engine/](https://cloud.google.com/container-engine/).
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes will be installed on GKE and will be managed by Google engineers.
    They also provide private registries and integration with your existing private
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'You create your first GKE cluster by using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: From the GCP console, in Compute, click on Container Engine, and then on Container
    Clusters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If this is your first time creating a cluster, you'll have an information box
    in the middle of the page. Click on the Create a container cluster button.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose a name for your cluster and the zone. You'll also be able to choose the
    machine type (instance size) for your nodes and how many nodes (cluster size)
    you want in your cluster. You'll also see a choice for node image, which lets
    you choose the base OS and machine image for the nodes themselves. The master
    is managed and updated by the Google team themselves.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Leave Stackdriver logging and Stackdriver monitoring checked. Click on Create,
    and in a few minutes, you'll have a new cluster ready for use.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You'll need `kubectl`, which is included with the Google SDK, to begin using
    your GKE cluster. Refer to [Chapter 1](446f901d-70fa-4ebe-be8a-0de14248f99c.xhtml),
    *Introduction to Kubernetes*, for details on installing the SDK. Once we have
    the SDK, we can configure `kubectl` and the SDK for our cluster using the steps
    outlined at [https://cloud.google.com/container-engine/docs/before-you-begin#install_kubectl](https://cloud.google.com/container-engine/docs/before-you-begin#install_kubectl).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Azure Kubernetes Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another cloud-managed offering is Microsoft's **Azure Kubernetes Service** (**AKS**).
    AKS is really nice because it allows you to choose from industry standard tools
    such as Docker Swarm, Kubernetes, and Mesos. It then creates a managed cluster
    for you, but uses one of these toolsets as the foundation. The advantage is that
    you can still use the tool's native API and management tools, but leave the management
    of the cloud infrastructure to Azure.
  prefs: []
  type: TYPE_NORMAL
- en: You can find out more about ACS at [https://azure.microsoft.com/en-us/services/container-service/](https://azure.microsoft.com/en-us/services/container-service/).
  prefs: []
  type: TYPE_NORMAL
- en: ClusterHQ
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ClusterHQ provides a solution for bringing stateful data into your containerized
    applications. They provide Flocker, a tool for managing persistent storage volumes
    with containers, and FlockerHub, which provides a storage repository for your
    data volumes.
  prefs: []
  type: TYPE_NORMAL
- en: Portworx
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Portworx is another player in the storage space. It provides solutions for bringing
    persistence storage to your containers. Additionally, it has features for snapshotting,
    encryption, and even multi-cloud replication.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the Portworx website for more information: [https://portworx.com/](https://portworx.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Shippable
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Shippable is a continuous integration, continuous deployment, and release automation
    platform that has built-in support for a variety of modern container environments.
    The product touts support for any language with a uniform support for packaging
    and test.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the Shippable website for more information: [https://app.shippable.com/](https://app.shippable.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Twistlock
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Twistlock.io is a vulnerability and hardening tool that's tailor-made for containers.
    It provides the ability to enforce policies, hardens according to CIS standards,
    and scans images in any popular registry for vulnerabilities. It also provides
    scan integration with popular CI/CD tools and RBAC solutions for many orchestration
    tools such as Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the Twistlock website for more information: [https://www.twistlock.com/](https://www.twistlock.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Aqua Sec
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Aqua Sec is another security tool that provides a variety of features. Image
    scanning with popular registries, policy enforcement, user access control, and
    container hardening are all covered. Additionally, Aqua Sec has some interesting
    functionality in network segmentation.
  prefs: []
  type: TYPE_NORMAL
- en: Please refer to the Aqua's website for more information: [https://www.aquasec.com/](https://www.aquasec.com/).
  prefs: []
  type: TYPE_NORMAL
- en: Mesosphere (Kubernetes on Mesos)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Mesosphere itself is building a commercially supported product around the open
    source Apache Mesos project. Apache Mesos is a cluster management system that
    offers scheduling and resource sharing, a bit like Kubernetes itself, but at a
    much higher level. The open source project is used by several well-known companies,
    such as Twitter and Airbnb.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can find out more information about the Mesos OS project and the Mesosphere
    offerings at the following sites:'
  prefs: []
  type: TYPE_NORMAL
- en: '[http://mesos.apache.org/](http://mesos.apache.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://mesosphere.com/](https://mesosphere.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mesos, by its nature, is modular, and allows the use of different frameworks
    for a variety of platforms. A Kubernetes framework is now available, so we can
    take advantage of the cluster management in Mesos while still maintaining the
    useful application-level abstractions in K8s. Refer to the following link for
    more information: [https://github.com/kubernetes-incubator/kube-mesos-framework](https://github.com/kubernetes-incubator/kube-mesos-framework).
  prefs: []
  type: TYPE_NORMAL
- en: Deis
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Deis project provides an open source **Platform as a Service** (**PaaS**)
    solution based on and around Kubernetes. This allows companies to deploy their
    own PaaS on-premise or on the public cloud. Deis provides tools for application
    composition and deployment, package management (at the pod level), and service
    brokering.
  prefs: []
  type: TYPE_NORMAL
- en: OpenShift
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Another PaaS solution is OpenShift from Red Hat. The OpenShift platform uses
    the Red Hat Atomic platform as a secure and slim OS for running containers. In
    version 3, Kubernetes was added as the orchestration layer for all container operations
    on your PaaS. This is a great combination for managing PaaS installations at a
    large scale.
  prefs: []
  type: TYPE_NORMAL
- en: More information on OpenShift can be found at [https://enterprise.openshift.com/.](https://enterprise.openshift.com/)
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we left a few breadcrumbs to guide you on your continuing journey
    with Kubernetes. You should have a solid set of production characteristics to
    get you started. There is a wide community in both the Docker and Kubernetes worlds.
    There are also a few additional resources that we provided if you need a friendly
    face along the way.
  prefs: []
  type: TYPE_NORMAL
- en: By now, you have seen the full spectrum of container operations with Kubernetes.
    You should be more confident in how Kubernetes can streamline the management of
    your container deployments and how you can plan to move containers off developer
    laptops and onto production servers. Now get out there and start shipping your
    containers!
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What are some of the key characteristics of production systems?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are two examples of third-party monitoring systems?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which tools can help you build Infrastructure as Code?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is RBAC?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What limits can you set in a Kubernetes cluster?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In which dimensions can constraints be set?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Which technology should be used to secure communication within a cluster?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Kubernetes project is an open source effort, so there is a broad community
    of contributors and enthusiasts. One great resource in order to find more assistance is
    the Kubernetes Slack channel: [http://slack.kubernetes.io/](http://slack.kubernetes.io/).
  prefs: []
  type: TYPE_NORMAL
- en: There is also a Kubernetes group on Google groups. You can join it at [https://groups.google.com/forum/#!forum/kubernetes-users](https://groups.google.com/forum/#!forum/kubernetes-users).
  prefs: []
  type: TYPE_NORMAL
- en: 'If you enjoyed this book, you can find more of my articles, how-tos, and various
    musings on my blogs and Twitter page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://medium.com/@grizzbaier](https://medium.com/@grizzbaier)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://twitter.com/grizzbaier](https://twitter.com/grizzbaier)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
