- en: '*Chapter 7*: Model Deployment and Automation'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 7 章*：模型部署与自动化'
- en: In the previous chapter, you saw how the platform enables you to build and register
    the model in an autonomous fashion. In this chapter, we will extend the **machine
    learning** (**ML**) engineering domain to model deployment, monitoring, and automation
    of deployment activities.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你了解了平台如何使你能够以自主管理的方式构建和注册模型。在本章中，我们将扩展 **机器学习** (**ML**) 工程领域，涵盖模型部署、监控和部署活动的自动化。
- en: You will learn how the platform provides the model packaging and deployment
    capabilities and how you can automate them. You will take the model from the registry,
    package it as a container, and deploy the model onto the platform to be consumed
    as an API. You will then automate all these steps using the workflow engine provided
    by the platform.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你将了解平台如何提供模型打包和部署功能，以及如何自动化这些过程。你将从注册表中获取模型，将其打包成容器，并将模型部署到平台上，作为 API 提供服务。接着，你将使用平台提供的工作流引擎自动化所有这些步骤。
- en: Once your model is deployed, it works well for the data it was trained upon.
    The real world, however, changes. You will see how the platform allows you to
    observe your model's performance. This chapter discusses the tools and techniques
    to monitor your model performance. The performance data could be used to decide
    whether the model needs retraining on the new dataset, or whether it is time to
    build a new model for the given problem.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你的模型部署完成，它将在其训练数据上表现良好。然而，现实世界是不断变化的。你将看到平台如何让你观察模型的性能。本章将讨论监控模型性能的工具和技术。这些性能数据可以帮助决定模型是否需要基于新的数据集重新训练，或者是否该为给定问题构建一个新的模型。
- en: 'In this chapter, you will learn about the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习以下主题：
- en: Understanding model inferencing with Seldon Core
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解使用 Seldon Core 的模型推理
- en: Packaging, running, and monitoring a model using Seldon Core
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Seldon Core 打包、运行和监控模型
- en: Understanding Apache Airflow
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 Apache Airflow
- en: Automating ML model deployments in Airflow
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Airflow 中自动化 ML 模型部署
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter includes some hands-on setup and exercises. You will need a running
    Kubernetes cluster configured with **Operator Lifecycle Manager**. Building such
    a Kubernetes environment is covered in [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040),
    *Exploring Kubernetes*. Before attempting the technical exercises in this chapter,
    please make sure that you have a working Kubernetes cluster and **Open Data Hub**
    (**ODH**) is installed on your Kubernetes cluster. Installing ODH is covered in
    [*Chapter 4*](B18332_04_ePub.xhtml#_idTextAnchor055), *The Anatomy of a Machine
    Learning Platform*.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包含一些动手设置和练习。你将需要一个运行中的 Kubernetes 集群，并且已配置 **Operator Lifecycle Manager**。如何构建这样的
    Kubernetes 环境将在[*第 3 章*](B18332_03_ePub.xhtml#_idTextAnchor040)中讨论，*探索 Kubernetes*。在尝试本章的技术练习之前，请确保你已经有一个可用的
    Kubernetes 集群，并且 **Open Data Hub** (**ODH**) 已经安装在你的 Kubernetes 集群上。安装 ODH 的过程将在[*第
    4 章*](B18332_04_ePub.xhtml#_idTextAnchor055)中讨论，*机器学习平台的结构*。
- en: Understanding model inferencing with Seldon Core
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解使用 Seldon Core 的模型推理
- en: In the previous chapter, you built the model. These models are built by data
    science teams to be used in production and serve the prediction requests. There
    are many ways to use a model in production, such as embedding the model with your
    customer-facing program, but the most common way is to expose the model as a REST
    API. The REST API can then be used by any application. In general, running and
    serving a model in production is called **model serving**.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，你已经构建了模型。这些模型是由数据科学团队构建的，用于生产环境并处理预测请求。有多种方式可以将模型投入生产使用，比如将模型嵌入到面向客户的程序中，但最常见的方式是将模型作为
    REST API 公开。然后，任何应用程序都可以使用这个 REST API。通常，运行和提供生产中的模型被称为 **模型服务**。
- en: However, once the model is in production, it needs to be monitored for performance
    and needs updating to meet the expected criteria. A hosted model solution enables
    you to not only serve the model but monitor its performance and generate alerts
    that can be used to trigger retraining of the model.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，一旦模型进入生产环境，它需要被监控其性能，并且需要更新以满足预期标准。托管的模型解决方案不仅可以让你提供模型服务，还能监控其性能并生成警报，用以触发模型的重新训练。
- en: 'Seldon is a UK-based firm that created a set of tools to manage the model''s
    life cycle. Seldon Core is an open source framework that helps expose ML models
    to be consumed as REST APIs. Seldon Core automatically exposes the monitoring
    statistics for the REST API, which can be consumed by **Prometheus**, the platform''s
    monitoring component. To expose your model as a REST API in the platform, the
    following steps are required:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Seldon 是一家总部位于英国的公司，创建了一套用于管理模型生命周期的工具。Seldon Core 是一个开源框架，帮助将机器学习模型暴露为 REST
    API 以供使用。Seldon Core 会自动暴露 REST API 的监控统计信息，这些信息可以被平台的监控组件**Prometheus**使用。要在平台中将模型暴露为
    REST API，您需要完成以下步骤：
- en: Write a language-specific wrapper for your model to expose as a service.
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为您的模型编写特定语言的包装器，将其暴露为服务。
- en: Containerize your model.
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将您的模型容器化。
- en: Define and deploy the model using the inference graph of your model using Seldon
    Deployment **custom resource** (**CR**) in Kubernetes
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Seldon 部署 **自定义资源**（**CR**）在 Kubernetes 中定义并部署模型，利用模型的推理图。
- en: Next, we will see these three steps in detail.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将详细了解这三个步骤。
- en: Wrapping the model using Python
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 封装模型
- en: Let's see how you can apply the preceding steps. In [*Chapter 6*](B18332_06_ePub.xhtml#_idTextAnchor086),
    *Machine Learning Engineering*, you registered your experiment details and a model
    with the MLflow server. Recall that the model file was stored in the artifacts
    of MLflow and named `model.pkl`.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下如何应用前面的步骤。在 [*第六章*](B18332_06_ePub.xhtml#_idTextAnchor086)，*机器学习工程* 中，您已将实验细节和模型注册到
    MLflow 服务器。回忆一下，模型文件被存储在 MLflow 的工件中，并命名为 `model.pkl`。
- en: 'Let''s take the model file and write a simple Python wrapper around it. The
    job of the wrapper is to use Seldon libraries to conveniently expose the model
    as a REST service. You can find the example of the wrapper in the code at `chapter7/model_deploy_pipeline/model_build_push/Predictor.py`.
    The key component of this wrapper is a function named `predict` that will be invoked
    from an HTTP endpoint created by the Seldon framework. *Figure 7.1* shows a simple
    Python wrapper using a `joblib` model:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将以模型文件为基础，写一个简单的 Python 包装器。包装器的作用是使用 Seldon 库将模型便捷地暴露为 REST 服务。您可以在 `chapter7/model_deploy_pipeline/model_build_push/Predictor.py`
    的代码中找到包装器的示例。这个包装器的关键组件是一个名为 `predict` 的函数，它会从 Seldon 框架创建的 HTTP 端点被调用。*图 7.1*
    显示了一个使用 `joblib` 模型的简单 Python 包装器：
- en: '![Figure 7.1 – A Python language wrapper for the model prediction'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.1 – 用于模型预测的 Python 语言包装器'
- en: '](img/B18332_07_001.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_001.jpg)'
- en: Figure 7.1 – A Python language wrapper for the model prediction
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – 用于模型预测的 Python 语言包装器
- en: The `predict` function receives a `numpy` array (`data_array`) and a set of
    column names (`column_names`), serialized from the HTTP request. The method returns
    the result of the prediction as either a `numpy` array or a list of values or
    bytes. There are many more methods available for the language wrapper and a full
    list is available at [https://docs.seldon.io/projects/seldon-core/en/v1.12.0/python/python_component.html#low-level-methods](https://docs.seldon.io/projects/seldon-core/en/v1.12.0/python/python_component.html#low-level-methods).
    Note that in later chapters of this book, you will see a more thorough inferencing
    example that will have additional wrappers for data transformation before prediction.
    But, for this chapter, we keep it as simple as possible.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`predict` 函数接收一个 `numpy` 数组（`data_array`）和一组列名（`column_names`），这些都是从 HTTP 请求中序列化过来的。该方法返回预测结果，结果可以是一个
    `numpy` 数组，或者是一个值或字节的列表。对于语言包装器，还有许多其他方法可以使用，完整的方法列表可以在 [https://docs.seldon.io/projects/seldon-core/en/v1.12.0/python/python_component.html#low-level-methods](https://docs.seldon.io/projects/seldon-core/en/v1.12.0/python/python_component.html#low-level-methods)
    中找到。请注意，在本书的后续章节中，您将看到更为详细的推理示例，其中会有额外的包装器用于数据转换。但在本章中，我们尽量保持简单。'
- en: The language wrapper is ready, and the next stage is to containerize the model
    and the language wrapper.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 语言包装器已准备好，下一步是将模型和语言包装器容器化。
- en: Containerizing the model
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器化模型
- en: What would you put in the container? Let's start with a list. You will need
    the model and the wrapper files. You will need the Seldon Python packages available
    in the container. Once you have all these packages, then you will use the Seldon
    services to expose the model. *Figure 7.2* shows a `Docker` file that is building
    one such container. This file is available in `Chapter 7/model_deployment_pipeline/model_build_push/Dockerfile.py`.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 你会把什么放入容器中？我们从一份清单开始。你需要模型和包装器文件。你还需要容器中可用的Seldon Python包。获取这些包后，你将使用Seldon服务来暴露模型。*图7.2*展示了一个构建此类容器的`Docker`文件。该文件位于`Chapter
    7/model_deployment_pipeline/model_build_push/Dockerfile.py`。
- en: '![Figure 7.2 – Docker file to package the model as a container'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.2 – 用于将模型打包为容器的Docker文件'
- en: '](img/B18332_07_002.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_002.jpg)'
- en: Figure 7.2 – Docker file to package the model as a container
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.2 – 用于将模型打包为容器的Docker文件
- en: 'Now, let''s understand the content of the Docker file:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们理解Docker文件的内容：
- en: '*Line 1* indicates the base container image for your model service. We have
    chosen the freely available image from Red Hat, but you can choose as per your
    convenience. This image could be your organization''s base image with the standard
    version of Python and related software.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第1行*指示了你模型服务的基础容器镜像。我们选择了来自Red Hat的免费镜像，但你可以根据自己的需要选择。这张镜像可以是你公司基础镜像，包含标准版本的Python及相关软件。'
- en: In *Line 3*, we have created a `microservice` directory to place all the related
    artifacts in our container.
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*第3行*，我们创建了一个`microservice`目录，将所有相关的文件放入我们的容器中。
- en: In *Line 4*, the first file we need to build the container is `base_requirements.txt`.
    This file contains the packages and dependencies for the Seldon Core system. You
    can find this file at `chapter7/model_deployment_pipeline/model_build_push/base_requirements.txt`.
    In this file, you will see that Seldon Core packages and `joblib` packages have
    been added.
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*第4行*，我们构建容器所需的第一个文件是`base_requirements.txt`。该文件包含Seldon Core系统的包和依赖项。你可以在`chapter7/model_deployment_pipeline/model_build_push/base_requirements.txt`中找到此文件。在该文件中，你会看到已添加了Seldon
    Core包和`joblib`包。
- en: '*Figure 7.3* shows the `base_requirements.txt` file:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '*图7.3*展示了`base_requirements.txt`文件：'
- en: '![Figure 7.3 – File adding Seldon and Joblib to the container'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.3 – 向容器中添加Seldon和Joblib文件'
- en: '](img/B18332_07_003.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_003.jpg)'
- en: Figure 7.3 – File adding Seldon and Joblib to the container
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.3 – 向容器中添加Seldon和Joblib文件
- en: '*Line 5* is using the `base_requirements.txt` file to install the Python packages
    onto the container.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第5行*使用`base_requirements.txt`文件将Python包安装到容器中。'
- en: In *Lines 7* and *8*, when you are training the model, you may use different
    packages. During inferencing, some of the packages may be needed; for example,
    if you have done input data scaling before model training using a library, you
    may need the same library to apply the scaling at inference time.
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在*第7行*和*第8行*，当你训练模型时，可能会使用不同的包。在推理时，某些包可能会需要；例如，如果你在模型训练之前使用某个库进行了输入数据缩放，你可能需要相同的库来在推理时应用缩放。
- en: In [*Chapter 6*](B18332_06_ePub.xhtml#_idTextAnchor086), *Machine Learning Engineering*,
    you registered your experiment details and a model with the MLflow server. Recall
    that the model file was stored in the artifacts along with a file containing packages
    used to train the model named `requirements.txt`. Using the `requirements.txt`
    file generated by MLflow, you can install the packages required to run your model,
    or you may choose to add these dependencies on your own to a custom file. *Figure
    7.4* shows the MLflow snapshot referred to in [*Chapter 6*](B18332_06_ePub.xhtml#_idTextAnchor086),
    *Machine Learning Engineering*. You can see the `requirements.txt` file here next
    to the `model.pkl` file.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第6章*](B18332_06_ePub.xhtml#_idTextAnchor086)，*机器学习工程*中，你将实验详情和模型注册到MLflow服务器。回想一下，模型文件与包含训练模型所用包的文件`requirements.txt`一起存储在工件中。使用MLflow生成的`requirements.txt`文件，你可以安装运行模型所需的包，或者你也可以选择将这些依赖项添加到自己的自定义文件中。*图7.4*展示了在[*第6章*](B18332_06_ePub.xhtml#_idTextAnchor086)，*机器学习工程*中提到的MLflow快照。你可以在这里看到与`model.pkl`文件并排的`requirements.txt`文件。
- en: '![Figure 7.4 – MLflow run artifacts'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '![图7.4 – MLflow运行工件'
- en: '](img/B18332_07_004.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_004.jpg)'
- en: Figure 7.4 – MLflow run artifacts
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图7.4 – MLflow运行工件
- en: '*Line 10*: You add the language wrapper files and the model files to the container.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '*第10行*：你将语言包装器文件和模型文件添加到容器中。'
- en: '*Line 11*: Here, you are using the `seldon-core-microservice` server to start
    the inferencing server. Notice that the parameters have been passed here, and
    in the next section, you will see how we can pass these parameters:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '*第 11 行*：在这里，您使用 `seldon-core-microservice` 服务器启动推理服务器。请注意，参数已经在这里传递，接下来您将看到如何传递这些参数：'
- en: '**MODEL_NAME**: This is the name of the Python class in the language wrapper
    containing the model.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MODEL_NAME**：这是包含模型的语言包装器中的 Python 类名称。'
- en: '`MODEL`.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MODEL`。'
- en: '**GRPC_PORT**: The port at which the **Google Remote Procedure Call** (**gRPC**)
    endpoint will listen for model inference.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**GRPC_PORT**：**Google 远程过程调用**（**gRPC**）端点将监听模型推理的端口。'
- en: '**METRICS_PORT**: The port at which the service performance data will be exposed.
    Note that this is the performance data for the service and not the model.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**METRICS_PORT**：暴露服务性能数据的端口。请注意，这里指的是服务的性能数据，而非模型的数据。'
- en: '**HTTP_NAME**: The HTTP port where will you serve the model over HTTP.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**HTTP_NAME**：您将通过 HTTP 提供模型的 HTTP 端口。'
- en: Now, we have a container specification in the form of the Docker file. Next,
    we will see how to deploy the container on the Kubernetes platform using the Seldon
    controller.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个以 Docker 文件形式的容器规格。接下来，我们将看到如何使用 Seldon 控制器在 Kubernetes 平台上部署容器。
- en: Deploying the model using the Seldon controller
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Seldon 控制器部署模型
- en: Our ML platform provides a Seldon controller, a piece of software that runs
    as a pod and assists in deploying the containers you built in the preceding section.
    Note that the controller in our platform is the extension of the existing Seldon
    operator. At the time of writing, the Seldon operator was not compatible with
    Kubernetes version 1.22, so we have extended the existing operator to work with
    the latest and future versions of the Kubernetes platform.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的机器学习平台提供了一个 Seldon 控制器，它作为一个 Pod 运行，并协助部署您在前一部分构建的容器。请注意，我们平台中的控制器是现有 Seldon
    操作符的扩展。在撰写本文时，Seldon 操作符不兼容 Kubernetes 版本 1.22，因此我们扩展了现有操作符，以便与最新及未来版本的 Kubernetes
    平台兼容。
- en: 'Refer to [*Chapter 4*](B18332_04_ePub.xhtml#_idTextAnchor055), *The Anatomy
    of a Machine Learning Platform*, where you learned about installing ODH and how
    it works on the Kubernetes cluster. In an equivalent manner, the Seldon controller
    is also installed by the ODH operator. The `manifests/ml-platform.yaml` file has
    the configuration for installing the Seldon controller. *Figure 7.5* shows the
    settings:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅 [*第 4 章*](B18332_04_ePub.xhtml#_idTextAnchor055)，*机器学习平台的构成*，在那里您学习了如何安装
    ODH 以及它如何在 Kubernetes 集群上工作。以同样的方式，Seldon 控制器也是由 ODH 操作符安装的。`manifests/ml-platform.yaml`
    文件包含了安装 Seldon 控制器的配置。*图 7.5* 展示了这些设置：
- en: '![Figure 7.5 – MLFlow section of the manifest file'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.5 – 清单文件的 MLFlow 部分'
- en: '](img/B18332_07_005.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_005.jpg)'
- en: Figure 7.5 – MLFlow section of the manifest file
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5 – 清单文件的 MLFlow 部分
- en: 'Let''s verify whether the Seldon controller is running correctly in the cluster:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们验证 Seldon 控制器是否在集群中正确运行：
- en: '[PRE0]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You should see the following response:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下响应：
- en: '![Figure 7.6 – Seldon controller pod'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.6 – Seldon 控制器 Pod'
- en: '](img/B18332_07_006.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_006.jpg)'
- en: Figure 7.6 – Seldon controller pod
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6 – Seldon 控制器 Pod
- en: 'The Seldon controller pod is installed by the ODH operators, which watch for
    the Seldon Deployment CR. This schema for this resource is defined by the Seldon
    Deployment `manifests/odhseldon/cluster/base/seldon-operator-crd-seldondeployments.yaml`.
    Once you create the Seldon Deployment CR, the controller deploys the pods associated
    with the CR. *Figure 7.7* shows this relationship:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Seldon 控制器 Pod 是由 ODH 操作符安装的，这些操作符会监视 Seldon 部署 CR。该资源的架构由 Seldon 部署 `manifests/odhseldon/cluster/base/seldon-operator-crd-seldondeployments.yaml`
    定义。一旦创建 Seldon 部署 CR，控制器将部署与该 CR 关联的 Pod。*图 7.7* 展示了这种关系：
- en: '![Figure 7.7 – Components of the platform for deploying Seldon services'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.7 – 用于部署 Seldon 服务的平台组件'
- en: '](img/B18332_07_007.jpg)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_007.jpg)'
- en: Figure 7.7 – Components of the platform for deploying Seldon services
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7 – 用于部署 Seldon 服务的平台组件
- en: Let's see the different components of the Seldon Deployment CR. You can find
    one simple example in `chapter7/manual_model_deployment/SeldonDeploy.yaml`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 Seldon 部署 CR 的不同组件。您可以在 `chapter7/manual_model_deployment/SeldonDeploy.yaml`
    中找到一个简单的示例。
- en: 'The Seldon Deployment CR contains all the information that is required by the
    Seldon controller to deploy your model on the Kubernetes cluster. There are three
    main sections in the Seldon Deployment CR:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
- en: '`apiVersion`, `kind`, and other Kubernetes-related information. You will define
    the labels and name of the Seldon Deployment as any other Kubernetes object. You
    can see in the following screenshot that it contains the labels and annotations
    for the object:'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.8 – Seldon Deployment – Kubernetes-related information'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_008.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.8 – Seldon Deployment – Kubernetes-related information
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '`chapter7/manual_model_deployment/SeldonDeploy.yaml` file that has this information.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Notice that `containers` take an array for the `image` object, so you can add
    more images to it. The `image` key will have the location of your container. The
    `env` array defines the environment variables that will be available for the pod.
    Recall that, in our Docker file in the previous section, these variables have
    been used. `MODEL_NAME` has a value of `Predictor`, which is the name of the class
    you have used as a wrapper. `SERVICE_TYPE` has a value of `MODEL`, which mentions
    the type of service this container provides.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: The last part has `hpaSpec`, which the Seldon controller will translate onto
    the `maxReplicas` is set to `1`, so there will not be any new pods, but you can
    control this value for each deployment. The scalability will kick in if the CPU
    utilization goes beyond 80% for the pods in the following example; however, because
    `maxReplica` is `1`, there will not be any new pods created.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.9 – Seldon Deployment – Seldon service containers'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_009.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.9 – Seldon Deployment – Seldon service containers
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: '`graph` key builds the inference graph for your service. An inference graph
    will have different nodes and you will define what container will be used at each
    node. You will see there is a `children` key that takes an array of objects through
    which you define your inference graph. For this example, `graph` has only one
    node and the `children` key has no information associated with it; however, in
    the later chapters, you will see how to build the inference graph with more nodes.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The remaining fields under the graph define the first node of your inference
    graph. The `name` field has the value that corresponds to the name you have given
    in the `containers` section. Note that this is the key through which Seldon knows
    what container would be serving at this node of your inference graph.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: The other important part is the `logger` section. Seldon can automatically forward
    the request and response to the URL mentioned under the `logger` section. The
    capability of forwarding the request and response can be used for a variety of
    scenarios, such as storing the payload for audit/legal reasons or applying data
    drift algorithms to trigger retraining or anything else. Note that Seldon can
    also forward to Kafka if needed, but this is outside the scope of this book.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个重要部分是 `logger` 部分。Seldon 可以自动将请求和响应转发到 `logger` 部分下提到的 URL。转发请求和响应的功能可以用于多种场景，例如出于审计/法律原因存储负载，或者应用数据漂移算法触发重新训练，或其他用途。请注意，Seldon
    也可以在需要时将请求转发到 Kafka，但这超出了本书的讨论范围。
- en: '![Figure 7.10 – Seldon Deployment – inference graph'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.10 – Seldon 部署 – 推理图'
- en: '](img/B18332_07_010.jpg)'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_010.jpg)'
- en: Figure 7.10 – Seldon Deployment – inference graph
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10 – Seldon 部署 – 推理图
- en: Once you create the Seldon Deployment CR using the routine `kubectl` command,
    the Seldon controller will deploy the pods, and the model will be available for
    consumption as a service.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你使用常规的 `kubectl` 命令创建 Seldon 部署 CR，Seldon 控制器将部署 pods，并且模型将作为服务供消费。
- en: Next, we'll move on to packaging and deploying the basic model that you built
    in [*Chapter 6*](B18332_06_ePub.xhtml#_idTextAnchor086), *Machine Learning Engineering*.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将继续打包并部署你在[*第 6 章*](B18332_06_ePub.xhtml#_idTextAnchor086)中构建的基础模型，*机器学习工程*。
- en: Packaging, running, and monitoring a model using Seldon Core
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Seldon Core 打包、运行和监控模型
- en: In this section, you will package and build the container from the model file
    you built in [*Chapter 6*](B18332_06_ePub.xhtml#_idTextAnchor086), *Machine Learning
    Engineering*. You will then use the Seldon Deployment to deploy and access the
    model. Later in this book, you will automate the process, but to do it manually,
    as you'll do in this section, we will further strengthen your understanding of
    the components and how they work.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，你将打包并构建容器，使用你在[*第 6 章*](B18332_06_ePub.xhtml#_idTextAnchor086)中构建的模型文件。然后，你将使用
    Seldon 部署来部署并访问该模型。稍后在本书中，你将自动化这一过程，但手动完成，如本节所做的那样，将进一步加深你对组件及其工作原理的理解。
- en: 'Before you start this exercise, please make sure that you have created an account
    with a public Docker registry. We will use the free `quay.io` as our registry,
    but you are free to use your preferred one:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始此练习之前，请确保你已经在公共 Docker 注册表上创建了一个帐户。我们将使用免费的 `quay.io` 作为我们的注册表，但你也可以使用你偏好的其他注册表：
- en: 'Let''s first verify that MLflow and Minio (our S3 server) are running in our
    cluster:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们首先验证 MLflow 和 Minio（我们的 S3 服务器）是否在集群中运行：
- en: '[PRE1]'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You should see the following response:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 7.11 – MLflow and Minio are running on the platform'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.11 – MLflow 和 Minio 正在平台上运行'
- en: '](img/B18332_07_011.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_011.jpg)'
- en: Figure 7.11 – MLflow and Minio are running on the platform
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11 – MLflow 和 Minio 正在平台上运行
- en: 'Get the ingress list for MLflow, and log in to MLflow using the `mlflow` URL
    available from the following output:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取 MLflow 的 ingress 列表，并通过以下输出中提供的 `mlflow` URL 登录 MLflow：
- en: '[PRE2]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'You should see the following response:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 7.12 – ingress in your Kubernetes cluster'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.12 – 你的 Kubernetes 集群中的 ingress'
- en: '](img/B18332_07_012.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_012.jpg)'
- en: Figure 7.12 – ingress in your Kubernetes cluster
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12 – 你的 Kubernetes 集群中的 ingress
- en: Once you are in the MLflow UI, navigate to the experiment that you recorded
    in [*Chapter 6*](B18332_06_ePub.xhtml#_idTextAnchor086), *Machine Learning Engineering*.
    The name of the experiment is **HelloMIFlow**.
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦进入 MLflow UI，导航到你在[*第 6 章*](B18332_06_ePub.xhtml#_idTextAnchor086)中记录的实验，*机器学习工程*。该实验的名称是**HelloMIFlow**。
- en: '![Figure 7.13 – MlFlow Experiment Tracking'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.13 – MlFlow 实验跟踪'
- en: '](img/B18332_07_013.jpg)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_013.jpg)'
- en: Figure 7.13 – MlFlow Experiment Tracking
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13 – MlFlow 实验跟踪
- en: Select the first run from the right-hand panel to get to the detail page of
    the run. From the `model.pkl` and you will see a little download arrow icon to
    the right. Use the icon to download the `requirements.txt` files from this screen.
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从右侧面板选择第一个运行，进入该运行的详细页面。从`model.pkl`文件中，你会看到右侧有一个小的下载箭头图标。点击该图标下载`requirements.txt`文件。
- en: '![Figure 7.14 – MLflow experiment tracking – run details'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.14 – MLflow 实验跟踪 – 运行详情'
- en: '](img/B18332_07_014.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_014.jpg)'
- en: Figure 7.14 – MLflow experiment tracking – run details
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14 – MLflow 实验跟踪 – 运行详情
- en: Go to the folder where you have cloned the code repository that comes with this
    book. If you have not done so, please clone the [https://github.com/PacktPublishing/Machine-Learning-on-Kubernetes.git](https://github.com/PacktPublishing/Machine-Learning-on-Kubernetes.git)
    repository on your local machine.
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入你克隆的代码仓库所在文件夹。如果还没克隆，请在本地机器上克隆[https://github.com/PacktPublishing/Machine-Learning-on-Kubernetes.git](https://github.com/PacktPublishing/Machine-Learning-on-Kubernetes.git)仓库。
- en: 'Then, go to the `chapter7/model_deploy_pipeline/model_build_push` folder and
    copy the two files downloaded in the previous step to this folder. In the end,
    this folder will have the following files:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，进入`chapter7/model_deploy_pipeline/model_build_push`文件夹，并将上一步骤中下载的两个文件复制到此文件夹。最终，这个文件夹将包含以下文件：
- en: '![Figure 7.15 – Sample files to package the model as a container'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.15 – 示例文件，用于将模型打包为容器'
- en: '](img/B18332_07_015.jpg)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_015.jpg)'
- en: Figure 7.15 – Sample files to package the model as a container
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.15 – 示例文件，用于将模型打包为容器
- en: Note
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The last two files are the ones that you have just copied. All other files are
    coming from the code repository that you have cloned.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 最后两个文件就是你刚才复制的文件。所有其他文件来自你克隆的代码仓库。
- en: Curious people will note that the `requirements.txt` file that you have downloaded
    from the MLFlow server contains the packages required while you run the notebook
    for model training. Not all of these packages (`mlflow`, for example) will be
    needed to execute the saved model. To keep things simple, we will add all of them
    to our container.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 好奇的人会注意到，你从 MLFlow 服务器下载的`requirements.txt`文件包含了在运行笔记本进行模型训练时所需的包。并不是所有这些包（例如`mlflow`）都需要用来执行保存的模型。为了简单起见，我们将它们全部添加到我们的容器中。
- en: 'Now, let''s build the container on the local machine:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们在本地机器上构建容器：
- en: '[PRE3]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You should see the following response:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 7.16 – Packaging the model as a container'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.16 – 将模型打包为容器'
- en: '](img/B18332_07_016.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_016.jpg)'
- en: Figure 7.16 – Packaging the model as a container
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.16 – 将模型打包为容器
- en: 'The next step is to tag the container and push it to the repository of your
    choice. Before you push your image to a repository, you will need to have an account
    with an image registry. If you do not have one, you can create one at [https://hub.docker.com](https://hub.docker.com)
    or [https://quay.io](https://quay.io). Once you have created your registry, you
    can run the following commands to tag and push the image:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下一步是标记容器并将其推送到你选择的仓库。在将镜像推送到仓库之前，你需要拥有一个镜像注册表账户。如果没有，可以在[https://hub.docker.com](https://hub.docker.com)
    或 [https://quay.io](https://quay.io) 创建一个账户。创建好注册表后，你可以运行以下命令来标记并推送镜像：
- en: '[PRE4]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You should see the following response. You will notice that, in the following
    screenshot, we refer to `quay.io/ml-on-k8s` as our registry:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应。你会注意到，在以下截图中，我们将`quay.io/ml-on-k8s`称为我们的注册表：
- en: '![Figure 7.17 – Pushing the model to a public repository'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.17 – 将模型推送到公共仓库'
- en: '](img/B18332_07_017.jpg)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_017.jpg)'
- en: Figure 7.17 – Pushing the model to a public repository
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.17 – 将模型推送到公共仓库
- en: Now that your container is available in a registry, you will need to use the
    Seldon Deployment CR to deploy it as a service. Open the `chapter7/manual_model_deployment/SeldonDeploy.yaml`
    file and adjust the location of the image.
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你的容器已经在一个注册表中可用，你需要使用 Seldon 部署 CR 将其部署为服务。打开`chapter7/manual_model_deployment/SeldonDeploy.yaml`文件，并调整镜像的位置。
- en: 'You can see the file after I have modified *line 16* (as per my image location)
    as follows:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到我修改后的文件，它显示了*第16行*（根据我的镜像位置）如下：
- en: '![Figure 7.18 – Seldon Deployment CR with the image location'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.18 – 带有镜像位置的 Seldon 部署 CR'
- en: '](img/B18332_07_018.jpg)'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_018.jpg)'
- en: Figure 7.18 – Seldon Deployment CR with the image location
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.18 – 带有镜像位置的 Seldon 部署 CR
- en: 'Let''s deploy the model as a service by deploying the `chapter7/manual_model_deployment/SeldonDeploy.yaml`
    file. Run the following command:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们通过部署`chapter7/manual_model_deployment/SeldonDeploy.yaml`文件来将模型作为服务部署。运行以下命令：
- en: '[PRE5]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You should see the following response:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 7.19 – Creating the Seldon Deployment CR'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.19 – 创建 Seldon 部署 CR'
- en: '](img/B18332_07_019.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_019.jpg)'
- en: Figure 7.19 – Creating the Seldon Deployment CR
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.19 – 创建 Seldon 部署 CR
- en: 'Validate that the container is in a running state. Run the following command:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证容器是否处于运行状态。运行以下命令：
- en: '[PRE6]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You will note that the name that you have put in the `graph` section of the
    `SeldonDeploy.yaml` file (`model-test-predictor`) is part of the container name.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: 'You should see the following response:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.20 – Validating the pod after the Seldon Deployment CR'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_020.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.20 – Validating the pod after the Seldon Deployment CR
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! You have a model running as a service. Now, let''s see what is in the
    pod created for us by the Seldon controller. Run the following command to get
    a list of containers inside our pod:'
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You should see the following response:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.21 – Containers inside the Seldon pod'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_021.jpg)'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.21 – Containers inside the Seldon pod
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: You will see that there are two containers. One is `model-test-predictor`, which
    is the image that we have built, and the second container is `seldon-container-engine`,
    which is the Seldon server.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'The `model-test-predictor` container has the model and is using the language
    wrapper to expose the model over HTTP and gRPC. You can use the following command
    to see the logs and what ports have been exposed from `model-test-predictor`:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You should see the following response (among other logs):'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.22 – Containers log showing the ports'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_022.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.22 – Containers log showing the ports
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see that the servers are ready to take the calls on `9000` for HTTP
    and on `6005` for the metrics server. This metrics server will have the Prometheus-based
    monitoring data exposed on the `/prometheus` endpoint. You can see this in the
    following portion of the log:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.23 – Containers log showing the Prometheus endpoint'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_023.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.23 – Containers log showing the Prometheus endpoint
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: The second container is `seldon-container-engine`, which does the orchestration
    for the inference graph and forwards the payloads to the service configured by
    you in the `logger` section of the Seldon Deployment CR.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'In this step, you will find out what Kubernetes objects your Seldon Deployment
    CR has created for you. A simple way to find out is by running the command as
    follows. This command depends on the Seldon controller labeling the objects it
    creates with the label key as `seldon-deployment-id`, and the value is the name
    of your Seldon Deployment CR, which is `model-test`:'
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-170
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You should see the following response:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.24 – Kubernetes objects created by the Seldon controller'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_024.jpg)'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.24 – Kubernetes objects created by the Seldon controller
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: You can see that there are Deployment objects, services, and **Horizontal Pod
    Autoscalers** (**HPA**) objects created for you for the Seldon controller using
    the configuration that you have provided in the Seldon Deployment CR. The deployment
    ends up creating pods and a replica set for your pods. The Seldon controller made
    it easy to deploy our model on the Kubernetes platform.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'You may have noticed that there is no ingress object created by the Seldon
    Deployment CR. Let''s create the ingress object so that we can call our model
    from outside the cluster by running the command as follows. The ingress object
    is created by the file in `chapter7/manual_model_deployment/Ingress.yaml`. Make
    sure to adjust the `host` value as per your configuration, as you have done in
    earlier chapters. You will also notice that the ingress is forwarding traffic
    to port `8000`. Seldon provides the listener to this port, which orchestrates
    the inference call. This service is available in the container named `seldon-container-engine`:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可能已经注意到，Seldon 部署 CR 没有创建入口对象。让我们创建入口对象，以便通过运行以下命令从集群外部调用我们的模型。入口对象是通过`chapter7/manual_model_deployment/Ingress.yaml`中的文件创建的。确保根据你的配置调整`host`值，正如你在前面的章节中所做的那样。你还会注意到，入口将流量转发到端口`8000`。Seldon
    提供了对该端口的监听器，负责协调推理调用。此服务可在名为`seldon-container-engine`的容器中使用：
- en: '[PRE10]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You should see the following response:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 7.25 – Creating ingress objects for our service'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.25 – 为我们的服务创建入口对象'
- en: '](img/B18332_07_025.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_025.jpg)'
- en: Figure 7.25 – Creating ingress objects for our service
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.25 – 为我们的服务创建入口对象
- en: 'Validate that the ingress has been created by issuing the following command:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行以下命令来验证入口是否已创建：
- en: '[PRE11]'
  id: totrans-183
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You should see the following response:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 7.26 – Validating the ingress for our service'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.26 – 验证我们服务的入口'
- en: '](img/B18332_07_026.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_026.jpg)'
- en: Figure 7.26 – Validating the ingress for our service
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.26 – 验证我们服务的入口
- en: 'Since our Seldon Deployment CR has referenced a logger URL, you will deploy
    a simple HTTP echo server that will just print the calls it received. This will
    assist us in validating whether the payloads have been forwarded to the configured
    URL in the `logger` section of the Seldon Deployment CR. A very simple echo server
    can be created via the following command:'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于我们的 Seldon 部署 CR 已引用了日志记录器 URL，你将部署一个简单的 HTTP 回显服务器，它只会打印收到的请求。这将帮助我们验证负载是否已转发到
    Seldon 部署 CR 中`logger`部分配置的 URL。可以通过以下命令创建一个非常简单的回显服务器：
- en: '[PRE12]'
  id: totrans-189
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You should see the following response:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 7.27 – Creating a simple HTTP echo server to validate payload logging'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.27 – 创建一个简单的 HTTP 回显服务器以验证负载日志记录'
- en: '](img/B18332_07_027.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_027.jpg)'
- en: Figure 7.27 – Creating a simple HTTP echo server to validate payload logging
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.27 – 创建一个简单的 HTTP 回显服务器以验证负载日志记录
- en: 'Validate that the pod has been created by issuing the following command:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 通过执行以下命令来验证 Pod 是否已创建：
- en: '[PRE13]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You should see the following response:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 7.28 – Validating a simple HTTP echo server'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.28 – 验证一个简单的 HTTP 回显服务器'
- en: '](img/B18332_07_028.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_028.jpg)'
- en: Figure 7.28 – Validating a simple HTTP echo server
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.28 – 验证一个简单的 HTTP 回显服务器
- en: Let's make a call for our model to predict something. The model we developed
    in the previous chapter is not very useful, but it will help us understand and
    validate the overall process of packaging and deploying the model.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 让我们调用模型进行预测。我们在上一章中开发的模型并不是非常有用，但它将帮助我们理解并验证整体的模型打包和部署过程。
- en: Recall from [*Chapter 6*](B18332_06_ePub.xhtml#_idTextAnchor086), *Machine Learning
    Engineering*, that the `hellomlflow` notebook has the input for the model with
    shape `(4,2)`, and the output shape is `(4,)`.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下 [*第六章*](B18332_06_ePub.xhtml#_idTextAnchor086)，*机器学习工程*，`hellomlflow`笔记本的模型输入形状是
    `(4,2)`，输出形状是 `(4,)`。
- en: '![Figure 7.29 – Input and output for the model'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.29 – 模型的输入和输出'
- en: '](img/B18332_07_029.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_029.jpg)'
- en: Figure 7.29 – Input and output for the model
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.29 – 模型的输入和输出
- en: 'So, if we want to send data to our model, it would be an array of integer pairs
    such as [`2,1`]. When you make a call to your model, the input data is required
    within an `ndarray` field under a key named `data`. The input would look as follows.
    This is the format the Seldon service expects for the data to be sent to it:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们要向模型发送数据，它将是一个整数对数组，例如[`2,1`]。当你调用模型时，输入数据必须位于一个名为`data`的字段下，并使用`ndarray`格式。输入数据将如下所示。这是
    Seldon 服务期望发送给它的数据格式：
- en: '![Figure 7.30 – Input for the model as an HTTP payload'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 7.30 – 作为 HTTP 负载的模型输入'
- en: '](img/B18332_07_030.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_07_030.jpg)'
- en: Figure 7.30 – Input for the model as an HTTP payload
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.30 – 作为 HTTP 负载的模型输入
- en: 'Next is the REST endpoint for the model. It will be the ingress that you created
    in *Step 13* and the standard Seldon URL. The final form would be as follows:
    http://<INGRESS_LOCATION>/api/v1.0/predictions.'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This would translate, in my case, to [http://model-test.192.168.61.72.nip.io/api/v1.0/predictions](http://model-test.192.168.61.72.nip.io/api/v1.0/predictions).
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: Now, you have the payload and the URL to send this request to.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: In this step, you will make a call to your model. We are using a commonly used
    command-line option to make this call; however, you may choose to use other software,
    such as Postman, to make this HTTP call.
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You will use the `POST` HTTP verb in the call and then provide the location
    of the service. You will have to pass the `Content-Type` header to mention JSON
    content and the body is passed using the `data-raw` flag of the curl program:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-214
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The final request should look as follows. Before making this call, make sure
    to change the URL as per your ingress location:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'You should see the following response. Note that the output of the command
    shows the array of the same shape as per our model, which is `(4,)`, and it is
    under the `ndarray` key in the following screenshot:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.31 – Output payload for the model inference call'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_031.jpg)'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.31 – Output payload for the model inference call
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s verify that the model payload has been logged onto our echo server.
    You are validating the capability of Seldon to capture input and output and send
    it to the desired location for further processing, such as drift detection or
    audit logging:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'You will see there is a separate record for the input and the output payload.
    You can use the `ce-requestid` key to correlate the two records in the logs. The
    following screenshot displays the main fields of the captured input payload of
    the inference call:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.32 – Captured input payload forwarded to the echo pod'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_032.jpg)'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.32 – Captured input payload forwarded to the echo pod
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot displays the main fields of the output payload of
    the inference call:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.33 – Captured output payload forwarded to the echo pod'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_033.jpg)'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.33 – Captured output payload forwarded to the echo pod
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: Now, let's verify that service monitoring data is captured by the Seldon engine
    and is available for us to use and record. Note that the way Prometheus works
    is by scraping repetitively, so this data is in the current state and the Prometheus
    server is responsible for calling this URL and record in its database.
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The URL format for this information is as follows. The ingress is the same
    as you created in *Step 13*:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'This would translate to the following for my ingress:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Open a browser and access the URL in it. You should see the following response:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.34 – Accessing monitoring data in Prometheus format'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_034.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.34 – Accessing monitoring data in Prometheus format
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: You will find that a lot of information is captured, including response times,
    the number of HTTP responses per status code (`200`, `400`, `500`, and so on),
    data capture, server performance, and exposing the Go runtime metrics. We encourage
    you to go through these parameters to develop an understanding of the data available.
    In the later chapters, you will see how to harvest and plot this data to visualize
    the performance of the model inferencing server.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: You have done a great deal in this exercise. The aim of this section was to
    showcase the steps and components involved to deploy a model using Seldon Core.
    In the next section, you will be introduced to the workflow component of the platform,
    Airflow, and in the next couple of chapters, all of these steps will be automated
    using the components in the ML platform.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: Introducing Apache Airflow
  id: totrans-242
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Apache Airflow is an open source software designed for programmatically authoring,
    executing, scheduling, and monitoring workflows. A workflow is a sequence of tasks
    that can include data pipelines, ML workflows, deployment pipelines, and even
    infrastructure tasks. It was developed by Airbnb as a workflow management system
    and was later open sourced as a project in Apache Software Foundation's incubation
    program.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: While most workflow engines use XML to define workflows, Airflow uses Python
    as the core language for defining workflows. The tasks within the workflow are
    also written in Python.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Airflow has many features, but we will cover only the fundamental bits of Airflow
    in this book. This section is by no means a detailed guide for Airflow. Our focus
    is to introduce you to the software components for the ML platform. Let's start
    with DAG.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Understanding DAG
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A workflow can be simply defined as a sequence of **tasks**. In Airflow, the
    sequence of tasks follows a data structure called a **directed acyclic graph**
    (**DAG**). If you remember your computer science data structures, a DAG is composed
    of nodes and one-way vertices organized in a way to ensure that there are no cycles
    or loops. Hence, a workflow in Airflow is called a DAG.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 7.35* shows a typical example of a data pipeline workflow:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.35 – Typical data pipeline workflow'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_035.jpg)'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.35 – Typical data pipeline workflow
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: 'The example workflow in *Figure 7.36* is composed of tasks represented by boxes.
    The order of execution of these tasks is determined by the direction of the arrows:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.36 – Example workflow with parallel execution'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_036.jpg)'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.36 – Example workflow with parallel execution
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: Another example of a workflow is shown in *Figure 7.36*. In this example, there
    are tasks that are executed in parallel. The **Generate Report** tasks will wait
    for both **Transform Data** tasks to complete. This is called **execution dependency**
    and it is one of the problems Airflow is solving. Tasks can only execute if the
    upstream tasks are completed.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: 'You can configure the workflow however you want as long as there are no cycles
    in the graph, as shown in *Figure 7.37*:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.37 – Example workflow with cycle'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_037.jpg)'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.37 – Example workflow with cycle
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: In the example in *Figure 7.37*, the **Clean Data** task will never be executed
    because it is dependent on the **Store Data** task, which will also not be executed.
    Airflow only allows acyclic graphs.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: 'As illustrated, a DAG is a series of tasks, and there are three common types
    of tasks in Airflow:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '**Operators**: Predefined tasks that you can use to execute something, They
    can be strung together to form a pipeline or a workflow. Your DAG is composed
    mostly, if not entirely, of operators.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sensors**: Subtypes of operators that are used for a series of other operators
    based on an external event.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`@task`. This allows you to run regular Python functions as tasks.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Airflow operators are extendable, which means there are quite a lot of predefined
    operators created by the community that you can simply use. One of the operators
    that you will mostly use in the following exercises is the **Notebook Operator**.
    This operator allows you to run any Jupyter notebook as tasks in the DAG.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: So, what are the advantages of using DAGs to execute a sequence of tasks? Isn't
    it enough to just write a script that can execute other scripts sequentially?
    Well, the answer lies in the features that Airflow offers, which we will explore
    next.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Airflow features
  id: totrans-268
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The advantages that Airflow brings when compared with `cron` jobs and scripts
    can be detailed by its features. Let''s start by looking at some of those features:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: '**Failure and error management**: In the event of a task failure, Airflow handles
    errors and failures gracefully. Tasks can be configured to automatically retry
    when they fail. You can also configure how many times it retries.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In terms of execution sequence, there are two types of task dependencies in
    a typical workflow that can be managed in Airflow much easier than writing a script.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '**Data dependencies**: Some tasks may require that the other tasks be processed
    first because they require data that is generated by other tasks. This can be
    managed in Airflow. Moreover, Airflow allows the passing of small amounts of metadata
    from the output of one task as an input to another task.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Execution dependencies**: You may be able to script execution dependencies
    in a small workflow. However, imagine scripting a workflow in Bash with a hundred
    tasks, where some tasks can run concurrently while others can only run sequentially.
    I imagine this to be a pretty daunting task. Airflow helps simplify this by creating
    DAGs.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: Airflow can horizontally scale to multiple machines or containers.
    The tasks in the workflow may be executed on different nodes while being orchestrated
    centrally by a common scheduler.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`git` repository containing your DAGs. This allows you to implement the continuous
    integration of DAGs.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The next step is to understand the different components of Airflow.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Airflow components
  id: totrans-277
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Airflow comprises multiple components running as independent services. *Figure
    7.38* shows the components of Airflow and their interactions:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.38 – Airflow components'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_038.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.38 – Airflow components
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: There are three core services in Airflow. The **Airflow Web** serves the user
    interface where users can visually monitor and interact with DAGs and tasks. The
    **Airflow Scheduler** is a service responsible for scheduling tasks for the Airflow
    Worker. Scheduling does not only mean executing tasks according to their scheduled
    time. It's also about executing the tasks in a particular sequence, taking into
    account the execution dependencies and failure management. **Airflow Worker**
    is the service that executes the tasks. This is also the main scalability point
    of Airflow. The more Airflow Worker is running, the more tasks can be executed
    concurrently.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: The DAG repository is a directory in the filesystem where DAG files written
    in Python are stored and retrieved by the scheduler. The Airflow instance configured
    in our platform includes a sidecar container that synchronizes the DAG repository
    with a remote `git` repository. This simplifies the deployment of DAGs by simply
    pushing a Python file to Git.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: We will not dig too deep into Airflow in this book. The objective is for you
    to learn enough to a point where you are able to create pipelines in Airflow with
    minimal Python coding. You will use the Elyra notebooks pipeline builder feature
    to build Airflow pipelines graphically. If you want to learn more about Airflow
    and how to build pipelines programmatically in Python, we recommend that you start
    with Apache Airflow's very rich documentation at [https://airflow.apache.org/docs/apache-airflow/stable/concepts/overview.html](https://airflow.apache.org/docs/apache-airflow/stable/concepts/overview.html).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have a basic understanding of Airflow, it's time to take a look
    at it in action. In [*Chapter 4*](B18332_04_ePub.xhtml#_idTextAnchor055), *The
    Anatomy of a Machine Learning Platform*, you installed a fresh instance of ODH.
    This process also installed the Airflow services for you. Now, let's validate
    this installation.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Validating the Airflow installation
  id: totrans-286
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To validate that Airflow is running correctly in your cluster, you need to
    perform the following steps:'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: 'Check whether all the Airflow pods are running by executing the following command:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-289
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'You should see the three Airflow services pods in running status, as shown
    in the following screenshot in *Figure 7.39*. Verify that all pods are in the
    `Running` state:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.39 – Airflow pods in the Running state'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_039.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.39 – Airflow pods in the Running state
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'Get the URL of Airflow Web by looking at the ingress host of `ap-airflow2`.
    You can do this by executing the following command:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'You should see results similar to *Figure 7.39*. Take note of the host value
    of the `ap-airflow2` ingress. The IP address may be different in your environment:'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.40 – Airflow ingress in the ml-workshop namespace'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_040.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.40 – Airflow ingress in the ml-workshop namespace
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to [https://airflow.192.168.49.2.nip.io](https://airflow.192.168.49.2.nip.io).
    Note that the domain name is the host value of the `ap-airflow2` ingress. You
    should see the Airflow Web UI, as shown in *Figure 7.41*:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.41 – Home screen of Apache Airflow'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_041.jpg)'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.41 – Home screen of Apache Airflow
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: If you are able to load the Airflow landing page, it means that the Airflow
    installation is valid. You must have also noticed that in the table listing the
    DAGs, there are already existing DAGs currently in failing status. These are existing
    DAG files that are in [https://github.com/airflow-dags/dags/](https://github.com/airflow-dags/dags/),
    the default configured DAG repository. You will need to create your own DAG repository
    for your experiments. The next section will provide the details on how to do this.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the Airflow DAG repository
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A DAG repository is a Git repository where Airflow picks up the DAG files that
    represent your pipelines or workflows. To configure Airflow to point to your own
    DAG repository, you need to create a Git repository and point the Airflow Scheduler
    and Airflow Web to this Git repository. You will use **GitHub** to create this
    repository. The following steps will guide you through the process:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a GitHub repository by going to [https://github.com](https://github.com).
    This requires that you have an existing account with GitHub. For the purpose of
    this exercise, let''s call this repository `airflow-dags`. Take note of the URL
    of your new Git repository. It should look like this: [https://github.com/your-user-name/airflow-dags.git](https://github.com/your-user-name/airflow-dags.git).
    We assume that you already know how to create a new repository on GitHub.'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Edit your instance of ODH by editing the `kfdef` (**Kubeflow definition**)
    object. You can do this by executing the following command:'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-309
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: You should be presented with a `vim` editor showing the `kfdef` manifest file
    as shown in *Figure 7.42*. Press *i* to start editing.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.42 – vim editor showing the section defining the Airflow instance'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_042.jpg)'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.42 – vim editor showing the section defining the Airflow instance
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Replace the value of the `DAG_REPO` parameter with the URL of the Git repository
    you created in *Step 1*. The edited file should look like the screenshot in *Figure
    7.43*. Press *Esc*, then *:*, and type `wq` and press *Enter* to save the changes
    you made to the `kfdef` object.
  id: totrans-314
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.43 – Value of the DAG_REPO parameter after editing'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_043.jpg)'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.43 – Value of the DAG_REPO parameter after editing
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: The changes will be picked up by the ODH operator and will be applied to the
    affected Kubernetes deployment objects, in this case, Airflow Web and Airflow
    Scheduler deployments. This process will take a couple of minutes to complete.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: 'Validate the changes by inspecting the Airflow deployments. You can do this
    by running the following command to look into the applied manifest of the deployment
    object:'
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This should return a line containing the URL of your GitHub repository.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: 'Because this repository is new and is empty, you should not see any DAG files
    when you open the Airflow Web UI. To validate the Airflow web application, navigate
    to your Airflow URL, or refresh your existing browser tab, and you should see
    an empty Airflow DAG list similar to the screenshot in *Figure 7.44*:'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.44 – Empty Airflow DAG list'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_044.jpg)'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.44 – Empty Airflow DAG list
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have validated your Airflow installation and updated the DAG repository
    to your own `git` repository, it's time to put Airflow to good use.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Airflow runtime images
  id: totrans-327
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Airflow pipelines, or DAGs, can be authored by writing Python files using the
    Airflow libraries. However, it is also possible to create DAGs graphically from
    an Elyra notebook. In this section, you will create an Airflow DAG from Elyra,
    push it to the DAG repository, and execute it in Airflow.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: 'To further validate the Airflow setup and test the configuration, you will
    need to run a simple `Hello world` pipeline. Follow the steps to create a two-task
    pipeline. You will create Python files, a pipeline, and configure runtime images
    to be used throughout the process:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: If you do not have a running notebook environment, start a notebook environment
    by navigating to JupyterHub, clicking **Start My Server**, and selecting a notebook
    image to run, as shown in *Figure 7.45*. Let's use **Base Elyra Notebook Image**
    this time as we do not require any special libraries.
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.45 – JupyterHub landing page showing Base Elyra Notebook Image selected'
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_045.jpg)'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.45 – JupyterHub landing page showing Base Elyra Notebook Image selected
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: In your Elyra browser, navigate to the `Machine-Learning-on-Kubernetes/chapter7/model_deploy_pipeline/`
    directory.
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open a new pipeline editor. You can do this by selecting the menu item `untitled.pipeline`.
  id: totrans-335
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.46 – Elyra notebook'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_046.jpg)'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.46 – Elyra notebook
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: Right-click on the `untitled.pipeline` file and rename it to `hello_world.pipeline`.
  id: totrans-339
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create two Python files with the same contents containing the following line:
    `print(''Hello airflow!'')`. You can do this by selecting the menu items `hello.py`
    and `world.py`. Your directory structure should look like the screenshot in *Figure
    7.47*:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.47 – Elyra directory structure showing the hello.pipeline file'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_047.jpg)'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.47 – Elyra directory structure showing the hello.pipeline file
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: Create a pipeline with two tasks by dragging the `hello.py` file into the pipeline
    editor window. Do the same for `world.py`. Connect the tasks by dragging the tiny
    circle on the right of the task box to another box. The resulting pipeline topology
    should look like the illustration in *Figure 7.48*. Save the pipeline by clicking
    the **Save** icon in the top toolbar.
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.48 – Task topology'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_048.jpg)'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.48 – Task topology
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we can run this pipeline, we need to configure each of the tasks. Because
    each task will run as a container in Kubernetes, we need to tell which container
    image that task will use. Select the **Runtime Images** icon on the toolbar on
    the left. Then, click the **+** button to add a new runtime image, as shown in
    *Figure 7.49*:'
  id: totrans-348
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.49 – Adding a new runtime image in Elyra'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_049.jpg)'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.49 – Adding a new runtime image in Elyra
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: In the **Add new Runtime Image** dialog, add the details of the **Kaniko Container
    Builder** image, as shown in *Figure 7.50*, and hit the **SAVE & CLOSE** button.
  id: totrans-352
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This container image ([https://quay.io/repository/ml-on-k8s/kaniko-container-builder](https://quay.io/repository/ml-on-k8s/kaniko-container-builder))
    contains the tools required to build Docker files and push images to an image
    registry from within Kubernetes. This image can also pull ML models and metadata
    from the MLflow model registry. You will use this image to build containers that
    host your ML model in the next section. This container image was created for the
    purpose of this book. You can use any container image as a runtime image for your
    pipeline tasks as long as the image can run on Kubernetes.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.50 – Add new Runtime Image dialog for Kaniko builder'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_050.jpg)'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.50 – Add new Runtime Image dialog for Kaniko builder
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: 'Add another runtime image called **Airflow Python Runner**. The container image
    is located at [https://quay.io/repository/ml-on-k8s/airflow-python-runner](https://quay.io/repository/ml-on-k8s/airflow-python-runner).
    This image can run any Python 3.8 scripts, and interact with Kubernetes and Spark
    operators. You will use this image to deploy container images to Kubernetes in
    the next section. Refer to *Figure 7.51* for the **Add new Runtime Image** dialog
    field values, and then hit the **SAVE & CLOSE** button:'
  id: totrans-357
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.51 – Add new Runtime Image dialog for Airflow Python Runner'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_051.jpg)'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.51 – Add new Runtime Image dialog for Airflow Python Runner
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: Pull the images from the remote repository to the local Docker daemon of your
    Kubernetes cluster. This will help speed up the start up times of tasks in Airflow
    by using a runtime image that is already pulled into the local Docker instance.
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'You can do this by running the following command on the same machine where
    your Minikube is running. This command allows you to connect your Docker client
    to the Docker daemon inside your Minikube **virtual machine** (**VM**):'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-363
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Pull the **Kaniko Container Builder** image by running the following command
    in the same machine where your Minikube is running. This will pull the image from
    [quay.io](http://quay.io) to the Docker daemon inside your Minikube:'
  id: totrans-364
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-365
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Pull the **Airflow Python Runner** image by running the following command in
    the same machine where your Minikube is running:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: Assign `hello.py` task. You can do this by right-clicking the task box and selecting
    the **Properties** context menu item. The properties of the task will be displayed
    in the right pane of the pipeline editor, as shown in *Figure 7.52*. Using the
    **Runtime Image** drop-down box, select **Kaniko Container Builder**.
  id: totrans-368
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.52 – Setting the runtime image of a task in the pipeline editor'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_052.jpg)'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.52 – Setting the runtime image of a task in the pipeline editor
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: If you do not see the newly added runtime images in the drop-down list, you
    need to close and reopen the pipeline editor. This will refresh the list of runtime
    images.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: 'Assign the `world.py` task. This is similar to *Step 10*, but for the `world.py`
    task. Refer to *Figure 7.53* for the **Runtime Image** value:'
  id: totrans-374
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.53 – Setting the runtime image of a task in the pipeline editor'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_053.jpg)'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.53 – Setting the runtime image of a task in the pipeline editor
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: 'You have just created an Airflow pipeline that has two tasks, where each task
    uses a different runtime. But, before we can run this pipeline in Airflow, we
    need to tell Elyra where Airflow is. To do this, select the **Runtimes** icon
    on the left toolbar of Elyra, as shown in *Figure 7.54*:'
  id: totrans-378
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.54 – Runtimes toolbar'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_054.jpg)'
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.54 – Runtimes toolbar
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: Hit the `ml-workshop`. This is the namespace of all your ML platform workloads.
  id: totrans-382
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`github-username/airflow-dags` format. Replace `github-username` with your
    GitHub username.'
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`minio`.'
  id: totrans-384
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`minio123`.'
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once all the fields are filled correctly, hit the **SAVE & CLOSE** button.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.55 – Adding a new Apache Airflow runtime configuration'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_055.jpg)'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.55 – Adding a new Apache Airflow runtime configuration
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: 'Run the pipeline in Airflow by clicking the **Play** button in the top toolbar
    of the pipeline editor. This will bring up a **Run pipeline** dialog. Select **Apache
    Airflow runtime** as the runtime platform and **MyAirflow** as the runtime configuration,
    and then hit **OK**. Refer to *Figure 7.56*:'
  id: totrans-390
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.56 – Run pipeline dialog'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_056.jpg)'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.56 – Run pipeline dialog
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: This action generates an Airflow DAG file and pushes the file to the GitHub
    repository configured as a DAG repository. You can verify this by checking your
    GitHub repository for newly pushed files.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: Open the Airflow website. You should see the newly create DAG, as shown in *Figure
    7.57*. If you do not see it, refresh the Airflow page a few times. Sometimes,
    it takes a few seconds before the DAGs appear in the UI.
  id: totrans-395
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.57 – Airflow showing a running DAG'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_057.jpg)'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.57 – Airflow showing a running DAG
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: The DAG should succeed in a few minutes. If it does fail, you need to review
    the steps to make sure you set the correct values and that you did not miss any
    steps.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: You have just created a basic Airflow DAG using Elyra's graphical pipeline editor.
    The generated DAG is, by default, configured to only run once, indicated by the
    `@once` annotation. In the real world, you may not want to run your DAGs directly
    from Elyra. You may want to add additional customizations to the DAG file. In
    this case, instead of running the DAG by clicking the play button, use the export
    feature. This will export the pipeline into a DAG file that you can further customize,
    such as setting the schedule. You can then push the customized DAG file to the
    DAG repository to submit it to Airflow.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: You have just validated your Airflow setup, added Airflow runtime configuration,
    and integrated Elyra with Airflow. Now it is time to build a real deployment pipeline!
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: Automating ML model deployments in Airflow
  id: totrans-402
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You have seen in the preceding sections how to manually package an ML model
    into a running HTTP service on Kubernetes. You have also seen how to create and
    run basic pipelines in Airflow. In this section, you will put this new knowledge
    together by creating an Airflow DAG to automate the model deployment process.
    You will create a simple Airflow pipeline for packaging and deploying an ML model
    from the MLflow model registry to Kubernetes.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: Creating the pipeline by using the pipeline editor
  id: totrans-404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Similar to the previous section, you will use Elyra''s pipeline editor to create
    the model build and deployment DAG:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: If you do not have a running Elyra environment, start a notebook environment
    by navigating to JupyterHub, clicking **Start My Server**, and selecting a notebook
    image to run, as shown in *Figure 7.45*. Let's use **Base Elyra Notebook Image**
    because this time, we do not require any special libraries.
  id: totrans-406
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In your Elyra browser, navigate to the `Machine-Learning-on-Kubernetes/chapter7/model_deploy_pipeline/`
    directory.
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Open a new pipeline editor. You can do this by selecting the menu item `untitled.pipeline`.
  id: totrans-408
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Right-click on the `untitled.pipeline` file and rename it `model_deploy.pipeline`.
    Your directory structure should look like the screenshot in *Figure 7.58*:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.58 – Elyra showing empty pipeline editor'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_058.jpg)'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.58 – Elyra showing empty pipeline editor
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: 'You will build a pipeline with two tasks in it. The first task will pull the
    model artifacts from the MLflow model registry, package the model as a container
    using Seldon core, and then push the container image to an image repository. To
    create the first task, drag and drop the `build_push_image.py` file from the `model_build_push`
    directory to the pipeline editor''s workspace. This action will create a new task
    in the pipeline editor window, as shown in *Figure 7.59*:'
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.59 – Elyra pipeline editor showing the build_push_image task'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_059.jpg)'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.59 – Elyra pipeline editor showing the build_push_image task
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: 'The second task will pull the container image from the image repository and
    deploy it to Kubernetes. Create the second task by dragging the `deploy_model.py`
    file from `model_deploy directory` and dropping it into the pipeline editor workspace.
    This action will create a second task in the pipeline editor, as shown in *Figure
    7.60*:'
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.60 – Elyra pipeline editor showing the deploy_model task'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_060.jpg)'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.60 – Elyra pipeline editor showing the deploy_model task
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: Connect the two tasks by dragging the tiny circle at the right-hand side of
    the `build_push_image.py` task to the `deploy_model.py` task box. The task topology
    should look like the illustration in *Figure 7.61*. Take note of the direction
    of the arrow highlighted in the red box.
  id: totrans-421
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.61 – Task topology of the DAG'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_061.jpg)'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.61 – Task topology of the DAG
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: Configure the `build_push_image.py` task by right-clicking the box and selecting
    **Properties**. A property panel will appear on the right side of the editor,
    as shown in *Figure 7.62*. Select **Kaniko Container Builder** as the runtime
    image for this task.
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.62 – Pipeline editor with the property panel displayed showing the
    Kaniko Builder runtime'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_062.jpg)'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.62 – Pipeline editor with the property panel displayed showing the
    Kaniko Builder runtime
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: Add file dependencies to `build_push_image.py` by clicking the `Dockerfile`
    – This is the Docker file that will be built to produce the container image that
    contains the ML model and the Predictor Python file.
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Predictor.py` – This is the Python file used by Seldon to define the inference
    graph. You have seen this file in the preceding section.'
  id: totrans-430
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Base_requirements.txt` – This is a regular text file that contains a list
    of Python packages required to run this model. This is used by the `pip install`
    command inside the Docker file.'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: At this point, you should have an idea of what the entire pipeline does. Because
    the pipeline needs to push a container image to a registry, you will need a container
    registry to hold your ML model containers. Create a new repository in a container
    registry of your choice. For the exercises in this book, we will use `mlflowdemo`.
  id: totrans-432
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you have the image repository created, set the `build_push_image.py` task,
    as shown in *Figure 7.63*. The following are the six variables you need to set:'
  id: totrans-433
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`MODEL_NAME` is the name of the ML model registered in MLflow. You used the
    name `mlflowdemo` in the previous sections. Set the value of this variable to
    `mlflowdemo`.'
  id: totrans-434
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`MODEL_VERSION` is the version number of the ML model registered in MLflow.
    Set the value of this variable to `1`.'
  id: totrans-435
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CONTAINER_REGISTRY` is the container registry API endpoint. For Docker Hub,
    this is available at [https://index.docker.io/v1](https://index.docker.io/v1).
    Set the value of this variable to `https://index.docker.io/v1/`.'
  id: totrans-436
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CONTAINER_REGISTRY_USER` is the username of the user who will push images
    to the image registry. Set this to your Docker Hub username.'
  id: totrans-437
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CONTAINER_REGISTRY_PASSWORD` is the password of your Docker Hub user. In production,
    you do not want to do this. You may use secret management tools to serve your
    Docker Hub password. However, to keep things simple for this exercise, you will
    put your Docker Hub password as an environment variable.'
  id: totrans-438
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CONTAINER_DETAILS` is the name of the repository where the image will be pushed,
    along with the name and tag of the image. This includes the Docker Hub username
    in the `your-username/mlflowdemo:latestv` format.'
  id: totrans-439
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Save the changes by clicking the **Save** icon from the top toolbar of the
    pipeline editor:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.63 – Example environment variables of the build_push_image.py task'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_063.jpg)'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.63 – Example environment variables of the build_push_image.py task
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
- en: 'Configure the `deploy_model.py` task by setting the runtime image, the file
    dependencies, and the environment variables, as shown in *Figure 7.64*. There
    are four environment variables you need to set, as detailed in the following list:'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`MODEL_NAME` is the name of the ML model registered in MLflow. You used the
    name `mlflowdemo` in the previous sections. Set the value of this variable to
    `mlflowdemo`.'
  id: totrans-445
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`MODEL_VERSION` is the version number of the ML model registered in MLflow.
    Set the value of this variable to `1`.'
  id: totrans-446
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`CONTAINER_DETAILS` is the name of the repository to where the image will be
    pushed and the image name and tag. This includes the Docker Hub username in the
    `your-username/mlflowdemo:latest` format.'
  id: totrans-447
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`CLUSTER_DOMAIN_NAME` is the DNS name of your Kubernetes cluster, in this case,
    the IP address of Minikube, which is `<Minikube IP>.nip.io`. For example, if the
    response of the `minikube ip` command is `192.168.49.2`, then the cluster domain
    name is `192.168.49.2.nip.io`. This is used to configure the ingress of the ML
    model HTTP service so that it is accessible outside the Kubernetes cluster.'
  id: totrans-448
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Save the changes by clicking the **Save** icon from the top toolbar of the pipeline
    editor.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.64 – Properties of the deploy_model.py task'
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_064.jpg)'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.64 – Properties of the deploy_model.py task
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: You are now ready to run the pipeline. Hit the **Play** button from the top
    toolbar of the pipeline editor. This will bring up the **Run** pipeline dialog,
    as shown in *Figure 7.65*. Select **Apache Airflow runtime** under **Runtime Platform**,
    and **MyAirflow** under **Runtime Configuration**. Click the **OK** button. This
    will generate the Airflow DAG Python file and push it to the Git repository.
  id: totrans-453
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.65 – Run pipeline dialog'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_065.jpg)'
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.65 – Run pipeline dialog
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: Once the DAG is successfully generated and pushed to the `git` repository, you
    should see a dialog as shown in *Figure 7.66*. Click **OK**.
  id: totrans-457
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.66 – DAG submission confirmation dialog'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_066.jpg)'
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.66 – DAG submission confirmation dialog
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: Navigate to Airflow's GUI. You should see a new DAG, labeled **model_deploy-some-number**,
    appear in the DAGs table, and it should start running shortly, as shown in *Figure
    7.67*. The mint green color of the job indicates that it is currently running.
    Dark green indicates that it is successful.
  id: totrans-461
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Note
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: If you do not see the new DAG, refresh the page until you see it. It may take
    a few seconds for the Airflow to sync with the Git repository.
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 7.67 – Airflow GUI showing the model_deploy DAG'
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_067.jpg)'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.67 – Airflow GUI showing the model_deploy DAG
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: Meanwhile, you can explore the DAG by clicking the DAG name and selecting the
    **Graph View** tab. It should display the topology of tasks as you designed it
    in Elyra's pipeline editor, as shown in *Figure 7.68*. You may explore the DAG
    further by selecting the **<> Code** tab. This will display the generated source
    code of the DAG.
  id: totrans-467
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 7.68 – Graph view of the model_deploy DAG in Airflow'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_068.jpg)'
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.68 – Graph view of the model_deploy DAG in Airflow
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: 'After a few minutes, the job should succeed and you should see the outline
    of all the tasks in **Graph View** turn to dark green. You can also explore the
    tasks by looking at the pods in Kubernetes. Run the following command and you
    should see two pods with the **Completed** status, as shown in *Figure 7.69*.
    These pods are the two tasks in the pipeline that have been executed successfully:'
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'You should see the following response:'
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.69 – Kubernetes pods with a Completed status'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_07_069.jpg)'
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: Figure 7.69 – Kubernetes pods with a Completed status
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
- en: You have just created a complete ML model build and deployment pipeline using
    Seldon Core, Elyra's pipeline editor, orchestrated by Airflow, and deployed to
    Kubernetes.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: Seldon Core and Airflow are big tools that have a lot more features that we
    have not covered and will not be entirely covered in this book. We have given
    you the essential knowledge and skills to start exploring these tools further
    as part of your ML platform.
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-479
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Congratulations! You made it this far!
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: As of this point, you have already seen and used JupyterHub, Elyra, Apache Spark,
    MLflow, Apache Airflow, Seldon Core, and Kubernetes. You have learned how these
    tools can solve the problems that MLOps is trying to solve. And, you have seen
    all these tools running well on Kubernetes.
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot more things that we want to show you on the platform. However,
    we can only write so much, as the features of each of those tools that you have
    seen are enough to fill an entire book.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will take a step back to look at the big picture of
    what has been built so far. Then, you will start using the platform end-to-end
    on an example use case. You will be wearing different hats, such as data scientist,
    ML engineer, data engineer, and a DevOps person in the succeeding chapters.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
