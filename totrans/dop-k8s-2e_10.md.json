["```\n//specify CIDR block as 10.0.0.0/16\n//the result, it returns VPC ID as \"vpc-0ca37d4650963adbb\"\n$ aws ec2 create-vpc --cidr-block 10.0.0.0/16\n{\n \"Vpc\": {\n \"CidrBlock\": \"10.0.0.0/16\",\n \"DhcpOptionsId\": \"dopt-3d901958\",\n \"State\": \"pending\",\n \"VpcId\": \"vpc-0ca37d4650963adbb\",\n...\n```", "```\n$ aws ec2 create-subnet --vpc-id vpc-0ca37d4650963adbb --cidr-block 10.0.1.0/24 --availability-zone us-east-1a\n{\n \"Subnet\": {\n \"AvailabilityZone\": \"us-east-1a\",\n \"AvailabilityZoneId\": \"use1-az6\",\n \"AvailableIpAddressCount\": 251,\n \"CidrBlock\": \"10.0.1.0/24\",\n \"DefaultForAz\": false,\n \"MapPublicIpOnLaunch\": false,\n \"State\": \"pending\",\n \"SubnetId\": \"subnet-09f8f7f06c27cb0a0\",\n \"VpcId\": \"vpc-0ca37d4650963adbb\",\n...\n```", "```\n$ aws ec2 create-subnet --vpc-id vpc-0ca37d4650963adbb --cidr-block 10.0.2.0/24 --availability-zone us-east-1b\n{\n \"Subnet\": {\n \"AvailabilityZone\": \"us-east-1b\",\n \"AvailabilityZoneId\": \"use1-az1\",\n \"AvailableIpAddressCount\": 251,\n \"CidrBlock\": \"10.0.2.0/24\",\n \"DefaultForAz\": false,\n \"MapPublicIpOnLaunch\": false,\n \"State\": \"pending\",\n \"SubnetId\": \"subnet-04b78ed9b5f96d76e\",\n \"VpcId\": \"vpc-0ca37d4650963adbb\",\n...\n```", "```\n$ aws ec2 create-subnet --vpc-id vpc-0ca37d4650963adbb --cidr-block 10.0.3.0/24 --availability-zone us-east-1b\n{\n \"Subnet\": {\n \"AvailabilityZone\": \"us-east-1b\",\n \"AvailabilityZoneId\": \"use1-az1\",\n \"AvailableIpAddressCount\": 251,\n \"CidrBlock\": \"10.0.3.0/24\",\n \"DefaultForAz\": false,\n \"MapPublicIpOnLaunch\": false,\n \"State\": \"pending\",\n \"SubnetId\": \"subnet-026058e32f09c28af\",\n \"VpcId\": \"vpc-0ca37d4650963adbb\",\n... \n```", "```\n$ aws ec2 create-subnet --vpc-id vpc-0ca37d4650963adbb --cidr-block 10.0.4.0/24 --availability-zone us-east-1a\n{\n    \"Subnet\": {\n        \"AvailabilityZone\": \"us-east-1a\",\n        \"AvailabilityZoneId\": \"use1-az6\",\n        \"AvailableIpAddressCount\": 251,\n        \"CidrBlock\": \"10.0.4.0/24\",\n        \"DefaultForAz\": false,\n        \"MapPublicIpOnLaunch\": false,\n        \"State\": \"pending\",\n        \"SubnetId\": \"subnet-08e16157c15cefcbc\",\n        \"VpcId\": \"vpc-0ca37d4650963adbb\",\n...\n```", "```\n//create IGW, it returns IGW id as igw-01769bff334dcc035\n$ aws ec2 create-internet-gateway\n{\n    \"InternetGateway\": {\n        \"Attachments\": [],\n        \"InternetGatewayId\": \"igw-01769bff334dcc035\",\n        \"Tags\": []\n    }\n} \n //attach igw-01769bff334dcc035 to vpc-0ca37d4650963adbb\n$ aws ec2 attach-internet-gateway --vpc-id vpc-0ca37d4650963adbb --internet-gateway-id igw-01769bff334dcc035\n```", "```\n//create route table within vpc-0ca37d4650963adbb\n//it returns route table id as rtb-0f45fc46edec61d8f\n$ aws ec2 create-route-table --vpc-id vpc-0ca37d4650963adbb\n{\n \"RouteTable\": {\n \"Associations\": [],\n \"PropagatingVgws\": [],\n \"RouteTableId\": \"rtb-0f45fc46edec61d8f\",\n...\n\n//then set default route (0.0.0.0/0) as igw-01769bff334dcc035\n$ aws ec2 create-route --route-table-id rtb-0f45fc46edec61d8f --gateway-id igw-01769bff334dcc035 --destination-cidr-block 0.0.0.0/0 \n//finally, update public 2 subnets to use this route table\n$ aws ec2 associate-route-table --route-table-id rtb-0f45fc46edec61d8f --subnet-id subnet-09f8f7f06c27cb0a0\n\n$ aws ec2 associate-route-table --route-table-id rtb-0f45fc46edec61d8f --subnet-id subnet-026058e32f09c28af \n //public subnet can assign public IP when launch EC2\n$ aws ec2 modify-subnet-attribute --subnet-id subnet-09f8f7f06c27cb0a0 --map-public-ip-on-launch\n\n$ aws ec2 modify-subnet-attribute --subnet-id subnet-026058e32f09c28af --map-public-ip-on-launch \n```", "```\n//allocate EIP, it returns allocation id as eipalloc-044f4dbafe870a04a\n$ aws ec2 allocate-address\n{\n    \"PublicIp\": \"54.161.228.168\",\n    \"AllocationId\": \"eipalloc-044f4dbafe870a04a\",\n    \"PublicIpv4Pool\": \"amazon\",\n    \"Domain\": \"vpc\"\n}\n //create NAT-GW on public subnet (subnet-09f8f7f06c27cb0a0)\n//also assign EIP eipalloc-044f4dbafe870a04a\n$ aws ec2 create-nat-gateway --subnet-id subnet-09f8f7f06c27cb0a0 --allocation-id eipalloc-044f4dbafe870a04a\n{\n    \"NatGateway\": {\n        \"CreateTime\": \"2018-12-09T20:17:33.000Z\",\n        \"NatGatewayAddresses\": [\n            {\n                \"AllocationId\": \"eipalloc-044f4dbafe870a04a\"\n            }\n        ],\n        \"NatGatewayId\": \"nat-05e34091f53f10172\",\n        \"State\": \"pending\",\n        \"SubnetId\": \"subnet-09f8f7f06c27cb0a0\",\n        \"VpcId\": \"vpc-0ca37d4650963adbb\"\n    }\n} \n```", "```\n//as same as public route, need to create a route table first\n$ aws ec2 create-route-table --vpc-id vpc-0ca37d4650963adbb\n{\n    \"RouteTable\": {\n        \"Associations\": [],\n        \"PropagatingVgws\": [],\n        \"RouteTableId\": \"rtb-08572c332e7e4f14e\",\n... \n //then assign default gateway as NAT-GW\n$ aws ec2 create-route --route-table-id rtb-08572c332e7e4f14e --nat-gateway-id nat-05e34091f53f10172 --destination-cidr-block 0.0.0.0/0\n\n   //finally update private subnet routing table\n$ aws ec2 associate-route-table --route-table-id rtb-08572c332e7e4f14e --subnet-id subnet-04b78ed9b5f96d76e\n\n$ aws ec2 associate-route-table --route-table-id rtb-08572c332e7e4f14e --subnet-id subnet-08e16157c15cefcbc \n```", "```\n//create one security group for public subnet\n$ aws ec2 create-security-group --vpc-id vpc-0ca37d4650963adbb --group-name public --description \"public facing host\"\n{\n    \"GroupId\": \"sg-03973d9109a19e592\"\n} \n //check your machine's public IP (if not sure, use 0.0.0.0/0 as temporary)\n$ curl ifconfig.co\n98.234.106.21 \n //public facing machine allows ssh only from your machine\n$ aws ec2 authorize-security-group-ingress --group-id sg-03973d9109a19e592 --protocol tcp --port 22 --cidr 98.234.106.21/32\n\n//public facing machine allow HTTP access from any host (0.0.0.0/0)\n$ aws ec2 authorize-security-group-ingress --group-id sg-03973d9109a19e592 --protocol tcp --port 80 --cidr 0.0.0.0/0 \n```", "```\n//create security group for private subnet\n$ aws ec2 create-security-group --vpc-id vpc-0ca37d4650963adbb --group-name private --description \"private subnet host\"\n{\n    \"GroupId\": \"sg-0f4058a729e2c207e\"\n} //private subnet allows ssh only from public subnet host security group\n$ aws ec2 authorize-security-group-ingress --group-id sg-0f4058a729e2c207e --protocol tcp --port 22 --source-group sg-03973d9109a19e592 \n\n//it also allows HTTP (80/TCP) from public subnet security group\n$ aws ec2 authorize-security-group-ingress --group-id sg-0f4058a729e2c207e --protocol tcp --port 80 --source-group sg-03973d9109a19e592 \n```", "```\n//create keypair (aws_rsa, aws_rsa.pub)\n$ ssh-keygen -f ~/.ssh/aws_rsa -N \"\" \n//register aws_rsa.pub key to AWS\n$ aws ec2 import-key-pair --key-name=my-key --public-key-material \"`cat ~/.ssh/aws_rsa.pub`\"\n{\n    \"KeyFingerprint\": \"73:89:80:1f:cc:25:94:7a:ba:f4:b0:81:ae:d8:bb:92\",\n    \"KeyName\": \"my-key\"\n}\n\n//launch public facing host, using Amazon Linux (ami-009d6802948d06e52) on us-east-1\n$ aws ec2 run-instances --image-id ami-009d6802948d06e52 --instance-type t2.nano --key-name my-key --security-group-ids sg-03973d9109a19e592 --subnet-id subnet-09f8f7f06c27cb0a0  //launch private subnet host\n$ aws ec2 run-instances --image-id ami-009d6802948d06e52 --instance-type t2.nano --key-name my-key --security-group-ids sg-0f4058a729e2c207e --subnet-id subnet-04b78ed9b5f96d76e \n```", "```\n//add private keys to ssh-agent\n$ ssh-add ~/.ssh/aws_rsa\n\n//ssh to the public subnet host with -A (forward ssh-agent) option\n$ ssh -A ec2-user@54.208.77.168\n...\n\n       __| __|_ )\n       _| ( / Amazon Linux 2 AMI\n      ___|\\___|___|\n\nhttps://aws.amazon.com/amazon-linux-2/\n1 package(s) needed for security, out of 5 available\nRun \"sudo yum update\" to apply all updates.\n[ec2-user@ip-10-0-1-41 ~]$ \n```", "```\n[ec2-user@ip-10-0-1-41 ~]$ ifconfig eth0\neth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 9001\n inet 10.0.1.41 netmask 255.255.255.0 broadcast 10.0.1.255\n inet6 fe80::cf1:1ff:fe9f:c7b2 prefixlen 64 scopeid 0x20<link>\n...\n```", "```\n$ amazon-linux-extras |grep nginx\n 4 nginx1.12 available [ =1.12.2 ]\n$ sudo amazon-linux-extras install nginx1.12\n$ sudo systemctl start nginx\n```", "```\n[ec2-user@ip-10-0-1-41 ~]$ exit\nlogout\nConnection to 54.208.77.168 closed.\n\n$ curl -I 54.208.77.168\nHTTP/1.1 200 OK\nServer: nginx/1.12.2\n...  \n```", "```\n[ec2-user@ip-10-0-1-41 ~]$ ssh 10.0.2.116\n...\n\n       __| __|_ )\n       _| ( / Amazon Linux 2 AMI\n      ___|\\___|___|\n\nhttps://aws.amazon.com/amazon-linux-2/\n1 package(s) needed for security, out of 5 available\nRun \"sudo yum update\" to apply all updates.\n[ec2-user@ip-10-0-2-116 ~]$ \n```", "```\n//create 40GB disk at us-east-1a (as same as EC2 public subnet instance)\n$ aws ec2 create-volume --availability-zone us-east-1a --size 40 --volume-type standard \n{\n    \"CreateTime\": \"2018-12-09T22:13:41.000Z\",\n    \"VolumeType\": \"standard\",\n    \"SnapshotId\": \"\",\n    \"VolumeId\": \"vol-006aada6fa87c0060\",\n    \"AvailabilityZone\": \"us-east-1a\",\n    \"Size\": 40,\n    \"State\": \"creating\",\n    \"Encrypted\": false\n} \n\n//attach to public subnet host as /dev/xvdh $ aws ec2 attach-volume --device xvdh --instance-id i-0f2750f65dd857e54 --volume-id vol-006aada6fa87c0060\n{\n    \"State\": \"attaching\",\n    \"InstanceId\": \"i-0f2750f65dd857e54\",\n    \"AttachTime\": \"2018-12-09T22:15:32.134Z\",\n    \"VolumeId\": \"vol-006aada6fa87c0060\",\n    \"Device\": \"xvdh\"\n} \n```", "```\n$ aws ec2 detach-volume --volume-id vol-006aada6fa87c0060\n{ \n \"InstanceId\": \"i-0f2750f65dd857e54\",\n \"VolumeId\": \"vol-006aada6fa87c0060\",\n \"State\": \"detaching\",\n \"Device\": \"xvdh\",\n \"AttachTime\": \"2018-12-09T22:15:32.000Z\"\n} \n```", "```\n// Create New Security Group for ELB\n$ aws ec2 create-security-group --vpc-id vpc-0ca37d4650963adbb --group-name elb --description \"elb sg\"\n{\n \"GroupId\": \"sg-024f1c5315bac6b9e\"\n}\n\n// ELB opens TCP port 80 for all IP addresses (0.0.0.0/0)\n$ aws ec2 authorize-security-group-ingress --group-id sg-024f1c5315bac6b9e --protocol tcp --port 80 --cidr 0.0.0.0/0 \n // create ELB on public subnets    \n$ aws elb create-load-balancer --load-balancer-name public-elb --listeners Protocol=HTTP,LoadBalancerPort=80,InstanceProtocol=HTTP,InstancePort=80 --subnets subnet-09f8f7f06c27cb0a0 subnet-026058e32f09c28af --security-group sg-024f1c5315bac6b9e\n{\n    \"DNSName\": \"public-elb-1952792388.us-east-1.elb.amazonaws.com\"\n}\n\n// Register an EC2 instance which runs nginx\n$ aws elb register-instances-with-load-balancer --load-balancer-name public-elb --instances i-0f2750f65dd857e54\n\n// You can access to ELB from your laptop\n$ curl -I public-elb-1952792388.us-east-1.elb.amazonaws.com\nHTTP/1.1 200 OK\nAccept-Ranges: bytes\nContent-Length: 3520\nContent-Type: text/html\nDate: Mon, 17 Dec 2018 06:05:45 GMT\nETag: \"5bbfda61-dc0\"\nLast-Modified: Thu, 11 Oct 2018 23:18:57 GMT\nServer: nginx/1.12.2\nConnection: keep-alive\n... \n```", "```\n$ aws iam create-role --role-name eksServiceRole --assume-role-policy-document '{ \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Principal\": { \"Service\": \"eks.amazonaws.com\" }, \"Action\": \"sts:AssumeRole\" } ] }'\n\n$ aws iam attach-role-policy --role-name eksServiceRole --policy-arn arn:aws:iam::aws:policy/AmazonEKSClusterPolicy\n\n$ aws iam attach-role-policy --role-name eksServiceRole --policy-arn arn:aws:iam::aws:policy/AmazonEKSServicePolicy\n```", "```\n$ aws ec2 create-security-group --vpc-id vpc-0ca37d4650963adbb --group-name eks-control-plane --description \"EKS Control Plane\"\n{\n \"GroupId\": \"sg-0fbac0a39bf64ba10\"\n}\n```", "```\n$ aws ec2 create-tags --resources subnet-04b78ed9b5f96d76e --tags Key=kubernetes.io/role/internal-elb,Value=1\n\n$ aws ec2 create-tags --resources subnet-08e16157c15cefcbc --tags Key=kubernetes.io/role/internal-elb,Value=1\n```", "```\n// Note: specify all 4 subnets\n$ aws eks create-cluster --name chap10 --role-arn arn:aws:iam::xxxxxxxxxxxx:role/eksServiceRole --resources-vpc-config subnetIds=subnet-09f8f7f06c27cb0a0,subnet-04b78ed9b5f96d76e,subnet-026058e32f09c28af,subnet-08e16157c15cefcbc,securityGroupIds=sg-0fbac0a39bf64ba10 --kubernetes-version 1.10\n```", "```\n$ aws-iam-authenticator token -i chap10\n```", "```\n$ aws eks update-kubeconfig --name chap10\n```", "```\n$ kubectl cluster-info\n$ kubectl get svc\n```", "```\n$ cat aws-auth-cm.yaml \napiVersion: v1\nkind: ConfigMap\nmetadata:\n name: aws-auth\n namespace: kube-system\ndata:\n mapRoles: |\n - rolearn: arn:aws:iam::xxxxxxxxxxxx:role/chap10-worker-NodeInstanceRole-8AFV8TB4IOXA\n username: system:node:{{EC2PrivateDNSName}}\n groups:\n - system:bootstrappers\n - system:nodes\n\n$ kubectl create -f aws-auth-cm.yaml \nconfigmap \"aws-auth\" created\n```", "```\n$ kubectl get nodes\nNAME                         STATUS    ROLES     AGE       VERSION\nip-10-0-2-218.ec2.internal   Ready     <none>    3m        v1.10.3\nip-10-0-4-74.ec2.internal    Ready     <none>    3m        v1.10.3 ...\n\n```", "```\n$ kubectl get sc\nNo resources found.\n```", "```\n//Storage Class for us-east-1a\n$ cat storage-class-us-east-1a.yaml \nkind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n name: gp2-us-east-1a\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n type: gp2\n  fsType: ext4 \n  zone: us-east-1a\n\n// Storage Class for us-east-1b\n$ cat storage-class-us-east-1b.yaml \nkind: StorageClass\napiVersion: storage.k8s.io/v1\nmetadata:\n name: gp2-us-east-1b\nprovisioner: kubernetes.io/aws-ebs\nparameters:\n type: gp2\n fsType: ext4 zone: us-east-1b # only change this\n\n$ kubectl create -f storage-class-us-east-1a.yaml \nstorageclass.storage.k8s.io \"gp2-us-east-1a\" created\n\n$ kubectl create -f storage-class-us-east-1b.yaml \nstorageclass.storage.k8s.io \"gp2-us-east-1b\" created\n\n// there are 2 StorageClass\n$ kubectl get sc\nNAME  PROVISIONER  AGE\ngp2-us-east-1a  kubernetes.io/aws-ebs  6s\ngp2-us-east-1b  kubernetes.io/aws-ebs  3s\n```", "```\n$ cat pvc-a.yaml \napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-a\nspec:\n  storageClassName: \"gp2-us-east-1a\"\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n storage: 10Gi\n\n$ cat pvc-b.yaml \napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-b\nspec:\n  storageClassName: \"gp2-us-east-1b\" # only change this\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n\n$ kubectl create -f pvc-a.yaml \npersistentvolumeclaim \"pvc-a\" created\n$ kubectl create -f pvc-b.yaml persistentvolumeclaim \"pvc-b\" created\n\n$ kubectl get pv\nNAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS    CLAIM           STORAGECLASS     REASON    AGE\npvc-20508a71-0187-11e9-bf51-02a2ca4dacd8   10Gi       RWO            Delete           Bound     default/pvc-a   gp2-us-east-1a             4m pvc-2235f412-0187-11e9-bf51-02a2ca4dacd8   10Gi       RWO            Delete           Bound               4m\n\n// use AWS CLI to search EBS instances by following command\n$ aws ec2 describe-volumes --query \"Volumes[*].{Id:VolumeId,AZ:AvailabilityZone,Tags:Tags[?Key=='kubernetes.io/created-for/pv/name'].Value}\" --filter \"Name=tag-key,Values=kubernetes.io/cluster/chap10\"\n[\n    {\n        \"Id\": \"vol-0fdec40626aac7cc4\",\n        \"AZ\": \"us-east-1a\",\n        \"Tags\": [\n            \"pvc-20508a71-0187-11e9-bf51-02a2ca4dacd8\"\n        ]\n    },\n    {\n        \"Id\": \"vol-0d9ef53eedde70115\",\n        \"AZ\": \"us-east-1b\",\n        \"Tags\": [\n            \"pvc-2235f412-0187-11e9-bf51-02a2ca4dacd8\"\n        ]\n    }\n]\n```", "```\n$ kubectl get nodes --show-labels\nNAME                         STATUS    ROLES     AGE       VERSION   LABELS\nip-10-0-2-218.ec2.internal   Ready     <none>    4h        v1.10.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.small,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-1,failure-domain.beta.kubernetes.io/zone=us-east-1b,kubernetes.io/hostname=ip-10-0-2-218.ec2.internal\nip-10-0-4-74.ec2.internal    Ready     <none>    4h        v1.10.3   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.small,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-1,failure-domain.beta.kubernetes.io/zone=us-east-1a,kubernetes.io/hostname=ip-10-0-4-74.ec2.internal\n```", "```\n// nodeSelector specifies us-east-1a, also pvc-a\n$ cat pod-us-east-1a.yaml \napiVersion: v1\nkind: Pod\nmetadata: \n  name: nginx\n  labels:\n    project: devops-with-kubernetes\n    app: nginx\nspec:\n  containers:\n  - name: nginx\n    image: nginx\n    volumeMounts:\n      - mountPath: /var/log/nginx\n        name: nginx-log\n  volumes:\n  - name: nginx-log\n    persistentVolumeClaim:\n      claimName: \"pvc-a\"\n  nodeSelector:\n    failure-domain.beta.kubernetes.io/zone: us-east-1a    \n\n$ kubectl create -f pod-us-east-1a.yaml pod \"nginx\" created\n\n// deploy to 10.0.4.0/24 subnet (us-east-1a)\n$ kubectl get pods -o wide\nNAME      READY     STATUS    RESTARTS   AGE       IP          NODE nginx     1/1       Running   0          18s       10.0.4.33   ip-10-0-4-74.ec2.internal\n\n// successfully to mount PVC-a \n$ kubectl exec -it nginx /bin/bash\nroot@nginx:/# df -h /var/log/nginx\nFilesystem      Size  Used Avail Use% Mounted on\n/dev/xvdca      9.8G   37M  9.2G   1% /var/log/nginx\n```", "```\n$ cat internal-elb.yaml apiVersion: v1\nkind: Service\nmetadata:\n name: nginx\n annotations:\n service.beta.kubernetes.io/aws-load-balancer-internal: 0.0.0.0/0\nspec:\n ports:\n - protocol: TCP\n port: 80\n type: LoadBalancer\n selector:\n project: devops-with-kubernetes\n app: nginx\n\n$ kubectl create -f internal-elb.yaml \nservice \"nginx\" created\n```", "```\n$ cat external-elb.yaml \napiVersion: v1\nkind: Service\nmetadata:\n name: nginx-external\nspec:\n ports:\n - protocol: TCP\n port: 80\n type: LoadBalancer\n selector:\n project: devops-with-kubernetes\n app: nginx\n\n$ kubectl create -f external-elb.yaml \nservice \"nginx-external\" created\n```", "```\nmetadata:\n  name: nginx-external\n  annotations:\n    service.beta.kubernetes.io/aws-load-balancer-type: \"nlb\"\n```", "```\n$ aws eks update-cluster-version --name chap10 --kubernetes-version 1.11\n{\n \"update\": {\n \"status\": \"InProgress\", \n \"errors\": [], \n \"params\": [\n {\n \"type\": \"Version\", \n \"value\": \"1.11\"\n }, \n {\n \"type\": \"PlatformVersion\", \n \"value\": \"eks.1\"\n }\n ], \n \"type\": \"VersionUpdate\", \n \"id\": \"09688495-4d12-4aa5-a2e8-dfafec1cee17\", \n \"createdAt\": 1545007011.285\n }\n}\n```", "```\n$ aws eks describe-update --name chap10 --update-id 09688495-4d12-4aa5-a2e8-dfafec1cee17\n{\n    \"update\": {\n        \"status\": \"InProgress\", \n        \"errors\": [], \n...\n...\n```", "```\n$ kubectl version --short\nClient Version: v1.10.7\nServer Version: v1.11.5-eks-6bad6d\n```", "```\n$ vi aws-auth-cm.yaml \napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: aws-auth\n  namespace: kube-system\ndata:\n  mapRoles: |\n    # \n    # new version of Worker Nodes\n    #\n    - rolearn: arn:aws:iam::xxxxxxxxxxxx:role/chap10-v11-NodeInstanceRole-10YYF3AILTJOS\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - system:bootstrappers\n        - system:nodes\n    #\n    # old version of Worker Nodes\n    #\n    - rolearn: arn:aws:iam::xxxxxxxxxxxx:role/chap10-worker-NodeInstanceRole-8AFV8TB4IOXA\n      username: system:node:{{EC2PrivateDNSName}}\n      groups:\n        - system:bootstrappers\n        - system:nodes\n\n//apply command to update ConfigMap\n$ kubectl apply -f aws-auth-cm.yaml \n\n// you can see both 1.10 and 1.11 nodes\n$ kubectl get nodes\nNAME                         STATUS    ROLES     AGE       VERSION\nip-10-0-2-122.ec2.internal   Ready     <none>    1m        v1.11.5\nip-10-0-2-218.ec2.internal   Ready     <none>    6h        v1.10.3\n...\n```", "```\n// prevent to assign pod to older Nodes\n$ kubectl taint nodes ip-10-0-2-218.ec2.internal key=value:NoSchedule\n$ kubectl taint nodes ip-10-0-4-74.ec2.internal key=value:NoSchedule\n\n// move Pod from older to newer Nodes\n$ kubectl drain ip-10-0-2-218.ec2.internal --ignore-daemonsets --delete-local-data\n$ kubectl drain ip-10-0-4-74.ec2.internal --ignore-daemonsets --delete-local-data\n\n// Old worker node became SchedulingDisabled\n$ kubectl get nodes\nNAME                         STATUS                     ROLES     AGE       VERSION\nip-10-0-2-122.ec2.internal   Ready                      <none>    7m        v1.11.5 ip-10-0-2-218.ec2.internal   Ready,SchedulingDisabled   <none>    7h        v1.10.3\nip-10-0-4-74.ec2.internal    Ready,SchedulingDisabled   <none>    7h        v1.10.3\n```", "```\n$ kubectl delete node ip-10-0-2-218.ec2.internal\nnode \"ip-10-0-2-218.ec2.internal\" deleted\n\n$ kubectl delete node ip-10-0-4-74.ec2.internal\nnode \"ip-10-0-4-74.ec2.internal\" deleted\n\n$ kubectl edit configmap aws-auth -n kube-system\nconfigmap \"aws-auth\" edited\n\n$ kubectl get nodes\nNAME                         STATUS    ROLES     AGE       VERSION\nip-10-0-2-122.ec2.internal   Ready     <none>    15m       v1.11.5\n```"]