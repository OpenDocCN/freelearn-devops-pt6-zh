- en: '15'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Working with AWS Fargate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout this book, we have used **Elastic Compute Cloud** (**EC2**) instances
    as worker nodes for our **Elastic Kubernetes Service** (**EKS**) cluster, but
    **AWS Fargate** can be used as an alternative to host Pods. As we will see later
    on, Fargate can be used to provide a more secure operating environment for a Pod
    and can also be more cost-effective (but not always).
  prefs: []
  type: TYPE_NORMAL
- en: 'In some cases, you want to deploy a workload/application that runs infrequently,
    has a small memory/CPU footprint, and/or needs enhanced security, for example,
    creating a regular dump of a production database. Fargate can be used to meet
    all of these requirements. In this chapter, we will dive into more detail on how
    and when you should use AWS Fargate, as well as how it works with EKS to provide
    an alternative to EC2-based worker nodes. Specifically, we will cover the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: What AWS Fargate is and how is it priced
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to create a Fargate profile in EKS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to deploy a Pod to a Fargate instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to troubleshoot common Fargate issues
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You should be familiar with YAML, AWS **Identity and Access Management** (**IAM**),
    and EKS architecture. Before getting started with this chapter, please ensure
    that the following is in place:'
  prefs: []
  type: TYPE_NORMAL
- en: Network connectivity to your EKS cluster API endpoint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AWS `kubectl` binary are installed on your workstation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have a basic understanding of AWS networking and EC2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is AWS Fargate?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'AWS Fargate was developed as an alternative to EC2 to provide a *serverless*,
    container-native compute solution with three key design tenets:'
  prefs: []
  type: TYPE_NORMAL
- en: To be as secure as possible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To be reliable and scale to meet demand
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To be cost-efficient
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If we compare the EC2-based EKS worker node and Fargate technical stacks, illustrated
    in *Figure 15**.1*, we can see that they are very similar. They run on physical
    servers, with both a virtual machine operating system and a container runtime
    that support a containerized application. The key difference is that Fargate is
    serverless, which means that you don’t need to care about the virtual machine
    operating system, container runtime, and so on, as this is all managed by AWS:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.1 – AWS Fargate versus EC2](img/Figure_15.1_B18838.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.1 – AWS Fargate versus EC2
  prefs: []
  type: TYPE_NORMAL
- en: The other main difference is that Fargate is really designed for small, bursty,
    or batch workloads, unlike EC2, which is traditionally used for more stable, long-running
    workloads. This means that the underlying physical compute fleet is optimized
    to maintain a high utilization/density, which in turn means it is operationally
    efficient and can therefore be much cheaper to use for the consumer.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following workloads suit the use of Fargate over a more traditional EC2
    deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: If your production workload is small with the occasional burst, such as sporadic
    web traffic during the day but low to no traffic at night
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you have a small test/non-production environment that is used occasionally,
    then Fargate can be more efficient than an underutilized EC2 instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your workload consists of a task that runs periodically, such as a batch
    or cron job
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Another consideration is the use of **Firecracker**, which is a **Virtual Machine
    Manager** (**VMM**) developed by AWS and open source. Firecracker uses the concept
    of a **MicroVM** to create a small, secure, isolated environment to run containers
    that are very quick to create or destroy and provide fine-grained control over
    how **central processing unit** (**CPU**), **random access memory** (**RAM**),
    disk, and networking shares are allocated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.2 – Fargate EKS architecture](img/Figure_15.2_B18838.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.2 – Fargate EKS architecture
  prefs: []
  type: TYPE_NORMAL
- en: Fargate uses EC2 Baremetal instances as its fleet and Firecracker to create
    and manage MicroVMs on these instances for multiple tenants (customers). Firecracker
    ensures that while a single Fargate EC2 host can support many MicroVMs from different
    AWS customers, they are all isolated through different **virtual machine** (**VM**)
    boundary controls.
  prefs: []
  type: TYPE_NORMAL
- en: A MicroVM will host a single Pod, and these Pods don’t share underlying kernels,
    CPU resources, memory resources, or **Elastic Network Interfaces** (**ENIs**)
    with another Pod. They are orchestrated through the Fargate EKS agent, which allows
    the K8s scheduler to schedule Pods on the Fargate fleet and connect it using the
    EKS AWS **virtual private cloud** (**VPC**) **Container Network Interface** (**CNI**)
    to private subnets (public subnets are not supported) in the customer’s VPC.
  prefs: []
  type: TYPE_NORMAL
- en: The K8s scheduler uses a **Fargate profile** to determine whether a Pod specification
    meets the requirements to be deployed onto the Fargate fleet. We will describe
    this process in more detail in the subsequent section.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand the general architecture, let’s look at how Fargate is
    priced.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Fargate pricing model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fargate has a simple pricing model based on the duration for which you use the
    MicroVM/Pod (per-second granularity) and the vCPU/RAM and disk allocated to it.
  prefs: []
  type: TYPE_NORMAL
- en: If we first look at a 2 CPU/4 GB EC2 instance with 30 GB of disk running 100%
    of the time, then based on on-demand pricing using the Frankfurt Region as an
    example, that would cost us approximately *$21/month*.
  prefs: []
  type: TYPE_NORMAL
- en: If we use a Fargate Pod with 2 CPU/4 GB with 30 GB of disk running for 5 hours
    every day, based on on-demand pricing in the Frankfurt Region, that would cost
    us approximately *$10/month*.
  prefs: []
  type: TYPE_NORMAL
- en: At first glance, we can see that Fargate is less than half the price of an EC2
    instance! However, if we just double the duration of the Pod execution time from
    5 hours/day to 10 hours/day, then the cost goes up to $35/month, which is quite
    a bit more. Also, bear in mind that with the EC2 instance, we could run multiple
    Pods on an instance without incurring any additional costs, whereas with Fargate,
    every Pod would be an additional $10 or $35 (assuming they are configured the
    same and run for the same amount of time).
  prefs: []
  type: TYPE_NORMAL
- en: What you can see from this example is that while the Fargate pricing model is
    easy to understand, from a pure cost perspective, using Fargate for long-running
    workloads is not very effective, but for bursty, short-lived workloads, it will
    be cost-efficient. However, if you factor in the total cost of managing and operating
    EC2 instances, as opposed to the fact that AWS will manage and patch your Fargate
    ones, you may be able to build a business case around Fargate.
  prefs: []
  type: TYPE_NORMAL
- en: You should also bear in mind that most EC2 instances are not 100% utilized;
    in many cases, they barely touch 30% utilization. So, if you have an existing
    large EC2 estate (of more than 100 instances), Fargate may save you a lot of money
    as you can reduce the impact of higher Fargate costs with a reduction in costs
    in your EC2 estate. Now that we’ve looked at the Fargate pricing model, let’s
    consider how we can configure EKS to use Fargate.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an AWS Fargate profile in EKS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding the AWS Fargate service is interesting, but we only covered it
    in this book to really give you some background. As Fargate is serverless, you
    really only need to understand how to get the Kubernetes scheduler to talk to
    the Fargate service and create the MicroVM, attach it to the network, and deploy
    the Pod. This is all done through the Fargate Profile, which will be discussed
    in detail in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how the AWS Fargate profile works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When considering how to integrate the Fargate service with EKS, the AWS team
    made a conscious decision not to make users update their existing K8s manifests
    to support Fargate. Instead, the **profile** identifies which namespaces and/or
    labels will be used to host Pods on Fargate, and no changes are required in the
    Pod definition. The following diagram illustrates how this process works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 15.3 – Fargate profile workflow](img/Figure_15.3_B18838.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 15.3 – Fargate profile workflow
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps shown in the previous diagram are detailed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: When a `Pod Create` API request is received by the API server (this could be
    an individual Pod spec, part of a deployment, or any other), it triggers an event
    that is captured by a custom webhook that is installed and managed by AWS in the
    EKS control plane.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This webhook looks at the Fargate profile to determine whether the namespace
    or labels being used are serviced by the Fargate service. If it matches, it will
    change the scheduler name to use the **Fargate Scheduler** instead of the standard
    K8s scheduler.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The API server now writes the *intent* with the appropriate scheduler name to
    `etcd` to wait to be scheduled.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If the scheduler name has been changed to the Fargate scheduler, then it will
    eventually be picked up by that scheduler, which takes care of requesting the
    compute resources from the AWS Fargate fleet and orchestrating the creation of
    the MicroVM and attaching it to the customer VPC. The Fargate Scheduler is another
    component that is created and managed by AWS in the EKS control plane.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: As you can see, the Fargate profile controls how everything works. So now, let’s
    create one and see how it works.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and adjusting the Fargate profile
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The easiest way to create a Fargate profile is to use `eksctl`. Let’s first
    create a new namespace to host the workload using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'We can then use `eksctl` to create (and verify) the Fargate profile and specify
    the new namespace as a target for Fargate (by default, you can have up to 10 profiles
    per cluster):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Now the profile is configured, let’s look at how we can use it.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a Pod to a Fargate instance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can see from the previous output `eksctl` has created not only the profile
    but also an execution role to allow Fargate Pods to use the AWS services and automatically
    assign the private subnets in the VPC.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we now take one of the manifests previously used in this book and simply
    change the namespace to the `fargate-workload` namespace and deploy it, we will
    see the Pod is deployed on a Fargate instance rather than on EC2 workers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'If we look at the Pod that was deployed using the following commands, we can
    see it’s running on Fargate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also verify in the Pod specification whether the scheduler has been
    set correctly and that the MicroVM is now registered as a node with our cluster
    using the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'While the Pod has been created, it is only accessible from inside the VPC (it
    will use the same security group as the EC2 base worker node) so we can add an
    NLB or ALB, as described in [*Chapter 14*](B18129_14.xhtml#_idTextAnchor205).
    A quick way to test connectivity to your Pod running on Fargate is to `curl` command,
    an example of which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Fargate has a number of preconfigured vCPU and memory sizes; if you don’t specify
    a vCPU and memory combination, then the smallest available combination is used
    (0.25 vCPU and 0.5 GB memory). This can be validated using the `kubectl describe
    po` command, an example of which is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'If we adjust the Pod spec in our initial deployment and set some limits, it
    will then change the size of the Fargate instance. An example of a K8s manifest
    is shown in the following code snippet, which uses memory and CPU limits:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'If we rerun the `describe` command after we update the deployment, we can see
    the provisioned capacity has increased:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: You can see that the limits and the Fargate annotation/size don’t exactly align!
    This is because there is 2 GiB set for memory in the manifest but 4 GB is assigned.
    This is because Fargate tries to match the manifest configuration to the set CPU/memory
    configurations that have been defined, and it will add some overhead (246 MB RAM)
    to support the required Kubernetes components (`kubelet`, `kube-proxy`, and `containerd`).
    Each Pod will also receive 20 GB of ephemeral storage that can be used to cache
    data, but this will be deleted when the Pod is deleted.
  prefs: []
  type: TYPE_NORMAL
- en: 'It’s worth noting that if you run your Pod for an extended period of time,
    there is a possibility that AWS will patch your Pod, and this could lead to it
    being evicted and deleted. In order to mitigate this, you should use **Pod Disruption
    Budgets** (**PDBs**) to maintain a certain number of Pods and prevent eviction,
    as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your K8s version, you may need to use the `apiVersion policy/v1beta1`
    beta policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can validate that the PDB is in place using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: While a PDB cannot guarantee your application resilience, it can go a certain
    way toward making sure operational issues don’t impact it. As AWS operates Fargate
    for you, most things happen seamlessly, but sometimes issues do occur. In the
    next section, let’s look at some common issues and how we can troubleshoot them.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting common issues on Fargate
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most common issue related to capacity is that occasionally, there will not
    be enough platform resources, and/or the CPU/RAM combination you want will not
    be supported. This results in the Pod status always being **PENDING**. If it is
    a platform issue, simply waiting and trying later (after 15/20 minutes) may resolve
    the issue; otherwise, adjust your Pod spec to support a different CPU/RAM combination.
  prefs: []
  type: TYPE_NORMAL
- en: 'If your Fargate nodes are shown as `Not Ready` when you run the `$ kubectl
    get nodes` command, ensure that the execution role they are using is also configured
    in the `aws-auth` ConfigMap, an example of which is shown as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: You may have issues with CoreDNS Pods staying in a PENDING state; this is normally
    due to the VPC DNS not being configured. The solution is to ensure you have `enableDNSHostnames`
    and `enableDNSSupport` set to `True` for your VPC.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you have issues with the Fargate profile, make sure the target namespaces
    and labels are correctly configured in your cluster and Pod spec. There are some
    common processing rules that need to be considered:'
  prefs: []
  type: TYPE_NORMAL
- en: The Fargate Scheduler matches all conditions, so if namespaces and labels are
    used in the profile, then they must both be used in the manifest in order to be
    scheduled on a Fargate instance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If multiple Fargate profiles exist and a Pod matches multiple profiles, it is
    scheduled using a random Fargate profile
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we have looked at what Fargate is, how it works and is configured,
    and how you can do some basic troubleshooting. We’ll now revisit the key learning
    points from this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored what Fargate is and how it works. You learned that
    Fargate is an AWS-managed service, so you really only need to focus on the Fargate
    profile and make sure that VPC networking and, optionally, load balancers are
    set up correctly for it all to work.
  prefs: []
  type: TYPE_NORMAL
- en: We also explored the technology and discovered that under the hood, Fargate
    uses a Firecracker MicroVM to provide complete isolation between your Pod and
    other Pods even if these are in the same cluster.
  prefs: []
  type: TYPE_NORMAL
- en: We reviewed how the Fargate profile is used to match Pod spec labels and namespaces
    in the profile and assign them to the Fargate scheduler, which handles the orchestration
    with the AWS Fargate service to provision your Pod on a Fargate MicroVM and connect
    it to your VPC.
  prefs: []
  type: TYPE_NORMAL
- en: We then looked at how you can use a Pod or deployment manifest unchanged by
    just matching the namespace and/or labels defined in the Fargate profile namespace.
    We also learned that adjusting the `Limits` or `Requests` resources in the manifest
    will change the size of the MicroVM (providing it matches one of the pre-defined
    CPU/RAM combinations).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we reviewed some common issues with Fargate and how to fix them. You
    should now be able to describe when to use Fargate for an EKS workload and be
    able to configure a Fargate profile to allow developers to deploy Pods on a Fargate
    instance.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at how you can use a service mesh to provide
    greater security or better telemetry/logging.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Understanding the Firecracker design: [https://github.com/firecracker-microvm/firecracker/blob/main/docs/design.md](https://github.com/firecracker-microvm/firecracker/blob/main/docs/design.md)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Understanding how Fargate is priced: [https://aws.amazon.com/fargate/pricing/](https://aws.amazon.com/fargate/pricing/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Understanding Fargate Pod configurations: [https://docs.aws.amazon.com/eks/latest/userguide/fargate-pod-configuration.html](https://docs.aws.amazon.com/eks/latest/userguide/fargate-pod-configuration.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
