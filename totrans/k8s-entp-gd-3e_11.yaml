- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Extending Security Using Open Policy Agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have covered Kubernetes’ built-in authentication and authorization
    capabilities, which help to secure a cluster. While this will cover most use cases,
    it doesn’t cover all of them. Some security best practices that Kubernetes can’t
    handle are pre-authorizing container registries and ensuring that Ingress objects
    don’t overlap (though most Ingress controllers do check, such as NGINX).
  prefs: []
  type: TYPE_NORMAL
- en: These tasks are left to outside systems and are called dynamic admission controllers.
    **Open Policy Agent** (**OPA**) and its Kubernetes native sub-project, **Gatekeeper**,
    is one of the most popular ways to handle these use cases. This chapter will detail
    the deployment of OPA and Gatekeeper, how OPA is architected, and how to develop
    policies.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to dynamic admission controllers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is OPA and how does it work?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Rego to write policies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enforcing Ingress policies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mutating objects and default values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating policies without Rego
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once you’ve completed this chapter, you’ll be on your way to developing and
    implementing important policies for your cluster and workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To complete the hands-on exercises in this chapter, you will require an Ubuntu
    22.04 server.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can access the code for this chapter at the following GitHub repository:
    [https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/tree/main/chapter11](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/tree/main/chapter11).'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to dynamic admission controllers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An admission controller is a specialized webhook in Kubernetes that runs when
    an object is created, updated, or deleted. When one of these three events happens,
    the API server sends information about the object and operation to the webhook.
    Admission controllers can be used to either determine if an operation should happen
    or give the cluster operator a chance to change the object definition before it’s
    processed by the API server. We’re going to look at using this mechanism to both
    enforce security and extend the functionality of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways to extend Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: Build a custom resource definition so that you can define your own objects and
    APIs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implement a webhook that listens for requests from the API server and responds
    with the necessary information. You may recall that in *Chapter 6*, *Integrating
    Authentication into Your Cluster*, we explained that a custom webhook could be
    used to validate tokens.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Starting in Kubernetes 1.9, a webhook can be defined as a dynamic admission
    controller, and in 1.16, the dynamic admission controller API became **Generally
    Available** (**GA**).
  prefs: []
  type: TYPE_NORMAL
- en: There are two types of dynamic admission controllers, validating and mutating.
    Validating admission controllers verify that a new object, update, or deletion
    can move forward. Mutation allows a webhook to change the payload of an object’s
    creation, deletion, or update. This section will focus on the details of admission
    controllers. We’ll talk more about mutation controllers in the next chapter, *Chapter
    12*, *Node Security with GateKeeper*.
  prefs: []
  type: TYPE_NORMAL
- en: The protocol is very straightforward. Once a dynamic admission controller is
    registered for a specific object type, the webhook is called with an HTTP POST
    every time an object of that type is created or edited. The webhook is then expected
    to return JSON, which represents whether it is allowed or not.
  prefs: []
  type: TYPE_NORMAL
- en: As of 1.16, `admission.k8s.io/v1` is at GA. All examples will use the GA version
    of the API.
  prefs: []
  type: TYPE_NORMAL
- en: 'The request submitted to the webhook is made up of several sections. We’re
    not including an example here because of how large an `Admission` object can get,
    but we’ll use [https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/blob/main/chapter11/example_admission_request.json](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/blob/main/chapter11/example_admission_request.json)
    as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Object identifiers**: The `resource` and `subResource` attributes identify
    the object, API, and group. If the version of the object is being upgraded, then
    `requestKind`, `requestResource`, and `requestSubResource` are specified. Additionally,
    `namespace` and `operation` are provided to provide the location of the object
    and whether it is a `CREATE`, `UPDATE`, `DELETE`, or `CONNECT` operation. In our
    example, a `Deployment` resource with a `subResource` of `Scale` is being created
    to scale our `Deployment` up in the `my-namespace` namespace.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Submitter identifiers**: The `userInfo` object identifies the user and groups
    of the submitter. The submitter and the user who created the original request
    are not always the same. For instance, if a user creates a `Deployment`, then
    the `userInfo` object won’t be for the user who created the original `Deployment`;
    it will be for the `ReplicaSet` controller’s service account because the `Deployment`
    creates a `ReplicaSet` that creates the pod. In our example, a user with the `uid`
    of admin submitted the scaling request.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Object**: `object` represents the JSON of the object being submitted, whereas
    `oldObject` represents what is being replaced if this is an update. Finally, `options`
    specifies additional options for the request. In our example, the new pod with
    the new number of replicas after the scaling operation is submitted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The response from the webhook will simply have two attributes, the original
    `uid` from the request and `allowed`, which can be `true` or `false`. For instance,
    to allow our scaling operation to complete:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: The `userInfo` object can create complications quickly. Since Kubernetes often
    uses multiple layers of controllers to create objects, it can be difficult to
    track usage creation based on a user who interacts with the API server.
  prefs: []
  type: TYPE_NORMAL
- en: It’s much better to authorize based on objects in Kubernetes, such as namespace
    labels or other objects.
  prefs: []
  type: TYPE_NORMAL
- en: A common use case is to allow developers to have a **sandbox** that they are
    administrators in, but that has very limited capacity. Instead of trying to validate
    the fact that a particular user doesn’t try to request too much memory, annotate
    a personal namespace with a limit so that the admission controller has something
    concrete to reference regardless of whether the user submits a pod or a Deployment.
    This way, the policy will check the annotation on the `namespace` instead of the
    individual user. To ensure that only the user who owns the namespace is able to
    create something in it, use RBAC to limit access.
  prefs: []
  type: TYPE_NORMAL
- en: 'One final point on generic validating webhooks: there is no way to specify
    a key or password. It’s an anonymous request. While, in theory, a validating webhook
    could be used to implement updates to your cluster, it is not recommended. For
    instance, you could use a validating webhook to create a `ClusterRoleBinding`
    when creating a `Namespace`, but that would mean that your policy check is not
    repeatable. It’s best to separate policy checking and workflow.'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve covered how Kubernetes implements dynamic access controllers,
    we’ll look at one of the most popular options in OPA.
  prefs: []
  type: TYPE_NORMAL
- en: What is OPA and how does it work?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: OPA is a lightweight authorization engine that fits well in Kubernetes. It didn’t
    get its start in Kubernetes, but it’s certainly found a home there. There’s no
    requirement to build dynamic admission controllers in OPA, but it’s very good
    at it and there are extensive resources and existing policies that can be used
    to start your policy library.
  prefs: []
  type: TYPE_NORMAL
- en: This section provides a high-level overview of OPA and its components with the
    rest of the chapter getting into the details of an OPA implementation in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: OPA architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'OPA comprises three components – the HTTP listener, the policy engine, and
    the database:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – OPA architecture ](img/B21165_11_01-01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: OPA architecture'
  prefs: []
  type: TYPE_NORMAL
- en: 'The database used by OPA is in memory and ephemeral. It doesn’t persist information
    used to make policy decisions. On the one hand, this makes OPA very scalable since
    it is essentially an authorization microservice. On the other hand, this means
    that every instance of OPA must be maintained on its own and must be kept in sync
    with authoritative data:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – OPA in Kubernetes ](img/B21165_11_02-01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.2: OPA in Kubernetes'
  prefs: []
  type: TYPE_NORMAL
- en: When used in Kubernetes, OPA populates its database using a sidecar, called
    `kube-mgmt`, which sets up watches on the objects you want to import into OPA.
    As objects are created, deleted, or changed, `kube-mgmt` updates the data in its
    OPA instance. This means that OPA is “eventually consistent” with the API server,
    but it won’t necessarily be a real-time representation of the objects in the API
    server. Since the entire etcd database is essentially being replicated over and
    over again, great care needs to be taken in order to refrain from replicating
    sensitive data, such as `Secrets`, in the OPA database.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s get introduced to the OPA policy language, Rego.
  prefs: []
  type: TYPE_NORMAL
- en: Rego, the OPA policy language
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll cover the details of Rego in the next section in detail. The main point
    to mention here is that **Rego** is a **policy evaluation language**, not a generic
    programming language. Rego can be difficult for developers who are used to languages
    such as Golang, Java, or JavaScript, which support complex logic such as iterators
    and loops. Rego is designed to evaluate policy and is streamlined as such. For
    instance, if you wanted to write code in Java to check that all the container
    images in a pod started with one of a list of registries, it would look something
    like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This code iterates over every container and every allowed registry to make
    sure that all of the images conform to the correct policy. The same code in Rego
    is much smaller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: The preceding rule will evaluate to `true` if any of the images on the containers
    come from unauthorized registries. We’ll cover the details of how this code works
    later in the chapter. The key to understanding why this code is so much more compact
    is that much of the boilerplate of loops and tests is inferred in Rego. The first
    line generates a list of conforming images, and the second line makes sure that
    the number of conforming images matches the number of total images. If they don’t
    match, then one or more of the images must come from invalid registries. The ability
    to write compact policy code is what makes Rego so well suited to admission controllers.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we’ve focused on generic OPA and Rego. In the early days, you would
    integrate Kubernetes directly into OPA using `ConfigMaps` to store policies; however,
    this proved to be really unwieldy. Microsoft developed a tool called GateKeeper,
    which is Kubernetes native and makes it easier to get the most out of OPA in Kubernetes.
    So, now, let’s get introduced to Gatekeeper.
  prefs: []
  type: TYPE_NORMAL
- en: Gatekeeper
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Thus far, everything discussed has been generic to OPA. It was mentioned at
    the beginning of the chapter that OPA didn’t get its start in Kubernetes. Early
    implementations had a sidecar that kept the OPA database in sync with the API
    server, but you had to manually create policies as `ConfigMap` objects and manually
    generate responses for webhooks. In 2018, Microsoft debuted Gatekeeper ([https://github.com/open-policy-agent/gatekeeper](https://github.com/open-policy-agent/gatekeeper))
    to provide a Kubernetes-native experience.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to moving from `ConfigMap` objects to proper custom resources, Gatekeeper
    adds an audit function that lets you test policies against existing objects. If
    an object violates a policy, then a violation entry is created to track it. This
    way, you can get a snapshot of the existing policy violations in your cluster
    or know whether something was missed during Gatekeeper downtime due to an upgrade.
  prefs: []
  type: TYPE_NORMAL
- en: A major difference between Gatekeeper and generic OPA is that in Gatekeeper,
    OPA’s functionality is not exposed via an API anyone can call. OPA is embedded,
    with Gatekeeper calling OPA directly to execute policies and keep the database
    up to date. Decisions can only be made based on data in Kubernetes or by pulling
    data at evaluation time.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying Gatekeeper
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The examples that will be used will assume the use of Gatekeeper instead of
    a generic OPA deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, create a new cluster to deploy GateKeeper into:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the new cluster is running, based on the directions from the Gatekeeper
    project, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This launches the Gatekeeper namespace pods and creates the validating webhook.
    Once deployed, move on to the next section. We’ll cover the details of using Gatekeeper
    throughout the rest of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Automated testing framework
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OPA has a built-in automated testing framework for your policies. This is one
    of the most valuable aspects of OPA. Being able to test policies consistently
    before deployment can save you hours of debugging time. When writing policies,
    have a file with the same name as your policies file, but with `_test` in the
    name. For instance, to have test cases associated with `mypolicies.rego`, have
    the test cases in `mypolicies_test.rego` in the same directory. Running the `opa`
    `test` will then run your test cases. We’ll show how to use this to debug your
    code in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Having covered the basics of OPA and how it is constructed, the next step is
    to learn how to use Rego to write policies.
  prefs: []
  type: TYPE_NORMAL
- en: Using Rego to write policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rego is a language specifically designed for policy writing. It is different
    from most languages you have likely written code in. Typical authorization code
    will look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Authorization code will generally default to unauthorized, with a specific condition
    having to happen in order to allow the final action to be authorized. Rego takes
    a different approach. Rego is generally written to authorize everything unless
    a specific set of conditions happens.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another major difference between Rego and more general programming languages
    is that there are no explicit `if`/`then`/`else` control statements. When a line
    of Rego is going to make a decision, the code is interpreted as “If this line
    is false, stop execution.” For instance, the following code in Rego says “If the
    image starts with `myregistry.lan/`, then stop the execution of the policy and
    pass this check; otherwise, generate an error message”:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The same code in Java might look as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: This difference between inferred control statements and explicit control statements
    is often the steepest part of the learning curve when learning Rego. While this
    can produce a steeper learning curve than other languages, Rego more than makes
    up for it by making it easy to test and build policies in an automated and manageable
    way. Another benefit of Rego is that it can be used for application-level authorizations.
    We’ll cover this more when we get to Istio later in the book.
  prefs: []
  type: TYPE_NORMAL
- en: OPA can be used to automate the testing of policies. This is incredibly important
    when writing code that the security of your cluster relies upon. Automating your
    testing will help speed up your development and will increase your security by
    catching any bugs introduced into previously working code by means of new working
    code. Next, let’s work through the life cycle of writing an OPA policy, testing
    it, and deploying it to our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Developing an OPA policy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A common example of using OPA is to limit which registries a pod can come from.
    This is a common security measure in clusters to help restrict which pods can
    run on a cluster. For instance, we’ve mentioned Bitcoin miners a few times. If
    the cluster won’t accept pods except from your own internal registry, then that’s
    one more step that needs to be taken for a bad actor to abuse your cluster. First,
    let’s write our policy, taken from the OPA documentation website ([https://www.openpolicyagent.org/docs/latest/kubernetes-introduction/](https://www.openpolicyagent.org/docs/latest/kubernetes-introduction/)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: The first line in this code declares the `package` our policy is in. Everything
    is stored in OPA in a package, both data and policies.
  prefs: []
  type: TYPE_NORMAL
- en: Packages in OPA are like directories on a filesystem. When you place a policy
    in a package, everything is relative to that package. In this case, our policy
    is in the `k8sallowedregistries` package.
  prefs: []
  type: TYPE_NORMAL
- en: The next section defines a rule. This rule ultimately will be `undefined` if
    our pod has an image that comes from `quay.io`. If the pod doesn’t have an image
    from `quay.io`, the rule will return `true`, signifying that the registry is invalid.
    Gatekeeper will interpret this as a failure and return `false` to the API server
    when the pod is evaluated during a dynamic admission review.
  prefs: []
  type: TYPE_NORMAL
- en: The next two rules look very similar. The first of the `input_images` rules
    says “Evaluate the calling rule against every `container` in the object’s `spec.container`,”
    matching pod objects directly submitted to the API server and extracting all the
    `image` values for each `container`. The second `input_images` rule states “Evaluate
    the calling rule against every `container` in the object’s `spec.template.spec.containers`"
    to short circuit `Deployment` objects and `StatefulSets`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, we add the rule that Gatekeeper requires to notify the API server
    of a failed evaluation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: This rule will return an empty `msg` if the registry is valid. It’s a good idea
    to break up your code into code that makes policy decisions and code that responds
    with feedback. This makes it easier to test, which we’ll do next.
  prefs: []
  type: TYPE_NORMAL
- en: Testing an OPA policy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Once we have written our policy, we want to set up an automated test. Just
    as with testing any other code, it’s important that your test cases cover both
    expected and unexpected input. It’s also important to test both positive and negative
    outcomes. It’s not enough to corroborate that our policy allowed a correct registry;
    we also need to make sure it stops an invalid one. Here are eight test cases for
    our code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'There are eight tests in total: two tests to make sure that the proper error
    message is returned when there’s an issue, and six tests covering two use cases
    for three input types. We’re testing simple pod definitions, `Deployment`, and
    `CronJob`. To validate success or failure as expected, we have included definitions
    that have `image` attributes that include `docker.io` and `quay.io` for each input
    type. The code is abbreviated for print but can be downloaded from [https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/tree/main/chapter11/simple-opa-policy/rego/](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/tree/main/chapter11/simple-opa-policy/rego/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To run the tests, first, install the OPA command-line executable as per the
    OPA website: [https://www.openpolicyagent.org/docs/latest/#running-opa](https://www.openpolicyagent.org/docs/latest/#running-opa).
    Once it has been downloaded, go to the `simple-opa-policy/rego` directory and
    run the tests:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Seven of the tests passed, but `test_cronjob_registry_not_allowed` failed. The
    `CronJob` submitted as `input` should not be allowed because its `image` uses
    `docker.io`. The reason it snuck through was that `CronJob` objects follow a different
    pattern to `Pods` and `Deployments`, so our two `input_image` rules won’t load
    any of the container objects from the `CronJob`. The good news is that when the
    `CronJob` ultimately submits the pod, Gatekeeper will not validate it, thereby
    preventing it from running. The bad news is that no one will know this until the
    pod is supposed to be run. Making sure we pick up `CronJob` objects in addition
    to our other objects with containers in them will make it much easier to debug
    because the `CronJob` won’t be accepted.
  prefs: []
  type: TYPE_NORMAL
- en: 'To get all tests passing, add a new `input_container` rule to the `limitregistries.rego`
    file in the GitHub repo that will match the container used by a `CronJob`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, running the tests will show that everything passes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: With a policy that has been tested, the next step is to integrate the policy
    into Gatekeeper.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying policies to Gatekeeper
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The policies we’ve created need to be deployed to Gatekeeper, which provides
    Kubernetes custom resources that policies need to be loaded into. The first custom
    resource is `ConstraintTemplate`, which is where the Rego code for our policy
    is stored. This object lets us specify parameters in relation to our policy enforcement,
    and we’ll cover this next. To keep things simple, create a template with no parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: The entire source code for this template is available at [https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/blob/main/chapter11/simple-opa-policy/yaml/gatekeeper-policy-template.yaml](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/blob/main/chapter11/simple-opa-policy/yaml/gatekeeper-policy-template.yaml).
  prefs: []
  type: TYPE_NORMAL
- en: 'Once created, the next step is to apply the policy by creating a constraint
    based on the template. Constraints are objects in Kubernetes based on the configuration
    of `ConstraintTemplate`. Notice that our template defines a custom resource definition.
    This gets added to the `constraints.gatekeeper.sh` API group. If you look at the
    list of CRDs on your cluster, you’ll see `k8sallowedregistries` listed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – CRD created by ConstraintTemplate ](img/B21165_11_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: CRD created by ConstraintTemplate'
  prefs: []
  type: TYPE_NORMAL
- en: Creating the constraint means creating an instance of the object defined in
    the template.
  prefs: []
  type: TYPE_NORMAL
- en: 'To keep from causing too much havoc in our cluster, we’re going to restrict
    this policy to the `testpolicy` namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The constraint limits the policy we wrote to just `Deployment`, `CronJob`,
    and `Pod` objects in the `testpolicy` namespace. Once our policy is created, if
    we try to create a pod in the `testpolicy` namespace that comes from `docker.io`,
    it will fail because the image comes from `docker.io`, not `quay.io`, not `quay.io`.
    First, let’s create our `testpolicy` namespace and an example `Deployment` that
    will violate this policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The last line tried to create a new `Deployment` that references `docker.io`
    instead of `quay.io`, which failed because our policy blocked it. But we also
    created a `Deployment` that violates this rule before deploying our policy, which
    means that our admission controller never received a create command. This is one
    feature of Gatekeeper over generic OPA that is very powerful: Gatekeeper audits
    your existing infrastructure against new policies. This way, you can find offending
    deployments quickly.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, look at the policy object. You will see that there are several violations
    in the `status` section of the object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Having deployed your first Gatekeeper policy, you may quickly notice it has
    a few issues. The first is that the registry is hardcoded. This means that we’d
    need to replicate our code for every change of registry. It’s also not flexible
    for the namespace. As an example, Tremolo Security’s images are across multiple
    `github.io` registries, so instead of limiting a specific registry server, we
    may want flexibility for each namespace and to allow multiple registries. Next,
    we’ll update our policies to provide this flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: Building dynamic policies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Our current registry policy is limiting. It is static and only supports a single
    registry. Both Rego and Gatekeeper provide functionality to build a dynamic policy
    that can be reused in our cluster and configured based on individual namespace
    requirements. This gives us one code base to work from and debug instead of having
    to maintain repetitive code. The code we’re going to use is at [https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/tree/main/chapter11/parameter-opa-policy](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/tree/main/chapter11/parameter-opa-policy).
  prefs: []
  type: TYPE_NORMAL
- en: 'When inspecting `rego/limitregistries.rego`, the main difference between the
    code in `parameter-opa-policy` and `simple-opa-policy` comes down to the `invalidRegistry`
    rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: The goal of the first line of the rule is to determine which images come from
    approved registries using a comprehension. Comprehensions provide a way to build
    out sets, arrays, and objects based on some logic. In this case, we want to only
    add images to the `ok_images` array that start with any of the allowed registries
    from `input.parameters.registries`.
  prefs: []
  type: TYPE_NORMAL
- en: To read a comprehension, start with the type of brace. Ours starts with a square
    bracket, so the result will be an array. Objects and sets can also be generated.
    The word between the open bracket and the pipe character (`|`) is called the head
    and this is the variable that will be added to our array if the right conditions
    are met. Everything to the right of the pipe character (`|`) is a set of rules
    used to determine what `image` should be and if it should have a value at all.
    If any of the statements in the rule resolve to `undefined` or `false`, the execution
    exits for that iteration.
  prefs: []
  type: TYPE_NORMAL
- en: The first rule of our comprehension is where most of the work is done. The `startswith`
    function is used to determine whether each of our images starts with the correct
    registry name. Instead of passing two strings to the function, we instead pass
    arrays. The first array has a variable we haven’t declared yet, `i`, and the other
    uses an underscore (`_`) where the index would usually be. The `i` is interpreted
    by Rego as “*Do this for each value in the array, incrementing by 1, and let it
    be referenced throughout the comprehension*.” The underscore is shorthand in Rego
    for “*Do this for all values*.” Since we specified two arrays, every combination
    of the two arrays will be used as input to the `startswith` function.
  prefs: []
  type: TYPE_NORMAL
- en: 'That means that if there are two containers and three potential pre-approved
    registries, then `startswith` will be called six times. When any of the combinations
    return `true` from `startswith`, the next rule is executed. That sets the `image`
    variable to `input_image` with index `i`, which then means that the image is added
    to `ok_images`. The same code in Java would look something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: One line of Rego eliminated seven lines of mostly boilerplate code.
  prefs: []
  type: TYPE_NORMAL
- en: The second line of the rule compares the number of entries in the `ok_images`
    array with the number of known container images. If they are equal, we know that
    every container contains a valid image.
  prefs: []
  type: TYPE_NORMAL
- en: 'With our updated Rego rules for supporting multiple registries, the next step
    is to deploy a new policy template (if you haven’t done so already, delete the
    old `k8sallowedregistries` `ConstraintTemplate` and `restrict-openunison-registries`
    `K8sAllowedRegistries`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Here’s our updated `ConstraintTemplate`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Beyond including our new rules, the highlighted section shows that we added
    a schema to our template. This will allow for the template to be reused with specific
    parameters. This schema goes into the `CustomResourceDefinition` that will be
    created and is used to validate input for the `K8sAllowedRegistries` objects we’ll
    create in order to enforce our pre-authorized registry lists. Create this new
    policy definition:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let’s create our policy for the `testpolicy` namespace. Since the
    only containers that are running in this namespace should come from NGINX’s `docker.io`
    registry, we’ll limit all pods to `docker.io/nginx/` using the following policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Unlike our previous version, this policy specifies which registries are valid
    instead of embedding the policy data directly into our Rego. With our policies
    in place, let’s try to run the `BusyBox` container in the `testpolicy` namespace
    to get a shell:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: In the above example, we were able to stop the BusyBox container from being
    deployed, but the NGINX `Deployment` was created because we were able to restrict
    the specific container registry on `docker.io`.
  prefs: []
  type: TYPE_NORMAL
- en: Using this generic policy template, we can restrict which registries the namespaces
    are able to pull from. As an example, in a multi-tenant environment, you may want
    to restrict all pods to the owner’s own registry. If a namespace is being used
    for a commercial product, you can stipulate that only that vendor’s containers
    can run in it. Before moving on to other use cases, it’s important to understand
    how to debug your code and handle Rego’s quirks.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging Rego
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Debugging Rego can be challenging. Unlike more generic programming languages
    such as Java or Go, there’s no way to step through code in a debugger. Take the
    example of the generic policy we just wrote for checking registries. All the work
    was done in a single line of code. Stepping through it wouldn’t do much good.
  prefs: []
  type: TYPE_NORMAL
- en: To make Rego easier to debug, the OPA project provides a trace of all failed
    tests when verbose output is set on the command line. This is another great reason
    to use OPA’s built-in testing tools.
  prefs: []
  type: TYPE_NORMAL
- en: 'To make better use of this trace, Rego has a function called `trace` that accepts
    a string. Combining this function with `sprintf` lets you more easily track where
    your code is not working as expected. In the `chapter11/parameter-opa-policy-fail/rego`
    directory, there’s a test that will fail. There is also an `invalidRegistry` rule
    with multiple trace options added:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: When the test is run, OPA will output a detailed trace of every comparison and
    code path. Wherever it encounters the `trace` function, a “note” is added to the
    trace. This is the equivalent of adding `print` statements in your code to debug.
    The output of the OPA trace is very verbose, and far too much text to include
    in print. Running `opa test . -v` in this directory will give you the full trace
    you can use to debug your code.
  prefs: []
  type: TYPE_NORMAL
- en: Using existing policies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before moving into more advanced use cases for OPA and Gatekeeper, it’s important
    to understand the implications of how OPA is built and used. If you inspect the
    code we worked through in the previous section, you might notice that we aren’t
    checking for an `initContainer`. We’re only looking for the primary containers.
    An `initContainer` is a special container that is run before the containers listed
    in a pod are expected to end. They’re often used to prepare the filesystem of
    a volume mount and for other “initial” tasks that should be performed before the
    containers of a pod have run. If a bad actor tried to launch a pod with an `initContainer`
    that pulls in a Bitcoin miner (or worse), our policy wouldn’t stop it.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to be very detailed in the design and implementation of policies.
    One of the ways to make sure you’re not missing something when building policies
    is to use policies that already exist and have been tested. The Gatekeeper project
    maintains several libraries of pre-tested policies and how to use them in its
    GitHub repo at [https://github.com/open-policy-agent/gatekeeper-library](https://github.com/open-policy-agent/gatekeeper-library).
    Before attempting to build one of your own policies, see whether one already exists
    there first.
  prefs: []
  type: TYPE_NORMAL
- en: This section provided an overview of Rego and how it works in policy evaluation.
    It didn’t cover everything, but should give you a good point of reference for
    working with Rego’s documentation. Next, we’ll learn how to build policies that
    rely on data from outside our request, such as other objects in our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Enforcing Ingress policies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far in this chapter, we’ve built policies that are self-contained. When checking
    whether an image is coming from a pre-authorized registry, the only data we needed
    was from the policy and the containers. This is often not enough information to
    make a policy decision. In this section, we’ll work on building a policy that
    relies on other objects in your cluster to make policy decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before diving into the implementation, let’s talk about the use case. It’s
    common to limit which namespaces can have `Ingress` objects. If a namespace hosts
    a workload that doesn’t require any inbound access, why allow an `Ingress` object
    at all? You may think you can enforce this using RBAC by limiting what tenants
    are allowed to deploy using a `Role` and `RoleBinding`, but this has some limitations:'
  prefs: []
  type: TYPE_NORMAL
- en: The `admin` and edit `ClusterRoles` are default aggregate `ClusterRoles`, so
    you would need to create a new `ClusterRole` that enumerates all objects except
    `Ingress` that you want your namespace admin to be able to create.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If your new `ClusterRole` included `RoleBindings`, your namespace owner could
    just grant themselves `Ingress` creation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using an admission controller with an annotation or a label is a good approach
    to enforcing if the namespace can have an `Ingress` in it. The `Namespace` object
    is cluster-scoped, so an `admin` won’t be able to elevate their privileges in
    the namespace and add the label.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our next example, we’ll write a policy that only allows `Ingress` objects
    in namespaces that have the correct label. The pseudo-code would look something
    like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: The hard part here is understanding if the namespace has a label. Kubernetes
    has an API, which you could query, but that would mean either embedding a secret
    into the policy so it can talk to the API server or allowing anonymous access.
    Neither of those options is a good idea. Another issue with querying the API server
    is that it’s difficult to automate testing since you are now reliant on an API
    server being available wherever you run your tests.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed earlier that OPA can replicate data from the API server in its
    own database. Gatekeeper uses this functionality to create a **cache** of objects
    that can be tested against. Once this cache is populated, we can replicate it
    locally to provide test data for our policy testing.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling the Gatekeeper cache
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Gatekeeper cache is enabled by creating a `Config` object in the `gatekeeper-system`
    namespace. Add this configuration to your cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This will begin replicating `Namespace` objects in Gatekeeper’s internal OPA
    database. Let’s create a `Namespace` with a label allowing `Ingress` objects and
    without a label allowing `Ingress` objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: After a moment, the data should be in the OPA database and ready to query.
  prefs: []
  type: TYPE_NORMAL
- en: The Gatekeeper service account has read access to everything in your cluster
    with its default installation. This includes secret objects. Be careful what you
    replicate in Gatekeeper’s cache as there are no security controls from inside
    a Rego policy. Your policy could very easily log secret object data if you are
    not careful. Also, make sure to control who has access to the `gatekeeper-system`
    namespace. Anyone who gets hold of the service account’s token can use it to read
    any data in your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have Gatekeeper set up and ready to start enforcing policies, how
    do we test policies? We could test them directly against a cluster, but that will
    slow down our development cycle. Next, we’ll see how to mock test data so that
    we can automate our testing outside of a Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Mocking up test data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to automate the testing of our policy, we need to create test data.
    In the previous examples, we used data injected into the `input` variable. Cache
    data is stored in the `data` variable. Specifically, in order to access our namespace
    labels, we need to access `data.inventory.cluster["v1"].Namespace["ns-with-ingress"].metadata.labels`.
    This is the standard way for you to query cluster data from Rego in Gatekeeper.
    If you want to query objects inside of a namespace, it would instead look like
    `data.inventory.namespace["myns"]["v1"]["ConfigMaps"]["myconfigmap"]`. Just as
    we did with the input, we can inject a mocked-up version of this data by creating
    a data object. Here’s what our JSON will look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: When you look at `chapter11/enforce-ingress/rego/enforceingress_test.rego`,
    you’ll see the tests have `with input as {…} with data as {…}` with the preceding
    document as our control data. This lets us test our policies with data that would
    exist in GateKeeper without having to deploy our code in a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Building and deploying our policy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Just as before, we’ve written test cases prior to writing our policy. Next,
    we’ll examine our policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: This code should look familiar. It follows a similar pattern as our earlier
    policies. The first rule, `violation`, is the standard reporting rule for Gatekeeper.
    The second and third rules have the same name but different logic. This is because
    Rego evaluates all of the statements in a rule as an AND, so for the rule to be
    true, all of the statements need to be true. If we only had the first `missingIngressLabel`
    rule, which checks if the `allowingress` label is true, then `Ingress` objects
    without this label at all would break the rule and so bypass our requirement.
    We could have a rule that requires that the label be set, but that would lead
    to a bad user experience. It would be better to set up our policy so that it will
    fail if the label isn’t true OR the label isn’t set at all.
  prefs: []
  type: TYPE_NORMAL
- en: To set up the logic of “if the label’s value is not true or the label is not
    present,” we need to have two rules with the same name. One rule checks for the
    label’s value, and the other validates if the label is there at all. Rego will
    execute both `missingIngressLabel` rules and, as long as one passes, execution
    will continue. In our case, if the namespace the `Ingress` object is created in
    doesn’t have the correct value of `allowingress`, or doesn’t have the label `allowingress`
    at all, the violation rule will complete, returning an error to the user.
  prefs: []
  type: TYPE_NORMAL
- en: This is a key difference between Rego and other languages. Rego isn’t executed
    in sequence the way Java, Go, or JavaScript is. It’s a policy language that’s
    evaluated, so the execution path is different. When writing Rego, it’s important
    to remember you’re not working with a typical programming language.
  prefs: []
  type: TYPE_NORMAL
- en: To deploy, add `chapter11/enforce-ingress/yaml/gatekeeper-policy-template.yaml`
    and `chapter11/enforce-ingress/yaml/gatekeeper-policy.yaml` to your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'To test, we’ll try creating an `Ingress` object in the `ns-without-ingress`
    namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that our policy blocked the `Ingress` object’s creation. Next,
    we’ll try to create the same `Ingress` object but in the `ns-with-ingress` namespace,
    which has the correct label:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: This time, our policy allowed the `Ingress` object to be created!
  prefs: []
  type: TYPE_NORMAL
- en: Most of this chapter has been spent writing policies. Next, we’ll cover how
    to provide sane defaults to your objects using mutating webhooks.
  prefs: []
  type: TYPE_NORMAL
- en: Mutating objects and default values
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Until this point, everything we have discussed has been about how to use Gatekeeper
    to enforce a policy. Kubernetes has another feature called mutating admission
    webhooks that allows a webhook to change, or mutate, an object before the API
    server processes it and runs validating admission controllers.
  prefs: []
  type: TYPE_NORMAL
- en: A common usage of a mutating webhook is to explicitly set security context information
    on pods that don’t have it set. For instance, if you create a pod with no `spec.securityContext.runAsUser`,
    then the pod will run as the user the Docker container was built to run using
    the `USER` directive (or root by default) when it was built. This is insecure
    since it means you could be running as root, especially if the container in question
    is from Docker Hub. While you can have a policy that blocks running as root, you
    could also have a mutating webhook that will set a default user ID if it’s not
    specified to make it a default. This makes for a better developer experience because,
    now, as a developer, I don’t have to worry about which user my container was built
    to run as so long as it was designed to work with any user.
  prefs: []
  type: TYPE_NORMAL
- en: This brings up a common question of defaults versus explicit configuration.
    There are two schools of thought. The first is that you should provide sane defaults
    wherever possible to minimize what developers have to know to get a typical workload
    running. This creates consistency and makes it easier to spot outliers. The other
    school of thought requires explicit configuration of security contexts so that
    it’s known looking at a glance what the workload expects. This can make auditing
    easier, especially if paired with GitOps to manage your manifests, but creates
    quite a bit of repetitive YAML.
  prefs: []
  type: TYPE_NORMAL
- en: I’m personally a fan of sane defaults. The vast majority of workloads will not
    require any privilege and should be treated as such. It doesn’t mean you don’t
    still need enforcement, just that it’s a better experience for your developers.
    It also makes it easier to make global changes. Want to change the default user
    ID or security context? You make the change in your mutating webhook instead of
    across tens, hundreds, or even thousands of manifests. Most of Kubernetes is built
    this way. You don’t create pod objects directly; you create `Deployments` and
    `StatefulSets` with controllers that create pods. Going back to our discussions
    on RBAC, aggregate roles work this way too. Instead of creating a massive `ClusterRole`
    for namespace administrators, Kubernetes uses a controller to generate the `ClusterRole`
    dynamically based on label selectors, making it easier to maintain. In my experience,
    this example should be applied to security defaults as well.
  prefs: []
  type: TYPE_NORMAL
- en: Gatekeeper’s mutation isn’t built on Rego the way its validation policies are.
    While you can write mutating webhooks in Rego, and I can say this from experience,
    it’s not well suited to it. What makes Rego a great policy definition language
    also makes it very hard to build mutations.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know what mutations are useful and that we can use Gatekeeper, let’s
    build a mutation that will configure all containers to run as a default user if
    none is specified.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s deploy something that we can test our mutations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can deploy the policy in `chapter11/defaultUser/addDefaultUser.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Let’s walk through this mutation. The first part of the `spec`, `applyTo`, tells
    Gatekeeper what objects you want this mutation to act on. For us, we want it to
    work on all pods.
  prefs: []
  type: TYPE_NORMAL
- en: The next section, `match`, gives you the chance to specify conditions on which
    pods we want the mutation to apply to. In our case, we’re applying to all of them
    except in the `kube-system` namespace. In general, I tend to avoid making changes
    to anything in the `kube-system` namespace because it’s the domain of whoever
    is managing your clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Making changes there can have permanent impacts on your cluster. In addition
    to specifying which namespaces you don’t want to apply your mutation to, you can
    also specify additional conditions:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kind` – What kind of object to match on'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labelSelectors` – Labels on the object that must match'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`namespaces` – List of namespaces to apply the mutation policy to'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`namespaceSelector` – Labels on the container namespaces'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We’ll talk more about label matching in *Chapter 12*, *Node Security with GateKeeper*.
  prefs: []
  type: TYPE_NORMAL
- en: After defining how to match objects to mutate, we specify what mutation to perform.
    For us, we want to set `spec.securityContext.runAsUser` to a randomly chosen user
    ID if one isn’t specified. The last part, `pathTests`, is what lets us set this
    value if the `spec.securityContext.runAsUser` isn’t already set.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you’ve applied your mutation policy, verify that the test pod isn’t running
    as a specific user:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, delete the pod and check again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Our pod is now running as user `70391`! Now, let’s edit our `deployment` so
    that the user is set the user identity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Our mutation didn’t apply because we already had a user specified in our `Deployment`
    object.
  prefs: []
  type: TYPE_NORMAL
- en: 'One last note on setting values: you’ll often find that you want to set a value
    for an object in a list. For instance, you may want to create a policy that will
    set any container as unprivileged unless specifically set to be privileged. In
    `chapter11/defaultUser/yaml/setUnprivileged.yaml`, our `location` (and `subPath`)
    have changed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'This reads as “Match all objects in the list `spec.containers` that have an
    attribute called `image`.” Since every container must have an image, this will
    match all containers. Apply this object and test it out again on the test pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Now our pod is marked as unprivileged!
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we looked at how you can set defaults using Gatekeeper’s built-in
    mutation support. We discussed the benefits of mutating webhooks that set defaults,
    enabled Gatekeeper’s support for mutations, and built policies that set a default
    user identity and disable privileged containers. Using what you’ve learned in
    this section, you can use Gatekeeper not only to enforce your policies but also
    to set sane defaults to make compliance easier for your developers. Using GateKeeper
    for policy management is great, but it does require additional skills and the
    management of an additional system. Next, we’ll learn how to create policies with
    alternatives to Rego or using Kubernetes’ new built-in policy engine.
  prefs: []
  type: TYPE_NORMAL
- en: Creating policies without Rego
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Rego is a very powerful way to build complex policies that are then implemented
    by the GateKeeper project. That power comes with a steep learning curve and complexity.
    It may not be the right choice for you or your clusters. It isn’t the only way
    to implement an admission controller. We’re not going to go into too many details,
    as these other projects all have their own capabilities that are worth exploring
    and I won’t be able to do them justice in one section.
  prefs: []
  type: TYPE_NORMAL
- en: 'The two most common alternatives to GateKeeper are:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Kyverno**: Kverno is a specialized policy engine for Kubernetes. It’s not
    designed as a generic authorization engine the way OPA is so it can make assumptions
    that provide a simpler experience for building Kubernetes policies ([https://kyverno.io/](https://kyverno.io/)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**jsPolicy**: The jsPolicy project allows you to build your policies in JavaScript
    or TypeScript instead of a **domain-specific language** (**DSL**) like Rego. The
    idea is that many of the quirks that come from Rego being a policy language, not
    a programming language, are eliminated by using a common language like JavaScript
    ([https://github.com/loft-sh/jspolicy](https://github.com/loft-sh/jspolicy)).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These projects both have their own strengths and I encourage you to evaluate
    them for your use cases. If your policies are straightforward and don’t require
    the power of one of these engines, you can also look at Kubernetes’ new built-in
    capabilities, which is what we’ll cover next.
  prefs: []
  type: TYPE_NORMAL
- en: Using Kubernetes’ validating admission policies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In 1.28 Kubernetes, validating admission policies went into beta, which allows
    you to create simpler policies without an external admission controller. For simpler
    policies, this eliminates a component that needs to be deployed. We’re not going
    to dive too deeply into building admission policies, but we wanted to give you
    an overview so that you have it as an option.
  prefs: []
  type: TYPE_NORMAL
- en: From a policy development perspective, the biggest difference between using
    Gatekeeper and validating admission policies is that while Gatekeeper uses Rego,
    validating admission policies use the **Common Expression Language** (**CEL**).
    CEL is not a Turing Complete language, which means that it isn’t as expressive
    and capable as JavaScript but is easier to secure. CEL is being integrated into
    multiple layers of Kubernetes. It’s being used to provide more expressive validation
    for custom resource definitions and is also being integrated into the new authentication
    configuration options that are being developed. You can learn more about CEL at
    [https://github.com/google/cel-spec](https://github.com/google/cel-spec).
  prefs: []
  type: TYPE_NORMAL
- en: 'From a capability perspective, you can use CEL to validate any of the data
    inside of the object to be created. There are two components to build a validating
    admission policy:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ValidatingAdmissionPolicy`: This is the object that describes the policy and
    the expressions to run as part of that policy. This is similar to `ConstraintTemplate`
    from Gatekeeper.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ValidatingAdmissionPolicyBinding`: This is how Kubernetes knows when to apply
    our `ValidatingAdmissionPolicy`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To implement our example from above where we want to limit Ingress objects
    to namespaces with a specific label, first, we’d create the `ValidatingAdmissionPolicy`
    (`chapter11/enforce-ingress-vap/vap-ingress.yaml`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'The above policy will fail if the namespace that the `Ingress` is added to
    doesn’t have the label `allowingress` with a value of `true`. Next, we need to
    tell Kubernetes to bind our policy. We want this to apply to all namespaces, but
    similar to a policy implementation for Gatekeeper, we can specify specific namespaces
    or namespace labels. We do this using a `ValidatingAdmissionPolicy` (`chapter11/enforce-ingress-vap/vap-binding-ingress.yaml`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'This binding will bind our policy to all namespaces, and on failure, deny the
    request. We could also warn the user or just audit the event. In our case, we
    want the request to fail. With these two objects created, we can try to create
    `Ingress` objects again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: Just as with our Gatekeeper examples, we see that we’re able to deny the creation
    of an `Ingress` rule if our namespace doesn’t have the appropriate label.
  prefs: []
  type: TYPE_NORMAL
- en: The addition of validating access policies to Kubernetes adds a powerful tool,
    but it does have its limits. It’s tempting to say we’ll use validating access
    policies for simple use cases, and Gatekeeper for more complex ones, but there
    are other things to keep in mind beyond the implementation complexity. For one,
    how are you monitoring failures? If you use both solutions, then even though you
    may have some simpler rule implementations, you’ll need to audit both solutions,
    which will create more work.
  prefs: []
  type: TYPE_NORMAL
- en: While we introduced validating access policies so you’re aware of their capability,
    we’re going to continue to focus on OPA and Gatekeeper in future chapters. In
    the next chapter, we’re going to apply what we’ve learned about OPA and Gatekeeper
    to help secure Kubernetes nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored how to use Gatekeeper as a dynamic admission controller
    to provide additional authorization policies on top of Kubernetes’ built-in RBAC
    capabilities. We looked at how Gatekeeper and OPA are architected. Then, we learned
    how to build, deploy, and test policies in Rego. Finally, you were shown how to
    use Gatekeeper’s built-in mutation support to create default configuration options
    in pods.
  prefs: []
  type: TYPE_NORMAL
- en: Extending Kubernetes’ policies leads to a stronger security profile in your
    clusters and provides greater confidence in the integrity of the workloads you
    are running.
  prefs: []
  type: TYPE_NORMAL
- en: Using Gatekeeper can also help catch previously missed policy violations through
    its application of continuous audits. Using these capabilities will provide a
    stronger foundation for your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter focused on whether or not to launch a pod based on our specific
    policies. In the next chapter, we’ll learn how to protect your nodes from the
    processes running in those pods.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Are OPA and Gatekeeper the same thing?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Yes'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'No'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: How is Rego code stored in Gatekeeper?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It is stored as `ConfigMap` objects that are watched.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Rego has to be mounted to the pod.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Rego needs to be stored as secret objects.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Rego is saved as a `ConstraintTemplate`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: How do you test Rego policies?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In production
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Using an automated framework built directly into OPA
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: By first compiling to WebAssembly
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In Rego, how do you write a `for` loop?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You don’t need to; Rego will identify iterative steps.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: By using the `for all` syntax.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: By initializing counters in a loop.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: There are no loops in Rego.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is the best way to debug Rego policies?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use an IDE to attach to the Gatekeeper container in a cluster.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: In production.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Add trace functions to your code and run the `opa test` command with `-v` to
    see execution traces.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Include `System.out` statements.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Constraints all need to be hardcoded.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Gatekeeper can replace pod security policies.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: b – No, Gatekeeper is a Kubernetes-native policy engine built on OPA.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: d – Rego is saved as a `ConstraintTemplate`
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: b – Please don’t test in production!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a – Everything is built on policy, not iterative control loops.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: c – Add trace functions to your code and run the `opa test` command with `-v`
    to see execution traces
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: b – False. You can have variable constraints.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a – True, and we’ll cover that in the next chapter!
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Join our book’s Discord space
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join the book’s Discord workspace for a monthly *Ask Me Anything* session with
    the authors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/K8EntGuide](https://packt.link/K8EntGuide)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code965214276169525265.png)'
  prefs: []
  type: TYPE_IMG
