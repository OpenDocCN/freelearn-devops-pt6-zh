<html><head></head><body>
		<div id="_idContainer024">
			<h1 id="_idParaDest-49" class="chapter-number"><a id="_idTextAnchor048"/>4</h1>
			<h1 id="_idParaDest-50"><a id="_idTextAnchor049"/>Exploring Container Runtimes, Interfaces, and Service Meshes</h1>
			<p>In this chapter, we’ll go further into exploring container runtimes, networking, interfaces, and learning about service meshes. We will see which runtime implementations exist and the difference between them, learn how containers can communicate with each other over the network, which container interfaces exist in Kubernetes, and get to know what a service mesh is and its applications. We will also do a few more exercises using the Docker tooling we have previously installed to support <span class="No-Break">our journey.</span></p>
			<p>The contents of this chapter will cover topics from the <em class="italic">Container Orchestration</em> domain of the KCNA certification, which is the second biggest part of the exam, so make sure to answer all questions at the end of <span class="No-Break">the chapter.</span></p>
			<p>Here are the topics we’re going <span class="No-Break">to cover:</span></p>
			<ul>
				<li><span class="No-Break">Container runtimes</span></li>
				<li><span class="No-Break">Container networking</span></li>
				<li><span class="No-Break">Container storage</span></li>
				<li><span class="No-Break">Container security</span></li>
				<li>Introducing <span class="No-Break">service meshes</span></li>
			</ul>
			<p>Let’s <span class="No-Break">get started!</span></p>
			<h1 id="_idParaDest-51"><a id="_idTextAnchor050"/>Container runtimes</h1>
			<p>As you know from the previous<a id="_idIndexMarker170"/> chapters, containers can run on virtual machines, in the cloud, on-premise, on bare-metal servers, or simply on your laptop. The software responsible for basic operations such as downloading images from the registry and creating, starting, stopping, or deleting containers is called the <strong class="bold">container runtime</strong>. We’ve already learned about Docker tooling and runtime, but there are more runtimes that exist, including <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Containerd</strong></span></li>
				<li><span class="No-Break"><strong class="bold">CRI-O</strong></span></li>
				<li><span class="No-Break"><strong class="bold">kata</strong></span></li>
				<li><span class="No-Break"><strong class="bold">gVisor</strong></span></li>
			</ul>
			<p>Before going into<a id="_idIndexMarker171"/> runtime specifics, we need to understand what a <strong class="bold">Container Runtime Interface</strong> (<span class="No-Break"><strong class="bold">CRI</strong></span><span class="No-Break">) is.</span></p>
			<p class="callout-heading">CRI</p>
			<p class="callout">The CRI is a plugin interface that allows Kubernetes to use different container runtimes. In the first releases of Kubernetes before the CRI was introduced, it was only possible to use Docker as <span class="No-Break">a runtime.</span></p>
			<p>As you might remember, Kubernetes<a id="_idIndexMarker172"/> does not have its own runtime to do basic container operations, so it needs a runtime to manage containers and this runtime has to be CRI compatible. For example, Docker Engine does not support the CRI, but most of the other runtimes, including <em class="italic">containerd</em> or <em class="italic">CRI-O</em>, do. Essentially, the CRI defines the protocol<a id="_idIndexMarker173"/> for communication between Kubernetes and the runtime of choice using <strong class="bold">gRPC</strong> (the high-performance <strong class="bold">Remote Procedure Call</strong> framework), as shown in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="image/B18970_04_01.jpg" alt="Figure 4.1 – Container runtime integration with CRI"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.1 – Container runtime integration with CRI</p>
			<p>Initially, there was no CRI implementation in Kubernetes, but as new container runtimes were developed, it became increasingly hard to incorporate all of them into Kubernetes, so the solution was to define a standard interface that would allow compatibility with any runtime. The introduction of the CRI in Kubernetes version 1.5 allowed the use of multiple container runtimes within a single K8s cluster and also made it easier to develop compatible runtimes. Today, <em class="italic">containerd</em> is the most used runtime with newer versions <span class="No-Break">of Kubernetes.</span></p>
			<p>But why would you need to run<a id="_idIndexMarker174"/> a mix of different runtimes in the same cluster? This is a rather advanced scenario and the main reason behind it is that some runtimes can provide better security for more sensitive container workloads. Therefore, when we talk about containers and their runtimes, we need to distinguish three <span class="No-Break">main types:</span></p>
			<ul>
				<li><strong class="bold">Namespaced</strong> – The fastest and most used type that is based <a id="_idIndexMarker175"/>on Linux kernel <em class="italic">cgroups</em> and <em class="italic">namespaces</em> functionality<a id="_idIndexMarker176"/> we covered in the previous chapter. This type shares the same kernel to run multiple containers and thus is considered the least secure out of all container types. Examples include <em class="italic">Docker</em>, <em class="italic">containerd</em>, <span class="No-Break">and </span><span class="No-Break"><em class="italic">CRI-O</em></span><span class="No-Break">.</span></li>
				<li><strong class="bold">Virtualized</strong> – The slowest type of container, which in fact<a id="_idIndexMarker177"/> requires a hypervisor as virtual<a id="_idIndexMarker178"/> machines do. Each container is started inside its own lightweight VM with its own dedicated kernel. This type is considered the most secure as it provides maximum isolation for container workloads. Virtualized containers are still faster to start than VMs and their advantage over traditional VMs is their easy integration with container orchestration systems such as Kubernetes. The <em class="italic">Kata</em> project is an example of <span class="No-Break">virtualized containers.</span></li>
				<li><strong class="bold">Sandboxed</strong> – This is a container type<a id="_idIndexMarker179"/> in-between the other two, providing<a id="_idIndexMarker180"/> better security than namespaced containers and being faster than virtualized containers. Better security is achieved with another layer of isolation that intercepts the system calls coming from the container workload. <em class="italic">gVisor</em> is an open source project<a id="_idIndexMarker181"/> from Google that allows the creation of <span class="No-Break">sandboxed containers.</span></li>
			</ul>
			<p>While this might sound very complicated, for the scope of the KCNA exam, you don’t really need to know all the details about container runtimes. This knowledge will be needed if you ever go for a CKS exam or have a special use case for using <em class="italic">sandboxed</em> or <em class="italic">virtualized</em> containers. For now, make<a id="_idIndexMarker182"/> sure to remember which container runtimes exist and the fact<a id="_idIndexMarker183"/> that in most scenarios, <em class="italic">namespaced</em> containers are used. Also, don’t confuse <em class="italic">CRI</em> with <em class="italic">OCI</em>, which we covered in <a href="B18970_02.xhtml#_idTextAnchor026"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Overview of CNCF and </em><span class="No-Break"><em class="italic">Kubernetes Certifications</em></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">The <strong class="bold">Open Container Initiative</strong> (<strong class="bold">OCI</strong>) provides the industry specifications<a id="_idIndexMarker184"/> for containers (image, runtime, and distribution specs) while CRI is a part of Kubernetes that makes it possible to use different runtimes with K8s in a <span class="No-Break">pluggable way.</span></p>
			<p>In practice, you do not interact <a id="_idIndexMarker185"/>with container runtimes directly but instead use orchestration systems such as Kubernetes or Docker Swarm. We can also use a CLI to talk to container runtimes as we did with the Docker CLI or as you can with the <strong class="source-inline">ctr</strong> or <strong class="source-inline">nerdctl</strong> CLI when using the <span class="No-Break"><em class="italic">containerd</em></span><span class="No-Break"> runtime.</span></p>
			<p>Moving on, in the following section, we are going to learn more about <span class="No-Break">container networking.</span></p>
			<h1 id="_idParaDest-52"><a id="_idTextAnchor051"/>Container networking</h1>
			<p>We have only tried creating individual containers<a id="_idIndexMarker186"/> so far, however, in the real world, we would need to deal with tens and often hundreds of containers. As the microservice architectures gained wider adoption, the applications were split into multiple smaller parts that communicate with each other over the network. One application could be represented by the frontend part, several backend services, and the database layer, where end-user requests hitting the frontend will trigger communication with the backend, and the backend will talk with the database. When each component is running in its own container across multiple servers, it is important to understand how they can all talk with each other. Networking is a large part of containers and Kubernetes, and it can be really challenging to understand how things work. For the moment, we are only going to touch the surface of container-to-container communication and continue with more details such as exposing containers and K8s specifics in the <span class="No-Break">later chapters.</span></p>
			<p>Let’s get back to the Docker tooling<a id="_idIndexMarker187"/> we installed in the previous chapter and try starting another <span class="No-Break">Ubuntu container.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Make sure that Docker Desktop is running before attempting to spawn containers. If you have not enabled auto-start previously, you might need to start it manually. On Linux with Docker Engine, you might need to execute <strong class="source-inline">$ sudo systemctl </strong><span class="No-Break"><strong class="source-inline">start docker</strong></span><span class="No-Break">.</span></p>
			<p>Open the terminal and run <span class="No-Break">the following:</span></p>
			<pre class="source-code">
$ docker run -it ubuntu:22.04 bash</pre>
			<p>Because the image is stripped down to the minimum to save space, there are no preinstalled basic packages such as <strong class="source-inline">net-tools</strong>. Let’s install those inside our container by calling <strong class="source-inline">apt update</strong> and <span class="No-Break"><strong class="source-inline">apt install</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
root@5919bb5d37e3:/# apt update; apt -y install net-tools
… SOME OUTPUT OMITTED …
Reading state information... Done
The following NEW packages will be installed:
  net-tools
… SOME OUTPUT OMITTED …
Unpacking net-tools (1.60+git20181103.0eebece-1ubuntu5) ...
Setting up net-tools (1.60+git20181103.0eebece-1ubuntu5) ...
root@5919bb5d37e3:/#</pre>
			<p>Now that we have <strong class="source-inline">net-tools</strong> installed, we can use the <strong class="source-inline">ifconfig</strong> tool inside the container. The output you’ll see should be similar <span class="No-Break">to this:</span></p>
			<pre class="source-code">
root@5919bb5d37e3:/# ifconfig
eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt;  mtu 1500
        inet 172.17.0.2  netmask 255.255.0.0  broadcast 172.17.255.255
        ether 02:42:ac:11:00:02  txqueuelen 0  (Ethernet)
        RX packets 14602  bytes 21879526 (21.8 MB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 3127  bytes 174099 (174.0 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt;  mtu 65536
        inet 127.0.0.1  netmask 255.0.0.0
        loop  txqueuelen 1000  (Local Loopback)
        RX packets 5  bytes 448 (448.0 B)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 5  bytes 448 (448.0 B)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</pre>
			<p>We can also see the container’s routing<a id="_idIndexMarker188"/> table by calling the <strong class="source-inline">route</strong> tool inside the container. The output will be similar to <span class="No-Break">the following:</span></p>
			<pre class="source-code">
root@9fd192b5897d:/# route
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref     Use Iface
default         172.17.0.1      0.0.0.0         UG    0      0         0 eth0
172.17.0.0      0.0.0.0         255.255.0.0     U     0      0         0 eth0</pre>
			<p>As we can see, our container has an <strong class="source-inline">eth0</strong> interface with the <strong class="source-inline">172.17.0.2</strong> IP address. In your case, the address might be different, but the important part is that our containers, by default, will have their own isolated networking stack with their own (virtual) interfaces, routing table, default gateway, and <span class="No-Break">so on.</span></p>
			<p>If we now open another terminal window<a id="_idIndexMarker189"/> and execute <strong class="source-inline">docker network ls</strong>, we will see which network types are supported using which drivers. The output will be similar to <span class="No-Break">the following:</span></p>
			<pre class="source-code">
$ docker network ls
NETWORK ID     NAME      DRIVER    SCOPE
c82a29c5280e   bridge    bridge    local
83de399192b0   host      host      local
d4c7b1acbc0d   none      null      local</pre>
			<p>There are three basic <span class="No-Break">network types:</span></p>
			<ul>
				<li><strong class="source-inline">bridge</strong> – This is the default type and driver<a id="_idIndexMarker190"/> for Docker containers we create. It allows containers connected to the same bridge network on the host to communicate with each other and provides isolation from other containers (that can also be attached to their own bridge<a id="_idIndexMarker191"/> network). Communication<a id="_idIndexMarker192"/> with the <em class="italic">outside world</em> is possible with the help of <strong class="bold">Network Address Translation</strong> (<strong class="bold">NAT</strong>) done via the <strong class="bold">IPtables</strong> of <span class="No-Break">the host.</span></li>
				<li><strong class="source-inline">host</strong> – This is a type that is used when we want<a id="_idIndexMarker193"/> to create containers without network isolation. A container spawned with a host network won’t be isolated from the network of the host system where it was created. For example, you can start a container with the Apache web server listening on port <strong class="source-inline">80</strong> and it will be reachable from any other hosts on the same network right away unless protected by <span class="No-Break">a firewall.</span></li>
				<li><strong class="source-inline">none</strong> – This is a rarely used option that means<a id="_idIndexMarker194"/> all networking will be disabled for <span class="No-Break">the container.</span></li>
			</ul>
			<p>Pay attention that those types in the output of <strong class="source-inline">docker network ls</strong> have the <strong class="source-inline">local</strong> scope, meaning that they can be used on individual hosts where we spawn containers with Docker. But they won’t allow containers created on one server to communicate with containers created on another server directly (unless host networking is used, which is similar to running applications directly on the host when no containers <span class="No-Break">are involved).</span></p>
			<p>In order to establish networking<a id="_idIndexMarker195"/> between multiple hosts where we spawn containers communicating with each other, we need a so-called <em class="italic">overlay</em> network. Overlay networks connect <a id="_idIndexMarker196"/>multiple servers together, allowing communication between containers located on <span class="No-Break">different hosts.</span></p>
			<p class="callout-heading">Overlay network</p>
			<p class="callout">An overlay network is a virtual network running on top of another network, typically using packet encapsulation – an overlay network packet resides inside another packet that is forwarded to a <span class="No-Break">particular host.</span></p>
			<p>Whether you are running Kubernetes, Docker Swarm, or another solution to orchestrate containers, in the real world, you’ll always run multiple hosts for your workloads, and containers running on those hosts need to talk with each other using <span class="No-Break">overlay networks.</span></p>
			<p>When it comes to Kubernetes, similar to the CRI, it implements a <strong class="bold">Container Network Interface</strong> (<strong class="bold">CNI</strong>) that allows the usage of different overlay networks<a id="_idIndexMarker197"/> in a <span class="No-Break">pluggable manner.</span></p>
			<p class="callout-heading">CNI</p>
			<p class="callout">A CNI is an interface that allows Kubernetes to use different overlay networking plugins <span class="No-Break">for containers.</span></p>
			<p>The introduction of the CNI has allowed third parties to develop their own solutions that are compatible with Kubernetes and offer their own unique features, such as traffic encryption or network policies (firewall rules) in <span class="No-Break">container networks.</span></p>
			<p>Some of the CNI<a id="_idIndexMarker198"/> network plugins<a id="_idIndexMarker199"/> used<a id="_idIndexMarker200"/> with<a id="_idIndexMarker201"/> Kubernetes today are <strong class="bold">flannel</strong>, <strong class="bold">Cilium</strong>, <strong class="bold">Calico</strong>, and <strong class="bold">Weave</strong>, just to name a few. Kubernetes also makes it possible to use multiple plugins<a id="_idIndexMarker202"/> at the same time with <strong class="bold">Multus</strong> (a Multi-Network Plugin); however, this is an advanced topic that is out of scope for the KCNA exam. In <em class="italic">Part 3</em>, <em class="italic">Learn Kubernetes Fundamentals</em>, of the book, we will have another closer look at networking in Kubernetes, but<a id="_idIndexMarker203"/> now it is time to look further into <span class="No-Break">container storage.</span></p>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor052"/>Container storage</h1>
			<p>Containers are lightweight by design and, as we saw earlier, often<a id="_idIndexMarker204"/> even the basic tools such as <strong class="source-inline">ifconfig</strong> and <strong class="source-inline">ping</strong> might not be included in container images. That is because containers represent a minimal version of the OS environment where we only install an application we are going to containerize with its dependencies. You don’t usually need many packages or tools pre-installed inside container images except for those required for your application <span class="No-Break">to run.</span></p>
			<p>Containers also don’t keep the state by default, meaning that if you’ve placed some files inside the container filesystem while it was running and deleted the container after, all those files<a id="_idIndexMarker205"/> will be completely<a id="_idIndexMarker206"/> gone. Therefore, it is common to call containers <strong class="bold">stateless</strong> and the on-disk files in <span class="No-Break">containers </span><span class="No-Break"><strong class="bold">ephemeral</strong></span><span class="No-Break">.</span></p>
			<p>That does not mean we cannot use containers for important data that we need to persist in case a container fails or an <span class="No-Break">application exits.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">In case the application running inside the container fails, crashes, or simply terminates, the container also stops <span class="No-Break">by default.</span></p>
			<p>It is possible to keep the important data from the container by using <em class="italic">external</em> <span class="No-Break">storage systems.</span></p>
			<p>External storage<a id="_idIndexMarker207"/> can be a block volume<a id="_idIndexMarker208"/> attached to the container with a protocol such as <strong class="bold">iSCSI</strong> or it could be a <strong class="bold">Network File System</strong> (<strong class="bold">NFS</strong>) mount, for example. Or, external could also simply be a <em class="italic">local</em> directory on your container host. There are many<a id="_idIndexMarker209"/> options out there, but we commonly refer to external container storage <span class="No-Break">as </span><span class="No-Break"><em class="italic">volumes</em></span><span class="No-Break">.</span></p>
			<p>One container can have multiple volumes attached and those volumes can be backed by different technologies, protocols, and hardware. Volumes can also be shared between containers or detached from one container and attached to another container. Volume content exists outside of the container life cycle, allowing us to decouple container and application<a id="_idIndexMarker210"/> data. Volumes allow us to run <strong class="bold">stateful</strong> applications in containers that need to write to disk, whether it is a database, application, or any <span class="No-Break">other files.</span></p>
			<p>Let’s get back to our computer<a id="_idIndexMarker211"/> with Docker tooling and try to run the following in <span class="No-Break">the terminal:</span></p>
			<pre class="source-code">
$ docker run -it --name mycontainer --mount source=myvolume,target=/app ubuntu:22.04 bash</pre>
			<p>As we run it and attach <em class="italic">tty</em> to a container, we should be able to see our new <strong class="source-inline">myvolume</strong> mounted inside container <span class="No-Break">at </span><span class="No-Break"><strong class="source-inline">/app</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
root@e642a068d4f4:/# df -h
Filesystem      Size  Used Avail Use% Mounted on
overlay         126G  7.9G  112G   7% /
tmpfs            64M     0   64M   0% /dev
tmpfs           3.0G     0  3.0G   0% /sys/fs/cgroup
shm              64M     0   64M   0% /dev/shm
/dev/vda1       126G  7.9G  112G   7% /app
tmpfs           3.0G     0  3.0G   0% /proc/acpi
tmpfs           3.0G     0  3.0G   0% /sys/firmware
root@e642a068d4f4:/# cd /app/
root@e642a068d4f4:/app#</pre>
			<p>What happened is that Docker automatically created and attached a <strong class="source-inline">local</strong> volume for our container at the start. Local means the volume is backed by a directory on the host where the container <span class="No-Break">was started.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">Local storage can be used for testing or some development, but by no means is it suitable for production workloads and <span class="No-Break">business-critical data!</span></p>
			<p>If we now write any files to <strong class="source-inline">/app</strong>, they <span class="No-Break">will persist:</span></p>
			<pre class="source-code">
root@e642a068d4f4:/app# echo test &gt; hello_world
root@e642a068d4f4:/app# cat hello_world
test
root@e642a068d4f4:/app# exit
exit</pre>
			<p>Even if we remove the container <a id="_idIndexMarker212"/>by calling <span class="No-Break"><strong class="source-inline">docker rm</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
$ docker rm mycontainer
mycontainer</pre>
			<p>By calling <strong class="source-inline">docker volume ls</strong>, we are able to see which volumes currently exist on <span class="No-Break">our host:</span></p>
			<pre class="source-code">
$ docker volume ls
DRIVER    VOLUME NAME
local     myvolume</pre>
			<p>To find more details about the volume, we can use the <strong class="source-inline">docker volume </strong><span class="No-Break"><strong class="source-inline">inspect</strong></span><span class="No-Break"> command:</span></p>
			<pre class="source-code">
$ docker volume inspect myvolume
[
    {
        "CreatedAt": "2022-05-15T18:00:06Z",
        "Driver": "local",
        "Labels": null,
        "Mountpoint": "/var/lib/docker/volumes/myvolume/_data",
        "Name": "myvolume",
        "Options": null,
        "Scope": "local"
    }
]</pre>
			<p>Feel free to experiment more with volumes yourself at this point. For example, you could create a new container and attach the existing volume to make sure the data is <span class="No-Break">still there:</span></p>
			<pre class="source-code">
$ docker run -it --name mycontainer2 --mount source=myvolume,target=/newapp ubuntu:22.04 bash
root@fc1075366787:/# ls /newapp/
hello_world
root@fc1075366787:/# cat /newapp/hello_world
test</pre>
			<p>Now, when it comes<a id="_idIndexMarker213"/> to Kubernetes, you’ve probably already guessed it – similar to the CRI and the CNI, K8s implements the <strong class="bold">Container Storage </strong><span class="No-Break"><strong class="bold">Interface</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">CSI</strong></span><span class="No-Break">).</span></p>
			<p class="callout-heading">CSI</p>
			<p class="callout">The CSI allows using pluggable storage layers. External storage systems can be integrated for use in Kubernetes in a standardized way with <span class="No-Break">the CSI.</span></p>
			<p>The CSI allows vendors and cloud providers to implement support for their storage services<a id="_idIndexMarker214"/> or hardware appliances. For example, there is an <strong class="bold">Amazon Elastic Block Store</strong> (<strong class="bold">EBS</strong>) CSI driver that allows you to fully manage the life cycle of EBS volumes<a id="_idIndexMarker215"/> in the AWS cloud via Kubernetes. There is a <strong class="bold">NetApp Trident</strong> CSI project, which supports a variety of NetApp storage filers that can be used by containers in Kubernetes. And plenty of other CSI-compatible storage solutions <span class="No-Break">available today.</span></p>
			<p>Kubernetes is very powerful when it comes<a id="_idIndexMarker216"/> to managing storage; it can automatically provision, attach, and re-attach volumes between hosts and containers in the cluster. We will learn in more detail about Kubernetes features for stateful applications in <span class="No-Break"><em class="italic">Chapter 6</em></span>, <em class="italic">Deploying and Scaling Applications with Kubernetes</em>, and now let’s move on to learn about <span class="No-Break">container security.</span></p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor053"/>Container security</h1>
			<p>Container security is an advanced<a id="_idIndexMarker217"/> and complex topic and yet even for an entry-level KCNA certification, you are expected to know a few basics. As we’ve learned, <em class="italic">Namespaced</em> containers are the most commonly used containers and they share the kernel of an underlying OS. That means a process running in a container cannot see other processes running in other containers or processes running on the host. However, all processes running on one host still use the same kernel. If one of the containers gets compromised, there is a chance of the host and all other containers being compromised <span class="No-Break">as well.</span></p>
			<p>Let’s get back to our Docker setup for a quick demonstration. Start an Ubuntu container as we did before and run the <strong class="source-inline">uname -r</strong> command to see which kernel version <span class="No-Break">is used:</span></p>
			<pre class="source-code">
$ docker run -it ubuntu:22.04 bash
root@4a3db7a03ccf:/# uname -r
5.10.47-linuxkit</pre>
			<p>The output you’ll see depends on your host OS and kernel version. Don’t get surprised if you see another version. For example, you might <span class="No-Break">see this:</span></p>
			<pre class="source-code">
 5.13.0-39-generic</pre>
			<p>Now exit the container and start another one with an older version <span class="No-Break">of </span><span class="No-Break"><strong class="source-inline">Ubuntu:16.04</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
$ docker run -it ubuntu:16.04 bash
Unable to find image 'ubuntu:16.04' locally
16.04: Pulling from library/ubuntu
58690f9b18fc: Pull complete
b51569e7c507: Pull complete
da8ef40b9eca: Pull complete
fb15d46c38dc: Pull complete
Digest: sha256:20858ebbc96215d6c3c574f781133ebffdc7c18d98af 4f294cc4c04871a6fe61
Status: Downloaded newer image for ubuntu:16.04
root@049e8a43181f:/# uname -r
5.10.47-linuxkit
root@049e8a43181f:/#</pre>
			<p>See? We took an <strong class="source-inline">Ubuntu:16.04</strong> image that is more than 5 years old by now, but the kernel version<a id="_idIndexMarker218"/> used is exactly the same as in the first container. Even if you take a different flavor of Linux, the kernel version of your host OS will <span class="No-Break">be used.</span></p>
			<p>So, how can we protect the kernel<a id="_idIndexMarker219"/> of our host where we run <em class="italic">Namespaced</em> containers? Perhaps the two most well-known technologies are <strong class="bold">AppArmor</strong> for Ubuntu and <strong class="bold">Security-Enchanced Linux</strong> (<strong class="bold">SELinux</strong>) for Red Hat and the CentOS Linux family. Essentially, those projects<a id="_idIndexMarker220"/> allow you to enforce access control policies for all user applications and system services. Access to specific files or network resources can also be restricted. There is also a special tool for SELinux that helps to generate security profiles specifically for applications running in containers (<a href="https://github.com/containers/udica">https://github.com/containers/udica</a>). Kubernetes has integration with both AppArmor and SELinux that allows you to apply profiles and policies to containers managed <span class="No-Break">with K8s.</span></p>
			<p>Moving on, it is considered a bad practice and a security risk to run containers as a <strong class="source-inline">root</strong> user. In Linux, a <strong class="source-inline">root</strong> user is a user with an ID of <strong class="source-inline">0</strong> and a group ID of <strong class="source-inline">0</strong> (UID=0, GID=0). In all our hands-on exercises, we’ve used a <strong class="source-inline">root</strong> user <span class="No-Break">inside containers:</span></p>
			<pre class="source-code">
<strong class="source-inline">root</strong>@4a3db7a03ccf:/#
root@4a3db7a03ccf:/# id -u
0</pre>
			<p>In a real production environment, you should consider running applications as a non-root user because <strong class="source-inline">root</strong> is essentially a super-admin that can do anything in the system. Now comes the interesting part – a <strong class="source-inline">root</strong> user inside a container can also be a <strong class="source-inline">root</strong> user on the host where the container is running <em class="italic">(very bad practice!)</em>. Or, thanks to the Namespace functionality of the Linux kernel, the <strong class="source-inline">root</strong> user inside the container can be mapped to a different user ID on the host OS (such as <strong class="source-inline">UID=1001</strong>, for example). This is still not perfect, but in case a container is compromised, <strong class="source-inline">root</strong> inside the container won’t automatically gain <strong class="source-inline">root</strong> privileges on the <span class="No-Break">host OS.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">It is possible to specify which user and group to use for the application packaged in the container during the image build process. You can simply add the <strong class="source-inline">USER mynewuser</strong> instruction to a <strong class="source-inline">Dockerfile</strong> to define which user to use. You might need to first create this user by adding one more instruction above it. For example: <strong class="source-inline">RUN useradd -r -u </strong><span class="No-Break"><strong class="source-inline">1001 mynewuser</strong></span></p>
			<p>Last but not least, keep in mind which container images<a id="_idIndexMarker221"/> you are using in your environments. If you go to Docker Hub (<a href="https://hub.docker.com/">https://hub.docker.com/</a>) or any other online container registry, you’ll find lots and lots of third-party images that anybody can download and run. You might encounter an image that does exactly what you need. For example, an image might package a tool or an application you wanted to try (e.g., to monitor the database you are running). But it may well package malicious code inside. Therefore, make sure to run trusted code in <span class="No-Break">your containers.</span></p>
			<p>It is also better to build the image yourself and store it in your own repository because third-party public image repositories are completely out of your control. Their owner might simply delete or replace the image at any given point in time or make the repository private. You won’t notice that immediately and this might cause an incident when the image isn’t available for download. Finally, there are a number of tools available today<a id="_idIndexMarker222"/> that perform container<a id="_idIndexMarker223"/> image scanning<a id="_idIndexMarker224"/> for security vulnerabilities (<strong class="bold">Clair</strong>, <strong class="bold">Dagda</strong>, and <strong class="bold">Anchore</strong>, to name a few). Those tools can be integrated into the image build process to reduce the risks of using outdated packages or installing software with known <span class="No-Break">security exposures.</span></p>
			<p>Now that we know more about container<a id="_idIndexMarker225"/> security and networking, we will look into <em class="italic">service meshes</em> – a rather new technology for managing traffic and securing <span class="No-Break">cloud-native applications.</span></p>
			<h1 id="_idParaDest-55"><a id="_idTextAnchor054"/>Introducing service meshes</h1>
			<p>Before jumping into the definition<a id="_idIndexMarker226"/> of the service mesh, let’s reiterate quickly what we’ve learned previously about the architecture of <span class="No-Break">cloud-native applications.</span></p>
			<p>Modern cloud-native applications rely on microservices that work together as a part of bigger applications and communicate with each other over a network. Those microservices are packaged as container images and run with the help of an orchestration system such as Kubernetes. The nature of cloud-native applications is highly dynamic, and the number of running containers varies a lot depending on the current load and infrastructure events <span class="No-Break">or outages.</span></p>
			<p>Consider a situation where you are responsible for running an application your company has developed that consists of 20 different microservices. You have implemented autoscaling for all services and in the peak load times, the number of running containers goes well over a hundred (e.g., several container replicas for each service spread across multiple cloud instances). Even if using Kubernetes to effectively orchestrate that fleet, you still want to make sure your application runs reliably, infrastructure is secure, and if any problem occurs, you’re able to detect it and act fast. This is where a service mesh comes <span class="No-Break">into play.</span></p>
			<p class="callout-heading">Service mesh</p>
			<p class="callout">A service mesh is a dedicated infrastructure layer for making communication between services safe, observable, <span class="No-Break">and reliable.</span></p>
			<p>A service mesh is a special layer for handling service-to-service communication. The service here is typically a microservice running in a container orchestrated by Kubernetes. Technically, a service mesh can be used without Kubernetes and even containers, but in practice, most of the time, a service mesh is used together with containers orchestrated by Kubernetes. Examples of service<a id="_idIndexMarker227"/> meshes include <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break"><strong class="bold">Linkerd</strong></span></li>
				<li><span class="No-Break"><strong class="bold">Istio</strong></span></li>
				<li><strong class="bold">Open Service </strong><span class="No-Break"><strong class="bold">Mesh</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">OSM</strong></span><span class="No-Break">)</span></li>
				<li><strong class="bold">Consul Connect </strong><span class="No-Break"><strong class="bold">Service Mesh</strong></span></li>
			</ul>
			<p>The first three in the list are in fact open source CNCF projects, although of different <span class="No-Break">maturity levels.</span></p>
			<p>Now, what does <em class="italic">safe communication</em> mean in the context of a <span class="No-Break">service mesh?</span></p>
			<p>In the preceding part, we covered the basics of container security, but we have not looked further into securing network communication <em class="italic">between</em> containers. Securing network communication<a id="_idIndexMarker228"/> is often a part of the so-called <strong class="bold">Zero Trust</strong> <span class="No-Break">security approach.</span></p>
			<p class="callout-heading">Zero Trust</p>
			<p class="callout">Zero Trust is an approach where no one is trusted by default from within the network or outside of the network. Verification is required to gain access to services connected to <span class="No-Break">the network.</span></p>
			<p>The traditional network security<a id="_idIndexMarker229"/> approach is based on securing the perimeter of the infrastructure, that is, it is hard to obtain access to the network from the <em class="italic">outside</em>, but <em class="italic">inside</em> the network everyone is trusted by default. Obviously, if an attacker can breach perimeter security and access internal networks, they are very likely to gain access everywhere else, including confidential data. This is the reason why more and more enterprises are implementing the Zero Trust approach, and this is where a service mesh is <span class="No-Break">very helpful.</span></p>
			<p>One of the major advantages of a service mesh is that you do not need any changes in the application code to use a service mesh and its features. A service mesh is implemented <em class="italic">on the platform layer</em>, meaning that, once installed on the platform, all the applications (e.g., microservices in containers) can benefit from its features. With a service mesh, all traffic between containers can be automatically encrypted and decrypted and the applications running inside <em class="italic">won’t require a single line of </em><span class="No-Break"><em class="italic">code change</em></span><span class="No-Break">.</span></p>
			<p>The traditional approach to accomplishing this without a service mesh would require managing SSL certificates, requesting and renewing them on expiration, and potentially making further changes to the application or the <span class="No-Break">infrastructure levels.</span></p>
			<p>In fact, all service<a id="_idIndexMarker230"/> meshes from the aforementioned list offer <strong class="bold">mutually-authenticated Transport Layer Security</strong> (<strong class="bold">mTLS</strong>) for all TCP traffic between containers connected to the mesh. It is similar to regular <em class="italic">TLS</em> when the server identity is presented with a certificate, with the difference that in the case of <em class="italic">mTLS</em>, both sides have to identify themselves to start communicating. That means the client also needs to present a certificate that the server will verify. In our example, the client and server are two services in containers connected to the service mesh. And again, mTLS can be enabled completely automatically with no extra work required on the <span class="No-Break">application part.</span></p>
			<p>Before exploring other features, let’s first understand better how a service mesh works. The service mesh layer is interfaced with microservices through an array of lightweight network proxies and all traffic between microservices<a id="_idIndexMarker231"/> is routed via those proxies in their own infrastructure layer. Typically, proxies run alongside each service in so-called <em class="italic">sidecar</em> containers, and altogether, those sidecar<a id="_idIndexMarker232"/> proxies form a service mesh network, as depicted in <span class="No-Break"><em class="italic">Figure 4</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/B18970_04_02.jpg" alt="Figure 4.2 – Service mesh overview"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 4.2 – Service mesh overview</p>
			<p>The service mesh is usually made up of <span class="No-Break">two parts:</span></p>
			<ul>
				<li><strong class="bold">Data plane</strong> – This consists of network proxies<a id="_idIndexMarker233"/> that run next to containers with microservices. For example, in the case of the <em class="italic">Linkerd</em> service mesh, a <em class="italic">linkerd-proxy</em> is used, and in the case of <em class="italic">Istio</em>, an extended version of the <em class="italic">Envoy</em> proxy <span class="No-Break">is used.</span></li>
				<li><strong class="bold">Control plane</strong> – This consists of multiple components<a id="_idIndexMarker234"/> responsible for configuring network proxies, service discovery, certificate management, and <span class="No-Break">other features.</span></li>
			</ul>
			<p>For a service mesh<a id="_idIndexMarker235"/> to work with Kubernetes, it has to be compatible with the K8s <strong class="bold">Service Mesh </strong><span class="No-Break"><strong class="bold">Interface</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">SMI</strong></span><span class="No-Break">).</span></p>
			<p class="callout-heading">SMI</p>
			<p class="callout">This is a specification defining a standard, common, and portable set of APIs for smooth service mesh integration in a vendor-agnostic way. <em class="italic">SMI</em> serves the same purpose as <em class="italic">CRI</em>, <em class="italic">CNI</em>, and <em class="italic">CSI</em>, but for <span class="No-Break">service meshes.</span></p>
			<p>When it comes to observability, a service mesh<a id="_idIndexMarker236"/> offers detailed telemetry for all communications happening within the mesh. Automatically collected metrics from all proxies allow operators and engineers to troubleshoot, maintain, and optimize their applications. With a service mesh, we can trace the calls and service dependencies as well as inspecting traffic flows and individual requests. This information is extremely helpful to audit service behavior and response times, and to detect abnormalities in complex <span class="No-Break">distributed systems.</span></p>
			<p>Finally, a service mesh offers traffic management and reliability features. The exact functionality might vary from project to project, therefore some features provided by one service mesh might not be offered by another one. For the sake of example, let’s see what a <em class="italic">Linkerd</em> mesh has <span class="No-Break">to offer:</span></p>
			<ul>
				<li><strong class="bold">Load balancing</strong> – This is used for <strong class="bold">HTTP</strong>, <strong class="bold">HTTP/2</strong>, and <strong class="bold">gRPC</strong> requests as well as <strong class="bold">TCP</strong> connections. A service<a id="_idIndexMarker237"/> mesh can also automatically detect the fastest service endpoints and send <span class="No-Break">requests there.</span></li>
				<li><strong class="bold">Automatic retry and timeouts</strong> – This allows you to gracefully handle transient service<a id="_idIndexMarker238"/> failures by transparently <span class="No-Break">doing retries.</span></li>
				<li><strong class="bold">Traffic splitting</strong> – This allows you to dynamically<a id="_idIndexMarker239"/> shift a portion of service traffic from one service to another to implement complex rollout strategies for new <span class="No-Break">service versions.</span></li>
				<li><strong class="bold">Fault injection</strong> – This allows you to artificially introduce errors<a id="_idIndexMarker240"/> and faults to test the impact on the system or <span class="No-Break">connected services.</span></li>
			</ul>
			<p>All in all, a service mesh is a complex and advanced topic and we have only scratched the surface to learn the minimum required for passing the KCNA exam. If you are interested in knowing more, it is recommended to check the <em class="italic">Further </em><span class="No-Break"><em class="italic">reading</em></span><span class="No-Break"> section.</span></p>
			<p>One question you might be asking yourself at this point is <em class="italic">what’s the difference between overlay networks and service meshes and why do we </em><span class="No-Break"><em class="italic">need both?</em></span></p>
			<p>The short answer is that most overlay<a id="_idIndexMarker241"/> networks operate on the lower layer of the <strong class="bold">Open Systems Interconnection</strong> (<strong class="bold">OSI</strong>) model (Network layer 3) whereas a service mesh operates on layer 7 of the OSI model, focusing on services and high-level application protocols (if you’re not familiar with the OSI model, check the <em class="italic">Further reading</em> section). The functionality of one is not a replacement for the other, and service meshes are still gaining momentum meaning, that not every microservice-based or containerized application running on Kubernetes will use a service mesh. Technically, we are also not obligated to always use overlay networks with containers, as we saw in our exercises with Docker, but in the upcoming<a id="_idIndexMarker242"/> chapters, we’ll see why it <span class="No-Break">is favorable.</span></p>
			<h1 id="_idParaDest-56"><a id="_idTextAnchor055"/>Summary</h1>
			<p>In this chapter, we’ve learned a lot about container runtimes, container interfaces, and service meshes. A container runtime is low-level software that manages basic container operations such as image downloading and the start or deletion of containers. Kubernetes does not have its own runtime, but it provides interfaces that allow you to use different runtimes, different network plugins, different storage solutions, and different service meshes. Those interfaces are called CRI, CNI, CSI, and SMI respectively and their introduction allowed a lot of flexibility when <span class="No-Break">using K8s.</span></p>
			<p>We’ve also learned about container runtime types and their differences. <em class="italic">Namespaced</em> containers are the most popular and lightweight, however, they are not as secure as other types. <em class="italic">Virtualized</em> containers are the slowest, but they provide maximum security as each container uses an individual Linux kernel. <em class="italic">Sandboxed</em> containers fill the gap between the other two – they are more secure than namespaced ones and faster than <span class="No-Break">virtualized ones.</span></p>
			<p>When it comes to container networking, there are many options. For container-to-container communication in a cluster, we would typically use an overlay network. Kubernetes supports third-party network plugins through CNI, and those plugins provide a different set of features and capabilities. It is also possible to run containers in a non-isolated network environment, for example, directly in the network namespace of the host where the container <span class="No-Break">is started.</span></p>
			<p>Containers are <em class="italic">stateless</em> by design, meaning that they don’t preserve the data on the disk by default. To run a <em class="italic">stateful</em> application in a container, we need to attach external storage volumes that can be anything ranging from an iSCSI block device to a specific vendor or cloud provider solution or even a simple local disk. Kubernetes with a pluggable CSI allows a lot of flexibility when it comes to integrating external storage to containers orchestrated <span class="No-Break">by K8s.</span></p>
			<p>We additionally touched on the basics of container security. <em class="italic">Namespaced</em> containers share the same kernel, which is why it is important to make sure that no container gets compromised. There are security extensions such as <em class="italic">AppArmor</em> and <em class="italic">SELinux</em> that add an extra kernel protection layer with configurable profiles and there are best practices that help to minimize <span class="No-Break">the risks.</span></p>
			<p>One of the practices is to use regular <em class="italic">(non-root)</em> user accounts in containers and another one is to ensure that you execute trusted code in a container. It is recommended to build your own images and keep them in your own registries, rather than using images from unknown third-party repositories. Additionally, you could implement automatic vulnerability scanning as a part of the image <span class="No-Break">build process.</span></p>
			<p>Finally, we learned about the service mesh – a special infrastructure layer that allows securing network communication between services without any changes to the application code. A service mesh also provides a rich set of features for observability and traffic management and even allows you to automatically retry requests and <span class="No-Break">split traffic.</span></p>
			<p>In the upcoming chapter, we will get to a major part of the KCNA exam and this book – namely, Kubernetes for container orchestration. Now make sure to answer all of the following recap questions to test <span class="No-Break">your knowledge.</span></p>
			<h1 id="_idParaDest-57"><a id="_idTextAnchor056"/>Questions</h1>
			<p>As we conclude, here is a list of questions for you to test your knowledge regarding this chapter’s material. You will find the answers in the <em class="italic">Assessments</em> section of <span class="No-Break">the </span><span class="No-Break"><em class="italic">Appendix</em></span><span class="No-Break">:</span></p>
			<ol>
				<li>Which of the following is software responsible for starting and <span class="No-Break">stopping containers?</span><ol><li><span class="No-Break">Container hypervisor</span></li><li><span class="No-Break">Container daemon</span></li><li><span class="No-Break">Kubernetes</span></li><li><span class="No-Break">Container runtime</span></li></ol></li>
				<li>Which of the following are valid types of containers (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break"><strong class="source-inline">Hyperspaced</strong></span></li><li><span class="No-Break"><strong class="source-inline">Sandboxed</strong></span></li><li><span class="No-Break"><strong class="source-inline">Namespaced</strong></span></li><li><span class="No-Break"><strong class="source-inline">Virtualized</strong></span></li></ol></li>
				<li>Which of the following is an example of <span class="No-Break">sandboxed containers?</span><ol><li><span class="No-Break">Kata</span></li><li><span class="No-Break">gVisor</span></li><li><span class="No-Break">Docker</span></li><li><span class="No-Break">containerd</span></li></ol></li>
				<li>Which of the following is an example of <span class="No-Break">virtualized containers?</span><ol><li><span class="No-Break">Docker</span></li><li><span class="No-Break">containerd</span></li><li><span class="No-Break">gVisor</span></li><li><span class="No-Break">Kata</span></li></ol></li>
				<li>Which of the following allows you to use different container runtimes <span class="No-Break">with Kubernetes?</span><ol><li><span class="No-Break">CSI</span></li><li><span class="No-Break">SMI</span></li><li><span class="No-Break">CNI</span></li><li><span class="No-Break">CRI</span></li></ol></li>
				<li>Which of the following allows you to use different service meshes <span class="No-Break">with Kubernetes?</span><ol><li><span class="No-Break">CRI</span></li><li><span class="No-Break">SMI</span></li><li><span class="No-Break">CNI</span></li><li><span class="No-Break">CSI</span></li></ol></li>
				<li>Why are Namespaced containers considered <span class="No-Break">less secure?</span><ol><li>They use old <span class="No-Break">kernel features</span></li><li>They need Kubernetes <span class="No-Break">to run</span></li><li>They share a <span class="No-Break">host kernel</span></li><li>They share a <span class="No-Break">host network</span></li></ol></li>
				<li>Which container type is considered the most lightweight <span class="No-Break">and fast?</span><ol><li><span class="No-Break">Virtualized</span></li><li><span class="No-Break">Sandboxed</span></li><li><span class="No-Break">Namespaced</span></li><li><span class="No-Break">Hyperspaced</span></li></ol></li>
				<li>Which of the following storage solutions can be used <span class="No-Break">with Kubernetes?</span><ol><li>Any that supports <span class="No-Break">NFS v4.1</span></li><li>Any that is <span class="No-Break">CSI compatible</span></li><li>Any that is <span class="No-Break">CNI compatible</span></li><li>Any third-party cloud <span class="No-Break">provider storage</span></li></ol></li>
				<li>What has to be changed in the application code for the service mesh <span class="No-Break">to work?</span><ol><li>The application has to be rewritten <span class="No-Break">in Golang</span></li><li>The application needs to expose <span class="No-Break">the SMI</span></li><li>The application has to <span class="No-Break">be stateless</span></li><li>No application <span class="No-Break">changes needed</span></li></ol></li>
				<li>Which of the following is a feature of a service mesh (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">mTLS</span></li><li><span class="No-Break">Traffic management</span></li><li><span class="No-Break">Observability</span></li><li><span class="No-Break">Traffic compression</span></li></ol></li>
				<li>Which component does the service mesh data <span class="No-Break">plane include?</span><ol><li>Lightweight <span class="No-Break">network firewall</span></li><li>Lightweight <span class="No-Break">network proxy</span></li><li>Lightweight <span class="No-Break">load balancer</span></li><li>Lightweight <span class="No-Break">web server</span></li></ol></li>
				<li>Which of the following is a service mesh (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">Istio</span></li><li><span class="No-Break">Prometheus</span></li><li><span class="No-Break">Falco</span></li><li><span class="No-Break">Linkerd</span></li></ol></li>
				<li>Which of the following is considered best practice when it comes to container security (<span class="No-Break">pick multiple)?</span><ol><li>Run the application <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">UID=0</strong></span></li><li>Scan container images <span class="No-Break">for vulnerabilities</span></li><li>Run the application <span class="No-Break">as non-root</span></li><li>Run containers <span class="No-Break">with Kubernetes</span></li></ol></li>
				<li>Which of the following technologies can be used to improve container security (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">AppArmor</span></li><li><span class="No-Break">Ansible</span></li><li><span class="No-Break">SELinux</span></li><li><span class="No-Break">Firewalld</span></li></ol></li>
				<li>Which potential problems can you encounter when using public container registries (<span class="No-Break">pick multiple)?</span><ol><li>Third-party images might be deleted at <span class="No-Break">any time</span></li><li>Third-party images might fail to download due to <span class="No-Break">rate limiting</span></li><li>Third-party images might <span class="No-Break">contain malware</span></li><li>Third-party images might work in development but fail <span class="No-Break">in production</span></li></ol></li>
				<li>Which containers can <span class="No-Break">Kubernetes spawn?</span><ol><li><span class="No-Break">Namespaced containers</span></li><li>K8s does not spawn containers; the <span class="No-Break">runtime does</span></li><li><span class="No-Break">Virtualized containers</span></li><li><span class="No-Break">Sandboxed containers</span></li></ol></li>
				<li>What is typically used for multi-host <span class="No-Break">container networkin</span><a href="https://www.beyondcorp.com/"><span class="No-Break">g?</span></a><ol><li><a href="https://www.beyondcorp.com/"><span class="No-Break">IPtables</span></a></li><li><a href="https://www.beyondcorp.com/"><span class="No-Break">CNI</span></a></li><li><a href="https://www.beyondcorp.com/"><span class="No-Break">Service mes</span></a><span class="No-Break">h</span></li><li><span class="No-Break">Overlay network</span></li></ol></li>
			</ol>
			<h1 id="_idParaDest-58"><a id="_idTextAnchor057"/>Further reading</h1>
			<p>To learn more about the topics that were covered in this chapter, take a look at the <span class="No-Break">following resources:</span></p>
			<ul>
				<li>Zero <span class="No-Break">Trust: </span><a href="https://www.beyondcorp.com/"><span class="No-Break">https://www.beyondcorp.com/</span></a></li>
				<li>Linkerd <span class="No-Break">overview: </span><a href="https://linkerd.io/2.12/overview/"><span class="No-Break">https://linkerd.io/2.12/overview/</span></a></li>
				<li>About <span class="No-Break">Istio: </span><a href="https://istio.io/latest/about/service-mesh/"><span class="No-Break">https://istio.io/latest/about/service-mesh/</span></a></li>
				<li>Open Systems Interconnection (<span class="No-Break">OSI): </span><a href="https://en.wikipedia.org/wiki/OSI_model"><span class="No-Break">https://en.wikipedia.org/wiki/OSI_model</span></a></li>
			</ul>
		</div>
	

		<div id="_idContainer025" class="Content">
			<h1 id="_idParaDest-59"><a id="_idTextAnchor058"/>Part 3: <span lang="en-US" xml:lang="en-US">Learning Kubernetes Fundamentals</span></h1>
			<p>In this part, you’ll learn about Kubernetes from the basics: the architecture, resources and components, features, and use cases. You will install Kubernetes and get practical experience with it using minikube. You will learn how to run stateless and stateful workloads, debug applications, and follow best practices <span class="No-Break">with Kubernetes.</span></p>
			<p><span lang="en-US" xml:lang="en-US">This part contains the </span><span class="No-Break" lang="en-US" xml:lang="en-US">following chapters:</span></p>
			<ul>
				<li><a href="B18970_05.xhtml#_idTextAnchor059"><em class="italic">Chapter 5</em></a>, <em class="italic">Orchestrating Containers with Kubernetes</em></li>
				<li><a href="B18970_06.xhtml#_idTextAnchor068"><em class="italic">Chapter 6</em></a>, <em class="italic">Deploying and Scaling Applications with Kubernetes</em></li>
				<li><a href="B18970_07.xhtml#_idTextAnchor077"><em class="italic">Chapter 7</em></a>, <em class="italic">Application Placement and Debugging with Kubernetes</em></li>
				<li><a href="B18970_08.xhtml#_idTextAnchor085"><em class="italic">Chapter 8</em></a>, <em class="italic">Following Kubernetes Best Practices</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer026">
			</div>
		</div>
		<div>
			<div id="_idContainer027">
			</div>
		</div>
	</body></html>