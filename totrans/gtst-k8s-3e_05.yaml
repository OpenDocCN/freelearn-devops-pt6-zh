- en: Exploring Kubernetes Storage Concepts
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索Kubernetes存储概念
- en: 'In order to power modern microservices and other stateless applications, Kubernetes
    operators need to have a way to manage stateful data storage on the cluster. While
    it''s advantageous to maintain as much state as possible outside of the cluster
    in dedicated database clusters as a part of cloud-native service offerings, there''s
    often a need to keep a statement of record or state cluster for stateless and
    ephemeral services. We''ll explore what''s considered a more difficult problem
    in the container orchestration and scheduling world: managing locality-specific,
    mutable data in a world that relies on declarative state, decoupling physical
    devices from logical objects, and immutable approaches to system updates. We''ll
    explore strategies for setting up reliable, replicated storage for modern database
    engines.'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 为了支持现代微服务和其他无状态应用程序，Kubernetes操作员需要有一种方法来管理集群上的有状态数据存储。尽管将尽可能多的状态保留在集群外部的专用数据库集群中，作为云原生服务的一部分是有优势的，但通常也需要为无状态和临时服务保持一个记录或状态集群。我们将探讨在容器编排和调度领域中被认为是一个更困难的问题：在一个依赖声明性状态、将物理设备与逻辑对象解耦，并且采用不可变系统更新方式的世界中，如何管理特定位置的可变数据。我们将探索为现代数据库引擎设置可靠、复制存储的策略。
- en: In this chapter, we will discuss how to attach persistent volumes and create
    storage for stateful applications and data. We will walk through storage concerns
    and how we can persist data across pods and the container life cycle. We will
    explore the `PersistentVolumes` types, as well as `PersistentVolumeClaim`. Finally,
    we will take a look at StatefulSets and how to use dynamic volume provisioning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论如何附加持久卷并为有状态应用程序和数据创建存储。我们将介绍存储相关问题，以及如何在多个Pod和容器生命周期之间持久化数据。我们将探讨`PersistentVolumes`类型，以及`PersistentVolumeClaim`。最后，我们将查看StatefulSets及如何使用动态卷供给。
- en: 'The following topics will be covered in the chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Persistent storage
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久存储
- en: '`PersistentVolumes`'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PersistentVolumes`'
- en: '`PersistentVolumeClaim`'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`PersistentVolumeClaim`'
- en: Storage Classes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存储类
- en: Dynamic volume provisioning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态卷供给
- en: StatefulSets
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: StatefulSets
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: You'll need to have a running Kubernetes cluster to go through these examples.
    Please start your cluster up on your cloud provider of choice, or a local Minikube
    instance.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要有一个正在运行的Kubernetes集群来进行这些示例操作。请在你选择的云提供商上启动集群，或使用本地的Minikube实例。
- en: The code for this repository can be found here: [https://github.com/PacktPublishing/Getting-Started-with-Kubernetes-third-edition/tree/master/Code-files/Chapter05](https://github.com/PacktPublishing/Getting-Started-with-Kubernetes-third-edition/tree/master/Code-files/Chapter05)[.](https://github.com/PacktPublishing/Getting-Started-with-Kubernetes-third-edition/tree/master/Code%20files/Chapter%2005)
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本仓库的代码可以在这里找到：[https://github.com/PacktPublishing/Getting-Started-with-Kubernetes-third-edition/tree/master/Code-files/Chapter05](https://github.com/PacktPublishing/Getting-Started-with-Kubernetes-third-edition/tree/master/Code-files/Chapter05)[.](https://github.com/PacktPublishing/Getting-Started-with-Kubernetes-third-edition/tree/master/Code%20files/Chapter%2005)
- en: Persistent storage
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持久存储
- en: So far, we only worked with workloads that we could start and stop at will,
    with no issue. However, real-world applications often carry state and record data
    that we prefer (even insist) not to lose. The transient nature of containers themselves
    can be a big challenge. If you recall our discussion of layered filesystems in
    [Chapter 1](446f901d-70fa-4ebe-be8a-0de14248f99c.xhtml), *Introduction to Kubernetes*,
    the top layer is writable. (It's also frosting, which is delicious.) However,
    when the container dies, the data goes with it. The same is true for crashed containers
    that Kubernetes restarts.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只处理了那些可以随时启动和停止的工作负载，没有任何问题。然而，现实世界中的应用程序通常携带状态并记录数据，这些数据我们希望（甚至坚持）不丢失。容器本身的瞬态特性可能是一个巨大的挑战。如果你回想一下我们在[第一章](446f901d-70fa-4ebe-be8a-0de14248f99c.xhtml)《Kubernetes简介》中的分层文件系统讨论，最上层是可写的。（它也很美味。）然而，当容器死亡时，数据也随之消失。对于Kubernetes重新启动的崩溃容器也是如此。
- en: This is where volumes or disks come into play. Volumes exist outside the container
    and are coupled to the pod, which allows us to save our important data across
    containers outages. Further more, if we have a volume at the pod level, data can
    be shared between containers in the same application stack and within the same
    pod. A volume itself on Kubernetes is a directory, which the Pod provides to the
    containers running on it. There are a number of different volume types available
    at `spec.volumes`, which we'll explore, and they're mounted into containers with
    the `spec.containers.volumeMounts` parameter.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是卷或磁盘发挥作用的地方。卷存在于容器之外，并且与 Pod 绑定，这使得我们可以在容器宕机时保存重要数据。此外，如果我们在 Pod 层面上有一个卷，数据可以在同一个应用堆栈和同一个
    Pod 内的容器之间共享。Kubernetes 中的卷本身是一个目录，Pod 为其上的容器提供这个目录。`spec.volumes` 中有许多不同类型的卷，我们将会探索这些卷，它们通过
    `spec.containers.volumeMounts` 参数挂载到容器中。
- en: To see all the types of volumes available, visit **[https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes](https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes)**.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看所有可用的卷类型，请访问**[https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes](https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes)**。
- en: Docker itself has some support for volumes, but Kubernetes gives us persistent
    storage that lasts beyond the lifetime of a single container. The volumes are
    tied to pods and live and die with those pods. Additionally, a pod can have multiple
    volumes from a variety of sources. Let's take a look at some of these sources.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 本身对卷有一定的支持，但 Kubernetes 为我们提供了超越单个容器生命周期的持久存储。这些卷与 Pod 绑定，随着 Pod 的生死而生死。此外，Pod
    可以有来自多种来源的多个卷。让我们来看看其中的一些来源。
- en: Temporary disks
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 临时磁盘
- en: One of the easiest ways to achieve improved persistence amid container crashes
    and data sharing within a pod is to use the `emptydir` volume. This volume type
    can be used with either the storage volumes of the node machine itself or an optional
    RAM disk for higher performance.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器崩溃和 Pod 内数据共享方面，实现更好持久性的最简单方法之一是使用 `emptydir` 卷。这种卷类型可以与节点机器本身的存储卷或可选的 RAM
    磁盘一起使用，以提供更高的性能。
- en: Again, we improve our persistence beyond a single container, but when a pod
    is removed, the data will be lost. A machine reboot will also clear any data from
    RAM-type disks. There may be times when we just need some shared temporary space
    or have containers that process data and hand it off to another container before
    they die. Whatever the case, here is a quick example of using this temporary disk
    with the RAM-backed option.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 我们再次改进了单个容器之外的持久化存储，但当 Pod 被移除时，数据将丢失。机器重启也会清除任何来自 RAM 类型磁盘的数据。有时候我们只需要一些共享的临时空间，或者有些容器处理数据后将其交给另一个容器处理，直到它们消失。无论情况如何，这里有一个使用
    RAM 支持选项的临时磁盘的快速示例。
- en: 'Open your favorite editor and create a `storage-memory.yaml` file and type
    the following code:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 打开你喜欢的编辑器，创建一个 `storage-memory.yaml` 文件并输入以下代码：
- en: '[PRE0]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The preceding example is probably second nature by now, but we will once again
    issue a `create` command followed by an `exec` command to see the folders in the
    container:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 上述示例现在可能已经是顺手的操作了，但我们将再次发出一个 `create` 命令，接着是一个 `exec` 命令，来查看容器中的文件夹：
- en: '[PRE1]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'This will give us a Bash shell in the container itself. The `ls` command shows
    us a `memory-pd` folder at the top level. We use `grep` to filter the output,
    but you can run the command without `| grep memory-pd` to see all folders:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为我们提供容器本身的 Bash Shell。`ls` 命令会显示我们在顶层看到一个 `memory-pd` 文件夹。我们使用 `grep` 来过滤输出，但你也可以不加
    `| grep memory-pd` 直接运行命令来查看所有文件夹：
- en: '![](img/5778376c-a13b-458b-8332-0456cd86a375.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](img/5778376c-a13b-458b-8332-0456cd86a375.png)'
- en: Temporary storage inside a container
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 容器内部的临时存储
- en: Again, this folder is temporary as everything is stored in the node's (minion's) RAM.
    When the node gets restarted, all the files will be erased. We will look at a
    more permanent example next.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 再次强调，这个文件夹是临时的，因为所有内容都存储在节点（工作节点）的 RAM 中。当节点重启时，所有文件将被删除。接下来我们将查看一个更持久的示例。
- en: Cloud volumes
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 云卷
- en: Let's move on to something more robust. There are two types of PersistentVolumes
    that we'll touch base with in order to explain how you can use AWS's and GCE's
    block storage engines to provide stateful storage for your Kubernetes cluster.
    Given that many companies have already made significant investment in cloud infrastructure,
    we'll get you up and running with two key examples. You can consider these types
    of volumes or persistent volumes as storage classes. These are different from
    the `emptyDir` that we created before, as the contents of a GCE persistent disk
    or AWS EBS volume will persist even if a pod is removed. Looking ahead, this provides
    operators with the clever feature of being able to pre-populate data in these
    drives and can also be switched between pods.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续进行更强大的存储配置。我们将介绍两种类型的持久卷，以说明如何使用 AWS 和 GCE 的块存储引擎为你的 Kubernetes 集群提供有状态存储。由于许多公司已经在云基础设施上做出了大量投资，我们将通过两个关键示例让你快速上手。你可以将这些类型的卷或持久卷视为存储类。这些与我们之前创建的
    `emptyDir` 不同，因为即使 Pod 被删除，GCE 持久磁盘或 AWS EBS 卷的内容也会保留。展望未来，这为运维人员提供了一个巧妙的功能：能够预先填充数据到这些磁盘中，并且可以在
    Pod 之间切换。
- en: GCE Persistent Disks
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GCE 持久磁盘
- en: 'Let''s mount a `gcePersistentDisk` first. You can see more information about
    these drives here: [https://cloud.google.com/compute/docs/disks/](https://cloud.google.com/compute/docs/disks/).'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先挂载一个 `gcePersistentDisk`。你可以在这里查看更多关于这些磁盘的信息：[https://cloud.google.com/compute/docs/disks/](https://cloud.google.com/compute/docs/disks/)。
- en: Google Persistent Disk is durable and high performance block storage for the
    Google Cloud Platform. Persistent Disk provides SSD and HDD storage, which can
    be attached to instances running in either Google Compute Engine or Google Container
    Engine. Storage volumes can be transparently resized, quickly backed up, and offer
    the ability to support simultaneous readers.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Google 持久磁盘是 Google Cloud Platform 上耐用且高性能的块存储。持久磁盘提供 SSD 和 HDD 存储，可以附加到运行在
    Google 计算引擎或 Google 容器引擎中的实例上。存储卷可以透明地调整大小，快速备份，并支持同时读取。
- en: 'You''ll need to create a Persistent Disk using the GCE GUI, API, or CLI before
    we''re able to use it in our cluster, so let''s get started:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们能够在集群中使用它之前，你需要使用 GCE GUI、API 或 CLI 创建一个持久磁盘，所以我们开始吧：
- en: 'From the console, in Compute Engine, go to Disks. On this new screen, click
    on the Create Disk button. We''ll be presented with a screen similar to the following GCE
    new persistent disk screenshot:'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在控制台中，进入计算引擎（Compute Engine），转到磁盘（Disks）。在此新屏幕上，点击“创建磁盘”按钮。我们将看到类似以下的 GCE 新持久磁盘截图：
- en: '![](img/c784df5a-3bc5-4b18-93d2-23b30c0353f4.png)'
  id: totrans-36
  prefs: []
  type: TYPE_IMG
  zh: '![](img/c784df5a-3bc5-4b18-93d2-23b30c0353f4.png)'
- en: GCE new persistent disk
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: GCE 新持久磁盘
- en: Choose a name for this volume and give it a brief description. Make sure that
    Zone is the same as the nodes in your cluster. GCE Persistent Disks can only be
    attached to machines in the same zone.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为这个卷选择一个名称并简要描述它。确保区域与集群中的节点相同。GCE 持久磁盘只能附加到相同区域的机器上。
- en: 'Enter `mysite-volume-1` in the Name field. Choose a zone matching at least
    one node in your cluster. Choose None (blank disk) for Source type and give `10`
    (10 GB) as the value in Size (GB). Finally, click on Create:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在“名称”字段中输入 `mysite-volume-1`。选择一个至少有一个节点的区域，选择“无”（空白磁盘）作为源类型，并在大小（GB）中输入 `10`（10
    GB）。最后，点击“创建”：
- en: 'The nice thing about Persistent Disks on GCE is that they allow for mounting
    to multiple machines (nodes in our case). However, when mounting to multiple machines,
    the volume must be in read-only mode. So, let''s first mount this to a single
    pod, so we can create some files. Use the following code to make a `storage-gce.yaml` file
    to create a pod that will mount the disk in read/write mode:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: GCE 上持久磁盘的一个优点是，它们允许挂载到多个机器（在我们的情况中是节点）。然而，当挂载到多个机器时，卷必须处于只读模式。因此，让我们首先将其挂载到单个
    Pod，以便我们可以创建一些文件。使用以下代码创建一个 `storage-gce.yaml` 文件，来创建一个将磁盘以读写模式挂载的 Pod：
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'First, let''s issue a `create` command followed by a `describe` command to
    find out which node it is running on:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们执行一个 `create` 命令，接着执行一个 `describe` 命令，查看它运行在哪个节点上：
- en: '[PRE3]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Note the node and save the pod IP address for later. Then, open an SSH session
    into that node:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 注意节点并保存 Pod IP 地址以备后用。然后，打开一个 SSH 会话连接到该节点：
- en: '![](img/85454969-36e6-41d4-905f-0a0b02c6bcc4.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/85454969-36e6-41d4-905f-0a0b02c6bcc4.png)'
- en: Pod described with persistent disk
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 使用持久磁盘描述的 Pod
- en: 'Type the following command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 输入以下命令：
- en: '[PRE4]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Since we''ve already looked at the volume from inside the running container,
    let''s access it directly from the node (minion) itself this time. We will run
    a `df` command to see where it is mounted, but we will need to switch to root
    first:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经从正在运行的容器内查看过卷了，这次我们直接从节点（minion）本身访问它。我们将运行 `df` 命令来查看它挂载的位置，但首先我们需要切换到
    root 用户：
- en: '[PRE5]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As you can see, the GCE volume is mounted directly to the node itself. We can
    use the mount path listed in the output of the earlier `df` command. Use `cd`
    to change to the folder now. Then, create a new file named `index.html` with your
    favorite editor:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，GCE 卷直接挂载到节点本身。我们可以使用早期 `df` 命令输出中列出的挂载路径。现在使用 `cd` 命令切换到该文件夹。然后，使用你喜欢的编辑器创建一个名为
    `index.html` 的新文件：
- en: '[PRE6]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Enter a quaint message, such as `Hello from my GCE PD!`. Now, save the file
    and exit the editor. If you recall from the `storage-gce.yaml` file, the Persistent
    Disk is mounted directly to the nginx HTML directory. So, let''s test this out
    while we still have the SSH session open on the node. Do a simple `curl` command
    to the pod IP we wrote down earlier:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 输入一条简单的消息，比如 `Hello from my GCE PD!`。现在，保存文件并退出编辑器。如果你还记得 `storage-gce.yaml`
    文件，持久化磁盘直接挂载到 nginx 的 HTML 目录。所以，在我们仍然保持 SSH 会话打开的情况下，让我们来测试一下。使用 `curl` 命令访问我们之前记下的
    pod IP：
- en: '[PRE7]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You should see `Hello from my GCE PD!` or whatever message you saved in the
    `index.html` file. In a real-world scenario, we can use the volume for an entire
    website or any other central storage. Let's take a look at running a set of load
    balanced web servers all pointing to the same volume.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到 `Hello from my GCE PD!` 或者你在 `index.html` 文件中保存的任何消息。在现实场景中，我们可以将该卷用于整个网站或任何其他中央存储。让我们来看看如何运行一组负载均衡的
    web 服务器，所有服务器都指向相同的卷。
- en: 'First, leave the SSH session with two `exit` commands. Before we proceed, we
    will need to remove our `test-gce` pod so that the volume can be mounted read-only
    across a number of nodes:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用两个 `exit` 命令退出 SSH 会话。在继续之前，我们需要删除 `test-gce` pod，以便该卷可以在多个节点上以只读方式挂载：
- en: '[PRE8]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Now, we can create an `ReplicationController` that will run three web servers,
    all mounting the same Persistent Disk, as follows. Save the following code as
    the `http-pd-controller.yaml` file:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以创建一个 `ReplicationController`，它将运行三个 web 服务器，并且都挂载相同的持久化磁盘，代码如下所示。将以下代码保存为
    `http-pd-controller.yaml` 文件：
- en: '[PRE9]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let''s also create an external service and save it as the `http-pd-service.yaml`
    file, so we can see it from outside the cluster:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们还创建一个外部服务并将其保存为 `http-pd-service.yaml` 文件，这样我们就可以从集群外部访问它：
- en: '[PRE10]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Go ahead and create these two resources now. Wait a few moments for the external
    IP to get assigned. After this, a `describe` command will give us the IP we can
    use in a browser:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在就创建这两个资源吧。稍等片刻，等待外部 IP 分配完毕。之后，使用 `describe` 命令我们可以得到一个可以在浏览器中使用的 IP：
- en: '[PRE11]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following screenshot is the result of the preceding command:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图是前面命令的结果：
- en: '![](img/b7391a3f-56ef-4353-8f16-3cbde71160ba.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](img/b7391a3f-56ef-4353-8f16-3cbde71160ba.png)'
- en: K8s service with GCE PD shared across three pods
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: K8s 服务与 GCE PD 共享的三个 pod
- en: If you don't see the `LoadBalancer Ingress` field yet, it probably needs more
    time to get assigned. Type the IP address from `LoadBalancer Ingress` into a browser,
    and you should see your familiar `index.html` file show up with the text we entered
    previously!
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你还没有看到 `LoadBalancer Ingress` 字段，可能需要更多时间才能分配。将 `LoadBalancer Ingress` 中的
    IP 地址输入浏览器，你应该能看到你之前输入文本的 `index.html` 文件！
- en: AWS Elastic Block Store
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: AWS 弹性块存储
- en: 'K8s also supports AWS **Elastic Block Store** (**EBS**) volumes. Like the GCE
    Persistent Disks, EBS volumes are required to be attached to an instance running
    in the same availability zone. A further limitation is that EBS can only be mounted
    to a single instance at one time. Similarly to before, you''ll need to create
    an EBS volume using API calls, the CLI, or you''ll need to log in to the GUI manually
    and create the volume referenced by `volumeID`. If you''re authorized in the AWS
    CLI, you can use the following command to create a volume:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: K8s 还支持 AWS **弹性块存储**（**EBS**）卷。与 GCE 持久化磁盘类似，EBS 卷要求附加到同一可用区中运行的实例上。另一个限制是，EBS
    卷一次只能挂载到单个实例。和之前一样，你需要通过 API 调用、CLI 或者手动登录到 GUI 来创建 `volumeID` 引用的 EBS 卷。如果你已授权使用
    AWS CLI，可以使用以下命令创建卷：
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Make sure that your volume is created in the same region as your Kubernetes
    cluster!
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 确保你的卷是在与你的 Kubernetes 集群相同的区域内创建的！
- en: 'For brevity, we will not walk through an AWS example, but a sample YAML file
    is included to get you started. Again, remember to create the EBS volume before
    your pod. Save the following code as the `storage-aws.yaml` file:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简洁起见，我们将不详细演示一个 AWS 示例，但已经包含了一个示例 YAML 文件，帮助你入门。再次提醒，记得在部署 pod 之前创建 EBS 卷。将以下代码保存为`storage-aws.yaml`文件：
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Other storage options
  id: totrans-74
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 其他存储选项
- en: Kubernetes supports a variety of other types of storage volumes. A full list
    can be found here: [https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes](https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes).
    [](http://kubernetes.io/v1.0/docs/user-guide/volumes.html#types-of-volumes)
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 支持多种其他类型的存储卷。完整列表请见此处：[https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes](https://kubernetes.io/docs/concepts/storage/volumes/#types-of-volumes)。
    [](http://kubernetes.io/v1.0/docs/user-guide/volumes.html#types-of-volumes)
- en: 'Here are a few that may be of particular interest:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是几个可能特别感兴趣的选项：
- en: '`nfs`: This type allows us to mount a **Network File Share** (**NFS**), which
    can be very useful for both persisting the data and sharing it across the infrastructure'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nfs`：这种类型允许我们挂载**网络文件共享**（**NFS**），这对于数据持久化和在基础设施之间共享数据非常有用。'
- en: '`gitrepo`: As you might have guessed, this option clones a Git repository into
    a new and empty folder'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`gitrepo`：正如你可能猜到的，这个选项会将 Git 仓库克隆到一个新的空文件夹中。'
- en: PersistentVolumes and Storage Classes
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 持久卷和存储类
- en: Thus far, we've seen examples of directly provisioning the storage within our
    pod definitions. This works quite well if you have full control over your cluster
    and infrastructure, but at larger scales, application owners will want to use
    storage that is managed separately. Typically, a central IT team or the cloud
    provider will take care of the details behind provisioning storage and leave the
    application owners to worry about their primary concern, the application itself.
    This separation of concerns and duties in Kubernetes allows you to structure your
    engineering focus around a storage subsystem that can be managed by a distinct
    group of engineers.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已看到在 pod 定义中直接配置存储的示例。如果你完全控制集群和基础设施，这种方式非常有效，但在更大的规模上，应用程序所有者可能希望使用独立管理的存储。通常，中央
    IT 团队或云服务提供商会处理存储的配置细节，而应用程序所有者则专注于他们的主要任务——应用程序本身。Kubernetes 中这种关注点和职责的分离，使得你可以围绕一个可以由独立工程团队管理的存储子系统来组织你的工程重点。
- en: In order to accommodate this, we need some way for the application to specify
    and request storage without being concerned with how that storage is provided.
    This is where `PersistentVolumes` and `PersistentVolumeClaim` come into play.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了适应这一点，我们需要一种方式让应用程序指定和请求存储，而无需关注存储是如何提供的。这就是`PersistentVolumes`和`PersistentVolumeClaim`派上用场的地方。
- en: '`PersistentVolumes` are similar to the volumes we created earlier, but they
    are provided by the cluster administrator and are not dependent on a particular
    pod. `PersistentVolumes` are a resource that''s provided to the cluster just like
    any other object. The Kubernetes API provides an interface for this object in
    the form of NFS, EBS Persistent Disks, or any other volume type described before.
    Once the volume has been created, you can use `PersistentVolumeClaims` to request
    storage for your applications.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '`PersistentVolumes` 类似于我们之前创建的卷，但它们是由集群管理员提供的，不依赖于特定的 pod。`PersistentVolumes`
    是提供给集群的资源，就像任何其他对象一样。Kubernetes API 提供了这种对象的接口，支持 NFS、EBS 持久磁盘或之前描述的任何其他卷类型。一旦卷被创建，你可以使用`PersistentVolumeClaims`请求为应用程序提供存储。'
- en: '`PersistentVolumeClaims` is an abstraction that allows users to specify the
    details of the storage needed. We can defined the amount of storage, as well as
    the access type, such as `ReadWriteOnce` (read and write by one node), `ReadOnlyMany`
    (read-only by multiple nodes), and `ReadWriteMany` (read and write by many nodes).
    The cluster operators are in charge of providing a wide variety of storage options
    for application operators in order to meet requirements across a number of different
    access modes, sizes, speeds, and durability without requiring the end users to
    know the details of that implementation. The modes supported by cluster operators
    is dependent on the backing storage provider. For example, we saw in the AWS `aws-ebs`
    example that mounting to multiple nodes was not an option, while with GCP Persistent
    Disks could be shared among several nodes in read-only mode.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`PersistentVolumeClaims`是一个抽象，它允许用户指定所需存储的详细信息。我们可以定义存储的大小，以及访问类型，如`ReadWriteOnce`（由一个节点读写）、`ReadOnlyMany`（由多个节点只读）和`ReadWriteMany`（由多个节点读写）。集群操作员负责为应用程序操作员提供多种存储选项，以满足不同访问模式、大小、速度和耐用性等要求，而无需最终用户了解具体的实现细节。集群操作员支持的模式取决于后端存储提供商。例如，我们在AWS
    `aws-ebs`示例中看到，多个节点挂载不是一个选项，而在GCP Persistent Disks中，磁盘可以在只读模式下被多个节点共享。'
- en: Additionally, Kubernetes provides two other methods for specifying certain groupings
    or types of storage volumes. The first is the use of selectors, as we have seen
    previously for pod selection. Here, labels can be applied to storage volumes and
    then claims can reference these labels to further filter the volume they are provided.
    Second, Kubernetes has the concept of `StorageClass,` which allows us specify
    a storage provisioner and parameters for the types of volumes it provisions.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Kubernetes提供了两种其他方法来指定特定类型或分组的存储卷。第一种是使用选择器，就像我们之前用于Pod选择一样。在这里，标签可以应用于存储卷，然后声明可以引用这些标签来进一步筛选所提供的卷。第二种，Kubernetes有`StorageClass`的概念，它允许我们指定存储提供者和其提供的卷类型的参数。
- en: '`PersistentVolumes` and `PersistentVolumeClaims` have a life cycle that involves
    the following phases:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`PersistentVolumes`和`PersistentVolumeClaims`有一个生命周期，包括以下阶段：'
- en: Provisioning
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 供应
- en: Static or dynamic
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 静态或动态
- en: Binding
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 绑定
- en: Using
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用
- en: Reclaiming
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 回收
- en: Delete, retain, or recycle
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除、保留或回收
- en: 'We will dive into Storage Classes in the next section, but here is a quick
    example of a `PersistentVolumeClaim` for illustration purposes. You can see in
    the annotations that we request `1Gi` of storage in `ReadWriteOnce` mode with
    a `StorageClass` of `solidstate` and a label of `aws-storage`. Save the following
    code as the `pvc-example.yaml` file:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节深入探讨存储类，但这里有一个`PersistentVolumeClaim`的快速示例，供说明使用。你可以在注释中看到，我们请求在`ReadWriteOnce`模式下分配`1Gi`存储，`StorageClass`为`solidstate`，并且标签为`aws-storage`。请将以下代码保存为`pvc-example.yaml`文件：
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'As of Kubernetes version 1.8, there''s also alpha support for expanding `PersistentVolumeClaim`
    for `gcePersistentDisk`, `awsElasticBlockStore`, `Cinder`, `glusterfs`, and `rbd`
    volume claim types. These are similar to the thin provisioning that you may have
    seen with systems such as VMware, and they allow for resizing of a storage class
    via the `allowVolumeExpansion` field as long as you''re running either XFS or
    Ext3/Ext4 filesystems. Here''s a quick example of what that looks like:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从Kubernetes 1.8版本开始，`PersistentVolumeClaim`也支持对`gcePersistentDisk`、`awsElasticBlockStore`、`Cinder`、`glusterfs`和`rbd`卷类型进行扩展的alpha支持。这些类似于你可能在VMware等系统中看到的薄配置，它们允许通过`allowVolumeExpansion`字段来调整存储类的大小，只要你使用的是XFS或Ext3/Ext4文件系统。以下是一个快速示例：
- en: '[PRE15]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Dynamic volume provisioning
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 动态卷供应
- en: Now that we've explored how to build from volumes, storage classes, persistent
    volumes, and persistent volume claims, let's take a look at how to make that all
    dynamic and take advantage of the built-in scaling of the cloud! Dynamic provisioning
    removes the need for pre-crafted storage; it relies on requests from application
    users instead. You use the `StorageClass` API object to create dynamic resources.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经探讨了如何通过卷、存储类、持久卷和持久卷声明来构建存储，让我们看看如何将这一切动态化，并利用云的内建扩展能力！动态供应消除了对预先制作存储的需求；它依赖于应用程序用户的请求。你可以使用`StorageClass`
    API对象来创建动态资源。
- en: 'First, we can create a manifest that will define the type of storage class
    that we''ll use for our dynamic storage. We''ll use a vSphere example here to
    try out another storage class:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们可以创建一个清单，定义我们将用于动态存储的存储类类型。我们将在这里使用一个 vSphere 示例来尝试另一种存储类：
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Once we have the manifest, we can use this storage by including it as a class
    in a new `PersistentVolumeClaim`. You may remember this as `volume.beta.kubernetes.io/storage-class`
    in earlier, pre-1.6 versions of Kubernetes, but now you can simply include this
    property in the `PersistentVolumeClaim` object. Keep in mind that the value of
    `storageClassName` must match the available, dynamic `StorageClass` that the cluster
    operators have provided. Here''s an example of that:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们拥有清单，我们可以通过将其作为类包含在新的 `PersistentVolumeClaim` 中来使用此存储。你可能记得在 Kubernetes
    1.6 之前的版本中，它被称为 `volume.beta.kubernetes.io/storage-class`，但现在你可以简单地将这个属性包含在 `PersistentVolumeClaim`
    对象中。请记住，`storageClassName` 的值必须与集群操作员提供的可用动态 `StorageClass` 匹配。以下是一个示例：
- en: '[PRE17]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: When this claim is removed, the storage is dynamically deleted. You can make
    this a cluster default by ensuring that the `DefaultStorageClass` admission controller
    is turned on, and after you ensure that one `StorageClass` object is set to default.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当这个声明被删除时，存储会被动态删除。你可以通过确保启用 `DefaultStorageClass` 准入控制器，并确保将一个 `StorageClass`
    对象设置为默认值来使其成为集群的默认值。
- en: StatefulSets
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: StatefulSets
- en: The purpose of StatefulSets is to provide some consistency and predictability
    to application deployments with stateful data. Thus far, we have deployed applications
    to the cluster, defining loose requirements around required resources such as
    compute and storage. The cluster has scheduled our workload on any node that can
    meet these requirements. While we can use some of these constraints to deploy
    in a more predictable manner, it will be helpful if we had a construct built to
    help us provide this consistency.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSets 的目的是为具有状态数据的应用程序部署提供一些一致性和可预测性。到目前为止，我们已将应用程序部署到集群中，定义了围绕所需资源（如计算和存储）的宽松要求。集群已将我们的工作负载调度到任何能够满足这些要求的节点上。虽然我们可以利用一些约束以更可预测的方式进行部署，但如果有一个构造可以帮助我们提供这种一致性，那就更有帮助了。
- en: StatefulSets were set to GA in 1.6 as we went to press. There were previously
    beta in version 1.5 and were known as Pet Sets prior to that (alpha in 1.3 and
    1.4).
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSets 在 1.6 版本中正式发布。它们之前在 1.5 版本中是 beta 版本，在此之前（1.3 和 1.4 版本）被称为 Pet
    Sets（alpha）。
- en: 'This is where StatefulSets come in. StatefulSets provide us first with numbered
    and reliable naming for both network access and storage claims. The pods themselves
    are named with the following convention, where `N` is from 0 to the number of
    replicas:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是 StatefulSets 的作用。StatefulSets 首先为我们提供了用于网络访问和存储声明的编号和可靠命名。Pod 本身的命名遵循以下约定，其中
    `N` 从 0 到副本数：
- en: '[PRE18]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This means that a StatefulSet called `db` with three replicas will create the
    following pods:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着一个名为 `db` 的 StatefulSet，具有三个副本，将创建以下 Pod：
- en: '[PRE19]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: This gives Kubernetes a way to associate network names and `PersistentVolumes`
    with specific pods. Additionally, it also serves to order the creation and termination
    of pods. Pod will be started from `0` to `N` and terminated from `N` to `0`.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这为 Kubernetes 提供了一种将网络名称和 `PersistentVolumes` 与特定 Pod 关联的方法。此外，它还用于控制 Pod 的创建和终止顺序。Pod
    将从 `0` 启动到 `N`，并从 `N` 终止到 `0`。
- en: A stateful example
  id: totrans-111
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 一个有状态的示例
- en: 'Let''s take a look at an example of a stateful application. First, we will
    want to create and use a `StorageClass`, as we discussed earlier. This will allow
    us to hook into the Google Cloud Persistent Disk provisioner. The Kubernetes community
    is building provisioners for a variety of `StorageClasses`, including GCP and
    AWS. Each provisioner has its own set of parameters available. Both GCP and AWS
    providers let you choose the type of disk (solid-state, standard, and so on) as
    well as the fault zone that is needed to match the pod attaching to it. AWS additionally
    allows you to specify encryption parameters as well as IOPs for provisioned IOPs
    volumes. There are a number of other provisioners in the works, including Azure
    and a variety of non-cloud options. Save the following code as `solidstate-sc.yaml`
    file:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个有状态应用的示例。首先，我们需要创建并使用一个`StorageClass`，正如我们之前讨论的那样。这将允许我们连接到 Google Cloud
    Persistent Disk 提供者。Kubernetes 社区正在为各种 `StorageClasses` 构建提供者，包括 GCP 和 AWS。每个提供者都有自己的一组可用参数。GCP
    和 AWS 提供者都允许您选择磁盘类型（固态、标准等），以及与之匹配的 pod 附加的故障域。AWS 还允许您指定加密参数以及为预配置的 IOPs 卷设置
    IOPs。还有许多其他提供者正在开发中，包括 Azure 以及各种非云选项。将以下代码保存为 `solidstate-sc.yaml` 文件：
- en: '[PRE20]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Use the following command with the preceding listing to create a `StorageClass`
    kind of SSD drive in `us-central1-b`:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令结合前面的列表来在 `us-central1-b` 创建一个 `StorageClass` 类型的 SSD 磁盘：
- en: '[PRE21]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Next, we will create a `StatefulSet` kind with our trusty `httpwhalesay` demo.
    While this application does include any real state, we can see the storage claims
    and explore the communication path as shown in the listing `sayhey-statefulset.yaml`:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个 `StatefulSet` 类型，并使用我们可靠的 `httpwhalesay` 示例应用。虽然这个应用并不包含任何实际的状态，但我们可以看到存储声明并探索通信路径，如
    `sayhey-statefulset.yaml` 列表所示：
- en: '[PRE22]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Use the following command to start the creation of this StatefulSet. If you
    observe pod creation closely, you will see it create `whaleset-0`, `whaleset-1`,
    and `whaleset-2` in succession:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令开始创建这个 StatefulSet。如果您仔细观察 pod 创建过程，您将看到它依次创建 `whaleset-0`、`whaleset-1`
    和 `whaleset-2`：
- en: '[PRE23]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Immediately after this, we can see our StatefulSet and the corresponding pods
    using the familiar `get` subcommand:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 紧接着，我们可以使用熟悉的 `get` 子命令查看我们的 StatefulSet 和相应的 pods：
- en: '[PRE24]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'These pods should create an output similar to the following images:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这些 pod 应该会生成类似于以下图片的输出：
- en: '![](img/fde496eb-700b-4031-b640-a23b597685ff.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![](img/fde496eb-700b-4031-b640-a23b597685ff.png)'
- en: StatefulSet listing
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSet 列表
- en: 'The `get pods` output will show the following:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '`get pods` 的输出将显示以下内容：'
- en: '![](img/f12ee6eb-82bc-4a6b-b835-79966684183f.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f12ee6eb-82bc-4a6b-b835-79966684183f.png)'
- en: Pods created by StatefulSet
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSet 创建的 pod
- en: Depending on your timing, the pods may still be being created. As you can see
    in the preceding screenshot, the third container is still being spun up.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 根据您的时机，pod 可能仍在创建中。正如您在前面的截图中看到的，第三个容器仍在启动中。
- en: 'We can also see the volumes the set has created and claimed for each pod. First
    are the `PersistentVolumes` themselves:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以看到该集合为每个 pod 创建并声明的卷。首先是 `PersistentVolumes` 本身：
- en: '[PRE25]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The preceding command should show the three `PersistentVolumes` named `www-whaleset-N`.
    We notice the size is `1Gi` and the access mode is set to **ReadWriteOnce** (**RWO**),
    just as we defined in our `StorageClass`:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的命令应该显示名为 `www-whaleset-N` 的三个 `PersistentVolumes`。我们注意到其大小为 `1Gi`，访问模式设置为
    **ReadWriteOnce** (**RWO**)，正如我们在 `StorageClass` 中定义的那样：
- en: '![](img/3aef7e63-a7c2-4949-b5da-3702291858fb.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![](img/3aef7e63-a7c2-4949-b5da-3702291858fb.png)'
- en: The PersistentVolumes listing
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: PersistentVolumes 列表
- en: 'Next, we can look at the `PersistentVolumeClaim` that reserves the volumes
    for each pod:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以查看为每个 pod 保留卷的 `PersistentVolumeClaim`：
- en: '[PRE26]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The following is the output of the preceding command:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前一个命令的输出：
- en: '![](img/579e0133-31b8-41d7-94cf-9306920b10da.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/579e0133-31b8-41d7-94cf-9306920b10da.png)'
- en: The PersistentVolumeClaim listing
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: PersistentVolumeClaim 列表
- en: You'll notice many of the same settings here as with the `PersistentVolumes`
    themselves. You might also notice the end of the claim name (or `PersistentVolumeClaim`
    name in the previous listing) looks like `www-whaleset-N`. `www` is the mount
    name we specified in the preceding YAML definition. This is then appended to the
    pod name to create the actual `PersistentVolume` and `PersistentVolumeClaim` name.
    One more area we can ensure that the proper disk is linked with it's matching
    pod.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到这里与 `PersistentVolumes` 本身有许多相同的设置。你还会注意到声明名称的结尾（或之前列出的 `PersistentVolumeClaim`
    名称）看起来像是 `www-whaleset-N`。`www` 是我们在前面 YAML 定义中指定的挂载名称。接着，这个名称会与 Pod 名称一起拼接，形成实际的
    `PersistentVolume` 和 `PersistentVolumeClaim` 名称。我们还可以确保将正确的磁盘与匹配的 Pod 进行关联。
- en: 'Another area where this alignment is important is in network communication.
    StatefulSets also provide consistent naming here. Before we can do this, let''s
    create a service endpoint `sayhey-svc.yaml`, so we have a common entry point for
    incoming requests:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 网络通信中，另一个需要对齐的领域是 StatefulSets 的一致命名。在此之前，我们需要创建一个服务端点 `sayhey-svc.yaml`，这样我们就有了一个通用的入口点来处理传入的请求：
- en: '[PRE27]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Now, let''s open a shell in one of the pods and see if we can communicate with
    another in the set:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在其中一个 Pod 中打开一个 shell，看看我们能否与该集合中的另一个 Pod 进行通信：
- en: '[PRE28]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The preceding command gives us a bash shell in the first `whaleset` pod. We
    can now use the service name to make a simple HTTP request. We can use both the
    short name, `sayhey-svc`, and the fully qualified name, `sayhey-svc.default.svc.cluster.local`:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令给了我们第一个 `whaleset` Pod 的 bash shell。现在，我们可以使用服务名称发出简单的 HTTP 请求。我们可以使用短名称
    `sayhey-svc` 以及完全限定名称 `sayhey-svc.default.svc.cluster.local`：
- en: '[PRE29]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'You''ll see an output similar to the following screenshot. The service endpoint
    acts as a common communication point for all three pods:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到类似于以下截图的输出。服务端点作为所有三个 Pod 的公共通信点：
- en: '![](img/f34721ea-f07b-4588-9646-d0809e47025b.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![](img/f34721ea-f07b-4588-9646-d0809e47025b.png)'
- en: HTTP whalesay curl output (whalesay-0 Pod)
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP whalesay curl 输出（whalesay-0 Pod）
- en: 'Now, let''s see if we can communicate with a specific pod in the StatefulSet.
    As we noticed earlier, the StatefulSet named the pods in an orderly manner. It
    also gives them hostnames in a similar fashion so that there is a specific DNS
    entry for each pod in the set. Again, we will see the convention of `"Name of
    Set"-N` and then add the fully qualified service URL. The following example shows
    this for `whaleset-1`, which is the second pod in our set:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看我们能否与 StatefulSet 中的特定 Pod 进行通信。如我们之前所注意到的，StatefulSet 以有序的方式命名 Pod。它还以类似的方式为它们分配主机名，因此每个
    Pod 在集合中都有一个特定的 DNS 条目。同样，我们将看到`"Name of Set"-N`的惯例，然后添加完全限定的服务 URL。以下示例展示了 `whaleset-1`，即集合中的第二个
    Pod：
- en: '[PRE30]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Running this command from our existing Bash shell in `whaleset-0` will show
    us the output from `whaleset-1`:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们现有的 Bash shell 中运行此命令，位于 `whaleset-0`，将显示来自 `whaleset-1` 的输出：
- en: '![](img/37cded0d-4ccf-4237-86b5-86c8e893a4b6.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![](img/37cded0d-4ccf-4237-86b5-86c8e893a4b6.png)'
- en: HTTP whalesay curl output (whalesay-1 Pod)
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: HTTP whalesay curl 输出（whalesay-1 Pod）
- en: You can exit out of this shell now with `exit`.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以通过 `exit` 退出这个 shell。
- en: For learning purposes, it may also be instructive to describe some of the items
    from this section in more detail. For example, `kubectl describe svc sayhey-svc`
    will show us all three pod IP address in the service endpoints.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 为了学习目的，描述这一部分中的某些项目的更多细节也可能是有益的。例如，`kubectl describe svc sayhey-svc` 将显示服务端点中的所有三个
    Pod IP 地址。
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored a variety of persistent storage options and how
    to implement them with our pods. We looked at `PersistentVolumes` and also `PersistentVolumeClaim`,
    which allow us to separate storage provisioning and application storage requests.
    Additionally, we looked at `StorageClasses` for provisioning groups of storage
    according to a specification.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探索了多种持久化存储选项以及如何在我们的 Pod 中实现它们。我们研究了`PersistentVolumes`和`PersistentVolumeClaim`，它们使我们能够分离存储供应和应用存储请求。此外，我们还研究了`StorageClasses`，它根据规范来提供一组存储。
- en: We also explored the new StatefulSets abstraction and learned how we can deploy
    stateful applications in a consistent and ordered manner. In the next chapter,
    we will look at how to integrate Kubernetes with Continuous Integration and Delivery
    pipelines.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还探索了新的 StatefulSets 抽象，并了解了如何以一致且有序的方式部署有状态应用程序。在下一章中，我们将探讨如何将 Kubernetes
    与持续集成和交付管道集成。
- en: Questions
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Name four kinds of volumes that Kubernetes supports
  id: totrans-160
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请列出 Kubernetes 支持的四种卷类型。
- en: What's the parameter that you can use to enable a simple, semi-persistent temporary
    disk?
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以使用哪个参数来启用一个简单的、半持久的临时磁盘？
- en: Name two backing technologies that make `PersistentVolumes` easy to implement
    with **Cloud Service Providers** (**CSPs**)
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 举出两种使`PersistentVolumes`在**云服务提供商**（**CSPs**）中易于实现的支持技术。
- en: What's a good reason for creating different types of `StorageClasses`?
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建不同类型`StorageClasses`的一个好理由是什么？
- en: Name two phases in the `PersistentVolume` and `PersistentVolumeClaim` lifecycle
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 举出`PersistentVolume`和`PersistentVolumeClaim`生命周期中的两个阶段
- en: Which Kubernetes object is used to provide a stateful storage-based application?
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个Kubernetes对象用于提供基于状态存储的应用？
- en: Further reading
  id: totrans-166
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: If you'd like to know more about dynamic storage provisioning, please read this
    blog post: [https://kubernetes.io/blog/2017/03/dynamic-provisioning-and-storage-classes-kubernetes/](https://kubernetes.io/blog/2017/03/dynamic-provisioning-and-storage-classes-kubernetes/)
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于动态存储配置的内容，请阅读这篇博客文章：[https://kubernetes.io/blog/2017/03/dynamic-provisioning-and-storage-classes-kubernetes/](https://kubernetes.io/blog/2017/03/dynamic-provisioning-and-storage-classes-kubernetes/)
- en: If you'd like to know more about the cutting edge of the **Storage Special Interest
    Group** (**SIG**), you can read about it here: [https://github.com/kubernetes/community/tree/master/sig-storage](https://github.com/kubernetes/community/tree/master/sig-storage)
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于**存储特别兴趣小组**（**SIG**）的前沿内容，可以在这里阅读：[https://github.com/kubernetes/community/tree/master/sig-storage](https://github.com/kubernetes/community/tree/master/sig-storage)
