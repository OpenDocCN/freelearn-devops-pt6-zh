<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer386">
<h1 class="chapter-number" id="_idParaDest-221"><a id="_idTextAnchor223"/>14</h1>
<h1 id="_idParaDest-222"><a id="_idTextAnchor224"/>Hardware Virtualization for Securing Containers</h1>
<p>In the previous chapter, we looked at how to create a highly available MicroK8s Kubernetes cluster using the stacked cluster <strong class="bold">high-availability</strong> (<strong class="bold">HA</strong>) topology. We have used the three nodes to install and configure MicroK8s on each of them, as well as simulating node failure to see whether the cluster could withstand component failures and still work normally. We’ve also gone over some best practices for deploying Kubernetes applications on a production-ready cluster. We noticed that MicroK8s’ HA option has also been streamlined and is now activated by default.</p>
<p>Container technologies have dominated the industry in recent years and have become the de facto standard for building modern IT infrastructure. They are frequently preferred over standard <strong class="bold">virtual machines (VMs)</strong> due to their lightweight design and bare-metal-like performance. However, security and isolation are two of the most common adoption issues (refer to the recent Kubernetes<a id="_idIndexMarker1146"/> and cloud-native operations report, published in 2022, at <a href="https://juju.is/cloud-native-kubernetes-usage-report-2022">https://juju.is/cloud-native-kubernetes-usage-report-2022</a>). In this chapter, we’ll look at how to use Kata Containers to create a secure container runtime and leverage hardware virtualization technology to give better workload isolation. </p>
<p>Before understanding what Kata Containers is, let us review how containers operate and how they relate to virtualization technology. A container is more like a <strong class="bold">VM</strong> that allows the packaging of software and all of its dependencies into a single entity that can execute in any supported environment. </p>
<p>VMs, on the other hand, are larger<a id="_idIndexMarker1147"/> and require longer to set up. Containers<a id="_idIndexMarker1148"/> have a substantially lower footprint than VMs and are thus much faster to set up (and tear down). Containers, unlike VMs, which keep entire copies of the operating system, only share the host system’s operating system kernel.</p>
<div>
<div class="IMG---Figure" id="_idContainer378">
<img alt="Figure 14.1 – VMs versus containers " height="687" src="image/Figure_14.1_B18115.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.1 – VMs versus containers</p>
<p>The container runtime<a id="_idIndexMarker1149"/> is the bridging software that allows a host system to separate<a id="_idIndexMarker1150"/> its resources for containers, tear down container images, and manage container life cycles. Every node on the Kubernetes cluster must have a container runtime installed. </p>
<p>Canonical MicroK8s has made it easy to enable Kata Containers (a container runtime), which can greatly improve the security and isolation of your container operations, with just a single command. It combines the advantages of a hypervisor, such as increased security, with Kubernetes’ container orchestration capabilities. In this chapter, we’re going to cover the following main topics:</p>
<ul>
<li>Overview of Kata Containers</li>
<li>Enabling the Kata add-on and running a sample application</li>
<li>Container security best practices</li>
</ul>
<h1 id="_idParaDest-223"><a id="_idTextAnchor225"/>Overview of Kata Containers</h1>
<p>The <strong class="bold">Open Container Interface</strong> (<strong class="bold">OCI</strong>) is a Linux Foundation initiative<a id="_idIndexMarker1151"/> that aims to establish<a id="_idIndexMarker1152"/> principles, standards, and specifications for Linux containers. The OCI runtime specifications are primarily<a id="_idIndexMarker1153"/> concerned with container life cycle management and configuration for multiple systems, including Linux, Windows, and Solaris. Low-level runtimes are container runtimes that comply with the OCI specification. Container creation and management are primarily the responsibility of low-level container runtimes. Designed by Docker, runC is an example of low-level container runtime and the standard for low-level container runtimes.</p>
<p>Low-level runtimes are native runtimes, which means they run containerized processes on the host kernel. There are also a few sandboxed and virtualized runtimes that provide improved process isolation by not running them on the host kernel. Kata Containers is one of the virtualized runtimes. To run containerized processes, these runtimes use a VM interface that behaves similarly to containers, but with the workload isolation and security benefits of VMs. </p>
<p>The Docker runtime was the default container runtime when Kubernetes was initially published. As the platform developed, so did the need to support different runtimes. </p>
<p>The <strong class="bold">Container Runtime Interface</strong> (<strong class="bold">CRI</strong>) was launched to make Kubernetes<a id="_idIndexMarker1154"/> more runtime agnostic. It’s a high-level specification that’s mostly focused on container orchestration. Unlike the OCI, the CRI handles extra aspects of container administration such as image management, snapshots, and networking while leaving container execution to an OCI-compliant runtime (such as runC).</p>
<p>Kata Containers (<a href="https://katacontainers.io/">https://katacontainers.io/</a>) is an open source project<a id="_idIndexMarker1155"/> that seeks to create a secure and OCI-compliant container runtime that improves the security and isolation of container workloads by encapsulating each one in a lightweight VM and employing hardware virtualization. Every VM has its own kernel that it uses.</p>
<p>As depicted in <em class="italic">Figure 14.2</em>, traditional containers employ runC as a container runtime, which relies on kernel features such as cgroups and namespaces to achieve isolation with the shared kernel; however, Kata Containers leverages hardware virtualization to isolate containers in their own lightweight VM as follows:</p>
<div>
<div class="IMG---Figure" id="_idContainer379">
<img alt="Figure 14.2 – Traditional containers versus Kata Containers " height="639" src="image/Figure_14.2_B18115.jpg" width="1235"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.2 – Traditional containers versus Kata Containers</p>
<p>Kata Containers<a id="_idIndexMarker1156"/> has a number of advantages over standard VMs, including the ability to effortlessly integrate with existing container orchestration technologies such as Kubernetes. Native Kubernetes capabilities such as auto-scaling and rolling updates are still available while you’re launching VMs. This enables the benefits of virtualization technology to be combined with container orchestration capabilities. In the following section, we can look at how the Kata containers are instantiated using kata-runtime.</p>
<h2 id="_idParaDest-224"><a id="_idTextAnchor226"/>How Kata Containers works</h2>
<p>When a Kubernetes cluster<a id="_idIndexMarker1157"/> is configured with a high-level runtime, such as containerd or CRI-O, a container runtime shim is installed to allow smooth communication between the CRI (containerd or CRI-O) and a low-level container runtime, such as runC (the default runtime), and this low-level container runtime is responsible for running the containers in the pod.</p>
<div>
<div class="IMG---Figure" id="_idContainer380">
<img alt="Figure 14.3 – Working of Kata Containers " height="553" src="image/Figure_14.3_B18115.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.3 – Working of Kata Containers</p>
<p>The steps for creating<a id="_idIndexMarker1158"/> Kata containers with segregated kernel and namespace are as follows:</p>
<ol>
<li>Kubernetes is configured with a high-level container runtime such as <strong class="bold">containerd</strong> or <strong class="bold">CRI-O</strong>. </li>
<li>A container runtime shim (<strong class="bold">containerd-shim</strong>) acts as a bridge between<a id="_idIndexMarker1159"/> the CRI (containerd or CRI-O) and a low-level container runtime, such as runC (the default runtime), for smooth communication.</li>
<li>The low-level container runtime (such as runC or kata-runtime) takes care of running the containers in the pod. </li>
<li>Kata Containers uses a runtime class (kata-runtime) to run containers in a separate kernel and namespace.</li>
</ol>
<p>Containers<a id="_idIndexMarker1160"/> can be run in a lightweight VM using <strong class="bold">containerd</strong> or <strong class="bold">CRI-O</strong> once Kata Containers<a id="_idIndexMarker1161"/> is enabled on the Kubernetes cluster with kata-runtime. <strong class="source-inline">containerd-shim-kata-v2</strong>, a new shim that acts as a bridge between containerd and <strong class="source-inline">kata-runtime</strong>, Kata Containers’ runtime class should also be enabled for running containers in a separate kernel and namespace.</p>
<p>In a nutshell, Kata is a container runtime that provides greater isolation between containers while maintaining the performance and efficiency of other runtimes. The following are some of its prominent features: </p>
<ul>
<li><strong class="bold">Security</strong>: It runs in a dedicated and isolated kernel and can be easily integrated with containerd or any other container runtime. It also supports several hypervisors such as QEMU, Cloud Hypervisor, and Firecracker.</li>
<li><strong class="bold">Compatibility with Docker and Kubernetes</strong>: By providing kata-runtime as a container runtime, it works easily with Docker and Kubernetes.</li>
<li><strong class="bold">Performance</strong>: It has the same consistency as any other Linux container but with more isolation. It also supports AMD64, ARM, IBM pSeries, and IBM zSeries platforms.</li>
<li><strong class="bold">Simplified</strong>: No need for nested containers inside VMs or sacrificing container speed.</li>
</ul>
<p>Apart from virtualized runtimes<a id="_idIndexMarker1162"/> or Kata Containers, there are various techniques<a id="_idIndexMarker1163"/> to isolate containers (refer to <a href="https://thenewstack.io/how-to-implement-secure-containers-using-googles-gvisor/">https://thenewstack.io/how-to-implement-secure-containers-using-googles-gvisor/</a>), each with its own set of attributes that will suit certain applications. The appropriate one for your apps is a crucial aspect of your container security architecture. </p>
<p>Now that we’ve grasped the fundamentals of how Kata Containers works, we can move on to the following step of enabling the Kata add-on and running a sample application.</p>
<h1 id="_idParaDest-225"><a id="_idTextAnchor227"/>Enabling the Kata add-on and running a sample application</h1>
<p>In this section, we can<a id="_idIndexMarker1164"/> go through the process of enabling the Kata add-on in your MicroK8s Kubernetes cluster. Then, to demonstrate Kata’s capabilities, we’ll deploy a sample application.</p>
<p class="callout-heading">Note</p>
<p class="callout">We’ll be using an Ubuntu VM for this section. The instructions for setting up the MicroK8s cluster are the same as in <a href="B18115_05.xhtml#_idTextAnchor070"><em class="italic">Chapter 5</em></a><em class="italic">,</em> <em class="italic">Creating and Implementing Updates on Multi-Node Raspberry Pi Kubernetes Clusters</em>.</p>
<h2 id="_idParaDest-226"><a id="_idTextAnchor228"/>Step 1 – Enabling the Kata add-on </h2>
<p>Starting with MicroK8s v1.24, you<a id="_idIndexMarker1165"/> must issue the <strong class="source-inline">enable community</strong> command to enable the community add-ons repository.</p>
<p>Use the following command to enable the <strong class="source-inline">community</strong> repository:</p>
<p class="source-code">microk8s enable community </p>
<p>It will take some time to finish activating the add-on; the following command execution output shows that the <strong class="source-inline">community</strong> repository has been successfully enabled:</p>
<div>
<div class="IMG---Figure" id="_idContainer381">
<img alt="Figure 14.4 – Enabling the community repository " height="155" src="image/Figure_14.4_B18115.jpg" width="993"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.4 – Enabling the community repository</p>
<p>Now that we have the <strong class="source-inline">community</strong> repository enabled, we can move on to the following step of enabling the Kata add-on.</p>
<p>Use the following command to enable the Kata add-on:</p>
<p class="source-code">microk8s enable kata </p>
<p>The following command execution output indicates that the Kata add-on is being enabled:</p>
<div>
<div class="IMG---Figure" id="_idContainer382">
<img alt="Figure 14.5 – Enabling the Kata add-on " height="493" src="image/Figure_14.5_B18115.jpg" width="1067"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.5 – Enabling the Kata add-on</p>
<p>From the preceding command<a id="_idIndexMarker1166"/> execution output, we can see that <strong class="source-inline">kata runtimeClassName</strong> (kata) is added, which allows us to specify which workloads should be launched in Kata Containers.</p>
<p class="callout-heading">Note</p>
<p class="callout">The <strong class="source-inline">--runtime-path</strong> parameter can also be used to specify<a id="_idIndexMarker1167"/> the location where the Kata runtime is installed. </p>
<p class="callout">Use the following command to enable the Kata add-on with the runtime path:</p>
<p class="callout"><strong class="source-inline">microk8s enable kata --runtime-path=&lt;&lt;kata-runtime-binary-path&gt;&gt;</strong></p>
<p>Before we move on to the following step, let’s make sure that the Kata add-on has been activated successfully using the <strong class="source-inline">microk8s status</strong> command as follows:</p>
<div>
<div class="IMG---Figure" id="_idContainer383">
<img alt="Figure 14.6 – The Kata add-on is enabled " height="239" src="image/Figure_14.6_B18115.jpg" width="899"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.6 – The Kata add-on is enabled</p>
<p>Now that the Kata add-on<a id="_idIndexMarker1168"/> has been enabled, we may deploy a sample nginx application in the following step.</p>
<p class="callout-heading">Note for using Kata Containers on multi-node clusters</p>
<p class="callout"><strong class="source-inline">microk8s enable kata</strong> must be executed<a id="_idIndexMarker1169"/> on each node in a multi-node cluster in order for the Kata runtime to be enabled on the desired nodes.</p>
<h2 id="_idParaDest-227"><a id="_idTextAnchor229"/>Step 2 – Deploying a sample application</h2>
<p>In this step, we will be deploying<a id="_idIndexMarker1170"/> the following sample nginx application deployment manifest, which uses the Kata runtime:</p>
<pre class="source-code">apiVersion: v1
kind: Pod
metadata:
  labels:
    app: kata
  name: nginx-kata
spec:
  runtimeClassName: kata
  containers:
    - name: nginx
      image: nginx</pre>
<p>Use the following command to create a sample nginx deployment:</p>
<p class="source-code">kubectl apply –f kata-nginx.yaml</p>
<p>The following command execution<a id="_idIndexMarker1171"/><a id="_idIndexMarker1172"/> output indicates that there is no error in the deployment and in the following steps, we can ensure that the pods are created as follows:</p>
<div>
<div class="IMG---Figure" id="_idContainer384">
<img alt="Figure 14.7 – Sample nginx application deployed " height="71" src="image/Figure_14.7_B18115.jpg" width="832"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.7 – Sample nginx application deployed</p>
<p>Now that the deployment is successful, let’s use the following <strong class="source-inline">kubectl</strong> command to check whether the pods are in a <strong class="source-inline">Running</strong> state:</p>
<div>
<div class="IMG---Figure" id="_idContainer385">
<img alt="Figure 14.8 – Checking whether the pods are in a Running state " height="107" src="image/Figure_14.8_B18115.jpg" width="891"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.8 – Checking whether the pods are in a Running state</p>
<p>The fact that <strong class="source-inline">nginx-kata</strong> is now in the <strong class="source-inline">Running</strong> state means that containers are running in a lightweight VM utilizing the containerd runtime. It used <strong class="source-inline">containerd-shim-kata-v2</strong>, which acts as a bridge between containerd and kata-runtime—a runtime class that comes with Kata Containers that allows containers to run in their own kernel and namespace.</p>
<p>Now that we’ve seen how easy is to enable the Kata add-on and run a sample application, let’s move on to the following section where we discuss the best practices for running containers.</p>
<h1 id="_idParaDest-228"><a id="_idTextAnchor230"/>Container security best practices </h1>
<p>Containers provide<a id="_idIndexMarker1173"/> a lot of advantages, but they also have some security issues that might be tough to solve. Because of the enormous number of containers based on many different underlying images, each of which could potentially have vulnerabilities, containers create a wider attack surface than traditional workloads.</p>
<p>Another important consideration is the kernel architecture shared by containers. Securing the host is insufficient to ensure security. You must also keep secure configurations to limit container permissions and ensure effective container isolation. For example, a container with an exploitable vulnerability, exposed metadata, and incorrect credentials configuration could jeopardize your entire infrastructure.</p>
<p>We’ll go through some of the most important factors to consider when running containers.</p>
<h2 id="_idParaDest-229"><a id="_idTextAnchor231"/>Utilizing DevSecOps</h2>
<p>The seamless integration of security testing<a id="_idIndexMarker1174"/> and protection across the software<a id="_idIndexMarker1175"/> development and deployment life cycle is referred to as DevSecOps. You may scan<a id="_idIndexMarker1176"/> your code for defects or possibly vulnerable code before shipping or even<a id="_idIndexMarker1177"/> building your application. There are various <strong class="bold">Static Application Security Testing</strong> (<strong class="bold">SAST</strong>) tools for application code, such as <strong class="bold">SonarQube</strong>, which provides vulnerability scanners<a id="_idIndexMarker1178"/> for various languages and detects vulnerabilities based on rules, linters, and so on. You can use them on the development workstation, but including code scanning tools in the CI/CD workflow ensures a minimal degree of code quality. For example, if some checks fail, you can deny pull requests by default.</p>
<p>Also, remove any components that your application doesn’t require. For example, remove the <strong class="source-inline">sed</strong> and <strong class="source-inline">awk</strong> binaries, which are installed by default on any UNIX system. This can assist you in lowering the attack surface.</p>
<h2 id="_idParaDest-230"><a id="_idTextAnchor232"/>Scanning external vulnerabilities via dependency scanning</h2>
<p>External dependencies, such<a id="_idIndexMarker1179"/> as third-party<a id="_idIndexMarker1180"/> libraries or frameworks that are used in your application, may contain flaws and vulnerabilities. Any application build process should incorporate dependency scanning as a best practice.</p>
<p>A vulnerability<a id="_idIndexMarker1181"/> database (such as NVD) can also be matched with your application dependencies using package management<a id="_idIndexMarker1182"/> tools such as <strong class="source-inline">npm</strong>, <strong class="source-inline">maven</strong>, <strong class="source-inline">go</strong>, and others to produce helpful alerts/warnings.</p>
<h2 id="_idParaDest-231"><a id="_idTextAnchor233"/>Analyzing container images using image scanning tools</h2>
<p>Analyze your container images<a id="_idIndexMarker1183"/> with an image scanner. The image scanning tool will find vulnerabilities<a id="_idIndexMarker1184"/> in the operating system packages provided by the container image base distribution (<strong class="source-inline">rpm</strong>, <strong class="source-inline">dpkg</strong>, <strong class="source-inline">apk</strong>, and so on). It will discover vulnerabilities in package dependencies for Java, Node.js, Python, and other languages.</p>
<p>Automating and enforcing image scanning is simple. It can be integrated into your CI/CD pipelines, triggered when new images are sent to a registry to ensure that non-compliant images are no longer permitted to run.</p>
<h2 id="_idParaDest-232"><a id="_idTextAnchor234"/>Enforcing image content trust</h2>
<p>If you aren’t making the image<a id="_idIndexMarker1185"/> from scratch, you should pick images<a id="_idIndexMarker1186"/> that are reliable. Anyone can utilize public image repositories such as Docker Hub, and they may contain viruses or misconfigurations.</p>
<p>Container image integrity can also be enforced by using Docker Notary or a comparable service to add digital signatures to the image, which can then be validated in the container runtime.</p>
<h2 id="_idParaDest-233"><a id="_idTextAnchor235"/>Securing registries</h2>
<p>Container images<a id="_idIndexMarker1187"/> are often saved in either private or public<a id="_idIndexMarker1188"/> registries. It’s crucial to keep these registries safe so that all team members and collaborators can use images that are as secure as possible. </p>
<p>If you have your own private registry, you must set up access controls that specify who can and cannot access and publish<a id="_idIndexMarker1189"/> images. Access control is a fundamental security measure that can prevent unauthorized <a id="_idIndexMarker1190"/>parties from altering, publishing, or deleting your images.</p>
<h2 id="_idParaDest-234"><a id="_idTextAnchor236"/>Securing your host</h2>
<p>It’s just as critical to secure<a id="_idIndexMarker1191"/> your host as it is to secure your containers. The host where the containers operate is often made up of an operating system with a Linux kernel, a collection of libraries, a container runtime, and various background services and helpers. Any of these components could be insecure or misconfigured, allowing unauthorized access to running containers or a <strong class="bold">Denial of Service</strong> (<strong class="bold">DoS</strong>) attack.</p>
<p>For example, difficulties with the container runtime itself, such as a DoS attack that prohibits the creation of new containers in a host, can have an impact on your operating containers. You could use host scanning utilities to identify known security holes in the host’s container runtime, services, standard libraries such glibc, and the kernel (quite similar to what image scanning does for a container image).</p>
<h2 id="_idParaDest-235"><a id="_idTextAnchor237"/>Securing your runtime</h2>
<p>The following <a id="_idIndexMarker1192"/>are some best practices<a id="_idIndexMarker1193"/> for ensuring runtime security:</p>
<ul>
<li><em class="italic">Create separate virtual networks for your containers</em>: This adds a layer of isolation that can help limit the attack surface.</li>
<li><em class="italic">Use the principle of least privilege</em>: Only allow connectivity between containers that genuinely require it.</li>
<li><em class="italic">Only expose the ports required by the application</em>: Except for SSH, do not expose any additional ports. Apply this idea to both containers and underlying computers.</li>
<li><em class="italic">Use TLS to secure service communication</em>: This method encrypts traffic and ensures that only authorized endpoints are allowed.</li>
<li><em class="italic">Use the Docker image policy plugin</em>: This plugin prevents any process from retrieving images<a id="_idIndexMarker1194"/> that have not previously<a id="_idIndexMarker1195"/> been allow-listed.</li>
</ul>
<h2 id="_idParaDest-236"><a id="_idTextAnchor238"/>Reviewing container privileges </h2>
<p>The scope of a vulnerability exploited<a id="_idIndexMarker1196"/> inside a container is largely determined by the container’s privileges and isolation from the host and other resources. The existing and prospective vulnerabilities can be mitigated by using runtime settings in the following ways:</p>
<ul>
<li>Run the container as a user, not as a root. Use randomized UIDs if possible.</li>
<li>Docker and Kubernetes both allow for the removal of capabilities and the disabling of privileged containers. Seccomp and AppArmor can limit the types of actions that a container can execute.</li>
<li>To avoid a container taking all of the memory or CPUs and starving other apps, use resource limits.</li>
<li>Examine shared storage or volumes on a regular basis, paying special attention to the host path and sharing the filesystem from the host.</li>
<li>Pod Security Policies can be used to create guardrails in your cluster and prevent misconfigured containers.</li>
</ul>
<h2 id="_idParaDest-237"><a id="_idTextAnchor239"/>Using real-time event and log auditing</h2>
<p>Threats to container<a id="_idIndexMarker1197"/> security can be detected by evaluating<a id="_idIndexMarker1198"/> aberrant activity<a id="_idIndexMarker1199"/> and auditing several sources of logs and events. The following<a id="_idIndexMarker1200"/> are some examples of sources of events:</p>
<ul>
<li>Logs from the host and Kubernetes</li>
<li>Container calls to the operating system</li>
</ul>
<p>Use tools (such as Falco and Sysdig Secure) that can track<a id="_idIndexMarker1201"/> the system calls that are made and send out alerts<a id="_idIndexMarker1202"/> if anything unusual happens. It should come with a pre-configured library of rules as well as the option to write your own using a simple syntax. It should also be able to monitor the Kubernetes audit log.</p>
<h2 id="_idParaDest-238"><a id="_idTextAnchor240"/>Monitoring resource usage</h2>
<p>Excessive resource utilization (CPU, RAM, and network), a rapid drop<a id="_idIndexMarker1203"/> in available disc space, an above-average<a id="_idIndexMarker1204"/> error rate, or increased latency could all be signs that something is wrong with your system.</p>
<p>Collect metrics in the same way as Prometheus (refer to <a href="B18115_08.xhtml#_idTextAnchor121"><em class="italic">Chapter 8</em></a>, <em class="italic">Monitoring the Health of Infrastructure and Applications</em>) does. Set up alerts to be notified as soon as the data exceeds the predicted thresholds. Use useful dashboards to track the evolution of metrics and see how they relate to other metrics and events in your system.</p>
<h2 id="_idParaDest-239"><a id="_idTextAnchor241"/>Common security misconfigurations and remediation</h2>
<p>Incorrectly configured<a id="_idIndexMarker1205"/> hosts, container runtimes, clusters, resources, and<a id="_idIndexMarker1206"/> so on may give an attacker a way to increase their privileges and move upward.</p>
<p>Learn how to spot configuration<a id="_idIndexMarker1207"/> errors, why they’re problematic, and how to correct them by using<a id="_idIndexMarker1208"/> benchmarks, best practices, and hardening guidelines. The <strong class="bold">Center for Internet Security</strong> (<strong class="bold">CIS</strong>) (<a href="https://www.cisecurity.org/benchmark/kubernetes">https://www.cisecurity.org/benchmark/kubernetes</a>) is the most authoritative source of information that provides free benchmarks for a variety of situations, and anyone and any firm can contribute their expertise. </p>
<p>The easiest method to ensure security is to automate as much as possible. There are a number of tools, such as kube-bench (<a href="https://github.com/aquasecurity/kube-bench">https://github.com/aquasecurity/kube-bench</a>), most of which are based on static configuration analysis, allow you to evaluate configuration parameters at various levels, and provide recommendations on how to change them.</p>
<p>To recap, security controls <a id="_idIndexMarker1209"/>that safeguard containers<a id="_idIndexMarker1210"/> and the underlying infrastructure should be implemented and maintained as part of container security. Integrating security into the development pipeline can ensure that all components are protected from the beginning of their development phase to the end of their life cycle.</p>
<h1 id="_idParaDest-240"><a id="_idTextAnchor242"/>Summary</h1>
<p>We looked at how to use Kata Containers to build a secure container runtime and how to employ hardware virtualization technology to improve workload isolation. We have also looked at how to enable the Kata add-on and run a sample application.</p>
<p>We discussed best practices for establishing container security on your production-grade cluster. We also noticed how the MicroK8s add-on option has made it simpler to activate Kata Containers, which can dramatically improve the security and isolation of your container operations.</p>
<p>With Kata Containers maturing into a production-ready container runtime and subsequent uptake, there is a great opportunity to improve the hosted build and development environment approach to address the noisy neighbor problem and handle unique and privileged requirements without affecting current host settings or policies.</p>
<p>In the following chapter, we will continue our next use case of implementing strict confinement for isolated containers. </p>
</div>
<div>
<div id="_idContainer387">
</div>
</div>
</div>
</body></html>