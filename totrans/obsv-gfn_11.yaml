- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Architecting an Observability Platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter covers several topics related to **architecting** a great observability
    platform for teams in an organization to use. We will discuss how to structure
    data into **domains** to help find relevant data quickly in even the largest organizations,
    and how that relates to other aspects of the business, such as financial reporting
    and **business intelligence** (**BI**). Then, we will discuss architecting the
    four main system components of an observability platform: **data production**,
    **data collection**, **data storage**, and data uses such as **visualization**
    and **alerting**. We will cover how to link the architecture with the IaC tools
    that were discussed in [*Chapter 10*](B18277_10.xhtml#_idTextAnchor204). After
    that, we will discuss how to use various easily available tools to validate a
    design with local testing. These tools can also be used in CI/CD pipelines to
    validate the platform after a change has been implemented. We will discuss the
    **role-based access controls** (**RBACs**) that are implemented in Grafana and
    how to set them up to provide least-privilege access. Finally, we will briefly
    discuss how to architect connections with other systems that make use of the same
    telemetry, such as **security information and event management** (**SIEM**) or
    BI systems. This chapter is aimed at a senior technical audience who has experience
    in architecting platforms and systems.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Architecting your observability platform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Proving theoretical designs (proof of concept)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting the right access levels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sending telemetry to other consumers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Architecting your observability platform
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding and articulating the problem(s) your organization is trying to
    solve is the most critical and undervalued aspect of a well-architected observability
    platform. There are some common problems that organizations are trying to solve
    with observability, but every organization is different, and working with people
    such as *Masha* (senior leadership, as introduced in [*Chapter 1*](B18277_01.xhtml#_idTextAnchor018))
    to understand the business needs is a step that is often missed and can lead to
    complex problems in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some common problems that organizations face that can be solved with
    an observability platform:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Customer-affecting incidents**: These types of incidents could range from
    downtime to data breaches. These pose a compliance, operational, and reputational
    risk to the organization. The customers could be internal or external to the organization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understanding the organization’s key performance indicators (KPIs)**: Organizations
    often want to have a clear understanding of the current state of their KPIs. These
    KPIs articulate whether the organization is doing well or whether something needs
    addressing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understanding how customers use products**: Understanding how customers interact
    with an organization’s products can identify pain points and help guide a better
    experience. Offering great products gives the organization a competitive advantage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Understanding the financial costs of serving customers**: This is commonly
    known as the **cost of goods sold** (**COGS**) and **operating** **expenses**
    (**OPEX**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we will consider how to architect the data structures used
    in an observability platform to support the organization’s goals. We’ll talk about
    the process of designing a system architecture and the considerations you should
    make to support the operational needs of the organization. Finally, we will think
    about designing management and automation processes so that following the best
    practices you establish becomes the easiest path for teams to take.
  prefs: []
  type: TYPE_NORMAL
- en: Defining a data architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A data architecture defines an organization’s data assets and maps how data
    flows through the organization’s systems. Most organizations will already have
    a data architecture in place, so it is worth discussing with the team responsible.
    In this section, we will discuss how the field names and data types in the observability
    platform need to match or be translatable into common fields across the organization.
  prefs: []
  type: TYPE_NORMAL
- en: Observability systems are inherently data systems. They collect, process, move,
    store, and use data. The data in an observability system is most valuable to the
    wider organization when it is compatible with other data systems so the organization
    can merge datasets. The crux of this is that when embarking on this journey, talk
    to people throughout the organization and find out who is responsible for the
    data architecture of the whole organization. If no one exists in that position,
    it can be raised with senior leadership as a hindrance to solving the problems
    they are trying to address. For example, when I was a junior engineer, I remember
    having many meetings discussing whether `tenantID` and `customerID` were different
    fields or not as there were two systems that used different names. Ultimately,
    it was decided they were different concepts so the business could capture the
    idea of principal and subsidiary organizations that were customers of the company.
    However, both systems then needed months of work to implement this wider concept.
    The logging platform also needed a lot of data model rebuilding to capture this
    new concept. This work would have been entirely avoidable by having someone responsible
    for the data model and defining the requirements early on.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is common to use data models from other areas of the organization when implementing
    an observability platform. There is a step that should be completed by an architect
    where they translate external requirements into a requirements document detailing
    where fields should be recorded. For example, it may be a requirement of the financial
    data model to record cost centers. There are many ways to achieve this, such as
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Requiring every log line, every metric, and every trace to include this information
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requiring every service to be tagged with an `organization.costcenter` label
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maintaining a lookup table of service name ↔ cost center
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The requirements guide should be clear on how this will be achieved for teams
    who will be meeting the requirements. We recommend a document structure such as
    **MoSCoW**, which stands for **Must have, Should have, Could have,** **Won’t have**.
  prefs: []
  type: TYPE_NORMAL
- en: 'Different telemetry types are best suited for different data types. Observability
    systems are also packed with features to gather data from other systems, such
    as Kubernetes object labels and cloud tags. These should form part of the data
    architecture. Here are some telemetry types and what they are best suited for:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Log fields in Loki**: Log fields are best suited to string data such as the
    following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application state fields in string format, such as *error* or *warn* states,
    for example, if an application queries data from another service and cannot connect
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Organizational or business data fields, such as service name, customer ID, user
    ID, and so on
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Low- to medium-cardinality indexed fields
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: High-cardinality unindexed fields
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Link from application state to system state in traces
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metric fields in Prometheus or Mimir**: Metric fields are best suited to
    numeric data such as the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Application state fields in numeric format, such as the count of records processed
    since startup
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Organizational or business data fields, including labels containing the service
    name, hostname, and so on
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Low- to medium-cardinality fields, such as HTTP methods (GET, POST, PUT, etc.)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Trace fields in Tempo**: Trace fields are a complex data type that can handle
    data such as the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: System state fields
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: High-cardinality fields
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Organizational or business data fields when added as an attribute, such as customer
    ID and user ID
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Cross-system fields
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Links to application state by using trace metrics
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kubernetes labels**: These are Kubernetes key-value pair data objects. They
    are used to record information such as the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Core organization fields, such as ownership and cost allocation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Linking the application to the infrastructure
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: These labels can be added to log, metric, and trace data as it is collected
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud vendor tags**: These are tags applied to infrastructure in a cloud
    vendor system. They can be used to record information such as the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Core organization fields, such as ownership and cost allocation
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: These labels can be added to log, metric, and trace data as it is collected
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A lot of this data is standard across many organizations and industries, and
    the libraries that produce the data are well tested. There is one area of data
    production that is not tested by these tools though, and that is organization-specific
    fields. These are always organization-specific, but some common examples are user
    ID or customer ID. These fields, when used by the organization, can be very important,
    even being reviewed regularly by executive leaders. It is important that these
    are tested as bad data can lead to bad decisions. Any data architecture documents
    should highlight this need. There is a lot of technical detail in achieving this
    goal, which we will not go into in this book, but we would recommend this article
    from Martin Fowler, which gives clear instructions on producing organizational
    data in a testable way: [https://martinfowler.com/articles/domain-oriented-observability.html](https://martinfowler.com/articles/domain-oriented-observability.html).'
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now seen how to work within the organization to have a coherent data architecture
    that works with the infrastructure layer, the application layer, the observability
    layer, and the business layer. Let’s now consider how to have a great system architecture
    for your organization’s observability platform.
  prefs: []
  type: TYPE_NORMAL
- en: Establishing system architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will consider the aspects of building a great observability
    system. We will see how to help software engineers with producing data. Then,
    we will consider how to collect that data, while providing engineers with a stable
    API. Finally, we’ll discuss the storage and visualization of the data. The following
    list presents some questions to consider relating to these topics:'
  prefs: []
  type: TYPE_NORMAL
- en: How will data be produced?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What telemetry types (logs, metrics, traces, or others) are used?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Will developers such as *Diego* be given standards for libraries?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Should *system* or *state* data be separated from *business* data?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: How will data be collected?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What systems do you need to collect data from?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If a tool is changed, will every application need to be updated?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: How much data will be collected?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: How will data be stored?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will any local storage be provided? If so, how will the scale and cost of this
    be managed?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Is the storage managed per cluster or environment, or as a centralized system?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Will a third-party solution such as Grafana Cloud be used? If so, how is the
    cost allocated?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: How will visualizations be managed?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will the system be fully open, so anyone can submit changes for any dashboard?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Will each team be responsible for their dashboards?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Will IaC tools be provided to help teams manage their dashboards?
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An additional question to consider for all of these is how the system employed
    handles failure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s cover these considerations in more detail, starting with architecting
    how applications produce data.
  prefs: []
  type: TYPE_NORMAL
- en: Data production
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Data production details how applications and services produce data. Teams responsible
    for observability platforms should assist the teams who produce data in doing
    so with all the correct fields, practices, and standards. Common topics to cover
    are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Which telemetry types must be produced and which should or may be produced?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is organizational or business data being collected from the observability systems?
    If it is, what are the fields? Is a data domain used (e.g., `acme.cost_center`
    or `acme.department`)?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Are developers expected to use libraries from a pre-approved list?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What standards are used by applications to present data?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'OpenTelemetry, while relatively young, is emerging as the standard in observability,
    with adoption across most vendors and systems. A suggested best practice for an
    application is to add instrumentation using the relevant OpenTelemetry SDK, as
    shown in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Proposed application data production standard](img/B18277_11_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 – Proposed application data production standard
  prefs: []
  type: TYPE_NORMAL
- en: Here, logs are produced on `stdout` and `stderr`. Metrics are published both
    to a Prometheus scrape endpoint and to an OpenTelemetry receiver via either gRPC
    on port `4317` or HTTP on port `4318`. Traces are also pushed to the OpenTelemetry
    receiver using the same ports.
  prefs: []
  type: TYPE_NORMAL
- en: Producing data is only part of the picture for a well-architected system. Next,
    let’s look at how to design a system to collect all this data so it is useful
    to the organization.
  prefs: []
  type: TYPE_NORMAL
- en: Data collection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The data collection agents we have discussed in previous chapters can collect
    data in many formats. Managing infrastructure that collects data in every format
    is a cumbersome challenge and prone to failure and errors. The system architecture
    needs to detail which protocols are preferred and which can be accepted. For mature
    organizations, start with which protocols are currently in use and set end-of-life
    dates for any protocols the organization wishes to remove. It is strongly recommended
    to stick with default ports where they exist, and where applicable in the environment.
  prefs: []
  type: TYPE_NORMAL
- en: Another consideration is whether data will be stored locally, remotely, or both.
    Local storage adds management overhead and cost but may be a requirement in some
    environments. Having remote storage reduces management costs, but it can remove
    the option of using the metrics from an application to make environment choices.
    An example of this would be the Prometheus **HorizontalPodAutoscaler** (**HPA**).
    We’ll discuss this in a little bit more detail in the *Management and automation*
    section. The authors have used short-lived, volatile local storage for such considerations
    in the past, while using a remote, third-party-provided infrastructure for long-lived
    storage, and such a setup works well.
  prefs: []
  type: TYPE_NORMAL
- en: OpenTelemetry offers several configurations. The following reference architectures
    are designed to give a starting point for readers who need to architect a system.
  prefs: []
  type: TYPE_NORMAL
- en: 'For instance, the simplest way to architect data collection is for each application
    to send data *directly* to the backends, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – Agentless configuration](img/B18277_11_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.2 – Agentless configuration
  prefs: []
  type: TYPE_NORMAL
- en: For demonstrations or small installations, this architecture is perfectly fine.
    However, each application needs to be aware of each backend service, which means
    that this installation type does not scale very well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding a **local agent** to the application adds a small amount of complexity
    but removes a lot of overhead for the team managing the application itself. Such
    an installation looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.3 – Local agent only](img/B18277_11_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.3 – Local agent only
  prefs: []
  type: TYPE_NORMAL
- en: Running a local agent is a very common pattern, and this pattern is great for
    many environments. As the number of instances of the agent grows, the agent configuration
    should be deployed using some form of configuration-as-code setup, such as Ansible,
    Salt, or Helm in a Kubernetes environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Adding a **gateway service** is another common architecture. This type of installation
    looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.4 – Gateway agent only](img/B18277_11_4.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.4 – Gateway agent only
  prefs: []
  type: TYPE_NORMAL
- en: '**Gateway architectures** are perfect in a couple of situations:'
  prefs: []
  type: TYPE_NORMAL
- en: When the number of local instances is high, it can cause strain on the backend
    system by having a lot of open connections. Tthe gateway architecture resolves
    this by spreading this load over multiple instances of the agent.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gateway architectures are very good for installations where the collection of
    data from SNMP or similar systems is a goal.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is best practice to put some form of load balancer in front of gateway architectures,
    and where possible to implement autoscaling.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes introduces its own challenges to data collection architecture; this
    next diagram tries to capture the most common tools needed to collect data across
    the cluster and node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.5 – A more complex Kubernetes architecture](img/B18277_11_5.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.5 – A more complex Kubernetes architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'A simple way to think of this configuration is to break it up into three parts:'
  prefs: []
  type: TYPE_NORMAL
- en: There is a **local agent** configuration on each node. This is configured to
    receive OTLP metrics on gRPC or HTTP. The local agent is also configured to query
    the kubelet for stats related to the Kubernetes node. It also has a host receiver
    configured to collect metrics; this would only be needed in a physical installation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **gateway agent** is also configured. This collects data from each node and
    from the cluster agent. Using a gateway agent here also allows for processing
    to be done in the gateway.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The final component is the **cluster agent**. This is a standalone instance
    of the agent configured to collect data from the Kubernetes API service. If this
    task were delegated to all node or gateway agents, the data would be collected
    by each instance, duplicating the data in the backend. By using a standalone instance,
    we get a single data stream, and this instance can leverage the gateway in the
    same way that the node agent can.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many more configurations that could be used, and we have not discussed
    the topic of using multiple different agents. However, this should give us a foundation
    to work from.
  prefs: []
  type: TYPE_NORMAL
- en: We have now looked at producing and collecting data. These systems will be similar
    for all organizations. Let’s have a look at architecting data storage systems
    next.
  prefs: []
  type: TYPE_NORMAL
- en: Data storage and data visualization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There is one key question to ask regarding data storage or visualization layers
    for observability platforms. Who is responsible? With Grafana tools, it is easily
    achievable to deploy a local storage solution. By doing this, the responsibility
    for maintaining that platform is with an internal team. The alternative is to
    use a third party with whom your organization has a contractual relationship.
    This relationship is a very helpful thing to have when something goes wrong.
  prefs: []
  type: TYPE_NORMAL
- en: We considered the architectures for Loki, Mimir, and Tempo in *Chapters 4*,
    *5*, and *6*, so we will not show the specific architectures of each tool. Let’s
    consider how to deploy these tools if you have reason to manage your own storage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Grafana Mimir, Loki, and Tempo offer multiple deployment modes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Monolithic mode**: In monolithic mode, all of the microservices are deployed
    as a single instance and connected to an object store. Monolithic mode can be
    horizontally scaled by deploying more instances. This scaling method can provide
    a highly available platform with lower complexity but has the drawback of not
    allowing for independent scaling of read and write paths. This deployment mode
    is also not recommended for production environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Microservices mode**: This mode deploys and scales each component of the
    system independently. This adds complexity but also allows the system to cater
    to the actual load that is placed on it. This mode is the recommended deployment
    mode for production use of Mimir and Tempo.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simple scalable mode (only available in Loki)**: This mode strikes a balance
    between monolithic and microservices mode by allowing the independent deployment
    and scaling of write targets, read targets, and backend targets. These targets
    contain all the services needed for their role. This mode is the recommended deployment
    mode for the production use of Loki.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For all three of the storage platforms, deployment is carried out using a Helm
    chart for Kubernetes deployments. Packages are also supplied for deployments to
    Linux operating systems. These deployments can be automated using the provided
    Puppet or Tanka packages.
  prefs: []
  type: TYPE_NORMAL
- en: When you wish to manage your own data visualization layer, the Grafana application
    needs to be installed. This is available as a package for Linux, macOS, or Windows
    operating systems. Grafana also provides Docker images and detailed guidance on
    deploying to Kubernetes using Helm.
  prefs: []
  type: TYPE_NORMAL
- en: Handling system failure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A big consideration for a data collection architecture is how it handles failure.
    For agent failure, the only real option is to restart the agent. However, when
    the collection pipeline fails, this can be handled by buffering in memory or on
    disk. Each collector in the system is capable of buffering by configuring the
    batch processor for memory and the file storage extension for disk storage. The
    main thing to consider when designing a buffering solution is how long the system
    will need to tolerate failure. This, along with the throughput of data, dictates
    how much memory or disk space must be available to the instances. Reporting this
    calculation as a **service-level indicator** (**SLI**) for the data collection
    layer is a good practice, as it makes the resilience of the system publicly available.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now looked at how to architect the data that an observability system will
    collect, and we’ve looked at how to architect a system to collect that data. Let’s
    now consider how to architect the system to account for management tools and automation
    tools.
  prefs: []
  type: TYPE_NORMAL
- en: Management and automation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We discussed using IaC in [*Chapter 10*](B18277_10.xhtml#_idTextAnchor204);
    when designing the system architecture, the use of IaC should manage the four
    systems (production, collection, storage, and visualization) as separate concerns:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data** **production system**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This should be managed by each application independently
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Guidance should be provided
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data** **collection system**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is usually managed by an infrastructure, platform, observability, or similar
    team
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This should have published SLIs and SLOs like any other component
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data** **storage system**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is usually managed by an infrastructure, platform, observability, or similar
    team
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: It is common to use a third-party tool (such as Grafana Cloud)
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Grafana Cloud stacks are a great tool for separating storage where necessary,
    for example, for CI/CD platforms or performance testing
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data** **visualization system**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The system itself would usually be managed by an infrastructure, platform, observability,
    or similar team
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The dashboards and other artifacts related to an application should be managed
    by each application team independently
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: IaC can be provided to teams to manage deployment
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Architecting for automation does not stop with the observability platform. Applications
    deployed to Kubernetes should be able to scale automatically as needed. When suggesting
    an ideal application pattern in the *Data production* section, keen-eyed readers
    may have seen that we recommended publishing metrics via a Prometheus endpoint
    as well as via OTLP export. This recommendation was made for autoscaling. While
    this book is concerned with observability in Grafana, a truly observable system
    can self-correct, such as the steam engine governor shown in [*Chapter 1*](B18277_01.xhtml#_idTextAnchor018).
    The Kubernetes HPA allows for the scaling of Pods based on CPU and memory usage.
    This is fine for some cases, but it is common for application teams to want to
    scale on metrics such as the rate of requests or number of sessions. The Prometheus
    community provides an adapter for Kubernetes Metrics APIs, which allows for querying
    a Prometheus endpoint to enable these types of scaling operations. An important
    question for an organization’s architecture is whether this type of instrumentation
    would be managed by a central team or by each application team, perhaps with a
    default configuration offered for teams to consume.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve looked at how to create an architectural design. There are a lot of tools
    available to test those designs in practice to prove they work. Let’s have a look
    at proving the architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Developing a proof of concept
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The best place to prove a theoretical design is in an environment that has customers
    actually interacting with it, that is, a **production environment**. This is because
    any other environment is a mock environment and may miss some nuance of customer
    interactions. This is a recommendation to get the pathway to production created
    early and use it regularly. Having made that recommendation, it is still very
    important to have spaces for testing designs.
  prefs: []
  type: TYPE_NORMAL
- en: We will discuss compute containerization and virtualization tools, as well as
    simulated data production tools, which can be used to validate designs quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Containerization and virtualization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using containerization and virtualization locally and as part of a deployment
    pipeline can be a huge boost to provide quick feedback on whether a collection
    or storage architecture is achievable. Let’s consider some of the tools that will
    help in this space:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Containerization**: The tools **k3d**, **KinD**, **MicroK8s**, and **minikube**
    can be used for containerization for the following reasons:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These four tools all offer the ability to run a Kubernetes cluster locally
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: KinD, k3d, and minikube can run using Docker or Podman drivers
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: minikube also offers a VM driver, which can be useful for certain local installations
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For data collection architecture and pipelines, the authors have used KinD to
    deliver very good results
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Virtualization**: **Vagrant** can be used with several virtualization tools,
    including **Hyper-V**, **VMware**, **VirtualBox**, **Xen**, **QEMU**, and **libvirt**.
    This is for the following reasons:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vagrant offers the ability to define virtual machines and virtual networking
    and deploy these definitions on different virtualization tools using providers
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: This is a valuable feature for providing a reference virtual infrastructure
    for experimenting and use in a pipeline
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: These tools provide the capability to build reference infrastructure on which
    to deploy data collectors. They also provide the ability to document architectural
    requirements and diagrams using a real setup that is deployed locally.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying infrastructure and data collectors is one part of the process of proving
    a design. Having tools to produce test data is also vital to check that the design
    is right. Let’s have a look at these tools now.
  prefs: []
  type: TYPE_NORMAL
- en: Data production tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are a couple of ways of testing data production – using a sample application
    (such as the OpenTelemetry Demo application) or replaying pre-recorded datasets:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Demo applications**: These applications can be used to generate real observability
    data to test observability systems. Take the following examples:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenTelemetry Demo application**: This is a full retail application that
    we have used to provide demo data throughout this book.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**One Observability Workshop applications**: These applications are provided
    by AWS and demo how to push data into AWS observability tools.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**mythical-creatures application**: This is an application written by Heds
    Simons for an interview with Grafana (he got the job). This application outputs
    metrics, logs, and traces. It’s a simpler application than the OTEL demo, which
    can be an advantage.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pre-recorded datasets**: These applications can be used to produce a predefined
    set of data to test observability systems. The process of replaying pre-recorded
    datasets crosses over very strongly with load-testing and packet capture tools.
    Tools such as **k6**, **Locust**, **Postman**, **Insomnia**, and **GHZ** can be
    used to send predefined data blobs to the data collection endpoints of your collection
    tools and validate the output. As observability tools use specific protocols,
    it’s important to look for features that match the organization’s production of
    data. Some examples are the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to send gRPC data as this is a common format for OpenTelemetry
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The ability to send other protocols such as SNMP if they are used
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools such as **Fiddler** and **Wireshark**, as well as other network analyzers
    or HTTP(S) debuggers, can be used to record wire data to build up a library of
    reference data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: We will discuss in greater detail, in [*Chapter 14*](B18277_14.xhtml#_idTextAnchor254),
    how these tools can be integrated into CI/CD pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now seen how to architect the different components of an observability
    platform and how to validate those designs. Another important architectural consideration
    is getting the access levels correct. Let’s look at that now.
  prefs: []
  type: TYPE_NORMAL
- en: Setting the right access levels
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have talked about the data in observability systems and how to architect
    the actual systems for producing, collecting, storing, and visualizing the data.
    A significant element of the architecture of the system that we have not discussed
    is RBAC.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two places where RBAC can be applied:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Grafana Cloud**: Administration of the deployed Grafana stacks and billing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Grafana instances**: Access to data and visualizations. These instances can
    be deployed to Grafana Cloud or on-premises.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s start by looking at the permissions currently available in Grafana Cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Permission/Role** | **Admin** | **Editor** | **Viewer** |'
  prefs: []
  type: TYPE_TB
- en: '| View API keys | ✓ | × | × |'
  prefs: []
  type: TYPE_TB
- en: '| Manage API keys | ✓ | × | × |'
  prefs: []
  type: TYPE_TB
- en: '| View organization billing information | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Manage organization billing information | ✓ | × | × |'
  prefs: []
  type: TYPE_TB
- en: '| Manage Grafana Cloud subscription | ✓ | × | × |'
  prefs: []
  type: TYPE_TB
- en: '| View Grafana instance plugins | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Manage Grafana instance plugins | ✓ | × | × |'
  prefs: []
  type: TYPE_TB
- en: '| View stacks | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Manage stacks | ✓ | ✓ | × |'
  prefs: []
  type: TYPE_TB
- en: '| Manage organization members | ✓ | × | × |'
  prefs: []
  type: TYPE_TB
- en: '| View invoices | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Pay invoices | ✓ | × | × |'
  prefs: []
  type: TYPE_TB
- en: '| View Enterprise licenses | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| View OAuth clients | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Manage OAuth clients | ✓ | × | × |'
  prefs: []
  type: TYPE_TB
- en: '| View support tickets | ✓ | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Open support tickets | ✓ | ✓ | × |'
  prefs: []
  type: TYPE_TB
- en: Table 11.1 – Grafana Cloud RBAC
  prefs: []
  type: TYPE_NORMAL
- en: 'These Grafana Cloud roles are focused on managing a Grafana Cloud instance.
    For most users, using and editing items in one or more Grafana instances is more
    applicable to their daily work. Grafana offers a rich permission set that breaks
    down into the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Basic roles**: The basic roles have very broad privileges. This is great
    for small organizations and having easy access to new installations. Assigning
    a basic role with least privilege to users is good practice. The basic roles are
    a default set of fixed role definitions, which we’ll discuss in the next point.
    Basic roles include the following:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Admin**: An admin for a Grafana organization.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Editor**: A user who has access to edit objects in the organization.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Viewer**: A user who has access to view objects.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**None**: A role that has minimal privileges for use with service accounts'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Grafana Admin**: A special admin account for all the Grafana organizations
    in an on-premises instance. As we have mainly discussed Grafana Cloud, let’s clarify
    what a Grafana organization is:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Organizations are a method to separate Grafana resources in a single instance.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In Grafana Cloud, organizations are not available to use. Stacks are a better
    way to separate parts of the organization as a dedicated Grafana instance will
    be used in each stack.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fixed role definitions**: Fixed roles can be used to expand the privileges
    assigned via basic roles. Fixed roles contain specific permission assignments
    that can be added to a subject.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Custom roles**: Custom roles allow for the creation of roles that have specific
    permissions, actions, and scopes assigned to them. Custom roles can only be created
    via the API, but Terraform can be used to manage these with IaC.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Permissions can also be assigned at the data source, team, dashboard, and folder
    levels. This can allow for structures such as giving management capabilities to
    all dashboards in a folder assigned to a specific team, but not granting management
    to other team folders. All the permission structures can also be managed using
    IaC, which we discussed in [*Chapter 10*](B18277_10.xhtml#_idTextAnchor204). Grafana
    provides a helpful guide on planning an RBAC rollout strategy here: [https://grafana.com/docs/grafana/latest/administration/roles-and-permissions/access-control/plan-rbac-rollout-strategy/](https://grafana.com/docs/grafana/latest/administration/roles-and-permissions/access-control/plan-rbac-rollout-strategy/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s consider how we might configure roles for some of the personas we have
    – *Diego Developer*, *Steven Service*, and *Pelé Product*:'
  prefs: []
  type: TYPE_NORMAL
- en: As a member of a team responsible for a service, *Diego* will need to be able
    to read dashboards to understand how other services may be behaving. He will also
    need to have write access for dashboards and alerts, but is limited to the folder
    that contains the application he is responsible for.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Steven* needs to be able to view dashboards but not edit them. However, he
    does need to be able to view and manage on-call schedules and silence alerts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Pelé* has a couple of distinct needs. For most day-to-day processes, he needs
    to be able to view dashboards, incident history, and query data about the applications
    he is the product owner for. However, he also needs a service account to run specific
    queries for business metrics and load the data into the BI platform that is used
    with *Masha Manager* to analyze whether the teams need any help with delivering
    great products. He worked on setting up this service account with limited permission
    with *Ophelia*, the admin of the Grafana system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For most users, once a role is created, it is simply a case of assigning the
    role to the individual user. Special consideration should be made for service
    accounts. Some service accounts, such as those used by the team managing the provisioning
    of Grafana tools, will need significant access and should be thoroughly audited.
    Other accounts, such as those used by an individual application team to manage
    dashboards, should have limited permissions. With this second type of account,
    it is a good idea to grant limited privileges for managing the service account
    to a senior member of the team as this enables the team to work independently.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand RBAC in Grafana, let’s have a look at how data collected
    for Grafana can be used in other systems.
  prefs: []
  type: TYPE_NORMAL
- en: Sending telemetry to other consumers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'It is common for the data collected by observability systems to be of use in
    other systems. Logs are often used in SIEM systems and aggregate metrics are of
    interest in BI systems. There are two different strategies that can be used to
    share telemetry with other consumers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Sharing data in the collection pipeline**: Sharing data in the collection
    pipeline is dependent on the data collection pipeline being used. We’ve talked
    a lot about the OpenTelemetry collector, which offers the ability to filter and
    send data to multiple backend systems. Similarly, AWS, GCP, and Azure offer options
    for writing telemetry to multiple backend systems. A consideration is that this
    type of solution will increase costs by storing multiple copies of the same data.
    Spending time with other consumers to understand their needs to minimize this
    cost is advised.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Querying data from Grafana directly**: Querying data from Grafana is done
    using a scheduled job that runs queries directly against Grafana. These are often
    custom connectors that will read data and write it into a BI platform. Grafana
    offers the recording rule functionality, which can assist in this data collection
    process. This functionality allows for the pre-computation of queries, which can
    be stored as a separate time series. For example, if the business were interested
    in the number of unique users who logged in daily, a recording rule could query
    this and store the data as a new metric. When the BI platform then collects this
    data, it would not need to wait for a potentially slow query to complete and instead
    would have the data easily available.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should now be confident in architecting a comprehensive observability platform
    that meets the needs of the organization and can feed valuable information into
    other systems across the organization.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we have explored the process of architecting the data fields
    that will be collected. You will be able to use this knowledge to structure data
    in a Grafana platform so it is easy to use across your organization. We have discussed
    the process of architecting data production by applications and offering standard
    guidance on the best application structure to use. This will account for most
    needs of the developers in the organization. We shared several levels of complexity
    for the data collection architecture. You can use these as a starting point for
    architecting your own system. We discussed the various tools that are available
    to validate an architectural design: both tools for running local infrastructure
    and tools to simulate data that is being collected. This will help in producing
    a pipeline for delivering the infrastructure for an observability platform that
    you can rely on. Finally, we briefly discussed how to share data with other consumers,
    either in the data collection pipeline or by querying Grafana directly. You can
    use this knowledge to link observability data back to the rest of the organization.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore the use of **real user monitoring** (**RUM**)
    to collect data directly from the browser. This provides visibility of how your
    code runs when users are active in the system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 4: Advanced Applications and Best Practices of Grafana'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are a number of topics related to observability, including frontend observability,
    application performance, load testing, DevOps pipelines, and monitoring security
    applications. This part will discuss these topics and additionally look at possible
    future trends. We will close out with some best practices and troubleshooting
    approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part has the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 12*](B18277_12.xhtml#_idTextAnchor231)*, Real User Monitoring with
    Grafana*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 13*](B18277_13.xhtml#_idTextAnchor239)*, Application Performance
    with Grafana Pyroscope and k6*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 14*](B18277_14.xhtml#_idTextAnchor254)*, Supporting DevOps Processes
    with Observability*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 15*](B18277_15.xhtml#_idTextAnchor272)*, Troubleshooting, Implementing
    Best Practices, and More with Grafana*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
