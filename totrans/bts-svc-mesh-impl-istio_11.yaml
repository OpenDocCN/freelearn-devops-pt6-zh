- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Troubleshooting and Operating Istio
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying microservices involves many moving parts, including the application,
    the underlying Kubernetes platform, and the application network provided by Istio.
    It is not uncommon for the mesh to be operating in an unintended way. Istio, in
    its early days, was infamous for being complex and too difficult to troubleshoot.
    The istio community took that perception very seriously and has been working toward
    simplifying its installation and day-2 operations to make it easier and more reliable
    to use in production-scale deployments.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will read about the common problems you will encounter when
    operating istio and how to distinguish and isolate them from other issues. We
    will then learn how to **troubleshoot** these problems once they are identified.
    We will also explore various **best practices** for deploying and operating istio
    and how to automate the enforcement of best practices.
  prefs: []
  type: TYPE_NORMAL
- en: 'In a nutshell, this chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding interactions between istio components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inspecting and analyzing the istio configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting errors using access logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting errors using debug logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Debugging istio agents
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding istio’s best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automating best practices using OPA Gatekeeper
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding interactions between Istio components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When troubleshooting problems with the Service Mesh, the unexpected behavior
    of the mesh is likely caused by one of the following underlying issues:'
  prefs: []
  type: TYPE_NORMAL
- en: Invalid control plane configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Invalid data plane configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unexpected data plane
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the upcoming sections, we will explore how to diagnose the underlying reason
    for any such unexpected behavior with the help of various diagnostic tools provided
    by istio. But first, let’s look at various interactions that happen inside the
    mesh between istiod, data planes, and other components.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Istiod ports
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Istiod exposes various ports, some of which can be used for troubleshooting.
    In this section, we will go through those ports, and understand what they do and
    how they can help with troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s get started by looking at those ports:'
  prefs: []
  type: TYPE_NORMAL
- en: '`443` but is forwarded to port `15017`, which we saw in action when setting
    up primary remote clusters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port 15014**: This port is used by Prometheus to scrape control plane metrics.
    You can check the metric using the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, you can fetch the metrics from port `15014`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`15010` is insecure and port `15012` is secure so can be used for production
    environments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`istiod` instance. This port is used to access the ControlZ interface either
    via REST API calls from within the mesh or via a dashboard, which can be accessed
    using the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following is a screenshot of the ControlZ interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Istio ControlZ interface](img/B17989_11_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.1 – Istio ControlZ interface
  prefs: []
  type: TYPE_NORMAL
- en: The ControlZ interface can be used to inspect logging scopes, environment variables,
    and so on. The interface can also be used to change logging levels.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we read about various ports exposed by istiod. Let’s move on
    to read about the ports exposed by the Istio data plane.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring Envoy ports
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Envoy, which is the data plane for Istio, exposes various ports for interaction
    with the Istio control plane and observability tools. Let’s look at those ports,
    what they do, and how they can help with troubleshooting:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Port 15000**: This is the Envoy admin interface, which can be used to inspect
    and query envoy configuration. We will read about this port in detail in the next
    section, *Inspecting and analyzing the* *Istio configuration*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port 15001**: This port is used for receiving all outbound traffic from the
    application Pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port 15004**: This port can be used to debug the data plane configuration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port 15006**: All inbound application traffic from within the mesh is routed
    to this port.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`istio-agent`, and the application, which is then scraped by Prometheus.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port 15021**: This port is exposed for performing health checks of the data
    plane.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port 15053**: This port is used to serve the DNS proxy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Port 15090**: This port provides Envoy telemetry information.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the next section, we will explore how to analyze and inspect the Istio configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Inspecting and analyzing the Istio configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When debugging the Istio data plane, it is useful to check whether there is
    any configuration mismatch between the Istio control plane and the data plane.
    When working with multi-cluster mesh, it is a good idea to first check the connectivity
    between the control plane and data plane; if your Pod supports `curl`, then you
    can use the following command to check the connectivity between the two:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: To inspect the configuration, the first checkpoint can be to use the `istioctl
    proxy-status` command to find the synchronization state of the cluster, listener,
    routes, and endpoints configuration between istiod and istio-proxy.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can use the following command to check the configuration status of the
    whole cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following are the possible values of the synchronization status:'
  prefs: []
  type: TYPE_NORMAL
- en: '`SYNCED`: Envoy has the latest config.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`NOT SENT`: istiod has not sent any config to Envoy; in most cases, the reason
    is that istiod has no config to send. In this example, the status is `NOT SENT`
    for the Istio Egress Gateway because there is no route information to be synced.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`STALE`: Envoy doesn’t have the latest config, which is an indication of a
    networking issue between Envoy and istiod.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can check the status of a workload using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'If the Pod being investigated supports `curl`, then you can perform a dump
    of the `istio-proxy` configuration by fetching config from Envoy’s admin interface
    exposed at port `15000` using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'You can selectively dump the configuration of listeners, clusters, routes,
    and endpoints by using the following `istioctl` `proxy-config` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'You can fetch the Envoy configuration from the istiod perspective and compare
    it with the config fetched from Envoy’s admin interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You can inspect the `istio-proxy` configuration in a Pod from a web browser
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'From the browser, you can now access the Envoy dashboard, as shown in the following
    figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – Envoy dashboard](img/B17989_11_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 11.2 – Envoy dashboard
  prefs: []
  type: TYPE_NORMAL
- en: The Envoy dashboard is a good option to inspect values but proceed with caution
    when changing configuration parameters because, from this dashboard, you will
    be changing data plane configuration outside the purview of istiod.
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing this book, `istioctl describe` is an experimental feature.
    It is used to describe a Pod, and if the Pod meets all the requirements to be
    part of the mesh, this command (when run against a Pod) can also tell whether
    istio-proxy in the Pod has been started or whether the Pod is part of the mesh
    or not. It will emit any warnings and suggestions to enable better integration
    of the Pod into the mesh.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following runs the `istioctl describe` command against the `envoydummy`
    Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In the output, you can see that it is suggesting to apply the `app` label to
    the Pod for Istio telemetry. Istio recommends adding `app` and `version` labels
    explicitly to workloads in the mesh. These labels add contextual information to
    the metrics and telemetry collected by Istio. The output also describes some other
    important pieces of information, such as the service is exposed on port `80` and
    the endpoint is on port `10000`, the `istio-proxy` Pod is exposed at port `15090`,
    and `mTLS mode` is permissive. It also describes and warns about any issues with
    destination rules and virtual services.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command is another example of when an incorrect virtual service
    configuration is applied to `envoydummy`. The correct configuration is available
    at `Chapter11/04-istio-gateway-chaos.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: The warning at the bottom of the preceding snippet clearly describes that the
    virtual service is routing traffic to `UNKNOWN subset v3`. To fix this problem,
    you need to either configure the virtual service to correct the subset defined
    in the destination rule or add a `v3` subset in the destination rules. The correct
    configuration is available at `Chapter11/04-istio-gateway.yaml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another diagnostic tool to inspect and detect any misconfiguration in the mesh
    is `istioctl analyze`. It can be run against the whole cluster as well as against
    any configuration before applying it to the mesh:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: In the preceding example, `istioctl analyze` pointed out the error by analyzing
    the configuration file. This is very handy to validate any erroneous configuration
    before applying it to the mesh. In the following section, we will read about how
    to troubleshoot errors using envoy access logs.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting errors using access logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`istio-proxy` container. Access logs are records of traffic flow to Envoy and
    can be intertwined together with the access of the Ingress and Egress gateway
    along with all other upstream and downstream workloads in the mesh, to follow
    the journey of the request.'
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, access logs are turned off unless you have installed Istio using
    the demo profile. You can check whether access logs are enabled by inspecting
    the Istio config map:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Access logs can be enabled via the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Depending on your needs and system performance requirements, you can decide
    to turn access logging on or off. If it is turned on and you want to disable it,
    you can do so by providing a blank value for the `accessLogFile` parameter:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The access log can also be enabled at the workload or namespace level. Assuming
    you have turned off access logs globally, we can turn them on selectively for
    the `envoydummy` workload using the `Telemetry` resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The configuration will turn on the access logging for the `envoydummy` Pod.
    The configuration is available at `Chapter11/03-telemetry-01.yaml` on GitHub:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply the configuration using the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, you can make a `curl` request to `envoydummy` from the `curl` Pod, as
    shown in the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, if you check the access logs of `istio-proxy` in the `curl` and `envoydummy`
    Pods, you will find that there are no access logs in the `curl` Pod but there
    are access logs in the `envoydummy` Pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The reason for not having any access logs in the `curl` Pod is that we turned
    them off globally but selectively turned them on for the `envoydummy` Pod using
    the `Telemetry` resource.
  prefs: []
  type: TYPE_NORMAL
- en: You can read more about how to configure `accessLogging` using `Telemetry` at
    [https://istio.io/latest/docs/reference/config/telemetry/#AccessLogging](https://istio.io/latest/docs/reference/config/telemetry/#AccessLogging).
  prefs: []
  type: TYPE_NORMAL
- en: 'The default encoding of access logs is a string formatted using the following
    specification:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: A detailed definition of each of these fields is available at [https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage](https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage).
  prefs: []
  type: TYPE_NORMAL
- en: 'Access logs can also be configured to be displayed in JSON format, which can
    be achieved by setting `accessLogEncoding` to `JSON`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Once set, the access log will be displayed in JSON format, which I have simplified
    for ease of reading:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In the access logs, there is a field called `response_flags` (as seen in the
    preceding code snippet), which is a very useful piece of information when troubleshooting
    via access logs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, we will learn about response flags by injecting some errors in the `envoydummy`
    Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first turn on access logs for the `curl` Pod using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Then, delete the `envoydummy` Pod but keep the `envoydummy` service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, the service is broken, and you will not be able to use `curl`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check the access logs for the `curl` Pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The value of `response_flags` is `UH`, which means there is no healthy upstream
    host in the upstream cluster. Possible values of `response_flag` are shown in
    the following table and referenced from [https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage](https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage):'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `UH` | No healthy upstream hosts in the upstream cluster in addition to a
    503 response code |'
  prefs: []
  type: TYPE_TB
- en: '| `UF` | Upstream connection failure in addition to a 503 response code |'
  prefs: []
  type: TYPE_TB
- en: '| `UO` | Upstream overflow (circuit breaking) in addition to a 503 response
    code |'
  prefs: []
  type: TYPE_TB
- en: '| `NR` | No route configured for a given request in addition to a 404 response
    code, or no matching filter chain for a downstream connection |'
  prefs: []
  type: TYPE_TB
- en: '| `URX` | The request was rejected because the upstream retry limit (HTTP)
    or maximum connect attempts (TCP) was reached |'
  prefs: []
  type: TYPE_TB
- en: '| `NC` | Upstream cluster not found |'
  prefs: []
  type: TYPE_TB
- en: '| `DT` | A request or connection exceeded `max_connection_duration` or `max_downstream_connection_duration`
    |'
  prefs: []
  type: TYPE_TB
- en: Table 11.1 – Response flag values for HTTP and TCP connections
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table describes the value of the response flag for HTTP connections:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `DC` | Downstream connection termination |'
  prefs: []
  type: TYPE_TB
- en: '| `LH` | Local service failed health check request in addition to a 503 response
    code |'
  prefs: []
  type: TYPE_TB
- en: '| `UT` | Upstream request timeout in addition to a 504 response code |'
  prefs: []
  type: TYPE_TB
- en: '| `LR` | Connection local reset in addition to a 503 response code |'
  prefs: []
  type: TYPE_TB
- en: '| `UR` | Upstream remote reset in addition to a 503 response code |'
  prefs: []
  type: TYPE_TB
- en: '| `UC` | Upstream connection termination in addition to a 503 response code
    |'
  prefs: []
  type: TYPE_TB
- en: '| `DI` | The request processing was delayed for a period specified via fault
    injection |'
  prefs: []
  type: TYPE_TB
- en: '| `FI` | The request was aborted with a response code specified via fault injection
    |'
  prefs: []
  type: TYPE_TB
- en: '| `RL` | The request was rate-limited locally by the HTTP rate limit filter
    in addition to a 429 response code |'
  prefs: []
  type: TYPE_TB
- en: '| `UAEX` | The request was denied by the external authorization service |'
  prefs: []
  type: TYPE_TB
- en: '| `RLSE` | The request was rejected because there was an error in the rate
    limit service |'
  prefs: []
  type: TYPE_TB
- en: '| `IH` | The request was rejected because it set an invalid value for a strictly-checked
    header, in addition to a 400 response code |'
  prefs: []
  type: TYPE_TB
- en: '| `SI` | Stream idle timeout in addition to a 408 or 504 response code |'
  prefs: []
  type: TYPE_TB
- en: '| `DPE` | The downstream request had an HTTP protocol error |'
  prefs: []
  type: TYPE_TB
- en: '| `UPE` | The upstream response had an HTTP protocol error |'
  prefs: []
  type: TYPE_TB
- en: '| `UMSDR` | The upstream request reached max stream duration |'
  prefs: []
  type: TYPE_TB
- en: '| `OM` | The overload manager terminated the request |'
  prefs: []
  type: TYPE_TB
- en: '| `DF` | The request was terminated due to a DNS resolution failure |'
  prefs: []
  type: TYPE_TB
- en: Table 11.2 – Response flag values for HTTP connections
  prefs: []
  type: TYPE_NORMAL
- en: Response flags are very useful in troubleshooting access logs and good indicators
    of what might have gone wrong with the upstream systems. With that knowledge,
    let’s move our focus to how Istio debug logs can be used for troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting errors using debug logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Istio components support a flexible logging scheme for **debug** logs. The debug
    log levels can be changed from a high level to a very verbose level to get details
    of what’s happening in the Istio control and data planes. The following two sections
    will describe the process for changing the log level for the Istio data and control
    planes. Let’s dive right in!
  prefs: []
  type: TYPE_NORMAL
- en: Changing debug logs for the Istio data plane
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following are various log levels for the Istio data plane – that is, the
    Envoy sidecar:'
  prefs: []
  type: TYPE_NORMAL
- en: '`trace`: Highest verbose log messages'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`debug`: Very verbose log messages'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`info`: Informative messages to know about Envoy’s execution state'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`warning/warn`: Events that indicate problems and may lead to error events'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`error`: Error events that are important and may impair some of Envoy’s capability
    but will not make Envoy completely non-functional'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`critical`: Severe error events that may cause Envoy to stop functioning'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`off`: Produces no logs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The log levels can be changed using the following command format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'An example of such a command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: This way of changing log levels doesn’t require a restart of the Pods. As discussed
    in the *Exploring istiod ports* section earlier in this chapter, the log levels
    can also be changed using the ControlZ interface.
  prefs: []
  type: TYPE_NORMAL
- en: Changing log levels for the Istio control plane
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Istio control plane supports the following log levels:'
  prefs: []
  type: TYPE_NORMAL
- en: '`none`: Produces no logs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`error`: Produces only errors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`warn`: Produces warning messages'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`info`: Produces detailed information for normal conditions'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`debug`: Produces the maximum amount of log messages'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each component inside istiod categorizes the logs based on the type of message
    being logged. These categories are called `ads`, `adsc`, `all`, `analysis`, `authn`,
    `authorization`, `ca`, `cache`, `cli`, `default`, `installer`, `klog`, `mcp`,
    `model`, `patch`, `processing`, `resource`, `source`, `spiffe`, `tpath`, `translator`,
    `util`, `validation`, `validationController`, and `wle`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of a command used to change log levels for various
    scopes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'In this example, we are changing the log levels for the `validation` scope
    to `debug`, the `validationController` scope to `info`, and `ads` to `debug`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'You can use `istioctl admin log` to retrieve the log level for all Istio components:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: We just looked at Envoy, which is on the `request` path of the request, but
    there is another critical component that is not on the `request` path but is important
    for smooth Envoy operations. In the next section, we will read about how to debug
    any issues in istio-agent.
  prefs: []
  type: TYPE_NORMAL
- en: Debugging the Istio agent
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will read how to troubleshoot any issues in the data plane
    caused by the misconfiguration of the Istio agent. An Istio agent may not act
    as expected due to a multitude of reasons; in this section, we will discuss various
    options to debug and troubleshoot such issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command can be used to inspect the initial bootstrap configuration
    file that is used by Envoy to start itself and connect with istiod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The bootstrap configuration is composed of the information provided by the Istiod
    controller during sidecar injection via validation and the sidecar injection webhook.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can check the certificate and `secret` configured for Envoy by `istio-agent`
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: You can also display the detailed information in JSON format by adding `-o json`
    to the command. `ROOTCA` is the root certificate, and `default` is the workload
    certificate. When performing a multi-cluster setup, ROOTCA must match in different
    clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can inspect the certificate values using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: There might be other Secrets also depending on configured gateways and destination
    rules. In the logs, if you find that Envoy is stuck in a warning state, then that
    means that the correct Secret has not been loaded in Envoy. Issues related to
    the `default` certificate and `ROOTCA` are usually caused by connectivity issues
    between istio-proxy and istiod.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check that Envoy has successfully started, you can log into the `istio-proxy`
    container using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: During the bootstrap of the sidecar proxy, `istio-agent` checks the readiness
    of Envoy by pinging `http://localhost:15021/healthz/ready`. It also uses the same
    endpoint for determining the readiness of Envoy during the lifetime of the Pod.
    An HTTP status code of 200 means that Envoy is ready and the `istio-proxy` container
    is marked as initialized. If the `istio-proxy` container is in a pending state
    and not initializing, then that means that Envoy has not received the configuration
    from istiod, which can be either because of connectivity issues with istiod or
    a config rejected by Envoy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Errors such as the following in `istio-proxy` logs denote connectivity issues
    either because of the network or unavailability of istiod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'If Envoy can connect with istiod, then you will find a message similar to the
    following in the log files:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we did a deep dive into Istio debug logs, and we looked at
    how to troubleshoot using the debug logs of Envoy, `istio-agent`, and the Istio
    control plane. In the next section, we will read about Istio’s best practices
    for securely managing and efficiently operating Istio.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Istio’s best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When operating the Service Mesh, it is advised to assume that security threats
    will not just originate from outside of the organization’s security boundaries
    but also from within the security perimeter. You should always assume that networks
    are not impregnable and create security controls that can secure assets, even
    if network boundaries are breached. In this section, we will discuss some of the
    various attack vectors to be mindful of when implementing Service Mesh.
  prefs: []
  type: TYPE_NORMAL
- en: Examining attack vectors for the control plane
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following list shows common strategies for initiating attacks on the control
    plane:'
  prefs: []
  type: TYPE_NORMAL
- en: Causing configuration to deliberately make the control plane malfunction so
    that the Service Mesh becomes inoperable, thus impacting business-critical applications
    being managed by the mesh. This can also be a precursor to forthcoming attacks
    targeting Ingress or any other applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Obtaining privileged access to be able to perform control plane and data plane
    attacks. By gaining privileged access, an attacker can then modify security policies
    to allow the exploitation of the assets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eavesdropping to exfiltrate sensitive data from the control plane, or tampering
    and spoofing communication between data and control planes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examining attack vectors for the data plane
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following are common strategies for initiating attacks on the data plane:'
  prefs: []
  type: TYPE_NORMAL
- en: Eavesdropping on service-to-service communication to exfiltrate sensitive data
    and send it to an attacker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Masquerading as a trusted service in the mesh; the attacker can then perform
    man-in-the-middle attacks between service-to-service communication. By using a
    man-in-the-middle attack, the attacker can steal sensitive data or tamper with
    the communication between the services to produce a favorable outcome for the
    attacker.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manipulating the applications to perform botnet attacks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The other component susceptible to attacks is the infrastructure hosting istio,
    which can be the Kubernetes cluster, virtual machines, or any other components
    of the underlying stack hosting istio. We will not dive into how to protect Kubernetes,
    as there are various books on how to secure Kubernetes clusters; one such book
    is *Learn Kubernetes Security*, written by Kaizhe Huang and Pranjal Jumde and
    published by Packt. Other best practices include protecting the Service Mesh,
    which we will discuss in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Securing the Service Mesh
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Some best practices on how to secure the Service Mesh are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Deploy a **web application firewall** (**WAF**) to protect Ingress traffic.
    WAF implements security controls, including threats identified by **Open Web Application
    Security Project** (**OWASP**); you can read about OWASP at [https://owasp.org/](https://owasp.org/).
    Most cloud providers provide WAF as part of their cloud offering; some examples
    are **AWS WAF** by AWS, **Cloud Armor** by Google Cloud, and **Azure Web Application
    Firewall** from Azure. There are other vendors, such as Cloudflare, Akamai, Imperva,
    and AppTrana, who provide WAF as a SaaS offering, whereas vendors such as Fortinet
    and Citrix also provide self-hosted WAF offerings. WAFs are one of your first
    lines of defense and will take care of many attack vectors bound for Ingress to
    the mesh.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define policies to control access from outside the mesh to services inside the
    mesh. Ingress access control policies are important to prohibit unauthorized access
    to services. Every Ingress should be well-defined and have associated authentication
    and authorization policies to verify whether external requests are authorized
    to access services exposed by the Ingress gateway. Nevertheless, all Ingress should
    happen via Ingress gateways, and every Ingress should be routed via a virtual
    service and the destination rules associated with it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All Egress systems should be known and defined, and traffic to unknown Egress
    points should not be allowed. Security policies should enforce TLS origination
    for Egress traffic and for all Egress to happen via Egress gateways. Authorization
    policies should be used to control what workloads are allowed to send Egress traffic
    and, if allowed, all Egress endpoints should be known and approved by security
    administrators. Egress security policies also help prevent data exfiltration;
    with Egress policies, you can control traffic to known Egresses only and thus
    stop an attacker who has infiltrated your system from sending data to the attacker’s
    systems. This also stops applications within the mesh from participating in any
    botnet attacks.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All services in the mesh should communicate over mTLS and should have associated
    authentication and authorization policies. By default, all service-to-service
    communication should be denied unless authorized via authorization policies, and
    any service-to-service communication should be explicitly enabled via well-defined
    service identities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where a service-to-service communication is happening on behalf of an end user
    or system, all such communication (apart from mTLS) should also make use of JWTs.
    A JWT acts as a credential to prove that a service request is explicitly being
    made on behalf of the end user; the caller service needs to present a JWT as a
    credential identifying an end user, combined with authentication and authorization
    policies that you can enforce after determining what services can be accessed
    and what level of access is granted. This helps to stop any compromised application
    from performing data exfiltration or service exploitation.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If any external long-lived authentication token is used for authenticating any
    subject, be it an end user or a system, then such a token should be replaced by
    a short-lived token. Token replacement should happen at Ingress, and then the
    short-lived token should be used throughout the mesh. Doing so helps prevent attacks
    where an attacker steals tokens and uses them for unauthorized access. Also, whereas
    the long-lived external attack might have many broader scopes attached to it that
    might be misused by a compromised application, having a short-lived token with
    restricted scope helps to avoid misuse of tokens.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When applying exceptions to mesh or security rules, then you should proceed
    with caution when defining exception policies. For example, if you want to enable
    workload A in the mesh to allow HTTP traffic from another workload, B, then instead
    of explicitly allowing all HTTP traffic, you should explicitly define an exception
    to allow HTTP traffic from workload B, whereas all other traffic should be on
    HTTPS only.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to istiod must be restricted and controlled. Firewall rules should restrict
    access to the control plane to known sources. The rule should cater to human operators
    as well the data plane’s access to the control plane in single and multi-cluster
    setups.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All workloads being managed by the Service Mesh should be managed by the Service
    Mesh only via **role-based access control** (**RBAC**) policies for the Kubernetes
    environment and user groups for non-Kubernetes workloads. Kubernetes administrators
    should carefully define RBAC policies for application users and mesh administrators
    and allow only the latter to make any changes to the mesh. Mesh operators should
    be further classified according to the operations they are authorized to perform.
    For example, mesh users with permission to deploy applications in a namespace
    should not have access to other namespaces.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restrict what repositories are accessible to users from where images can be
    pulled for deployment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we read about istio’s best practices; as well as this section,
    you should also read about best practices on the istio website at [https://istio.io/latest/docs/ops/best-practices/](https://istio.io/latest/docs/ops/best-practices/).
    The website is frequently updated based on feedback from the istio community.
  prefs: []
  type: TYPE_NORMAL
- en: Even after all controls, mesh operators may accidentally misconfigure the Service
    Mesh, which can result in unexpected outcomes and even security breaches. One
    option is to enforce a stringent review and governance process for making changes,
    but doing so manually is expensive, time-consuming, error-prone, and often annoying.
    In the following section, we will read about **OPA Gatekeeper** and how to use
    it for the automation of best practices policies.
  prefs: []
  type: TYPE_NORMAL
- en: Automating best practices using OPA Gatekeeper
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To avoid human errors, you can define the best practices and constraints in
    the form of policies that can then be enforced automatically whenever a resource
    is created, deleted, or updated in the cluster. Automated policy enforcement ensures
    consistency and adherence to best practices without compromising agility and deployment
    velocity. One such software is **Open Policy Agent** (**OPA**) Gatekeeper, which
    is an admission controller that enforces policies based on the **custom resource
    definition** (**CRD**), executed by OPA. OPA Gatekeeper enables the enforcement
    of guard rails; any istio configuration not within the guard rails is automatically
    rejected. It also allows **cluster administrators** to audit the resources in
    breach of best practices. Using the following steps, we will set up OPA Gatekeeper,
    followed by the configuration to enforce some of the best practices for istio.
    Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: 'Install Gatekeeper using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Configure Gatekeeper to sync namespaces, Pods, Services, istio CRD gateways,
    virtual services, destination rules, policy, and service role bindings into its
    cache. We have defined that in the following file available at `Chapter11/05-GatekeeperConfig.yaml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, apply the configuration using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This completes the installation of Gatekeeper; next, we will configure constraints.
  prefs: []
  type: TYPE_NORMAL
- en: We will start with a simple policy for ensuring Pod naming conventions as per
    istio best practices. As discussed in the *Inspecting and analyzing istio configuration*
    section, istio recommends adding an explicit `app` and `version` label to every
    Pod deployment. The `app` and `version` labels add contextual information to the
    metrics and telemetry that istio collects.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform the following steps to enforce this governance rule so that any deployment
    not adhering to this rule is automatically rejected:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we must define `ConstraintTemplate`. In the constraint template, we
    do the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Describe the policy that will be used to enforce the constraints
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Describe the schema of the constraint
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Gatekeeper constraints are defined using a purpose-built, high-level declarative
    language called **Rego**. Rego is particularly used for writing OPA policies;
    you can read more about Rego at https://www.openpolicyagent.org/docs/latest/#rego.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps defines the constraint template and the schema:'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will declare a constraint template using the OPA CRD:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will define the schema:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, we will define `rego` to check the labels and detect any violation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'The configuration is available at `Chapter11/gatekeeper/01-istiopodlabelconstraint_template.yaml`.
    Apply the configuration using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will define `constraints` that are used to inform Gatekeeper that
    we want to enforce the constraint template named `istiorequiredlabels`, as per
    the configuration defined in the `mesh-pods-must-have-app-and-version` constraint.
    The sample file is available at `Chapter11/gatekeeper/01-istiopodlabelconstraint.yaml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'For the constraint configuration, we have defined the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '`enforcementAction`: This field defines the action for handling constraint
    violations. The field is set to `deny`, which is also the default behavior; any
    resource creation or update that is in violation of this constraint will be handled
    as per enforcement action. Other supported `enforcementAction` values include
    `dryrun` and `warn`. When rolling out new constraints to running clusters, the
    `dryrun` functionality can be helpful to test them in a running cluster without
    enforcing them. The `warn` enforcement action offers the same benefits as `dryrun`,
    such as testing constraints without enforcing them. In addition to this, it also
    provides immediate feedback on why that constraint would have been denied.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`match`: This field defines the selection criteria for identifying the objects
    to which the constraints will be applied. In the configuration, we have defined
    that the constraints should be applied to `pod` resources that are deployed in
    a namespace with the label of `istio-injection` and a value of `enabled`. By doing
    this, we can selectively apply the constraints to namespaces that are part of
    the mesh data plane.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finally, we have defined the message to be displayed when constraints are violated.
    Apply the following constraints:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'As a test, we will deploy the `envoydummy` Pod with missing labels:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The deployment was verified by Gatekeeper and rejected because it is violating
    constraints by not having `app` and `version` labels. Please fix the labels and
    redeploy to check that you can successfully deploy with the correct labels.
  prefs: []
  type: TYPE_NORMAL
- en: I hope this gave you some idea about how to use Gatekeeper for automating some
    of the best practices. We will practice one more example to give you some further
    confidence on how to use Gatekeeper. At first, it might appear a daunting task
    to define the constraints, but once you build some experience using `rego`, then
    you will find it simple and easy to use.
  prefs: []
  type: TYPE_NORMAL
- en: 'As another example, let’s write another constraint to enforce port naming conventions.
    As per istio best practices described at [https://istio.io/v1.0/docs/setup/kubernetes/spec-requirements/](https://istio.io/v1.0/docs/setup/kubernetes/spec-requirements/),
    `Service` ports must be named. The port names must be of the `<protocol>[-<suffix>]`
    form, with `http`, `http2`, `grpc`, `mongo`, or `redis` as `<protocol>`. This
    is important if you want to take advantage of istio’s routing features. For example,
    `name: http2-envoy` and `name: http` are valid port names, but `name: http2envoy`
    is an invalid name.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The `rego` in the constraint template will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: In the `rego`, we are defining that port names should start with a prefix, and
    if the prefix is missing, then it should be considered a violation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The constraint is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: In the constraint, we are defining the various prefixes that are allowed and
    the corresponding error message to be displayed when the constraints are violated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s apply the constraint template and configuration as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'After applying the config, let’s deploy `envoydummy` with incorrect names for
    the service ports. We will create an `envoydummy` service without specifying any
    port names, as described in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'The file is available at `Chapter11/07-envoy-proxy-chaos.yaml`. Apply the configuration
    using the following code and observe the error message to see OPA Gatekeeper in
    action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'In the response, you can see the error message caused by the incorrect naming
    of the port in the service configuration. The issue can be resolved by adding
    a name to the port declaration as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: OPA Gatekeeper is a powerful tool to automate the enforcement of best practices
    for the Service Mesh. It compensates for any misconfiguration caused by human
    operators and reduces the cost and time required to keep your mesh aligned with
    the best practices guard rails. You can read more about OPA Gatekeeper at [https://open-policy-agent.github.io/gatekeeper/website/docs/](https://open-policy-agent.github.io/gatekeeper/website/docs/),
    and there are also some good examples of Gatekeeper available at [https://github.com/crcsmnky/gatekeeper-istio](https://github.com/crcsmnky/gatekeeper-istio).
  prefs: []
  type: TYPE_NORMAL
- en: Uninstalling OPA Gatekeeper
  prefs: []
  type: TYPE_NORMAL
- en: 'To uninstall OPA Gatekeeper, you may use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '`% kubectl delete -``f` [https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml](https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml)'
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we read about various troubleshooting techniques as well as
    best practices for configuring and operating istio. By now, you should have a
    good understanding of various ports exposed by istio and how they can help diagnose
    any errors in the mesh. You also read about debugs and access logs produced by
    Envoy and istiod and how they can help you pinpoint the root cause of errors.
    istio provides various tools in its diagnostic toolkit that are very helpful for
    troubleshooting and analyzing issues and errors in the Service Mesh.
  prefs: []
  type: TYPE_NORMAL
- en: Security is of utmost importance when running the Service Mesh, which is why
    we discussed various attack vectors for the control and data planes. You should
    now have a good understanding of the list of controls you can put in place to
    secure the Service Mesh. Finally, we read about how to automate best practices
    using OPA Gatekeeper to catch most, if not all, non-compliant configurations.
    You learned how to set up OPA Gatekeeper, how to define constraint templates using
    Rego and constraint schema, and how to use them to catch poor configurations.
    I hope this chapter provides you with the confidence to troubleshoot and operate
    istio and use automation tools such as OPA Gatekeeper to enforce configuration
    hygiene in your istio Service Mesh implementation.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will put the learning from this book into practice by
    deploying an application on the mesh.
  prefs: []
  type: TYPE_NORMAL
