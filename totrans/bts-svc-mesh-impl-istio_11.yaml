- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Troubleshooting and Operating Istio
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 排除故障与操作 Istio
- en: Deploying microservices involves many moving parts, including the application,
    the underlying Kubernetes platform, and the application network provided by Istio.
    It is not uncommon for the mesh to be operating in an unintended way. Istio, in
    its early days, was infamous for being complex and too difficult to troubleshoot.
    The istio community took that perception very seriously and has been working toward
    simplifying its installation and day-2 operations to make it easier and more reliable
    to use in production-scale deployments.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 部署微服务涉及许多活动组件，包括应用程序、底层的 Kubernetes 平台，以及由 Istio 提供的应用程序网络。网格在某些情况下表现异常并不罕见。Istio
    在早期以复杂且难以排查故障而臭名昭著。Istio 社区非常重视这种看法，并一直在致力于简化其安装和 Day-2 操作，使其在生产环境中的部署更加简便和可靠。
- en: In this chapter, we will read about the common problems you will encounter when
    operating istio and how to distinguish and isolate them from other issues. We
    will then learn how to **troubleshoot** these problems once they are identified.
    We will also explore various **best practices** for deploying and operating istio
    and how to automate the enforcement of best practices.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论在操作 Istio 时可能遇到的常见问题，以及如何将它们与其他问题区分开来并加以隔离。然后，我们将学习如何在识别出问题后**排除故障**。我们还将探索部署和操作
    Istio 的各种**最佳实践**，以及如何自动化实施最佳实践。
- en: 'In a nutshell, this chapter will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，本章将涵盖以下内容：
- en: Understanding interactions between istio components
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 Istio 组件之间的交互
- en: Inspecting and analyzing the istio configuration
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 检查和分析 Istio 配置
- en: Troubleshooting errors using access logs
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用访问日志排除故障
- en: Troubleshooting errors using debug logs
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用调试日志排除故障
- en: Debugging istio agents
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 调试 Istio 代理
- en: Understanding istio’s best practices
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 Istio 的最佳实践
- en: Automating best practices using OPA Gatekeeper
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 OPA Gatekeeper 自动化最佳实践
- en: Understanding interactions between Istio components
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 Istio 组件之间的交互
- en: 'When troubleshooting problems with the Service Mesh, the unexpected behavior
    of the mesh is likely caused by one of the following underlying issues:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在排除服务网格问题时，网格的异常行为很可能是由以下潜在问题之一引起的：
- en: Invalid control plane configuration
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无效的控制平面配置
- en: Invalid data plane configuration
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 无效的数据平面配置
- en: Unexpected data plane
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 异常的数据平面
- en: In the upcoming sections, we will explore how to diagnose the underlying reason
    for any such unexpected behavior with the help of various diagnostic tools provided
    by istio. But first, let’s look at various interactions that happen inside the
    mesh between istiod, data planes, and other components.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将探索如何借助 Istio 提供的各种诊断工具诊断任何异常行为的根本原因。但首先，让我们看看 Istio 中 istiod、数据平面和其他组件之间的各种交互。
- en: Exploring Istiod ports
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 Istiod 端口
- en: Istiod exposes various ports, some of which can be used for troubleshooting.
    In this section, we will go through those ports, and understand what they do and
    how they can help with troubleshooting.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Istiod 暴露了多个端口，其中一些可以用于故障排除。在本节中，我们将介绍这些端口，了解它们的功能以及如何帮助排查故障。
- en: 'Let’s get started by looking at those ports:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从查看这些端口开始：
- en: '`443` but is forwarded to port `15017`, which we saw in action when setting
    up primary remote clusters.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`443` 端口会被转发到 `15017` 端口，我们在设置主远程集群时已经看到过它的实际应用。'
- en: '**Port 15014**: This port is used by Prometheus to scrape control plane metrics.
    You can check the metric using the following command:'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**15014 端口**：该端口由 Prometheus 用于抓取控制平面指标。你可以使用以下命令查看该指标：'
- en: '[PRE0]'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then, you can fetch the metrics from port `15014`:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以从 `15014` 端口获取指标：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '`15010` is insecure and port `15012` is secure so can be used for production
    environments.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`15010` 端口是不安全的，而 `15012` 端口是安全的，因此可以用于生产环境。'
- en: '`istiod` instance. This port is used to access the ControlZ interface either
    via REST API calls from within the mesh or via a dashboard, which can be accessed
    using the following command:'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`istiod` 实例。该端口用于通过网格内的 REST API 调用或仪表板访问 ControlZ 接口，可以使用以下命令进行访问：'
- en: '[PRE2]'
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following is a screenshot of the ControlZ interface:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 ControlZ 接口的截图：
- en: '![Figure 11.1 – Istio ControlZ interface](img/B17989_11_01.jpg)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.1 – Istio ControlZ 接口](img/B17989_11_01.jpg)'
- en: Figure 11.1 – Istio ControlZ interface
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – Istio ControlZ 接口
- en: The ControlZ interface can be used to inspect logging scopes, environment variables,
    and so on. The interface can also be used to change logging levels.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ControlZ 接口可用于检查日志范围、环境变量等。该接口也可以用来更改日志级别。
- en: In this section, we read about various ports exposed by istiod. Let’s move on
    to read about the ports exposed by the Istio data plane.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中，我们将了解 istiod 暴露的各种端口。接下来我们将阅读有关 Istio 数据平面暴露的端口。
- en: Exploring Envoy ports
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 Envoy 端口
- en: 'Envoy, which is the data plane for Istio, exposes various ports for interaction
    with the Istio control plane and observability tools. Let’s look at those ports,
    what they do, and how they can help with troubleshooting:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Envoy 作为 Istio 的数据平面，暴露了多个端口与 Istio 控制平面和可观察性工具进行交互。我们来看一下这些端口，它们的作用以及它们如何帮助故障排除：
- en: '**Port 15000**: This is the Envoy admin interface, which can be used to inspect
    and query envoy configuration. We will read about this port in detail in the next
    section, *Inspecting and analyzing the* *Istio configuration*.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端口 15000**：这是 Envoy 管理界面，可用于检查和查询 Envoy 配置。我们将在下一节中详细阅读此端口，*检查和分析 Istio 配置*。'
- en: '**Port 15001**: This port is used for receiving all outbound traffic from the
    application Pods.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端口 15001**：此端口用于接收来自应用程序 Pods 的所有出站流量。'
- en: '**Port 15004**: This port can be used to debug the data plane configuration.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端口 15004**：此端口可用于调试数据平面配置。'
- en: '**Port 15006**: All inbound application traffic from within the mesh is routed
    to this port.'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端口 15006**：所有来自网格内部的入站应用流量都会被路由到此端口。'
- en: '`istio-agent`, and the application, which is then scraped by Prometheus.'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`istio-agent`，以及应用程序，随后由 Prometheus 抓取。'
- en: '**Port 15021**: This port is exposed for performing health checks of the data
    plane.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端口 15021**：此端口暴露用于执行数据平面健康检查。'
- en: '**Port 15053**: This port is used to serve the DNS proxy.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端口 15053**：此端口用于提供 DNS 代理服务。'
- en: '**Port 15090**: This port provides Envoy telemetry information.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**端口 15090**：此端口提供 Envoy 的遥测信息。'
- en: In the next section, we will explore how to analyze and inspect the Istio configuration.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将探讨如何分析和检查 Istio 配置。
- en: Inspecting and analyzing the Istio configuration
  id: totrans-45
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 检查和分析 Istio 配置
- en: 'When debugging the Istio data plane, it is useful to check whether there is
    any configuration mismatch between the Istio control plane and the data plane.
    When working with multi-cluster mesh, it is a good idea to first check the connectivity
    between the control plane and data plane; if your Pod supports `curl`, then you
    can use the following command to check the connectivity between the two:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在调试 Istio 数据平面时，检查 Istio 控制平面和数据平面之间是否存在配置不匹配非常有用。在处理多集群网格时，最好首先检查控制平面和数据平面之间的连接性；如果你的
    Pod 支持 `curl`，可以使用以下命令检查二者之间的连接性：
- en: '[PRE3]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: To inspect the configuration, the first checkpoint can be to use the `istioctl
    proxy-status` command to find the synchronization state of the cluster, listener,
    routes, and endpoints configuration between istiod and istio-proxy.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查配置，第一个检查点是使用`istioctl proxy-status`命令，查看集群、监听器、路由和端点配置在 istiod 和 istio-proxy
    之间的同步状态。
- en: 'You can use the following command to check the configuration status of the
    whole cluster:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令检查整个集群的配置状态：
- en: '[PRE4]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The following are the possible values of the synchronization status:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是同步状态的可能值：
- en: '`SYNCED`: Envoy has the latest config.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`SYNCED`：Envoy 已经拥有最新的配置。'
- en: '`NOT SENT`: istiod has not sent any config to Envoy; in most cases, the reason
    is that istiod has no config to send. In this example, the status is `NOT SENT`
    for the Istio Egress Gateway because there is no route information to be synced.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NOT SENT`：istiod 尚未向 Envoy 发送任何配置；在大多数情况下，原因是 istiod 没有配置需要发送。在此示例中，Istio
    Egress Gateway 的状态为 `NOT SENT`，因为没有需要同步的路由信息。'
- en: '`STALE`: Envoy doesn’t have the latest config, which is an indication of a
    networking issue between Envoy and istiod.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`STALE`：Envoy 没有最新的配置，表示 Envoy 和 istiod 之间存在网络问题。'
- en: 'You can check the status of a workload using the following command:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令检查工作负载的状态：
- en: '[PRE5]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'If the Pod being investigated supports `curl`, then you can perform a dump
    of the `istio-proxy` configuration by fetching config from Envoy’s admin interface
    exposed at port `15000` using the following command:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果被调查的 Pod 支持 `curl`，那么你可以通过以下命令从 Envoy 的管理界面（暴露在端口 `15000` 上）抓取配置，来执行 `istio-proxy`
    配置的转储：
- en: '[PRE6]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can selectively dump the configuration of listeners, clusters, routes,
    and endpoints by using the following `istioctl` `proxy-config` command:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用以下 `istioctl` `proxy-config` 命令，选择性地转储监听器、集群、路由和端点的配置：
- en: '[PRE7]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You can fetch the Envoy configuration from the istiod perspective and compare
    it with the config fetched from Envoy’s admin interface:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从 istiod 的角度获取 Envoy 配置，并将其与从 Envoy 管理界面获取的配置进行比较：
- en: '[PRE8]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You can inspect the `istio-proxy` configuration in a Pod from a web browser
    using the following command:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过以下命令，从 Web 浏览器中检查 Pod 中的 `istio-proxy` 配置：
- en: '[PRE9]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'From the browser, you can now access the Envoy dashboard, as shown in the following
    figure:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以通过浏览器访问 Envoy 仪表盘，如下图所示：
- en: '![Figure 11.2 – Envoy dashboard](img/B17989_11_02.jpg)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.2 – Envoy 仪表盘](img/B17989_11_02.jpg)'
- en: Figure 11.2 – Envoy dashboard
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – Envoy 仪表盘
- en: The Envoy dashboard is a good option to inspect values but proceed with caution
    when changing configuration parameters because, from this dashboard, you will
    be changing data plane configuration outside the purview of istiod.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Envoy 仪表盘是查看值的一个好选择，但在更改配置参数时需要谨慎，因为通过此仪表盘，你将更改数据平面配置，而这超出了 istiod 的控制范围。
- en: At the time of writing this book, `istioctl describe` is an experimental feature.
    It is used to describe a Pod, and if the Pod meets all the requirements to be
    part of the mesh, this command (when run against a Pod) can also tell whether
    istio-proxy in the Pod has been started or whether the Pod is part of the mesh
    or not. It will emit any warnings and suggestions to enable better integration
    of the Pod into the mesh.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在写这本书时，`istioctl describe`是一个实验性功能。它用于描述一个 Pod，如果该 Pod 满足成为服务网格一部分的所有要求，那么此命令（对
    Pod 运行时）还可以告诉你该 Pod 中的 `istio-proxy` 是否已启动，或者该 Pod 是否属于服务网格的一部分。它会输出任何警告和建议，以便更好地将
    Pod 集成到服务网格中。
- en: 'The following runs the `istioctl describe` command against the `envoydummy`
    Pod:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对 `envoydummy` Pod 运行 `istioctl describe` 命令的示例：
- en: '[PRE10]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the output, you can see that it is suggesting to apply the `app` label to
    the Pod for Istio telemetry. Istio recommends adding `app` and `version` labels
    explicitly to workloads in the mesh. These labels add contextual information to
    the metrics and telemetry collected by Istio. The output also describes some other
    important pieces of information, such as the service is exposed on port `80` and
    the endpoint is on port `10000`, the `istio-proxy` Pod is exposed at port `15090`,
    and `mTLS mode` is permissive. It also describes and warns about any issues with
    destination rules and virtual services.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在输出中，你可以看到它建议将 `app` 标签应用到该 Pod 上以启用 Istio 测量。Istio 推荐明确地将 `app` 和 `version`
    标签添加到服务网格中的工作负载上。这些标签为 Istio 收集的指标和遥测数据添加了上下文信息。输出还描述了其他一些重要信息，比如服务暴露在端口 `80`
    上，端点在端口 `10000` 上，`istio-proxy` Pod 暴露在端口 `15090` 上，以及 `mTLS 模式` 是宽松的。它还描述并警告了有关目标规则和虚拟服务的任何问题。
- en: 'The following command is another example of when an incorrect virtual service
    configuration is applied to `envoydummy`. The correct configuration is available
    at `Chapter11/04-istio-gateway-chaos.yaml`:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令是另一个示例，展示了当错误的虚拟服务配置应用到 `envoydummy` 时的情况。正确的配置可以在 `Chapter11/04-istio-gateway-chaos.yaml`
    中找到：
- en: '[PRE11]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: The warning at the bottom of the preceding snippet clearly describes that the
    virtual service is routing traffic to `UNKNOWN subset v3`. To fix this problem,
    you need to either configure the virtual service to correct the subset defined
    in the destination rule or add a `v3` subset in the destination rules. The correct
    configuration is available at `Chapter11/04-istio-gateway.yaml`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 前面片段底部的警告清楚地描述了虚拟服务将流量路由到 `UNKNOWN subset v3`。要解决这个问题，你需要配置虚拟服务以纠正目标规则中定义的子集，或者在目标规则中添加
    `v3` 子集。正确的配置可以在 `Chapter11/04-istio-gateway.yaml` 中找到。
- en: 'Another diagnostic tool to inspect and detect any misconfiguration in the mesh
    is `istioctl analyze`. It can be run against the whole cluster as well as against
    any configuration before applying it to the mesh:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个用于检查和检测服务网格中任何配置错误的诊断工具是 `istioctl analyze`。它可以对整个集群运行，也可以在将配置应用到服务网格之前对任何配置运行：
- en: '[PRE12]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: In the preceding example, `istioctl analyze` pointed out the error by analyzing
    the configuration file. This is very handy to validate any erroneous configuration
    before applying it to the mesh. In the following section, we will read about how
    to troubleshoot errors using envoy access logs.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，`istioctl analyze`通过分析配置文件指出了错误。这对于在将配置应用到服务网格之前验证任何错误配置非常有用。在接下来的部分，我们将学习如何使用
    Envoy 访问日志来排除错误。
- en: Troubleshooting errors using access logs
  id: totrans-79
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用访问日志排查错误
- en: '`istio-proxy` container. Access logs are records of traffic flow to Envoy and
    can be intertwined together with the access of the Ingress and Egress gateway
    along with all other upstream and downstream workloads in the mesh, to follow
    the journey of the request.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '`istio-proxy` 容器。访问日志是流量访问 Envoy 的记录，可以与 Ingress 和 Egress 网关的访问记录以及网格中所有其他上游和下游工作负载的访问记录交织在一起，以跟踪请求的生命周期。'
- en: 'By default, access logs are turned off unless you have installed Istio using
    the demo profile. You can check whether access logs are enabled by inspecting
    the Istio config map:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，访问日志是关闭的，除非你使用演示配置文件安装了 Istio。你可以通过检查 Istio 配置映射来查看是否启用了访问日志：
- en: '[PRE13]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Access logs can be enabled via the following command:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过以下命令启用访问日志：
- en: '[PRE14]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Depending on your needs and system performance requirements, you can decide
    to turn access logging on or off. If it is turned on and you want to disable it,
    you can do so by providing a blank value for the `accessLogFile` parameter:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的需求和系统性能要求，你可以决定是否启用访问日志。如果启用了访问日志且想要禁用它，可以通过将 `accessLogFile` 参数设置为空值来实现：
- en: '[PRE15]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The access log can also be enabled at the workload or namespace level. Assuming
    you have turned off access logs globally, we can turn them on selectively for
    the `envoydummy` workload using the `Telemetry` resource:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 访问日志也可以在工作负载或命名空间级别启用。假设你已全局关闭访问日志，我们可以使用 `Telemetry` 资源有选择性地为 `envoydummy`
    工作负载打开访问日志：
- en: '[PRE16]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The configuration will turn on the access logging for the `envoydummy` Pod.
    The configuration is available at `Chapter11/03-telemetry-01.yaml` on GitHub:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 该配置将为 `envoydummy` Pod 打开访问日志。配置文件可在 GitHub 上的 `Chapter11/03-telemetry-01.yaml`
    中找到：
- en: 'Apply the configuration using the following commands:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令应用配置：
- en: '[PRE17]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, you can make a `curl` request to `envoydummy` from the `curl` Pod, as
    shown in the following command:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，你可以从 `curl` Pod 向 `envoydummy` 发起一个 `curl` 请求，命令如下：
- en: '[PRE18]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Next, if you check the access logs of `istio-proxy` in the `curl` and `envoydummy`
    Pods, you will find that there are no access logs in the `curl` Pod but there
    are access logs in the `envoydummy` Pod:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，如果你检查 `curl` 和 `envoydummy` Pods 中的 `istio-proxy` 访问日志，你会发现 `curl` Pod 中没有访问日志，而
    `envoydummy` Pod 中有访问日志：
- en: '[PRE19]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The reason for not having any access logs in the `curl` Pod is that we turned
    them off globally but selectively turned them on for the `envoydummy` Pod using
    the `Telemetry` resource.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '`curl` Pod 中没有访问日志的原因是我们全局关闭了访问日志，但通过 `Telemetry` 资源有选择性地为 `envoydummy` Pod
    打开了访问日志。'
- en: You can read more about how to configure `accessLogging` using `Telemetry` at
    [https://istio.io/latest/docs/reference/config/telemetry/#AccessLogging](https://istio.io/latest/docs/reference/config/telemetry/#AccessLogging).
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以阅读更多关于如何使用 `Telemetry` 配置 `accessLogging` 的信息，网址是 [https://istio.io/latest/docs/reference/config/telemetry/#AccessLogging](https://istio.io/latest/docs/reference/config/telemetry/#AccessLogging)。
- en: 'The default encoding of access logs is a string formatted using the following
    specification:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 访问日志的默认编码是按照以下规范格式化的字符串：
- en: '[PRE20]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: A detailed definition of each of these fields is available at [https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage](https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 每个字段的详细定义可以在 [https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage](https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage)
    上找到。
- en: 'Access logs can also be configured to be displayed in JSON format, which can
    be achieved by setting `accessLogEncoding` to `JSON`:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 访问日志也可以配置为以 JSON 格式显示，可以通过将 `accessLogEncoding` 设置为 `JSON` 来实现：
- en: '[PRE21]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Once set, the access log will be displayed in JSON format, which I have simplified
    for ease of reading:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 设置后，访问日志将以 JSON 格式显示，我已经简化了它以便于阅读：
- en: '[PRE22]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In the access logs, there is a field called `response_flags` (as seen in the
    preceding code snippet), which is a very useful piece of information when troubleshooting
    via access logs.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在访问日志中，有一个字段叫做 `response_flags`（如前面的代码片段所示），这是在通过访问日志排查故障时非常有用的信息。
- en: 'Next, we will learn about response flags by injecting some errors in the `envoydummy`
    Pod:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过在 `envoydummy` Pod 中注入一些错误来了解响应标志：
- en: 'Let’s first turn on access logs for the `curl` Pod using the following command:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，通过以下命令为 `curl` Pod 打开访问日志：
- en: '[PRE23]'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Then, delete the `envoydummy` Pod but keep the `envoydummy` service:'
  id: totrans-109
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，删除 `envoydummy` Pod，但保留 `envoydummy` 服务：
- en: '[PRE24]'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Now, the service is broken, and you will not be able to use `curl`:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，服务已经损坏，你将无法使用 `curl`：
- en: '[PRE25]'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Check the access logs for the `curl` Pod:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 检查 `curl` Pod 的访问日志：
- en: '[PRE26]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'The value of `response_flags` is `UH`, which means there is no healthy upstream
    host in the upstream cluster. Possible values of `response_flag` are shown in
    the following table and referenced from [https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage](https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage):'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '`response_flags` 的值为 `UH`，这意味着上游集群中没有健康的上游主机。`response_flag` 的可能值显示在以下表格中，并参考了
    [https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage](https://www.envoyproxy.io/docs/envoy/latest/configuration/observability/access_log/usage)：'
- en: '| **Name** | **Description** |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| **Name** | **描述** |'
- en: '| `UH` | No healthy upstream hosts in the upstream cluster in addition to a
    503 response code |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| `UH` | 上游集群中没有健康的上游主机，此外还返回了 503 响应码 |'
- en: '| `UF` | Upstream connection failure in addition to a 503 response code |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| `UF` | 上游连接失败，此外还返回了 503 响应码 |'
- en: '| `UO` | Upstream overflow (circuit breaking) in addition to a 503 response
    code |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| `UO` | 上游溢出（断路器）发生，此外还返回了 503 响应码 |'
- en: '| `NR` | No route configured for a given request in addition to a 404 response
    code, or no matching filter chain for a downstream connection |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| `NR` | 没有为给定请求配置路由，此外还返回了 404 响应码，或下游连接没有匹配的过滤链 |'
- en: '| `URX` | The request was rejected because the upstream retry limit (HTTP)
    or maximum connect attempts (TCP) was reached |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| `URX` | 请求被拒绝，因为达到了上游重试限制（HTTP）或最大连接尝试次数（TCP） |'
- en: '| `NC` | Upstream cluster not found |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| `NC` | 未找到上游集群 |'
- en: '| `DT` | A request or connection exceeded `max_connection_duration` or `max_downstream_connection_duration`
    |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `DT` | 请求或连接超出了 `max_connection_duration` 或 `max_downstream_connection_duration`
    |'
- en: Table 11.1 – Response flag values for HTTP and TCP connections
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 11.1 – HTTP 和 TCP 连接的响应标志值
- en: 'The following table describes the value of the response flag for HTTP connections:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 以下表格描述了 HTTP 连接的响应标志值：
- en: '| **Name** | **Description** |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| **Name** | **描述** |'
- en: '| `DC` | Downstream connection termination |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| `DC` | 下游连接终止 |'
- en: '| `LH` | Local service failed health check request in addition to a 503 response
    code |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| `LH` | 本地服务健康检查失败请求，此外还返回了 503 响应码 |'
- en: '| `UT` | Upstream request timeout in addition to a 504 response code |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| `UT` | 上游请求超时，此外还返回了 504 响应码 |'
- en: '| `LR` | Connection local reset in addition to a 503 response code |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| `LR` | 连接本地重置，此外还返回了 503 响应码 |'
- en: '| `UR` | Upstream remote reset in addition to a 503 response code |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| `UR` | 上游远程重置，此外还返回了 503 响应码 |'
- en: '| `UC` | Upstream connection termination in addition to a 503 response code
    |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| `UC` | 上游连接终止，此外还返回了 503 响应码 |'
- en: '| `DI` | The request processing was delayed for a period specified via fault
    injection |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| `DI` | 请求处理被延迟，延迟时间由故障注入指定 |'
- en: '| `FI` | The request was aborted with a response code specified via fault injection
    |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| `FI` | 请求被中止，并返回了通过故障注入指定的响应码 |'
- en: '| `RL` | The request was rate-limited locally by the HTTP rate limit filter
    in addition to a 429 response code |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| `RL` | 请求被 HTTP 速率限制过滤器在本地限速，此外还返回了 429 响应码 |'
- en: '| `UAEX` | The request was denied by the external authorization service |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| `UAEX` | 请求被外部授权服务拒绝 |'
- en: '| `RLSE` | The request was rejected because there was an error in the rate
    limit service |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| `RLSE` | 请求被拒绝，因为速率限制服务发生错误 |'
- en: '| `IH` | The request was rejected because it set an invalid value for a strictly-checked
    header, in addition to a 400 response code |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| `IH` | 请求被拒绝，因为它为严格检查的头部设置了无效的值，此外还返回了 400 响应码 |'
- en: '| `SI` | Stream idle timeout in addition to a 408 or 504 response code |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| `SI` | 流空闲超时，此外还返回了 408 或 504 响应码 |'
- en: '| `DPE` | The downstream request had an HTTP protocol error |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| `DPE` | 下游请求发生 HTTP 协议错误 |'
- en: '| `UPE` | The upstream response had an HTTP protocol error |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| `UPE` | 上游响应发生 HTTP 协议错误 |'
- en: '| `UMSDR` | The upstream request reached max stream duration |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| `UMSDR` | 上游请求达到了最大流持续时间 |'
- en: '| `OM` | The overload manager terminated the request |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| `OM` | 超载管理器终止了请求 |'
- en: '| `DF` | The request was terminated due to a DNS resolution failure |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| `DF` | 请求由于 DNS 解析失败而终止 |'
- en: Table 11.2 – Response flag values for HTTP connections
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 11.2 – HTTP 连接的响应标志值
- en: Response flags are very useful in troubleshooting access logs and good indicators
    of what might have gone wrong with the upstream systems. With that knowledge,
    let’s move our focus to how Istio debug logs can be used for troubleshooting.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 响应标志在故障排除访问日志时非常有用，是指示上游系统可能出错的好指标。了解这些信息后，我们可以将焦点转向 Istio 调试日志如何用于故障排除。
- en: Troubleshooting errors using debug logs
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用调试日志排查错误
- en: Istio components support a flexible logging scheme for **debug** logs. The debug
    log levels can be changed from a high level to a very verbose level to get details
    of what’s happening in the Istio control and data planes. The following two sections
    will describe the process for changing the log level for the Istio data and control
    planes. Let’s dive right in!
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: Istio 组件支持灵活的日志方案，用于**调试**日志。调试日志级别可以从较高的级别更改为非常冗长的级别，以便获取 Istio 控制平面和数据平面中发生的详细信息。接下来的两节将描述如何更改
    Istio 数据平面和控制平面的日志级别。让我们直接开始吧！
- en: Changing debug logs for the Istio data plane
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更改 Istio 数据平面的调试日志
- en: 'The following are various log levels for the Istio data plane – that is, the
    Envoy sidecar:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Istio 数据平面的各种日志级别——即 Envoy 侧车：
- en: '`trace`: Highest verbose log messages'
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`trace`：最高冗长的日志消息'
- en: '`debug`: Very verbose log messages'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`debug`：非常冗长的日志消息'
- en: '`info`: Informative messages to know about Envoy’s execution state'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`info`：关于 Envoy 执行状态的通知性消息'
- en: '`warning/warn`: Events that indicate problems and may lead to error events'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`warning/warn`：表明可能导致错误事件的问题的事件'
- en: '`error`: Error events that are important and may impair some of Envoy’s capability
    but will not make Envoy completely non-functional'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`error`：重要的错误事件，可能会损害 Envoy 的某些功能，但不会让 Envoy 完全无法运行'
- en: '`critical`: Severe error events that may cause Envoy to stop functioning'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`critical`：严重的错误事件，可能导致 Envoy 停止运行'
- en: '`off`: Produces no logs'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`off`：不产生任何日志'
- en: 'The log levels can be changed using the following command format:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 日志级别可以使用以下命令格式进行更改：
- en: '[PRE27]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'An example of such a command is as follows:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的命令示例如下：
- en: '[PRE28]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: This way of changing log levels doesn’t require a restart of the Pods. As discussed
    in the *Exploring istiod ports* section earlier in this chapter, the log levels
    can also be changed using the ControlZ interface.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 这种改变日志级别的方法不需要重启 Pods。如本章前面*探索 istiod 端口*一节所述，也可以使用 ControlZ 接口来更改日志级别。
- en: Changing log levels for the Istio control plane
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更改 Istio 控制平面的日志级别
- en: 'The Istio control plane supports the following log levels:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Istio 控制平面支持以下日志级别：
- en: '`none`: Produces no logs'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`none`：不产生任何日志'
- en: '`error`: Produces only errors'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`error`：只产生错误信息'
- en: '`warn`: Produces warning messages'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`warn`：产生警告消息'
- en: '`info`: Produces detailed information for normal conditions'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`info`：在正常情况下产生详细信息'
- en: '`debug`: Produces the maximum amount of log messages'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`debug`：产生最多的日志消息'
- en: Each component inside istiod categorizes the logs based on the type of message
    being logged. These categories are called `ads`, `adsc`, `all`, `analysis`, `authn`,
    `authorization`, `ca`, `cache`, `cli`, `default`, `installer`, `klog`, `mcp`,
    `model`, `patch`, `processing`, `resource`, `source`, `spiffe`, `tpath`, `translator`,
    `util`, `validation`, `validationController`, and `wle`.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: istiod 内部的每个组件根据所记录消息的类型对日志进行分类。这些分类包括 `ads`、`adsc`、`all`、`analysis`、`authn`、`authorization`、`ca`、`cache`、`cli`、`default`、`installer`、`klog`、`mcp`、`model`、`patch`、`processing`、`resource`、`source`、`spiffe`、`tpath`、`translator`、`util`、`validation`、`validationController`
    和 `wle`。
- en: 'The following is an example of a command used to change log levels for various
    scopes:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是更改不同范围的日志级别时使用的命令示例：
- en: '[PRE29]'
  id: totrans-172
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'In this example, we are changing the log levels for the `validation` scope
    to `debug`, the `validationController` scope to `info`, and `ads` to `debug`:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们将 `validation` 范围的日志级别更改为 `debug`，将 `validationController` 范围更改为 `info`，将
    `ads` 更改为 `debug`：
- en: '[PRE30]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'You can use `istioctl admin log` to retrieve the log level for all Istio components:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `istioctl admin log` 来获取所有 Istio 组件的日志级别：
- en: '[PRE31]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: We just looked at Envoy, which is on the `request` path of the request, but
    there is another critical component that is not on the `request` path but is important
    for smooth Envoy operations. In the next section, we will read about how to debug
    any issues in istio-agent.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚看到了 Envoy，它位于请求路径的`request`上，但还有另一个关键组件，它不在`request`路径上，但对 Envoy 的平稳操作非常重要。在接下来的章节中，我们将了解如何调试
    Istio 代理中的问题。
- en: Debugging the Istio agent
  id: totrans-178
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 调试 Istio 代理
- en: In this section, we will read how to troubleshoot any issues in the data plane
    caused by the misconfiguration of the Istio agent. An Istio agent may not act
    as expected due to a multitude of reasons; in this section, we will discuss various
    options to debug and troubleshoot such issues.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将学习如何排查由 Istio 代理配置错误导致的数据平面问题。Istio 代理可能由于多种原因未按预期工作；本节将讨论调试和排查此类问题的多种方法。
- en: 'The following command can be used to inspect the initial bootstrap configuration
    file that is used by Envoy to start itself and connect with istiod:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令可用于检查Envoy用来启动并与istiod连接的初始引导配置文件：
- en: '[PRE32]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The bootstrap configuration is composed of the information provided by the Istiod
    controller during sidecar injection via validation and the sidecar injection webhook.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 引导配置由Istiod控制器在通过验证和Sidecar注入Webhook注入Sidecar时提供的信息组成。
- en: 'We can check the certificate and `secret` configured for Envoy by `istio-agent`
    using the following command:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令检查由`istio-agent`为Envoy配置的证书和`secret`：
- en: '[PRE33]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: You can also display the detailed information in JSON format by adding `-o json`
    to the command. `ROOTCA` is the root certificate, and `default` is the workload
    certificate. When performing a multi-cluster setup, ROOTCA must match in different
    clusters.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以通过在命令中添加`-o json`来以JSON格式显示详细信息。`ROOTCA`是根证书，`default`是工作负载证书。在进行多集群配置时，ROOTCA在不同集群之间必须匹配。
- en: 'You can inspect the certificate values using the following command:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令检查证书的值：
- en: '[PRE34]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: There might be other Secrets also depending on configured gateways and destination
    rules. In the logs, if you find that Envoy is stuck in a warning state, then that
    means that the correct Secret has not been loaded in Envoy. Issues related to
    the `default` certificate and `ROOTCA` are usually caused by connectivity issues
    between istio-proxy and istiod.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 根据配置的网关和目标规则，可能还会有其他Secrets。在日志中，如果发现Envoy处于警告状态，这意味着正确的Secret未加载到Envoy中。与`default`证书和`ROOTCA`相关的问题通常是由于istio-proxy与istiod之间的连接问题引起的。
- en: 'To check that Envoy has successfully started, you can log into the `istio-proxy`
    container using the following command:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查Envoy是否已成功启动，可以使用以下命令登录到`istio-proxy`容器：
- en: '[PRE35]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: During the bootstrap of the sidecar proxy, `istio-agent` checks the readiness
    of Envoy by pinging `http://localhost:15021/healthz/ready`. It also uses the same
    endpoint for determining the readiness of Envoy during the lifetime of the Pod.
    An HTTP status code of 200 means that Envoy is ready and the `istio-proxy` container
    is marked as initialized. If the `istio-proxy` container is in a pending state
    and not initializing, then that means that Envoy has not received the configuration
    from istiod, which can be either because of connectivity issues with istiod or
    a config rejected by Envoy.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在Sidecar代理的启动过程中，`istio-agent`通过ping `http://localhost:15021/healthz/ready`来检查Envoy的就绪状态。它还在Pod的生命周期内使用相同的端点来确定Envoy的就绪状态。HTTP状态码200表示Envoy已就绪，`istio-proxy`容器被标记为已初始化。如果`istio-proxy`容器处于待处理状态并未初始化，这意味着Envoy未从istiod接收到配置，可能是由于与istiod的连接问题或Envoy拒绝配置。
- en: 'Errors such as the following in `istio-proxy` logs denote connectivity issues
    either because of the network or unavailability of istiod:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 以下错误信息表明`istio-proxy`日志中存在连接问题，可能是由于网络问题或istiod不可用：
- en: '[PRE36]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'If Envoy can connect with istiod, then you will find a message similar to the
    following in the log files:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如果Envoy能够连接到istiod，那么你会在日志文件中找到类似以下的消息：
- en: '[PRE37]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: In this section, we did a deep dive into Istio debug logs, and we looked at
    how to troubleshoot using the debug logs of Envoy, `istio-agent`, and the Istio
    control plane. In the next section, we will read about Istio’s best practices
    for securely managing and efficiently operating Istio.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们深入分析了Istio调试日志，并查看了如何使用Envoy、`istio-agent`和Istio控制平面的调试日志进行故障排除。在下一节中，我们将阅读有关Istio最佳实践的内容，了解如何安全地管理和高效地操作Istio。
- en: Understanding Istio’s best practices
  id: totrans-197
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解Istio的最佳实践
- en: When operating the Service Mesh, it is advised to assume that security threats
    will not just originate from outside of the organization’s security boundaries
    but also from within the security perimeter. You should always assume that networks
    are not impregnable and create security controls that can secure assets, even
    if network boundaries are breached. In this section, we will discuss some of the
    various attack vectors to be mindful of when implementing Service Mesh.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在操作Service Mesh时，建议假设安全威胁不仅会来自组织安全边界之外，还可能来自安全边界内部。你应该始终假设网络不是坚不可摧的，并创建能够保护资产的安全控制，即使网络边界被突破。在本节中，我们将讨论在实施Service
    Mesh时需要关注的各种攻击向量。
- en: Examining attack vectors for the control plane
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查控制平面的攻击向量
- en: 'The following list shows common strategies for initiating attacks on the control
    plane:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 以下列表显示了针对控制平面发起攻击的常见策略：
- en: Causing configuration to deliberately make the control plane malfunction so
    that the Service Mesh becomes inoperable, thus impacting business-critical applications
    being managed by the mesh. This can also be a precursor to forthcoming attacks
    targeting Ingress or any other applications.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故意造成配置问题，使控制平面发生故障，从而使服务网格无法正常工作，进而影响网格管理的业务关键应用。这也可能是针对Ingress或其他应用程序的攻击的前奏。
- en: Obtaining privileged access to be able to perform control plane and data plane
    attacks. By gaining privileged access, an attacker can then modify security policies
    to allow the exploitation of the assets.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取特权访问权限，能够执行控制平面和数据平面的攻击。通过获得特权访问，攻击者可以修改安全策略，从而利用资产进行攻击。
- en: Eavesdropping to exfiltrate sensitive data from the control plane, or tampering
    and spoofing communication between data and control planes.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 垃圾数据窃取：窃听控制平面数据，或篡改并伪造数据平面与控制平面之间的通信。
- en: Examining attack vectors for the data plane
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 检查数据平面的攻击路径。
- en: 'The following are common strategies for initiating attacks on the data plane:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是对数据平面发起攻击的常见策略：
- en: Eavesdropping on service-to-service communication to exfiltrate sensitive data
    and send it to an attacker.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 窃听服务间通信以窃取敏感数据，并将其发送给攻击者。
- en: Masquerading as a trusted service in the mesh; the attacker can then perform
    man-in-the-middle attacks between service-to-service communication. By using a
    man-in-the-middle attack, the attacker can steal sensitive data or tamper with
    the communication between the services to produce a favorable outcome for the
    attacker.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 假冒为网格中的受信任服务；攻击者可以执行服务间的中间人攻击。通过使用中间人攻击，攻击者可以窃取敏感数据或篡改服务之间的通信，以便为攻击者创造有利结果。
- en: Manipulating the applications to perform botnet attacks.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操控应用程序进行僵尸网络攻击。
- en: The other component susceptible to attacks is the infrastructure hosting istio,
    which can be the Kubernetes cluster, virtual machines, or any other components
    of the underlying stack hosting istio. We will not dive into how to protect Kubernetes,
    as there are various books on how to secure Kubernetes clusters; one such book
    is *Learn Kubernetes Security*, written by Kaizhe Huang and Pranjal Jumde and
    published by Packt. Other best practices include protecting the Service Mesh,
    which we will discuss in the following section.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个容易受到攻击的组件是托管istio的基础设施，可以是Kubernetes集群、虚拟机或任何托管istio的底层堆栈组件。我们不打算深入讨论如何保护Kubernetes，因为有各种关于如何安全配置Kubernetes集群的书籍；其中一本是Kaizhe
    Huang和Pranjal Jumde所著的*Learn Kubernetes Security*，由Packt出版。其他最佳实践包括保护服务网格，我们将在下一节中讨论。
- en: Securing the Service Mesh
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保护服务网格
- en: 'Some best practices on how to secure the Service Mesh are as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是保护服务网格的一些最佳实践：
- en: Deploy a **web application firewall** (**WAF**) to protect Ingress traffic.
    WAF implements security controls, including threats identified by **Open Web Application
    Security Project** (**OWASP**); you can read about OWASP at [https://owasp.org/](https://owasp.org/).
    Most cloud providers provide WAF as part of their cloud offering; some examples
    are **AWS WAF** by AWS, **Cloud Armor** by Google Cloud, and **Azure Web Application
    Firewall** from Azure. There are other vendors, such as Cloudflare, Akamai, Imperva,
    and AppTrana, who provide WAF as a SaaS offering, whereas vendors such as Fortinet
    and Citrix also provide self-hosted WAF offerings. WAFs are one of your first
    lines of defense and will take care of many attack vectors bound for Ingress to
    the mesh.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署**Web应用防火墙**（**WAF**）来保护入口流量。WAF实施安全控制措施，包括**开放Web应用安全项目**（**OWASP**）识别的威胁；你可以在[https://owasp.org/](https://owasp.org/)阅读有关OWASP的信息。大多数云提供商提供WAF作为其云服务的一部分；例如AWS的**AWS
    WAF**、Google Cloud的**Cloud Armor**和Azure的**Azure Web应用防火墙**。还有其他供应商，如Cloudflare、Akamai、Imperva和AppTrana，提供SaaS形式的WAF，而像Fortinet和Citrix这样的供应商也提供自托管WAF服务。WAF是你防御的第一道防线，它会处理许多指向网格入口的攻击路径。
- en: Define policies to control access from outside the mesh to services inside the
    mesh. Ingress access control policies are important to prohibit unauthorized access
    to services. Every Ingress should be well-defined and have associated authentication
    and authorization policies to verify whether external requests are authorized
    to access services exposed by the Ingress gateway. Nevertheless, all Ingress should
    happen via Ingress gateways, and every Ingress should be routed via a virtual
    service and the destination rules associated with it.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义策略来控制从外部网格到网格内部服务的访问。入口访问控制策略对于禁止未授权访问服务非常重要。每个入口应明确定义，并且应具有关联的身份验证和授权策略，以验证外部请求是否被授权访问通过入口网关暴露的服务。然而，所有的入口访问应该通过入口网关进行，并且每个入口应通过虚拟服务及其关联的目标规则进行路由。
- en: All Egress systems should be known and defined, and traffic to unknown Egress
    points should not be allowed. Security policies should enforce TLS origination
    for Egress traffic and for all Egress to happen via Egress gateways. Authorization
    policies should be used to control what workloads are allowed to send Egress traffic
    and, if allowed, all Egress endpoints should be known and approved by security
    administrators. Egress security policies also help prevent data exfiltration;
    with Egress policies, you can control traffic to known Egresses only and thus
    stop an attacker who has infiltrated your system from sending data to the attacker’s
    systems. This also stops applications within the mesh from participating in any
    botnet attacks.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有出口系统应为已知并定义，且不应允许向未知的出口点发送流量。安全策略应强制出口流量的 TLS 起源，并且所有出口流量应通过出口网关进行。授权策略应用于控制哪些工作负载被允许发送出口流量，并且如果允许，所有出口端点应由安全管理员知晓并批准。出口安全策略还帮助防止数据泄露；通过出口策略，您可以仅控制流量发送到已知的出口点，从而阻止已渗透系统的攻击者将数据发送到攻击者的系统。这还可以防止网格中的应用程序参与任何僵尸网络攻击。
- en: All services in the mesh should communicate over mTLS and should have associated
    authentication and authorization policies. By default, all service-to-service
    communication should be denied unless authorized via authorization policies, and
    any service-to-service communication should be explicitly enabled via well-defined
    service identities.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网格中的所有服务应通过 mTLS 进行通信，并应具有相关的身份验证和授权策略。默认情况下，所有服务间通信应被拒绝，除非通过授权策略授权，并且任何服务间通信应通过明确定义的服务身份进行显式启用。
- en: Where a service-to-service communication is happening on behalf of an end user
    or system, all such communication (apart from mTLS) should also make use of JWTs.
    A JWT acts as a credential to prove that a service request is explicitly being
    made on behalf of the end user; the caller service needs to present a JWT as a
    credential identifying an end user, combined with authentication and authorization
    policies that you can enforce after determining what services can be accessed
    and what level of access is granted. This helps to stop any compromised application
    from performing data exfiltration or service exploitation.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当服务间通信代表终端用户或系统进行时，除 mTLS 外，所有此类通信应使用 JWT。JWT 作为凭证，证明服务请求是明确代表终端用户发出的；调用服务需要提供一个
    JWT 作为凭证，以识别终端用户，并结合身份验证和授权策略来确定可以访问的服务以及授予的访问级别。这有助于防止任何受损的应用程序进行数据泄露或服务利用。
- en: If any external long-lived authentication token is used for authenticating any
    subject, be it an end user or a system, then such a token should be replaced by
    a short-lived token. Token replacement should happen at Ingress, and then the
    short-lived token should be used throughout the mesh. Doing so helps prevent attacks
    where an attacker steals tokens and uses them for unauthorized access. Also, whereas
    the long-lived external attack might have many broader scopes attached to it that
    might be misused by a compromised application, having a short-lived token with
    restricted scope helps to avoid misuse of tokens.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果使用任何外部长期有效的身份验证令牌来验证任何主体，无论是终端用户还是系统，那么此类令牌应被短期令牌替换。令牌替换应在入口处进行，然后在整个网格中使用短期令牌。这样做有助于防止攻击者窃取令牌并利用其进行未授权访问。同时，外部长期攻击可能会附带许多更广泛的作用域，受损的应用程序可能会滥用这些作用域，而短期令牌具有受限作用域，有助于避免令牌滥用。
- en: When applying exceptions to mesh or security rules, then you should proceed
    with caution when defining exception policies. For example, if you want to enable
    workload A in the mesh to allow HTTP traffic from another workload, B, then instead
    of explicitly allowing all HTTP traffic, you should explicitly define an exception
    to allow HTTP traffic from workload B, whereas all other traffic should be on
    HTTPS only.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在应用网格或安全规则的例外时，应谨慎定义例外策略。例如，如果您希望启用工作负载A在网格中允许来自另一个工作负载B的HTTP流量，那么您应明确规定允许来自工作负载B的HTTP流量的例外，而不是明确允许所有HTTP流量，且所有其他流量应仅限于HTTPS。
- en: Access to istiod must be restricted and controlled. Firewall rules should restrict
    access to the control plane to known sources. The rule should cater to human operators
    as well the data plane’s access to the control plane in single and multi-cluster
    setups.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须限制并控制对istiod的访问。防火墙规则应限制对控制平面的访问，仅允许已知来源。该规则应同时适应人工操作员和数据平面对控制平面的访问，无论是在单集群还是多集群配置中。
- en: All workloads being managed by the Service Mesh should be managed by the Service
    Mesh only via **role-based access control** (**RBAC**) policies for the Kubernetes
    environment and user groups for non-Kubernetes workloads. Kubernetes administrators
    should carefully define RBAC policies for application users and mesh administrators
    and allow only the latter to make any changes to the mesh. Mesh operators should
    be further classified according to the operations they are authorized to perform.
    For example, mesh users with permission to deploy applications in a namespace
    should not have access to other namespaces.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有由服务网格管理的工作负载应仅通过**基于角色的访问控制**（**RBAC**）策略在Kubernetes环境中进行管理，对于非Kubernetes工作负载，则通过用户组进行管理。Kubernetes管理员应仔细定义应用程序用户和网格管理员的RBAC策略，并仅允许后者对网格进行任何更改。网格操作员应根据其被授权执行的操作进一步分类。例如，有权限在命名空间中部署应用程序的网格用户不应有权访问其他命名空间。
- en: Restrict what repositories are accessible to users from where images can be
    pulled for deployment.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制用户可以访问的仓库，以便从中拉取镜像进行部署。
- en: In this section, we read about istio’s best practices; as well as this section,
    you should also read about best practices on the istio website at [https://istio.io/latest/docs/ops/best-practices/](https://istio.io/latest/docs/ops/best-practices/).
    The website is frequently updated based on feedback from the istio community.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们了解了istio的最佳实践；除此之外，您还应该访问istio官网，阅读有关最佳实践的内容，网址为[https://istio.io/latest/docs/ops/best-practices/](https://istio.io/latest/docs/ops/best-practices/)。该网站会根据istio社区的反馈定期更新。
- en: Even after all controls, mesh operators may accidentally misconfigure the Service
    Mesh, which can result in unexpected outcomes and even security breaches. One
    option is to enforce a stringent review and governance process for making changes,
    but doing so manually is expensive, time-consuming, error-prone, and often annoying.
    In the following section, we will read about **OPA Gatekeeper** and how to use
    it for the automation of best practices policies.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 即便在所有控制措施到位的情况下，网格操作员也可能会错误地配置服务网格，导致意外结果甚至安全漏洞。一个解决方案是强制执行严格的审查和治理流程来进行更改，但手动执行这一过程既昂贵又耗时，且容易出错，通常也很麻烦。在接下来的部分，我们将了解**OPA
    Gatekeeper**以及如何使用它来自动化最佳实践政策。
- en: Automating best practices using OPA Gatekeeper
  id: totrans-224
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用OPA Gatekeeper自动化最佳实践
- en: To avoid human errors, you can define the best practices and constraints in
    the form of policies that can then be enforced automatically whenever a resource
    is created, deleted, or updated in the cluster. Automated policy enforcement ensures
    consistency and adherence to best practices without compromising agility and deployment
    velocity. One such software is **Open Policy Agent** (**OPA**) Gatekeeper, which
    is an admission controller that enforces policies based on the **custom resource
    definition** (**CRD**), executed by OPA. OPA Gatekeeper enables the enforcement
    of guard rails; any istio configuration not within the guard rails is automatically
    rejected. It also allows **cluster administrators** to audit the resources in
    breach of best practices. Using the following steps, we will set up OPA Gatekeeper,
    followed by the configuration to enforce some of the best practices for istio.
    Let’s get started!
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免人为错误，你可以将最佳实践和约束定义为策略的形式，并在集群中创建、删除或更新资源时自动强制执行这些策略。自动化的政策执行确保了一致性，并遵循最佳实践，同时不影响敏捷性和部署速度。一种这样的软件是**Open
    Policy Agent**（**OPA**）Gatekeeper，它是一个基于**自定义资源定义**（**CRD**）的准入控制器，执行由OPA执行的策略。OPA
    Gatekeeper使得强制执行保护措施成为可能；任何不符合保护措施的istio配置都会被自动拒绝。它还允许**集群管理员**审核不符合最佳实践的资源。通过以下步骤，我们将设置OPA
    Gatekeeper，并配置一些用于istio的最佳实践强制执行。让我们开始吧！
- en: 'Install Gatekeeper using the following command:'
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令安装Gatekeeper：
- en: '[PRE38]'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Configure Gatekeeper to sync namespaces, Pods, Services, istio CRD gateways,
    virtual services, destination rules, policy, and service role bindings into its
    cache. We have defined that in the following file available at `Chapter11/05-GatekeeperConfig.yaml`:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置Gatekeeper同步命名空间、Pods、Services、istio CRD网关、虚拟服务、目标规则、策略和服务角色绑定到其缓存中。我们已经在以下文件中定义了这一点，文件路径为`Chapter11/05-GatekeeperConfig.yaml`：
- en: '[PRE39]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Now, apply the configuration using the following command:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令应用配置：
- en: '[PRE40]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: This completes the installation of Gatekeeper; next, we will configure constraints.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了Gatekeeper的安装；接下来，我们将配置约束。
- en: We will start with a simple policy for ensuring Pod naming conventions as per
    istio best practices. As discussed in the *Inspecting and analyzing istio configuration*
    section, istio recommends adding an explicit `app` and `version` label to every
    Pod deployment. The `app` and `version` labels add contextual information to the
    metrics and telemetry that istio collects.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从确保Pod命名约定符合istio最佳实践的简单策略开始。正如在*检查和分析istio配置*部分中讨论的，istio建议向每个Pod部署添加显式的`app`和`version`标签。`app`和`version`标签为istio收集的指标和遥测数据添加了上下文信息。
- en: 'Perform the following steps to enforce this governance rule so that any deployment
    not adhering to this rule is automatically rejected:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下步骤来强制执行这一治理规则，以便任何不遵守该规则的部署都会被自动拒绝：
- en: 'First, we must define `ConstraintTemplate`. In the constraint template, we
    do the following:'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们必须定义`ConstraintTemplate`。在约束模板中，我们执行以下操作：
- en: Describe the policy that will be used to enforce the constraints
  id: totrans-236
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述将用于强制执行约束的策略
- en: Describe the schema of the constraint
  id: totrans-237
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 描述约束的模式
- en: Important note
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 重要说明
- en: Gatekeeper constraints are defined using a purpose-built, high-level declarative
    language called **Rego**. Rego is particularly used for writing OPA policies;
    you can read more about Rego at https://www.openpolicyagent.org/docs/latest/#rego.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: Gatekeeper约束使用一种专门的、高层次的声明式语言**Rego**定义。Rego特别用于编写OPA策略；你可以在https://www.openpolicyagent.org/docs/latest/#rego查看更多关于Rego的信息。
- en: 'The following steps defines the constraint template and the schema:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤定义了约束模板和模式：
- en: 'We will declare a constraint template using the OPA CRD:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用OPA CRD声明一个约束模板：
- en: '[PRE41]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Next, we will define the schema:'
  id: totrans-243
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将定义模式：
- en: '[PRE42]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Finally, we will define `rego` to check the labels and detect any violation:'
  id: totrans-245
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将定义`rego`以检查标签并检测任何违规：
- en: '[PRE43]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'The configuration is available at `Chapter11/gatekeeper/01-istiopodlabelconstraint_template.yaml`.
    Apply the configuration using the following command:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件位于`Chapter11/gatekeeper/01-istiopodlabelconstraint_template.yaml`。使用以下命令应用配置：
- en: '[PRE44]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Next, we will define `constraints` that are used to inform Gatekeeper that
    we want to enforce the constraint template named `istiorequiredlabels`, as per
    the configuration defined in the `mesh-pods-must-have-app-and-version` constraint.
    The sample file is available at `Chapter11/gatekeeper/01-istiopodlabelconstraint.yaml`:'
  id: totrans-249
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将定义用于通知Gatekeeper我们希望强制执行名为`istiorequiredlabels`的约束模板的`constraints`，该模板根据在`mesh-pods-must-have-app-and-version`约束中定义的配置进行定义。示例文件可在`Chapter11/gatekeeper/01-istiopodlabelconstraint.yaml`中找到：
- en: '[PRE45]'
  id: totrans-250
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'For the constraint configuration, we have defined the following fields:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 对于约束配置，我们定义了以下字段：
- en: '`enforcementAction`: This field defines the action for handling constraint
    violations. The field is set to `deny`, which is also the default behavior; any
    resource creation or update that is in violation of this constraint will be handled
    as per enforcement action. Other supported `enforcementAction` values include
    `dryrun` and `warn`. When rolling out new constraints to running clusters, the
    `dryrun` functionality can be helpful to test them in a running cluster without
    enforcing them. The `warn` enforcement action offers the same benefits as `dryrun`,
    such as testing constraints without enforcing them. In addition to this, it also
    provides immediate feedback on why that constraint would have been denied.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enforcementAction`：此字段定义处理约束违规的操作。该字段设置为`deny`，这是默认行为；任何违反此约束的资源创建或更新将根据强制执行的操作进行处理。其他支持的`enforcementAction`值包括`dryrun`和`warn`。在向运行中的集群推出新约束时，`dryrun`功能可以帮助在不强制执行的情况下测试它们。`warn`强制执行操作提供与`dryrun`相同的好处，例如在不强制执行的情况下测试约束。此外，它还提供了即时反馈，说明为何该约束会被拒绝。'
- en: '`match`: This field defines the selection criteria for identifying the objects
    to which the constraints will be applied. In the configuration, we have defined
    that the constraints should be applied to `pod` resources that are deployed in
    a namespace with the label of `istio-injection` and a value of `enabled`. By doing
    this, we can selectively apply the constraints to namespaces that are part of
    the mesh data plane.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`match`：此字段定义了选择标准，用于识别约束将应用于哪些对象。在配置中，我们定义了约束应应用于在具有`istio-injection`标签并且值为`enabled`的命名空间中部署的`pod`资源。通过这样做，我们可以选择性地将约束应用于属于数据平面网格的命名空间。'
- en: 'Finally, we have defined the message to be displayed when constraints are violated.
    Apply the following constraints:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们定义了当约束被违反时显示的消息。应用以下约束：
- en: '[PRE46]'
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'As a test, we will deploy the `envoydummy` Pod with missing labels:'
  id: totrans-256
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为测试，我们将部署缺少标签的`envoydummy` Pod：
- en: '[PRE47]'
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: The deployment was verified by Gatekeeper and rejected because it is violating
    constraints by not having `app` and `version` labels. Please fix the labels and
    redeploy to check that you can successfully deploy with the correct labels.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: Gatekeeper已经验证了该部署并拒绝了它，因为它违反了约束，缺少`app`和`version`标签。请修复标签并重新部署，以检查是否可以使用正确的标签成功部署。
- en: I hope this gave you some idea about how to use Gatekeeper for automating some
    of the best practices. We will practice one more example to give you some further
    confidence on how to use Gatekeeper. At first, it might appear a daunting task
    to define the constraints, but once you build some experience using `rego`, then
    you will find it simple and easy to use.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我希望这能给你一些关于如何使用Gatekeeper自动化一些最佳实践的想法。我们将进行另一个示例练习，以帮助你进一步了解如何使用Gatekeeper。一开始，定义约束可能看起来是一个艰巨的任务，但一旦你积累了使用`rego`的经验，你会发现它简单易用。
- en: 'As another example, let’s write another constraint to enforce port naming conventions.
    As per istio best practices described at [https://istio.io/v1.0/docs/setup/kubernetes/spec-requirements/](https://istio.io/v1.0/docs/setup/kubernetes/spec-requirements/),
    `Service` ports must be named. The port names must be of the `<protocol>[-<suffix>]`
    form, with `http`, `http2`, `grpc`, `mongo`, or `redis` as `<protocol>`. This
    is important if you want to take advantage of istio’s routing features. For example,
    `name: http2-envoy` and `name: http` are valid port names, but `name: http2envoy`
    is an invalid name.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '作为另一个示例，让我们编写另一个约束，以强制执行端口命名约定。根据在[https://istio.io/v1.0/docs/setup/kubernetes/spec-requirements/](https://istio.io/v1.0/docs/setup/kubernetes/spec-requirements/)中描述的Istio最佳实践，`Service`端口必须命名。端口名称必须采用`<protocol>[-<suffix>]`的形式，其中`http`、`http2`、`grpc`、`mongo`或`redis`为`<protocol>`。如果你希望利用Istio的路由功能，这一点非常重要。例如，`name:
    http2-envoy`和`name: http`是有效的端口名称，但`name: http2envoy`是无效的名称。'
- en: 'The `rego` in the constraint template will be as follows:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 约束模板中的`rego`如下所示：
- en: '[PRE48]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: In the `rego`, we are defining that port names should start with a prefix, and
    if the prefix is missing, then it should be considered a violation.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在`rego`中，我们定义了端口名称应该以前缀开始，如果缺少前缀，则应视为违规。
- en: 'The constraint is defined as follows:'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 该约束定义如下：
- en: '[PRE49]'
  id: totrans-265
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: In the constraint, we are defining the various prefixes that are allowed and
    the corresponding error message to be displayed when the constraints are violated.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 在约束中，我们定义了允许的各种前缀，并且当约束被违反时，显示相应的错误信息。
- en: 'Now, let’s apply the constraint template and configuration as follows:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们应用约束模板和配置，如下所示：
- en: '[PRE50]'
  id: totrans-268
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'After applying the config, let’s deploy `envoydummy` with incorrect names for
    the service ports. We will create an `envoydummy` service without specifying any
    port names, as described in the following code snippet:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 应用配置后，我们部署一个名称不正确的`envoydummy`服务端口。我们将创建一个没有指定任何端口名称的`envoydummy`服务，具体方法如下代码片段所示：
- en: '[PRE51]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The file is available at `Chapter11/07-envoy-proxy-chaos.yaml`. Apply the configuration
    using the following code and observe the error message to see OPA Gatekeeper in
    action:'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 文件位于`Chapter11/07-envoy-proxy-chaos.yaml`。使用以下代码应用配置，并观察错误信息，查看OPA Gatekeeper的实际操作：
- en: '[PRE52]'
  id: totrans-272
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'In the response, you can see the error message caused by the incorrect naming
    of the port in the service configuration. The issue can be resolved by adding
    a name to the port declaration as follows:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 在响应中，你可以看到由于服务配置中的端口命名错误而导致的错误信息。通过如下方式给端口声明添加名称，可以解决该问题：
- en: '[PRE53]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: OPA Gatekeeper is a powerful tool to automate the enforcement of best practices
    for the Service Mesh. It compensates for any misconfiguration caused by human
    operators and reduces the cost and time required to keep your mesh aligned with
    the best practices guard rails. You can read more about OPA Gatekeeper at [https://open-policy-agent.github.io/gatekeeper/website/docs/](https://open-policy-agent.github.io/gatekeeper/website/docs/),
    and there are also some good examples of Gatekeeper available at [https://github.com/crcsmnky/gatekeeper-istio](https://github.com/crcsmnky/gatekeeper-istio).
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: OPA Gatekeeper是一个强大的工具，用于自动执行服务网格的最佳实践。它弥补了人为操作导致的任何配置错误，减少了保持网格与最佳实践对齐所需的时间和成本。你可以在[https://open-policy-agent.github.io/gatekeeper/website/docs/](https://open-policy-agent.github.io/gatekeeper/website/docs/)阅读更多关于OPA
    Gatekeeper的内容，并且在[https://github.com/crcsmnky/gatekeeper-istio](https://github.com/crcsmnky/gatekeeper-istio)中有一些Gatekeeper的优秀示例。
- en: Uninstalling OPA Gatekeeper
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 卸载OPA Gatekeeper
- en: 'To uninstall OPA Gatekeeper, you may use the following command:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 要卸载OPA Gatekeeper，可以使用以下命令：
- en: '`% kubectl delete -``f` [https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml](https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml)'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '`% kubectl delete -``f` [https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml](https://raw.githubusercontent.com/open-policy-agent/gatekeeper/master/deploy/gatekeeper.yaml)'
- en: Summary
  id: totrans-279
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, we read about various troubleshooting techniques as well as
    best practices for configuring and operating istio. By now, you should have a
    good understanding of various ports exposed by istio and how they can help diagnose
    any errors in the mesh. You also read about debugs and access logs produced by
    Envoy and istiod and how they can help you pinpoint the root cause of errors.
    istio provides various tools in its diagnostic toolkit that are very helpful for
    troubleshooting and analyzing issues and errors in the Service Mesh.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们学习了各种故障排除技巧以及配置和操作istio的最佳实践。到现在为止，你应该已经很好地理解了istio暴露的各种端口以及它们如何帮助诊断网格中的任何错误。你还学习了Envoy和istiod生成的调试信息和访问日志，以及它们如何帮助你找出错误的根本原因。istio在其诊断工具包中提供了多种非常有用的工具，帮助故障排除和分析服务网格中的问题和错误。
- en: Security is of utmost importance when running the Service Mesh, which is why
    we discussed various attack vectors for the control and data planes. You should
    now have a good understanding of the list of controls you can put in place to
    secure the Service Mesh. Finally, we read about how to automate best practices
    using OPA Gatekeeper to catch most, if not all, non-compliant configurations.
    You learned how to set up OPA Gatekeeper, how to define constraint templates using
    Rego and constraint schema, and how to use them to catch poor configurations.
    I hope this chapter provides you with the confidence to troubleshoot and operate
    istio and use automation tools such as OPA Gatekeeper to enforce configuration
    hygiene in your istio Service Mesh implementation.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性在运行服务网格时至关重要，这也是我们讨论控制平面和数据平面的各种攻击向量的原因。你现在应该已经对可以采取的安全控制措施有了很好的理解。最后，我们阅读了如何使用OPA
    Gatekeeper自动化最佳实践，以捕捉大多数（如果不是全部的话）不合规的配置。你学习了如何设置OPA Gatekeeper，如何使用Rego和约束模板定义约束，以及如何使用它们来捕捉不良配置。我希望这一章能让你有信心去排查问题、操作Istio，并使用自动化工具如OPA
    Gatekeeper来强制执行配置卫生，确保你的Istio服务网格实现符合最佳实践。
- en: In the next chapter, we will put the learning from this book into practice by
    deploying an application on the mesh.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将通过在网格上部署一个应用程序，将本书的学习内容付诸实践。
