- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Monitoring the Health of Infrastructure and Applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the last chapter, we looked at how to expose Services outside of the cluster,
    and load balancers were used to expose applications to the outside network. The
    single `LoadBalancer` Kubernetes service is implemented by `MetalLB`. `MetalLB`
    assigns a client an IP address from a predefined range when a `LoadBalancer` service
    is requested and informs the network that the IP address is in the cluster. `MetalLB`,
    which may be deployed alongside Ingress in the same Kubernetes cluster, can also
    be utilized as a load balancer. Another technique to expose the Ingress controller
    to the outside world is through `NodePort`. Both options were explored in detail
    in the previous chapter, with various examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will look at various options for monitoring, logging, and
    alerting for your infrastructure and applications. In a traditional, host-centric
    infrastructure, there used to be only two levels of monitoring: applications and
    the hosts that run them. Then, container abstraction came in, between the host
    and your applications, after which Kubernetes came in to orchestrate your containers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To manage infrastructure thoroughly, Kubernetes must now be observed as well.
    As a result, four distinct components must now be monitored, each with its own
    set of challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: Hosts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: And finally, the Kubernetes cluster itself
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To keep track of the health of the Kubernetes infrastructure, there is a need
    to collect metrics and events from all containers and Pods. However, to fully
    comprehend what clients or users are going through, there is now a need to keep
    track of the applications that are operating in these Pods. Note that you normally
    have very little influence over where workloads run when using Kubernetes, which
    automatically schedules them.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to monitoring, Kubernetes forces you to reconsider your strategy.
    But if you know what to look for, where to look for it, and how to aggregate and
    analyze it, you can make sure your applications are running smoothly and Kubernetes
    is doing its job effectively.
  prefs: []
  type: TYPE_NORMAL
- en: For aggregating and reporting monitoring data from your cluster, the Kubernetes
    ecosystem currently offers two in-built add-ons, as detailed next.
  prefs: []
  type: TYPE_NORMAL
- en: Metrics Server collects resource consumption statistics from each `kubelet`
    on each node and returns aggregated metrics via the `Metrics` `kube-state-metrics`
    add-on service makes cluster state data public. Unlike Metrics Server, which provides
    metrics on Pod and node resource utilization, `kube-state-metrics` polls the control
    plane API server for information on the overall status of Kubernetes objects (nodes,
    Pods, Deployments, and so on), as well as resource restrictions and allocations.
    The information is then utilized to generate metrics, which may be accessed through
    the Metrics API. In short, `kube-state-metrics` focuses on creating whole new
    metrics from Kubernetes' object state, whereas `metrics-server` merely saves the
    most recent data and is not responsible for transmitting metrics to third-party
    destinations.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we'll go over in detail the various options for retrieving
    metrics using Metrics Server and `kube-state-metrics`. The advantage of MicroK8s
    is that the monitoring tools can be enabled in under a minute with only a few
    commands. It is small enough to fit on a Raspberry Pi and it can be used to develop
    a monitoring stack that can be deployed anywhere, even at the edge. Furthermore,
    this is built using some of the most popular open source components that come
    preinstalled with MicroK8s.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll look at how to easily deploy monitoring tools at the edge in this chapter.
    Such a deployment provides privacy, low latency, and minimal bandwidth costs in
    **internet of things** (**IoT**)/edge applications. In this chapter, we''re going
    to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Overview of monitoring, logging, and alerting options
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring a monitoring and alerting stack using the Prometheus, Grafana, and
    Alertmanager tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring a monitoring, logging, and alerting stack using the **Elasticsearch,
    Fluentd, and Kibana** (**EFK**) toolset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Key metrics that need to be monitored
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of monitoring, logging, and alerting options
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes has a lot of advantages, but it also adds a lot of complexity. Its
    capacity to distribute containerized applications across several nodes and even
    different data centers (cloud providers, for example) necessitates a comprehensive
    monitoring solution that can collect and aggregate metrics from a variety of sources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many free and paid solutions provide real-time monitoring of Kubernetes clusters
    and the applications they host, and continuous monitoring of system and application
    health is critical. Here, we list some prominent open source Kubernetes monitoring
    tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubelets` and exposes them in the Kubernetes API server through the following
    Metrics API endpoints:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Table 8.1 – Metrics API endpoints ](img/01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 8.1 – Metrics API endpoints
  prefs: []
  type: TYPE_NORMAL
- en: '**Kubernetes Dashboard** (in-built) is a web **user interface** (**UI**) add-on
    for Kubernetes clusters that allows you to keep track of workload health. Using
    a simple web interface, Kubernetes Dashboard allows you to manage cluster resources
    and troubleshoot containerized applications. It provides a concise overview of
    cluster-wide and individual node resources. It also lists all clusters'' namespaces
    as well as all storage classes that have been declared.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Prometheus** is an open source system for collecting metrics on Kubernetes
    health. It deploys node exporter Pods on each cluster node, and its server collects
    data from nodes, Pods, and jobs. Final time-series metrics data is saved in a
    database, and alerts can be generated automatically based on predefined conditions.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Prometheus has its own dashboard with limited capabilities that have been extended
    by the usage of other visualization tools such as Grafana, which uses the Prometheus
    database to provide advanced inquiries, debugging, and reporting designed for
    development, test, and production teams.
  prefs: []
  type: TYPE_NORMAL
- en: 'It was built with the objective of monitoring applications and microservices
    in containers at scale, and it can connect to a wide range of third-party databases
    and supports the bridging of data from other tools. It is made up of three components
    at its core, as outlined here:'
  prefs: []
  type: TYPE_NORMAL
- en: All metrics data will be stored in an in-built time-series database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A data retrieval worker is in charge of obtaining metrics from outside sources
    and entering them into the database.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A web server with a simple web interface for configuring and querying the stored
    data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Some of the key features of Prometheus are presented here:'
  prefs: []
  type: TYPE_NORMAL
- en: Time-series data classified by metric name and key/value pairs in a multidimensional
    data model.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using **Prometheus Query Language** (**PromQL**), a flexible query language
    that allows us to make use of this dimensionality without relying on distributed
    storage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Single-server nodes are self-contained, and time series are collected using
    a pull model over **HyperText Transfer Protocol** (**HTTP**).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternatively, an intermediary gateway can be used to push time series to destinations
    that are discovered using service discovery or static configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple graphing and dashboarding options are supported.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Grafana**, an open source analytics and metric visualization platform, includes
    four dashboards: **Cluster**, **Node**, **Pod/Container**, and **Deployment**.
    Grafana and the Prometheus data source are frequently used by Kubernetes administrators
    to create information-rich dashboards.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Elasticsearch, Fluentd, and Kibana** make up the EFK stack, which is a combination
    of three tools that function well together. Fluentd is a data collector for Kubernetes
    cluster nodes that collects logs from Pods. It sends these logs to the Elasticsearch
    search engine, which ingests and stores the data in a central location. The EFK
    stack''s UI is Kibana, a data visualization plugin for Elasticsearch that allows
    users to visualize collected logs and metrics and construct custom dashboards.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now that we've seen a variety of choices for monitoring, logging, and alerting,
    we'll go over how to configure them.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a monitoring and alerting stack using the Prometheus, Grafana, and
    Alertmanager tools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: MicroK8s ships pre-integrated add-ons with Prometheus Operator for Kubernetes,
    which handles simplified monitoring definitions for Kubernetes services, as well
    as Prometheus instance deployment and management.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'Operators are Kubernetes-specific applications (Pods) that automate the configuration,
    management, and optimization of other Kubernetes deployments. Operators typically
    take care of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: a. Installing your Kubernetes cluster's specifications and offering initial
    setup and sizing for your deployment.
  prefs: []
  type: TYPE_NORMAL
- en: b. Reloading Deployments and Pods in real time to accommodate any user-requested
    parameter changes (hot config reloading).
  prefs: []
  type: TYPE_NORMAL
- en: c. Scaling up or down automatically based on performance data.
  prefs: []
  type: TYPE_NORMAL
- en: d. Backups, integrity checks, and other maintenance tasks should all be performed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the Prometheus add-on is enabled, Prometheus Operator takes care of the
    installation and configuration of the following items:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Kubernetes-Prometheus stack**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prometheus servers
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Alertmanager
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Grafana
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Host-node exporter
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`kube-state-metrics`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**ServiceMonitor** entities that define metric endpoint autoconfiguration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operator Custom Resource Definitions (CRDs) and ConfigMaps** that can be
    used to customize and scale the services, thus making our configuration entirely
    portable and declarative.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following CRDs are managed by Prometheus Operator:'
  prefs: []
  type: TYPE_NORMAL
- en: '**PrometheusDeployment**—The Operator ensures that a deployment that matches
    the resource definition is operating at all times.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ServiceMonitor**—Declaratively specifies how to monitor groups of services.
    Based on the definition, the Operator produces a Prometheus scrape setup automatically.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PrometheusRule**—Specifies a Prometheus rule file to be loaded by a Prometheus
    instance with Prometheus alerting rules.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AlertManager**—Specifies the Alertmanager deployment that is desired. The
    Operator ensures that a deployment that matches the resource definition is operating
    at all times.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For more information on Prometheus Operator, please refer to the following
    link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/prometheus-operator/prometheus-operator](https://github.com/prometheus-operator/prometheus-operator)'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the components that we discussed previously:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Prometheus Operator components ](img/Figure_8.01_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – Prometheus Operator components
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, we are going to use the following tools to collect, aggregate,
    and visualize metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes metrics pulled from Metrics Endpoints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Host metrics using Prometheus Node Exporter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alerting using Prometheus Alertmanager.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prometheus gathers data from configured targets (from the Kubernetes endpoints
    discussed in the previous section) at predetermined intervals, analyses rule expressions,
    displays the results, and can also send out alerts when certain criteria are matched.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualization using Grafana pre-built dashboards.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that we are clear on the tools, we will dive into the steps of configuring
    a monitoring and alerting stack. The following diagram depicts our Raspberry Pi
    cluster setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Raspberry Pi cluster setup ](img/Figure_8.02_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – Raspberry Pi cluster setup
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know what we want to do, let's look at the requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Requirements for setting up a MicroK8s Raspberry Pi cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before you begin, here are the prerequisites for building a Raspberry Pi Kubernetes
    cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: A microSD card (4 **gigabytes** (**GB**) minimum; 8 GB recommended)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A computer with a microSD card drive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Raspberry Pi 2, 3, or 4 (one or more)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A micro-USB power cable (USB-C for the Pi 4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Wi-Fi network or an Ethernet cable with an internet connection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (Optional) A monitor with a **High-Definition Multimedia Interface** (**HDMI**)
    interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (Optional) An HDMI cable for the Pi 2 and 3 and a micro-HDMI cable for the Pi
    4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (Optional) A **Universal Serial Bus** (**USB**) keyboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we've established the requirements, we'll go on to the step-by-step
    instructions on how to complete the process.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Creating a MicroK8s Raspberry Pi cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Please follow the steps that we covered in [*Chapter 5*](B18115_05.xhtml#_idTextAnchor070)*,
    Creating and Implementing Updates on Multi-Node Raspberry Pi Kubernetes Clusters,*
    to create a MicroK8s Raspberry Pi cluster. Here''s a quick refresher:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Step 1*: Installing the **operating system** (**OS**) image to a **Secure
    Digital** (**SD**) card'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Step 1a*: Configuring Wi-Fi access settings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Step 1b*: Configuring remote access settings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Step 1c*: Configuring control group settings'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Step 1d*: Configuring hostname'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Step 2*: Installing and configuring MicroK8s'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Step 3*: Adding worker node'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A fully functional multi-node Kubernetes cluster should look like the one shown
    in the following screenshot. To summarize, we have installed MicroK8s on the Raspberry
    Pi boards and joined multiple Deployments to form the cluster. We have also added
    nodes to the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Fully functional MicroK8s Kubernetes cluster ](img/Figure_8.03_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – Fully functional MicroK8s Kubernetes cluster
  prefs: []
  type: TYPE_NORMAL
- en: We can now go to the next step of deploying monitoring tools, as we have a fully
    functional cluster.
  prefs: []
  type: TYPE_NORMAL
- en: By default, none of the MicroK8s add-ons are turned on. As a result, Grafana
    and Prometheus must be activated post-installation.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Configuring Prometheus, Grafana, and Alertmanager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we''ll enable the Prometheus add-on and access the Prometheus
    and Grafana dashboards so that we can monitor the Kubernetes cluster and can view
    alerts if something goes wrong. Use the following command to enable the Dashboard
    and the Prometheus add-on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output indicates the Dashboard and the Prometheus
    add-on have been enabled successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – Enabling Dashboard and the Prometheus add-on ](img/Figure_8.04_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – Enabling Dashboard and the Prometheus add-on
  prefs: []
  type: TYPE_NORMAL
- en: 'It will take some time to finish activating the add-on, but the following command
    execution output shows that Prometheus has been successfully enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Add-ons activated ](img/Figure_8.05_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – Add-ons activated
  prefs: []
  type: TYPE_NORMAL
- en: Grafana cannot be enabled with a command. When the Kubernetes Dashboard is enabled,
    it starts automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'To access the Kubernetes Dashboard, we need to create a user and admin role
    binding. In the next steps, we will create a deployment for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a `dashboard-adminuser.yaml` file with the preceding content and use
    the following command to create a user and admin role binding:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output confirms that there is no error in the
    deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Creating a user and admin role binding ](img/Figure_8.06_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – Creating a user and admin role binding
  prefs: []
  type: TYPE_NORMAL
- en: 'To access the dashboard, we need an access token, which can be obtained by
    invoking the `kubectl` command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Copy the token from the command's output and use it in the following step.
  prefs: []
  type: TYPE_NORMAL
- en: 'It will be necessary to build a secure channel to the cluster with the following
    command in order to access the Kubernetes Dashboard:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output confirms that a secure channel has been
    created and we can access the dashboard in the next step:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Creating a secure channel for the dashboard ](img/Figure_8.07_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 – Creating a secure channel for the dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'After that, you''ll be able to access the dashboard at the following address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'By copying and pasting the token generated in the previous step, you will have
    access to the cluster''s web-based **command-line interface** (**CLI**), as illustrated
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.8 – Kubernetes Dashboard ](img/Figure_8.08_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 – Kubernetes Dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'As discussed earlier, Dashboard is a Kubernetes UI that can be accessed through
    the web. It can be used to deploy containerized applications to a Kubernetes cluster,
    troubleshoot them, and control the cluster''s resources. The dashboard can be
    used for a variety of purposes, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: All nodes and persistent storage volumes are listed in **Admin overview**, along
    with aggregated metrics for each node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Workloads view** displays a list of all running applications by namespace,
    as well as current Pod memory utilization and the number of Pods in a Deployment
    that are currently ready.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Discover view** displays a list of services that have been made public and
    have enabled cluster discovery.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drilling down logs from containers belonging to a single Pod is possible using
    the **Logs viewer** functionality.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each clustered application and all Kubernetes resources running in the cluster,
    **Storage view** identifies persistent volume claims.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will go to the next step of accessing Prometheus, Grafana, and Alertmanager
    now that we've enabled all of the required add-ons.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Accessing Prometheus, Grafana, and Alertmanager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We can validate whether Grafana, Prometheus, and Alertmanager are running on
    the cluster before moving on to other steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'Navigate to **Monitoring** under **Namespaces** on the Kubernetes Dashboard,
    and then click **Services**. A list of monitoring services running on the cluster,
    as well as cluster IP addresses, internal endpoints, and ports, will be displayed,
    as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.9 – Validating Grafana, Prometheus, and Alertmanager are running
    on the cluster ](img/Figure_8.09_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.9 – Validating Grafana, Prometheus, and Alertmanager are running on
    the cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'From Kubernetes Dashboard, shown in *Figure 8.9*, we can ensure the following
    components are operational:'
  prefs: []
  type: TYPE_NORMAL
- en: '`prometheus-operator` Pod—The core of the stack, in charge of managing other
    Deployments such as Prometheus servers or Alertmanager servers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`node-exporter` pod—Per physical host (one in this example)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-state-metrics` exporter'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`prometheus-k8s` (replicas: 1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alertmanager-main` (replicas: 1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`grafana` (replicas: 1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Grafana and Prometheus UIs can then be accessible simply by putting the
    service IP and ports into the browser in the format `<IP address>:<port>`. The
    login and password for Grafana will be `admin/admin`.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, Grafana uses port `3000`; so, navigate to `http://localhost:3000`
    in your web browser, and you''ll be able to visit the Grafana interface, which
    is already populated with some interesting dashboards, as we can see here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.10 – Grafana pre-built dashboards ](img/Figure_8.10_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.10 – Grafana pre-built dashboards
  prefs: []
  type: TYPE_NORMAL
- en: 'Grafana comes with Prometheus preinstalled as a data source, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.11 – Grafana/Prometheus data source ](img/Figure_8.11_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.11 – Grafana/Prometheus data source
  prefs: []
  type: TYPE_NORMAL
- en: 'In a similar way, the Prometheus UI can be accessed. There will be no need
    for a username or password. By default, Prometheus uses port `9090` and exposes
    its internal metrics and performance. The Node Exporter Prometheus process runs
    on port `9100`. This exposes the details about the node, including storage space,
    `http://<IP address:9090/metrics` path. You can see an overview of the Prometheus
    UI here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.12 – Prometheus UI ](img/Figure_8.12_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.12 – Prometheus UI
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus will scrape and store data based on the predefined configuration.
    Go to the dashboard to see whether Prometheus has information about the time series
    that this endpoint exposes on the node.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see a list of metrics this server is collecting, use the dropdown next to
    the `node_` that have been collected by Node Exporter can be found in the list.
    The `cpu metric` node, for example, displays the node''s CPU utilization, as illustrated
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13 – Prometheus metrics visualization ](img/Figure_8.13_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.13 – Prometheus metrics visualization
  prefs: []
  type: TYPE_NORMAL
- en: 'ServiceMonitor automatically detects and registers each target in your Prometheus
    configuration, as illustrated here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.14 – Prometheus scrape targets ](img/Figure_8.14_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.14 – Prometheus scrape targets
  prefs: []
  type: TYPE_NORMAL
- en: 'From the Prometheus server interface, the **Alerts** tab displays alerts that
    are created, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.15 – Prometheus Alertmanager ](img/Figure_8.15_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.15 – Prometheus Alertmanager
  prefs: []
  type: TYPE_NORMAL
- en: 'Please refer to the Prometheus community GitHub repository for predefined alert
    rules, at the following link:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack/templates/prometheus/rules-1.14](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack/templates/prometheus/rules-1.14)'
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, we looked at how to quickly deploy a Kubernetes monitoring and
    alerting stack using the Prometheus add-on, which is also easy to expand, alter,
    or migrate to a new set of servers based on the needs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following things should be noted for production deployments:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Long-term storage**—The Prometheus database stores metrics for the previous
    15 days by default. Prometheus doesn''t offer long-term storage of metrics. There
    is no option for backup, data redundancy, trend analysis, data mining, and so
    on.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Authorization and authentication**—There is no server-side authentication,
    authorization, or encryption provided by Prometheus or its components.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no support for vertical/horizontal scalability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We've looked at how to use the Prometheus add-on to enable Kubernetes monitoring
    and alerting, and now, we'll look at how to use the EFK toolset to configure a
    logging, monitoring, and alerting stack.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a logging, monitoring, and alerting stack using the EFK toolset
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In cases where we need to analyze massive volumes of log data collected by
    Pods running many services and applications on a Kubernetes cluster, a centralized,
    cluster-level logging stack could be useful. EFK is the most popular centralized
    logging solution. Elasticsearch is a real-time search engine that supports full-text
    and structured searches, as well as analytics, and is distributed and scalable.
    It''s most commonly used for indexing and searching large amounts of log data.
    Elasticsearch is widely used in conjunction with Kibana, a powerful data visualization
    frontend and dashboard for Elasticsearch. Kibana is a web-based tool that allows
    you to quickly query and get insight into Kubernetes applications by viewing Elasticsearch
    log data and creating dashboards and queries. To gather, transform, and transfer
    log data to the Elasticsearch backend, we''ll use Fluentd, a popular open source
    data collector, to tail container log files, filter and change data, and feed
    it to an Elasticsearch cluster for indexing and storage on our Kubernetes nodes.
    The following diagram depicts what we want to achieve using the EFK toolset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.16 – Centralized logging solution: EFK toolset ](img/Figure_8.16_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8.16 – Centralized logging solution: EFK toolset'
  prefs: []
  type: TYPE_NORMAL
- en: Since EFK isn't available for `arm64` architecture, I'll be using an Ubuntu
    **virtual machine** (**VM**) for this section. The instructions for setting up
    a MicroK8s cluster are the same as in [*Chapter 5*](B18115_05.xhtml#_idTextAnchor070)*,
    Creating and Implementing Updates on Multi-Node Raspberry Pi Kubernetes Clusters*.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are clear on what we want to achieve, we will dive into the steps
    in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Step 1 – Enabling the Fluentd add-on
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll enable the Fluentd add-on in this section, which allows the EFK toolset
    to gather log data, pass it to Elasticsearch for indexing, and then view aggregated
    logs using the Kibana dashboard. Use the following command to enable the Fluentd
    add-on:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: When you enable this add-on, Elasticsearch, Fluentd, and Kibana (the EFK stack)
    will be added to MicroK8s.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command execution output confirms that the EFK add-on has been
    enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.17 – Enabling Fluentd add-on ](img/Figure_8.17_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.17 – Enabling Fluentd add-on
  prefs: []
  type: TYPE_NORMAL
- en: Before moving to the next step, let's verify the add-on has been activated.
  prefs: []
  type: TYPE_NORMAL
- en: 'To do this, use the `microk8s status` command. The following command execution
    output indicates that the Fluentd add-on has been enabled:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.18 – Validating whether the add-on is activated ](img/Figure_8.18_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.18 – Validating whether the add-on is activated
  prefs: []
  type: TYPE_NORMAL
- en: 'All of the services for EFK are active, as shown in the output of the command
    shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.19 – Verifying EFK Pods are running ](img/Figure_8.19_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.19 – Verifying EFK Pods are running
  prefs: []
  type: TYPE_NORMAL
- en: 'We now have all the services of EFK up and running. To access the Kibana dashboard,
    we will need to build a secure channel (as we did for Kubernetes Dashboard) to
    the cluster with the command shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output confirms that port forwarding is successful:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.20 – Creating a secure channel for the Kibana dashboard ](img/Figure_8.20_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.20 – Creating a secure channel for the Kibana dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'The Kibana dashboard should be now available at the following address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: To summarize, we now have a completely functional EFK stack that can be configured.
    The next step is to start defining an index pattern in the Kibana dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: Step 2 – Defining an index pattern
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are going to analyze whether the EFK container can start up logs itself.
    To do that, we'll need to establish an index pattern. A collection of documents
    with similar characteristics is referred to as an index. An index is given a name,
    which is used to refer to it while conducting indexing, searching, updating, and
    deleting operations on the documents it contains.
  prefs: []
  type: TYPE_NORMAL
- en: 'Launch the Kibana dashboard, and you should see Kibana welcome page, as shown
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.21 – Kibana welcome page ](img/Figure_8.21_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.21 – Kibana welcome page
  prefs: []
  type: TYPE_NORMAL
- en: 'Click `logstash-*`), as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.22 – Creating an index pattern ](img/Figure_8.22_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.22 – Creating an index pattern
  prefs: []
  type: TYPE_NORMAL
- en: 'Kibana will then request a field with a time/timestamp that it can use to visualize
    time-series data. This is the `@timestamp` field in our case, as shown in the
    following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.23 – Creating an index pattern with a timestamp field ](img/Figure_8.23_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.23 – Creating an index pattern with a timestamp field
  prefs: []
  type: TYPE_NORMAL
- en: 'Click **Create index pattern**, and it should just take a few minutes now that
    we''ve built the index pattern. You can see the output here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.24 – Index pattern created ](img/Figure_8.24_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.24 – Index pattern created
  prefs: []
  type: TYPE_NORMAL
- en: 'Select the **Discover** option from the left-hand drop-down menu. You should
    see container log events displayed, as shown in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.25 – Discovering data using the index pattern ](img/Figure_8.25_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.25 – Discovering data using the index pattern
  prefs: []
  type: TYPE_NORMAL
- en: The next step is to filter and examine the container startup log events now
    that we've created an index pattern and organized the data.
  prefs: []
  type: TYPE_NORMAL
- en: Step 3 – Filtering and viewing the data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There will be a listing of all log events with fields available for filtering
    on the left-hand side, as illustrated in the following screenshot. You may either
    create a new filter or utilize the `kubernetes.podname` parameter in **Kibana
    Query Language** (**KQL**) to filter events:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.26 – Filtering log events for a particular Pod ](img/Figure_8.26_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.26 – Filtering log events for a particular Pod
  prefs: []
  type: TYPE_NORMAL
- en: The log list is now filtered to show only log events from that particular Pod.
    You can explore any event or filter to see more information.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the Fluent Bit log processor is enabled, it will read, parse, and filter
    the logs of every Pod on the Kubernetes cluster, enriching each entry with the
    following data:'
  prefs: []
  type: TYPE_NORMAL
- en: Pod name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pod **identifier** (**ID**)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container ID
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labels
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Annotations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once all the events are indexed, the alerting configuration of Kibana could
    be used to create rules that detect failure scenarios and then act when those
    criteria are fulfilled.
  prefs: []
  type: TYPE_NORMAL
- en: 'More details on alerting can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://www.elastic.co/guide/en/kibana/current/alerting-getting-started.xhtml](https://www.elastic.co/guide/en/kibana/current/alerting-getting-started.xhtml)'
  prefs: []
  type: TYPE_NORMAL
- en: '`Fluentd` has a lighter version, Fluent Bit, which was created by the same
    team for situations with more limited resources. Functionality-wise, `Fluentd`
    is a log aggregator, while Fluent Bit is just a forwarder. `Fluentd` offers a
    more robust ecosystem, whereas Fluent Bit is more prevalent in IoT devices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'More details on Fluent Bit can be found here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://fluentbit.io/](https://fluentbit.io/)'
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! Using the EFK stack, we have learned how to aggregate all Kubernetes
    container logs and analyze them centrally.
  prefs: []
  type: TYPE_NORMAL
- en: To recap, we looked at some of the most popular monitoring, logging, and alerting
    stack options. The next step is to determine which critical metrics should be
    monitored in order to manage your infrastructure and applications effectively.
  prefs: []
  type: TYPE_NORMAL
- en: Key metrics that need to be monitored
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The rapid adoption of containers in enterprise organizations has provided numerous
    benefits to developers. However, the flexibility and scalability that Kubernetes
    provides in deploying containerized applications have also introduced new complications.
    Keeping track of the health of applications abstracted by containers and then
    abstracted again by Kubernetes can be difficult without the right tools because
    there is no longer a 1-to-1 correlation between an application and the server
    it runs on.
  prefs: []
  type: TYPE_NORMAL
- en: Containerized applications can be spread across multiple environments, and Kubernetes
    is a complicated environment. Monitoring tools should have the capability to collect
    metrics from across a distributed environment and deal with the transient nature
    of containerized resources. Monitoring tools rely on services as their endpoint
    because Pods and their containers are in constant motion and dynamically scheduled.
    Services broadcast an IP address that can be accessed from outside Pods, allowing
    services to communicate in real time as Pods and containers are built and removed.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Kubernetes, there are two levels of monitoring, as outlined here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cluster monitoring**—Monitors the health of a Kubernetes cluster as a whole.
    Helps in checking whether nodes are up to date and running, how many applications
    are running on each node, and how the cluster as a whole is using resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pod monitoring**—Keeps track of issues that affect individual Pods, including
    a Pod''s resource use, application metrics, and metrics linked to replication
    or autoscaling.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we discussed in the preceding sections, Kubernetes-based architecture already
    provides a framework for analyzing and monitoring your applications. You can get
    a comprehensive view of application health and performance with a suitable monitoring
    solution that integrates with Kubernetes' built-in abstractions, even if the containers
    that execute those applications are continually shifting across hosts or scaling
    up and down.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look at some of the key metrics that should be monitored. These
    are listed here.
  prefs: []
  type: TYPE_NORMAL
- en: '**Cluster level**—The following cluster-state metrics can give you a high-level
    picture of your cluster''s current state. They can reveal problems with nodes
    or Pods, alerting you to the risk of a bottleneck or the need to expand up your
    cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 8.2 – Cluster-state metrics ](img/02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 8.2 – Cluster-state metrics
  prefs: []
  type: TYPE_NORMAL
- en: '**Node level**—The following measures give you a high-level picture of a node''s
    health and whether or not the scheduler can schedule Pods on it. When you compare
    resource utilization to resource requests and limits, you may get a better idea
    of whether your cluster has enough resources to handle its workloads and accommodate
    new ones. It''s critical to maintain and track resource utilization across your
    cluster''s levels, especially for your nodes and the Pods that run on them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 8.3 – Node-level metrics ](img/03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 8.3 – Node-level metrics
  prefs: []
  type: TYPE_NORMAL
- en: '**Pod level**—Although a Pod may be functioning, if it is not accessible, this
    means it is not ready to accept traffic. This is normal in some situations, such
    as when a Pod is first launched or when a change to the Pod''s specifications
    is made and deployed. However, if you notice a surge in the number of unavailable
    Pods or Pods that are constantly unavailable, it could suggest a setup issue.
    Keep track of the following metrics to gauge the health of Pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 8.4 – Pod-level metrics ](img/04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 8.4 – Pod-level metrics
  prefs: []
  type: TYPE_NORMAL
- en: '**Container level**—Some of the container metrics that should be tracked to
    assess container health are listed next:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 8.5 – Container metrics ](img/05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 8.5 – Container metrics
  prefs: []
  type: TYPE_NORMAL
- en: '**Storage**—Volumes serve as a crucial abstraction in the Kubernetes storage
    architecture. Containers can request storage resources dynamically via a mechanism
    called volume claims, and volumes can be persistent or non-persistent, as detailed
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 8.6 – Storage metrics ](img/06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 8.6 – Storage metrics
  prefs: []
  type: TYPE_NORMAL
- en: '**Control plane**—The worker nodes and Pods in a cluster are managed by the
    control plane. Here are the control plane components that need to be monitored:'
  prefs: []
  type: TYPE_NORMAL
- en: '**etcd**—Stores configuration information that each node in the cluster can
    use'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**API server**—Validates and configures data for API objects such as Pods,
    services, and replication controllers, among other things'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scheduler**—Manages the use of workloads and the assignment of Pods to available
    nodes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Controller Manager**—A daemon in charge of gathering and sending data to
    the API server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can see more details on these components here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 8.7 – Control-plane metrics ](img/07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 8.7 – Control-plane metrics
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes events
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Kubernetes events are a resource type in Kubernetes that are created automatically
    when other resources'' states change, errors occur, or other messages need to
    be broadcast to the system. Here are various types of events that need to be monitored:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Failed events**—While containers are created on a regular basis, the operation
    can frequently fail; as a result, Kubernetes does not successfully create that
    container. Failed events are frequently associated with image retrieval errors.
    These failures could be caused by typos, insufficient permissions, or upstream
    build failures. Furthermore, nodes can also fail on their own. When these failures
    occur, applications should fall back to functional, remaining nodes, but some
    kind of alerting system is required to determine why the failure occurred. Because
    a failure is a showstopper—that is, your container will not run until it is resolved—you
    should pay close attention to this event type.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Evicted events**—Certain Pods can consume a disproportionate amount of computing
    and memory resources in comparison to their respective runtimes. Kubernetes addresses
    this issue by evicting Pods and reallocating disk, memory, or CPU space elsewhere.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Storage specific events**—Storage within Pods is commonly used by applications
    and workloads. Volumes provided by respective providers store critical content
    that is required by application runtimes. Upon creation, Pods mount these volumes,
    paving the way for successful operation. These events can alert you when storage
    volumes are behaving strangely. Furthermore, a node may not be in good enough
    health to mount a volume. These errors, on the other hand, can make it appear
    as if a Pod is just getting started. However, discovering these events can assist
    you in resolving the underlying issues caused by faulty volume mounting.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`FailedScheduling` event occurring when the Kubernetes scheduler is unable
    to find a suitable node.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`NodeNotReady` event denotes a node that is not ready for Pod scheduling.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For Kubernetes events, metrics and alert criteria that must be monitored are
    listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 8.8 – Kubernetes events metrics ](img/08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 8.8 – Kubernetes events metrics
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To summarize, we've covered key Kubernetes components, as well as the metrics
    and events that can help you track their health and performance over time. We
    have also covered how to collect all of the metrics using built-in Kubernetes
    APIs and utilities, allowing you to gain comprehensive visibility into your container
    infrastructure and workloads.
  prefs: []
  type: TYPE_NORMAL
- en: We looked at Prometheus, Grafana, and Alertmanager as tools for setting up a
    monitoring and alerting stack. We've also looked at how to set up a centralized,
    cluster-level logging stack with the EFK toolset, which can handle massive amounts
    of log data. Finally, we went over the essential indicators that should be watched
    in order to successfully manage your infrastructure and apps.
  prefs: []
  type: TYPE_NORMAL
- en: We'll look at how to develop and deploy a machine learning model using the Kubeflow
    MLOps platform in the next chapter. Kubeflow and MicroK8s deliver reliable and
    efficient operations as well as infrastructure optimization.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a monitoring and alerting stack using the Prometheus, Grafana, and
    Alertmanager tools
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a monitoring and alerting stack using the Prometheus, Grafana, and
    Alertmanager tools
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a monitoring and alerting stack using the Prometheus, Grafana, and
    Alertmanager tools
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a monitoring and alerting stack using the Prometheus, Grafana, and
    Alertmanager tools
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a monitoring and alerting stack using the Prometheus, Grafana, and
    Alertmanager tools
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a monitoring and alerting stack using the Prometheus, Grafana, and
    Alertmanager tools
  prefs: []
  type: TYPE_NORMAL
- en: Configuring a monitoring and alerting stack using the Prometheus, Grafana, and
    Alertmanager tools
  prefs: []
  type: TYPE_NORMAL
