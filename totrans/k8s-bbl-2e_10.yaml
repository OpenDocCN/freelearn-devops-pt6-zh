- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Running Production-Grade Kubernetes Workloads
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行生产级 Kubernetes 工作负载
- en: In the previous chapters, we focused on containerization concepts and the fundamental
    Kubernetes building blocks, such as Pods, Jobs, and ConfigMaps. Our journey so
    far has covered mostly single-machine scenarios, where the application requires
    only one container host or Kubernetes node. For **production-grade** Kubernetes,
    you have to consider different aspects, such as **scalability**, **high availability**
    (**HA**), and **load balancing**, and this always requires **orchestrating** containers
    running on multiple hosts.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在前几章中，我们专注于容器化概念和基本的 Kubernetes 构建模块，如 Pods、Jobs 和 ConfigMaps。到目前为止，我们的旅程主要涵盖了单机场景，其中应用程序仅需要一个容器主机或
    Kubernetes 节点。对于**生产级** Kubernetes，您必须考虑不同的方面，如 **可扩展性**、**高可用性（HA）** 和 **负载均衡**，这总是需要在多个主机上进行容器的**编排**。
- en: Briefly, **container orchestration** is a way of managing multiple containers’
    life cycles in large, dynamic environments—this can include deploying and maintaining
    the desired states for container networks, providing redundancy and HA of containers
    (using external components), scaling up and down the cluster and container replicas,
    automated health checks, and telemetry (log and metrics) gathering. Solving the
    problem of efficient container orchestration at cloud scale is not straightforward—this
    is why Kubernetes exists!
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，**容器编排** 是在大型动态环境中管理多个容器生命周期的一种方式——这可以包括部署和维护容器网络的所需状态，提供容器的冗余和高可用性（使用外部组件），扩展集群和容器副本，自动健康检查以及收集遥测数据（日志和指标）。解决云规模下高效容器编排的问题并不直接——这就是
    Kubernetes 存在的原因！
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Ensuring High Availability and Fault Tolerance on Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上确保高可用性和容错性
- en: What is ReplicationController?
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是复制控制器（ReplicationController）？
- en: What is ReplicaSet?
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是副本集（ReplicaSet）？
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you will need the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，您将需要以下内容：
- en: A Kubernetes cluster deployed. You can use either a local or a cloud-based cluster,
    but in order to fully understand the concepts, we recommend using a multi-node,
    cloud-based Kubernetes cluster.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已部署 Kubernetes 集群。您可以使用本地或基于云的集群，但为了全面理解概念，我们建议使用多节点、基于云的 Kubernetes 集群。
- en: The Kubernetes **command-line interface** (**CLI**) (`kubectl`) installed on
    your local machine and configured to manage your Kubernetes cluster.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在本地机器上安装并配置用于管理 Kubernetes 集群的 Kubernetes **命令行界面（CLI）**（`kubectl`）。
- en: Kubernetes cluster deployment (local and cloud-based) and `kubectl` installation
    were covered in *Chapter 3*, *Installing Your First Kubernetes Cluster*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群部署（本地和基于云）以及在 *第 3 章* *安装您的第一个 Kubernetes 集群* 中介绍的 `kubectl` 安装。
- en: You can download the latest code samples for this chapter from the official
    GitHub repository at [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter10](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter10).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以从官方 GitHub 仓库 [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter10](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter10)
    下载本章的最新代码示例。
- en: Ensuring High Availability and Fault Tolerance on Kubernetes
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上确保高可用性和容错性
- en: First, let’s quickly recap how we define HA and **fault tolerance** (**FT**)
    and how they differ. These are key concepts in cloud applications that describe
    the ability of a system or a solution to be continuously operational for a desirably
    long length of time. From a system end user perspective, the aspect of availability,
    alongside data consistency, is usually the most important requirement.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们快速回顾一下我们如何定义 **高可用性** 和 **容错性（FT）** 以及它们之间的区别。这些是云应用中的关键概念，描述了系统或解决方案持续运行的能力，具有期望的长时间。从系统最终用户的角度来看，可用性方面，以及数据一致性，通常是最重要的要求。
- en: High availability
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高可用性
- en: 'In short, the term *availability* in systems engineering describes the percentage
    of time when the system is fully functional and operational for the end user.
    In other words, it is a measure of system uptime divided by the sum of uptime
    and downtime (which is basically the total time). For example, if, in the last
    30 days (720 hours), your cloud application had 1 hour of unplanned maintenance
    time and was not available to the end user, it means that the availability measure
    of your application is ![](img/B22019_10_001.png). Usually, to simplify this notation
    when designing systems, the availability will be expressed in so-called nines:
    for example, if we say that a system has an availability of five nines, it means
    it is available at least 99.999% of the total time. To put this into perspective,
    such a system can have up to only 26 seconds per month of downtime! These measures
    are often the base indicators for defining **service-level agreements** (**SLAs**)
    for billed cloud services.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，系统工程中的*可用性*描述的是系统在用户端完全功能性和可操作性的时间百分比。换句话说，它是系统正常运行时间与正常运行时间和停机时间总和（即总时间）的比值。例如，如果在过去的30天（720小时）中，你的云应用程序有1小时的计划外维护时间，并且对终端用户不可用，这意味着你的应用程序的可用性指标为![](img/B22019_10_001.png)。通常，在设计系统时，为了简化这个表示，可用性将以所谓的“九”来表示：例如，如果我们说一个系统有五个九的可用性，意味着它至少在99.999%的总时间内可用。换句话说，这样的系统每月最多只能有26秒的停机时间！这些指标通常是定义**服务水平协议**（**SLA**）的基础，这些协议适用于计费的云服务。
- en: The definition of HA, based on that, is relatively straightforward, although
    not precise—a system is highly available if it is operational (available) without
    interruption for long periods of time. Usually, we can say that five nines of
    availability is considered the gold standard of HA.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，高可用性的定义相对直接，尽管不够精确——如果一个系统在长时间内能够不中断地运行（可用），则认为它具有高可用性。通常，我们可以说五个九的可用性是高可用性的黄金标准。
- en: 'Achieving HA in your system usually involves one or a combination of the following
    techniques:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的系统中实现高可用性（HA）通常涉及以下一种或多种技术：
- en: '**Eliminating single points of failure (SPOFs) in the system**. This is usually
    achieved by components’ redundancy.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**消除系统中的单点故障（SPOF）**。这通常通过组件冗余来实现。'
- en: '**Failover setup**, which is a mechanism that can automatically switch from
    the currently active (possibly unhealthy) component to a redundant one.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**故障切换设置**，这是一种可以自动将当前活跃（可能不健康）的组件切换到冗余组件的机制。'
- en: '**Load balancing**, which means managing traffic coming into the system and
    routing it to redundant components that can serve the traffic. This will, in most
    cases, involve proper failover setup, component monitoring, and telemetry.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**负载均衡**，指的是管理流入系统的流量，并将其路由到可以处理流量的冗余组件。这通常会涉及适当的故障切换设置、组件监控和遥测。'
- en: Let’s introduce the related concept of FT, which is also important in distributed
    systems such as applications running on Kubernetes.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们介绍与 FT 相关的概念，它在分布式系统中也非常重要，例如运行在 Kubernetes 上的应用程序。
- en: Fault tolerance
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容错
- en: 'Now, FT can be presented as a complement to the HA concept: a system is fault-tolerant
    if it can continue to be functional and operating in the event of the failure
    of one or more of its components. For example, FT mechanisms like RAID for data
    storage, which distributes data across multiple disks, or load balancers that
    redirect traffic to healthy nodes, are commonly used to ensure system resilience
    and minimize disruptions. Achieving full FT means achieving 100% HA, which, in
    many cases, requires complex solutions actively detecting faults and remediating
    the issues in the components without interruptions. Depending on the implementation,
    the fault may result in a graceful degradation of performance that is proportional
    to the severity of the fault. This means that a small fault in the system will
    have a small impact on the overall performance of the system while serving requests
    from the end user.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，FT 可以作为 HA 概念的补充来展示：如果一个系统在其一个或多个组件发生故障时仍能继续保持功能和运行，那么这个系统就是容错的。例如，像 RAID
    这样的 FT 机制用于数据存储，将数据分布在多个磁盘上，或者负载均衡器将流量重定向到健康的节点，通常用于确保系统的韧性并尽量减少中断。实现完整的 FT 意味着实现100%的
    HA，这在许多情况下需要复杂的解决方案，能够主动检测故障并在不间断的情况下修复组件中的问题。根据实现的不同，故障可能会导致性能的平滑降级，降级程度与故障的严重程度成比例。这意味着系统中的小故障对整体性能的影响较小，同时仍然可以响应终端用户的请求。
- en: HA and FT for Kubernetes applications
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 应用的 HA 和 FT
- en: In previous chapters, you learned about Pods and how Services expose them to
    external traffic (*Chapter 8*, *Exposing Your Pods with Services*). Services are
    Kubernetes objects that provide a stable network address for a set of healthy
    Pods. Internally, inside the Kubernetes cluster, the Service makes Pods addressable
    using virtual IP addresses managed by the `kube-proxy` component on each node.
    Externally, cloud environments typically use a cloud load balancer to expose the
    Service. This load balancer integrates with the Kubernetes cluster through a cloud-specific
    plugin within the `cloud-controller-manager` component. With an external load
    balancer in place, microservices or workloads running on Kubernetes can achieve
    load balancing across healthy Pods on the same or different nodes, which is a
    crucial building block for HA.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，你了解了Pods以及如何通过Services将其暴露给外部流量（*第8章*，*通过Services暴露你的Pods*）。Services是Kubernetes中的对象，它为一组健康的Pods提供一个稳定的网络地址。在Kubernetes集群内部，Service通过每个节点上的`kube-proxy`组件管理的虚拟IP地址使Pods可以被寻址。在外部，云环境通常使用云负载均衡器来暴露Service。这个负载均衡器通过`cloud-controller-manager`组件中的云特定插件与Kubernetes集群集成。通过外部负载均衡器，运行在Kubernetes上的微服务或工作负载可以在同一节点或不同节点上的健康Pods之间实现负载均衡，这是高可用性的一个关键构建模块。
- en: 'Services are required for load balancing requests to Pods, but we haven’t yet
    covered how to maintain multiple replicas of the same Pod object definition that
    are possibly redundant and allocated on different nodes. Kubernetes offers multiple
    building blocks to achieve this goal, outlined as follows:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: Services是请求负载均衡到Pods所必需的，但我们还没有讨论如何维护可能冗余并分配到不同节点上的同一Pod对象定义的多个副本。Kubernetes提供了多个构建模块来实现这一目标，具体如下：
- en: '**A ReplicationController object**—the original form of defining Pod replication
    in Kubernetes.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ReplicationController对象**—是Kubernetes中定义Pod复制的原始形式。'
- en: '**A ReplicaSet object**—the successor to ReplicationController. The main difference
    is that ReplicaSet has support for set-based requirement selectors for Pods.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ReplicaSet对象**—是ReplicationController的继任者。主要的区别是ReplicaSet支持基于集合的Pod选择器。'
- en: The preferred way to manage ReplicaSets is through a Deployment object, which
    simplifies updates and rollbacks.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 管理ReplicaSets的首选方式是通过Deployment对象，它简化了更新和回滚操作。
- en: '**A Deployment object**—another level of abstraction on top of ReplicaSet.
    This provides *declarative* updates for Pods and ReplicaSets, including rollouts
    and rollbacks. It is used for managing *stateless* microservices and workloads.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Deployment对象**—是ReplicaSet之上的另一层抽象。它提供对Pods和ReplicaSets的*声明式*更新，包括发布和回滚。它用于管理*无状态*的微服务和工作负载。'
- en: '**A StatefulSet object**—similar to Deployment but used to manage *stateful*
    microservices and workloads in the cluster. Managing the state inside a cluster
    is usually the toughest challenge to solve in distributed systems design.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**StatefulSet对象**—类似于Deployment，但用于管理集群中的*有状态*微服务和工作负载。在分布式系统设计中，管理集群内的状态通常是最难解决的挑战。'
- en: '**A DaemonSet object**—used for running a singleton copy of a Pod on all (or
    some) of the nodes in the cluster. These objects are usually used for managing
    internal Services for log aggregation or node monitoring.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DaemonSet对象**—用于在集群的所有（或部分）节点上运行Pod的单例副本。这些对象通常用于管理内部Services，如日志聚合或节点监控。'
- en: In the next sections, we will cover the basics of ReplicationController and
    ReplicaSets. The more advanced objects, such as Deployment, StatefulSet, and DaemonSet,
    will be covered in the next chapters.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将介绍ReplicationController和ReplicaSets的基础知识。更高级的对象，如Deployment、StatefulSet和DaemonSet，将在后续章节中讨论。
- en: This chapter covers HA and FT for Kubernetes workloads and applications. If
    you are interested in how to ensure HA and FT for Kubernetes itself, please refer
    to the official documentation at [https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/).
    Please note that in managed Kubernetes offerings in the cloud, such as **Azure
    Kubernetes Service** (**AKS**), Amazon **Elastic Kubernetes Service** (**EKS**),
    or **Google Kubernetes Engine** (**GKE**), you are provided with highly available
    clusters, and you do not need to manage the master nodes yourself.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本章介绍了 Kubernetes 工作负载和应用程序的 HA 和 FT。如果你对如何确保 Kubernetes 本身的 HA 和 FT 感兴趣，请参考官方文档：[https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/)。请注意，在云端的托管
    Kubernetes 服务中，例如 **Azure Kubernetes Service** (**AKS**)，Amazon **Elastic Kubernetes
    Service** (**EKS**)，或 **Google Kubernetes Engine** (**GKE**)，你将获得高度可用的集群，无需自行管理主节点。
- en: What is ReplicationController?
  id: totrans-37
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 ReplicationController？
- en: 'Achieving HA and FT requires providing redundancy of components and proper
    load balancing of incoming traffic between the replicas of components. Let’s take
    a look at the first Kubernetes object that allows you to create and maintain multiple
    replicas of the Pods in your cluster: ReplicationController. Please note that
    we are discussing ReplicationController mainly for historical reasons as it was
    the initial way of creating multiple Pod replicas in Kubernetes. We advise you
    to use ReplicaSet whenever possible, which is basically the next generation of
    ReplicationController with an extended specification API.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 实现高可用性（HA）和故障转移（FT）需要为组件提供冗余，并在组件的副本之间对传入流量进行适当的负载均衡。我们来看一下 Kubernetes 中第一个允许你创建和维护
    Pod 副本的对象：ReplicationController。请注意，我们主要讨论 ReplicationController 是出于历史原因，因为它是
    Kubernetes 中最初用于创建多个 Pod 副本的方式。我们建议你在可能的情况下使用 ReplicaSet，它基本上是 ReplicationController
    的下一代，具有扩展的规格 API。
- en: 'The Controller objects in Kubernetes have one main goal: to observe the current
    and the desired cluster state that is exposed by the Kubernetes API server and
    command changes that attempt to change the current state to the desired one. They
    serve as continuous feedback loops, doing all they can to bring clusters to the
    desired state described by your object templates.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 中的控制器对象有一个主要目标：观察当前和期望的集群状态，这些状态通过 Kubernetes API 服务器暴露，并指挥变更，试图将当前状态更改为期望的状态。它们作为持续反馈循环，尽最大努力将集群带入由你对象模板描述的期望状态。
- en: ReplicationController has a straightforward task—it needs to ensure that a specified
    number of Pod replicas (defined by a template) are running and healthy in a cluster
    at any time. This means that if ReplicationController is configured to maintain
    three replicas of a given Pod, it will try to keep exactly three Pods by creating
    and terminating Pods when needed. For example, right after you create a ReplicationController
    object, it will create three new Pods based on its template definition. If, for
    some reason, there are four such Pods in the cluster, ReplicationController will
    terminate one Pod, and if by any chance a Pod gets deleted or becomes unhealthy,
    it will be replaced by a new, hopefully healthy, one.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicationController 的任务很简单——它需要确保集群中始终有指定数量的 Pod 副本（由模板定义）在运行并处于健康状态。这意味着，如果
    ReplicationController 配置为维护给定 Pod 的三个副本，它将尝试通过创建和终止 Pod 来确保始终保持恰好三个 Pod。例如，在你创建
    ReplicationController 对象后，它将根据模板定义创建三个新的 Pod。如果由于某种原因集群中有四个这样的 Pod，ReplicationController
    会终止一个 Pod；如果某个 Pod 被删除或变得不健康，它将被一个新的、 hopefully 健康的 Pod 替换。
- en: Since a Deployment, which configures a ReplicaSet, is now the recommended method
    for managing replication, we will not cover ReplicationController here. In the
    next section, we will focus on understanding and practicing the ReplicaSet concept.
    A detailed exploration of Deployments will follow in *Chapter 11*, *Using Kubernetes
    Deployments for Stateless Workloads*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 由于现在推荐使用配置了 ReplicaSet 的 Deployment 来管理副本，我们将在此不讨论 ReplicationController。接下来的章节将专注于理解和实践
    ReplicaSet 概念。关于 Deployments 的详细探讨将在 *第 11 章*，《使用 Kubernetes 部署无状态工作负载》中进行。
- en: What is ReplicaSet?
  id: totrans-42
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是 ReplicaSet？
- en: 'Let’s introduce another Kubernetes object: ReplicaSet. This is very closely
    related to ReplicationController, which we have just discussed. In fact, this
    is a **successor** to ReplicationController, which has a very similar specification
    API and capabilities. The purpose of ReplicaSet is also the same—it aims to maintain
    a fixed number of healthy, identical Pods (replicas) that fulfill certain conditions.
    So, again, you just specify a template for your Pod, along with appropriate label
    selectors and the desired number of replicas, and Kubernetes ReplicaSetController
    (this is the actual name of the controller responsible for maintaining ReplicaSet
    objects) will carry out the necessary actions to keep the Pods running.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们介绍另一个 Kubernetes 对象：ReplicaSet。它与我们刚刚讨论的 ReplicationController 密切相关。实际上，ReplicaSet
    是 ReplicationController 的**继任者**，它具有非常相似的规格 API 和功能。ReplicaSet 的目的也是相同的——旨在维护一定数量的健康且相同的
    Pods（副本），以满足特定条件。因此，你只需为 Pod 指定一个模板，并提供合适的标签选择器和所需的副本数量，Kubernetes ReplicaSetController（这是负责维护
    ReplicaSet 对象的控制器的实际名称）将执行必要的操作，确保 Pods 运行。
- en: Before we learn more about ReplicaSet, let us learn the major differences between
    ReplicationController and ReplicaSet in the next section.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入了解 ReplicaSet 之前，让我们在下一节中学习 ReplicationController 和 ReplicaSet 之间的主要区别。
- en: How does ReplicaSet differ from ReplicationController?
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ReplicaSet 与 ReplicationController 有何不同？
- en: 'The differences between ReplicaSet and ReplicationController are summarized
    in the following table:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet 和 ReplicationController 之间的差异总结如下表所示：
- en: '| **Feature** | **ReplicaSet** | **ReplicationController** |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| **特性** | **ReplicaSet** | **ReplicationController** |'
- en: '| Label selectors | Supports set-based selectors (e.g., inclusion/exclusion
    of labels). Allows more complex logic, such as including `environment=test` or
    `environment=dev`, while excluding `environment=prod`. | Only supports equality-based
    selectors (e.g., `key=value`). No advanced label matching. |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 标签选择器 | 支持基于集合的选择器（例如，包含/排除标签）。允许更复杂的逻辑，如包含 `environment=test` 或 `environment=dev`，同时排除
    `environment=prod`。 | 仅支持基于等式的选择器（例如，`key=value`）。不支持高级标签匹配。 |'
- en: '| Integration with other Kubernetes objects | Acts as a foundation for more
    advanced objects like **Deployment** and **HorizontalPodAutoscaler** (**HPA**).
    | Primarily manages Pod replication directly, without such integrations. |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 与其他 Kubernetes 对象的集成 | 作为更高级对象（如**Deployment**和**HorizontalPodAutoscaler**（**HPA**））的基础。
    | 主要直接管理 Pod 的复制，未实现此类集成。 |'
- en: '| Pod update rollout | Managed declaratively through Deployment objects, allowing
    for **staged rollouts** and **rollbacks**. | Managed manually with the now-deprecated
    `kubectl rolling-update` imperative command. |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| Pod 更新发布 | 通过 Deployment 对象声明式管理，支持**分阶段发布**和**回滚**。 | 使用现在已弃用的 `kubectl
    rolling-update` 命令进行手动管理。 |'
- en: '| Future support | A more modern and flexible resource with future-proof features.
    | Expected to be deprecated in the future. |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 未来支持 | 一个更现代且灵活的资源，具备面向未来的功能。 | 预计未来将被弃用。 |'
- en: 'Table 10.1: Differences between ReplicaSet and ReplicationController'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 表 10.1：ReplicaSet 和 ReplicationController 的区别
- en: The bottom line—always choose ReplicaSet over ReplicationController. However,
    you should also remember that using bare ReplicaSets is generally not useful in
    production clusters, and you should use higher-level abstractions such as Deployment
    objects for managing ReplicaSets. We will introduce this concept in the next chapter.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 底线—始终选择 ReplicaSet 而非 ReplicationController。然而，你也应该记住，单独使用 ReplicaSet 在生产集群中通常没有实际意义，你应该使用更高级的抽象，如
    Deployment 对象来管理 ReplicaSet。我们将在下一章介绍这个概念。
- en: In the next section, let us learn about creating and managing ReplicaSet objects.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习如何创建和管理 ReplicaSet 对象。
- en: Creating a ReplicaSet object
  id: totrans-55
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建 ReplicaSet 对象
- en: 'For the following demonstration, we are using a multi-node cluster using `kind`,
    which you have already learned about in *Chapter 3*, *Installing Your First Kubernetes
    Cluster*:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的演示中，我们使用的是一个多节点集群，基于 `kind`，你已经在*第 3 章*《安装你的第一个 Kubernetes 集群》中学过：
- en: '[PRE0]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: First of all, let us create a namespace to park our ReplicaSet resources.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个命名空间来存放我们的 ReplicaSet 资源。
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, let’s take a look at the structure of an `nginx-replicaset.yaml` example
    YAML manifest file that maintains three replicas of an `nginx` Pod, as follows:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下 `nginx-replicaset.yaml` 示例 YAML 清单文件的结构，该文件维护三个 `nginx` Pod 的副本，如下所示：
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'There are three main components of the ReplicaSet specification, as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet 规范有三个主要组件，如下所示：
- en: '`replicas`: Defines the number of Pod replicas that should run using the given
    `template` and matching label `selector`. Pods may be created or deleted in order
    to maintain the required number.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`replicas`：定义应该使用给定 `template` 和匹配标签 `selector` 运行的 Pod 副本数量。可以创建或删除 Pods，以保持所需的副本数量。'
- en: '`selector`: A label selector that defines how to identify Pods that the ReplicaSet
    object owns or acquires. Again, similar to the case of ReplicationController,
    please take note that this may have a consequence of existing bare Pods being
    acquired by ReplicaSet if they match the selector!'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`selector`：一个标签选择器，定义如何识别 ReplicaSet 对象拥有或获取的 Pods。再次提醒，与 ReplicationController
    的情况类似，请注意，如果现有裸 Pods 与选择器匹配，它们可能会被 ReplicaSet 获取！'
- en: '`template`: Defines a template for Pod creation. Labels used in `metadata`
    must match the `selector` label query.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`template`：定义 Pod 创建的模板。`metadata` 中使用的标签必须与 `selector` 标签查询匹配。'
- en: 'These concepts have been visualized in the following diagram:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这些概念已经在下图中进行了可视化：
- en: '![Figure 10.2 – Kubernetes ReplicaSet'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 10.2 – Kubernetes ReplicaSet'
- en: '](img/B22019_10_01.png)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B22019_10_01.png)'
- en: 'Figure 10.1: Kubernetes ReplicaSet'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1：Kubernetes ReplicaSet
- en: As you can see, the ReplicaSet object uses `.spec.template` in order to create
    Pods. These Pods must match the label selector configured in `.spec.selector`.
    Please note that it is also possible to acquire existing bare Pods that have labels
    matching the ReplicaSet object. In the case shown in *Figure 10.1*, the ReplicaSet
    object only creates two new Pods, whereas the third Pod is a bare Pod that was
    acquired.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，ReplicaSet 对象使用 `.spec.template` 来创建 Pods。这些 Pods 必须与 `.spec.selector`
    中配置的标签选择器匹配。请注意，也可能会获取与 ReplicaSet 对象标签匹配的现有裸 Pods。在 *图 10.1* 所示的情况下，ReplicaSet
    对象只创建了两个新的 Pods，而第三个 Pod 是一个被获取的裸 Pod。
- en: 'In the preceding example, we have used a simple, **equality-based** selector
    specified by `spec.selector.matchLabels`. A more advanced, **set-based** selector
    can be defined using `spec.selector.matchExpressions`—for example, like this:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的示例中，我们使用了由 `spec.selector.matchLabels` 指定的简单 **基于相等的** 选择器。也可以使用 `spec.selector.matchExpressions`
    定义更高级的 **基于集合的** 选择器——例如，像这样：
- en: '[PRE3]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This specification would make ReplicaSet still match only Pods with `app=nginx`,
    and `environment=test` or `environment=dev`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 该规范将使 ReplicaSet 仍然只匹配 `app=nginx` 且 `environment=test` 或 `environment=dev`
    的 Pods。
- en: When defining ReplicaSet, `.spec.template.metadata.labels` must match `spec.selector`,
    or it will be rejected by the API.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在定义 ReplicaSet 时，`.spec.template.metadata.labels` 必须与 `spec.selector` 匹配，否则将被
    API 拒绝。
- en: 'Now, let’s apply the ReplicaSet manifest to the cluster using the `kubectl
    apply` command, as follows:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用 `kubectl apply` 命令将 ReplicaSet 清单应用到集群中，如下所示：
- en: '[PRE4]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You can immediately observe the status of your new ReplicaSet object named
    `nginx-replicaset-example` using the following command:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以立即使用以下命令观察名为 `nginx-replicaset-example` 的新 ReplicaSet 对象的状态：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You can use the `kubectl get pods -n rs-ns` command to observe the Pods that
    are managed by the ReplicaSet object. If you are interested, you can use the `kubectl
    describe pod <podId>` command in order to inspect the labels of the Pods and also
    see that it contains a `Controlled By: ReplicaSet/nginx-replicaset-example` property
    that identifies our example ReplicaSet object.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '你可以使用 `kubectl get pods -n rs-ns` 命令观察由 ReplicaSet 对象管理的 Pods。如果你感兴趣，你可以使用
    `kubectl describe pod <podId>` 命令检查 Pods 的标签，并且看到它包含一个 `Controlled By: ReplicaSet/nginx-replicaset-example`
    属性，以标识我们的示例 ReplicaSet 对象。'
- en: When using `kubectl` commands, you can use an `rs` abbreviation instead of typing
    `replicaset`.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用 `kubectl` 命令时，你可以使用 `rs` 缩写来代替输入 `replicaset`。
- en: Now let’s move on to testing the behavior of ReplicaSet in the next section.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们进入下一部分，测试 ReplicaSet 的行为。
- en: Testing the behavior of ReplicaSet
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 测试 ReplicaSet 的行为
- en: 'To demonstrate the agility of our ReplicaSet object, let’s now delete one of
    the Pods that are owned by the `nginx-replicaset-example` ReplicaSet object using
    the following `kubectl delete` command:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示我们 ReplicaSet 对象的灵活性，现在让我们使用以下 `kubectl delete` 命令删除一个由 `nginx-replicaset-example`
    ReplicaSet 对象拥有的 Pod：
- en: '[PRE6]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Now, if you are quick enough, you will be able to see from using the `kubectl
    get pods` command that one of the Pods is being terminated and ReplicaSet is immediately
    creating a new one in order to match the target number of replicas!
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你足够快速，你将能够通过使用 `kubectl get pods` 命令看到其中一个 Pod 正在终止，并且 ReplicaSet 会立即创建一个新的
    Pod，以便匹配目标副本数量！
- en: 'If you want to see more details about events that happened in relation to our
    example ReplicationController object, you can use the `kubectl describe` command,
    as illustrated in the following code snippet:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看与我们示例的 ReplicationController 对象相关的事件的更多细节，可以使用 `kubectl describe` 命令，如下所示：
- en: '[PRE7]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: In this case, the `nginx-replicaset-example-krdrs` Pod is a new Pod that was
    created by the ReplicaSet.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个例子中，`nginx-replicaset-example-krdrs` Pod 是一个由 ReplicaSet 创建的新 Pod。
- en: Now, let’s try something different and create a bare Pod that matches the label
    selector of our ReplicaSet object. You can expect that the number of Pods that
    match the ReplicaSet will be four, so ReplicaSet is going to terminate one of
    the Pods to bring the replica count back to three.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们尝试不同的操作，创建一个与我们 ReplicaSet 对象的标签选择器匹配的裸 Pod。你可以预期，匹配 ReplicaSet 的 Pod
    数量将是四个，因此 ReplicaSet 将终止其中一个 Pod 以将副本数恢复到三个。
- en: Be careful with labels on bare Pods (Pods without a ReplicaSet manager). ReplicaSets
    can take control of any Pod with matching labels, potentially causing them to
    manage your bare Pod unintentionally. Use unique labels for bare Pods to avoid
    conflicts.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 小心裸 Pod（没有 ReplicaSet 管理的 Pod）上的标签。ReplicaSets 可以控制任何具有匹配标签的 Pod，可能会无意中管理你的裸
    Pod。请为裸 Pod 使用唯一的标签，以避免冲突。
- en: 'First, let’s create a simple bare Pod manifest file named `nginx-pod-bare.yaml`,
    as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们创建一个简单的裸 Pod 清单文件，命名为 `nginx-pod-bare.yaml`，如下所示：
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The metadata of `Pod` must have labels matching the ReplicaSet selector. Now,
    apply the manifest to your cluster using the following command:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`Pod` 的 metadata 必须有与 ReplicaSet 选择器匹配的标签。现在，使用以下命令将清单应用到你的集群中：'
- en: '[PRE9]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Immediately after that, check the events for our example ReplicaSet object
    using the `kubectl describe` command, as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 紧接着，使用 `kubectl describe` 命令检查我们示例 ReplicaSet 对象的事件，如下所示：
- en: '[PRE10]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As you can see, the ReplicaSet object has immediately detected that there is
    a new Pod created matching its label selector and has terminated the Pod.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，ReplicaSet 对象已经立即检测到有一个新 Pod 被创建，并且与其标签选择器匹配，并已终止该 Pod。
- en: Similarly, it is possible to remove Pods from a ReplicaSet object by modifying
    their labels so that they no longer match the selector. This is useful in various
    debugging or incident investigation scenarios.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，通过修改 Pod 的标签，使其不再匹配选择器，可以从 ReplicaSet 对象中移除 Pods。这在各种调试或故障排查场景中非常有用。
- en: In the following section, we will learn how ReplicaSet helps with the HA and
    FT of an application.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将学习 ReplicaSet 如何帮助应用程序实现高可用性（HA）和容错（FT）。
- en: Testing HA and FT with a ReplicaSet
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 ReplicaSet 测试 HA 和 FT
- en: To demonstrate the scenario, let us use the previously deployed ReplicaSet `nginx-replicaset-example`.
    However, we will create a Service to expose this application, as follows.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示这个场景，我们将使用之前部署的 ReplicaSet `nginx-replicaset-example`。不过，我们将创建一个 Service
    来暴露这个应用程序，具体如下。
- en: '[PRE11]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Let’s forward the Service as follows for testing purposes:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了测试目的，让我们像下面这样转发 Service：
- en: '[PRE12]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Open another console and verify the application access.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 打开另一个控制台并验证应用程序的访问。
- en: '[PRE13]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: You should get the response with a default NGINX page output.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能得到一个默认的 NGINX 页面输出。
- en: 'Previously we tested deleting the Pod and verified that the ReplicaSet will
    recreate the Pod based on the replica count. In this case, let us remove one of
    the Kubernetes nodes and see the behavior. Before we delete the node, let us check
    the current Pod placement as follows:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 之前我们测试了删除 Pod，并验证了 ReplicaSet 会根据副本数重新创建 Pod。现在，让我们移除一个 Kubernetes 节点并观察其行为。在删除节点之前，先检查当前的
    Pod 分配情况，如下所示：
- en: '[PRE14]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: '[PRE15]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now, let us check the Pod placement and number of replicas.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们检查 Pod 的分配情况和副本数量。
- en: '[PRE16]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: As per the output, the ReplicaSet has already created the desired number of
    Pods on the available nodes.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 根据输出，ReplicaSet 已经在可用节点上创建了所需数量的 Pods。
- en: If your `kubectl port-forward` is still running, you can again verify the application
    access (`curl localhost:8080`) and confirm the availability. Please note that
    for production environments, it is a best practice to integrate monitoring tools
    like **Prometheus** or **Grafana** for real-time health and resource visualization,
    and use **Fluentd** for logging to capture Pod logs to diagnose failures.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的 `kubectl port-forward` 仍然在运行，你可以再次验证应用程序的访问（`curl localhost:8080`）并确认其可用性。请注意，在生产环境中，最佳做法是集成监控工具，如
    **Prometheus** 或 **Grafana**，用于实时健康检查和资源可视化，并使用 **Fluentd** 进行日志记录，捕获 Pod 日志以诊断故障。
- en: Now that we have learned the behavior of ReplicaSet with multiple examples,
    let us learn how to scale ReplicaSet.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们通过多个示例已经了解了ReplicaSet的行为，接下来让我们学习如何扩展ReplicaSet。
- en: Scaling ReplicaSet
  id: totrans-116
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展ReplicaSet
- en: For ReplicaSet, we can do a similar scaling operation as for ReplicationController
    in the previous section. In general, you will not perform manual scaling of ReplicaSets
    in usual scenarios. Instead, the size of the ReplicaSet object will be managed
    by another, higher-level object, such as Deployment.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 对于ReplicaSet，我们可以执行类似于前一节中ReplicationController的扩展操作。通常，在常规场景下，你不会手动扩展ReplicaSet。而是ReplicaSet对象的大小将由另一个更高层的对象（如Deployment）来管理。
- en: 'Let’s first scale up our example ReplicaSet object. Open the `nginx-replicaset.yaml`
    file and modify the `replicas` property to `5`, as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们首先扩展我们的示例ReplicaSet对象。打开`nginx-replicaset.yaml`文件，并将`replicas`属性修改为`5`，如下所示：
- en: '[PRE17]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now, we need to declaratively apply the changes to the cluster state. Use the
    following `kubectl apply` command to do this:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们需要声明性地将更改应用于集群状态。使用以下`kubectl apply`命令来实现：
- en: '[PRE18]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: To see that the number of Pods controlled by the ReplicaSet object has changed,
    you can use the `kubectl get pods` or `kubectl describe rs/nginx-replicaset-example`
    command.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 若要查看ReplicaSet对象控制的Pod数量是否发生变化，可以使用`kubectl get pods`或`kubectl describe rs/nginx-replicaset-example`命令。
- en: You can achieve similar results to the case of ReplicationController using the
    `kubectl scale rs/nginx-replicaset-example --replicas=5` imperative command. In
    general, such imperative commands are recommended only for development or learning
    scenarios.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用`kubectl scale rs/nginx-replicaset-example --replicas=5`这种命令来达到与ReplicationController类似的扩展效果。通常，这种命令只推荐在开发或学习场景中使用。
- en: 'Similarly, if you would like to scale down, you need to open the `nginx-replicaset.yaml`
    file and modify the `replicas` property to `2`, as follows:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，如果你想进行缩容，你需要打开`nginx-replicaset.yaml`文件，并将`replicas`属性修改为`2`，如下所示：
- en: '[PRE19]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Again, declaratively apply the changes to the cluster state. Use the following
    `kubectl apply` command to do this:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 再次声明性地将更改应用于集群状态。使用以下`kubectl apply`命令来实现：
- en: '[PRE20]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: At this point, you can use the `kubectl get pods` or `kubectl describe rs/nginx-replicaset-example`
    command to verify that the number of Pods has been reduced to just `2`.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，你可以使用`kubectl get pods`或`kubectl describe rs/nginx-replicaset-example`命令来验证Pods的数量已减少至`2`。
- en: Using Pod liveness probes together with ReplicaSet
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 将Pod活性探针与ReplicaSet一起使用
- en: Sometimes, you may want to consider a Pod unhealthy and require a container
    restart, even if the main process in the container has not crashed. You already
    learned about probes in *Chapter 8*, *Exposing Your Pods with Services*. We will
    quickly demonstrate how you can use **liveness probes** together with ReplicaSet
    to achieve even greater resilience to failures of containerized components.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，即使容器中的主进程未崩溃，你可能仍希望将Pod视为不健康并需要重启容器。你已经在*第8章*《使用服务暴露Pod》中了解了探针。我们将快速演示如何将**活性探针**与ReplicaSet结合使用，以增强容器化组件故障的容错能力。
- en: 'In our example, we will create a ReplicaSet object that runs `nginx` Pods with
    an additional liveness probe on the main container, which checks whether an `HTTP
    GET` request to the path: `/` responds with a *successful* HTTP status code. You
    can imagine that, in general, your `nginx` process running in the container will
    always be healthy (until it crashes), but that doesn’t mean that the Pod can be
    considered healthy. If the web server is not able to successfully provide content,
    it means that the web server process is running but something else might have
    gone wrong, and this Pod should no longer be used. We will simulate this situation
    by simply deleting the `/index.html` file in the container, which will cause the
    liveness probe to fail.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的示例中，我们将创建一个ReplicaSet对象，运行带有额外活性探针的`nginx` Pods，该探针会检查主容器的路径`/`是否能返回*成功*的HTTP状态码。你可以想象，一般情况下，容器中的`nginx`进程始终会保持健康（直到崩溃），但这并不意味着Pod本身可以被认为是健康的。如果Web服务器无法成功提供内容，说明Web服务器进程运行正常，但可能发生了其他问题，这时Pod就不再适用。我们通过简单地删除容器中的`/index.html`文件来模拟这种情况，这会导致活性探针失败。
- en: 'First, let’s create a YAML manifest file named `nginx-replicaset-livenessprobe.yaml`
    for our new `nginx-replicaset-livenessprobe-example` ReplicaSet object with the
    following content:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们为新的`nginx-replicaset-livenessprobe-example` ReplicaSet对象创建一个名为`nginx-replicaset-livenessprobe.yaml`的YAML清单文件，内容如下：
- en: '[PRE21]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: The highlighted part of the preceding code block contains the liveness probe
    definition and is the only difference between our earlier ReplicaSet examples.
    The liveness probe is configured to execute an HTTP `GET` request to the `/` path
    at port `80` for the container every 2 seconds (`periodSeconds`). The first probe
    will start after 2 seconds (`initialDelaySeconds`) from the container start.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码块中突出显示的部分包含了存活探针定义，这是与我们之前的 ReplicaSet 示例的唯一区别。存活探针被配置为每 2 秒对容器的 `/` 路径和
    `80` 端口执行 HTTP `GET` 请求（`periodSeconds`）。第一次探测将在容器启动后的 2 秒后（`initialDelaySeconds`）开始。
- en: If you are modifying an existing ReplicaSet object, you need to first delete
    it and recreate it in order to apply changes to the Pod template.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在修改现有的 ReplicaSet 对象，你需要先删除它并重新创建，以便应用对 Pod 模板的更改。
- en: 'Now, apply the manifest file to the cluster using the following command:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，使用以下命令将清单文件应用到集群中：
- en: '[PRE22]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Verify that the Pods have been successfully started using the following command:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令验证 Pod 是否已成功启动：
- en: '[PRE23]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Now, you need to choose one of the ReplicaSet Pods in order to simulate the
    failure inside the container that will cause the liveness probe to fail. In the
    case of our example, we will be using the first Pod in the list and removing the
    `index.html` file inside the Pod. To simulate the failure, run the following command.
    This command will remove the `index.html` file served by the `nginx` web server
    and will cause the HTTP `GET` request to fail with a non-successful HTTP status
    code:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你需要选择一个 ReplicaSet Pod，以模拟容器内部导致存活探针失败的故障。在我们的示例中，我们将使用列表中的第一个 Pod，并删除 Pod
    内的 `index.html` 文件。为了模拟故障，运行以下命令。该命令将删除由 `nginx` Web 服务器提供的 `index.html` 文件，并导致
    HTTP `GET` 请求以非成功的 HTTP 状态码失败：
- en: '[PRE24]'
  id: totrans-141
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Inspect the events for this Pod using the `kubectl describe` command, as follows:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `kubectl describe` 命令检查该 Pod 的事件，如下所示：
- en: '[PRE25]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: As you can see, the liveness probe has correctly detected that the web server
    became unhealthy and restarted the container inside the Pod.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，存活探针已正确检测到 Web 服务器变得不健康，并重新启动了 Pod 内的容器。
- en: However, please note that the ReplicaSet object itself did not take part in
    the restart in any way—the action was performed at the Pod level. This demonstrates
    how individual Kubernetes objects provide different features that can work together
    to achieve improved FT. Without the liveness probe, the end user could be served
    by a replica that is not able to provide content, and this would go undetected!
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，请注意，ReplicaSet 对象本身并未以任何方式参与重启——该操作是在 Pod 层面执行的。这展示了各个 Kubernetes 对象如何提供不同的功能，并能够协同工作以实现更好的故障转移。没有存活探针的话，最终用户可能会被一个无法提供内容的副本服务，而这将无法被发现！
- en: Deleting a ReplicaSet object
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除 ReplicaSet 对象
- en: 'Lastly, let’s take a look at how you can delete a ReplicaSet object. There
    are two possibilities, outlined as follows:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，让我们来看一下如何删除 ReplicaSet 对象。有两种可能性，概述如下：
- en: Delete the ReplicaSet object together with the Pods that it owns—this is performed
    by first scaling down automatically.
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除 ReplicaSet 对象及其拥有的 Pod——这一过程首先会自动缩容。
- en: Delete the ReplicaSet object and leave the Pods unaffected.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除 ReplicaSet 对象并保持 Pod 不受影响。
- en: 'To delete the ReplicaSet object together with the Pods, you can use the regular
    `kubectl delete` command, as follows:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除 ReplicaSet 对象及其 Pod，可以使用常规的 `kubectl delete` 命令，如下所示：
- en: '[PRE26]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: You will see that the Pods will first get terminated and then the ReplicaSet
    object is deleted.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到，Pod 会首先被终止，然后 ReplicaSet 对象会被删除。
- en: 'Now, if you would like to delete just the ReplicaSet object, you need to use
    the `--cascade=orphan` option for `kubectl delete`, as follows:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你只想删除 ReplicaSet 对象，则需要为 `kubectl delete` 命令使用 `--cascade=orphan` 选项，如下所示：
- en: '[PRE27]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: After this command, if you inspect which Pods are in the cluster, you will still
    see all the Pods that were owned by the `nginx-replicaset-livenessprobe-example`
    ReplicaSet object. These Pods can now, for example, be acquired by another ReplicaSet
    object that has a matching label selector.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此命令后，如果检查集群中的 Pod，你仍然会看到所有由 `nginx-replicaset-livenessprobe-example` ReplicaSet
    对象拥有的 Pod。这些 Pod 现在可以被其他具有匹配标签选择器的 ReplicaSet 对象获取。
- en: Summary
  id: totrans-156
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 概述
- en: In this chapter, you learned about the key building blocks for providing HA
    and FT for applications running in Kubernetes clusters. First, we explained why
    HA and FT are important. Next, you learned more details about providing component
    replication and failover using ReplicaSet, which is used in Kubernetes in order
    to provide multiple copies (replicas) of identical Pods. We demonstrated the differences
    between ReplicationController and ReplicaSet and explained why using ReplicaSet
    is currently the recommended way to provide multiple replicas of Pods.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，你了解了为在 Kubernetes 集群中运行的应用程序提供高可用性（HA）和容错性（FT）的关键构建块。首先，我们解释了 HA 和 FT
    为什么重要。接着，你了解了如何使用 ReplicaSet 提供组件复制和故障转移的更多细节，ReplicaSet 用于 Kubernetes 中提供相同 Pods
    的多个副本（replicas）。我们演示了 ReplicationController 和 ReplicaSet 之间的区别，并解释了为什么当前推荐使用 ReplicaSet
    来提供多个 Pods 副本。
- en: 'The next chapters in this part of the book will give you an overview of how
    to use Kubernetes to orchestrate your container applications and workloads. You
    will familiarize yourself with concepts relating to the most important Kubernetes
    objects, such as Deployment, StatefulSet, and DaemonSet. Also, in the next chapter,
    we will focus on the next level of abstraction over ReplicaSets: Deployment objects.
    You will learn how to deploy and easily manage rollouts and rollbacks of new versions
    of your application.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 本书接下来的章节将概述如何使用 Kubernetes 来编排容器应用程序和工作负载。你将熟悉与最重要的 Kubernetes 对象相关的概念，如 Deployment、StatefulSet
    和 DaemonSet。此外，在下一章中，我们将重点介绍 ReplicaSet 上的下一个抽象层：Deployment 对象。你将学习如何部署并轻松管理应用程序的新版本的发布和回滚。
- en: Further reading
  id: totrans-159
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'ReplicaSet: [https://kubernetes.io/docs/concepts/workloads/controllers/replicaset](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset
    )'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ReplicaSet: [https://kubernetes.io/docs/concepts/workloads/controllers/replicaset](https://kubernetes.io/docs/concepts/workloads/controllers/replicaset)'
- en: 'ReplicationController: [https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller](https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'ReplicationController: [https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller](https://kubernetes.io/docs/concepts/workloads/controllers/replicationcontroller)'
- en: Join our community on Discord
  id: totrans-162
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 加入我们社区的 Discord 空间，与作者和其他读者讨论：
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
- en: '![](img/QR_Code119001106479081656.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code119001106479081656.png)'
