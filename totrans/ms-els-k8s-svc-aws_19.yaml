- en: '19'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '19'
- en: Developing on EKS
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在EKS上开发
- en: Throughout the book, we’ve looked at how to build EKS clusters and deploy workloads.
    In this chapter, we will look at some ways you can make these activities more
    efficient if you’re a developer or DevOps engineer using automation and CI/CD.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在整本书中，我们已经探讨了如何构建EKS集群和部署工作负载。在本章中，我们将探讨一些方法，帮助开发人员或DevOps工程师通过自动化和CI/CD使这些活动更加高效。
- en: 'In this chapter, we will discuss the tools and techniques you can use to deploy
    and test clusters and workloads natively on AWS, or by using third-party tools.
    We will cover the following:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论你可以用来在AWS上原生部署和测试集群及工作负载的工具和技术，或者使用第三方工具。我们将涵盖以下内容：
- en: Different IT personas
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的IT角色
- en: Using Cloud9 as your integrated development environment
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Cloud9作为你的集成开发环境
- en: Building clusters with EKS Blueprints and Terraform
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用EKS蓝图和Terraform构建集群
- en: Using CodePipeline and CodeBuild to build clusters
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用CodePipeline和CodeBuild构建集群
- en: Using Argo CD, Crossplane, and GitOps to deploy workloads
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Argo CD、Crossplane和GitOps部署工作负载
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'You should have a familiarity with YAML, AWS IAM, and EKS architecture. Before
    getting started with this chapter, please ensure the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该熟悉YAML、AWS IAM和EKS架构。在开始本章之前，请确保以下几点：
- en: You have network connectivity to your EKS cluster API endpoint
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你可以访问到你的EKS集群API端点
- en: The AWS CLI, Docker, and `kubectl` binaries are installed on your workstation
    and have administrator access
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS CLI、Docker和`kubectl`二进制文件已安装在你的工作站，并且你拥有管理员权限
- en: Different IT personas
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不同的IT角色
- en: 'Before we look at the technology that supports development, it’s important
    to consider who in your organization or team will deploy your EKS clusters or
    applications/workloads. The following diagram illustrates IT functional groups
    you might find in a typical enterprise; this is often referred to as the cloud
    operating model and consists of the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们探讨支持开发的技术之前，首先需要考虑谁将负责在你的组织或团队中部署EKS集群或应用/工作负载。下图展示了你可能在典型企业中找到的IT职能组，这通常被称为云操作模型，包括以下内容：
- en: Application engineers that build applications
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建应用的**应用工程师**
- en: Application operations that operate and support applications
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作和支持应用的**应用运维**
- en: Platform engineers that build middleware, networks, databases, and so on
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建中间件、网络、数据库等的**平台工程师**
- en: Platform operations that operate and support infrastructure and middleware
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作和支持基础设施及中间件的**平台运维**
- en: '![Figure 19.1 – Cloud operating model functional architecture](img/Figure_19.01_B18129.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图19.1 – 云操作模型功能架构](img/Figure_19.01_B18129.jpg)'
- en: Figure 19.1 – Cloud operating model functional architecture
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.1 – 云操作模型功能架构
- en: Many organizations now use a DevOps model, where they combine **Application
    Engineering** and **Application Operations** in the developer team, using the
    mantra “*you build it, you run it.*” This can also include platform engineering
    but often traditional IT operational teams for network and databases exist, and
    they must work with the application teams.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 许多组织现在采用DevOps模型，将**应用工程**和**应用运维**结合在开发团队中，秉持“*你构建，你运维*”的理念。这也可以包括平台工程，但通常网络和数据库等传统IT运维团队仍然存在，他们必须与应用团队协作。
- en: In recent years, platform engineering teams have also started appearing to being
    engineering and supporting parts of the infrastructure used by developers/DevOps
    engineers, such as EKS, databases, messaging, and APIs. This team’s mantra is
    “*you code and test and we’ll do all* *the rest.*”
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，平台工程团队也开始出现，他们负责工程和支持开发者/DevOps工程师使用的部分基础设施，例如EKS、数据库、消息系统和API。该团队的口号是“*你编写代码和测试，我们负责所有其余的工作*”。
- en: Which specific model is used and which teams do what is really down to your
    organization. However, for the rest of this section, we will use the term *DevOps
    engineers* to refer to roles that are responsible for application engineering/operations,
    and *platform engineers* for roles that are responsible for the EKS cluster and
    support infrastructure, such as databases or networking.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 具体使用哪种模型，以及各个团队的职责分配，实际上取决于你的组织。然而，在本节的其余部分，我们将使用*DevOps工程师*来指代负责应用工程/运维的角色，*平台工程师*来指代负责EKS集群和支持基础设施（如数据库或网络）的角色。
- en: Let’s explore how we can interact with the AWS environment to build, deploy,
    and test platform and application services.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探讨如何与AWS环境进行交互，以构建、部署和测试平台和应用服务。
- en: Using Cloud9 as your integrated development environment
  id: totrans-25
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Cloud9 is a simple **integrated development environment** (**IDE**) that runs
    on top of EC2 and is similar in nature to other IDEs, such as Microsoft’s Visual
    Studio Code, Eclipse, or PyCharm. It can be used by platform engineers or developers
    alike. While Cloud9 isn’t as extensible as those IDEs, it does have several advantages,
    such as the following:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: It runs on EC2 inside your account/s, which will allow you to communicate with
    private resources, such as private EKS clusters, without network access
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can use AWS Systems Manager Session Manager to connect to your instance,
    which only needs IAM permissions and access to the AWS console
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As it’s an EC2 instance, you can assign a role to your instance with the permissions
    required, and these credentials are automatically refreshed and don’t expire (which
    is useful when you’re provisioning clusters, as this can take some time)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It provides an integrated AWS toolkit to simplify your interaction with resources
    such as S3 and Lambda
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can run Docker containers on your instance and preview HTTP if your container
    or code uses a localhost address on port `8080`, `8081`, or `8082`
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most recently, it has been integrated with Amazon CodeWhisperer, which uses
    machine learning and can generate code for languages such as Python and Java
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: I’ve used Cloud9 extensively throughout this book’s development, as it is simple
    and secure to use, but you can, of course, use any IDE. In the rest of this section,
    we will look at how you can set up and use Cloud9 to develop for EKS.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: Creating and configuring your Cloud9 instance
  id: totrans-34
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We will use the following Terraform code to create a Cloud9 instance, allow
    the user defined within the `myuser_arn` local to use it, and connect it to the
    subnet defined in `subnet_id`. As we have defined the connection type as `CONNECT_SSM`,
    this subnet can be private as long as it has connectivity to the AWS SSM API,
    either through a private endpoint or a NAT gateway:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Note
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Please note that can you modify `instance_type` to whatever you are comfortable
    paying for because, although there is no charge for Cloud9, there is a charge
    for the EC2 instance hosting it.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
- en: Once the Terraform code has completed, you can use the AWS console, browse to
    the **Cloud9** | **Environments** tab, and use the **Open** link to start up your
    EC2 instance and launch the IDE in your browser, using an SSM session. This is
    illustrated in the following screenshot.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 19.2 – Launching a Cloud9 SSM session](img/Figure_19.02_B18129.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: Figure 19.2 – Launching a Cloud9 SSM session
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, Cloud9 will use AWS managed temporary credentials, which have limited
    permissions and can be found at the following link: [https://docs.aws.amazon.com/cloud9/latest/user-guide/security-iam.html#auth-and-access-control-temporary-managed-credentials-supported](https://docs.aws.amazon.com/cloud9/latest/user-guide/security-iam.html#auth-and-access-control-temporary-managed-credentials-supported).
    They won’t allow you to fully interact with the AWS platform. We will create a
    role with `AdministratorAccess`, turn off managed temporary credentials in our
    Cloud9 instance, and then associate this new role with the EC2 instance hosting
    the Cloud9 IDE.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Cloud9将使用AWS管理的临时凭证，这些凭证具有有限的权限，可以通过以下链接查看：[https://docs.aws.amazon.com/cloud9/latest/user-guide/security-iam.html#auth-and-access-control-temporary-managed-credentials-supported](https://docs.aws.amazon.com/cloud9/latest/user-guide/security-iam.html#auth-and-access-control-temporary-managed-credentials-supported)。这些凭证无法让你完全与AWS平台互动。我们将创建一个具有`AdministratorAccess`权限的角色，关闭Cloud9实例中的管理临时凭证，然后将这个新角色与托管Cloud9
    IDE的EC2实例关联。
- en: 'The role description is shown next, and it has an explicit trust with the `ec2.amazonaws.com`
    service. You can follow the process described in the following link to configure
    your Cloud9 instance: [https://catalog.us-east-1.prod.workshops.aws/workshops/c15012ac-d05d-46b1-8a4a-205e7c9d93c9/en-US/15-aws-event/cloud9](https://catalog.us-east-1.prod.workshops.aws/workshops/c15012ac-d05d-46b1-8a4a-205e7c9d93c9/en-US/15-aws-event/cloud9).'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来展示的是角色描述，它与`ec2.amazonaws.com`服务有明确的信任关系。你可以按照以下链接中的过程来配置你的Cloud9实例：[https://catalog.us-east-1.prod.workshops.aws/workshops/c15012ac-d05d-46b1-8a4a-205e7c9d93c9/en-US/15-aws-event/cloud9](https://catalog.us-east-1.prod.workshops.aws/workshops/c15012ac-d05d-46b1-8a4a-205e7c9d93c9/en-US/15-aws-event/cloud9)。
- en: '![Figure 19.3 – An example IAM role](img/Figure_19.03_B18129.jpg)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![图19.3 – 一个示例IAM角色](img/Figure_19.03_B18129.jpg)'
- en: Figure 19.3 – An example IAM role
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图19.3 – 一个示例IAM角色
- en: Note
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: We only add the `AdministratorAccess` policy for simplicity. Ideally, you would
    tailor the Cloud9 permissions to support the least amount of privilege needed.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为简便起见，我们只添加了`AdministratorAccess`策略。理想情况下，你应该根据最小权限原则，定制Cloud9的权限，以满足所需的最低权限。
- en: 'We can verify the role is attached using the following command in a Cloud9
    terminal session:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令在Cloud9终端会话中验证角色是否已附加：
- en: '[PRE1]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We now need to install the necessary tools; as Cloud9 comes with the AWS CLI,
    Python, and Docker, we still need to install `kubectl` and so on. You can install
    these components manually, but AWS provides a handy script as part of its Cloud9
    workshop (in the URL shown previously), so we will use this to install the necessary
    tools, including `kubectl` and AWS **Cloud Development Kit** (**CDK**). The commands
    are shown here:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们需要安装必要的工具；由于Cloud9自带了AWS CLI、Python和Docker，但我们仍然需要安装`kubectl`等工具。你可以手动安装这些组件，但AWS提供了一个方便的脚本，作为Cloud9工作坊的一部分（如前述URL所示），所以我们将使用这个脚本来安装必要的工具，包括`kubectl`和AWS
    **云开发工具包**（**CDK**）。相关命令如下：
- en: '[PRE2]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'We will also install/upgrade `terraform`, as we will use this later on in this
    section, using the following commands:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将安装/升级`terraform`，因为我们稍后将在本节中使用它，安装命令如下：
- en: '[PRE3]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We can also add `eksctl`, which was used in the earlier sections of the book,
    using these commands:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以添加在本书早期章节中使用的`eksctl`，可以通过以下命令进行安装：
- en: '[PRE4]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Finally, we will just set the default region so that all tools that use the
    SDK will use the region we specify:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将设置默认区域，以便所有使用SDK的工具都能使用我们指定的区域：
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Now, we have our Cloud9 instance configured. We will now use it to deploy clusters
    using EKS Blueprints.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的Cloud9实例已经配置完毕。接下来，我们将使用它来通过EKS蓝图部署集群。
- en: Building clusters with EKS Blueprints and Terraform
  id: totrans-59
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用EKS蓝图和Terraform构建集群
- en: In this book, we mainly used `eksctl` to build our clusters and leverage add-ons
    to support simpler upgrades of standard components, such as the VPC CNI plugin
    or kube-proxy. We also deployed additional software such as Prometheus and KEDA
    ([*Chapter 18*](B18129_18.xhtml#_idTextAnchor264)). EKS blueprints provides you
    with a way to build an opinionated cluster, with this operational software already
    deployed. This simplifies the job of the platform of DevOps engineers, and they
    can use blueprints to repeatedly build clusters for different environments and/or
    teams with very little effort.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们主要使用`eksctl`来构建我们的集群，并利用附加组件来简化标准组件的升级，例如VPC CNI插件或kube-proxy。我们还部署了其他软件，如Prometheus和KEDA（[*第18章*](B18129_18.xhtml#_idTextAnchor264)）。EKS蓝图为你提供了一种构建具有预设方案的集群的方法，这些操作软件已经部署好。这简化了DevOps工程师平台的工作，他们可以使用蓝图反复构建适用于不同环境和/或团队的集群，几乎不需要任何额外努力。
- en: EKS Blueprint Clusters are built using AWS CDK, which is a set of libraries
    and constructs that allow you to create and deploy complex CloudFormation templates,
    using standard programming languages such as TypeScript or Python. Recently, AWS
    has released EKS Blueprints for Terraform, and this is what we will use in the
    rest of the section to create a cluster that can be used by our developers to
    deploy their applications.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: EKS Blueprint 集群是使用 AWS CDK 构建的，AWS CDK 是一套库和构造，允许你使用标准编程语言（如 TypeScript 或 Python）创建和部署复杂的
    CloudFormation 模板。最近，AWS 发布了 Terraform 版 EKS Blueprints，我们将在接下来的章节中使用它来创建一个可以供开发者用来部署应用程序的集群。
- en: You can follow a phased approach to developing your cluster configuration. The
    following diagram shows the suggested approach.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照阶段性的方法来开发集群配置。以下图表展示了推荐的方法。
- en: '![Figure 19.4 – The EKS blueprints development life cycle](img/Figure_19.04_B18129.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.4 – EKS 蓝图开发生命周期](img/Figure_19.04_B18129.jpg)'
- en: Figure 19.4 – The EKS blueprints development life cycle
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.4 – EKS 蓝图开发生命周期
- en: In the next section, we will step through each phase of the development life
    cycle as we download, version, and customize our blueprint code.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将逐步走过开发生命周期的每个阶段，下载、版本化并定制我们的蓝图代码。
- en: Customizing and versioning EKS Blueprints for Terraform
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 定制和版本化 Terraform 的 EKS Blueprints
- en: 'The first thing we’re going to do is use our Cloud9 instance to create a Git-compliant
    repository in `CodeCommit` to store our version of the Terraform code. The following
    commands can be used to create the repository, clone it, and create a new branch
    for our work:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们要做的第一件事是使用我们的 Cloud9 实例，在 `CodeCommit` 中创建一个符合 Git 的仓库，以存储我们的 Terraform 代码版本。以下命令可以用来创建仓库、克隆它并为我们的工作创建一个新分支：
- en: '[PRE6]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In our `cluster-tf` directory, we will create a new `.gitignore` file based
    on the template found at [https://github.com/github/gitignore/blob/main/Terraform.gitignore](https://github.com/github/gitignore/blob/main/Terraform.gitignore)
    (you can create your own).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 `cluster-tf` 目录中，我们将基于在 [https://github.com/github/gitignore/blob/main/Terraform.gitignore](https://github.com/github/gitignore/blob/main/Terraform.gitignore)
    找到的模板创建一个新的 `.gitignore` 文件（你也可以创建自己的）。
- en: Setting up the base variables and providers
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置基础变量和提供程序
- en: 'To use the Terraform blueprint modules, we need to configure key Terraform
    resources such as the providers and data sources to use. Let’s start with the
    providers, which are the base “engines” of Terraform, and translate the Terraform
    resources into actual deployed objects in AWS or K8s. The following configuration
    is saved in the `providers.tf` file in our cloned repository directory:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 Terraform 蓝图模块，我们需要配置关键的 Terraform 资源，例如使用的提供程序和数据源。让我们从提供程序开始，它们是 Terraform
    的基础“引擎”，将 Terraform 资源转换为在 AWS 或 K8s 中实际部署的对象。以下配置保存在我们克隆仓库目录中的 `providers.tf`
    文件中：
- en: '[PRE7]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We will also create a `data.tf` file that will get the current AWS credentials,
    Region, and Availability Zones for that Region:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将创建一个 `data.tf` 文件，用于获取当前 AWS 凭证、区域和该区域的可用区：
- en: '[PRE8]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'We will also create a `local.tf` file that maintains the base configuration,
    including the cluster name and version. The cluster name is derived from the repository
    path, but for production usage, you will want to use the `locals int` variables
    and then populate them at build time:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将创建一个 `local.tf` 文件，保持基础配置，包括集群名称和版本。集群名称是从仓库路径中派生的，但对于生产使用，你可能需要使用 `locals
    int` 变量，并在构建时填充它们：
- en: '[PRE9]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'We can now run the following commands to initialize Terraform with the providers
    and push the initial code to our **CodeCommit** repository:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以运行以下命令，用提供程序初始化 Terraform 并将初始代码推送到我们的 **CodeCommit** 仓库：
- en: '[PRE10]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Now that we have the providers and the base configuration stored, we can use
    it to create a VPC and tag it for use with EKS.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经存储了提供程序和基础配置，我们可以使用它来创建一个 VPC 并将其标记为 EKS 使用。
- en: Creating the EKS VPC
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建 EKS VPC
- en: 'Your cluster needs an existing VPC for the EKS cluster. We will create a new
    one with the code shown next, but you can modify the code shown in the *Creating
    the EKS cluster* section to use a pre-existing one and skip this step:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你的集群需要一个现有的 VPC 用于 EKS 集群。我们将使用接下来的代码创建一个新的 VPC，但你也可以修改 *创建 EKS 集群* 部分中的代码，使用一个已有的
    VPC，并跳过这一步：
- en: '[PRE11]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'We will also create an `outputs.tf` file that stores the newly created VPC’s
    ID, which can be used when we create the EKS cluster using the following code:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还将创建一个 `outputs.tf` 文件，用于存储新创建的 VPC 的 ID，该 ID 可以在我们使用以下代码创建 EKS 集群时使用：
- en: '[PRE12]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'We can now validate that the code is correct, create the VPC, and save the
    final code by using the following commands:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以验证代码是否正确，创建VPC，并使用以下命令保存最终代码：
- en: '[PRE13]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Note
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Terraform stores its state in a state file, `terraform.tfstate`. At present,
    this will be stored locally in the repository directory and ignored by Git (because
    of the `.gitignore` file). We will discuss strategies for managing this file later
    on in this chapter.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Terraform将其状态存储在状态文件`terraform.tfstate`中。目前，它将被保存在本地仓库目录中，并被Git忽略（由于`.gitignore`文件）。我们将在本章稍后讨论管理此文件的策略。
- en: Now that we have a new VPC, we will use EKS Blueprints to configure and deploy
    an EKS cluster referencing the new VPC.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个新的VPC，我们将使用EKS蓝图来配置并部署一个引用新VPC的EKS集群。
- en: Creating the EKS cluster
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建EKS集群
- en: 'We will now create an EKS cluster using the Blueprint module; we will use 4.31.0,
    which is the latest at the time of writing. An example configuration, `main.tf`,
    is shown in the following snippet. This will create the cluster in the VPC we
    created previously with just the standard K8s services:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用Blueprint模块创建一个EKS集群；我们将使用4.31.0版本，这是目前写作时的最新版本。以下是`main.tf`文件中的示例配置。这将创建在我们之前创建的VPC中的集群，并且只包含标准的K8s服务：
- en: '[PRE14]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Note
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: In the `eks blueprints` module shown previously, we use the `ref` keyword to
    indicate which version of the blueprint module we will call; this may change depending
    on the blueprints’ release schedule.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前显示的`eks blueprints`模块中，我们使用`ref`关键字来指示我们将调用哪个版本的蓝图模块；这可能会根据蓝图发布计划而有所变化。
- en: 'We need to configure some additional data sources for our cluster deployment
    to work, including one in another region, `eu-east-1`. A sample configuration
    created in the `eks-data.tf` file is shown in the following snippet:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要为集群部署配置一些额外的数据源，包括一个位于其他区域的`eu-east-1`。以下是`eks-data.tf`文件中创建的示例配置：
- en: '[PRE15]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'We also need to configure an additional output in the `eks-output.tf` file,
    shown next, so that we can interact manually with the cluster using our Cloud9
    instance:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还需要在`eks-output.tf`文件中配置一个额外的输出，如下所示，以便可以通过Cloud9实例手动与集群交互：
- en: '[PRE16]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now we have all the configurations in place, we can validate whether the code
    is correct, create the EKS cluster, and save the code by using the following commands:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了所有配置，可以使用以下命令验证代码是否正确，创建EKS集群，并保存代码：
- en: '[PRE17]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Please note that it can take up to 15 minutes to deploy your cluster.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，部署集群可能需要最多15分钟的时间。
- en: Now that we have a working cluster, we can allow access to different users,
    roles, or teams.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个可用的集群，我们可以允许不同的用户、角色或团队访问。
- en: Adding users/teams to your cluster
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将用户/团队添加到您的集群
- en: At present, only the role/identity associated with the credentials you’ve used
    to run the terraform will have access to your clusters. So, we will add a new
    administrator to the cluster and then add a tenant.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，只有与您用于运行terraform的凭证相关的role/identity才能访问您的集群。因此，我们将添加一个新的管理员到集群，然后添加一个租户。
- en: 'In the `main.tf` file, you can add a `map roles` section, which will add a
    single role as an administrator for the cluster:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在`main.tf`文件中，您可以添加一个`map roles`部分，这将为集群添加一个作为管理员的单一角色：
- en: '[PRE18]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Note
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You will need to replace the role/admin with an appropriate role in your account.
    Remember that if the IAM credentials used by Terraform are not included in the
    configuration after its application, Terraform may lose access to the cluster
    to perform K8s API actions, such as modifying the `aws-auth` config map.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要将role/admin替换为帐户中的适当角色。请记住，如果在应用配置后Terraform使用的IAM凭证未包含在配置中，Terraform可能会失去访问集群的权限，从而无法执行K8s
    API操作，例如修改`aws-auth`配置映射。
- en: 'For the tenants/users, we will create a new `locals` file, `locals-team.tf`,
    but again, you will probably want to use a variable. An example is shown next
    for two teams, a platform team and an application team:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 对于租户/用户，我们将创建一个新的`locals`文件`locals-team.tf`，但您可能希望使用变量。以下是针对两个团队（平台团队和应用程序团队）的示例：
- en: '[PRE19]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Note
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You will need to use valid user account ARNs or `[data.aws_caller_identity.current.arn]`.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要使用有效的用户帐户ARN或`[data.aws_caller_identity.current.arn]`。
- en: 'We now need to modify our `main.tf` file for the cluster and add the following
    code snippet, `platform_teams`, to provide cluster admin access to a list of platform
    team users. This will create a new IAM role with cluster access and allow the
    list of users assigned to the platform teams to assume that role and get admin
    access:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在需要修改集群的 `main.tf` 文件，并添加以下代码片段 `platform_teams`，为一组平台团队用户提供集群管理员访问权限。这将创建一个具有集群访问权限的新
    IAM 角色，并允许分配给平台团队的用户列表承担该角色并获得管理员访问权限：
- en: '[PRE20]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'And in the `main.tf` file, we can add also add a tenant DevOps or application
    team with limits, which will also create a namespace:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `main.tf` 文件中，我们还可以添加一个租户 DevOps 或应用程序团队并设置限制，这也将创建一个命名空间：
- en: '[PRE21]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We can now do the regular Terraform `plan` and `apply` commands to deploy these
    changes, grant access to the ARNs listed in the local file, and use our standard
    Git commands to commit the changes to our repository. Examples of the main commands
    are shown here:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以执行常规的 Terraform `plan` 和 `apply` 命令来部署这些更改，授予对本地文件中列出的 ARN 的访问权限，并使用我们的标准
    Git 命令将更改提交到我们的代码库。以下是主要命令的示例：
- en: '[PRE22]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'If you want to see the `kubectl` commands that each team needs to configure,
    you can add the following configuration to the `outputs.tf` file:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想查看每个团队需要配置的 `kubectl` 命令，可以将以下配置添加到 `outputs.tf` 文件：
- en: '[PRE23]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Now that we’ve set up our cluster with the right access for both the platform
    engineering teams, as well as the application development teams, we can deploy
    a number of add-ons.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经为平台工程团队和应用开发团队设置了正确的访问权限，我们可以部署多个插件。
- en: Adding blueprints to your cluster
  id: totrans-123
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 将蓝图添加到您的集群
- en: As we saw in previous chapters, deploying tools such as the AWS Load Balancer
    Controller or Karpenter can take quite a bit of work. Blueprints extend the EKs
    add-on concepts to other tools and can leverage the EKS add-on or ArgoCD to deploy
    this software. The currently supported add-ons can be found at https://aws-ia.github.io/terraform-aws-eks-blueprints/add-ons.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在前面的章节中看到的，部署像 AWS 负载均衡器控制器或 Karpenter 这样的工具可能需要相当多的工作。蓝图将 EKS 插件概念扩展到其他工具，并可以利用
    EKS 插件或 ArgoCD 来部署这些软件。当前支持的插件可以在 [https://aws-ia.github.io/terraform-aws-eks-blueprints/add-ons](https://aws-ia.github.io/terraform-aws-eks-blueprints/add-ons)
    找到。
- en: We will deploy ArgoCD, which is a GitOps deployment tool (discussed in more
    detail in the *Using ArgoCD, Crossplane, and GitOps to deploy workloads* section),
    and then ArgoCD will deploy (most of the) other add-ons.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将部署 ArgoCD，这是一个 GitOps 部署工具（在 *使用 ArgoCD、Crossplane 和 GitOps 部署工作负载* 章节中会更详细讨论），然后
    ArgoCD 将部署（大部分）其他插件。
- en: 'The first thing we will do is create a `locals-blueprints.tf` file in our repository,
    with the contents shown next. This will tell ArgoCD where to look for the different
    helm charts to deploy the add-ons:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先要做的是在我们的代码库中创建一个 `locals-blueprints.tf` 文件，文件内容如下所示。这将告诉 ArgoCD 在哪里查找不同的
    Helm 图表来部署插件：
- en: '[PRE24]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: The next step is to deploy `argodCD` and tell it which add-ons to deploy. Note
    that the blueprint add-on module is opinionated, so some of the add-ons, such
    as the AWS CSI driver, will be deployed directly as EKS add-ons (and will appear
    as add-ons), whereas others will be handled by `argoCD`.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是部署 `argodCD` 并告诉它要部署哪些插件。请注意，蓝图插件模块是有意见的，因此一些插件，如 AWS CSI 驱动程序，将直接作为 EKS
    插件部署（并将作为插件显示），而其他插件将由 `argoCD` 处理。
- en: 'We will deploy `argoCD` and the AWS EBS CSI driver directly, and then Argo
    CD (`argoCD`) will deploy the following:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将直接部署 `argoCD` 和 AWS EBS CSI 驱动程序，然后 Argo CD（`argoCD`）将部署以下内容：
- en: The AWS Load Balancer Controller
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS 负载均衡器控制器
- en: Fluent Bit for logging
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fluent Bit 用于日志记录
- en: The metrics server for standard metrics
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于标准度量的度量服务器
- en: Karpenter for autoscaling
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karpenter 用于自动扩展
- en: Crossplane (discussed later) for infrastructure as code
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Crossplane（稍后讨论）用于基础设施即代码
- en: 'The following code snippet will be used as `blueprints.tf`:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段将作为 `blueprints.tf` 使用：
- en: '[PRE25]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following commands can be used to do the following:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令可以用于执行以下操作：
- en: Deploy the Terraform updates
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署 Terraform 更新
- en: 'Validate that the add-ons in EKS have all been deployed successfully:'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 验证 EKS 中的插件是否都已成功部署：
- en: '[PRE26]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'We can now get the ArgoCD details and access them to review the details of
    the other add-ons, by using the following commands:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以获取 ArgoCD 的详细信息并访问它，以查看其他插件的详细信息，使用以下命令：
- en: '[PRE27]'
  id: totrans-142
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'We can now browse to the ArgoCD URL and log in with the details shown previously
    to see the status of the other add-ons:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在可以浏览到 ArgoCD URL，并使用前面显示的详细信息登录，查看其他插件的状态：
- en: '![Figure 19.5 – The argoCD applications/add-ons status](img/Figure_19.05_B18129.jpg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.5 – ArgoCD 应用程序/附加组件状态](img/Figure_19.05_B18129.jpg)'
- en: Figure 19.5 – The argoCD applications/add-ons status
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.5 – ArgoCD 应用程序/附加组件状态
- en: Note
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Please make sure you have pushed all changes to the `CodeCommit` repository
    and have also destroyed the cluster using the `terraform destroy` command. It
    can take some time to destroy the VPC and the networking components.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保您已经将所有更改推送到 `CodeCommit` 仓库，并使用 `terraform destroy` 命令销毁了集群。销毁 VPC 和网络组件可能需要一些时间。
- en: Modification and upgrades follow a similar pattern; the Terraform code is modified,
    and then the Terraform `plan` and `apply` commands are used to upgrade or reconfigure
    the cluster, node groups, access permission, and blueprints.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 修改和升级遵循类似的模式；修改 Terraform 代码后，使用 Terraform 的 `plan` 和 `apply` 命令来升级或重新配置集群、节点组、访问权限和蓝图。
- en: Now that we have created (and destroyed) our resources manually using Terraform,
    let’s look at how we can use AWS CI/CD tools to automate the testing and deployment
    of your cluster.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经使用 Terraform 手动创建（和销毁）了资源，让我们来看一下如何使用 AWS CI/CD 工具来自动化集群的测试和部署。
- en: Using CodePipeline and CodeBuild to build clusters
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 CodePipeline 和 CodeBuild 来构建集群
- en: We have done the deployment manually so far by running the Terraform `plan`
    and `apply` commands. CodeBuild is an AWS service that acts as a CI build server
    but also deploys our Terraform configuration. CodePipeline automates the end-to-end
    release pipeline and sequences build, test, and deploy phases, based on commits
    to a repository such as CodeCommit.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经通过运行 Terraform 的 `plan` 和 `apply` 命令手动完成了部署。CodeBuild 是 AWS 的一项服务，作为
    CI 构建服务器，同时也部署我们的 Terraform 配置。CodePipeline 自动化了端到端的发布管道，并基于对 CodeCommit 等代码库的提交，依次执行构建、测试和部署阶段。
- en: 'The first thing we need to do is adjust our Terraform code to support the storage
    of state in an S3 bucket. This is necessary, as by default, Terraform will use
    local storage for its state, and as CodeBuild is a transient environment, that
    state will be lost between builds. Terraform relies on a state file to determine
    what needs adding, changing, or removing. We will simply add the backend configuration
    code shown next to the `providers.tf` file we created previously. We don’t need
    to specify any details, as this will be configured dynamically during the Terraform
    `init` phase:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要做的第一件事是调整 Terraform 代码，以支持将状态存储在 S3 存储桶中。这是必要的，因为默认情况下，Terraform 会使用本地存储来存储其状态，而
    CodeBuild 是一个临时环境，因此在构建之间该状态将会丢失。Terraform 依赖于状态文件来确定需要添加、修改或删除的内容。我们只需将下面显示的后端配置代码添加到之前创建的
    `providers.tf` 文件中即可。我们不需要指定任何详细信息，因为这将在 Terraform `init` 阶段动态配置：
- en: '[PRE28]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Note
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Once you’ve modified the code, commit the changes to your repository.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦修改了代码，请将更改提交到您的代码库。
- en: 'The next thing we need to do is add a `buildspec.yml` file to the `root` directory
    of our repository. This file is used by CodeBuild to run the build/deploy commands.
    The `buildspec` file is a specific format and consists of a number of phases:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们需要做的是将 `buildspec.yml` 文件添加到我们代码库的 `root` 目录中。此文件由 CodeBuild 用于运行构建/部署命令。`buildspec`
    文件是一个特定格式的文件，包含多个阶段：
- en: In the *install* phase, install the latest version of **Terraform** and **jq**
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 *安装* 阶段，安装 **Terraform** 和 **jq** 的最新版本。
- en: In the *pre-build* phase, run `terraform init` and configure it to use an S3
    bucket and prefix in a specific region, using environment variables, and also
    run the Terraform `validate` command as a basic test
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 *预构建* 阶段，运行 `terraform init` 并配置它使用 S3 存储桶和特定区域的前缀，使用环境变量，还要运行 Terraform `validate`
    命令作为基本测试。
- en: In the *build* phase, a Terraform `plan`, `apply`, or `destroy` command can
    be run based on the action specified in an environment variable
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 *构建* 阶段，可以根据环境变量中指定的操作，运行 Terraform 的 `plan`、`apply` 或 `destroy` 命令。
- en: 'An example of the `buildspec.yml` file is shown next:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是 `buildspec.yml` 文件的一个示例：
- en: '[PRE29]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Once you’ve modified the code, commit the changes to your repository.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦修改了代码，请将更改提交到您的代码库。
- en: As we now have the Terraform backend configured and a `buildspec` file that
    CodeBuild will use to build/deploy the resources, we need to create and configure
    the build project.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们现在已经配置了 Terraform 后端，并且拥有一个 CodeBuild 用于构建/部署资源的 `buildspec` 文件，我们需要创建并配置构建项目。
- en: Setting up the CodeBuild project
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 CodeBuild 项目
- en: 'Using the AWS console, navigate to the AWS CodeBuild Service and add a new
    build project. Fill in the **Project name** and **Description** fields, as shown
    in the following figure:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 AWS 控制台，导航到 AWS CodeBuild 服务并添加一个新的构建项目。填写 **项目名称** 和 **描述** 字段，如下图所示：
- en: '![Figure 19.6 – CodeBuild project configuration](img/Figure_19.06_B18129.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.6 – CodeBuild 项目配置](img/Figure_19.06_B18129.jpg)'
- en: Figure 19.6 – CodeBuild project configuration
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.6 – CodeBuild 项目配置
- en: 'In the `CodeCommit` repository and branch where the Terraform code and `buildspec`
    files are located, as shown in the following figure:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `CodeCommit` 仓库和分支中，Terraform 代码和 `buildspec` 文件位于其中，如下图所示：
- en: '![Figure 19.7 – CodeBuild source configuration](img/Figure_19.07_B18129.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.7 – CodeBuild 源代码配置](img/Figure_19.07_B18129.jpg)'
- en: Figure 19.7 – CodeBuild source configuration
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.7 – CodeBuild 源代码配置
- en: 'In the first part of the **Environment** panel, define the build environment
    as a standard Linux environment, as shown in the following figure:'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 在**环境**面板的第一部分，将构建环境定义为标准的 Linux 环境，如下图所示：
- en: '![Figure 19.8 – CodeBuild environment configuration](img/Figure_19.08_B18129.jpg)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.8 – CodeBuild 环境配置](img/Figure_19.08_B18129.jpg)'
- en: Figure 19.8 – CodeBuild environment configuration
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.8 – CodeBuild 环境配置
- en: 'Leave the service role to create a new service role and the **Buildspec** panel
    as is (shown next). Then, click on **Create Build Project** at the bottom of the
    screen (not shown):'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 保持服务角色设置为创建新服务角色，并保持 **Buildspec** 面板原样（如下所示）。然后，点击屏幕底部的 **创建构建项目**（未显示）：
- en: '![Figure 19.9 – CodeBuild buildspec configuration](img/Figure_19.09_B18129.jpg)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.9 – CodeBuild buildspec 配置](img/Figure_19.09_B18129.jpg)'
- en: Figure 19.9 – CodeBuild buildspec configuration
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.9 – CodeBuild buildspec 配置
- en: 'You will need to configure the following environment variables, which are used
    by the `buildspec` file:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 您需要配置以下环境变量，这些变量由 `buildspec` 文件使用：
- en: '**TFSTATE_BUCKET** points to an existing S3 bucket name'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TFSTATE_BUCKET** 指向现有的 S3 存储桶名称'
- en: '**TF_ACTION** will perform and **apply -auto-approve**, but this could be changed
    to a **destroy** or **plan** action'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TF_ACTION** 将执行并 **apply -auto-approve**，但可以更改为 **destroy** 或 **plan** 操作'
- en: '`cluster/cluster-tf/terraform.tfstate` value'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster/cluster-tf/terraform.tfstate` 的值'
- en: '**TFSTATE_REGION** points to the correct region'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TFSTATE_REGION** 指向正确的区域'
- en: '![Figure 19.10 – CodeBuild environment variables](img/Figure_19.10_B18129.jpg)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.10 – CodeBuild 环境变量](img/Figure_19.10_B18129.jpg)'
- en: Figure 19.10 – CodeBuild environment variables
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.10 – CodeBuild 环境变量
- en: Once you have configured the environment variables, click on **Create** **Build
    Project**.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 配置好环境变量后，点击 **创建** **构建项目**。
- en: Note
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The build project service role created for the project will need to have the
    relevant IAM permissions added to it to allow the Terraform code to create the
    resources.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 为项目创建的构建项目服务角色需要添加相关的 IAM 权限，以允许 Terraform 代码创建资源。
- en: 'We should also add the service role used explicitly by the code build to the
    `map_role` section in our `main.tf` code, as shown next:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该将代码构建中明确使用的服务角色添加到 `main.tf` 代码中的 `map_role` 部分，如下所示：
- en: '[PRE30]'
  id: totrans-188
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Note
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Replace the `service-role` name with the one your CodeBuild project uses, and
    commit your changes to the repository.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 将 `service-role` 名称替换为您的 CodeBuild 项目使用的名称，并提交您的更改到仓库。
- en: Now, we have built a project pointing to our repository and branch with a specific
    `buildspec.yml` file, which provides the commands we need to deploy the Terraform
    configuration.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经创建了一个指向我们的仓库和分支的项目，并且有一个特定的 `buildspec.yml` 文件，它提供了我们部署 Terraform 配置所需的命令。
- en: '![Figure 19.11 – The CodeBuild Start build dropdown](img/Figure_19.11_B18129.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.11 – CodeBuild 启动构建下拉菜单](img/Figure_19.11_B18129.jpg)'
- en: Figure 19.11 – The CodeBuild Start build dropdown
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.11 – CodeBuild 启动构建下拉菜单
- en: Once the build starts, you can look at the logs and see any errors, but it will
    eventually be complete, and then you can review the build history. If you look
    at the example shown next, you can see it took just over 30 minutes to deploy
    Terraform, and it completed successfully.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦构建开始，您可以查看日志并查看任何错误，但它最终会完成，然后您可以查看构建历史。如果查看下图所示的示例，您可以看到部署 Terraform 仅花费了
    30 分钟多一点，并且成功完成。
- en: '![Figure 19.12 – The CodeBuild Build history screen](img/Figure_19.12_B18129.jpg)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.12 – CodeBuild 构建历史记录屏幕](img/Figure_19.12_B18129.jpg)'
- en: Figure 19.12 – The CodeBuild Build history screen
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.12 – CodeBuild 构建历史记录屏幕
- en: If we look in the S3 bucket, we can see the prefix we defined in the `TFSTATE_KEY`
    environment variable and the `terraform.tfstate` file.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看 S3 存储桶，我们可以看到我们在 `TFSTATE_KEY` 环境变量中定义的前缀和 `terraform.tfstate` 文件。
- en: '![Figure 19.13 – The S3 Terraform state file](img/Figure_19.13_B18129.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.13 – S3 Terraform 状态文件](img/Figure_19.13_B18129.jpg)'
- en: Figure 19.13 – The S3 Terraform state file
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.13 – S3 Terraform 状态文件
- en: In order to trigger the build job, we need to either click on the **Start build**
    button or use the CodeBuild API. Next, we will look at how we can use CodePipeline
    to trigger the build on a code change.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 为了触发构建任务，我们需要点击 **开始构建** 按钮，或使用 CodeBuild API。接下来，我们将看看如何使用 CodePipeline 在代码更改时触发构建。
- en: Note
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You should delete the Terraform-created resource before progressing, either
    manually or by changing the build job `TF_ACTION` to `destroy -auto-approve` and
    rerunning the build job.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续之前，你应该删除 Terraform 创建的资源，可以手动删除，也可以通过将构建任务的 `TF_ACTION` 改为 `destroy -auto-approve`
    然后重新运行构建任务来删除。
- en: Setting up CodePipeline
  id: totrans-203
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 CodePipeline
- en: 'When we set up CodePipeline, we will configure two stages – a *source* stage
    that references our CodeCommit repository with the Terraform and `buildspec` files,
    and a *build* stage that references our CodeBuild project. An example is shown
    in the following screenshot:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们设置 CodePipeline 时，我们将配置两个阶段——一个 *源* 阶段，引用我们的 CodeCommit 仓库，其中包含 Terraform
    和 `buildspec` 文件，和一个 *构建* 阶段，引用我们的 CodeBuild 项目。以下截图展示了一个示例：
- en: '![Figure 19.14 – The CodePipeline stages](img/Figure_19.14_B18129.jpg)'
  id: totrans-205
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.14 – CodePipeline 阶段](img/Figure_19.14_B18129.jpg)'
- en: Figure 19.14 – The CodePipeline stages
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.14 – CodePipeline 阶段
- en: 'We will configure our source stage with the CodeCommit repository and the branch
    details we will use for our code, and we will leave the default change detection
    and output artifacts. This means that when we make a change (commit), we will
    trigger a CloudWatch event that will be used in the next stage. An example of
    the CodeCommit configuration is shown next:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将配置源阶段，使用我们的 CodeCommit 仓库和我们将用于代码的分支详细信息，并保留默认的更改检测和输出工件。这意味着当我们做出更改（提交）时，我们将触发一个
    CloudWatch 事件，并在下一阶段使用它。以下是 CodeCommit 配置的示例：
- en: '![Figure 19.15 – A CodePipeline source stage configuration snippet](img/Figure_19.15_B18129.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.15 – 一个 CodePipeline 源阶段配置片段](img/Figure_19.15_B18129.jpg)'
- en: Figure 19.15 – A CodePipeline source stage configuration snippet
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.15 – 一个 CodePipeline 源阶段配置片段
- en: 'We then need to configure our build stage to point to our existing CodeBuild
    project in the correct region. An example of the CodeBuild configuration is shown
    next:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们需要配置我们的构建阶段，使其指向我们在正确区域中的现有 CodeBuild 项目。以下是 CodeBuild 配置的示例：
- en: '![Figure 19.16 – A CodePipeline build stage configuration snippet](img/Figure_19.16_B18129.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.16 – 一个 CodePipeline 构建阶段配置片段](img/Figure_19.16_B18129.jpg)'
- en: Figure 19.16 – A CodePipeline build stage configuration snippet
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.16 – 一个 CodePipeline 构建阶段配置片段
- en: 'Now when we make a commit, CodePipeline detects it and triggers CodeBuild to
    run the build project we created previously. We can see in the example next that
    the commit ID and message are shown as the trigger:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当我们进行提交时，CodePipeline 会检测到它并触发 CodeBuild 运行我们之前创建的构建项目。我们可以看到下面的示例中，提交 ID
    和消息被显示为触发器：
- en: '![Figure 19.17 – A successful pipeline run](img/Figure_19.17_B18129.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.17 – 一个成功的管道运行](img/Figure_19.17_B18129.jpg)'
- en: Figure 19.17 – A successful pipeline run
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.17 – 一个成功的管道运行
- en: Note
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: As the source code is now generated by CodePipeline and in the Terraform code,
    we will use the filepath of the repository and see a cluster built with the name
    of `src` (which is the name of the directory generated by CodePipeline). We should
    change the way Terraform generates the cluster name using a variable or local.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 由于源代码现在由 CodePipeline 生成，并且在 Terraform 代码中，我们将使用仓库的文件路径，并看到一个名为 `src`（这是 CodePipeline
    生成的目录名称）的集群被构建。我们应该使用变量或本地值来改变 Terraform 生成集群名称的方式。
- en: Now that we have had a quick review of using CodePipeline and CodeBuild to build
    our cluster based on changes to our code, let’s see how we can use ArgoCD and
    Crossplane to deploy EKS workloads in a similar manner.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经快速回顾了如何使用 CodePipeline 和 CodeBuild 根据代码的更改构建我们的集群，接下来我们来看如何使用 ArgoCD 和
    Crossplane 以类似的方式部署 EKS 工作负载。
- en: Using ArgoCD, Crossplane, and GitOps to deploy workloads
  id: totrans-219
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 ArgoCD、Crossplane 和 GitOps 部署工作负载
- en: In the previous section, we used CodePipline to deploy changes to our AWS environment
    based on a commit and a CodePipline configuration.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们使用 CodePipeline 根据提交和 CodePipeline 配置将更改部署到我们的 AWS 环境。
- en: '**GitOps** is a way of implementing **continuous deployment** (**CD**) to deploy
    both a containerized application and infrastructure but with a focus on self-service
    and developer experience. This means that the developer can use the Git repository
    to not only store, version, test, and build their code but also do the same for
    their infrastructure as code, deploying both things together.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '**GitOps** 是实现 **持续部署**（**CD**）的一种方式，用于同时部署容器化应用程序和基础设施，但更侧重于自服务和开发人员体验。这意味着开发人员不仅可以使用
    Git 仓库来存储、版本控制、测试和构建他们的代码，还可以对他们的基础设施代码进行同样的操作，同时部署两者。'
- en: We will use two open source projects in this chapter – **ArgoCD**, which is
    a deployment tool that will continually poll our application repository to look
    for changes, and the **K8s API** to deploy them. Crossplane allows us to use a
    custom Kubernetes resource to build infrastructure resources that support our
    application like a database. ArgoCD can use Helm to deploy and modify (patch)
    K8s resources or Kustomize. **Kustomize** allows you to easily customize K8s manifest
    files and can also be used directly by the **kubectl** tool. The architecture
    used is shown next.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将使用两个开源项目——**ArgoCD**，这是一个部署工具，它会持续轮询我们的应用程序仓库以查找变化，以及**K8s API**来部署它们。Crossplane
    允许我们使用自定义的 Kubernetes 资源来构建支持我们应用程序的基础设施资源，如数据库。ArgoCD 可以使用 Helm 来部署和修改（补丁）K8s
    资源或 Kustomize。**Kustomize** 使你能够轻松定制 K8s 清单文件，并且也可以直接通过 **kubectl** 工具使用。使用的架构如下所示。
- en: '![Figure 19.18 – GitOps architecture](img/Figure_19.18_B18129.jpg)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.18 – GitOps 架构](img/Figure_19.18_B18129.jpg)'
- en: Figure 19.18 – GitOps architecture
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.18 – GitOps 架构
- en: We will use the cluster we created using the Terraform BluePrint, which already
    has ArgoCD installed and running, so we will start with the ArgoCD repository
    configuration.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用通过 Terraform BluePrint 创建的集群，该集群已安装并运行 ArgoCD，因此我们将从 ArgoCD 仓库配置开始。
- en: Setting up our application repository
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置我们的应用程序仓库
- en: We will create and clone a new CodeCommit repository called `myapp`, using the
    same commands shown in the *Customizing and versioning EKS Blueprints for Terraform*
    section, to create and clone the repository into our Cloud9 instance.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将创建并克隆一个名为 `myapp` 的新 CodeCommit 仓库，使用在 *为 Terraform 定制和版本控制 EKS 蓝图* 部分中显示的相同命令，将仓库创建并克隆到我们的
    Cloud9 实例中。
- en: 'We also should install Kustomize locally in our environment for local testing,
    using the following commands:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还应该在本地环境中安装 Kustomize 进行本地测试，使用以下命令：
- en: '[PRE31]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Now that we have the repository and the **Kustomize** tool installed, we can
    set up the general structure. We will use the pause container image and adjust
    the namespace, replica count, and memory request size based on the environment.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经安装了仓库和 **Kustomize** 工具，可以设置一般结构。我们将使用暂停容器镜像，并根据环境调整命名空间、副本数和内存请求大小。
- en: 'We will use two manifest files, which, once created, should only be changed
    when resources are added or deleted. The `namespace.yaml` file will define the
    namespace; an example is shown here:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用两个清单文件，这些文件一旦创建，只有在添加或删除资源时才需要更改。`namespace.yaml` 文件将定义命名空间；示例如下：
- en: '[PRE32]'
  id: totrans-232
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'The `deployment.yaml` file will define the deployment for the pause container.
    An example is shown here:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '`deployment.yaml` 文件将定义暂停容器的部署。示例如下：'
- en: '[PRE33]'
  id: totrans-234
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'We will now create the `base` directory and `kustomise.yaml` file that will
    reference the preceding templates, and also do a dry run of the deployment using
    the `kubectl create -k` command. These commands are shown here:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将创建 `base` 目录和 `kustomize.yaml` 文件，这些文件将引用前面的模板，并使用 `kubectl create -k`
    命令进行部署的干运行。命令如下所示：
- en: '[PRE34]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'We’ve discussed the namespace and deployment file, but the `kustomize.yaml`
    file is also used by Kustomize to understand what resources it needs to deploy
    or modify (patch). An example is shown next:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经讨论了命名空间和部署文件，但 `kustomize.yaml` 文件也被 Kustomize 用来了解它需要部署或修改（补丁）哪些资源。示例如下：
- en: '[PRE35]'
  id: totrans-238
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'As this file is created in the base directory, it simply references the two
    manifest files with no amendments. We will now create two overlays that adjust
    the values of these files for the non-production and production environments:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 由于此文件是在基础目录中创建的，它仅引用两个没有修改的清单文件。接下来我们将创建两个覆盖文件，分别调整这些文件在非生产和生产环境中的值：
- en: '[PRE36]'
  id: totrans-240
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'The `kustomize.yaml` file for non-production is shown next and will adjust
    the namespace and `non-production-` prefix to all the resources:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 非生产环境的 `kustomize.yaml` 文件如下所示，它将调整命名空间以及 `non-production-` 前缀应用到所有资源：
- en: '[PRE37]'
  id: totrans-242
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'It also references a `deployment.yaml` file in the local directory, which is
    shown next, increases the replica count in the base template to `1`, and also
    adds new limits and requests:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 它还引用了本地目录中的 `deployment.yaml` 文件，该文件将基模板中的副本数增加到 `1`，并添加了新的限制和请求：
- en: '[PRE38]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'When we run the `kubectl create -k` command, these changes will be merged with
    the base manifests and deployed. The following commands will deploy and verify
    our customizations for non-production:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们运行 `kubectl create -k` 命令时，这些更改将与基础清单合并并部署。以下命令将部署并验证我们针对非生产环境的自定义内容：
- en: '[PRE39]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: We can now replicate the configuration into the `./overlays/production` directory,
    changing the prefix and namespace to `production`, the limits and request to `2Gi`,
    and the number of replicas to `3`. We can now commit these changes to our repository,
    and we know that if we run the `Kustomize` command from either the production
    or non-production `overlays` directories, we will get slightly different configurations
    for each environment.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以将配置复制到 `./overlays/production` 目录，修改前缀和命名空间为 `production`，将限制和请求更改为 `2Gi`，副本数更改为
    `3`。我们现在可以将这些更改提交到我们的仓库，并且我们知道，如果从生产或非生产的 `overlays` 目录运行 `Kustomize` 命令，我们将为每个环境获得略有不同的配置。
- en: The next step is to configure ArgoCD to deploy these resources.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是配置 ArgoCD 来部署这些资源。
- en: Setting up the ArgoCD application
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 ArgoCD 应用程序
- en: '**ArgoCD** uses the *application* concept, which represents a Git repository.
    Depending on the configuration of the application, ArgoCD will poll that repository
    and, in our case, use Kustomize to add, change, or delete resources.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '**ArgoCD** 使用 *应用程序* 概念，代表一个 Git 仓库。根据应用程序的配置，ArgoCD 将轮询该仓库，在我们的情况下，使用 Kustomize
    添加、修改或删除资源。'
- en: 'ArgoCD doesn’t support AWS IAM roles, so it will use SSH credentials to poll
    the repository. So, we need to configure SSH credentials for a CI/CD user that
    has permission to access the `codecommit` repository. We will use the instructions
    shown at this link: [https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-ssh-unixes.html](https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-ssh-unixes.html)
    to create an SSH key, and add it to a user with CodeCommit privileges. Once we
    have the SSH key ID, we can do the following:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: ArgoCD 不支持 AWS IAM 角色，因此它将使用 SSH 凭证来轮询仓库。所以，我们需要为具有访问 `codecommit` 仓库权限的 CI/CD
    用户配置 SSH 凭证。我们将使用以下链接中的说明：[https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-ssh-unixes.html](https://docs.aws.amazon.com/codecommit/latest/userguide/setting-up-ssh-unixes.html)
    来创建 SSH 密钥，并将其添加到具有 CodeCommit 权限的用户中。一旦我们拥有 SSH 密钥 ID，我们可以执行以下操作：
- en: Install and configure the ArgoCD client
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装并配置 ArgoCD 客户端
- en: Add a secret for ArgoCD to use to connect to the repository
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为 ArgoCD 添加一个秘密，用于连接到仓库
- en: Add our application and check the deployment
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 添加我们的应用程序并检查部署
- en: 'The following commands will install the ArgoCD client:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将安装 ArgoCD 客户端：
- en: '[PRE40]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Next, we will configure the necessary environment variables to connect to our
    environment; examples are shown next, but you should add details relevant to your
    environment:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将配置必要的环境变量以连接到我们的环境；以下是示例，但你应该根据自己的环境添加相关细节：
- en: '[PRE41]'
  id: totrans-258
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We can now add our repository and SSH keys to ArgoCD using the following command:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用以下命令将仓库和 SSH 密钥添加到 ArgoCD：
- en: '[PRE42]'
  id: totrans-260
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We can set up our application to use the repository and private key to deploy
    the resources. We will point it to the non-production overlay so that it will
    use the Kustomize configuration located there:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以设置应用程序，使用仓库和私钥来部署资源。我们将其指向非生产叠加层，以便它使用位于该位置的 Kustomize 配置：
- en: '[PRE43]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: If we look at the Argo CD UI, we can see the app is healthy and the components
    have been deployed, and ArgoCD will continue to keep them in sync as we make changes
    to the underlying CodeCommit repository.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们查看 Argo CD 的 UI，我们可以看到应用程序是健康的，组件已经部署，并且 ArgoCD 将继续同步它们，因为我们对底层的 CodeCommit
    仓库进行了更改。
- en: '![Figure 19.19 – The myapp application status in ArgoCD](img/Figure_19.19_B18129.jpg)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![图 19.19 – ArgoCD 中 myapp 应用程序的状态](img/Figure_19.19_B18129.jpg)'
- en: Figure 19.19 – The myapp application status in ArgoCD
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19.19 – ArgoCD 中 myapp 应用程序的状态
- en: Now, we have a working application that will be continually deployed by Argo
    CD. We can see how we add infrastructure resources to the same repository and
    have them provisioned by Crossplane.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有一个可以持续由 Argo CD 部署的应用程序。我们可以看到如何将基础设施资源添加到同一仓库，并让 Crossplane 为其提供服务。
- en: Adding AWS infrastructure with Crossplane
  id: totrans-267
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Crossplane 添加 AWS 基础设施
- en: Throughout this book, we saw how we can add K8s resources and use K8s controllers,
    such as the AWS Load Balancer Controller, to create AWS resources such as a network
    or application load balancer. Crossplane can be seen as a generic controller for
    AWS resources.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，我们展示了如何添加 K8s 资源并使用 K8s 控制器，如 AWS 负载均衡器控制器，来创建 AWS 资源，如网络负载均衡器或应用负载均衡器。Crossplane
    可以看作是 AWS 资源的通用控制器。
- en: 'We will use the cluster we created with Blueprints but replace the Crossplane
    deployment with the latest version. So, we will install helm and then use it to
    deploy the Crossplane charts:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用我们通过 Blueprints 创建的集群，但用最新版本替换 Crossplane 部署。因此，我们将安装 helm，然后使用它来部署 Crossplane
    图表：
- en: '[PRE44]'
  id: totrans-270
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Note
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: You may need to delete the `Crossplane-system` namespace before deploying.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署之前，您可能需要删除`Crossplane-system`命名空间。
- en: Now that we have installed the latest version of Crossplane, we need to configure
    the provider and its associated permissions.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经安装了最新版本的 Crossplane，我们需要配置提供程序及其相关权限。
- en: Setting up our Crossplane AWS providers
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设置我们的 Crossplane AWS 提供程序
- en: 'As Crossplane will create resources in AWS, it requires a role/permission to
    do this. We will start by creating an IRSA role, mapping it to our cluster, and
    assigning it the admin role. The commands for this are shown here:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 Crossplane 将在 AWS 中创建资源，它需要一个角色/权限来执行此操作。我们将从创建一个 IRSA 角色开始，将其映射到我们的集群，并赋予它管理员角色。相关命令如下所示：
- en: '[PRE45]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Now, we have a role that trusts our cluster’s OIDC provider and has permission
    to provision AWS resources. Next, we need to configure the Crossplane deployment
    to use it. This can be done using the following manifest to configure the provider
    and the controller:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有了一个信任我们集群的 OIDC 提供程序并具有创建 AWS 资源权限的角色。接下来，我们需要配置 Crossplane 部署来使用它。可以使用以下清单来配置提供程序和控制器：
- en: '[PRE46]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'We can deploy the AWS provider using the following commands:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令部署 AWS 提供程序：
- en: '[PRE47]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Once the provider is *healthy*, we can finish the configuration by adding a
    provider configuration and defining the credential insertion method as IRSA. This
    is one of the differences of the `upbound` AWS provider – it uses a different
    API and the IRSA source key:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦提供程序是*健康*的，我们可以通过添加提供程序配置并将凭证插入方法定义为 IRSA 来完成配置。这是 `upbound` AWS 提供程序的区别之一——它使用不同的
    API 和 IRSA 源密钥：
- en: '[PRE48]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We can deploy this manifest file with the following command:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令部署此清单文件：
- en: '[PRE49]'
  id: totrans-284
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'As we enabled debug logging, we can look at the logs of the provider to confirm
    that all the configurations and AWS permissions are in place with the following
    commands:'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们启用了调试日志记录，可以使用以下命令查看提供程序的日志，以确认所有配置和 AWS 权限是否已正确设置：
- en: '[PRE50]'
  id: totrans-286
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Note
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: For a production configuration, you should disable debug logging, as it is very
    verbose and generates a lot of data.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 对于生产配置，您应该禁用调试日志记录，因为它非常冗长，并且会生成大量数据。
- en: Creating infrastructure resources
  id: totrans-289
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建基础设施资源
- en: 'Now that we have a working Crossplane AWS provider, we can actually provision
    an AWS resource. We will configure an S3 bucket with some basic configuration.
    The following manifest will create an S3 bucket called `myapp-Crossplane-bucket637678`
    and use the AWS provider we created in the previous step:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经有了一个工作中的 Crossplane AWS 提供程序，我们实际上可以配置一个 AWS 资源。我们将配置一个带有一些基本配置的 S3 桶。以下清单将创建一个名为`myapp-Crossplane-bucket637678`的
    S3 桶，并使用我们在上一步创建的 AWS 提供程序：
- en: '[PRE51]'
  id: totrans-291
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'We can deploy and verify the bucket using the following commands:'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用以下命令来部署并验证桶：
- en: '[PRE52]'
  id: totrans-293
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'This manifest can be added to our application repository and the relevant `kustomize.yaml`
    files modified. This now means that, as a DevOps engineer or developer, we can
    configure not only an application but also any supporting infrastructure. If you
    want to use ArgoCD to deploy a Crossplane resource, please refer to this link:
    https://docs.Crossplane.io/v1.10/guides/argo-cd-Crossplane/.'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 此清单可以添加到我们的应用程序仓库，并修改相关的 `kustomize.yaml` 文件。这意味着，作为 DevOps 工程师或开发人员，我们不仅可以配置应用程序，还可以配置任何支持的基础设施。如果您想使用
    ArgoCD 部署 Crossplane 资源，请参阅此链接：https://docs.Crossplane.io/v1.10/guides/argo-cd-Crossplane/。
- en: While this is a long chapter, I have only touched the surface of developing
    for EKS, but hopefully, you have enough information to allow you to explore further!
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这是一个较长的章节，但我只是触及了开发 EKS 的表面，但希望您已经掌握了足够的信息，可以进一步探索！
- en: In this section, we looked at how we can develop on EKS, use a variety of AWS
    services and open source tools to automate our cluster builds, and deploy and
    test our applications. We’ll now revisit the key learning points from this chapter.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了如何在 EKS 上开发，使用多种 AWS 服务和开源工具来自动化集群构建、部署和测试应用。现在，我们将回顾本章的关键学习点。
- en: Summary
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we started by considering that there are multiple personas
    that need to develop on EKS, from traditional developers to DevOps or platform
    engineers. Each of these roles needs similar but different things to do their
    job, so it is really important to consider your operating model when looking at
    EKS development.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们首先考虑了需要在 EKS 上进行开发的多种角色，从传统开发者到 DevOps 或平台工程师。这些角色需要类似但不同的需求来完成工作，因此在进行
    EKS 开发时，考虑操作模式是非常重要的。
- en: Next, we looked at how you can use an IDE to develop your infrastructure/application
    code and how AWS Cloud9 provides a simple and secure interface to do this on EKS.
    We then built a `CodeCommit` repository, and deploying it using the Terraform
    commands. This created a complete EKS cluster, in a new VPC, with a set of applications
    and add-ons automatically configured.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们了解了如何使用 IDE 开发基础设施/应用代码，以及 AWS Cloud9 如何提供一个简单且安全的界面来在 EKS 上执行这些操作。然后我们创建了一个
    `CodeCommit` 仓库，并使用 Terraform 命令部署它。这创建了一个完整的 EKS 集群，位于新的 VPC 中，并自动配置了一系列应用和插件。
- en: We then looked at how platform/DevOps engineers can automate the deployment/testing
    of the EKS cluster using a `buildspec.yaml` file, and we automated this process
    using `CodeCommit` branch. Additionally, we looked at how DevOps engineers or
    developers can use ArgoCD/Kustomize to automate the customization and deployment
    of K8s manifest files.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们探讨了平台/DevOps 工程师如何使用 `buildspec.yaml` 文件自动化部署/测试 EKS 集群，我们通过 `CodeCommit`
    分支实现了此过程的自动化。此外，我们还探讨了 DevOps 工程师或开发者如何使用 ArgoCD/Kustomize 自动化 K8s 清单文件的自定义和部署。
- en: Finally, we looked at how we can incorporate AWS infrastructure resources into
    our application repository, by using Crossplane and creating an S3 bucket in AWS
    using a K8s manifest and custom resource.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们探讨了如何通过使用 Crossplane 将 AWS 基础设施资源集成到我们的应用程序仓库中，并通过 K8s 清单和自定义资源在 AWS 中创建一个
    S3 存储桶。
- en: In the final chapter, we will look at how to troubleshoot common EKS problems.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后一章中，我们将讨论如何排查常见的 EKS 问题。
- en: Further reading
  id: totrans-303
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: 'Using Cloud9 in headerless mode:'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在无头模式下使用 Cloud9：
- en: https://aws.amazon.com/blogs/devops/how-to-run-headless-front-end-tests-with-aws-cloud9-and-aws-codebuild/
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: https://aws.amazon.com/blogs/devops/how-to-run-headless-front-end-tests-with-aws-cloud9-and-aws-codebuild/
- en: 'Getting started with EKS blueprints for Terraform:'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开始使用 Terraform 的 EKS 蓝图：
- en: '[https://aws-ia.github.io/terraform-aws-eks-blueprints/getting-started/](https://aws-ia.github.io/terraform-aws-eks-blueprints/getting-started/)'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://aws-ia.github.io/terraform-aws-eks-blueprints/getting-started/](https://aws-ia.github.io/terraform-aws-eks-blueprints/getting-started/)'
- en: 'Creating a secure AWS CI/CD pipeline:'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建安全的 AWS CI/CD 管道：
- en: https://aws.amazon.com/blogs/devops/setting-up-a-secure-ci-cd-pipeline-in-a-private-amazon-virtual-private-cloud-with-no-public-internet-access/
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: https://aws.amazon.com/blogs/devops/setting-up-a-secure-ci-cd-pipeline-in-a-private-amazon-virtual-private-cloud-with-no-public-internet-access/
- en: 'GitOps on AWS:'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 AWS 上使用 GitOps：
- en: '[https://aws.amazon.com/blogs/containers/gitops-model-for-provisioning-and-bootstrapping-amazon-eks-clusters-using-Crossplane-and-argo-cd/](https://aws.amazon.com/blogs/containers/gitops-model-for-provisioning-and-bootstrapping-amazon-eks-clusters-using-crossplane-and-argo-cd/)'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://aws.amazon.com/blogs/containers/gitops-model-for-provisioning-and-bootstrapping-amazon-eks-clusters-using-Crossplane-and-argo-cd/](https://aws.amazon.com/blogs/containers/gitops-model-for-provisioning-and-bootstrapping-amazon-eks-clusters-using-crossplane-and-argo-cd/)'
- en: 'Part 5: Overcoming Common EKS Challenges'
  id: totrans-312
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第五部分：克服常见的 EKS 挑战
- en: The goal of this fifth section is to provide more details on troubleshooting
    common EKS issues.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的目标是提供更多关于排查常见 EKS 问题的细节。
- en: 'This section has the following chapter:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 本节包括以下章节：
- en: '[*Chapter 20*](B18129_20.xhtml#_idTextAnchor331)*, Troubleshooting Common Issues*'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第 20 章*](B18129_20.xhtml#_idTextAnchor331)*，排查常见问题*'
