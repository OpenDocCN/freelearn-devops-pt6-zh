- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Supporting DevOps Processes with Observability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter will discuss the use of Grafana in two different aspects of the
    technology industry – **software delivery** and **platform operations**.
  prefs: []
  type: TYPE_NORMAL
- en: We will briefly introduce you to the **DevOps life cycle** as valuable foundational
    knowledge. Using this framework, we will guide you through the value of Grafana
    in each phase to enrich the software development process in your organization.
    We encourage you to spend time understanding where bottlenecks are in this process
    and focus resources on the most appropriate phase for your team or organization.
  prefs: []
  type: TYPE_NORMAL
- en: Platform operations are typified by using third-party applications. This removes
    about half of the DevOps life cycle, as those stages are conducted by a third
    party. You will be introduced to the considerations you should make for using
    Grafana during the deployment and operation of several types of platforms. We
    will look at collecting data from data collection tools in an observability platform
    and consider best practices around disaster planning for the failure of this business-critical
    system. We will look at the particular needs of the operators and users of platforms
    that provide **continuous integration** (**CI**) or **continuous delivery/deployment**
    (**CD**) capabilities to an organization, as monitoring these platforms can be
    challenging. We will discuss resources available to monitor databases, in-memory
    data stores, message buses, and web servers, covering how to install them efficiently
    and how these common tools have publicly available dashboards in Grafana to use.
    Finally, we will have a quick look at how this same pattern of monitoring platforms
    is applicable for some security tools.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter will handle technical concepts but there are no requirements to
    have experience with individual tools, and the chapter should be accessible to
    anyone, regardless of background.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the DevOps life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Grafana for fast feedback during the development life cycle
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Grafana to monitor infrastructure and platforms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing the DevOps life cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we explain what the DevOps life cycle is, let’s consider the history
    of Agile, DevOps, DevSecOps, and platform engineering a little.
  prefs: []
  type: TYPE_NORMAL
- en: 'Iterative development practices were used as early as the late 1950s, but in
    the 1990s, several development methods were introduced as a reaction to development
    practices that were seen as heavyweight, micromanaged, highly regulated, and with
    a high risk of project failure. These new methods included **rapid application
    development** (**RAD**), **Scrum**, **extreme programming**, and **feature-driven
    design** (**FDD**). These all originated before the Agile Manifesto, but they
    are now known as agile practices. According to the Agile Manifesto, published
    in 2001, we prefer the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Individuals and interactions over processes and tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working software over comprehensive documentation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Customer collaboration over contract negotiation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Responding to change over following a plan
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This indicates that, while there is value in the items on the right, we value
    the items on the left more.
  prefs: []
  type: TYPE_NORMAL
- en: Agile practices evolved from development practices, and they are focused on
    development teams, although there are a lot of crossovers with operational practices.
    These manifesto notions drove a lot of interest in practices such as test-driven
    development, CI, CD, and many others.
  prefs: []
  type: TYPE_NORMAL
- en: In the early 2000s, concerns around the separation of development practices
    and operational practices were highlighted (although these concerns were also
    raised through the 1980s and 1990s). These concerns coalesced in 2009 with the
    first *DevOps Days* conference. DevOps does not articulate a central philosophy
    such as Agile, but it suggests practices and measures that are intended to speed
    the delivery of working software to customers. A lot of these practices revolve
    around having developers, testers, and operators collaborate more closely, often
    by bringing them together in the same team. Similarly, development practices such
    as using version control systems (for example, Git) are adopted so operational
    concerns such as system configuration can become part of the shared understanding
    of a whole software system.
  prefs: []
  type: TYPE_NORMAL
- en: 'DevOps has several branches, extensions, and concepts. Here are some of them
    for those who are interested in reading further: **ArchOps**, **site reliability
    engineering** (**SRE**), **DevSecOps**, **DataOps**, **12-factor apps** or **15-factor
    apps**, **infrastructure as code** (**IaC**), **configuration as code** (**CaC**),
    and **GitOps**.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A quote from Amazon CTO Werner Vogels back in 2006 became a bit of a rallying
    cry for the DevOps movement: “*You build it, you run it*.” This has a lot of merit.
    Having the team who designed and wrote a product also be responsible for its operation
    should mean that incidents are resolved quicker and customer feedback can be heard
    and responded to. Teams can be more agile! When managed well and in the right
    organization, this can be a very effective way to operate. However, as the analysis
    by Matthew Skelton and Manuel Pais in *Team Topologies* ([https://web.devopstopologies.com/index.html#anti-types](https://web.devopstopologies.com/index.html#anti-types))
    shows, many anti-patterns can appear and lead to dysfunction in an organization.
    This approach can also lead to a significant cognitive load for development teams,
    which makes organizations less able to respond to change.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You might ask why we include this history when we are explaining what the DevOps
    life cycle is. The reason is to caution you that this life cycle is a tool and,
    in most organizations, a collection of processes; while they do have value, they
    should not be valued more than individuals and interactions. The way that teams
    tasked with managing a customer-facing software system will interact with an observability
    platform will differ significantly from a team tasked with managing the platform
    in support of the organization’s goals. With this caution given, let’s look at
    the DevOps life cycle as it gives us a good framework to discuss the many aspects
    of using an observability platform through the life cycle:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.1 – The DevOps life cycle](img/B18277_14_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.1 – The DevOps life cycle
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: There’s isn’t a clear definition of DevOps or DevSecOps. The DevOps life cyle
    itself covers development and operations while the security aspect wraps around
    all of that (and more), as shown in *Figure 14**.1*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s walk through each phase of this life cycle:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Code**: This is where new code is written in line with the specification
    given during the planning phase'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Build**: This phase is where new code is built'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Test**: New code is tested in various ways during this phase'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Release**: The code is verified as ready to be deployed to production in
    this phase; any final checks or assurances will be performed here'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deploy**: The code is deployed to a production environment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Operate**: This phase is a continuous phase; the latest deployed release
    is run in a production environment'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitor**: Any data collected from the release that is currently operating
    in production is gathered, as well as any feedback or user research, and is collated
    together to be used in the next planning phase'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Plan**: During this phase, the team plans what future iterations of the product
    will contain'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security**: This is a continuous concern for the team in a DevSecOps approach
    and is the responsibility of all members of the team'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have seen the DevOps life cycle, let’s consider how we can use Grafana
    tools during each phase of this cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Using Grafana for fast feedback during the development life cycle
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will consider how to use Grafana tools through each stage
    of the DevOps life cycle. Developing software can be risky and expensive, and
    observability platforms can also be expensive. Therefore, using the data from
    an observability platform to reduce the risks and expense of developing software
    is a great investment. We’ll start with the *code* phase of the life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Code
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To use Grafana in the DevOps life cycle, the system must produce useful data
    that can be used to understand the state of the system. To that end, the first
    act during the *code* phase of the life cycle is to *instrument* the system. Depending
    on the type of system we are working on, the method of producing data may look
    different:'
  prefs: []
  type: TYPE_NORMAL
- en: A **software application** would be instrumented by adding libraries or SDKs
    that produce data in a format agreed with the team(s) who collects this data.
    In some situations, this can even be achieved by the injection of instrumentation
    into the application, which can happen during the *deploy* stage of the life cycle.
    Organizations need to be clear on where this responsibility lies.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **cloud infrastructure** or **cloud platform** component would be instrumented
    by collecting data from the vendor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **local infrastructure** or **local platform** component would be instrumented
    by collecting data in a format supported by the vendor of the component.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a lot of systems, this may be all that is needed. However, there are times
    when an organization needs custom data from a system. Adding such instrumentation
    falls squarely in the *code* phase of the life cycle. However, when considering
    such activities, it is important to also ensure that the *plan* and *test* phases
    are considered. This can be achieved through activities such as agreeing on a
    data format and field definitions and implementing the code in a way that it can
    be tested in future iterations of the product (for example, domain-orientated
    observability).
  prefs: []
  type: TYPE_NORMAL
- en: The final area in which Grafana can help during the coding process is by being
    run directly against code as it is developed. Most, if not all developers, will
    run their code locally before it is committed to a version control repository.
    As Grafana is open source, it is very easy to implement a local development environment
    that produces and collects observability telemetry; we provided an example of
    this kind of environment when we explored live data in *Chapters 3*, *4*, *5,*
    and *6*. This wealth of information can feed directly back into the coding process
    as it happens.
  prefs: []
  type: TYPE_NORMAL
- en: The next phase of the life cycle is the *build* phase. We will skip over this
    as we deal with monitoring builds in a lot more detail when we talk about monitoring
    CI/CD platforms in the next section of this chapter. Let’s talk about the *test*
    phase next.
  prefs: []
  type: TYPE_NORMAL
- en: Test
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *test* phase can cover a lot of different test types. While tests are typically
    managed by the CI/CD platform, such as the use of a testing framework or static
    analysis tools, the most common form of feedback in Grafana is to monitor the
    CI/CD platform itself. An additional approach for organizations or teams who want
    to track more information is to output time series data from the CI/CD platform
    into a **time series database** (**TSDB**). These kinds of custom approaches can
    often become like a complex Rube Goldberg machine, so we would caution you to
    be very mindful of what the value is to the organization, and we recommend that
    you research the market in case a more suitable product is available.
  prefs: []
  type: TYPE_NORMAL
- en: As the *test* phase moves into end-to-end tests, tools such as k6 really come
    into play (we discussed this in [*Chapter 13*](B18277_13.xhtml#_idTextAnchor239)).
    Writing great repeatable tests for tools in this space can also offer a very valuable
    ability to run them during the *deploy* phase of the life cycle to confirm that
    the new code has been successfully deployed.
  prefs: []
  type: TYPE_NORMAL
- en: The *release* phase encompasses everything between completing testing and releasing
    code to customers. This often covers activities such as gaining approvals for
    the deployment from stakeholders or assurance teams. Let’s have a look at how
    Grafana can help.
  prefs: []
  type: TYPE_NORMAL
- en: Release
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s start discussing using Grafana for the *release* phase with a brief warning:
    many tools on the market may offer a better fit for organizations and teams, so
    we recommend that organizations do some research if they are having problems with
    their release processes.'
  prefs: []
  type: TYPE_NORMAL
- en: Perhaps the biggest feature of Grafana that enables a smooth release step is
    the ability to show whether a new iteration of a product complies with the **service-level
    objectives** (**SLOs**) and **service-level agreements** (**SLAs**) for the product.
    Showing these metrics from a new iteration, especially when the product has been
    put under load by a tool such as k6, is a very powerful way to say that the new
    iteration behaves as expected.
  prefs: []
  type: TYPE_NORMAL
- en: The other feature that may be of interest to some teams is the ability to automatically
    build dashboards that contain HTML widgets. This can be used to automatically
    assemble a release dashboard with links to various artifacts such as test reports,
    tickets for included features, and similar.
  prefs: []
  type: TYPE_NORMAL
- en: The operational phases of the life cycle are the most associated with Grafana.
    Let’s start looking at these with the *deploy* phase, in which code is deployed
    into a production environment ready for customers to access.
  prefs: []
  type: TYPE_NORMAL
- en: Deploy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The *deploy* phase will see a lot of changes occur, and the details of using
    Grafana will differ depending on how the system is deployed:'
  prefs: []
  type: TYPE_NORMAL
- en: Where an application is deployed to a Kubernetes cluster, Pods will be scheduled
    for termination, while new Pods using the newer version will be started. We might
    see Pods responsible for database updates scheduled, and various other aspects.
    When used as the repository for all telemetry from a Kubernetes cluster, Grafana
    can be used to visualize the deployment process in a way that suits the deployment
    team, from prebuilt dashboards to a custom dashboard specifically designed for
    a specific application deployment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where applications are deployed directly to an operating system rather than
    a containerized environment, Grafana still offers detailed monitoring, with prebuilt
    dashboards for operating systems, common languages, web servers, databases, in-memory
    data stores, and many other tools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These approaches provide **white box monitoring** of a deployment; a lot of
    organizations will also implement **black box monitoring** of the application
    during a deployment. Grafana can help here as well. By using **Grafana OnCall**
    to receive messages from an availability monitoring tool such as the Prometheus
    blackbox exporter, k6, or Pingdom, this stream of data can also be monitored during
    a deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is best practice to generate annotations when a deployment happens, which
    can be done via the API. Here is an example of an annotation added to a deployment
    of the OpenTelemetry Collector that caused an incident:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 14.2 – Annotations in action](img/B18277_14_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 14.2 – Annotations in action
  prefs: []
  type: TYPE_NORMAL
- en: As the screenshot shows, Grafana will display contextual information about deployments
    on any visualization that has the option switched on. Annotations appear as a
    line on the chart and show information when hovered over; this contextual information
    can be tagged.
  prefs: []
  type: TYPE_NORMAL
- en: 'At their heart, CD platforms are code execution platforms, which means that
    any action that can be coded can be performed by a CD platform. We just talked
    about monitoring a deployment visually using a dashboard. This approach is great
    when deployments happen infrequently. When deployments occur much more frequently,
    it can be valuable to invest time in writing stages of a deployment where the
    state of the application being deployed is monitored. Loki, Mimir, and Tempo all
    offer query endpoints, which can be used to run queries as part of the scripted
    CD job. Effectively, this offloads the need to watch a dashboard to the CD pipeline,
    and rollback steps can be defined if the deployment fails. Some common examples
    of this use are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring the error rate seen in the application logs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checking whether login actions are successful. This would usually be tied to
    a smoke test to ensure that login events occur.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Checking whether communication with downstream services is affected.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If these checks were to fail, the deployment could be quickly rolled back using
    automated procedures. This approach significantly reduces the **mean time to recovery**
    (**MTTR**) for such common issues and ensures that engineers can be focused on
    more valuable tasks during a deployment.
  prefs: []
  type: TYPE_NORMAL
- en: The gold standard for leveraging the tools provided by Grafana is to also deploy
    any updates to the dashboards used for a service with Terraform during the same
    deployment window as the code deployment. Adopting this practice allows for an
    easily repeatable process, moving from local development work through testing
    and into a production environment.
  prefs: []
  type: TYPE_NORMAL
- en: While exciting, the *deploy* phase is not the phase where code is in *normal*
    operation; that phase is the *operate* phase. Let’s look at this phase next.
  prefs: []
  type: TYPE_NORMAL
- en: Operate
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The *operate* phase is where the product is live in front of customers. The
    most important aspect of this phase is ensuring customers are getting a great
    service. This can be achieved by monitoring SLOs and SLAs, checking errors that
    may occur, responding to incidents, and helping customers in their use of the
    product. Grafana is primarily a tool that is used through the *operate* phase
    of the life cycle, so most tools in Grafana are targeted toward this phase. Some
    key components that will be used by all teams who use Grafana are **dashboards**
    and **alerts**. The ability to see how a user is interacting with a product is
    also very valuable to operational teams, such as customer experience or customer
    support teams.
  prefs: []
  type: TYPE_NORMAL
- en: We discussed in [*Chapter 9*](B18277_09.xhtml#_idTextAnchor183) how **Grafana
    Alerting** and **Grafana Incident** can integrate with many systems. This capability
    is very helpful in creating a detailed incident response system – for example,
    by linking Grafana with ServiceNow so the creation, updating, and closing of incident
    tickets can be partially or fully automated, even with capabilities to collect
    chat communications to reduce the time needed to write up what happened during
    an incident for reporting.
  prefs: []
  type: TYPE_NORMAL
- en: We talked about using **Grafana Frontend Observability** in [*Chapter 12*](B18277_12.xhtml#_idTextAnchor231);
    when correctly implemented with distributed tracing, this tool allows customer-facing
    teams to reconstruct an individual user’s session. This allows these teams to
    work quickly with the customer to understand the frontend problem they are experiencing
    and translate that into a trace path through the system to identify the source
    of the issue and get it to the right team quickly, with easy-to-digest information
    on what happened.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider how to use Grafana to monitor the system.
  prefs: []
  type: TYPE_NORMAL
- en: Monitor
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Like the *operate* phase. the *monitor* phase is the phase in which using Grafana
    can really shine. The two biggest challenges are knowing what telemetry to use
    to answer a question about the product and whether the telemetry is being made
    available. While it would be impossible to list every potential question, here
    are some common questions, linked with the telemetry type that would be best suited
    to answer them:'
  prefs: []
  type: TYPE_NORMAL
- en: How are my customers interacting with my product?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is best answered by using real user monitoring, which we discussed in [*Chapter
    12*](B18277_12.xhtml#_idTextAnchor231). This question could cover many similar
    questions such as what the uptake of a new feature is, and whether there are unvisited
    pages or features in the system.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Are there particular functions that are slow?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This can be answered by combining the timing information for requests from metrics
    with the detailed application information produced in logs. We discussed these
    in *Chapters 4* and *5*. For applications with downstream dependencies, this information
    can also be complemented with trace data, as discussed in [*Chapter 6*](B18277_06.xhtml#_idTextAnchor134).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Why is a particular function slow?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Often, this question will be answered through local testing, but this process
    may be significantly aided by using continuous profiling against a system with
    real or replayed requests. [*Chapter 13*](B18277_13.xhtml#_idTextAnchor239) discussed
    continuous profiling in more detail.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Is my application behaving as expected?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is best addressed by establishing clear **service-level indicators** (**SLIs**)
    and SLOs for the application; we outlined how to do this in [*Chapter 9*](B18277_09.xhtml#_idTextAnchor183).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Is the service compliant with the SLOs/SLAs?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This is typically answered by using metrics data. However, some indicators may
    be metrics derived from logs or tracing data – for example, creating a metric
    from logs of the number of errors seen.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Is my infrastructure scaled correctly?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This would be answered by collecting data from the infrastructure. How that
    is done may differ depending on the type of infrastructure:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: For cloud infrastructure, this is done via an integration that provides logs,
    metrics, and sometimes tracing data
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: For on-premises infrastructure, the collection methods will vary
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: We discussed this topic in more detail in [*Chapter 7*](B18277_07.xhtml#_idTextAnchor147).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: What is the long-term trend for something?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The best telemetry type for long-term trending is metrics as they provide a
    default 13-month retention period. This means the best practice for such analysis
    is to produce a metric from the data you wish to track.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Another approach would be to load data from Grafana into some form of data warehouse,
    but this is outside the scope of this book.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The real difference between the *operate* phase and the *monitor* phase is the
    aim of the use of Grafana. In the *operate* phase, the goal is to ensure that
    the system is functioning correctly for customers of the system. In the *monitor*
    phase, the goal is to understand and document how the system is functioning to
    feed into the *plan* phase to improve the system. Let’s finish discussing the
    DevOps life cycle with the *plan* phase.
  prefs: []
  type: TYPE_NORMAL
- en: Plan
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The *plan* phase takes input from many sources to help a team decide what the
    next priority for work is. The questions asked in the *monitor* phase, and any
    incidents or SLO breaches from the *operate* phase, are some of those sources.
    To help prioritize, it is common to consider things such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: How many customers are affected by a particular incident or potential improvement?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The logs, metrics, and traces in Grafana can collect the data needed to answer
    this. This is true even for changes that have been sourced from other places such
    as user feedback.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: How close to capacity is a component of the system, or how much time is there
    to address a bottleneck before it begins creating incidents or performance degradation?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying bottlenecks before they become critical can be done by using k6
    to load test the system with spike testing, stress testing, or even testing it
    to breakpoint.
  prefs: []
  type: TYPE_NORMAL
- en: The DevOps life cycle is very focused on teams who are developing software.
    It’s common for organizations to use software provided by third parties to provide
    internal platforms. There is a lot of crossover with the *deploy*, *operate*,
    and *monitor* phases, but let’s take a more detailed look at using observability
    with some of these platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Using Grafana to monitor infrastructure and platforms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Teams who work with third-party infrastructure and platforms are well supported
    by the tools from Grafana and OpenTelemetry. We’ll consider a few major types
    of platforms; observability, CI, CD, infrastructure and resource, and finally,
    security platforms. The *deploy*, *operate*, *monitor*, and *plan* phases should
    all be understood for these platforms and the points made in the previous section
    for these phases are relevant to these kinds of platform products. Let’s start
    by considering observability platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Observability platforms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Teams who manage observability platforms have a responsibility to offer a platform
    that demonstrates best practices by having well-documented SLIs and SLOs, easy-to-find
    dashboards, and a dependable incident management process.
  prefs: []
  type: TYPE_NORMAL
- en: Helpfully, there are dashboards available through the Grafana Dashboards community
    portal that provide very detailed views of the OpenTelemetry Collector and the
    data flows as they pass through the Collector. Deciding what aspects of the Collector
    are most important to your organization and publishing them is a step that should
    be taken by any team that manages observability collection.
  prefs: []
  type: TYPE_NORMAL
- en: An important consideration for managing an observability platform is the disaster
    management process for the loss of the platform. While this scenario is unlikely,
    it is much better to have a tested plan than to try to come up with one when the
    platform is on fire – this is advised after a very painful experience. Usually,
    such a disaster plan can be simple – for instance, the ability to create a Prometheus
    instance or even a full Grafana stack in each cluster will give organizations
    the capability to continue operating in the event of the **software-as-a-service**
    (**SaaS**) platform they use being down.
  prefs: []
  type: TYPE_NORMAL
- en: A related plan that should exist is how noisy data sources are controlled. Compartmentalization
    of production data from other sources is a best practice. Sometimes, the financial
    or capacity cost of a noisy data source could be a business interruption. These
    risks can be managed in several ways, such as revoking API keys, adding filtering
    to collectors, or even more extreme measures such as switching off the data source.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider CI platforms next.
  prefs: []
  type: TYPE_NORMAL
- en: CI platforms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: CI platforms cover a lot of different tools, such as Github Actions, GitLab
    CI/CD, Jenkins, Azure DevOps, Google Cloud Build, and similar. We believe the
    most common question asked of CI platforms is “*Why did my build fail?*”. Giving
    engineers tools to debug their builds is very important for such a platform. Often,
    this feedback can be seen in the CI platform itself. However, for some types of
    failures, it may not be obvious, such as a runner that failed, a noisy neighbor,
    or some other issue. In these cases, having data collected from the CI platform
    itself can be very useful.
  prefs: []
  type: TYPE_NORMAL
- en: 'Due to the nature of the CI platform, data collection usually needs to be tailored
    to the platform:'
  prefs: []
  type: TYPE_NORMAL
- en: Platforms provided by cloud vendors would usually be instrumented by collecting
    the logs and metrics from the platform in the vendor’s own tooling (for example,
    AWS CloudWatch, GCP Operations Suite, or Azure Monitor) and then sending them
    on to a Grafana instance if appropriate.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other platforms will probably need to have an agent installed. We discussed
    this process in [*Chapter 13*](B18277_13.xhtml#_idTextAnchor239). For reference,
    the OpenTelemetry Collector is provided via a Docker image, Alpine image (APK),
    Debian image (`.deb`), Enterprise Linux image (`.rpm`), and as a general image
    (`.tar.gz`), which includes executables for macOS (Intel and ARM) and Windows.
    The Grafana Agent is provided as a Docker image, Debian image (`.deb`), Enterprise
    Linux image (`.rpm`), SUSE image, macOS image (via Homebrew for Intel and ARM),
    and Windows Installer (`.exe`).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once an agent is installed, the configuration should be managed to give the
    best support for the nature of the integration work that is carried out on the
    platform. We recommend using one of the automation tools discussed in [*Chapter
    10*](B18277_10.xhtml#_idTextAnchor204) to manage this.
  prefs: []
  type: TYPE_NORMAL
- en: Logs and metrics are the prime data components to capture, as CI platforms do
    not typically need distributed tracing. One thing to consider as a team adds observability
    to a CI platform is whether the leadership team wishes to track higher-level business
    metrics – for example, lead time for changes, defect counts, or similar. For those
    of you who want to look further into these ideas, we recommend looking at Google’s
    **DevOps Research and Assessment** (**DORA**) team reports ([https://cloud.google.com/devops/state-of-devops/](https://cloud.google.com/devops/state-of-devops/)).
    These kinds of considerations would usually need to be agreed upon across several
    teams, so having a clearly documented definition of how they are calculated and
    collected is vital. This kind of data collection may or may not be done in the
    observability tooling. It is best practice to separate the data from CI platforms
    from business-critical workloads. This can easily be achieved by dedicating a
    separate Grafana stack for CI workloads. There are publicly available dashboards
    for these systems as well.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve seen how to monitor a CI platform, let’s consider the deployment
    platform.
  prefs: []
  type: TYPE_NORMAL
- en: CD platforms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'CD platforms often have crossover with CI platforms; we’re considering them
    separate as they are different aspects of the overall system. These platforms
    use tools such as Jenkins, GitLab CI/CD, AWS CodeDeploy, ArgoCD, FluxCD, and similar.
    For infrastructure deployment, they may also include tools such as Terraform Cloud,
    Atlantis, or Spacelift. There are two main groups of CD tools: **push systems**
    and **pull systems**. We’ll discuss them separately in this way as the data collection
    processes differ. With either deployment method, a very important aspect of integrating
    with Grafana well is to record an annotation in Grafana. We discussed this in
    more detail when we talked about the *deploy* phase of the DevOps life cycle,
    but this contextual information can save huge amounts of time during troubleshooting,
    and ultimately, provide a better customer experience.'
  prefs: []
  type: TYPE_NORMAL
- en: Pull systems in Kubernetes also use the term *GitOps*; such systems typically
    use tools such as **ArgoCD** or **FluxCD**. As these tools are deployed into an
    existing Kubernetes cluster, the observability stance is very simple, in that
    the service will have data collected by the existing collection infrastructure
    in the cluster. ArgoCD provides metrics in Prometheus format, and there are several
    dashboards publicly available. It’s also possible to extend the data collection
    via other tools in the Argo group of tools. FluxCD provides Prometheus metrics
    that can be extended with kube-state-metrics as well. The tool also provides logs
    and produces Kubernetes events as well. There are other pull systems outside of
    Kubernetes, such as **Chef** and **ansible-pull**, but due to the low prevalence
    of these tools, we’ll not discuss them here.
  prefs: []
  type: TYPE_NORMAL
- en: Push-based CD platforms have one or more central systems that connect to the
    deployment target and run the deployment process. Jenkins is perhaps the classic
    example here, but systems such as GitHub Actions and GitLab CI/CD also fall into
    this category. You may notice that these tools were also mentioned previously
    when we considered the CI platform. Unsurprisingly, these tools are monitored
    in the same way, whether they are used for integration tasks or delivery/deployment
    tasks. When the use of these tools has a mix of integration and delivery/deployment
    tasks, monitoring the actions of the platform is very important from a security
    perspective as these systems will often consume third-party libraries during the
    integration phase, which opens the system to supply chain attacks. Combining such
    an attack with high-level access to production on a single system is a very real
    threat to organizations.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now considered how to monitor the platforms that build and deploy software.
    Let’s consider a wider group of systems next. We’ll consider data storage and
    message queue systems in this next section.
  prefs: []
  type: TYPE_NORMAL
- en: Resource platforms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’re using the term *resource platform* to describe the types of backend systems
    that an application may depend on. These might include databases, in-memory data
    stores, message buses, web servers, or similar. These platforms are an odd case,
    as the responsibility for the system can reside in many different areas of the
    organization. Commonly, either a software delivery team would be responsible,
    or sometimes a centralized team would be responsible. We will attempt to ignore
    this complexity by talking in general terms about how to ensure these tools are
    observable.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few places to start looking at monitoring these systems:'
  prefs: []
  type: TYPE_NORMAL
- en: '**OpenTelemetry Collector contributed receivers**: There are contributed receiver
    modules for a vast array of resource platforms. Deploying these receivers is very
    simple:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In Kubernetes, the collector can be deployed as a sidecar to the service, or
    as a dedicated agent in the cluster or namespace that forwards telemetry on to
    a gateway. An example of a dedicated agent is shown in *Figure 11.5* in [*Chapter
    11*](B18277_11.xhtml#_idTextAnchor218) where the agent is used to collect metrics
    from the Kubernetes cluster.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: In a virtual or bare metal installation, a dedicated OpenTelemetry Collector
    needs to be deployed, although this can often be done on the instance being monitored
    with no performance degradation.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prometheus modules**: These are modules that allow Prometheus to scrape data
    from a lot of resource platforms. These can simply be deployed to a Prometheus
    instance and configured to connect to the platform that needs to be monitored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once metrics are collected from these systems, Grafana offers a wide range of
    prebuilt public dashboards for them. The wide availability of these dashboards
    means the time to value is very good.
  prefs: []
  type: TYPE_NORMAL
- en: One thing to highlight to prevent confusion with these systems is that this
    type of data collection is not the same as using the system as a data source in
    Grafana. A lot of these systems, especially databases such as MySQL, PostgreSQL,
    and MongoDB, can be used as a Grafana data source. A data source connects to the
    system and allows users to query the data in the system. The tools we are discussing
    here connect to the system and query operational metrics from it. These metrics
    can then be used to provide SLOs and transparency of the operation of the system
    to other teams.
  prefs: []
  type: TYPE_NORMAL
- en: Security platforms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will not delve too deeply into **security platforms** as they could fill
    an entire book on their own. However, it’s worth noting that several tools, such
    as **Falco**, **Open Policy Agent**, **kube-bench**, **Trivy,** and others, have
    methods of exposing metrics related to their operation, which can be consumed
    by Grafana in some way.
  prefs: []
  type: TYPE_NORMAL
- en: There is also a very big crossover of concerns of observability platforms with
    cyber security platforms. Both platforms consume log data, which can lead to the
    running of multiple agents to collect this data. A more cost-effective solution
    could be for these teams to work together on a shared pipeline of this data that
    supports both teams’ operations. Such a pipeline should be monitored closely as
    it could present a significant risk to the organization.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now considered using Grafana both in the software application life cycle
    and for the management of infrastructure and platforms.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have considered how you can use Grafana through the DevOps
    life cycle. You learned about deploying Grafana in a local environment to speed
    up development time by getting instant feedback on the performance of the code.
    We looked at the testing phase, and you learned how using tools such as k6 can
    provide great repeatable tests that can even be used as an application is deployed.
    During the release phase, Grafana can be used to demonstrate various aspects of
    an application to the stakeholders who approve your releases. We saw how deployments
    can have their risks reduced by leveraging SLOs and black box monitoring. We also
    saw how using Grafana annotations can improve the visibility of deployments occurring.
    The *operate* and *monitor* phases use Grafana in very similar ways, which have
    been covered in this book. You were introduced to the difference in the aim of
    these two phases, with the *operate* phase being concerned with the correct functioning
    and the *monitor* phase being concerned with how to improve the customer experience.
    Finally, we talked about how Grafana can be used to have a data-driven discussion
    during the planning phase of a software tool.
  prefs: []
  type: TYPE_NORMAL
- en: We then considered how Grafana can also be used with various types of platforms.
    We introduced you to using Grafana to monitor your observability platform, effectively
    demonstrating the principle of using your own product or “*eating your own dog
    food*,” and acting as an example of best practice to an organization. You saw
    how to use Grafana with your CI/CD platforms, so engineers in an organization
    have a lot of data to understand how their builds and deployments are working.
    We then discussed how to get operational data from many systems used across the
    industry, such as databases, in-memory data stores, message buses, and web servers.
    You learned that the best approach is to look for available data collection tooling
    and publicly available dashboards. The final kind of platform we looked at was
    a security platform, where you saw that some tools also surface data in Prometheus
    or OpenTelemetry format, which can be consumed by Grafana. Where this is available,
    prebuilt Grafana dashboards are also available, which significantly reduces the
    time to value for using these tools.
  prefs: []
  type: TYPE_NORMAL
- en: We have nearly reached the end of the book. The next chapter will cover best
    practices and troubleshooting techniques. You will look at some specific items
    around data collection and the Grafana stack as well as general guidance on common
    pitfalls in observability. We will also discuss interesting future trends.
  prefs: []
  type: TYPE_NORMAL
