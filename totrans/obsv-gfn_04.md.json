["```\n    $ helm upgrade --version '0.73.1' --values chapter4/OTEL-Collector.yaml --values OTEL-Creds.yaml owg open-telemetry/opentelemetry-collector\n    NAME: owg-otel-collector\n    LAST DEPLOYED: Sun Apr 25 12:15:03 2023\n    NAMESPACE: default\n    STATUS: deployed\n    REVISION: 2\n    …\n    ```", "```\n    $ kubectl get pods --selector=app.kubernetes.io/instance=owg\n    NAME  READY   STATUS    RESTARTS   AGE\n    owg-opentelemetry-collector-594fddd656-tfstk   1/1     Terminating   1 (70s ago)   2m8s\n    owg-opentelemetry-collector-7955d689c4-gsvqm   1/1     Running       0             3s\n    ```", "```` error` `` | `&#124;=`,`!=`,`&#124;~`,`!~` | Filter to matching log lines |\n| **Parser** | `&#124;` `json` | `json`, `logfmt`, `pattern`, `regexp`, `unpack` | Parse and extract labels from the log content, with parses for structured and unstructured logs |\n| **Label filter** | `&#124;` `label=\"value\"` | `=`,`!=`,`=~`,`!~`,`<`,`<=`,`>`,`>=` | Filter log lines using original and newly extracted labels |\n| **Line format** | `&#124;` `line_format \"{{.label}}\"` |  | Rewrite the log line content for presentation purposes |\n| **Label format** | `&#124;` `new_label=\"{{.label}}\"` |  | Rename, modify, or add labels |\n\nTable 4.1 – LogQL feature overview\n\nLet’s start by looking at the log stream selector in detail.\n\n## Log stream selector\n\nSelecting log streams to include in your query results requires filtering based on the Loki labels using simple operators. By improving the granularity of your log stream selector, you can reduce the number of streams searched and improve query performance. We will discuss this in more detail later in this chapter when we look at the Loki architecture. There must always be at least one stream selector, but it must be written in a way that will not match empty values; for example, the `{label=~\".*\"}` will fail as a 0 or more quantifier and `{label=~\".+\"}` will pass as a 1 or more quantifier. Multiple stream selectors can be used and are separated using commas. The log stream selector must be the first item in your LogQL query and identified with curly braces. For example, the following LogQL query will select log streams where the `component` label ends with `service` and the `name` label equals `owg-demo-checkoutservice`:\n\n```\n {component=~\".+service\", name=\"owg-demo-checkoutservice\"}\n```\n\nAs mentioned at the beginning of this section, LogQL was inspired by PromQL and as such, the Prometheus label selector rules have been adopted by LogQL for log stream selectors:\n\n| **Operator** | **Meaning** |\n| = | Exactly equal |\n| != | Not equal |\n| =~ | Regex matches |\n| !~ | Regex does not match |\n\nTable 4.2 – Log stream selector operators\n\nGrafana has implemented the **Golang RE2 syntax** for log streams, which means you will have to match against entire strings. This includes newlines, so it’s worth checking this if your regex filters are failing. Syntax documentation can be found here: [https://github.com/google/re2/wiki/Syntax](https://github.com/google/re2/wiki/Syntax).\n\nOnce you have your log streams selected, the **log pipeline** can then be used to filter and process them. Let’s discuss this next.\n\n## Log pipeline\n\nAs we presented in *Table 4.1*, the expressions available are line and label filters, parsers, and formatters. Expressions are executed in sequence for each line of the log stream, dropping anything filtered out and moving on to the next line.\n\nExpressions allow you to transform or mutate the log data to then use it for additional filtering/processing. Let’s look at the following example (this is the pipeline section only; you would need the `{component=~\".+service\"}` selector to make it work in Grafana):\n\n```\n  |= `emailservice`\n  | json\n  | resources_k8s_container_restart_count > 0\n  | line_format `{{.body}}`\n  | __error__=``\n```\n\nHere, we’re doing the following tasks:\n\n1.  We start by matching the logs containing `emailservice`.\n2.  We then use the `json` parser to extract additional labels that are filtered where `resources_k8s_container_restart_count` is greater than 0.\n3.  We then rewrite the log line to only contain the contents of `body`.\n4.  Finally, we strip all formatting and parsing errors.\n\nLet’s now look at each of the log pipeline expressions and how to use them.\n\n### Line filters\n\nGrafana describes `grep` over the aggregated logs from the matching log streams. We will understand this statement better in the *Loki’s architecture* section. For now, it’s fine to just understand line filters as case-sensitive searches through log line contents dropping lines that do not match. Filter expressions are made up of a filter operator followed by text or regex. The following table shows the meaning of each expression with examples:\n\n| **Operator** | **Meaning** | **Example** |\n| `&#124;=` | Log line contains a string | `` &#124;= ` ````", "```` emailservice` `` |\n| `&#124;~` | Log line contains a match to the regex | `` &#124;~ ` ````", "```` email\\w+` `` |\n\nTable 4.3 – Line filters\n\nIt is best practice to start log pipelines with line filter expressions to reduce the result set for subsequent expressions and improve the performance of the query.\n\n### IP address matching\n\nLogQL provides a useful function to aid `ip(\"<pattern>\")` syntax, it supports both IPv4 and IPv6 addresses, address ranges, and CIDR patterns. This function works for both line and label filters with a slight caveat in implementation; only `|=` and `!=` are allowed for line filter expressions. We’ll look at this in the context of label filters later in this section.\n\nThe following examples show various patterns (`ip(<pattern>)`) along with an explanation of what each will do, for both IPv4 and IPv6:\n\n*   `ip(\"192.168.0.22\")` and `ip(\"::1\")`\n*   `ip(\"192.168.0.1-192.189.10.12\")` and `ip(\"2001:db8::1-2001:db8::8\")`\n*   `ip(\"192.52.100.0/24\")` and `ip(\"2001:db8::/32\")`\n\n### Decolorize\n\nIn [*Chapter 2*](B18277_02.xhtml#_idTextAnchor043), we mentioned unstructured logging is often color-coded to improve readability on the computer terminal. However, in a log aggregation system, such as Loki, those color codes are displayed in full. For example, the color red would be displayed as `\\u001b[31m`.\n\nLoki has a simple line filter expression that removes these ANSI sequences for color codes so that you can clean the log to make it more readable in Grafana:\n\n```\n{name=\"emailservice\"} | decolorize\n```\n\n### Parsers\n\nWe have said this before: Loki accepts logs from all sources. It does not really matter what your logs look like; they can come in structured, semi-structured, or unstructured formats. It is, however, important when designing and building observability solutions to understand the log formats you are working with. This ensures that you can ingest, store, and parse log data in a way it can be used effectively. The personas in [*Chapter 1*](B18277_01.xhtml#_idTextAnchor018) give you an idea of who these will be used by and for what purpose.\n\nHaving a good understanding of your source log format is important to instruct you on what to use and help with your overall observability design. The following LogQL parsers can be used to parse and extract labels from your log content:\n\n*   `json`: If your log content is structured or semi-structured JSON and has embedded JSON (which can be isolated using the `line_format` expression), the `| json` on its own will extract all of the JSON properties as labels. Any nested properties will be represented as a single label separated with `_`. Arrays are skipped completely when extracting all of the properties. Additionally, expressions can be passed into the JSON parser as quoted strings to restrict the output to only the labels required, for example, `| json label1=\"expression\", label2=\"expression\"`, where the expression identifies a key or nested key. Arrays are returned where identified by expressions and they are assigned to the label formatted as JSON.\n*   `logfmt`: If your log content is structured, single-level key-value pairs, it can be parsed with the `| logfmt` on its own will extract all of the key-value pairs. Similar to the JSON parser, expressions can be passed into the `logfmt` parser as quoted strings to restrict the output to only the labels required, for example, `| logfmt label1=\"expression\", label2=\"expression\"`, where `expression` identifies a key.\n*   `pattern`: For unstructured log content, the `| pattern \"<expression>\"`, where `expression` matches the structure of a log line. The pattern parser expression is made up of captures delimited by the `<` and `>` characters and literals, which can be any sequence of UTF-8 characters.\n*   `regexp`: Unstructured log content can also be extracted using the `| regexp \"<expression>\"`, where `expression` is a regex pattern that complies with the Golang RE2 syntax. A valid expression must contain at least one sub-match, with each sub-match extracting a different label.\n*   `unpack`: If you are using a compatible logging agent, such as Grafana Agent or Promtail, you can take advantage of the `unpack` parser to unpack embedded labels created by Promtail’s `pack` feature. With Promtail’s `pack` feature, the original log line is stored in the `_entry` key. This value will be used to replace the log line.\n\n### Label filters\n\nWe discussed log labels at the beginning of this section with regard to log ingestion and retrieval. Additionally, labels can be extracted as part of the log pipeline using parser and formatter expressions. The **label filter** expression can then be used to filter your log line with either of these labels.\n\nThe statement part of the filter is referred to as the *predicate*, and in the case of label filters, it contains the following:\n\n*   The label identifier\n*   The operation\n*   A value\n\nFor example, in `name=\"emailservice\"`, the `name` label is compared, using the `=` operator, with the value `\"emailservice\"`. It is processed from left to right, so the label identifier must start the predicate.\n\n**Value types** are inferred from your query input. In the following table, you will find an overview of these types as a useful reference for building your label filters:\n\n| **Value Type** | **Description** |\n| String | Can be surrounded with double quotes or backticks, for example, `\"emailservice\"` or `` `emailservice` ``. |\n| Duration | Structured as a sequence of decimal numbers. They can optionally contain fractions and the unit can be declared as a suffix, for example, `\"280ms\"`, `\"1.3h\"`, or `\"2h30m\"`. Units of time that can be used are `\"ns\"`, `\"us\"` (or `\"µs\"`), `\"ms\"`, `\"s\"`, `\"m\"`, and `\"h\"`, and as the examples show, you can use multiple units: `\"2h30m\"`. |\n| Number | Standard floating-point numbers, for example, `357` or `98.421`. |\n| Bytes | Structured as a sequence of decimal numbers. They can optionally contain fractions and the unit can be declared as a suffix, for example, `\"36MB\"`, `\"2.4Kib\"`, or `\"18b\"`. Units for bytes that can be used are `\"b\"`, `\"kib\"`, `\"kb\"`, `\"mib\"`, `\"mb\"`, `\"gib\"`, `\"gb\"`, `\"tib\"`, `\"tb\"`, `\"pib\"`, `\"pb\"`, `\"eib\"`, and `\"eb\"`. |\n\nTable 4.4 – Value types\n\nLet’s now look at these value types in more detail:\n\n*   `=`, `!=`, `=~`, and `!~` operations can be used. The `string` type is used to filter the built in label `__error__`, which is often used to strip formatting and parsing errors from results; for example, `|` ``` __error__=`` ```.\n*   `=` or `==`\n\n    Equals\n\n    `!=`\n\n    Does not equal\n\n    `>` and `>=`\n\n    Is greater than or greater than and equal to\n\n    `<` and `<=`\n\n    Is less than or less than and equal to\n\nTable 4.5 – Type operators\n\nTake the example `| resources_k8s_container_restart_count > 0`. Loki attempts to convert the value for use with the operator if it needs to. If there are any errors with the conversion, the `__error__` label will be added to the log line, which as we demonstrated earlier, can be filtered out using `|` ``` __error__=`` ```.\n\nGrafana LogQL also allows for multiple predicates to be *chained* together using `and` and `or` . `and` can alternatively be expressed using `,` or `|` or `<space>`.\n\nFor example, all of the following produce the same output:\n\n```\n  | quantity >= 2 and productId!~\"OLJ.*\"\n  | quantity >= 2 | productId!~\"OLJ.*\"\n  | quantity >= 2 , productId!~\"OLJ.*\"\n  | quantity >= 2 productId!~\"OLJ.*\"\n```\n\nWe described `=` and `!=` label matchers are allowed. Once you have filtered and parsed your logs as required, you can begin to transform the data, whether that is for presentation or further pipeline processing. We will discuss the two ways of doing this in detail next. But first, let’s explore **template functions**, which are implemented by both line and label filters.\n\n### Template functions\n\nThe Golang text/template format has a large set of available template functions, all of which are available for use in LogQL queries. Full documentation can be found on the Grafana website. The **templating engine** has access to your data in various ways:\n\n*   It can treat labels as variables, referencing them using `.`, for example, `{{ .``component }}`\n*   It can access the log line itself using `__line__`, for example, `` `{{ __line__ | `` `` lower }}` ``\n*   It can access the log timestamp using `__timestamp__`, for example, `` `{{ __timestamp__ | date \" ````", "```\n    {instance=\"owg-demo\", component=\"featureflagservice\"} |= `Sent`\n    | json\n    | regexp \"(?P<method>Sent) (?P<status>\\\\d+?) in\\\\s(?P<duration>.*?ms)\"\n    |label_format new_label=\"{{ .label }}\" is used to rename, modify, or even create new labels. It accepts a comma-separated list of equality operations, allowing multiple operations to be carried out simultaneously.To rename a label with another label, the label identifiers must be on both sides of the operator; for example, `target=source` will put the contents of the `source` label into the `target` label and drop the `source` label.A label can be populated using the Golang text/template format and functions detailed previously (double quotes or backticks). For example, if we have the `user=diego` and `status=200` labels, the `|label_format target=\"{{.status}} {{.user}}\"` pipeline would define the `target` label as `200 diego`.Templating can be used if you wish to preserve the original `source` label. In the example, `target=source` removed the `source` label. We can write this as `target=\"{{.source}}\"`, which will put the contents of the `source` label into the `target` label while preserving the `source` label. If the target label does not already exist, a new label is created.\n    ```", "```\n    count_over_time({component=\"currencyservice\"}[10m])\n    ```", "```\n    sum by (component) (rate({component=~\".+service\"}\n    |= \"error\" [1m]))\n    ```", "```\n    quantile_over_time(0.99,\n      {container=\"webserver\"}\n        | json\n        | __error__ = \"\"\n        | unwrap duration_seconds(request_time) [1m]) by (path)\n    ```", "```\n     sum by (org_id) (\n      sum_over_time(\n      {container=\"webserver\"}\n          |= \"metrics\"\n          | logfmt\n          | unwrap bytes(bytes_processed) [1m])\n      )\n    ```", "```\n    topk(10, sum(rate({region=\"us-west1\"}[10m])) by (name))\n    ```", "```\n    avg(rate(({container=\"webserver\"} |= \"GET\" | json | path=\"/hello\")[10s])) by (region)\n    ```"]