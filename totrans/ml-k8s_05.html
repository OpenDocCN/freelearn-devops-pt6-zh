<html><head></head><body>
		<div id="_idContainer161">
			<h1 id="_idParaDest-87"><em class="italic"><a id="_idTextAnchor086"/>Chapter 6</em>: Machine Learning Engineering</h1>
			<p>In this chapter, we will move the discussion to the model building and model management activities of the <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) engineering lifecycle. You will learn about the ML platform's role of providing a self-serving solution to data scientist so they can work more efficiently and collaborate with data teams and fellow data scientists.</p>
			<p>The focus of this chapter is not on building models; instead, it is on showing how the platform can bring consistency and security across different environments and different members of your teams. You will learn how the platform simplifies the work of data scientists in terms of preparing and maintaining their data science workspaces.</p>
			<p>In this chapter, you will learn about the following topics:</p>
			<ul>
				<li>Understanding ML engineering?</li>
				<li>Using a custom notebook image </li>
				<li>Introducing MLflow</li>
				<li>Using MLflow as an experiment tracking system</li>
				<li>Using MLflow as a model registry system</li>
			</ul>
			<h1 id="_idParaDest-88"><a id="_idTextAnchor087"/>Technical requirements</h1>
			<p>This chapter includes some hands-on setup and exercises. You will need a running Kubernetes cluster configured with <strong class="bold">Operator Lifecycle Manager</strong> (<strong class="bold">OLM</strong>). Building such a Kubernetes environment is covered in <a href="B18332_03_ePub.xhtml#_idTextAnchor040"><em class="italic">Chapter 3</em></a>, <em class="italic">Exploring Kubernetes</em>. Before attempting the technical exercises in this chapter, please make sure that you have a working Kubernetes cluster and that <strong class="bold">Open Data Hub</strong> (<strong class="bold">ODH</strong>) is installed on your Kubernetes cluster. Installing ODH is covered in <a href="B18332_04_ePub.xhtml#_idTextAnchor055"><em class="italic">Chapter 4</em></a>, <em class="italic">The Anatomy of a Machine Learning Platform</em>. You can find all the code associated with this book at <a href="https://github.com/PacktPublishing/Machine-Learning-on-Kubernetes">https://github.com/PacktPublishing/Machine-Learning-on-Kubernetes</a>.</p>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor088"/>Understanding ML engineering</h1>
			<p>ML engineering is the process<a id="_idIndexMarker425"/> of applying software engineering principles and practices to ML projects. In the context of this book, ML engineering is also a discipline that facilitates applying application development practices to the data science lifecycle. When you write a traditional application such as a website or a banking system, there are processes and tools to assist you in writing high-quality code right from the start. Smart IDEs, standard environments, continuous integration, automated testing, and static code analysis are just a few examples. Automation and continuous deployment practices enable organizations to deploy applications many times in a day and with no downtime. </p>
			<p>ML engineering is a loose term that brings the benefits of traditional software engineering practices to the model development world. However, most data scientists are not developers. They may not be familiar with software engineering practices. Also, the tools that the data scientists use may not be the right tools to perform ML engineering tasks. Having said that, the model is just another piece of software. Therefore, we can also apply existing software engineering approaches to ML models. Using containers to package and deploy ML models is one such example.</p>
			<p>Some teams may employ ML engineers to supplement the work of data scientists. While the data scientist's primary responsibility is to build ML or deep learning models that solve business problems, ML engineers focus more on the software engineering facets. Some of the <a id="_idIndexMarker426"/>responsibilities of data engineers include the following:</p>
			<ul>
				<li>Model optimization (also about making sure that the built model is optimized for the target environment where the model will be hosted).</li>
				<li>Model packaging (making ML models portable, shippable, executable, and version-controlled). Model packaging may also include model serving and containerization.</li>
				<li>Monitoring (establishing an infrastructure for collecting performance metrics, logging, alerting, and anomaly detection such as drift and outlier detection).</li>
				<li>Model testing (including facilitation and automation of A/B testing).</li>
				<li>Model deployment.</li>
				<li>Building and maintenance of MLOps infrastructure.</li>
				<li>Implementation of continuous integration and continuous deployment pipelines for ML models.</li>
				<li>Automation of ML lifecycle processes.</li>
			</ul>
			<p>There are other responsibilities of ML engineers that are not listed in the preceding list, but this list should already give you an idea of how to differentiate data science from ML engineering.</p>
			<p>The ML platform that <a id="_idIndexMarker427"/>you are building will reduce the number of ML engineering tasks to be done manually to a point where even the data scientists can do most of the ML engineering tasks by themselves.</p>
			<p>In the next sections, you will see how data scientists can track the model development iterations to improve model quality and share the learning with the team. You will see how teams can apply version control to ML models and other practices of software engineering to the ML world.</p>
			<p>We will continue our journey of ML engineering into the next chapter, where you will see how models can be packaged and deployed in a standard way and see how the deployment process can be automated.</p>
			<p>Let's start with building standard development environments for our data science team.</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor089"/>Using a custom notebook image</h1>
			<p>As you have seen in <a href="B18332_05_ePub.xhtml#_idTextAnchor069"><em class="italic">Chapter 5</em></a>, <em class="italic">Data Engineering</em>, JupyterHub allows you to spin up Jupyter Notebook-based development <a id="_idIndexMarker428"/>environments in a self-service manner. You have launched the <strong class="bold">Base Elyra Notebook Image</strong> container image and used it to <a id="_idIndexMarker429"/>write the data processing code using Apache Spark. This approach enables your team to use a consistent or standardized development environment (for example, same Python versions and same libraries for building code) and apply security policies to the known set of software being used by your team. However, you may also want to create your own custom images with a different set of libraries or a different ML framework. The platform allows you to do that. </p>
			<p>In the following subsection, you will build and deploy a custom container image to be used within your team.</p>
			<h2 id="_idParaDest-91"><a id="_idTextAnchor090"/>Building a custom notebook container image</h2>
			<p>Let's assume that your team wants<a id="_idIndexMarker430"/> to use a specific version of the Scikit library along with some other supporting libraries such as <strong class="source-inline">joblib</strong>. You then want your team to use this library while developing their data science code:</p>
			<ol>
				<li value="1">Open the <strong class="source-inline">Dockerfile</strong> provided in the code repository of this book at <strong class="source-inline">chapter6/CustomNotebookDockerfile</strong>. This file uses the base image provided and used by ODH and then adds the required libraries. The file is shown in <em class="italic">Figure 6.1</em>: </li>
			</ol>
			<div>
				<div id="_idContainer125" class="IMG---Figure">
					<img src="image/B18332_06_001.jpg" alt="Figure 6.1 – Dockerfile for the custom notebook image&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.1 – Dockerfile for the custom notebook image</p>
			<p>Note the first line, which refers to the latest image at the time of writing. This image is used by ODH. Lines 4 and 5 install the Python packages defined in the <strong class="source-inline">requirements.txt</strong> file. Line 8 installs the dependencies that are not in the <strong class="source-inline">requirements.txt</strong> file. If you wish to add additional packages to the image, you can simply insert a line in <strong class="source-inline">requirements.txt</strong>.</p>
			<ol>
				<li value="2">Build the image using the file provided in the preceding step. Run the following command:<p class="source-code"><strong class="bold">docker build -t scikit-notebook:v1.1.0 -f chapter6/CustomNotebookDockerfile ./chapter6/. </strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer126" class="IMG---Figure">
					<img src="image/B18332_06_002.jpg" alt="Figure 6.2 – Output of the container build command&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.2 – Output of the container build command</p>
			<ol>
				<li value="3">Tag the built image as per your liking. You will need to push this image to a registry from where your Kubernetes cluster can access it. We use <strong class="source-inline">quay.io</strong> as the public Docker repository of choice, and you can use your preferred repository here. Notice <a id="_idIndexMarker431"/>that you will need to adjust the following command and change the <strong class="source-inline">quay.io/ml-on-k8s/</strong> part before execution of the command:<p class="source-code"><strong class="bold">docker tag scikit-notebook:v1.1.0 quay.io/ml-on-k8s/scikit-notebook:v1.1.0</strong></p></li>
			</ol>
			<p>There is no output of the preceding command.</p>
			<ol>
				<li value="4">Push the image to the Docker repository of your choice. Use the following command and make sure to change the repository location as per <em class="italic">Step 3</em>. This image may take some time to be pushed to an internet repository based on your connection speed. Be patient:<p class="source-code"><strong class="bold">docker push quay.io/ml-on-k8s/scikit-notebook:v1.1.0</strong></p></li>
			</ol>
			<p>You should see the output of this command as shown in <em class="italic">Figure 6.3</em>. Wait for the push to complete.</p>
			<div>
				<div id="_idContainer127" class="IMG---Figure">
					<img src="image/B18332_06_003.jpg" alt="Figure 6.3 – Pushing the custom notebook image to a Docker repository&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.3 – Pushing the custom notebook image to a Docker repository</p>
			<p>Now, the image is available<a id="_idIndexMarker432"/> to be used. You will configure ODH manifests in the next steps to use this image. </p>
			<ol>
				<li value="5">Open the <strong class="source-inline">manifests/jupyterhub-images/base/customnotebook-imagestream.yaml</strong> file. This file is shown as follows:</li>
			</ol>
			<div>
				<div id="_idContainer128" class="IMG---Figure">
					<img src="image/B18332_06_004.jpg" alt="Figure 6.4 – ImageStream object&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.4 – ImageStream object</p>
			<p>JupyterHub from ODH uses<a id="_idIndexMarker433"/> a CRD called <strong class="bold">Imagestream</strong>. This is a native object on Red Hat OpenShift, but it is not available in standard Kubernetes. We have created this object as a<a id="_idIndexMarker434"/> custom resource in the manifests of ODH so that it can integrate with upstream Kubernetes. You can find these resources at <strong class="source-inline">manifests/odh-common/base/imagestream-crd.yaml</strong>.</p>
			<p>Notice on lines 7 and 8, we have defined some annotations. JupyterHub reads all the <strong class="source-inline">imagestream</strong> objects and uses these annotations to be displayed on the JupyterHub landing page. JupyterHub also looks at the field named <strong class="source-inline">dockerImageReference</strong> to load these container images upon request.</p>
			<p>We encourage you to fork the code repository of this book onto your own Git account and add more images. Keep in mind to change the location of the Git repository in the <strong class="source-inline">manifests/kfdef/ml-platform.yaml</strong> file.</p>
			<ol>
				<li value="6">For the JupyterHub server to see the newly created image, you will need to restart the JupyterHub pod. You can find the pod via the following command and delete this pod. After a few seconds, Kubernetes will restart this pod and your new image will appear on the JupyterHub landing page:<p class="source-code"><strong class="bold">kubectl get pods -n ml-workshop | grep jupyterhub</strong></p></li>
			</ol>
			<p>You should see the following response. Note that the pod name will be different for your setup:</p>
			<div>
				<div id="_idContainer129" class="IMG---Figure">
					<img src="image/B18332_06_005.jpg" alt="Figure 6.5 – Pods with names containing jupyterhub&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.5 – Pods with names containing jupyterhub</p>
			<ol>
				<li value="7">Delete the JupyterHub pod by running the following command. Note that you do not need to delete this pod for this exercise, because the custom image is already present <a id="_idIndexMarker435"/>in our manifest files. This step will be required once you add a new customer notebook image using the steps mentioned in this section: <p class="source-code"><strong class="bold">kubectl delete pod jupyterhub-7848ccd4b7-thnmm -n ml-workshop</strong></p></li>
			</ol>
			<p>You should see the following response. Note that the pod name will be different for your setup:</p>
			<div>
				<div id="_idContainer130" class="IMG---Figure">
					<img src="image/B18332_06_006.jpg" alt="Figure 6.6 – Output of the delete pod command&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.6 – Output of the delete pod command</p>
			<ol>
				<li value="8">Log in to JupyterHub and you will see the new notebook image listed there: </li>
			</ol>
			<div>
				<div id="_idContainer131" class="IMG---Figure">
					<img src="image/B18332_06_007.jpg" alt="Figure 6.7 – JupyterHub landing page showing the new notebook image&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.7 – JupyterHub landing page showing the new notebook image</p>
			<p>In the next section, you will<a id="_idIndexMarker436"/> learn about MLflow, a software that assists teams in recording and sharing the outcomes of model training and tuning experiments.</p>
			<h1 id="_idParaDest-92"><a id="_idTextAnchor091"/>Introducing MLflow</h1>
			<p>Simply put, MLflow is there<a id="_idIndexMarker437"/> to simplify the model development lifecycle. A lot of the data scientist's time is spent finding the right algorithms with the right hyperparameters for the given dataset. As a data scientist, you experiment with different combinations of parameters and algorithms, then review and compare the results to make the right choice. MLflow allows you to record, track, and compare these parameters, their results, and associated<a id="_idIndexMarker438"/> metrics. The component of MLflow that captures the details of each of your experiments is called the <strong class="bold">tracking server</strong>. The tracking server captures the environment details of your notebook, such as the Python libraries and their versions, and the artifacts generated by your experiment.</p>
			<p>The tracking server allows you to compare the data captured between different runs of an experiment, such as the performance metrics (for example, accuracy) alongside the hyperparameters used. You can also share this data with your team for collaboration.</p>
			<p>The second key capability of the MLflow tracking server is the model registry. Consider that you have run ten different <a id="_idIndexMarker439"/>experiments for the given dataset, while each of the experiments resulted in a model. Only one of the models will be used for the given problem. The model registry allows you to tag the selected model with one of the three stages (<strong class="bold">Staging</strong>, <strong class="bold">Production</strong>, and <strong class="bold">Archived</strong>). The model registry has APIs that allow you to access these models from your automated jobs. Versioning models in a registry will enable you to roll back to previous versions of the model using your automation tools in production if needed.</p>
			<p><em class="italic">Figure 6.8</em> shows the two major capabilities of the MLflow software:</p>
			<div>
				<div id="_idContainer132" class="IMG---Figure">
					<img src="image/B18332_06_008.jpg" alt="Figure 6.8 – MLflow major capabilities&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.8 – MLflow major capabilities</p>
			<p>Now that you know what MLFlow is used for, let's take a look at the components that made up MLFlow.</p>
			<h2 id="_idParaDest-93"><a id="_idTextAnchor092"/>Understanding MLflow components</h2>
			<p>Let's see what the major<a id="_idIndexMarker440"/> components of the MLflow system are and how it fits into our ML platform's ecosystem.</p>
			<h3>MLflow server</h3>
			<p>MLflow is deployed as a container, and it contains a backend server, a GUI, and an API to interact with it. In the later sections<a id="_idIndexMarker441"/> of this chapter, you will use <a id="_idIndexMarker442"/>the MLflow API to store the experiment data onto it. You will use the GUI component to visualize experiment tracking and the model registry parts. You can find this configuration at <strong class="source-inline">manifests/mlflow/base/mlflow-dc.yaml</strong>.</p>
			<h3>MLflow backend store</h3>
			<p>The MLflow server needs a backend <a id="_idIndexMarker443"/>store to store the metadata about experiments. The ODH component automatically provisions a PostgreSQL database to be <a id="_idIndexMarker444"/>used as a backend store for MLflow. You can find this configuration at <strong class="source-inline">manifests/mlflow/base/mlflow-postgres-statefulset.yaml</strong>.</p>
			<h3>MLflow storage </h3>
			<p>The MLflow server supports <a id="_idIndexMarker445"/>several types of storage, such as S3 and databases. This storage will serve as the persistent storage for the artifacts, such as files <a id="_idIndexMarker446"/>and model files. In our platform, you will provision an open source S3 compatible storage <a id="_idIndexMarker447"/>service known as <strong class="bold">Minio</strong>. Minio will provide the S3 API capabilities to the platform; however, your organization may already have an enterprise-wide S3 solution, and we recommend using the existing solution if there is one. You can find this configuration at <strong class="source-inline">manifests/minio/base/minio-dc.yaml</strong>.</p>
			<h3>MLflow authentication</h3>
			<p>MLflow does not have an<a id="_idIndexMarker448"/> out-of-the-box authentication system at the time of writing. In our <a id="_idIndexMarker449"/>platform, we have configured a proxy server in front of the MLflow GUI that will authenticate the request before forwarding it to the MLflow server. We are using the open source component at <a href="https://github.com/oauth2-proxy/oauth2-proxy">https://github.com/oauth2-proxy/oauth2-proxy</a> for this purpose. The proxy has been<a id="_idIndexMarker450"/> configured to perform <strong class="bold">Single-Sign-On</strong> (<strong class="bold">SSO</strong>) with the <strong class="bold">Keycloak</strong> service of the platform.</p>
			<div>
				<div id="_idContainer133" class="IMG---Figure">
					<img src="image/B18332_06_009.jpg" alt="Figure 6.9 – MLflow and associated components in the platform&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.9 – MLflow and associated components in the platform</p>
			<p>As you can see in <em class="italic">Figure 6.9</em>, the MLflow pod has two containers in it: the MLflow server and the OAuth2 proxy. The Oauth2 proxy has been configured to use the Keycloak instance you<a id="_idIndexMarker451"/> installed.</p>
			<p>When you created a<a id="_idIndexMarker452"/> new instance of ODH in <a href="B18332_05_ePub.xhtml#_idTextAnchor069"><em class="italic">Chapter 5</em></a>, <em class="italic">Data Engineering</em>, it installed many platform components, including MLflow and Minio. Now, let's validate the MLflow installation.</p>
			<h2 id="_idParaDest-94"><a id="_idTextAnchor093"/>Validating the MLflow installation</h2>
			<p>ODH has already installed the<a id="_idIndexMarker453"/> MLflow and associated components for you. Now, you will use the MLflow GUI to get yourself familiar with the tool. You can imagine all the team members will have access to experiments and models, which will improve your team's collaboration:</p>
			<ol>
				<li value="1">Get the ingress objects created in your Kubernetes environment using the following command. This is to get the URL of the endpoints where our services are deployed:<p class="source-code"><strong class="bold">kubectl get ingress -n ml-workshop</strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer134" class="IMG---Figure">
					<img src="image/B18332_06_010.jpg" alt="Figure 6.10 – All ingress objects in your cluster namespace&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.10 – All ingress objects in your cluster namespace</p>
			<ol>
				<li value="2">Open the Minio GUI, our S3 component, and validate that there is a bucket available for MLflow to be used as<a id="_idIndexMarker454"/> its storage. The URL for the Minio component will look like <strong class="source-inline">https://minio.192.168.61.72.nip.io</strong>, where you will adjust the IP address as per your environment. The password is configured in the manifests file, and it is <strong class="source-inline">minio123</strong>. We have added Minio to the manifests to show that there is an option available using open source technologies, but making it suitable for production is out of scope for this book. Click on the buckets menu item on the left-hand side of the screen and you will see the available buckets:</li>
			</ol>
			<div>
				<div id="_idContainer135" class="IMG---Figure">
					<img src="image/B18332_06_011.jpg" alt="Figure 6.11 – Minio bucket list&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.11 – Minio bucket list</p>
			<p>How are all of these buckets created? In the manifests, we have a Kubernetes job that creates the buckets. You can find the job at <strong class="source-inline">manifests/minio/base/minio-job.yaml</strong>. The job is using the Minio command-line client, <strong class="source-inline">mc</strong>, to create<a id="_idIndexMarker455"/> the buckets. You can find these commands under the <strong class="source-inline">command</strong> field name in this file.</p>
			<p>The configuration of S3 that is being used by MLflow is configured at <strong class="source-inline">manifests/mlflow/base/mlflow-dc.yaml file</strong>.</p>
			<p>You can see the settings as follows: </p>
			<div>
				<div id="_idContainer136" class="IMG---Figure">
					<img src="image/B18332_06_012.jpg" alt="Figure 6.12 – MLflow configuration to use Minio&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.12 – MLflow configuration to use Minio</p>
			<ol>
				<li value="3">Open a browser and paste the <strong class="source-inline">HOSTS</strong> value for the <strong class="source-inline">jupyterhub</strong> ingress into your browser. For me, it was <a href="https://mlflow.192.168.61.72.nip.io">https://mlflow.192.168.61.72.nip.io</a>. This URL will take you to the Keycloak login page, which is the SSO server as shown in the following figure. Make sure that you replace the IP address with yours in this URL. Recall that the authentication part of MLflow is being managed by a proxy that you have configured in <strong class="source-inline">manifests/mlflow/base/mlflow-dc.yaml</strong>.</li>
				<li>You can see the configuration of the OAuth proxy for MLflow as follows. Because <strong class="source-inline">oauth-proxy</strong> and MLflow belong to<a id="_idIndexMarker456"/> the same pod, all we have done is route the traffic from <strong class="source-inline">oauth-proxy</strong> to the MLflow container. This is set up with the <strong class="source-inline">–upstream</strong> property. You can also see <strong class="source-inline">oauth-proxy</strong> needs the name of the identity provider server, which is Keycloak, and it is configured under the <strong class="source-inline">–oidc-issuer</strong> property:</li>
			</ol>
			<div>
				<div id="_idContainer137" class="IMG---Figure">
					<img src="image/B18332_06_013.jpg" alt="Figure 6.13 – OAuth proxy configuration for MLflow &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.13 – OAuth proxy configuration for MLflow </p>
			<p>The landing page of MLflow looks like the page in <em class="italic">Figure 6.14</em>. You will notice there are two sections on the top bar menu. One has the label <strong class="bold">Experiments </strong>and the other one, <strong class="bold">Models</strong>.</p>
			<ol>
				<li value="5">Before you see this page, the SSO <a id="_idIndexMarker457"/>configuration will display the login page. Enter the user ID as <strong class="source-inline">mluser</strong> and the password as <strong class="source-inline">mluser</strong> to log in. The username and password were configured in <a href="B18332_04_ePub.xhtml#_idTextAnchor055"><em class="italic">Chapter 4</em></a>, <em class="italic">The</em> <em class="italic">Anatomy of a Machine Learning Platform</em>, in the <em class="italic">Creating a Keycloak user</em> section. </li>
			</ol>
			<div>
				<div id="_idContainer138" class="IMG---Figure">
					<img src="image/B18332_06_014.jpg" alt="Figure 6.14 – MLflow experiment tracking page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.14 – MLflow experiment tracking page</p>
			<p>The left-hand side of the <strong class="bold">Experiments</strong> screen contains the list of experiments, and the right-hand side displays the details of experiment runs. Think of the experiment as the data science project you are working on, such as fraud detection in consumer transactions, and the <strong class="bold">Notes</strong> section captures the combination of parameters, algorithms, and other information used to run the experiment.</p>
			<ol>
				<li value="6">Click on the <strong class="bold">Models</strong> tab to see the<a id="_idIndexMarker458"/> landing page of the model registry.</li>
			</ol>
			<p>The <strong class="bold">Models</strong> tab contains the list of models in the registry, their versions, and their corresponding stages, which mention what environment the models are deployed in.</p>
			<div>
				<div id="_idContainer139" class="IMG---Figure">
					<img src="image/B18332_06_015.jpg" alt="Figure 6.15 – MLflow model registry page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.15 – MLflow model registry page</p>
			<p>If you can open the MLflow URL and see the pages as described in the preceding steps, then you have just validated that MLflow is configured in your platform. The next step is to write a notebook that will train a basic model while recording the details in your MLflow server.</p>
			<h1 id="_idParaDest-95"><a id="_idTextAnchor094"/>Using MLFlow as an experiment tracking system</h1>
			<p>In this section, you<a id="_idIndexMarker459"/> will see how the MLflow library allows you to record your experiments with the MLflow server. The custom notebook image, which you saw in the first part of this chapter, already has MLflow libraries packaged into the container. Please refer to the <strong class="source-inline">chapter6/requirements.txt</strong> file for the exact version of the MLflow library.</p>
			<p>Before we start this activity, it is important to understand two main concepts: <strong class="bold">experiment</strong> and <strong class="bold">run</strong>.</p>
			<p>An experiment is a<a id="_idIndexMarker460"/> logical name under which MLflow records and groups the metadata, for example, an experiment could be the name of your project. Let's say you are working on building a model for<a id="_idIndexMarker461"/> predicting credit card fraud for your retail customer. This could become the experiment name.</p>
			<p>A run is a single<a id="_idIndexMarker462"/> execution of an experiment that is tracked in MLflow. A run belongs to an experiment. Each run may have a slightly different configuration, different hyperparameters, and sometimes, different datasets. You will tweak these parameters of the experiment in a Jupyter notebook. Each execution of model training is typically considered a run.</p>
			<p>MLflow has two main methods of recording the experiment details. The first one, which is our preferred method, is to enable the auto-logging features of MLflow to work with your ML library. It has integration with Scikit, TensorFlow, PyTorch, XGBoost, and a few more. The second way is to record everything manually. You will see both options in the following steps.</p>
			<p>These steps will show you how an experiment run or a model training can be recorded in MLflow while executing in a Jupyter notebook:</p>
			<ol>
				<li value="1">Log in to JupyterHub and make sure to select the custom container, for example, <strong class="bold">Scikit v1.10 - Elyra Notebook Image</strong>.</li>
			</ol>
			<p>Before you hit the <strong class="bold">Start Server</strong> button, add an environment variable by clicking on the <strong class="bold">Add more variables</strong> link. This variable may contain sensitive information such as passwords. MLflow needs this information to upload the artifacts to the Minio S3 server.</p>
			<p>The landing page will look like the screenshot in <em class="italic">Figure 6.16</em>:</p>
			<div>
				<div id="_idContainer140" class="IMG---Figure">
					<img src="image/B18332_06_016.jpg" alt="Figure 6.16 – JupyterHub with an environment variable&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.16 – JupyterHub with an environment variable</p>
			<ol>
				<li value="2">Open the <a id="_idIndexMarker463"/>notebook at <strong class="source-inline">chapter6/hellomlflow.ipynb</strong>. This notebook shows you how you can record your experiment data onto the MLflow server.</li>
			</ol>
			<div>
				<div id="_idContainer141" class="IMG---Figure">
					<img src="image/B18332_06_017.jpg" alt="Figure 6.17 – Notebook with Mlflow integration&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.17 – Notebook with Mlflow integration</p>
			<p>Note that at the first code cell, you have imported the MLflow library. In the second code cell, you have set up the location of the MLflow server through the <strong class="source-inline">set_tracking_uri</strong> method. Note that because your notebook and the MLflow server are<a id="_idIndexMarker464"/> running on Kubernetes, we just put the location of the Kubernetes Service that is stored in the <strong class="source-inline">HOST</strong> variable name and is being used in this method.</p>
			<p>You then set the name of the experiment using the <strong class="source-inline">set_experiment</strong> method. This is one important variable through which all your experiment runs will be stored in the MLflow server.</p>
			<p>The last method in this cell is <strong class="source-inline">sklearn.autolog</strong>, which is a way to tell MLflow that we are using the Scikit library for our training, and MLflow will record the data through Scikit APIs.</p>
			<div>
				<div id="_idContainer142" class="IMG---Figure">
					<img src="image/B18332_06_018.jpg" alt="Figure 6.18 – Notebook cell with MLflow configuration&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.18 – Notebook cell with MLflow configuration</p>
			<p>In the last cell of this notebook, you are using a simple <strong class="source-inline">DecisionTreeClassifier</strong> to train your model. Notice that this is quite a simple model and is used to highlight the capabilities of the MLflow server.</p>
			<ol>
				<li value="3">Run the notebook by selecting the <strong class="bold">Run &gt; Run all cells</strong> menu option.</li>
				<li>Log in to the <a id="_idIndexMarker465"/>MLflow server and click on the experiment name <strong class="source-inline">HelloMlFlow</strong>. The URL of MLflow will be like <a href="https://mlflow.192.168.61.72.nip.io">https://mlflow.192.168.61.72.nip.io</a> with the IP address replaced as per your environment. As mentioned earlier in this chapter, you get this URL by listing the <em class="italic">ingress</em> objects of your Kubernetes cluster.</li>
			</ol>
			<p>You will see the screen as shown in <em class="italic">Figure 6.19</em>:</p>
			<div>
				<div id="_idContainer143" class="IMG---Figure">
					<img src="image/B18332_06_019.jpg" alt="Figure 6.19 – MLflow experiments tracking screen showing an experiment run&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption"> </p>
			<p class="figure-caption">Figure 6.19 – MLflow experiments tracking screen showing an experiment run</p>
			<p>You will notice that the table on the right-hand side contains one record. This is the experiment run <a id="_idIndexMarker466"/>you performed in <em class="italic">Step 6</em>. If you have executed your notebook multiple times with different parameters, each run will be recorded as a row in this table.</p>
			<ol>
				<li value="5">Click on the first row of the table.</li>
			</ol>
			<p>You will get to the details of the run you selected in the previous step. The screen will look like the screenshot in <em class="italic">Figure 6.20</em>:</p>
			<div>
				<div id="_idContainer144" class="IMG---Figure">
					<img src="image/B18332_06_020.jpg" alt="Figure 6.20 – MLflow run details&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.20 – MLflow run details</p>
			<p>Let's understand the information that is available on this screen:</p>
			<ul>
				<li><strong class="bold">Parameters</strong>: If you click on the little arrow next to <strong class="bold">Parameters</strong>, you will see that it has recorded the hyperparameters of your model training run. If you refer to the <a id="_idIndexMarker467"/>notebook code cell number <strong class="source-inline">4</strong>, you will see that the parameters that we have used for <strong class="source-inline">DecisionTreeClassifier</strong> are recorded here too. One such example is the <strong class="source-inline">max_depth</strong> parameter, as shown in <em class="italic">Figure 6.21</em>:</li>
			</ul>
			<div>
				<div id="_idContainer145" class="IMG---Figure">
					<img src="image/B18332_06_021.jpg" alt="Figure 6.21 – MLflow run parameters&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.21 – MLflow run parameters</p>
			<ul>
				<li><strong class="bold">Metrics</strong>: If you click on the <a id="_idIndexMarker468"/>little arrow next to <strong class="bold">Metrics</strong>, you will see that it has recorded the metrics for your model training run. You can see <strong class="source-inline">training_accuracy</strong> in the screenshot, as shown in <em class="italic">Figure 6.22</em>:</li>
			</ul>
			<div>
				<div id="_idContainer146" class="IMG---Figure">
					<img src="image/B18332_06_022.jpg" alt="Figure 6.22 – MLflow run metrics&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.22 – MLflow run metrics</p>
			<ul>
				<li><strong class="bold">Tags</strong>: If you click on the little arrow next to <strong class="bold">Tags</strong>, you will see the automatically associated tags (for example, <strong class="source-inline">estimator_class</strong>), which define the type of <a id="_idIndexMarker469"/>ML algorithm you have used. Note that you can add your own tags if needed. In the next section, we will show how to associate a custom tag for your run. <em class="italic">Figure 6.23</em> shows an example of tags:</li>
			</ul>
			<div>
				<div id="_idContainer147" class="IMG---Figure">
					<img src="image/B18332_06_023.jpg" alt="Figure 6.23 – MLflow run tags&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.23 – MLflow run tags</p>
			<ul>
				<li><strong class="bold">Artifacts</strong>: This section contains the artifacts associated with the run, such as the binary model file. Note that <a id="_idIndexMarker470"/>you can add your own artifacts here if needed. In the next section, we will show you how to associate an artifact with your run. Keep in mind that the artifacts are stored in the associated S3 bucket of your MLflow server. Note that the model binary is saved as a <strong class="source-inline">model.pkl</strong> file.</li>
			</ul>
			<div>
				<div id="_idContainer148" class="IMG---Figure">
					<img src="image/B18332_06_024.jpg" alt="Figure 6.24 – MLflow run artifacts&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.24 – MLflow run artifacts</p>
			<ol>
				<li value="6">To validate that these files are indeed stored in the S3 server, log in to the Minio server, select <strong class="bold">Buckets</strong>, and click on <strong class="bold">Browse</strong> button for the MLflow bucket. You will find a folder created with the name of your run. This name is displayed in the top-left corner of<a id="_idIndexMarker471"/> your experiment screen; consult the top-left corner of the preceding screen and you will see a label with a combination of 32 alphanumeric characters. This long number is your <strong class="bold">run ID</strong>, and you can see a folder label with a combination of 32 alphanumeric characters in your S3 bucket, as shown in the following screenshot. You can click on this link to find the artifacts stored on the S3 bucket:</li>
			</ol>
			<div>
				<div id="_idContainer149" class="IMG---Figure">
					<img src="image/B18332_06_025.jpg" alt="Figure 6.25 – Minio bucket location&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.25 – Minio bucket location</p>
			<p>You have just successfully trained a model in JupyterHub and tracked the training run in MLflow.</p>
			<p>You have seen how MLflow<a id="_idIndexMarker472"/> associates the data with each of your runs. You can even compare the data between multiple runs by selecting multiple runs from the table shown in <em class="italic">Step 6</em> and clicking on the <strong class="bold">Compare</strong> button.</p>
			<h2 id="_idParaDest-96"><a id="_idTextAnchor095"/>Adding custom data to the experiment run</h2>
			<p>Now, let's see how<a id="_idIndexMarker473"/> we can add more data for each run. You will learn how to use the MLflow API to associate custom data with your experiment:</p>
			<ol>
				<li value="1">Start by firing up the Jupyter notebook as you did in the preceding section.</li>
				<li>Open the notebook at <strong class="source-inline">chapter6/hellomlflow-custom.ipynb</strong>. This notebook shows you how you can customize the recording of your experiment data onto the MLflow server. The notebook is similar to the previous notebook, except for the code in cell number <strong class="source-inline">6</strong>, which is shown in <em class="italic">Figure 6.26</em>. This code cell contains the functions that show how to associate data with your experiment:</li>
			</ol>
			<div>
				<div id="_idContainer150" class="IMG---Figure">
					<img src="image/B18332_06_026.jpg" alt="Figure 6.26 – MLflow customized data collection notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.26 – MLflow customized data collection notebook</p>
			<p>Let's understand these<a id="_idIndexMarker474"/> functions in the next few steps. The code snippet in code cell number <strong class="source-inline">6</strong> is as follows:</p>
			<p class="source-code">with mlflow.start_run(tags={    "mlflow.source.git.commit" : mlflow_util.get_git_revision_hash() ,    "mlflow.source.git.branch": mlflow_util.get_git_branch(),    "code.repoURL": mlflow_util.get_git_remote()    }) as run:        model.fit(X, y)    mlflow_util.record_libraries(mlflow)    mlflow_util.log_metric(mlflow, "custom_mteric", 1.0)    mlflow_util.log_param(mlflow, "docker_image_name", os.environ["JUPYTER_IMAGE"])</p>
			<p>The preceding code will include a custom tag labeled <strong class="source-inline">code.repoURL</strong>. This makes it easier to trace back the original source code that produced the model in a given experiment run.</p>
			<ol>
				<li value="3">You can associate any tags while calling the <strong class="source-inline">start_run</strong> function. Tag keys that start with <em class="italic">mlflow</em> are reserved for internal use. You can see that we have associated the GIT commit hash with the first property. This will help us in following through on what experiment belongs to what code version in your code repository.</li>
			</ol>
			<p>You will find that the <strong class="source-inline">code.repoURL</strong> tag contains the Git repository location. You can add as many tags as you want. You can see the tags by going to the MLflow UI and opening the experiment. Note that the notebook has a different experiment name, and it is being referenced as <strong class="source-inline">HelloMlFlowCustom</strong>.</p>
			<p>Note the <strong class="bold">Git Commit</strong> label at the top<a id="_idIndexMarker475"/> section of the page, and the custom tag name <strong class="source-inline">code.repoURL</strong> in the <strong class="bold">Tags</strong> section:</p>
			<div>
				<div id="_idContainer151" class="IMG---Figure">
					<img src="image/B18332_06_027.jpg" alt=" Figure 6.27 – MLflow custom tags&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption"> Figure 6.27 – MLflow custom tags</p>
			<ol>
				<li value="4">The second function that we have used is <strong class="source-inline">record_libraries</strong>. This is a wrapper function that internally uses the <strong class="source-inline">mlflow.log_artifact</strong> function to associate a file with the run. This utility function is capturing the <strong class="source-inline">pip freeze</strong> output, which gives the libraries in the current environment. The utility function then writes it to a file and uploads the file to the MLflow experiment. You can look at this, and all the other functions, in the <strong class="source-inline">chapter6/mlflow_util.py</strong> file.</li>
			</ol>
			<p>You can see in the <strong class="bold">Artifacts</strong> section that a new file, <strong class="source-inline">pip_freeze.txt</strong>, is available, and it records the<a id="_idIndexMarker476"/> output of the <strong class="source-inline">pipe freeze</strong> command:</p>
			<div>
				<div id="_idContainer152" class="IMG---Figure">
					<img src="image/B18332_06_028.jpg" alt="Figure 6.28 – MLflow customized artifacts&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.28 – MLflow customized artifacts</p>
			<ol>
				<li value="5">The <strong class="source-inline">log_metric</strong> function records the metric name and its associated value. Note that the value for the metric is expected to be a number. For the sample code, you can see that we have just <a id="_idIndexMarker477"/>put a hardcoded value (<strong class="source-inline">1</strong>), however, in the real world, this would be a dynamic value that refers to something relative to each run of your experiment. You can find your custom metric in the <strong class="bold">Metrics </strong>section of the page:</li>
			</ol>
			<div>
				<div id="_idContainer153" class="IMG---Figure">
					<img src="image/B18332_06_029.jpg" alt="Figure 6.29 – MLflow customized metrics&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.29 – MLflow customized metrics</p>
			<ol>
				<li value="6">The <strong class="source-inline">log_param</strong> function is like the <strong class="source-inline">log_metric</strong> function, but it can take any type of value against a given parameter name. For example, we have recorded the Docker image used by<a id="_idIndexMarker478"/> the Jupyter notebook. Recall that this is the custom image you built to be used by the data scientist team. You can see the following <strong class="source-inline">docker_image_name</strong> parameter that contains the desired value:</li>
			</ol>
			<div>
				<div id="_idContainer154" class="IMG---Figure">
					<img src="image/B18332_06_030.jpg" alt="Figure 6.30 – MLflow customized parameters&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.30 – MLflow customized parameters</p>
			<p>You have used MLflow to track, add <a id="_idIndexMarker479"/>custom tags, and custom artifacts to an experiment run. In the next section, you will see the capabilities of MLflow as a model registry component. Let's dig in.</p>
			<h1 id="_idParaDest-97"><a id="_idTextAnchor096"/>Using MLFlow as a model registry system</h1>
			<p>Recall that MLflow has a <a id="_idIndexMarker480"/>model registry feature. The registry provides the versioning capabilities for your models. Automation tools can get the models from the registry to deploy or even roll back your models across different environments. You will see in the later chapters that automation tools in our platform fetch the model from this registry via the API. For now, let's see how to use the registry:</p>
			<ol>
				<li value="1">Log in to the MLflow server by accessing the UI and clicking on the <strong class="bold">Models</strong> link. You should see the following screen. Click on the <strong class="bold">Create Model</strong> button:</li>
			</ol>
			<div>
				<div id="_idContainer155" class="IMG---Figure">
					<img src="image/B18332_06_031.jpg" alt="Figure 6.31 – MLflow registering a new model&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.31 – MLflow registering a new model</p>
			<ol>
				<li value="2">Type a name for your <a id="_idIndexMarker481"/>model in the pop-up window, as shown in the following screenshot, and click on the <strong class="bold">Create</strong> button. This name could mention the name of the project that this model is serving:</li>
			</ol>
			<div>
				<div id="_idContainer156" class="IMG---Figure">
					<img src="image/B18332_06_032.jpg" alt="Figure 6.32 – MLflow model name prompt&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.32 – MLflow model name prompt</p>
			<ol>
				<li value="3">Now, you need to attach a model file to this registered name. Recall from the preceding section that you have multiple <em class="italic">runs</em> in your <em class="italic">experiment</em>. Each run defines the set of configuration parameters and associated models with it. Select the experiment and run for which you want to register your model.</li>
				<li>You will see a screen<a id="_idIndexMarker482"/> like the following. Select the <strong class="bold">model</strong> label in the <strong class="bold">Artifacts</strong> section, and you will notice a <strong class="bold">Register Model</strong> button on the right-hand side. Click on this button:</li>
			</ol>
			<div>
				<div id="_idContainer157" class="IMG---Figure">
					<img src="image/B18332_06_033.jpg" alt="Figure 6.33 – MLflow showing the Register Model button&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.33 – MLflow showing the Register Model button</p>
			<ol>
				<li value="5">From the pop-up window, select the model name you created in <em class="italic">Step 1</em> and click on <strong class="bold">Register</strong>.</li>
			</ol>
			<div>
				<div id="_idContainer158" class="IMG---Figure">
					<img src="image/B18332_06_034.jpg" alt="Figure 6.34 – Model name dialog when registering a model in MLflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.34 – Model name dialog when registering a model in MLflow</p>
			<ol>
				<li value="6">Go to the <strong class="bold">Models</strong> tab as mentioned in <em class="italic">Step 1</em> and you will see your model is registered in the MLflow<a id="_idIndexMarker483"/> registry. You will see the list as shown in the following screenshot. Click on the model name, for example, <strong class="source-inline">mlflowdemo</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer159" class="IMG---Figure">
					<img src="image/B18332_06_035.jpg" alt="Figure 6.35 – MLflow showing the list of registered models and their versions&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.35 – MLflow showing the list of registered models and their versions</p>
			<ol>
				<li value="7">You will see the detail screen where you can attach the stage of the model as referred to by the <strong class="bold">Stage</strong> label. You <a id="_idIndexMarker484"/>can also edit other properties, and we will leave it to you to explore the data you can associate with this model:</li>
			</ol>
			<div>
				<div id="_idContainer160" class="IMG---Figure">
					<img src="image/B18332_06_036.jpg" alt="Figure 6.36 – MLflow showing the buttons for promoting registered models to higher environments&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 6.36 – MLflow showing the buttons for promoting registered models to higher environments</p>
			<p>Congratulations! You have just <a id="_idIndexMarker485"/>experienced using MLflow as a model registry! You have also seen how the model version can be promoted to the different stages of the lifecycle.</p>
			<h1 id="_idParaDest-98"><a id="_idTextAnchor097"/>Summary</h1>
			<p>In this chapter, you have gained a better understanding of ML engineering and how it differs from data science. You have also learned about some of the responsibilities of ML engineers. You must take note that the definition of ML engineering and the role of ML engineers are still evolving, as more and more techniques are surfacing. One such technique that we will not talk about in this book is <strong class="bold">online ML</strong>.</p>
			<p>You have also learned how to create a custom notebook image and use it to standardize notebook environments. You have trained a model in the Jupyter notebook while using MLflow to track and compare your model development parameters, training results, and metrics. You have also seen how MLflow can be used as a model registry and how to promote model versions to different stages of the lifecycle.</p>
			<p>The next chapter will continue the ML engineering domain and you will package and deploy ML models to be consumed as an API. You will then automate the package and deploy the process using the tools available in the ML platform.</p>
		</div>
	</body></html>