<html><head></head><body>
		<div id="_idContainer056">
			<h1 id="_idParaDest-105" class="chapter-number"><a id="_idTextAnchor104"/>10</h1>
			<h1 id="_idParaDest-106"><a id="_idTextAnchor105"/>Implementing Telemetry and Observability in the Cloud</h1>
			<p>As we already know, Cloud Native applications typically consist of multiple small services that communicate over the network. Cloud Native apps are frequently updated and replaced with newer versions and in this chapter, we emphasize the need to monitor and optimize them based on observations for best performance with cost <span class="No-Break">in mind.</span></p>
			<p>This chapter covers further requirements from <em class="italic">Cloud Native Observability</em> domain of KCNA exam that makes up 8% of the total exam questions. The following are the topics we’re going to <span class="No-Break">focus on:</span></p>
			<ul>
				<li>Telemetry <span class="No-Break">and observability</span></li>
				<li>Prometheus for monitoring <span class="No-Break">and alerting</span></li>
				<li>FinOps and <span class="No-Break">cost management</span></li>
			</ul>
			<p>Let’s <span class="No-Break">get started!</span></p>
			<h1 id="_idParaDest-107"><a id="_idTextAnchor106"/>Telemetry and observability</h1>
			<p>With the evolution of traditional monolithic architectures towards distributed loosely coupled microservice architectures, the need for detailed high-quality telemetry quickly became apparent. Before elaborating any further, let’s first define what <strong class="bold">Telemetry</strong> is in the context <a id="_idIndexMarker577"/>of <span class="No-Break">IT infrastructure.</span></p>
			<p class="callout-heading">Telemetry</p>
			<p class="callout">Refers to monitoring and collection of data about system performance for analysis that helps identify issues. Telemetry is a <a id="_idIndexMarker578"/>broad term for <strong class="bold">logs</strong>, <strong class="bold">metrics</strong>, and <strong class="bold">traces</strong> that <a id="_idIndexMarker579"/>are also known as telemetry types <span class="No-Break">or</span><span class="No-Break"><a id="_idIndexMarker580"/></span><span class="No-Break"> signals.</span></p>
			<p>With Cloud Native applications being distributed by design, the ability to track and trace all communication between the parts plays a major role for troubleshooting, finding bottlenecks and providing insights on how <span class="No-Break">application performs.</span></p>
			<p>All three<a id="_idIndexMarker581"/> telemetry signals (<strong class="bold">logs</strong>, <strong class="bold">metrics</strong> and <strong class="bold">traces</strong>) help us to better understand the state of the application and infrastructure at any given point of time and take a corrective action <span class="No-Break">if needed.</span></p>
			<p class="callout-heading">Observability</p>
			<p class="callout">Is the <a id="_idIndexMarker582"/>capability to continuously generate insights based on telemetry signals from the observed system. In other words, an observable system is the one, the state of which is clear with the <em class="italic">right data</em> provided at the <em class="italic">right time</em> to make the <span class="No-Break"><em class="italic">right decision</em></span><span class="No-Break">.</span></p>
			<p>Let’s explain what this <em class="italic">right data</em> at the <em class="italic">right time</em> to make the <em class="italic">right decision</em> means with an example. Consider you are operating microservices on Kubernetes with most of the services persisting data in a database layer <a id="_idIndexMarker583"/>backed by <strong class="bold">Persistent </strong><span class="No-Break"><strong class="bold">Volumes</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">PV</strong></span><span class="No-Break">).</span></p>
			<p>Obviously, you need to make sure that all databases are operational and that there is enough disk space available on the storage appliance serving the PVs. If you only collect and analyze the <em class="italic">logs</em> of the services, that will not be enough to make decision when the storage capacity should be extended. For instance, services using databases can crash suddenly because they cannot write to their databases anymore. Logs of the databases will point to the fact that the storage space has run out and more capacity is <span class="No-Break">urgently required.</span></p>
			<p>In this case, the logs are helpful to find the culprit, but they are not exactly the right data provided at the right time. The <em class="italic">right data</em> would be continuous disk utilization metrics collected from the storage appliance. The <em class="italic">right time</em> would be predefined threshold (let’s say appliance is 70% full) that gives operator enough time to make the <em class="italic">right decision</em> of extending or freeing the capacity. Informing operator that the database storage is 100% full and services are down at 2AM is clearly not the best way <span class="No-Break">to go.</span></p>
			<p>That is why relying on only one telemetry signal is almost never enough and we should have all three in place to ensure observability. Observability is one of the keys behind faster incident responses, increased productivity and optimal performance. However, having more information does not necessary translate into a more observable system. Sometimes, having <a id="_idIndexMarker584"/>too much information can have an opposite effect and make it harder to distinguish the valuable insights from the noise (e.g., excessive log records produced by the maximum debug level of <span class="No-Break">an application).</span></p>
			<p>Let’s now see each of the telemetry signals in more details<a id="_idIndexMarker585"/> starting <span class="No-Break">with logs.</span></p>
			<p class="callout-heading">Logs</p>
			<p class="callout">Are <a id="_idIndexMarker586"/>events described as text which are recorded by an application, an operating system or an appliance (for example, firewall, load <span class="No-Break">balancer, etc.).</span></p>
			<p>The events that log records represent could be pretty much anything ranging from a service restart and user login to an API request with payload received or an execution of a certain method in code. Logs often include timestamp, text message and further information such as status codes, severity levels (<strong class="source-inline">DEBUG</strong>, <strong class="source-inline">INFO</strong>, <strong class="source-inline">WARNING</strong>, <strong class="source-inline">ERROR</strong>, <strong class="source-inline">CRITICAL</strong>), user ids and <span class="No-Break">so on.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">The log severity levels as well as instructions on how to access container logs in Kubernetes have been discussed in detail in <a href="B18970_07.xhtml#_idTextAnchor077"><span class="No-Break"><em class="italic">Chapter 7</em></span></a> in section <em class="italic">Debugging applications in Kubernetes</em>. Make sure to go back, if you’ve skipped it before for <span class="No-Break">any reason.</span></p>
			<p>Below you’ll find a sample log message recorded by Nginx webserver when processing an <strong class="source-inline">HTTP v1.1</strong> <strong class="source-inline">GET</strong> request received from client with IP <strong class="source-inline">66.211.65.62</strong> on the 4<span class="superscript">th</span> of <span class="No-Break">October 2022:</span></p>
			<pre class="source-code">
66.211.65.62 - - [04/Oct/2022:19:12:14 +0600] "GET /?q=%E0%A6%A6%E0%A7%8B%E0%A7%9F%E0%A6%BE HTTP/1.1" 200 4556 "-" "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)"</pre>
			<p>Additional information can be derived from the message, <span class="No-Break">such as:</span></p>
			<ul>
				<li>response status code <strong class="source-inline">200</strong> (<span class="No-Break"><strong class="source-inline">HTTP OK</strong></span><span class="No-Break">)</span></li>
				<li>the number of bytes sent to the <span class="No-Break">client </span><span class="No-Break"><strong class="source-inline">4556</strong></span></li>
				<li>the URL and query <span class="No-Break">string </span><span class="No-Break"><strong class="source-inline">/?q=%E0%A6%A6%E0%A7%8B%E0%A7%9F%E0%A6%</strong></span></li>
				<li>as well as user agent <strong class="source-inline">Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)</strong> that in fact tells us that the request is done by Google’s <span class="No-Break">web crawler.</span></li>
			</ul>
			<p>Depending <a id="_idIndexMarker587"/>on the application, the log format can be adjusted to only include the information you’d like and skip any <span class="No-Break">unnecessary details.</span></p>
			<p>Next on the <a id="_idIndexMarker588"/>signals list are<a id="_idIndexMarker589"/> metrics. Let’s figure out what <span class="No-Break">they are.</span></p>
			<p class="callout-heading">Metrics</p>
			<p class="callout">Are regular measurements that describe the performance of an application or a system over the course of time in a <span class="No-Break">time-series format.</span></p>
			<p>Common examples include metrics like CPU, RAM utilization, number of open connections or response time. If you think about it, single, irregular measurements do not provide much value or insight about the state of the system. There might be a short spike in utilization that is over in less than a minute, or the other way around: utilization dropping for <span class="No-Break">some time.</span></p>
			<p>With single measurements, it is not possible to make any prediction or analyze how the application or the system behaves. With time-series, we can analyze how one or another metric has changed, determine trends and patters, and envision upcoming changes. That is why metrics should be collected at a regular, short intervals typically in a range between 30 seconds to a few minutes. Time-series can also be plotted as a graph for visual representation as shown on <span class="No-Break"><em class="italic">Figure </em></span><span class="No-Break"><em class="italic">10</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break"> below:</span></p>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/B18970_10_01.jpg" alt="Figure 10.1 – CPU usage metric visualization (X = time, Y = utilization)."/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.1 – CPU usage metric visualization (X = time, Y = utilization).</p>
			<p>While it<a id="_idIndexMarker590"/> looks<a id="_idIndexMarker591"/> like there been a huge increase in CPU usage between 12:30 to 13:15 according to the graph, the maximum utilization over the period shown was always under 10% suggesting that the system is heavily underutilized. Basic metrics like CPU, memory, or disk usage should always be collected, but often they are not enough to make the <span class="No-Break"><em class="italic">right decisions</em></span><span class="No-Break">.</span></p>
			<p>Therefore, it is recommended to collect multiple application-specific metrics which could include number of API requests per minute, number of messages waiting in a queue, request response times, number of open connections, and so on. Some of those metrics can be well suited to making right autoscaling decisions and some to provide valuable insights on <span class="No-Break">application performance.</span></p>
			<p>That’s it about <a id="_idIndexMarker592"/>metrics for now. Let’s continue with request tracing <span class="No-Break">as next.</span></p>
			<p class="callout-heading">Tracing</p>
			<p class="callout">Is a complete<a id="_idIndexMarker593"/> tracking of the requests passing through the components of a distributed system. It allows to see which components are involved in the processing of a particular request, how long the processing takes, and any additional events that happen along. <em class="italic">Traces</em> are the results of <span class="No-Break">tracing requests.</span></p>
			<p>Now imagine the following situation. You are investigating longer response times of a distributed, microservice based application you operate, yet the number of requests or load has not <a id="_idIndexMarker594"/>changed much. Since <a id="_idIndexMarker595"/>most of the application requests traverses’ multiple services, you’ll need to verify each and every service to find the one (or several ones) that are not performing well. However, if you integrate a tracing utility <a id="_idIndexMarker596"/>such as <strong class="bold">Jaeger</strong> or <strong class="bold">Zipkin</strong>, it would allow <a id="_idIndexMarker597"/>you to<a id="_idIndexMarker598"/> trace requests and store and analyze the results. Traces would show which service is having longer response times and might be slowing the whole application down. The traces collected can then be viewed in a dashboard such as the one shown on <span class="No-Break"><em class="italic">Figure </em></span><span class="No-Break"><em class="italic">10</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break"> below:</span></p>
			<div>
				<div id="_idContainer054" class="IMG---Figure">
					<img src="image/B18970_10_02.jpg" alt="Figure 10.2 – example trace view in Jaeger dashboard."/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.2 – example trace view in Jaeger dashboard.</p>
			<p>All-in-all, tracing contributes a lot to observability. It helps to understand the flow of traffic and detect the bottlenecks or issues quickly. Along with logs and metrics, the three telemetry types are a must for monitoring of modern applications and infrastructure. Without those, operators are <em class="italic">blind</em> and cannot be sure that all systems are operational and perform as expected. It might take some effort and time to implement the telemetry and observability right, but it always pays off as eventually it will save you a lot of time when it comes to <span class="No-Break">troubleshooting problems.</span></p>
			<p>Speaking about implementation – there is a CNCF project called <strong class="bold">OpenTelemetry</strong> or <strong class="bold">OTel</strong> for short. It <a id="_idIndexMarker599"/>provides a set of standardized vendor-agnostic APIs, SDKs and tools to ingest, transform and send data to an observability backend. Support for a large number of open-source and commercial protocols and programming languages (<em class="italic">C++</em>, <em class="italic">Java</em>, <em class="italic">Go</em>, <em class="italic">Python</em>, <em class="italic">PHP</em>, <em class="italic">Ruby</em>, <em class="italic">Rust</em> and more) makes it easy to incorporate telemetry into practically any application. It is not strictly required for the scope of KCNA, but if you’d like to know more about it – there will be links in the <em class="italic">Further Reading</em> <span class="No-Break">section below.</span></p>
			<p>Moving on, in<a id="_idIndexMarker600"/> the next section we’ll learn about <strong class="bold">Prometheus</strong> – number one tool for Cloud <span class="No-Break">Native observability.</span></p>
			<h1 id="_idParaDest-108"><a id="_idTextAnchor107"/>Prometheus for monitoring and alerting</h1>
			<p>After its<a id="_idIndexMarker601"/> initial appearance in 2012, Prometheus quickly gained popularity with its rich functionality and <strong class="bold">Time Series Database</strong> (<strong class="bold">TSDB</strong>) that <a id="_idIndexMarker602"/>allowed to persisting metrics for querying, analysis, and predictions. Interestingly, Prometheus was inspired by Google’s <strong class="bold">Borgmon</strong> – tool<a id="_idIndexMarker603"/> used for monitoring<a id="_idIndexMarker604"/> Google’s <strong class="bold">Borg</strong> – the predecessor <span class="No-Break">of Kubernetes.</span></p>
			<p>In 2016, Prometheus was accepted as the second CNCF project (after K8s) that has reached <em class="italic">Graduated</em> status by the year 2018. Today, Prometheus is considered an industry standard for monitoring and alerting and widely used with Kubernetes and other <span class="No-Break">CNCF projects.</span></p>
			<p>But enough history, let’s get to the point. First, what is <span class="No-Break">a TSDB?</span></p>
			<p class="callout-heading">TSDB</p>
			<p class="callout">Is a database optimized for storage of data with timestamps. The data could be measurements or events that are tracked and aggregated over time. In case of Prometheus, the data are metrics collected regularly from applications and parts of the infrastructure. The metrics are kept in Prometheus TSDB and can be queried with its own, powerful <em class="italic">PromQL</em> <span class="No-Break">query language.</span></p>
			<p>How are the metrics being collected? In general, there are two approaches on collecting <span class="No-Break">monitoring metrics:</span></p>
			<ul>
				<li><strong class="bold">Pull</strong> – when a (micro-)service exposes an HTTP endpoint with metrics data, that is periodically <em class="italic">scraped (collected)</em> by the monitoring software. Commonly, it is a <strong class="source-inline">/metrics</strong> URL that is called with a simple HTTP <strong class="source-inline">GET</strong> request. This is the dominant way how Prometheus works. The service should make the metrics available and keep them up-to-date and Prometheus should make <strong class="source-inline">GET</strong> requests against <strong class="source-inline">/metrics</strong> to fetch the <span class="No-Break">data regularly.</span></li>
				<li><strong class="bold">Push</strong> – opposite of pull, the service or an application should send the metrics data to the monitoring software. Also supported by Prometheus with <strong class="source-inline">Pushgateway</strong> and done with HTTP <strong class="source-inline">PUT</strong> requests. Helpful for the cases when service metrics cannot be <em class="italic">scrapped (pulled)</em> due to network restrictions (service behind a firewall or NAT gateway) or simply when the source of the metric has very short lifespan (e.g., quick <span class="No-Break">batch job).</span></li>
			</ul>
			<p>When we say <em class="italic">metrics data</em>, it means not just the metric name and value but also a timestamp and often additional labels. Labels indicate certain attributes of a metric <a id="_idIndexMarker605"/>and can hold the hostname of a server where the metric was scraped, the name of an application or pretty much anything else. Labels are very helpful for grouping and querying the metrics data with Prometheus’ PromQL language. Let’s see the following metric for <span class="No-Break">an example:</span></p>
			<pre class="source-code">
nginx_ingress_controller_requests{
cluster="production",
container="controller",
controller_class="k8s.io/ingress-nginx",
endpoint="metrics",
exported_namespace="kcna",
exported_service="kcnamicroservice",
host="kcnamicroservice.prd.kcna.com",
ingress="kcnamicroservice",
instance="100.90.111.22:10254",
job="kube-system-ingress-nginx-controller-metrics",
method="GET",
namespace="kube-system",
path="/",
pod="kube-system-ingress-nginx-controller-7bc4747dcf-4d246",
prometheus="kube-monitoring/collector-kubernetes",
status="200"} 273175</pre>
			<p>Here, <strong class="source-inline">nginx_ingress_controller_requests</strong> is the name of the metric, <strong class="source-inline">273175</strong> is the value of the metric (representing number of requests) and everything else between <strong class="source-inline">{}</strong> are the labels. As you can see, labels are crucial to narrow down the metric scope, which service it applies to, or what exactly it represents. In this example, it shows the count of HTTP <strong class="source-inline">GET</strong> requests that were responded with HTTP <strong class="source-inline">200 OK</strong> for the service called <strong class="source-inline">kcnamicroservice</strong> located in <span class="No-Break"><strong class="source-inline">kcna</strong></span><span class="No-Break"> namespace.</span></p>
			<p>One other <a id="_idIndexMarker606"/>great feature of Prometheus is the dashboard that lets us visualize the data from TSDB directly in the Prometheus UI. While it is very easy to plot graphs with it, its functionality is somewhat limited and that is why many people use <strong class="bold">Grafana</strong> for<a id="_idIndexMarker607"/> visualization and <span class="No-Break">metrics analytics.</span></p>
			<p>Now let’s think for a moment how we could collect metrics with Prometheus from applications that we cannot modify? We are talking about services that weren’t developed within your company and the ones that don’t expose the metrics on a <strong class="source-inline">/metrics</strong> endpoint. This also applies to software that does not come with a webserver such as databases and message buses or even for basic OS stats (CPU, RAM, disk utilization). The solution for such cases is called<a id="_idIndexMarker608"/> <span class="No-Break">Prometheus </span><span class="No-Break"><strong class="bold">Exporter</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Prometheus Exporter</p>
			<p class="callout">Is a small tool that bridges the gap between the Prometheus server and applications that don’t natively export metrics. Exporters aggregate custom metrics from a process or a service in the format supported by Prometheus and expose them over <strong class="source-inline">/metrics</strong> endpoint <span class="No-Break">for collection.</span></p>
			<p>Essentially, an exporter is a minimalistic webserver that knows how to capture metrics from an application that must be monitored and transforms those into Prometheus format for collection. Let’s take PostgreSQL database as an example. Natively it does not expose any metrics, but we can run an exporter along with it that would query the DB and provide observability data that will be pulled into Prometheus TSDB. If run on Kubernetes, the typical way to place an exporter is to put it in the same Pod with the service monitored as a <em class="italic">Sidecar</em> container (in case you missed it, <em class="italic">Sidecar</em> containers are explained in <a href="B18970_05.xhtml#_idTextAnchor059"><span class="No-Break"><em class="italic">Chapter 5</em></span></a><span class="No-Break">).</span></p>
			<p>Today, you’ll find a ton of ready-to-use exporters for popular software such as <em class="italic">MySQL</em>, <em class="italic">Redis</em>, <em class="italic">Nginx</em>, <em class="italic">HaProxy</em>, <em class="italic">Kafka</em> and more. However, if there is no exporter available – it is not a big deal to write one own using any popular programming language with Prometheus <span class="No-Break">client libraries.</span></p>
			<p>Speaking about <a id="_idIndexMarker609"/>Kubernetes and Prometheus, there is a seamless integration between the two. Prometheus has <em class="italic">out-of-the-box</em> capabilities to monitor Kubernetes and automatically discover the service endpoints of the workloads you run in your K8s cluster. Besides Kubernetes, there is also support for various PaaS and IaaS offerings including those from Google Cloud, Microsoft Azure, Amazon Web Services and <span class="No-Break">many other.</span></p>
			<p>With that, we’ve covered the part about monitoring with Prometheus and before moving on to the alerting, let’s <a id="_idIndexMarker610"/>have a look at <span class="No-Break"><em class="italic">Figure </em></span><span class="No-Break"><em class="italic">10</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break"> first:</span></p>
			<div>
				<div id="_idContainer055" class="IMG---Figure">
					<img src="image/B18970_10_03.jpg" alt="Figure 10.3 – Prometheus architecture."/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 10.3 – Prometheus architecture.</p>
			<p>As you can see, Prometheus server will pull metrics from its <em class="italic">targets</em> that can be statically configured or discovered dynamically with service discovery. Short-lived jobs or services behind NAT can also push their metrics via <strong class="source-inline">Pushgateway</strong>. The metrics can be queried, displayed, and visualized with <strong class="source-inline">PromQL</strong> in <em class="italic">Prometheus web UI</em> or <span class="No-Break">third-party tools.</span></p>
			<p>Moving on, we are going to<a id="_idIndexMarker611"/> learn about Prometheus <strong class="bold">Alertmanager</strong> and<a id="_idIndexMarker612"/> its <span class="No-Break">notification capabilities.</span></p>
			<p class="callout-heading">Alerts</p>
			<p class="callout">Are reactive elements of a monitoring system triggered by a metric change or a crossing of a <span class="No-Break">certain threshold.</span></p>
			<p>Alerts are used to notify team or an engineer on duty about the change of state in an application or an infrastructure. The notification can take a form of an e-mail, SMS or a chat message as an example. Alertmanager, as you already guessed, is the component of Prometheus responsible for the alerts <span class="No-Break">and notifications.</span></p>
			<p>An alert is normally triggered when a certain metric (or a combination of multiple metrics) has crossed a predefined threshold and stayed above or beyond it for some minutes. Alert definitions are based on Prometheus expression language and accept mathematical operations which allows flexible definition of conditions. In fact, a quite unique feature of Prometheus is the ability to predict when a metric will reach a certain threshold and raise an alert early, before it actually happens. This way, you can define an alert that will notify you five days in advance before a host runs of disk space, as an example. This is possible thanks to Prometheus TSDB that keeps time-series and allows analyzing the data and its rate <span class="No-Break">of change.</span></p>
			<p>Overall, Prometheus is an ultimate solution for monitoring in the Cloud Native era. It is often used to monitor both Kubernetes itself and workloads that run on top of Kubernetes. Today you’ll find plenty of software that supports Prometheus natively by exposing metrics data via <strong class="source-inline">/metrics</strong> endpoint in the Prometheus format. Client libraries available in many languages make it possible to integrate Prometheus support directly in your own applications. This process is sometimes called <strong class="bold">direct instrumentation</strong> as it <a id="_idIndexMarker613"/>introduces native support of Prometheus. For applications and software that does not offer native support, you are likely to find exporters that extract the data and offer it in Prometheus metric format <span class="No-Break">for collection.</span></p>
			<p>Now, some of you probably cannot wait to make hands dirty with Prometheus, but in fact we’ve already covered it in more details than it is required to pass KCNA exam. Nevertheless, you <a id="_idIndexMarker614"/>are encouraged to check <em class="italic">Further Reading</em> section and try deploying Prometheus onto our miniKube K8s cluster yourself. And for now, we’re moving on to the topic of <span class="No-Break">cost management.</span></p>
			<h1 id="_idParaDest-109"><a id="_idTextAnchor108"/>FinOps and cost management</h1>
			<p>With<a id="_idIndexMarker615"/> rapid transition<a id="_idIndexMarker616"/> from traditional data centers and collocation towards cloud, it has quickly became apparent<a id="_idIndexMarker617"/> that cloud services might be pretty expensive. In fact, if you’d see a bill of a public cloud provider, you’ll often find that <em class="italic">everything</em> is metered and <em class="italic">everything</em> costs money: cross availability zone traffic and Internet traffic, number of objects or usage of space, number of API requests, Internet IPs, different VM flavors, tiered storage and additional IOPS, storage of VMs that are shut down and the list goes on and on. Sometimes, prices also vary from region to region making it hard to estimate the costs in advance. This has led to the appearance of FinOps in the <span class="No-Break">recent years.</span></p>
			<p class="callout-heading">FinOps</p>
			<p class="callout">Is a <a id="_idIndexMarker618"/>cloud financial management discipline and cultural practice. It helps organizations to get the maximum business value based on collaboration of engineering, finance, technology and business teams to make data-driven <span class="No-Break">spending decisions.</span></p>
			<p>Where DevOps puts a lot of focus on collaboration between <em class="italic">Development</em> and <em class="italic">Operations</em>, FinOps adds <em class="italic">Finance</em> to the mix. It helps the teams to manage their cloud spending and stresses the need of collaboration between engineering and business teams as a part of continuous improvement and optimization process. While you don’t need to know the details for the scope of KCNA exam, you’re still encouraged to check about FinOps in the <em class="italic">Further </em><span class="No-Break"><em class="italic">Reading</em></span><span class="No-Break"> section.</span></p>
			<p>When we talk about cloud, by default we assume that we can provision and terminate resources such as virtual machines at any time we want. And we only pay for the time the VM was running. This is <a id="_idIndexMarker619"/>known as <strong class="bold">on-demand</strong> capacity or on-demand pricing model, and this is the most popular way to consume cloud services today. You use it – you pay for it, if you’re running nothing – then nothing <span class="No-Break">is charged.</span></p>
			<p>However, there are two more options commonly offered by public <span class="No-Break">cloud providers:</span></p>
			<ul>
				<li><strong class="bold">Reserved instances</strong> – These <a id="_idIndexMarker620"/>are VMs or bare-metal servers that you reserve for a longer period of time (typically one or more years) and pay the costs up front. Reserved instances come with a very good discount (30-70%) from the regular, on-demand pricing, but you don’t get the same flexibility. Meaning that you’ll keep paying for reserved resources even if you don’t <span class="No-Break">need them.</span></li>
				<li><strong class="bold">Spot instances</strong> (sometimes called <strong class="bold">preemptible instances</strong>) – are the instances<a id="_idIndexMarker621"/> that can <a id="_idIndexMarker622"/>be terminated (deleted) by the cloud provider at any point. Spot instances are leftover and spare capacities that providers offer with huge discounts (60-90%) from on-demand capacity. In some cases, you’ll need to bid (as on auction) for Spot instances and as long as you’re bidding more than the others your instance continues <span class="No-Break">to run.</span></li>
			</ul>
			<p>So, which instance type should <span class="No-Break">you use?</span></p>
			<p>There is no easy answer to this question as there are many variables that come into play and the answer varies from case to case. The rule of a thumb is to buy Reserved instances only for constant workloads or the minimal capacity that is always needed to run your applications. Spot instances can be used for non-critical workloads, batch processing and various non-real-time analytics. Workloads that can be restarted and completed later are a great fit for Spot. And on-demand can be used for everything else including temporarily scaling to accommodate higher loads. As you remember from the previous chapter, <em class="italic">Autoscaling</em> is one of<a id="_idIndexMarker623"/> the main features of Cloud Native architectures and this is where you’d normally use <span class="No-Break">on-demand instances.</span></p>
			<p>Yet effective cost management in cloud needs more than just right capacity type (on-demand/reserved/spot). The<a id="_idIndexMarker624"/> instances should also be of the right size (flavor). This is known <span class="No-Break">as </span><span class="No-Break"><strong class="bold">Righsizing</strong></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Rightsizing</p>
			<p class="callout">Is the continuous process of matching instance size to workload performance and capacity requirements with cost <span class="No-Break">in mind.</span></p>
			<p>We already know that autoscaling is crucial for cost efficiency, and autoscaling can be seen as a part<a id="_idIndexMarker625"/> of Rightsizing strategy. You don’t want to run too many underutilized instances when the load is low and the opposite – not having enough instances to handle high load. Autoscaling should target the sweet spot between the capacity/performance and the associated infrastructure costs. But besides the number of instances, their size (number of CPUs, GBs of memory, network throughput, etc.) is <span class="No-Break">also important.</span></p>
			<p>For example, running 40 Kubernetes worker nodes as VMs with only 4 CPUs and 8 GB of RAM might cost you more than running 20 worker nodes with 8 CPUs and 16 GB RAM each despite the same total number of CPUs and RAM. Additionally, many providers offer instances based on different CPU generations and flavors optimized for specific workloads. Some instances might be optimized for high network throughput and some for low-latency disk operations and thus be better suited for your applications. All of that should be taken into consideration as a part of rightsizing strategy and cost management in <span class="No-Break">the cloud.</span></p>
			<h1 id="_idParaDest-110"><a id="_idTextAnchor109"/>Summary</h1>
			<p>In this chapter we’ve learned a lot about Telemetry and Observability. The three telemetry types or signals are <em class="italic">logs</em>, <em class="italic">metrics</em> and <em class="italic">traces</em> which provide valuable insights into the system observed from slightly different perspectives. An observable system is the one that is constantly monitored where we know the state based on the telemetry data that serves <span class="No-Break">as evidence.</span></p>
			<p>We’ve also learned about projects such as <em class="italic">OpenTelemetry</em> that can help with instrumentation and simplify the work needed to implement telemetry. Had a quick introduction to projects such as <em class="italic">Zipkin</em> and <em class="italic">Jaeger</em> for tracing and had a closer look at Prometheus – a fully featured <span class="No-Break">monitoring platform.</span></p>
			<p>Prometheus supports both <em class="italic">Push</em> and <em class="italic">Pull</em> operating models for metric collection, but dominantly uses <em class="italic">Pull</em> model to periodically scrape the metric data at (<strong class="source-inline">/metrics</strong> endpoint) and save it in TSDB in time-series format. Having metrics in TSDB allows us visualizing the data in software such as <em class="italic">Grafana</em> and define alerts that would notify us over the preferred channel when one or another metric is crossing the <span class="No-Break">threshold defined.</span></p>
			<p>Another great point about Prometheus is the Kubernetes integration. Prometheus supports automatic discovery of targets that are running in Kubernetes which makes operator’s life easier. For software that doesn’t natively provide metrics in Prometheus format it is possible to run exporters – small tools that aggregate the metrics from the service or an application and expose them in Prometheus format via <strong class="source-inline">/metrics</strong> endpoint for collection. If you are in control of the source code of applications you run – it is also possible to add support for Prometheus with a help of client libraries available in many programming languages. This is known as <span class="No-Break"><em class="italic">direct instrumentation</em></span><span class="No-Break">.</span></p>
			<p>Finally, we’ve got to know about FinOps and cost management in cloud. Most commonly, the so called <em class="italic">on-demand</em> capacities are consumed in the cloud. That means resources can be provisioned when needed and deleted when no longer required and only the time when they were running is billed. This is different from <em class="italic">Reserved</em> capacity when instances are paid in advance for longer periods of time. Reserved capacities come with very good discounts but will still cost money if unused. And <em class="italic">Spot</em> or <em class="italic">Preemptible</em> instances are spare capacity that cloud provider might just terminate at any time. They are the cheapest among three options, however, might not be the right choice for critical workloads that require <span class="No-Break">maximum uptime.</span></p>
			<p>Last, but not least, we’ve covered <em class="italic">Rightsizing</em>. It’s a process of finding the best instance size and number of instances for current workload as a balance between performance requirements <span class="No-Break">and cost.</span></p>
			<p>Next chapter is about automation and delivery of Cloud Native applications. We will learn about best practices and see how we can ship better software faster and <span class="No-Break">more reliably.</span></p>
			<h1 id="_idParaDest-111"><a id="_idTextAnchor110"/>Questions</h1>
			<p>Correct answers can be found <span class="No-Break">at __TBD__</span></p>
			<ol>
				<li>Which of the following are valid telemetry signals (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">Tracks</span></li><li><span class="No-Break">Pings</span></li><li><span class="No-Break">Logs</span></li><li><span class="No-Break">Metrics</span></li></ol></li>
				<li>Which is the dominant operation model of Prometheus for <span class="No-Break">metrics collection?</span><ol><li><span class="No-Break">Push</span></li><li><span class="No-Break">Pull</span></li><li><span class="No-Break">Commit</span></li><li><span class="No-Break">Merge</span></li></ol></li>
				<li>Which of the following allows to collect metrics with Prometheus when native application support <span class="No-Break">is missing?</span><ol><li>Running application <span class="No-Break">in Kubernetes</span></li><li><span class="No-Break">Installing Pushgateway</span></li><li><span class="No-Break">Installing Alertmanager</span></li><li>Installing <span class="No-Break">application exporter</span></li></ol></li>
				<li>Which of the following signals does <span class="No-Break">Prometheus collect?</span><ol><li><span class="No-Break">Logs</span></li><li><span class="No-Break">Metrics</span></li><li><span class="No-Break">Traces</span></li><li><span class="No-Break">Audits</span></li></ol></li>
				<li>Which component can be used to allow applications to push metrics <span class="No-Break">into Prometheus?</span><ol><li><span class="No-Break">Zipkin</span></li><li><span class="No-Break">Grafana</span></li><li><span class="No-Break">Alertmanager</span></li><li><span class="No-Break">Pushgateway</span></li></ol></li>
				<li>Which telemetry signal fits best to see how request traverses a <span class="No-Break">microservice-base application?</span><ol><li><span class="No-Break">Logs</span></li><li><span class="No-Break">Traces</span></li><li><span class="No-Break">Metrics</span></li><li><span class="No-Break">Pings</span></li></ol></li>
				<li>Which software allows visualizing metrics stored in <span class="No-Break">Prometheus TSDB?</span><ol><li><span class="No-Break">Zipkin</span></li><li><span class="No-Break">Kibana</span></li><li><span class="No-Break">Grafana</span></li><li><span class="No-Break">Jaeger</span></li></ol></li>
				<li>Which software can be used for end-to-end tracing of distributed applications (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">Prometheus</span></li><li><span class="No-Break">Grafana</span></li><li><span class="No-Break">Jaeger</span></li><li><span class="No-Break">Zipkin</span></li></ol></li>
				<li>What makes it possible to query Prometheus metrics from <span class="No-Break">the past?</span><ol><li><span class="No-Break">Alertmanager</span></li><li><span class="No-Break">TSDB</span></li><li><span class="No-Break">PVC</span></li><li><span class="No-Break">Graphite</span></li></ol></li>
				<li>Which endpoint Prometheus collects metrics from <span class="No-Break">by default?</span><ol><li><strong class="source-inline">/</strong><span class="No-Break"><strong class="source-inline">collect</strong></span></li><li><strong class="source-inline">/</strong><span class="No-Break"><strong class="source-inline">prometheus</strong></span></li><li><strong class="source-inline">/</strong><span class="No-Break"><strong class="source-inline">metric</strong></span></li><li><strong class="source-inline">/</strong><span class="No-Break"><strong class="source-inline">metrics</strong></span></li></ol></li>
				<li>What is the format of <span class="No-Break">Prometheus metrics?</span><ol><li><span class="No-Break">Timeseries</span></li><li><span class="No-Break">Traces</span></li><li><span class="No-Break">Spans</span></li><li><span class="No-Break">Plots</span></li></ol></li>
				<li>Which of the following allows direct instrumentation for applications to provide metrics in <span class="No-Break">Prometheus format?</span><ol><li>K8s <span class="No-Break">service discovery</span></li><li><span class="No-Break">Pushgateway</span></li><li><span class="No-Break">Exporters</span></li><li><span class="No-Break">Client libraries</span></li></ol></li>
				<li>A periodic job takes only 30 seconds to complete, but Prometheus scrape interval is 60 seconds. What is the best way to collect the metrics from <span class="No-Break">such job?</span><ol><li>push the metrics <span class="No-Break">to Pushgateway</span></li><li>reduce scrape interval to <span class="No-Break">30 seconds</span></li><li>reduce scrape interval to <span class="No-Break">29 seconds</span></li><li>replace job with <span class="No-Break">Kubernetes CronJob</span></li></ol></li>
				<li>Which of the following is a crucial part <span class="No-Break">of Rightsizing?</span><ol><li><span class="No-Break">FinOps</span></li><li><span class="No-Break">Reserved instances</span></li><li><span class="No-Break">Autoscaling</span></li><li><span class="No-Break">Automation</span></li></ol></li>
				<li>Which of the following should be taken into consideration when <span class="No-Break">implementing Autoscaling?</span><ol><li>CPU <span class="No-Break">utilization metric</span></li><li>RAM <span class="No-Break">utilization metric</span></li><li>CPU + RAM <span class="No-Break">utilization metrics</span></li><li>CPU, RAM, and application <span class="No-Break">specific metrics</span></li></ol></li>
				<li>Which of the following instance types are offered by many public cloud providers (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">On-demand</span></li><li><span class="No-Break">Serverless</span></li><li><span class="No-Break">Spot</span></li><li><span class="No-Break">Reserved</span></li></ol></li>
				<li>Which of the following instance types fits for constant workloads with no spikes in load that should run for few <span class="No-Break">years straight?</span><ol><li><span class="No-Break">On-demand</span></li><li><span class="No-Break">Serverless</span></li><li><span class="No-Break">Spot</span></li><li><span class="No-Break">Reserved</span></li></ol></li>
				<li>Which of the following instance types fits for batch processing and periodic jobs that can be interrupted if lowest price is the <span class="No-Break">main priority?</span><ol><li><span class="No-Break">On-demand</span></li><li><span class="No-Break">Serverless</span></li><li><span class="No-Break">Spot</span></li><li><span class="No-Break">Reserved</span></li></ol></li>
			</ol>
			<h1 id="_idParaDest-112"><a id="_idTextAnchor111"/>Further reading</h1>
			<ul>
				<li><span class="No-Break">OpenTelemetry: </span><a href="https://opentelemetry.io/docs/"><span class="No-Break">https://opentelemetry.io/docs/</span></a></li>
				<li><span class="No-Break">Jaeger: </span><a href="https://www.jaegertracing.io/"><span class="No-Break">https://www.jaegertracing.io/</span></a></li>
				<li><span class="No-Break">Grafana: </span><a href="https://grafana.com/grafana/"><span class="No-Break">https://grafana.com/grafana/</span></a></li>
				<li>Prometheus query <span class="No-Break">language: </span><a href="https://prometheus.io/docs/prometheus/latest/querying/basics/"><span class="No-Break">https://prometheus.io/docs/prometheus/latest/querying/basics/</span></a></li>
				<li>Prometheus <span class="No-Break">exporters: </span><a href="https://prometheus.io/docs/instrumenting/exporters/"><span class="No-Break">https://prometheus.io/docs/instrumenting/exporters/</span></a></li>
				<li>Kubernetes metrics for <span class="No-Break">Prometheus:</span><span class="No-Break"><span class="hidden"> </span></span><a href="https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/"><span class="No-Break">https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/</span></a></li>
				<li>Introduction to <span class="No-Break">FinOps: </span><a href="https://www.finops.org/"><span class="No-Break">https://www.finops.org/</span></a></li>
			</ul>
		</div>
	</body></html>