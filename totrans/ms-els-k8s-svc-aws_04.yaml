- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running Your First Application on EKS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapters, we talked about how to configure and build a basic
    cluster. In this chapter, we will explore how we deploy our first application
    on that cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes has grown in popularity due in part to the flexible way you can build
    and deploy services and applications and how you can use key Kubernetes features
    to recover from failure and scale your application in and out. In the CNCF Annual
    Survey in 2021, 96% of respondents said they were either using or evaluating Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we cover the different ways you can deploy a simple application
    on EKS and tools to visualize your workloads. Specifically, we will cover the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the different configuration options for your application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating your first EKS application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Visualizing your workloads using the AWS Management Console and third-party
    tools, such as Lens
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You should be familiar with YAML, basic networking, and EKS architecture. Let’s
    begin by determining what needs to be done prior to deploying your first application.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before getting started with this chapter, please ensure the following:'
  prefs: []
  type: TYPE_NORMAL
- en: You have an EKS cluster and are able to perform administrative tasks
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have at least two worker nodes connected to your cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have network connectivity to your EKS API endpoint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The AWS CLI and the `kubectl` binary are installed on your workstation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the different configuration options for your application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'An application on Kubernetes is made up of one or more containers, spread across
    the worker nodes and exposed outside the cluster using different methods. The
    following table defines what will be configured and provides a map to other chapters
    that show additional configuration steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Application** **Configuration Domain** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Single Pod** | In this example, a single Pod can be pulled from a supported
    repository image and deployed to a specific namespace. |'
  prefs: []
  type: TYPE_TB
- en: '| **Resilient deployment** | In this example, a Kubernetes Deployment will
    be used to deploy multiple Pods across different worker nodes, and the scheduler
    will maintain the desired number. |'
  prefs: []
  type: TYPE_TB
- en: '| **Updating** **your Deployment** | In this example, the Deployment container
    image is updated, and the new image is rolled out across the Deployment. |'
  prefs: []
  type: TYPE_TB
- en: '| **External service** | In this example, the Deployment will be exposed as
    a simple node-port service. |'
  prefs: []
  type: TYPE_TB
- en: '| **Ingress controller** | In this example, the Deployment will be exposed
    using an NGINX Ingress controller that provides more access control. |'
  prefs: []
  type: TYPE_TB
- en: '| **Multi-container Pod** | Typically using a sidecar for a health check or
    service mesh. This is discussed in detail in [*Chapter 16*](B18129_16.xhtml#_idTextAnchor232).
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Load balancer** | This is discussed in detail in [*Chapter 14*](B18129_14.xhtml#_idTextAnchor205).
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Auto-scaling Pods** | This is discussed in [*Chapter 18*](B18129_18.xhtml#_idTextAnchor264).
    |'
  prefs: []
  type: TYPE_TB
- en: '| **Storage** **for Pods** | This is discussed in [*Chapter 12*](B18129_12.xhtml#_idTextAnchor175).
    |'
  prefs: []
  type: TYPE_TB
- en: Table 4.1 – Application configuration areas
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now look at what you need to deploy your first application to EKS.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing kubectl configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**kubectl** is a Kubernetes command-line management client tool that allows
    a user to interact with the Kubernetes API server and perform any administrative
    task, including deploying, updating, or deleting an application (as long as they
    have permission to do so).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to communicate with the cluster, the cluster details, such as the
    API endpoint DNS name and server certificates, all need to be added to the `kubeconfig`
    file. The following command can be used (you will need to have the AWS CLI installed)
    to update the config file, which will normally be stored in the `config` file
    in `$HOME/.kube`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The AWS user that is being used to run the CLI command will need IAM permissions
    to the AWS EKS API to successfully perform this operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The file will now contain a reference to the new cluster, in the `cluster`
    section, with the certificate data, API endpoint (*server*), and name. An example
    is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'It will also contain a `user` section. By default, EKS will use an IAM identity,
    so there is no actual user data. Instead, the CLI command `aws eks get-token`
    (with supporting parameters) is used to get the identity token that’s used by
    EKS to map the IAM user to a Kubernetes identity (see [*Chapter 6*](B18129_06.xhtml#_idTextAnchor095)
    for more information). An example of the configuration seen in the configuration
    file is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, a Kubernetes `context` is also created, which will link the `cluster`
    and `user` configuration together. An example of this is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Contexts allow multiple clusters and identities to be configured in the config
    file and for a user to switch between them. Switching between contexts can be
    done using the `kubectl config --kubeconfig=<CONFIGDIR> use-context <CONTEXT>`
    command or using an open source tool, such as [https://github.com/ahmetb/kubectx](https://github.com/ahmetb/kubectx).
  prefs: []
  type: TYPE_NORMAL
- en: Now we have set up the basic configuration needed to communicate with our cluster.
    In the next section, we will do some basic cluster connectivity verification with
    `kubectl` and deploy our first Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying connectivity with kubectl
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The easiest way to verify whether you have connectivity to your cluster is
    to use the `kubectl version` command. You should see something similar to the
    output shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'The following table indicates some errors you may see when running this command
    and how to resolve them:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Error output** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| **Unable to connect to the server: getting credentials: exec: executable
    aws failed with exit** **code 253** | In this case, `kubectl` can’t retrieve AWS
    IAM credentials to request a token from the EKS API; update or add your AWS credentials
    to the workstation. |'
  prefs: []
  type: TYPE_TB
- en: '| **Unable to connect to the server: dial tcp 10.1.3.51:443:** **i/o timeout**
    | In this case, the IP address is a private address, and the `kubectl` client
    has no route to it. This error typically indicates a network issue such as IP
    routing or some sort of firewall/IP whitelisting issue with the client IP. |'
  prefs: []
  type: TYPE_TB
- en: '| **error: You must be logged in to the server (the server has asked for the
    client to** **provide credentials)** | In this case, `kubectl` has credentials
    and can connect to the server endpoint, but the credentials don’t have permission
    to retrieve version information. This is an RBAC issue and typically means that
    the IAM user being used doesnt have the right Kubernetes permissions. |'
  prefs: []
  type: TYPE_TB
- en: Table 4.2 – Typical kubectl connectivity error examples
  prefs: []
  type: TYPE_NORMAL
- en: kubectl cheat sheet
  prefs: []
  type: TYPE_NORMAL
- en: 'The kubectl cheat sheet contains very useful content that can help you quickly
    learn which `kubectl` command to use. You can study commonly used `kubectl` commands
    and flags in the official Kubernetes documentation: [https://kubernetes.io/docs/reference/kubectl/cheatsheet/](https://kubernetes.io/docs/reference/kubectl/cheatsheet/).'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve validated connectivity to the cluster from kubectl, we deploy
    our first application.
  prefs: []
  type: TYPE_NORMAL
- en: Creating your first EKS application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The lowest level of abstraction in Kubernetes is the Pod, which represents one
    or more containers that share the same namespace. You may choose to have additional
    containers in your Pod to provide additional functionality, such as a service
    mesh or cache. So, while many Pods only contain one single container, you are
    not restricted to one.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, we will deploy a Pod and then build on this using
    more advanced Kubernetes objects. As a developer or DevOps engineer, you will
    spend a lot of time building and deploying applications, so it’s really important
    to understand what you need to do.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying your first Pod on Amazon EKS using the kubectl command
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can use the `kubectl run` command to quickly deploy and attach your CLI
    session to a Pod using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'There are several things that happen when you execute this command, but before
    we review them, let’s look at the manifest being created with the `kubectl run
    busybox --image=busybox --restart=Never` **--dry-run=client -o yaml** command,
    which shows the API object/kind being created *but* will not send it to the Kubernetes
    API. The output of the command is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, the manifest defines a `Pod` specification, with a `name`, the
    `busybox` image (which will be pulled from a public repository), and a `restartPolicy`,
    which means once it finishes, the scheduler won’t try to restart it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The deployment process is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The `kubectl run` command will create the manifest for the Pod and submit it
    to the Kubernetes API.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The API server will persist the Pod specification.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The scheduler will pick up the new Pod specification, review it, and through
    a process of filtering and scoring, select a worker node to deploy the resource
    onto and mark the Pod spec for this node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: On the node, the kubelet agent is monitoring the cluster datastore, etcd, and
    if a new Pod specification is found, the specification is used to create the Pod
    on the node.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Once the Pod has started, your kubectl session will attach to the Pod (as we
    specified with the `-it` flag). You will now be able to use Linux commands to
    interact with your Pod. You can leave the session by typing `exit`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you exit the session, you can verify the Pod status as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'The Pod status is `Completed`, because we specified `restartPolicy: Never`,
    so once the interactive session has terminated, the container is no longer accessible.
    You can delete the Pod using the `$ kubectl delete pod` `busybox` command.'
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will see how to extend this concept of a Pod into a
    Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a Pod using a Kubernetes Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A Deployment adds a further layer of abstraction on top of a Pod; it allows
    you to deploy a Pod specification and supports scaling those Pods and updating
    the Pod images. A Deployment will allow you to manage the life cycle of your application
    much more efficiently than the basic Pod specifications. The following Deployment
    manifest will be used to deploy two Pods running version 1.34.1 of BusyBox. We
    also include a simple command to `execute sleep 3600`, which keeps the container
    *alive* for 3,600 seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '**chapter4-deployment.yaml**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: You can use the `$ kubectl create -f chapter4-deployment.yaml` command to create
    the Deployment. You will also see the `deployment.apps/busybox-deployment created`
    message in response.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can verify the Deployment by using the `$ kubectl get deployment simple-deployment`
    command; an example output is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The Deployment is a composite type, and it contains the Deployment itself,
    the Pods, and a *ReplicaSet*, which is used to maintain the desired state of two
    Pods per Deployment. You can use the `kubectl get all` command to retrieve all
    the resources in the current namespace. An example output is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: A Deployment provides an easy way to make changes. Let’s look at how we can
    modify this Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Modifying your Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a Deployment, we can scale it with the `kubectl scale deployment
    simple-deployment --replicas=3` command, which will increase the desired number
    of Pods to three, which, in turn, will add another Pod.
  prefs: []
  type: TYPE_NORMAL
- en: We can also update the Deployment image with the `kubectl set image deployment
    simple-deployment busybox=busybox:1.35.0` command, which will trigger a rolling
    update (the default mechanism).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can validate the rollout using the `kubectl rollout` `status` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: You will see that the Pods are all replaced with the new version, which you
    can attach to the Pod shell (`/bin/sh`) using the `$ kubectl exec --stdin --tty
    <POD ID> -- /bin/sh` command and then, once in the Pod shell, run the `busybox
    |head -``1` command.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s look at how we make this Deployment visible to users outside the
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing your Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While we have deployed the pods using a Deployment, in order for other Pods/Deployments
    to communicate with these Pods, they must use the Pods IP address. A better way
    to expose these Pods is by using a service, which means other cluster Pods or
    external systems can use the service, and Kubernetes will load balance the requests
    over all the available Pods. An example of a service is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '**chapter4-basic-service.yaml**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The service we create is a `ClusterIP` service, which means it is only visible
    from inside the cluster. It will expose port `80` and map that to port `9376`
    on any Pod that has a label of `app=simple-deployment-app` (the Pods we created
    previously with the Deployment).
  prefs: []
  type: TYPE_NORMAL
- en: 'We can validate the service using the `kubectl get` `service` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'If we look deeper at the service using the `kubectl describe service myapp`command,
    we can see the `Endpoints` configuration item, which contains the IP addresses
    of the Pods that have the label `app=simple-deployment-app`. We verify this with
    the kubectl `get po -o wide` command, illustrated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This service is visible in the cluster using the cluster DNS, so `myapp.default.svc.cluster.local`
    will resolve to `172.20.124.66`, which is the IP address assigned to the `clusterIP`.
    To expose the service outside of the cluster, we need to use either a different
    service, an Ingress or Ingress controller, or a load balancer. We will discuss
    these next.
  prefs: []
  type: TYPE_NORMAL
- en: Using a NodePort service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A `NodePort` service exposes a static port, between `30000-32768` by default
    on each worker node in the cluster, and then maps traffic back to port `80` (in
    the configuration shown next, only one port is defined, so the target port and
    the service have the same value) on any Pod that matches the selector.
  prefs: []
  type: TYPE_NORMAL
- en: '**chapter4-basic-nodeport-service.yaml**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The service we create is a `NodePort` service that selects a Pod that has a
    label of `app=simple-nginx-app`, which is another Deployment of NGINX Pods. We
    can see that `NodePort` has been created successfully using the `kubectl get`
    `service` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: If you use **curl** to browse the service endpoint, you will see the NGINX standard
    page (assuming all worker node security groups are configured to allow traffic).
  prefs: []
  type: TYPE_NORMAL
- en: Using an Ingress
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An Ingress builds on top of services by providing a mechanism to expose HTTP/HTTPS
    routes, such as `/login` or `/order`, outside of the cluster. An Ingress is independent
    of the underlying services, so a typical use case is to use a single Ingress to
    provide a central entry point for multiple (micro) services. To use an Ingress,
    you need an Ingress controller; this is not provided by Kubernetes, so it must
    be installed. We will use the NGINX Ingress controller.
  prefs: []
  type: TYPE_NORMAL
- en: 'To install the NGINX Ingress controller with no cloud/AWS extensions, you can
    use the following command to deploy the bare-metal controller:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We can verify the new Ingress controller with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: We can see the Ingress controller is exposed as a `NodePort` service listening
    on `31371` for HTTP connections and `31159` for HTTPS connections. Normally, we
    would place a load balancer in front of this `NodePort` service (which we will
    explore in the next example), but for the time being, we will just use the simple
    `NodePort` service.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the previous service and simply expose a URL on top of the service
    using the following manifest with the `$ kubectl create -f` `chapter4-@ingress.yaml
    command`:'
  prefs: []
  type: TYPE_NORMAL
- en: '**chapter4-ingress.yaml**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The Ingress we create uses `annotations` to configure the Ingress controller
    we created previously with the path rules in the `spec` section. The rule states
    when a request arrives for `myweb.packt.com/login`, you need to send it to the
    `myapp-ext` service on port `80` and rewrite `/login` to just `/`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can test this with the following command, which should return the NGINX
    welcome page:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Using an AWS Load Balancer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we have an Ingress controller, exposed as a `NodePort`, and the underlying
    service, we could simply create a load balancer and create a target group for
    the worker nodes and the Ingress controller `NodePort` port. However, we want
    to integrate the Ingress controller and `loadbalancer` so that as the Ingress
    controller scales and changes, the `loadbalancer` configuration will also change.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you have removed the Ingress (`$ kubectl delete -f chapter4-ingress.yaml`)
    and the Ingress controller (`$ kubectl delete -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.0/deploy/static/provider/baremetal/deploy.yaml`)
    from the previous section.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now redeploy the NGINX Ingress controller that is integrated with AWS
    load balancers using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'After we have deployed the controller, we can review the Ingress controller
    with the following command. From the output, we can see the annotations that will
    create an AWS **Network Load Balancer** (**NLB**) and also the target group for
    the Ingress controller running in EKS:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see the load balancer that we have created using the AWS CLI command
    shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: This is a public load balancer (`internet-facing`), so the service is now reachable
    (through the Ingress controller) from the internet. You can access the link using
    the `DNSName` of the load balancer. We can now redeploy the Ingress manifest (without
    any changes as we’ve just added an NLB on top of the Ingress controller) using
    the `$ kubectl create -f chapter4-ingress.yaml` command to enable access through
    the NLB to our service.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can now test access to your service by using the following command from
    any workstation with internet access. This will display the NGINX welcome screen:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you have removed the Ingress (`$ kubectl delete -f chapter4-ingress.yaml`)
    and the Ingress controller (`$ kubectl delete -``f` [https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.0/deploy/static/provider/aws/deploy.yaml](https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.2.0/deploy/static/provider/aws/deploy.yaml)).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we have looked at the different ways you can deploy Pods and
    expose them through services, an Ingress, and a load balancer. So far, all the
    examples have been using the command line. In the next section, we will look at
    how you can visualize your workloads and applications using the AWS console and
    a third-party tool.
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing your workloads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Throughout the book and in the real world, you will mainly interact with EKS
    through the command line or a CI/CD pipeline. It is, however, sometimes useful
    to be able to view what you have running on a cluster in a visual form. Kubernetes
    provides a web dashboard, but with EKS, you can see most of the cluster configuration
    through the main EKS and using CloudWatch (discussed more in [*Chapter 19*](B18129_19.xhtml#_idTextAnchor313),
    *Developing on EKS*), which has removed the need to deploy a separate dashboard.
    To access the console, sign in to [http://aws.amazon.com](http://aws.amazon.com)
    and log in with credentials that are allowed to view the cluster (see [*Chapter
    3*](B18129_03.xhtml#_idTextAnchor047), *Building Your First EKS Cluster*). You
    can then select Amazon **Elastic Kubernetes Service** | **Clusters** and you will
    be presented with a list of clusters running in the region (you can now add on-premise
    clusters as well). From the main view, you can see clusters, their version, and
    whether they need updating (discussed more in [*Chapter 10*](B18129_10.xhtml#_idTextAnchor146),
    *Upgrading* *EKS Cluster*).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – The main cluster panel](img/B18129_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – The main cluster panel
  prefs: []
  type: TYPE_NORMAL
- en: 'You can select a cluster by clicking on the name hyperlink, and you will be
    taken to a more detailed view, where you can do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Upgrade the cluster control plane with a single click
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delete the cluster (you may have to delete the node groups first)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: View and modify the cluster configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 4.2 – mycluster details panel](img/B18129_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – mycluster details panel
  prefs: []
  type: TYPE_NORMAL
- en: The preceding figure shows the **mycluster** | **Resources** window, which can
    be used to get a list of currently running Pods, Deployments, and Services, but
    remember the IAM User/Role you use in the console must have cluster (RBAC) permissions
    to at least read/get the resources. It’s also possible to create node groups from
    here and manage configuration items such as **Public Endpoint** IP whitelists,
    and add-ons.
  prefs: []
  type: TYPE_NORMAL
- en: Generally, it’s better to make changes using infrastructure as code or through
    a CI/CD pipeline, but you can also manage the cluster through the console. There
    are a host of other tools you can run from your workstation that are useful if
    you’re trying to troubleshoot an issue. I often use [https://k8slens.dev/](https://k8slens.dev/),
    but other options are available!
  prefs: []
  type: TYPE_NORMAL
- en: All these tools will need a network route/path to the EKS API endpoint (public
    or private) and AWS IAM credentials that have permission to manage the EKS cluster
    (`system:masters` if you want to make changes).
  prefs: []
  type: TYPE_NORMAL
- en: 'In your `.kube/config` file, you will need to make changes to the `users` section
    to include the `AWS_PROFILE` environment variable to point to the AWS credentials
    profile that has access to the cluster itself. An example is shown next:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Once your workstation is configured, you install and launch Lens. If you are
    using temporary credentials, then you might find it easier to launch Lens from
    the command line on macOS. I would recommend using the `$ open -a lens` command,
    following which you will have a workstation environment so you can visualize your
    cluster/clusters from your workstation. The next screenshot shows the cluster
    view presented by Lens:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – A Lens cluster view](img/B18129_04_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – A Lens cluster view
  prefs: []
  type: TYPE_NORMAL
- en: One of the things I really like about Lens is the ability to add extensions;
    for example, if you install the Resource Map Extension ([https://github.com/nevalla/lens-resource-map-extension](https://github.com/nevalla/lens-resource-map-extension))
    from Lauri Nevala, you can get a visualization of the resources of your cluster
    and how they link together. For a complete list of extensions, take a look at
    [https://github.com/lensapp/lens-extensions/blob/main/README.md](https://github.com/lensapp/lens-extensions/blob/main/README.md).
  prefs: []
  type: TYPE_NORMAL
- en: 'The following screenshot shows an example of a Resource Map:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 4.4 – An example \uFEFFResource \uFEFFMap](img/B18129_04_04.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 – An example Resource Map
  prefs: []
  type: TYPE_NORMAL
- en: You are now familiar with how you can visualize the workloads in your cluster
    using the AWS console and a third-party tool such as Lens.
  prefs: []
  type: TYPE_NORMAL
- en: In all, we have looked at how to verify connectivity to your cluster, and deploy
    and visualize Pods in the cluster. Let’s now revisit the key learning points from
    this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we examined the different ways you can deploy applications,
    starting with creating a simple Pod and building on top of this concept with deployments,
    services, an Ingress, and finally deploying an AWS NLB and NGINX Ingress controller
    to expose the service to the internet. We discussed how a Deployment and Service
    can provide greater resilience and abstraction on top of a Pod and how services,
    Ingresses, and load balancers can be used to expose a service in a secure/resilient
    manner outside of the cluster/VPC.
  prefs: []
  type: TYPE_NORMAL
- en: Throughout this chapter, we used a Kubernetes YAML manifest to illustrate how
    to build and deploy these objects using kubectl. You now have the ability to deploy
    applications in EKS using the basic YAML manifests and kubectl. In the next chapter,
    we will look at how Helm can be used to create flexible manifests that can be
    parametrized at deployment time to support different requirements and/or environments.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Understanding Deployments:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://kubernetes.io/docs/concepts/workloads/controllers/deployment/](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Understanding Services:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://kubernetes.io/docs/concepts/services-networking/service/](https://kubernetes.io/docs/concepts/services-networking/service/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using NGINX Ingress Controller and AWS NLB:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://aws.amazon.com/blogs/opensource/network-load-balancer-nginx-ingress-controller-eks/](https://aws.amazon.com/blogs/opensource/network-load-balancer-nginx-ingress-controller-eks/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'NGINX Ingress Controller:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://kubernetes.github.io/ingress-nginx/examples/](https://kubernetes.github.io/ingress-nginx/examples/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes Lens:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://k8slens.dev/](https://k8slens.dev/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deploying and using the Kubernetes Dashboard:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/](https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/)'
  prefs: []
  type: TYPE_NORMAL
