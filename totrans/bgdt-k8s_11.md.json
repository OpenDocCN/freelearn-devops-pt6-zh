["```\n    import boto3\n    from langchain_community.chat_models import BedrockChat\n    from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n    bedrock = boto3.client(service_name='bedrock-runtime', region_name=\"us-east-1\")\n    ```", "```\n    inference_modifier = {\n        \"max_tokens\": 4096,\n        \"temperature\": 0.5,\n        \"top_k\": 250,\n        \"top_p\": 1,\n        \"stop_sequences\": [\"\\n\\nHuman:\"],\n    }\n    ```", "```\n    def choose_model(option):\n        modelId = \"\"\n        if option == \"Claude 3 Haiku\":\n            modelId = \"anthropic.claude-3-haiku-20240307-v1:0\"\n        elif option == \"Claude 3 Sonnet\":\n            modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n        model = BedrockChat(\n            model_id=modelId,\n            client=bedrock,\n            model_kwargs=inference_modifier,\n            streaming=True,\n            callbacks=[StreamingStdOutCallbackHandler()],\n        )\n        return model\n    ```", "```\n    def reset_conversation():\n        st.session_state.messages = []\n    ```", "```\n    def main():\n        with st.sidebar:\n            option = st.selectbox(\n                \"What model do you want to talk to?\",\n                (\"Claude 3 Haiku\", \"Claude 3 Sonnet\")\n            )\n            st.write(f\"You are talking to **{option}**\")\n            st.button('Reset Chat', on_click=reset_conversation)\n        model = choose_model(option)\n        st.title(\"Chat with Claude 3\")\n    ```", "```\n    if \"messages\" not in st.session_state:\n            st.session_state.messages = []\n        for message in st.session_state.messages:\n            with st.chat_message(message[\"role\"]):\n                st.markdown(message[\"content\"])\n    ```", "```\n        if prompt := st.chat_input(\"Enter your prompt here\"):\n            st.session_state.messages.append(\n                {\"role\": \"user\", \"content\": prompt}\n            )\n            with st.chat_message(\"user\"):\n                st.markdown(prompt)\n            with st.chat_message(\"assistant\"):\n                response = st.write_stream(\n                    model.stream(prompt)\n                )\n            st.session_state.messages.append(\n                {\"role\": \"assistant\", \"content\": response}\n            )\n    ```", "```\n    if __name__ == \"__main__\":\n        main()\n    ```", "```\n    boto3==1.34.22\n    langchain-community==0.0.33\n    langchain==0.1.16\n    streamlit==1.34.0\n    pip install -r requirements.txt\n    ```", "```\n    streamlit run main.py\n    ```", "```\n    FROM python:3.9-slim\n    WORKDIR /app\n    RUN apt-get update && apt-get install -y \\\n        build-essential \\\n        curl \\\n        software-properties-common \\\n        git \\\n        && rm -rf /var/lib/apt/lists/*\n    COPY app /app/\n    EXPOSE 8501\n    HEALTHCHECK CMD curl --fail http://localhost:8501/_stcore/health\n    RUN pip3 install -r requirements.txt\n    ENTRYPOINT [\"streamlit\", \"run\", \"main.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"]\n    ```", "```\n    docker build --platform linux/amd64 -t <YOUR_USERNAME>/chat-with-claude:v1 .\n    ```", "```\n    docker push <YOUR_USERNAME>/chat-with-claude:v1\n    ```", "```\n    apiVersion: apps/v1\n    kind: Deployment\n    metadata:\n      name: chat-with-claude\n    spec:\n      replicas: 1\n      selector:\n        matchLabels:\n          app: chat-with-claude\n      template:\n        metadata:\n          labels:\n            app: chat-with-claude\n        spec:\n          containers:\n          - name: chat-with-claude\n            image: docker.io/neylsoncrepalde/chat-with-claude:v1\n            ports:\n            - containerPort: 8501\n            env:\n            - name: AWS_ACCESS_KEY_ID\n              valueFrom:\n                secretKeyRef:\n                  name: aws-credentials\n                  key: aws_access_key_id\n            - name: AWS_SECRET_ACCESS_KEY\n              valueFrom:\n                secretKeyRef:\n                  name: aws-credentials\n                  key: aws_secret_access_key\n    ```", "```\n    ---\n    apiVersion: v1\n    kind: Service\n    metadata:\n      name: chat-with-claude\n    spec:\n      type: LoadBalancer\n      ports:\n      - port: 8501\n        targetPort: 8501\n      selector:\n        app: chat-with-claude\n    ```", "```\n    kubectl create namespace genai\n    kubectl create secret generic aws-credentials --from-literal=aws_access_key_id=<YOUR_ACCESS_KEY_ID> --from-literal=aws_secret_access_key=\"<YOUR_SECRET_ACCESS_KEY>\" -n genai\n    kubectl apply -f deploy_chat_with_claude.yaml -n genai\n    ```", "```\n    kubectl get svc -n genai\n    ```", "```\n    pip install \"beautifulsoup4==4.12.2\"\n    python get_competency_data.py\n    ```", "```\n    import os\n    from botocore.client import Config\n    from langchain.prompts import PromptTemplate\n    from langchain.retrievers.bedrock import AmazonKnowledgeBasesRetriever\n    from langchain.chains import RetrievalQA\n    ```", "```\n    kb_id = os.getenv(\"KB_ID\")\n    bedrock_config = Config(connect_timeout=120, read_timeout=120, retries={'max_attempts': 0})\n    bedrock_agent_client = boto3.client(\n        \"bedrock-agent-runtime\", config=bedrock_config, region_name = \"us-east-1\"\n    )\n    ```", "```\n    PROMPT_TEMPLATE = \"\"\"\n    Human: You are a friendly AI assistant and provide answers to questions about AWS competency program for partners.\n    Use the following pieces of information to provide a concise answer to the question enclosed in <question> tags.\n    Don't use tags when you generate an answer. Answer in plain text, use bullets or lists if needed.\n    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n    <context>\n    {context}\n    </context>\n    <question>\n    {question}\n    </question>\n    The response should be specific and use statistics or numbers when possible.\n    Assistant:\"\"\"\n    claude_prompt = PromptTemplate(template=PROMPT_TEMPLATE,\n                                   input_variables=[\"context\",\"question\"])\n    ```", "```\n    retriever = AmazonKnowledgeBasesRetriever(\n            knowledge_base_id=kb_id,\n            retrieval_config={\n                \"vectorSearchConfiguration\": {\n                    \"numberOfResults\": 4\n                }\n            },\n            client=bedrock_agent_client\n        )\n    ```", "```\n    qa = RetrievalQA.from_chain_type(\n            llm=model,\n            chain_type=\"stuff\",\n            retriever=retriever,\n            return_source_documents=False,\n            chain_type_kwargs={\"prompt\": claude_prompt}\n        )\n    ```", "```\n    with st.chat_message(\"assistant\"):\n        response = qa.invoke(prompt)['result']\n        st.write(response)\n    ```", "```\n    env:\n      - name: AWS_ACCESS_KEY_ID\n        valueFrom:\n          secretKeyRef:\n            name: aws-credentials\n            key: aws_access_key_id\n      - name: AWS_SECRET_ACCESS_KEY\n        valueFrom:\n          secretKeyRef:\n            name: aws-credentials\n            key: aws_secret_access_key\n      - name: KB_ID\n        valueFrom:\n          configMapKeyRef:\n            name: kb-config\n            key: kb_id\n    ```", "```\n    kubectl create configmap kb-config --from-literal=kb_id=<YOUR_KB_ID> -n genai\n    kubectl apply -f deploy_chat_with_claude.yaml -n genai\n    ```", "```\n    kubectl get svc -n genai\n    ```", "```\n    ├── app\n    │   └── main.py\n    ├── function\n    │   ├── lambda_function.py\n    │   ├── lambda_requirements.txt\n    │   ├── test_event.json\n    │   └── worksheet\n    │       ├── __init__.py\n    │       └── template.py\n    ├── openapi_schema.json\n    └── scripts\n        ├── build_lambda_package.sh\n    scripts folder and run the following commands:\n\n    ```", "```\n\n    ```", "```\n    kubectl create configmap agent-config --from-literal=agent_alias_id=<YOUR_ALIAS_ID> --from-literal=agent_id=<YOUR_AGENT_ID> -n genai\n    ```", "```\n    kubectl apply -f deploy_agent.yaml -n genai\n    ```", "```\n    kubectl get svc -n genai\n    ```"]