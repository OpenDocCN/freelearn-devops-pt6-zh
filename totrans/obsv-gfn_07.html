<html><head></head><body>
		<div id="_idContainer113">
			<h1 id="_idParaDest-135" class="chapter-number"><a id="_idTextAnchor147"/>7</h1>
			<h1 id="_idParaDest-136"><a id="_idTextAnchor148"/>Interrogating Infrastructure with Kubernetes, AWS, GCP, and Azure</h1>
			<p>This<a id="_idIndexMarker615"/> chapter will introduce the setup and configuration required to capture <strong class="bold">telemetry</strong> from various common cloud infrastructure providers. You will learn about the different options available for Kubernetes. Additionally, you will investigate the main plugins that <a id="_idIndexMarker616"/>allow Grafana to query data from cloud vendors such as <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>), <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>), and <a id="_idIndexMarker617"/>Azure. You will look at solutions for handling large volumes of telemetry where direct connections are not scalable. The chapter will also cover options for filtering and selecting telemetry data before it gets to<a id="_idIndexMarker618"/> Grafana<a id="_idIndexMarker619"/> for <strong class="bold">security</strong> and <span class="No-Break"><strong class="bold">cost optimization</strong></span><span class="No-Break">.</span></p>
			<p>We will cover the following main topics in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>Monitoring Kubernetes <span class="No-Break">using Grafana</span></li>
				<li>Visualizing AWS telemetry with <span class="No-Break">Grafana Cloud</span></li>
				<li>Monitoring GCP <span class="No-Break">using Grafana</span></li>
				<li>Monitoring Azure <span class="No-Break">using Grafana</span></li>
				<li>Best practices <span class="No-Break">and approaches</span></li>
			</ul>
			<h1 id="_idParaDest-137"><a id="_idTextAnchor149"/>Technical requirements</h1>
			<p>In this chapter, you will work with multiple cloud providers using a Grafana Cloud instance. You will need <span class="No-Break">the following:</span></p>
			<ul>
				<li>A Grafana Cloud instance (set up in <a href="B18277_03.xhtml#_idTextAnchor063"><span class="No-Break"><em class="italic">Chapter 3</em></span></a><span class="No-Break">)</span></li>
				<li>Kubernetes and Helm (set up in <a href="B18277_03.xhtml#_idTextAnchor063"><span class="No-Break"><em class="italic">Chapter 3</em></span></a><span class="No-Break">)</span></li>
				<li>Accounts with the AWS, GCP, and Azure cloud providers with <span class="No-Break">admin-level permissions</span></li>
			</ul>
			<h1 id="_idParaDest-138"><a id="_idTextAnchor150"/>Monitoring Kubernetes using Grafana</h1>
			<p>Kubernetes<a id="_idIndexMarker620"/> has been designed to be monitored, and as such, it <a id="_idIndexMarker621"/>presents multiple options for anyone wanting to monitor it or the workloads running on it using Grafana. In this section, we will focus on monitoring Kubernetes, as we have already worked with Kubernetes workloads in previous chapters using the OpenTelemetry <span class="No-Break">Demo application.</span></p>
			<p>The OpenTelemetry Collector<a id="_idIndexMarker622"/> introduced in <a href="B18277_03.xhtml#_idTextAnchor063"><span class="No-Break"><em class="italic">Chapter 3</em></span></a> provides receivers, processors, and exporters to implement Kubernetes monitoring with data collection and enrichment. The following table identifies those components with a brief explanation for each <span class="No-Break">of them:</span></p>
			<table id="table001-6" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">OpenTelemetry Component</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Description</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Kubernetes <span class="No-Break">Attributes Processor</span></p>
						</td>
						<td class="No-Table-Style">
							<p>The Kubernetes Attributes Processor appends Kubernetes metadata to telemetry, providing the necessary context <span class="No-Break">for correlation.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Kubeletstats Receiver</span></p>
						</td>
						<td class="No-Table-Style">
							<p>The Kubeletstats Receiver obtains Pod metrics via a pull mechanism from the kubelet API. It collects node and workload metrics from each node it is <span class="No-Break">installed on.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Filelog Receiver</span></p>
						</td>
						<td class="No-Table-Style">
							<p>The Filelog Receiver collects Kubernetes and workload logs that are written to <strong class="source-inline">stdout</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">stderr</strong></span><span class="No-Break">.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Kubernetes <span class="No-Break">Cluster Receiver</span></p>
						</td>
						<td class="No-Table-Style">
							<p>The Kubernetes Cluster Receiver collects cluster-level metrics and entity events using the <span class="No-Break">Kubernetes API.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Kubernetes <span class="No-Break">Object Receiver</span></p>
						</td>
						<td class="No-Table-Style">
							<p>The Kubernetes Object Receiver collects objects for example events from the <span class="No-Break">Kubernetes API.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Prometheus Receiver</span></p>
						</td>
						<td class="No-Table-Style">
							<p>The Prometheus Receiver scrapes metrics using Prometheus <span class="No-Break"><strong class="source-inline">scrape_config</strong></span><span class="No-Break"> settings.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Host <span class="No-Break">Metrics Receiver</span></p>
						</td>
						<td class="No-Table-Style">
							<p>The Host Metrics Receiver scrapes metrics from <span class="No-Break">Kubernetes nodes.</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 7.1 – Kubernetes receivers</p>
			<p>Let’s now explore each component and how to <span class="No-Break">implement them.</span></p>
			<h2 id="_idParaDest-139"><a id="_idTextAnchor151"/>Kubernetes Attributes Processor</h2>
			<p>The OpenTelemetry <strong class="bold">Kubernetes Attributes Processor</strong> can automatically discover Pods, extract metadata from them, and <a id="_idIndexMarker623"/>add the extracted metadata to spans, metrics, and logs as additional resource attributes. It provides necessary context to your telemetry, enabling the correlation of your application’s metrics, events, logs, traces, and signals with your Kubernetes telemetry, such as Pod metrics <span class="No-Break">and traces.</span></p>
			<p>Data passing through the processor is by default associated to a Pod via the incoming request’s IP address, but different rules can <span class="No-Break">be configured.</span></p>
			<p>The OpenTelemetry Collector Helm chart comes with several presets. For instance, the <strong class="source-inline">kubernetesAttributes</strong> preset, when enabled, will add the necessary RBAC roles to a ClusterRole and will add a <strong class="source-inline">k8sattributesprocessor</strong> to each <span class="No-Break">enabled pipeline:</span></p>
			<pre class="source-code">
presets:
  kubernetesAttributes:
    enabled: true</pre>			<p>Kubernetes comes with its own metadata to document its components. When using the <strong class="source-inline">kubernetesAttributes</strong> preset, the following attributes are added <span class="No-Break">by default:</span></p>
			<ul>
				<li><strong class="source-inline">k8s.namespace.name</strong>: The namespace the Pod is <span class="No-Break">deployed to.</span></li>
				<li><strong class="source-inline">k8s.pod.name</strong>: The name of <span class="No-Break">the Pod.</span></li>
				<li><strong class="source-inline">k8s.pod.uid</strong>: The unique ID for <span class="No-Break">the Pod.</span></li>
				<li><strong class="source-inline">k8s.pod.start_time</strong>: The timestamp for Pod creation, useful when understanding <span class="No-Break">Pod restarts.</span></li>
				<li><strong class="source-inline">k8s.deployment.name</strong>: The Kubernetes deployment name for <span class="No-Break">the application.</span></li>
				<li><strong class="source-inline">k8s.node.name</strong>: The name of the node the Pod is running on. As Kubernetes distributes the Pods over all of its nodes, it is important to understand whether any are having <span class="No-Break">specific problems.</span></li>
			</ul>
			<p>Additionally, the<a id="_idIndexMarker624"/> Kubernetes Attributes Processor creates custom resource attributes for your telemetry using Pod and namespace labels <span class="No-Break">and annotations.</span></p>
			<p>There are two methods applied to obtain and associate your data, that is, <strong class="source-inline">extract</strong> and <strong class="source-inline">pod_association</strong>. You can enable them in your Helm chart as detailed in the <span class="No-Break">following code:</span></p>
			<pre class="source-code">
k8sattributes:
  auth_type: 'serviceAccount'
  extract:
  pod_association:</pre>			<p>Let’s look at these methods in <span class="No-Break">greater detail:</span></p>
			<ul>
				<li><strong class="source-inline">extract</strong>: This method provides the ability to use metadata, annotations, and labels as resource attributes for your telemetry. It has the <span class="No-Break">following options:</span><ul><li><strong class="source-inline">metadata</strong>: Used to extract values from the Pod and namespace, such as <strong class="source-inline">k8s.namespace.name</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">k8s.pod.name</strong></span></li><li><strong class="source-inline">annotations</strong>: Used to extract the value of a Pod or namespace annotation with a key and insert it as a <span class="No-Break">resource attribute:</span><pre class="source-code">
      - tag_name: attribute-name
        key: annotation-name
        from: pod</pre></li><li><strong class="source-inline">labels</strong>: Used to extract the value of a Pod or namespace label with a key and insert it as a <span class="No-Break">resource attribute:</span><pre class="source-code">      - tag_name: attribute-name
        key: label-name
        from: pod</pre></li></ul><p class="list-inset">Both <strong class="source-inline">annotations</strong> and <strong class="source-inline">labels</strong> can also be used with regex to extract part of the value for the new <span class="No-Break">resource attribute.</span></p></li>				<li><strong class="source-inline">pod_association</strong>: This method associates data with the relevant Pod. You can configure multiple sources and the agent will try them in order, stopping when it finds a match. <strong class="source-inline">pod_association</strong> has the <strong class="source-inline">sources</strong> option, which is used to identify the resource attribute to use for the association, or it uses the IP attribute from<a id="_idIndexMarker625"/> the <span class="No-Break">connection context:</span><pre class="source-code">
  pod_association:
    - sources:
        - from: resource_attribute
          name: k8s.pod.ip
    - sources:
        - from: resource_attribute
          name: k8s.pod.uid
    - sources:
        - from: connection</pre></li>			</ul>
			<p class="callout-heading">Permissions</p>
			<p class="callout">If you are not using the <strong class="source-inline">kubernetesAttributes</strong> preset, you will have to provide the necessary permissions to allow access to the Kubernetes API. Usually, being able to access Pod, namespace, and ReplicaSet resources is adequate, but this will depend upon your <span class="No-Break">cluster configuration.</span></p>
			<h2 id="_idParaDest-140"><a id="_idTextAnchor152"/>Kubeletstats Receiver</h2>
			<p>The <strong class="bold">Kubeletstats Receiver</strong> connects <a id="_idIndexMarker626"/>to the kubelet API to collect metrics about the node and the workloads running on the node, which is why the preferred deployment mode is DaemonSet. Metrics are collected for Pods and nodes by default but can additionally be configured to collect metrics from containers <span class="No-Break">and volumes.</span></p>
			<p>The following code shows the configuration of the <span class="No-Break">Kubeletstats Receiver:</span></p>
			<pre class="source-code">
receivers:
  kubeletstats:
    collection_interval: 60s
    auth_type: 'serviceAccount'
    endpoint: '${env:K8S_NODE_NAME}:10250'
    insecure_skip_verify: true
    metric_groups:
      - node
      - pod
      - container</pre>			<h2 id="_idParaDest-141"><a id="_idTextAnchor153"/>Filelog Receiver</h2>
			<p>Although not a <a id="_idIndexMarker627"/>Kubernetes-specific receiver, the <strong class="bold">Filelog Receiver</strong> is the most popular log collection mechanism for Kubernetes. It tails and parses logs from files using operators chained together to process <span class="No-Break">log data.</span></p>
			<p>The OpenTelemetry Collector Helm chart has the <strong class="source-inline">logsCollection</strong> preset to add the necessary RBAC roles to the ClusterRole, and it will add a <strong class="source-inline">filelogreceiver</strong> instance to each enabled pipeline (we will explain <strong class="source-inline">includeCollectorLogs</strong> in <a href="B18277_10.xhtml#_idTextAnchor204"><span class="No-Break"><em class="italic">Chapter 10</em></span></a><span class="No-Break">):</span></p>
			<pre class="source-code">
presets:
  logsCollection:
    enabled: true
    includeCollectorLogs: false</pre>			<p>If <a id="_idIndexMarker628"/>configuring this yourself, you will have to add the roles and <strong class="source-inline">filelogreceiver</strong> into your pipelines manually. A basic Filelog Receiver shows what to include and exclude, along with additional <span class="No-Break">processing options:</span></p>
			<pre class="source-code">
filelog:
  include:
    - /var/log/pods/*/*/*.log
  exclude:
    - /var/log/pods/*/otel-collector/*.log
  start_at: beginning
  include_file_path: true
  include_file_name: false</pre>			<p>Additionally, operators can be applied for log processing, filtering, <span class="No-Break">and parsing.</span></p>
			<p>The following is a list of Filelog <span class="No-Break">Receiver parsers:</span></p>
			<ul>
				<li><strong class="source-inline">json_parser</strong>: To <span class="No-Break">parse JSON</span></li>
				<li><strong class="source-inline">regex_parser</strong>: To perform regular <span class="No-Break">expression parsing</span></li>
				<li><strong class="source-inline">csv_parser</strong>: To parse <span class="No-Break">comma-separated values</span></li>
				<li><strong class="source-inline">key_value_parser</strong>: To process structured <span class="No-Break">key-value pairs</span></li>
				<li><strong class="source-inline">uri_parser</strong>: To process structured <span class="No-Break">web paths</span></li>
				<li><strong class="source-inline">syslog_parser</strong>: To process the standard syslog <span class="No-Break">log format</span></li>
			</ul>
			<h2 id="_idParaDest-142"><a id="_idTextAnchor154"/>Kubernetes Cluster Receiver</h2>
			<p>The <strong class="bold">Kubernetes Cluster Receiver</strong>, as<a id="_idIndexMarker629"/> its name suggests, collects metrics and events from the cluster using the Kubernetes API server. This receiver is used to obtain information regarding Pod phases, node conditions, and other cluster-level operations. The receiver must be deployed as a single instance; otherwise, the data would <span class="No-Break">be duplicated.</span></p>
			<p>An example cluster receiver <span class="No-Break">configuration follows:</span></p>
			<pre class="source-code">
k8s_cluster:
  auth_type: serviceAccount
  node_conditions_to_report:
    - Ready
    - MemoryPressure
  allocatable_types_to_report:
    - cpu
    - memory
  metrics:
    k8s.container.cpu_limit:
      enabled: false
  resource_attributes:
    container.id:
      enabled: false</pre>			<h2 id="_idParaDest-143"><a id="_idTextAnchor155"/>Kubernetes Object Receiver</h2>
			<p>The <strong class="bold">Kubernetes Objects Receiver</strong> can be<a id="_idIndexMarker630"/> used to collect any type of object from the Kubernetes API server. As with the Kubernetes Cluster Receiver, this must be deployed as a single instance to prevent <span class="No-Break">duplicate data.</span></p>
			<p>The receiver can be implemented to pull or watch objects by using <strong class="source-inline">pull</strong> <span class="No-Break">or </span><span class="No-Break"><strong class="source-inline">watch</strong></span><span class="No-Break">:</span></p>
			<ul>
				<li>When <strong class="source-inline">pull</strong> is implemented, the receiver periodically polls the Kubernetes API and lists all the objects in the cluster. Each object will be converted to its <span class="No-Break">own log.</span></li>
				<li>When <strong class="source-inline">watch</strong> is configured, the receiver creates a stream with the Kubernetes API to receive updates as and when objects change; this is the most common <span class="No-Break">use case.</span></li>
			</ul>
			<p>Let’s look at an<a id="_idIndexMarker631"/> example of Kubernetes Object <span class="No-Break">Receiver configuration:</span></p>
			<pre class="source-code">
  k8sobjects:
    auth_type: serviceAccount
    objects:
      - name: pods
        mode: pull
        label_selector: environment in (prod)
        field_selector: status.phase=Running
        interval: 15m
      - name: events
        mode: watch
        group: events.k8s.io
        namespaces: [default]</pre>			<h2 id="_idParaDest-144"><a id="_idTextAnchor156"/>Prometheus Receiver</h2>
			<p>The <strong class="bold">Prometheus Receiver</strong> can be<a id="_idIndexMarker632"/> used to collect (scrape) metrics from Kubernetes and its workloads. The full range of Prometheus <strong class="source-inline">scrape_config</strong> options are supported by the receiver. An example of this implementation and <strong class="source-inline">scrape_configs</strong> can be seen in the <a href="B18277_05.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 5</em></span></a> demo project code. Here is an example Prometheus <span class="No-Break">Receiver configuration:</span></p>
			<pre class="source-code">
    prometheus:
      config:
        scrape_configs:
          - job_name: 'opentelemetry-collector'
            tls_config:
              insecure_skip_verify: true
            scrape_interval: 60s
            scrape_timeout: 5s
            kubernetes_sd_configs:
              - role: pod</pre>			<p>The Prometheus <a id="_idIndexMarker633"/>Receiver is stateful, so the following points need to be taken into consideration when <span class="No-Break">using it:</span></p>
			<ul>
				<li>The receiver cannot auto-scale the scraping process with <span class="No-Break">multiple replicas</span></li>
				<li>Running multiple replicas with the same config will scrape targets <span class="No-Break">multiple times</span></li>
				<li>To manually scale the scraping process, each replica will need to be configured with a different <span class="No-Break">scraping configuration</span></li>
			</ul>
			<h2 id="_idParaDest-145"><a id="_idTextAnchor157"/>Host Metrics Receiver</h2>
			<p>The <strong class="bold">Host Metrics Receiver</strong> collects metrics<a id="_idIndexMarker634"/> from a host using a variety of scrapers; the receiver will need access to the host filesystem volume to <span class="No-Break">work correctly.</span></p>
			<p><em class="italic">Table 7.2</em> shows the metrics available to scrape. The OpenTelemetry Collector Helm chart has the <strong class="source-inline">hostMetrics</strong> preset to add the <span class="No-Break">necessary configurations:</span></p>
			<pre class="source-code">
mode: daemonset
presets:
  hostMetrics:
    enabled: true</pre>			<p>By default, the<a id="_idIndexMarker635"/> preset will scrape every 10 seconds, which may generate too many metrics for your backend system. Be aware of this and consider overriding it to 60 seconds. The following table also shows the metrics that will be scraped by default using <span class="No-Break">the preset:</span></p>
			<table id="table002-5" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Metric Scraper</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Description</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Included when using the </strong><span class="No-Break"><strong class="bold">hostMetrics preset</strong></span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">CPU</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Scrapes CPU <span class="No-Break">utilization metrics</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Yes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Disk</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Scrapes disk <span class="No-Break">I/O metrics</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Yes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Load</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Scrapes CPU <span class="No-Break">load metrics</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Yes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Filesystem</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Scrapes filesystem <span class="No-Break">utilization metrics</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Yes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Memory</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Scrapes memory <span class="No-Break">utilization metrics</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Yes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Network</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Scrapes network interface I/O metrics and TCP <span class="No-Break">connection metrics</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Yes</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Paging</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Scrapes paging and swap space utilization and <span class="No-Break">I/O metrics</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">No</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Processes</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Scrapes process <span class="No-Break">count metrics</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">No</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Process</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Scrapes per-process CPU, memory, and disk <span class="No-Break">I/O metrics</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">No</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 7.2 – Host Metrics Receiver scrapers</p>
			<p>Let’s now take a look at our first cloud provider, AWS, and the connectivity <span class="No-Break">options available.</span></p>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor158"/>Visualizing AWS telemetry with Grafana Cloud</h1>
			<p>There are two main<a id="_idIndexMarker636"/> ways in which you can visualize <a id="_idIndexMarker637"/>your AWS telemetry with <span class="No-Break">Grafana Cloud:</span></p>
			<ul>
				<li><strong class="bold">Amazon CloudWatch data source</strong>: Amazon <a id="_idIndexMarker638"/>CloudWatch telemetry remains in AWS and Grafana is configured to remotely read the data at <span class="No-Break">query time</span></li>
				<li><strong class="bold">AWS integration</strong>: AWS <a id="_idIndexMarker639"/>CloudWatch telemetry data is either sent to or scraped and stored in Grafana Cloud (logs in Loki and metrics <span class="No-Break">in Mimir).</span></li>
			</ul>
			<p>Let’s take a look at the differences between these two options to understand whether the integration option or the data source option best fits your <span class="No-Break">use case.</span></p>
			<h2 id="_idParaDest-147"><a id="_idTextAnchor159"/>Amazon CloudWatch data source</h2>
			<p>Grafana<a id="_idIndexMarker640"/> Cloud comes with support for <strong class="bold">Amazon CloudWatch</strong>, allowing you<a id="_idIndexMarker641"/> to query, trigger alerts, and visualize your data in Grafana dashboards. To read CloudWatch telemetry, you will need to configure the AWS <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) permissions and <a id="_idIndexMarker642"/>provide the necessary authentication details in the data source configuration screen. This does not store any telemetry data in Grafana; it only retrieves it at <span class="No-Break">query time.</span></p>
			<p>Let’s now look at the different <span class="No-Break">configuration steps.</span></p>
			<h3>Configuring the data source</h3>
			<p>Data sources can be <a id="_idIndexMarker643"/>accessed from the menu under the <strong class="bold">Connections</strong> item. To create a new connection, click the <strong class="bold">Add new data source</strong> button and search for <strong class="source-inline">CloudWatch</strong>. For existing ones, search for <strong class="source-inline">CloudWatch</strong> in the <strong class="bold">Data sources</strong> search box. You will see a screen similar to the following. Click <strong class="bold">CloudWatch</strong> to open the <span class="No-Break"><strong class="bold">Settings</strong></span><span class="No-Break"> page:</span></p>
			<div>
				<div id="_idContainer088" class="IMG---Figure">
					<img src="image/B18277_Figure_7.1.jpg" alt="Figure 7.1 – Grafana Connections Data sources screen"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.1 – Grafana Connections Data sources screen</p>
			<p>The <strong class="bold">Settings</strong> screen<a id="_idIndexMarker644"/> requires the AWS configuration details needed to establish the connection, as shown in the following screenshot. Here, you can also configure namespace details for custom metrics, log query timeouts, and X-Ray <span class="No-Break">trace links:</span></p>
			<div>
				<div id="_idContainer089" class="IMG---Figure">
					<img src="image/B18277_Figure_7.2.jpg" alt="Figure 7.2 – Amazon CloudWatch data source settings"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.2 – Amazon CloudWatch data source settings</p>
			<h3>Using the Amazon CloudWatch query editor</h3>
			<p>The <a id="_idIndexMarker645"/>CloudWatch data source comes with its own specialized query editor that can query data from both CloudWatch metrics <span class="No-Break">and logs.</span></p>
			<p>From the data explorer, you can select <strong class="bold">CloudWatch Metrics</strong> or <strong class="bold">CloudWatch Logs</strong> as the source data, as shown in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer090" class="IMG---Figure">
					<img src="image/B18277_Figure_7.3.jpg" alt="Figure 7.3 – Amazon CloudWatch query editor"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.3 – Amazon CloudWatch query editor</p>
			<p>With the metrics editor in <strong class="bold">Builder</strong> mode, you can create a valid metric search query by specifying the namespace, metric name, and at least <span class="No-Break">one statistic.</span></p>
			<p>The logs editor provides a <strong class="bold">Log group</strong> selector, allowing you to specify the target log groups and then use AWS CloudWatch Logs Query Language <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html">https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html</a> in the <span class="No-Break">query editor.</span></p>
			<h3>Using Amazon CloudWatch dashboards</h3>
			<p>On the data <a id="_idIndexMarker646"/>source <strong class="bold">Settings</strong> screen, there is a <strong class="bold">Dashboards</strong> tab with a set of pre-configured dashboards to get <span class="No-Break">you started.</span></p>
			<p>The following figure shows the list of available dashboards and import details (if a dashboard has already been imported, you will see the options to delete <span class="No-Break">or reimport):</span></p>
			<div>
				<div id="_idContainer091" class="IMG---Figure">
					<img src="image/B18277_Figure_7.4.jpg" alt="Figure 7.4 – Amazon CloudWatch pre-configured dashboards"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.4 – Amazon CloudWatch pre-configured dashboards</p>
			<p>Let’s now take a look at the AWS <span class="No-Break">integration option.</span></p>
			<h2 id="_idParaDest-148"><a id="_idTextAnchor160"/>Exploring AWS integration</h2>
			<p>The AWS integration <a id="_idIndexMarker647"/>option can be added to your account. It will then be available as a connection. When added and configured, you will be able to ingest metric and log data directly into Grafana, which provides a query time benefit as the data is contained within your Grafana Cloud stack. The metrics and logs can then be queried using LogQL or PromQL; see <a href="B18277_04.xhtml#_idTextAnchor092"><span class="No-Break"><em class="italic">Chapter 4</em></span></a> and <a href="B18277_05.xhtml#_idTextAnchor106"><span class="No-Break"><em class="italic">Chapter 5</em></span></a> <span class="No-Break">for refreshers.</span></p>
			<p>Let’s now look at the different <span class="No-Break">configuration steps.</span></p>
			<h3>Configuring the integration</h3>
			<p>The AWS connection<a id="_idIndexMarker648"/> can be accessed from the menu under the <strong class="bold">Connections</strong> item. Search for <strong class="source-inline">aws</strong> from the <strong class="bold">Add new connection </strong>screen; you will see a screen similar to the following. You will see this is an <strong class="bold">Infrastructure</strong> connection and is labeled as <strong class="bold">Guide</strong>. This means there will be comprehensive instructions to help you connect the account and walk you through <span class="No-Break">the process:</span></p>
			<div>
				<div id="_idContainer092" class="IMG---Figure">
					<img src="image/B18277_Figure_7.5.jpg" alt="Figure 7.5 – Grafana Add new connection screen"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.5 – Grafana Add new connection screen</p>
			<p>Selecting the AWS<a id="_idIndexMarker649"/> integration option presents you with several options for integration – <strong class="bold">CloudWatch metrics</strong>, <strong class="bold">Logs with Lambda</strong>, and <strong class="bold">Logs with Firehose</strong> – as shown in the <span class="No-Break">following screenshot:</span></p>
			<div>
				<div id="_idContainer093" class="IMG---Figure">
					<img src="image/B18277_Figure_7.6.jpg" alt="Figure 7.6 – AWS integration screen"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.6 – AWS integration screen</p>
			<p>Next, we will discuss CloudWatch metrics and Logs <span class="No-Break">with Lambda.</span></p>
			<h3>CloudWatch metrics</h3>
			<p>The <a id="_idIndexMarker650"/>CloudWatch integration allows you to scrape Amazon CloudWatch metrics without installing any collector or agent infrastructure. Multiple scrape jobs can be created to separate concerns, but metrics can only be discovered for AWS resources <span class="No-Break">with tags.</span></p>
			<p>As mentioned earlier, this integration is guided and presents you with all the necessary details to get started by using infrastructure as code or by manually connecting and configuring scrape jobs. The following screenshot shows the CloudWatch metrics <strong class="bold">Configuration </strong><span class="No-Break"><strong class="bold">Details</strong></span><span class="No-Break"> screen:</span></p>
			<div>
				<div id="_idContainer094" class="IMG---Figure">
					<img src="image/B18277_Figure_7.7.jpg" alt="Figure 7.7 – CloudWatch Configuration Details screen"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.7 – CloudWatch Configuration Details screen</p>
			<p>Additionaly there <a id="_idIndexMarker651"/>are some pre-built dashboards that are ready to use. The following figure shows the list of pre-built dashboards that come with the integration option at the time <span class="No-Break">of writing:</span></p>
			<div>
				<div id="_idContainer095" class="IMG---Figure">
					<img src="image/B18277_Figure_7.8.jpg" alt="Figure 7.8 – Sample CloudWatch Metrics dashboard"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.8 – Sample CloudWatch Metrics dashboard</p>
			<h3>Logs with Lambda</h3>
			<p>The Logs with Lambda integration<a id="_idIndexMarker652"/> enables you to send CloudWatch logs to Grafana Cloud. The integration will guide you through the deployment of an AWS Lambda function that forwards CloudWatch logs to Grafana Cloud Loki, where they can be queried using LogQL. <a href="B18277_04.xhtml#_idTextAnchor092"><span class="No-Break"><em class="italic">Chapter 4</em></span></a> explains Loki and LogQL <span class="No-Break">in detail.</span></p>
			<p>The following screenshot shows the <strong class="bold">Logs with Lambda</strong> configuration screen where you can select your <span class="No-Break">deployment approach:</span></p>
			<div>
				<div id="_idContainer096" class="IMG---Figure">
					<img src="image/B18277_Figure_7.9.jpg" alt="Figure 7.9 – Logs with Lambda configuration details"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.9 – Logs with Lambda configuration details</p>
			<p>The following screenshot shows the<a id="_idIndexMarker653"/> configuration steps as the onscreen guide walks you through the connection and configuration of the <span class="No-Break">logs integration:</span></p>
			<div>
				<div id="_idContainer097" class="IMG---Figure">
					<img src="image/B18277_Figure_7.10.jpg" alt="Figure 7.10 – Logs with Lambda CloudFormation configuration"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.10 – Logs with Lambda CloudFormation configuration</p>
			<p>Let’s now look at our second cloud provider – <span class="No-Break">GCP.</span></p>
			<h1 id="_idParaDest-149"><a id="_idTextAnchor161"/>Monitoring GCP using Grafana</h1>
			<p>Grafana Cloud comes with support for <strong class="bold">Google Cloud Monitoring</strong>, allowing <a id="_idIndexMarker654"/>you to query, trigger alerts, and visualize your data in Grafana dashboards. It does not store any telemetry data in Grafana; it only retrieves it at <span class="No-Break">query time.</span></p>
			<p>Let’s now look at the steps for configuring the <span class="No-Break">data source.</span></p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor162"/>Configuring the data source</h2>
			<p>Data sources can be<a id="_idIndexMarker655"/> accessed from the menu under the <strong class="bold">Connections</strong> item. Search for <strong class="source-inline">Google Cloud Monitoring</strong> in the <strong class="bold">Data sources</strong> search box; you will see a screen similar to the one shown in <span class="No-Break"><em class="italic">Figure 7</em></span><em class="italic">.11</em>. Click on <strong class="bold">Google Cloud Monitoring</strong> to open the settings page. The settings<a id="_idIndexMarker656"/> screen prompts for the Google configuration needed to establish and test the connection. The <strong class="bold">Connections</strong> search results screen is <span class="No-Break">shown here:</span></p>
			<div>
				<div id="_idContainer098" class="IMG---Figure">
					<img src="image/B18277_Figure_7.11.jpg" alt="Figure 7.11 – Connections search results screen"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.11 – Connections search results screen</p>
			<p>The configuration settings for <strong class="bold">Google Cloud Monitoring</strong> shown in the following screenshot walk you through the configuration, helping you to choose an authentication method of<a id="_idIndexMarker657"/> either <strong class="bold">JSON Web Token</strong> (<strong class="bold">JWT</strong>) or <strong class="bold">GCE Default </strong><span class="No-Break"><strong class="bold">Service Account</strong></span><span class="No-Break">:</span></p>
			<div>
				<div id="_idContainer099" class="IMG---Figure">
					<img src="image/B18277_Figure_7.12.jpg" alt="Figure 7.12 – Google Cloud Monitoring configuration settings"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.12 – Google Cloud Monitoring configuration settings</p>
			<p>Depending upon <a id="_idIndexMarker658"/>the size of your GCP deployment, you may have to consider, as part of your design, any limits imposed on the token or <span class="No-Break">service account.</span></p>
			<h2 id="_idParaDest-151"><a id="_idTextAnchor163"/>Google Cloud Monitoring query editor</h2>
			<p>The Google Cloud Monitoring data <a id="_idIndexMarker659"/>source comes with its own specialized query editor that can help you build queries for metrics and GCP <strong class="bold">Service Level Objectives</strong> (<strong class="bold">SLOs</strong>), both of <a id="_idIndexMarker660"/>which return time-series data (you will learn more about visualizing time-series data in <a href="B18277_08.xhtml#_idTextAnchor172"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>). Metrics can be queried using the <strong class="bold">Builder</strong> interface or using GCP’s <strong class="bold">Monitoring Query Language</strong> (<strong class="bold">MQL</strong>). The SLO <a id="_idIndexMarker661"/>query builder helps you visualize SLO data in a time-series format. To understand the basic concepts of GCP service monitoring, refer to the GCP documentation <span class="No-Break">at </span><span class="No-Break">https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring</span><span class="No-Break">.</span></p>
			<p>The <strong class="bold">Google Cloud Monitoring</strong> query editor <a id="_idIndexMarker662"/>in the following screenshot shows the three <span class="No-Break">available choices:</span></p>
			<div>
				<div id="_idContainer100" class="IMG---Figure">
					<img src="image/B18277_Figure_7.13.jpg" alt="Figure 7.13 – Google Cloud Monitoring query editor selection"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.13 – Google Cloud Monitoring query editor selection</p>
			<p>Let’s look at the different Explorer <span class="No-Break">query types:</span></p>
			<ul>
				<li><strong class="bold">Metrics queries</strong>: The metrics query editor<a id="_idIndexMarker663"/> builder helps you <a id="_idIndexMarker664"/>select metrics, group and aggregate them by labels and time, and specify time filters for the time-series data you want <span class="No-Break">to query:</span></li>
			</ul>
			<div>
				<div id="_idContainer101" class="IMG---Figure">
					<img src="image/B18277_Figure_7.14.jpg" alt="Figure 7.14 – Google Cloud Monitoring query editor metrics builder"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.14 – Google Cloud Monitoring query editor metrics builder</p>
			<p class="list-inset">The following screenshot shows the query editor for MQL, which provides an interface to create and execute your <span class="No-Break">MQL query:</span></p>
			<div>
				<div id="_idContainer102" class="IMG---Figure">
					<img src="image/B18277_Figure_7.15.jpg" alt="Figure 7.15 – Google Cloud Monitoring query editor metrics MQL interface"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.15 – Google Cloud Monitoring query editor metrics MQL interface</p>
			<p class="list-inset">Full<a id="_idIndexMarker665"/> documentation for the MQL language <a id="_idIndexMarker666"/>specification<a id="_idIndexMarker667"/> can be found on the Google Cloud website <span class="No-Break">at </span><a href="https://cloud.google.com/monitoring/mql"><span class="No-Break">https://cloud.google.com/monitoring/mql</span></a><span class="No-Break">.</span></p>
			<ul>
				<li><strong class="bold">SLO queries</strong>: The SLO query builder<a id="_idIndexMarker668"/> helps you visualize <a id="_idIndexMarker669"/>SLO data in time-series format. Documentation to explain the basic concepts of service monitoring<a id="_idIndexMarker670"/> can be found on the Google Cloud website <span class="No-Break">at </span><a href="https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring"><span class="No-Break">https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring</span></a><span class="No-Break">.</span><p class="list-inset">The Google Cloud Monitoring SLO query editor is shown in the <span class="No-Break">following screenshot:</span></p></li>
			</ul>
			<div>
				<div id="_idContainer103" class="IMG---Figure">
					<img src="image/B18277_Figure_7.16.jpg" alt="Figure 7.16 – Google Cloud Monitoring query editor metrics SLO builder"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.16 – Google Cloud Monitoring query editor metrics SLO builder</p>
			<h2 id="_idParaDest-152"><a id="_idTextAnchor164"/>Google Cloud Monitoring dashboards</h2>
			<p>From the <strong class="bold">Data source</strong> | <strong class="bold">Settings</strong> screen, the <strong class="bold">Dashboards</strong> tab lists a set of pre-configured <a id="_idIndexMarker671"/>dashboards to get you started. The following screenshot shows the list of available dashboards at the time of writing and import details (if a dashboard has already been imported, there are options to delete or reimport). You can see from the list the various GCP components that are covered, including firewalls, data processing, SQL, and <span class="No-Break">so on:</span></p>
			<div>
				<div id="_idContainer104" class="IMG---Figure">
					<img src="image/B18277_Figure_7.17.jpg" alt="Figure 7.17 – Google Cloud Monitoring pre-built dashboards"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.17 – Google Cloud Monitoring pre-built dashboards</p>
			<p>Let’s now look at our third cloud <span class="No-Break">provider, Azure.</span></p>
			<h1 id="_idParaDest-153"><a id="_idTextAnchor165"/>Monitoring Azure using Grafana</h1>
			<p>Grafana Cloud comes with support for Azure, allowing you to query, trigger alerts, and visualize your data in Grafana dashboards. This is called the <strong class="bold">Azure Monitor</strong> data source. As with the other <a id="_idIndexMarker672"/>cloud data sources, it does not store any telemetry data in Grafana; it only retrieves it at <span class="No-Break">query time.</span></p>
			<p>Let’s now step through <span class="No-Break">the configuration.</span></p>
			<h2 id="_idParaDest-154"><a id="_idTextAnchor166"/>Configuring the data source</h2>
			<p>Data sources can be <a id="_idIndexMarker673"/>accessed from the menu under the <strong class="bold">Connections</strong> item. Search for <strong class="source-inline">Azure Monitor</strong> in the <strong class="bold">Data sources</strong> search box; you will see a screen similar to <span class="No-Break">the following:</span></p>
			<div>
				<div id="_idContainer105" class="IMG---Figure">
					<img src="image/B18277_Figure_7.18.jpg" alt="Figure 7.18 – Connection search results screen for Azure Monitor"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.18 – Connection search results screen for Azure Monitor</p>
			<p>Click on <strong class="bold">Azure Monitor</strong> to open the settings page. The configuration settings for <strong class="bold">Azure Monitor</strong> shown in the following screenshot walk you through the configuration, helping you to set up authentication using the Azure <strong class="bold">Client Secret</strong> configuration, and test <span class="No-Break">the connection:</span></p>
			<div>
				<div id="_idContainer106" class="IMG---Figure">
					<img src="image/B18277_Figure_7.19.jpg" alt="Figure 7.19 – Azure Monitor data source settings screen"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.19 – Azure Monitor data source settings screen</p>
			<h2 id="_idParaDest-155"><a id="_idTextAnchor167"/>Using the Azure Monitor query editor</h2>
			<p>The Azure Monitor<a id="_idIndexMarker674"/> data source comes with its own specialized query editor that can help you build queries for metrics and logs, Azure Resource Graph, and Application <span class="No-Break">Insights traces.</span></p>
			<p>The following Azure Monitor query editor screenshot shows <span class="No-Break">four choices:</span></p>
			<div>
				<div id="_idContainer107" class="IMG---Figure">
					<img src="image/B18277_Figure_7.20.jpg" alt="Figure 7.20 – Azure Monitor query editor selector"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.20 – Azure Monitor query editor selector</p>
			<p>Let’s look at these options <span class="No-Break">in detail:</span></p>
			<ul>
				<li><strong class="bold">Metrics queries</strong>: The <a id="_idIndexMarker675"/>Azure Monitor metrics queries collect numeric data from Azure-supported resources, which are listed here on the<a id="_idIndexMarker676"/> Microsoft Azure <span class="No-Break">website: </span><a href="https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference"><span class="No-Break">https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference</span></a><span class="No-Break">.</span><p class="list-inset">The metrics<a id="_idIndexMarker677"/> store numeric data only, and in a specific structure that allows for near real-time detection of platform health, performance, and usage. The Azure Monitor metrics query builder is <span class="No-Break">shown here:</span></p></li>
			</ul>
			<div>
				<div id="_idContainer108" class="IMG---Figure">
					<img src="image/B18277_Figure_7.21.jpg" alt="Figure 7.21 – Azure Monitor metrics query builder"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.21 – Azure Monitor metrics query builder</p>
			<ul>
				<li><strong class="bold">Log queries</strong>: The <a id="_idIndexMarker678"/>Azure Monitor logs queries collect and organize log data from Azure-supported resources. A variety of data types, each with their own defined structure, are accessible, and to access these, the <strong class="bold">Kusto Query Language</strong> (<strong class="bold">KQL</strong>) can be used. An overview of KQL can be found on the Microsoft <a id="_idIndexMarker679"/>Azure website here: <a href="https://learn.microsoft.com/en-us/azure/data-explorer/kusto/query/">https://learn.microsoft.com/en-us/azure/data-explorer/kusto/query/</a>. The Azure<a id="_idIndexMarker680"/> Monitor logs query editor is shown in the <span class="No-Break">following screenshot:</span></li>
			</ul>
			<div>
				<div id="_idContainer109" class="IMG---Figure">
					<img src="image/B18277_Figure_7.22.jpg" alt="Figure 7.22 – Azure Monitor logs query editor"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.22 – Azure Monitor logs query editor</p>
			<p class="list-inset">Azure Monitor logs can store a variety of data types, each with its own structure. For more details, you can refer <span class="No-Break">to </span><a href="https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference"><span class="No-Break">https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference</span></a><span class="No-Break">.</span></p>
			<ul>
				<li><strong class="bold">Traces queries</strong>: The Azure Monitor traces queries can be regarded as Azure Application<a id="_idIndexMarker681"/> Insights under the hood. The Azure Application Insights service provides <strong class="bold">application performance monitoring</strong> (<strong class="bold">APM</strong>) features to its workloads. The Azure Monitor traces can be used to interrogate and visualize various metrics and trace data. The query editor looks <span class="No-Break">like this:</span></li>
			</ul>
			<div>
				<div id="_idContainer110" class="IMG---Figure">
					<img src="image/B18277_Figure_7.23.jpg" alt="Figure 7.23 – Azure Monitor traces query editor"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.23 – Azure Monitor traces query editor</p>
			<ul>
				<li><strong class="bold">Azure Resource Graph</strong> (<strong class="bold">ARG</strong>): The ARG <a id="_idIndexMarker682"/>service extends the functionality of Azure Resource Manager by providing the ability to query across multiple Azure subscriptions in a scalable manner. This allows you to query Azure resources using the resource graph query language, making it ideal for querying and analyzing larger Azure cloud infrastructure deployments. Full documentation for the resource <a id="_idIndexMarker683"/>graph query language can be found <span class="No-Break">at </span><a href="https://learn.microsoft.com/en-us/azure/governance/resource-graph/samples/starter?tabs=azure-cli"><span class="No-Break">https://learn.microsoft.com/en-us/azure/governance/resource-graph/samples/starter?tabs=azure-cli</span></a><span class="No-Break">.</span><p class="list-inset">The following example query shows all resources <span class="No-Break">by name:</span></p><pre class="source-code">
<strong class="bold">Resources | project name, type, location | order by name asc</strong></pre><p class="list-inset"> Here’s what the ARG query editor <span class="No-Break">looks like:</span></p></li>			</ul>
			<div>
				<div id="_idContainer111" class="IMG---Figure">
					<img src="image/B18277_Figure_7.24.jpg" alt="Figure 7.24 – Azure Resource Graph query editor"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.24 – Azure Resource Graph query editor</p>
			<h2 id="_idParaDest-156"><a id="_idTextAnchor168"/>Using Azure Monitor dashboards</h2>
			<p>From the <strong class="bold">Data source</strong> | <strong class="bold">Settings</strong> screen, the <strong class="bold">Dashboards</strong> tab shows a set of pre-configured dashboards that <a id="_idIndexMarker684"/>will get you started with Azure Monitor. In the following screenshot, there is a list of the various Azure components that have dashboards designed for them; they include applications, SQL servers, and <span class="No-Break">storage accounts:</span></p>
			<div>
				<div id="_idContainer112" class="IMG---Figure">
					<img src="image/B18277_Figure_7.25.jpg" alt="Figure 7.25 – Azure Monitor pre-built dashboards"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 7.25 – Azure Monitor pre-built dashboards</p>
			<p>Let’s now review some of the best practices we have covered for each of the cloud infrastructure providers we have discussed in <span class="No-Break">this chapter.</span></p>
			<h1 id="_idParaDest-157"><a id="_idTextAnchor169"/>Best practices and approaches</h1>
			<p>In this chapter, we have provided an overview of several popular cloud infrastructures. Let’s now discuss some of the best practices that should be considered when implementing observability on any application <span class="No-Break">or system:</span></p>
			<ul>
				<li><strong class="bold">Performance</strong>: The <a id="_idIndexMarker685"/>process of retrieving telemetry data can potentially incur a performance overhead. For example, with a remote Grafana data source, the telemetry data is fetched at query time over a great distance. This can introduce latency when compared to data stored closer to the Grafana query engine using one of the Grafana Cloud data sources, such as Loki, Mimir, and Tempo. Where performance is important and there is an option to ship telemetry into Grafana, that could be the best choice. Alternatively, several data sources have caching options to improve query speed; improvements in query speed can also be made using specific configurations. Take the time to understand your data and ensure you are using it in an <span class="No-Break">optimal way.</span></li>
				<li><strong class="bold">Cost</strong>: Alongside the increased network and storage costs of shipping data into Grafana Cloud, there can also be costs when querying a cloud provider API. It is important to understand where charges are raised. This ensures that they are factored in when you’re designing your observability solution for the specific platform that your <span class="No-Break">systems utilize.</span></li>
				<li><strong class="bold">Constraints</strong>: In general, infrastructure <a id="_idIndexMarker686"/>platforms come configured with constraints in place to protect the system. Sometimes these are soft limits that can be relaxed after careful consideration, but they may be hard limits. Before committing to a solution for a specific platform, understand your requirements and the volume of data or query transactions expected. You can compare these to any documented limits, your API key use, or your network egress volumes, therefore validating that the system will support <span class="No-Break">your needs.</span></li>
				<li><strong class="bold">Security</strong>: For most of the configuration options we discussed in this chapter, we identified how they can be set up to generate separation of concerns. Having separate data sources or other controls on the data being queried or ingested will allow you to improve your security posture based on the underlying data and <span class="No-Break">use </span><span class="No-Break"><a id="_idIndexMarker687"/></span><span class="No-Break">case.</span></li>
			</ul>
			<p class="callout-heading">Important note</p>
			<p class="callout">As this book was nearing publication, Grafana Labs released <strong class="bold">private data source connect</strong> (<strong class="bold">PDC</strong>), which gives<a id="_idIndexMarker688"/> administrators the ability to connect to any network-secured data source, regardless of where it is hosted. We have not covered this topic, but it is likely to be of interest <span class="No-Break">to readers.</span></p>
			<p>We will now wrap this chapter up with a summary and set the stage for the <span class="No-Break">next chapter.</span></p>
			<h1 id="_idParaDest-158"><a id="_idTextAnchor170"/>Summary</h1>
			<p>In this chapter, we have looked at various common cloud infrastructure providers, starting with Kubernetes, and we presented examples that can be used with the demo project provided alongside this book. We then looked at the big three cloud providers, AWS, GCP, and Azure. We presented an overview of the connection options and how to get started with the pre-built dashboards and the data explorer. Lastly, we covered some of the best practices that need to be considered with all <span class="No-Break">observability integrations.</span></p>
			<p>In the next chapter, we move on from getting telemetry data into Grafana and on to the visualization of that data using dashboards. This is where the <span class="No-Break">fun starts!</span></p>
		</div>
	

		<div id="_idContainer114" class="Content">
			<h1 id="_idParaDest-159" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor171"/>Part 3: Grafana in Practice</h1>
			<p>In practice, Grafana is used to understand the current system state and take appropriate actions to give customers the best results. This part will cover the wide variety of activities that may be needed to complete that goal and what should be considered along the way. You will learn how to present your data while considering the requirements of your audience. You will explore how to build a world-class incident management process. You will also learn approaches to automating and architecting your <span class="No-Break">observability platform.</span></p>
			<p>This part has the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B18277_08.xhtml#_idTextAnchor172"><em class="italic">Chapter 8</em></a><em class="italic">, Displaying Data with Dashboards</em></li>
				<li><a href="B18277_09.xhtml#_idTextAnchor183"><em class="italic">Chapter 9</em></a><em class="italic">, Managing Incidents Using Alerts</em></li>
				<li><a href="B18277_10.xhtml#_idTextAnchor204"><em class="italic">Chapter 10</em></a><em class="italic">, Automation with Infrastructure as Code</em></li>
				<li><a href="B18277_11.xhtml#_idTextAnchor218"><em class="italic">Chapter 11</em></a><em class="italic">, Architecting an Observability Platform</em></li>
			</ul>
		</div>
		<div>
			<div id="_idContainer115">
			</div>
		</div>
		<div>
			<div id="_idContainer116" class="Basic-Graphics-Frame">
			</div>
		</div>
	</body></html>