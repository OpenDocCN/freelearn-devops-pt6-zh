- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using Multi-Container Pods and Design Patterns
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running complex applications on Kubernetes will require that you run not one
    but several containers in the same Pods. The strength of Kubernetes also lies
    in its ability to create Pods made up of several containers. We will focus on
    those Pods in this chapter by studying the different aspects of hosting several
    containers in the same Pod, as well as having these different containers communicate
    with each other.
  prefs: []
  type: TYPE_NORMAL
- en: 'So far, we’ve only created Pods running a single container: those were the
    simplest forms of Pods, and you’ll use these Pods to manage the simplest of applications.
    We also discovered how to update and delete them by running simple **create**,
    **read**, **update, and delete** (**CRUD**) operations against those Pods using
    the `kubectl` command-line tool.'
  prefs: []
  type: TYPE_NORMAL
- en: Besides mastering the basics of CRUD operations, you have also learned how to
    access a running Pod inside a Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: While single-container Pods are more common, there are situations where using
    multiple containers in a single Pod is beneficial. For example, using a dedicated
    container to handle log gathering with the main container inside a Pod or another
    dedicated container to enable proxy communication between services. In this chapter,
    we will push all of this one step forward and discover how to manage Pods when
    they are meant to launch not one but several containers. The good news is that
    everything you learned previously will also be valid for multi-container Pods.
    Things won’t differ much in terms of raw Pod management because updating and deleting
    Pods is not different, no matter how many containers the Pod contains.
  prefs: []
  type: TYPE_NORMAL
- en: Besides those basic operations, we are also going to cover how to access a specific
    container inside a multi-container Pod and how to access its logs. When a given
    Pod contains more than one container, you’ll have to run some specific commands
    with specific arguments to access it, and that’s something we are going to cover
    in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: We will also discover some important design patterns such as Ambassador, Sidecar,
    and Adapter containers. You’ll need to learn these architectures to effectively
    manage multi-container Pods. You’ll also learn how to deal with volumes from Kubernetes.
    Docker also provides volumes, but in Kubernetes, they are used to share data between
    containers launched by the same Pod, and this is going to be an important part
    of this chapter. After this chapter, you’re going to be able to launch complex
    applications inside Kubernetes Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding what multi-container Pods are
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharing volumes between containers in the same Pod
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Ambassador Design Pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Sidecar Design Pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Adapter Design Pattern
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sidecars versus Kubernetes Native Sidecars
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You will require the following prerequisites for this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: A working `kubectl` command-line utility.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A local or cloud-based Kubernetes cluster to practice with.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can download the latest code samples for this chapter from the official
    GitHub repository: [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter05](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter05).'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding what multi-container Pods are
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Multi-container Pods are a way to package tightly coupled applications together
    in Kubernetes. This allows multiple containers to share resources and easily communicate
    with each other, which is ideal for scenarios like sidecars and service mesh.
    In this section, we’ll learn about the core concepts of Pods for managing multiple
    containers at once by discussing some concrete examples of multi-container Pods.
  prefs: []
  type: TYPE_NORMAL
- en: Concrete scenarios where you need multi-container Pods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You should group your containers into a Pod when they need to be tightly linked.
    More broadly, a Pod must correspond to an application or a process running in
    your Kubernetes cluster. If your application requires multiple containers to function
    properly, then those containers should be launched and managed through a single
    Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the containers are supposed to work together, you should group them into
    a single Pod. Keep in mind that a Pod cannot span across multiple compute nodes.
    So, if you create a Pod containing several containers, then all these containers
    will be created on the same compute node. To understand where and when to use
    multi-container Pods, take the example of two simple applications:'
  prefs: []
  type: TYPE_NORMAL
- en: '**A log forwarder**: In this example, imagine that you have deployed a web
    server such as NGINX that stores its logs in a dedicated directory. You might
    want to collect and forward these logs. For that, you could deploy something like
    a Splunk forwarder as a container within the same Pod as your NGINX server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These log forwarding tools are used to forward logs from a source to a destination
    location, and it is very common to deploy agents such as Splunk, Fluentd, or Filebeat
    to grab logs from a container and forward them to a central location such as an
    Elasticsearch cluster. In the Kubernetes world, this is generally achieved by
    running a multi-container Pod with one container dedicated to running the application,
    and another one dedicated to grabbing the logs and sending them elsewhere. Having
    these two containers managed by the same Pod would ensure that they are launched
    on the same node as the log forwarder and at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: '**A proxy server**: Imagine an NGINX reverse proxy container in the same Pod
    as your main application, efficiently handling traffic routing and security with
    custom rules. This concept extends to **service mesh**, where a dedicated proxy
    like Envoy can be deployed alongside your application container, enabling features
    like load balancing and service discovery within a microservices architecture.
    (We will learn about service mesh in detail in *Chapter 8*, *Exposing Your Pods
    with Services*.) By bundling the two containers in the same Pod, you’ll get two
    Pods running in the same node. You could also run a third container in the same
    Pod to forward the logs that are emitted by the two others to a central logging
    location! This is because Kubernetes has no limit on the number of containers
    you can have in the same Pod, as long as you have enough computing resources to
    run them all.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/B22019_05_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.1: Sample multi-container Pod scenario'
  prefs: []
  type: TYPE_NORMAL
- en: In general, every time several of your containers work together and are tightly
    coupled, you should have them in a multi-container Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s discover how to create multi-container Pods.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Pod made up of two containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the previous chapter, we discovered two syntaxes for manipulating Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: The imperative syntax
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The declarative syntax
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Most of the Kubernetes objects we are going to discover in this book can be
    created or updated using these two methods, but unfortunately, this is not the
    case for multi-container Pods.
  prefs: []
  type: TYPE_NORMAL
- en: When you need to create a Pod containing multiple containers, you will need
    to go through the declarative syntax. This means that you will have to create
    a YAML file containing the declaration of your Pods and all the containers it
    will manage, and then apply it through `kubectl apply -f file.yaml`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following YAML manifest file stored in `~/multi-container-pod.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'This YAML manifest will create a Kubernetes Pod made up of two containers:
    one based on the `nginx:latest` image and the other one based on the `debian`
    image.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create it, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: This will result in the Pod being created. The kubelet on the elected node will
    have the container runtime (e.g., containerd, CRI-O, or Docker daemon) to pull
    both images and instantiate two containers.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check whether the Pod was correctly created, we can run `kubectl get pods`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Do you remember the role of `kubelet` from *Chapter 2*, *Kubernetes Architecture
    – from Container Images to Running Pods*? This component runs on each node that
    is part of your Kubernetes cluster and is responsible for converting Pod manifests
    received from `kube-apiserver` into actual containers.
  prefs: []
  type: TYPE_NORMAL
- en: All the containers that are declared in the same Pod will be scheduled, or launched,
    on the same node and Pods cannot span multiple machines.
  prefs: []
  type: TYPE_NORMAL
- en: Containers in the same Pod are meant to live together. If you terminate a Pod,
    all its containers will be killed together, and when you create a Pod, the kubelet
    will, at the very least, attempt to create all its containers together.
  prefs: []
  type: TYPE_NORMAL
- en: High availability is generally achieved by replicating multiple Pods over multiple
    nodes, which you will learn about later in this book.
  prefs: []
  type: TYPE_NORMAL
- en: From a Kubernetes perspective, applying this file results in a fully working
    multi-container Pod made up of two containers, and we can make sure that the Pod
    is running with the two containers by running a standard `kubectl get pods` command
    to fetch the Pod list from `kube-apiserver`.
  prefs: []
  type: TYPE_NORMAL
- en: Do you see the column that states `2/2` in the previous `kubectl` command output?
    This is the number of containers inside the Pod. Here, this is saying that the
    two containers that are part of this Pod were successfully launched! We can see
    the logs from different containers as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: We learned how to create and manage multi-container Pods, and in the next section,
    we will learn how to troubleshoot when a multi-container Pod fails.
  prefs: []
  type: TYPE_NORMAL
- en: What happens when Kubernetes fails to launch one container in a Pod?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes keeps track of all the containers that are launched in the same Pod.
    But it often happens that a specific container cannot be launched. Let’s introduce
    a typo in the YAML manifest to demonstrate how Kubernetes reacts when some containers
    of a specific Pod cannot be launched.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we have defined a container image that does not exist
    at all for the NGINX container; note the `nginx:i-do-not-exist` tag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can apply the following container using the `kubectl apply -f failed-multi-container-pod.yaml`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: Here, you can see that the Pod was effectively created. This is because even
    if there’s a non-existent image, the YAML remains valid from a Kubernetes perspective.
    So, Kubernetes simply creates the Pod and persists the entry into `etcd`, but
    we can easily imagine that the kubelet will encounter an error when it launches
    the container to retrieve the image from the container registry (e.g., Docker
    Hub).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check the status of the Pod using `kubectl get pod`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the status of the Pod is `ImagePullBackOff`. This means that
    Kubernetes is trying to launch the Pod but failing with an image access issue.
    To find out why it’s failing, you have to describe the Pod using the `kubectl
    describe pod failed-multi-container-pod` command as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: It’s a little bit hard to read, but by following this log, you can see that
    `debian-container` is okay since `kubelet` has succeeded in creating it, as shown
    by the last line of the preceding output. But there’s a problem with the other
    container; that is, `nginx-container`.
  prefs: []
  type: TYPE_NORMAL
- en: Here, you can see that the output error is `ErrImagePull` and, as you can guess,
    it’s saying that the container cannot be launched because the image pull fails
    to retrieve the `nginx:i-do-not-exist` image tag.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, Kubernetes does the following:'
  prefs: []
  type: TYPE_NORMAL
- en: First, it creates the entry in `etcd` if the Pod of the YAML file is valid.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, it simply tries to launch the container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If an error is encountered, it will try to launch the failing container again
    and again.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: If any other container works properly, it’s fine. However, your Pod will never
    enter the `Running` status because of the failed container. After all, your app
    certainly needs the failing container to work properly; otherwise, that container
    should not be there at all!
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s learn how to delete a multi-container Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting a multi-container Pod
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you want to delete a Pod containing multiple containers, you have to go
    through the `kubectl delete` command, just like you would for a single-container
    Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, you have two choices:'
  prefs: []
  type: TYPE_NORMAL
- en: You can specify the path to the YAML manifest file that’s used by using the
    `-f` option.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can delete the Pod without using its YAML path if you know its name.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The first way consists of specifying the path to the YAML manifest file. You
    can do so using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Otherwise, if you already know the Pod’s name, you can do this as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'To figure out the name of the Pods, you can use the `kubectl get` commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: When we ran them, only `failed-multi-container-pod` was created in the cluster,
    so that’s why you can just see one line in the output.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how you can delete `failed-multi-container-pod` imperatively without
    specifying the YAML file that created it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: After a few seconds, the Pod is removed from the Kubernetes cluster, and all
    its containers are removed from the container daemon and the Kubernetes cluster
    node.
  prefs: []
  type: TYPE_NORMAL
- en: The amount of time that’s spent before the command is issued and the Pod’s name
    is deleted and released is called the **grace period**. Let’s discover how to
    deal with it!
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the Pod deletion grace period
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One important concept related to deleting Pods is what is called the grace period.
    Both single-container Pods and multi-container Pods have this grace period, which
    can be observed when you delete them. This grace period can be ignored by passing
    the `--grace-period=0 --force` option to the `kubectl delete` command.
  prefs: []
  type: TYPE_NORMAL
- en: During the deletion of a Pod, certain `kubectl` commands display its status
    as `Terminating`. Notably, this `Terminating` status is not categorized within
    the standard Pod phases. Pods are allocated a designated grace period for graceful
    termination, typically set to 30 seconds. To forcefully terminate a Pod, the `--force`
    flag can be employed. When the deletion is forced by setting `--grace-period=0`
    with the `--force` flag, the Pod’s name is immediately released and becomes available
    for another Pod to take it. During an unforced deletion, the grace period is respected,
    and the Pod’s name is released after it is effectively deleted.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This command should be used carefully if you don’t know what you are doing.
    Forcefully deleting a Pod shouldn’t be seen as the norm because, as the output
    states, you cannot be sure that the Pod was effectively deleted. If, for some
    reason, the Pod cannot be deleted, it might run indefinitely, so do not run this
    command if you are not sure of what to do.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s discover how to access a specific container that is running inside
    a multi-container Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing a specific container inside a multi-container Pod
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you have several containers in the same Pod, you can access each of them
    individually. Here, we will access the NGINX container of our multi-container
    Pods. Let’s start by recreating it because we deleted it in our previous example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: To access a running container, you need to use the `kubectl exec` command, just
    like you need to use `docker exec` to launch a command in an already created container
    when using Docker without Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'This command will ask for two important parameters:'
  prefs: []
  type: TYPE_NORMAL
- en: The Pod that wraps the container you want to target
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The name of the container itself, as entered in the YAML manifest file
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We already know the name of the Pod because we can easily retrieve it with the
    `kubectl get` command. In our case, the Pod is named `multi-container-pod`.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, we don’t have the container’s name because there is no `kubectl get`
    containers command that would allow us to list the running containers. This is
    why we will have to use the `kubectl describe pods/multi-container-pod` command
    to find out what is contained in this Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: This command will show the names of all the containers contained in the targeted
    Pod. Here, we can see that our Pod is running two containers, one called `debian-container`
    and another called `nginx-container`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, the following is a command for listing all the container names
    contained in a dedicated Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'This command will spare you from using the `describe` command. However, it
    makes use of `jsonpath`, which is an advanced feature of `kubectl`: this command
    might look strange but it mostly consists of a sort filter that’s applied against
    the command. The `jsonpath` expression `{.spec.containers[*].name}` can be used
    with the `kubectl get pod` command to retrieve the names of all containers within
    a specific Pod. The `.` denotes the entire response object, while `spec.containers`
    targets the containers section within the Pod specification. The `[*]` operator
    instructs `jsonpath` to iterate through all elements within the containers list,
    and `.name` extracts the `name` property from each container object. Essentially,
    this expression provides a comma-separated list of container names within the
    specified Pod.'
  prefs: []
  type: TYPE_NORMAL
- en: '`jsonpath` filters are not easy to get right, so, feel free to add this command
    as a bash alias or note it somewhere because it’s a useful one.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In any case, we can now see that we have these two containers inside the `multi-container-pod`
    Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '`nginx-container`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`busybox-container`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let’s access `nginx-container`. You have the name of the targeted container
    in the targeted Pod, so use the following command to access the Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'After running this command, you will find yourself inside `nginx-container`.
    Let’s explain this command a little bit. `kubectl exec` does the same as `docker
    exec`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl exec`: This is the command to execute commands in a Kubernetes container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-it`: These are options for the execution. `-t` allocates a pseudo-TTY, and
    `-i` allows interaction with the container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`multi-container-pod`: This is the name of the Pod in which you want to execute
    the command.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`--container nginx-container`: This specifies the container within the Pod
    where the command should be executed. In Pods with multiple containers, you need
    to specify the container you want to interact with.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-- /bin/bash`: This is the actual command that will be executed in the specified
    container. It launches a Bash shell (`/bin/bash`) in interactive mode, allowing
    you to interact with the container’s command line.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you run this command, you get the shell of the container, inside the multi-container
    Pod, at a point at which you will be ready to run commands inside this very specific
    container on your Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The main difference from the single container Pod situation is the `--container`
    option (the `-c` short option works, too). You need to pass this option to tell
    `kubectl` what container you want to reach.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s discover how to run commands in the containers running in your Pods!
  prefs: []
  type: TYPE_NORMAL
- en: Running commands in containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One powerful aspect of Kubernetes is that you can, at any time, access the containers
    running on your Pods to execute some commands. We did this previously, but did
    you know you can also execute any command you want directly from the `kubectl`
    command-line tool?
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we are going to recreate the multi-container Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: To run a command in a container, you need to use `kubectl exec`, just like we
    did previously. But this time, you have to remove the `-ti` parameter to prevent
    `kubectl` from attaching to your running terminal session.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we are running the `ls` command to list files in `nginx-container` from
    the `multi-container-pod` Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: You can omit the container name but if you do so, `kubectl` will use the default
    first one.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will discover how to override the commands that are run by your containers.
  prefs: []
  type: TYPE_NORMAL
- en: Overriding the default commands run by the containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Overriding default commands is important in multi-container Pods because it
    lets you control each container’s behavior individually. This means you can customize
    how each container works within the Pod. For example, a web server container might
    normally run a `start server` command, but you could override a sidecar container’s
    command to handle logging instead. This approach can also help with resource management.
    If a container usually runs a heavy process, you can change it to a lighter one
    in the Pod to ensure other containers have enough resources. Finally, it helps
    with managing dependencies. For instance, a database container might typically
    start right away, but you could override its command to wait until a related application
    container is ready.
  prefs: []
  type: TYPE_NORMAL
- en: 'When using Docker, you have the opportunity to write files called `Dockerfiles`
    to build container images. `Dockerfiles` make use of two keywords to tell us what
    commands and arguments the containers that were built with this image will launch
    when they’re created using the `docker run` command. These two keywords are `ENTRYPOINT`
    and `CMD`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ENTRYPOINT` is the main command the container will launch.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`CMD` is used to replace the parameters that are passed to the `ENTRYPOINT`
    command.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, a classic `Dockerfile` that should be launched to run the `sleep`
    command for `30` seconds would be written like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '**Containerfile and Podman**'
  prefs: []
  type: TYPE_NORMAL
- en: A Containerfile acts as a recipe for building a container image similar to Dockerfiles.
    It contains a series of instructions specifying the operating system, installing
    dependencies, copying application code, and configuring settings. Podman, a tool
    similar to Docker, can interpret this Containerfile and construct the image based
    on the instructions.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Thanks to the `CMD` instruction, you can override the default `30` seconds
    like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Kubernetes, on the other hand, allows us to override both `ENTRYPOINT` and
    `CMD` thanks to YAML Pod definition files. To do so, you must append two optional
    keys to your YAML configuration file: `command` and `args`.'
  prefs: []
  type: TYPE_NORMAL
- en: This is a very big benefit that Kubernetes brings you because you can decide
    to append arguments to the command that’s run by your container’s `Dockerfile`,
    just like the `CMD` arguments do with bare Docker, or completely override `ENTRYPOINT`!
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we are going to write a new manifest file that will override the default
    `ENTRYPOINT` and `CMD` parameters of the `busybox` image to make the `busybox`
    container sleep for 60 seconds. Here is how to proceed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: This is a bit tricky to understand because what `Dockerfile` calls `ENTRYPOINT`
    corresponds to the `command` argument in the YAML manifest file, and what `Dockerfile`
    calls `CMD` corresponds to the `args` configuration key in the YAML manifest file.
  prefs: []
  type: TYPE_NORMAL
- en: What if you omit one of them? Kubernetes will default to what is inside the
    container image. If you omit the `args` key in the YAML, then Kubernetes will
    go for the `CMD` provided in the `Dockerfile`, while if you omit the `command`
    key, Kubernetes will go for the `ENTRYPOINT` declared in the `Dockerfile`. Most
    of the time, or at least if you’re comfortable with your container’s `ENTRYPOINT`,
    you’re just going to override the `args` file (the `CMD Dockerfile` instruction).
  prefs: []
  type: TYPE_NORMAL
- en: 'When we create the Pod, we can check the output as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: Therefore, overriding default commands offers granular control over container
    behavior within multi-container Pods. This enables tailored functionality, resource
    optimization, and dependency management for seamless Pod operation. In this section,
    we learned that Kubernetes allows overriding defaults through the `command` and
    `args` fields in Pod YAML definitions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s look at another feature: `initContainers`! In the next section,
    you’ll see another way to execute some additional side containers in your Pod
    to configure the main ones.'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing initContainers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`initContainers` is a feature provided by Kubernetes Pods to run setup scripts
    before the actual containers start. You can think of them as additional side containers
    you can define in your Pod YAML manifest file: they will first run when the Pod
    is created. Then, once they complete, the Pod starts creating its main containers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'You can execute not one but several `initContainers` in the same Pod, but when
    you define lots of them, keep in mind that they will run one after another, not
    in parallel. Once an `initContainer` completes, the next one starts, and so on.
    In general, `initContainers` are used for preparation tasks; some of them are
    outlined in the following list:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Database initialization**: Set up and configure databases before the main
    application starts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configuration file download**: Download essential configuration files from
    remote locations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Package installation**: Install dependencies required by the main application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Waiting for external service**: Ensure external services are available before
    starting the main container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Running pre-checks**: Perform any necessary checks or validations before
    starting the main application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Secret management**: Download and inject secrets securely into the main container’s
    environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data migration**: Migrate data to a database or storage system before the
    main application starts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Customizing file permissions**: Set appropriate file permissions for the
    main application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Since `initContainers` can have their own container images. You can offload
    some configuration to them by keeping the main container images as small as possible,
    thus increasing the whole security of your setup by removing unnecessary tools
    from your main container images. Here is a YAML manifest that introduces an `initContainer`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: As you can see from this YAML file, `initContainer` runs the BusyBox image,
    which will download the application (in this case, simple website content from
    [https://github.com/iamgini/website-demo-one-page](https://github.com/iamgini/website-demo-one-page))
    and copy the same application to a shared volume called `website-volume`. (You
    will learn about volumes and persistent storage in *Chapter 9*, *Persistent Storage
    in Kubernetes*, later in this book.) The same volume is also configured to mount
    under the NGINX container so that NGINX will use it as the default website content.
    Once the execution of `initContainer` is complete, Kubernetes will create the
    `nginx-container` container.
  prefs: []
  type: TYPE_NORMAL
- en: Keep in mind that if `initContainer` fails, Kubernetes won’t initiate the primary
    containers. It’s crucial not to perceive `initContainer` as an optional component
    or one that can afford to fail. If included in the YAML manifest file, they are
    mandatory and their failure prevents the launch of the main containers!
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create the Pod. After this, we will run the `kubectl get Pods -w` command
    for `kubectl` to watch for a change in the Pod list. The output of the command
    will be updated regularly, showing the change in the Pod’s status. Please take
    note of the `status` column, which says that an `initContainer` is running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, `Init:0/1` indicates that `initContainer` is being launched.
    After its completion, the `Init:` prefix disappears for the next statuses, indicating
    that we are done with `initContainer` and that Kubernetes is now creating the
    main container – in our case, the NGINX one!
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to explore this further, you can expose the Pod with a NodePort
    service as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, start a port forwarding service using `kubectl port-forward` command as
    follows so that we can access the service outside of the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Now, access `http://localhost:8080` and you will see a one-page website with
    content copied from [https://github.com/iamgini/website-demo-one-page](https://github.com/iamgini/website-demo-one-page).
    We will learn about exposing services in *Chapter 8*, *Exposing Your Pods with
    Services*. Also remember to stop the port forward by pressing the *ctrl + c* to
    in your console before proceeding to the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Use `initContainer` wisely when you’re building your Pods! You are not forced
    to use `init` containers, but they can be really helpful for running configuration
    scripts or pulling something from external servers before you launch your actual
    containers!
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s learn how to access the logs of a specific container inside a running
    Pod!
  prefs: []
  type: TYPE_NORMAL
- en: Accessing the logs of a specific container
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When using multiple containers in a single Pod, you can retrieve the logs of
    a dedicated container inside the Pod. The proper way to proceed is by using the
    `kubectl logs` command.
  prefs: []
  type: TYPE_NORMAL
- en: The most common way a containerized application exposes its logs is by sending
    them to `stdout`. The `kubectl logs` command is capable of streaming the `stdout`
    property of a dedicated container in a dedicated Pod and retrieving the application
    logs from the container. For it to work, you will need to know the name of both
    the precise container and its parent Pod, just like when we used `kubectl exec`
    to access a specific container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Please read the previous section, *Accessing a specific container inside a
    multi-container Pod*, to discover how to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Please note the `--container` option (the `-c` short option works, too), which
    specifies the container you want to retrieve the logs for. Note that it also works
    the same for `initContainers`: you have to pass its name to this option to retrieve
    its logs.'
  prefs: []
  type: TYPE_NORMAL
- en: Remember that if you do not pass the `--container` option, you will retrieve
    all the logs from all the containers that have been launched inside the Pod. Not
    passing this option is useful in the case of a single-container Pod, but you should
    consider this option every time you use a multi-container Pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are other multiple useful options you need to be aware of when it comes
    to accessing the logs of a container in a Pod. You can decide to retrieve the
    logs written in the last two hours by using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Also, you can use the `--tail` option to retrieve the most recent lines of
    a log’s output. Here’s how to do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Here, we are retrieving the 30 most recent lines in the log output of `nginx-container`.
  prefs: []
  type: TYPE_NORMAL
- en: Now, you are ready to read and retrieve the logs from your Kubernetes Pods,
    regardless of whether they are made up of one or several containers!
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we discovered how to create, update, and delete multi-container
    Pods. We also discovered how to force the deletion of a Pod. We then discovered
    how to access a specific container in a Pod, as well as how to retrieve the logs
    of a specific container in a Pod. Though we created an NGINX and a Debian container
    in our Pod, they are relatively poorly linked since they don’t do anything together.
    To remediate that, we will now learn how to deal with volumes so that we can share
    files between our two containers.
  prefs: []
  type: TYPE_NORMAL
- en: Sharing volumes between containers in the same Pod
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we’ll learn what volumes are from a Kubernetes point of view
    and how to use them. Docker also has volumes, but they differ from Kubernetes
    volumes: they answer the same need but they are not the same.'
  prefs: []
  type: TYPE_NORMAL
- en: We will discover what Kubernetes volumes are, why they are useful, and how they
    can help us when it comes to Kubernetes volumes.
  prefs: []
  type: TYPE_NORMAL
- en: What are Kubernetes volumes?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are going to answer a simple problem. Our multi-container Pods are currently
    made up of two containers: an NGINX one and a Debian one. We are going to try
    sharing the log directory in the NGINX container with the Debian container by
    mounting the log directory of NGINX in the directory of the Debian container.
    This way, we will create a relationship between the two containers to have them
    share a directory.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes has two kinds of volumes:'
  prefs: []
  type: TYPE_NORMAL
- en: Volumes, which we will discuss here.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`PersistentVolume`, which is a more advanced feature we will discuss later,
    in*Chapter 9*, *Persistent Storage in Kubernetes*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keep in mind that these two are not the same. `PersistentVolume` is a resource
    of its own, whereas “volumes” is a Pod configuration. As the name suggests, `PersistentVolume`
    is persistent, whereas volumes are not supposed to be. But keep in mind that this
    is not always the case!
  prefs: []
  type: TYPE_NORMAL
- en: In straightforward terms, volumes in Kubernetes are intricately linked to the
    life cycle of a Pod. When you instantiate a Pod, you can define and connect volumes
    to the containers within it. Essentially, volumes represent storage tied to the
    existence of the Pod. Once the Pod is removed, any associated volumes are also
    deleted.
  prefs: []
  type: TYPE_NORMAL
- en: While volumes serve a broader range of purposes beyond this scenario, it’s worth
    noting that this description doesn’t universally apply. However, you can view
    volumes as an especially effective method for facilitating the sharing of directories
    and files among containers coexisting within a Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that volumes are bound to the Pod’s life cycle, not the container’s
    life cycle. If a container crashes, the volume will survive because if a container
    crashes, it won’t cause its parent Pod to crash, and thus, no volume will be deleted.
    So long as a Pod is alive, its volumes are, too.
  prefs: []
  type: TYPE_NORMAL
- en: Volumes are a core concept for managing data in containerized applications.
    They provide a way to persist data independent of the container’s life cycle.
    Kubernetes supports various volume types, including those mounted from the host
    file system, cloud providers, and network storage systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, Kubernetes expanded on this by introducing support for various drivers,
    enabling integration of Pod volumes with external solutions. For instance, an
    AWS EBS (Elastic Block Store) volume seamlessly serves as a Kubernetes volume.
    Some widely utilized solutions include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '`hostPath`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`emptyDir`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nfs`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`persistentVolumeClaim` (when you need to use a `PersistentVolume`, which is
    outside the scope of this chapter)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Please note that some of the old volume types are removed or deprecated in
    the latest Kubernetes version; refer to the documentation to learn more ([https://kubernetes.io/docs/concepts/storage/volumes/](https://kubernetes.io/docs/concepts/storage/volumes/)).
    Refer to the following list for examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '`azureDisk` (removed)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`gcePersistentDisk` (removed)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`glusterfs` (removed)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`azureFile` (deprecated)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Please note that using external solutions to manage the Kubernetes volumes will
    require you to follow those external solutions’ requirements. For example, using
    an AWS EBS volume as a Kubernetes volume will require your Pods to be executed
    on a Kubernetes worker node, which would be an EC2 instance. The reason for this
    is that AWS EBS volumes can only be attached to EC2 instances. Thus, a Pod exploiting
    such a volume would need to be launched on an EC2 instance. Refer to [https://kubernetes.io/docs/concepts/storage/volumes/](https://kubernetes.io/docs/concepts/storage/volumes/)
    to learn more.
  prefs: []
  type: TYPE_NORMAL
- en: The following diagram shows the high-level idea about the `hostPath` and `emptyDir`
    volumes.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22019_05_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.2: hostPath and emptyDir volumes'
  prefs: []
  type: TYPE_NORMAL
- en: 'We are going to discover the two basic volume drivers here: `emptyDir` and
    `hostPath`. We will also talk about `persistentVolumeClaim` because this one is
    going to be a little special in comparison to the other volumes and will be fully
    discovered in *Chapter 9*, *Persistent Storage in Kubernetes*.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s start discovering how to share files between containers in the same
    Pod using volumes with the `emptyDir` volume type!
  prefs: []
  type: TYPE_NORMAL
- en: Creating and mounting an emptyDir volume
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As the name suggests, it is simply an empty directory that is initialized at
    Pod creation that you can mount to the location of each container running in the
    Pod.
  prefs: []
  type: TYPE_NORMAL
- en: It is certainly the easiest and simplest way to have your containers share data
    between them. Let’s create a Pod that will manage two containers.
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, we are creating a Pod that will launch two containers,
    and just like we had previously, it’s going to be an NGINX container and a Debian
    container. We are going to override the command that’s run by the Debian container
    when it starts to prevent it from completing. That way, we will get it running
    indefinitely as a long process and we will be able to launch additional commands
    to check whether our `emptyDir` has been initialized correctly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Both containers will have a common volume mounted at `/var/i-am-empty-dir-volume/`,
    which will be our `emptyDir` volume, initialized in the same Pod. Here is the
    YAML file for creating the Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Note that the object we will create in our Kubernetes cluster will become more
    complex as we go through this example, and, as you can imagine, most complex things
    cannot be achieved with just imperative commands. That’s why you are going to
    see more and more examples relying on the YAML manifest file: you should start
    a habit of trying to read them to figure out what they do.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can now apply the manifest file using the following `kubectl apply -f` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, we can check that the Pod is successfully running by issuing the `kubectl
    get Pods` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: Now that we are sure the Pod is running and that both the NGINX and Debian containers
    have been launched, we can check that the directory can be accessed in both containers
    by issuing the `ls` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the command is not failing, as we saw previously, we can run the `ls` command
    in the containers by simply running the `kubectl exec` command. As you may recall,
    the command takes the Pod’s name and the container’s name as arguments. We are
    going to run it twice to make sure the volume is mounted in both containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the `ls /var` command is showing the name in both containers!
    This means that `emptyDir` was initialized and mounted in both containers correctly.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s create a file in one of the two containers. The file should be immediately
    visible in the other container, proving that the volume mount is working properly!
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following command, we are simply creating a `.txt` file called `hello-world.txt`
    in the mounted directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, we used `debian-container` to create the `/var/i-am-empty-dir-volume/hello-world.txt`
    file, which contains the `hello-world` string. Then, we simply used the `cat`
    command to access the file from both containers; you can see that the file is
    accessible in both cases. Again, remember that `emptyDir` volumes are completely
    tied to the life cycle of the Pod. If the Pod declares it is destroyed, then the
    volume is destroyed, too, along with all its content, and it will become impossible
    to recover!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we will discover another volume type: the `hostPath` volume. As you can
    imagine, it’s going to be a directory that you can mount on your containers that
    is backed by a path on the host machine – the Kubernetes node running the Pod!'
  prefs: []
  type: TYPE_NORMAL
- en: Creating and mounting a hostPath volume
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As the name suggests, hostPath will allow you to mount a directory in the host
    machine to containers in your Pod! The host machine is the Kubernetes compute
    node (or controller node) executing the Pod. Here are some examples:'
  prefs: []
  type: TYPE_NORMAL
- en: If your cluster is based on minikube (a single-node cluster), the host is your
    local machine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: On Amazon EKS, the host machine will be an EC2 instance.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In a `kubeadm` cluster, the host machine is generally a standard Linux machine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The host machine is the machine running the Pod, and you can mount a directory
    from the file system of the host machine to the Kubernetes Pod!
  prefs: []
  type: TYPE_NORMAL
- en: In the following example, we will be working on a Kubernetes cluster based on
    minikube, so `hostPath` will be a directory that’s been created on your computer
    that will then be mounted in a Kubernetes Pod.
  prefs: []
  type: TYPE_NORMAL
- en: Using the `hostPath` volume type can be useful, but in the Kubernetes world,
    you can consider it an anti-pattern. The `hostPath` volume type, while convenient,
    is discouraged in Kubernetes due to reduced portability and potential security
    risks. It can also be incompatible with advanced security features like SELinux
    **multi-category security** (**MCS**), now supported by many Kubernetes distributions.
    For a more portable, secure, and future-proof approach, leverage **persistent
    volumes** (**PVs**) and **persistent volume claims** (**PVCs**) to manage persistent
    data within your containerized applications.
  prefs: []
  type: TYPE_NORMAL
- en: The whole idea behind Pods is that they are supposed to be easy to delete and
    reschedule on another worker node without problems. Using `hostPath` will create
    a tight relationship between the Pod and the worker node, and that could lead
    to major issues if your Pod were to fail and be rescheduled on a node where the
    required path on the host machine is not present.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s discover how to create `hostPath`.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s imagine that we have a file on the worker node on `worker-node/nginx.conf`
    and we want to mount it on `/var/config/nginx.conf` on the `nginx` container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the YAML file to create the setup. As you can see, we declared a `hostPath`
    volume at the bottom of the file that defines a path that should be present on
    the host machine. Now, we can mount it on any container that needs to deal with
    the volume in the `containers` block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, mounting the value is just like what we did with the `emptyDir`
    volume in the previous section regarding the `emptyDir` volume type. By using
    a combination of volumes at the Pod level and `volumeMounts` at the container
    level, you can mount a volume on your containers.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: You can also mount the directory on the Debian container so that it gets access
    to the directory on the host.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before running the YAML manifest file, though, you need to create the path
    on your host and create the necessary file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'If you are using a minikube cluster, remember to do this step inside the minikube
    VM as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'If your minikube cluster is created using Podman containers (e.g., `minikube
    start --profile cluster2-podman --driver=podman`), then log in to the minikube
    Pod and create the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that the path exists on the host machine, we can apply the YAML file to
    our Kubernetes cluster and, immediately after, launch a `kubectl get Pod` command
    to check that the Pod was created correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Everything seems good! Now, let’s echo the file that should be mounted at `/foo/hello-world.txt`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: We can see the local file (on the Kubernetes node) is available inside the container
    via the hostPath volume mount.
  prefs: []
  type: TYPE_NORMAL
- en: At the beginning of this chapter, we discovered the different aspects of multi-container
    Pods! We discovered how to create, update, and delete multi-container Pods, as
    well as how to use `initContainers`, access logs, override command-line arguments
    passed to containers directly from the Pod’s resources, and share directories
    between containers using the two basic volumes.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are going to put a few architecting principles together and discover
    some notions related to multi-container Pods called “patterns.”
  prefs: []
  type: TYPE_NORMAL
- en: The ambassador design pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When designing a multi-container Pod, you can decide to follow some architectural
    principles to build your Pod. Some typical needs are answered by these design
    principles, and the ambassador pattern is one of them.
  prefs: []
  type: TYPE_NORMAL
- en: Here, we are going to discover what the ambassador design pattern is, learn
    how to build an ambassador container in Kubernetes Pods, and look at a concrete
    example of them.
  prefs: []
  type: TYPE_NORMAL
- en: What is the ambassador design pattern?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In essence, the ambassador design pattern applies to multi-container Pods.
    We can define two containers in the same Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: The first container will be called the main container.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The other container will be called the ambassador container.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this design pattern, we assume that the main container might have to access
    external services to communicate with them. For example, you can have an application
    that must interact with an SQL database that is living outside of your Pod, and
    you need to reach this database to retrieve data from it.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22019_05_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.3: Ambassador design pattern in Kubernetes'
  prefs: []
  type: TYPE_NORMAL
- en: This is the typical use case where you can deploy an adapter container alongside
    the main container, next to it, in the same Pod. The whole idea is to get the
    ambassador container to proxy the requests run by the main container to the database
    server.
  prefs: []
  type: TYPE_NORMAL
- en: In this case, the ambassador container will be essentially an SQL proxy. Every
    time the main container wants to access the database, it won’t access it directly
    but rather create a connection to the ambassador container that will play the
    role of a proxy.
  prefs: []
  type: TYPE_NORMAL
- en: Running an ambassador container is fine, but only if the external API is not
    living in the same Kubernetes cluster. To run requests on another Pod, Kubernetes
    provides strong mechanics called Services. We will have the opportunity to discover
    them in *Chapter 8*, *Exposing Your Pods with Services*.
  prefs: []
  type: TYPE_NORMAL
- en: 'But why would you need a proxy to access external databases? Here are some
    concrete benefits this design pattern can bring you:'
  prefs: []
  type: TYPE_NORMAL
- en: Offloading SQL configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Management of **Secure Sockets Layer**/**Transport Layer Security** (**SSL**/**TLS**)
    certificates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Please note that having an ambassador proxy is not limited to an SQL proxy but
    this example is demonstrative of what this design pattern can bring you. Note
    that the ambassador proxy is only supposed to be called for outbound connections
    from your main container to something else, such as data storage or an external
    API. It should not be seen as an entry point to your cluster! Now, let’s quickly
    discover how to create an ambassador SQL proxy with a YAML file.
  prefs: []
  type: TYPE_NORMAL
- en: Ambassador multi-container Pod – an example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now that we know about ambassador containers, let’s learn how to create one
    with Kubernetes. The following YAML manifest file creates a Pod that creates two
    containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '`nginx-app`, derived from the `nginx:latest` image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sql-ambassador-proxy`, created from the `mysql-proxy:latest` container image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following example is only to demonstrate the concept of the ambassador SQL
    proxy. If you want to test the full functionality, you should have a working AWS
    **RDS** (**Relational Database Service**) instance reachable from your Kubernetes
    cluster and a proper application to test the database operations.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: As you can imagine, it’s going to be the developer’s job to get the application
    code running in the NGINX container to query the ambassador instead of the Amazon
    RDS endpoint. As the ambassador container can be configured from environment variables,
    it’s going to be easy for you to just input the configuration variables in `ambassador-container`.
  prefs: []
  type: TYPE_NORMAL
- en: Do not get tricked by the order of the containers in the YAML file. The fact
    that the ambassador container appears first does not make it the *main* container
    of the Pod. This notion of the *main* container does not exist at all from a Kubernetes
    perspective – both are plain containers that run in parallel with no concept of
    a hierarchy between them. Here, we just access the Pod from the NGINX container,
    which makes it the most important one.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the ambassador running in the same Pod as the NGINX container
    makes it accessible from NGINX on `localhost:3306.`
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn about the sidecar pattern, another important
    concept in multi-container Pods.
  prefs: []
  type: TYPE_NORMAL
- en: The sidecar design pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The sidecar design pattern is good when you want to extend the features of your
    main container with features it would normally not be able to achieve on its own.
  prefs: []
  type: TYPE_NORMAL
- en: Just like we did for the ambassador container, we’re going to explain exactly
    what the sidecar design pattern is by covering some examples.
  prefs: []
  type: TYPE_NORMAL
- en: What is the sidecar design pattern?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Think of the sidecar container as an extension or a helper for your main container.
    Its main purpose is to extend the main container to bring it a new feature, but
    without changing anything about it. Unlike the ambassador design pattern, the
    main container may even not be aware of the presence of a sidecar.
  prefs: []
  type: TYPE_NORMAL
- en: 'Just like the ambassador design pattern, the sidecar design pattern makes use
    of a minimum of two containers:'
  prefs: []
  type: TYPE_NORMAL
- en: The main container – the one that is running the application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The sidecar container – the one that is bringing something additional to the
    first one
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may have already guessed, but this pattern is especially useful when you
    want to run monitoring or log forwarder agents. The following figure shows a simple
    sidecar design with a main app container and a sidecar container to collect the
    application logs.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22019_05_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.4: Sidecar design pattern in Kubernetes'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three things to understand when you want to build a sidecar that
    is going to forward your logs to another location:'
  prefs: []
  type: TYPE_NORMAL
- en: You must locate the directory where your main containers write their data (e.g.,
    logs).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You must create a volume to make this directory accessible to the sidecar container
    (e.g., a log forwarder sidecar).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You must launch the sidecar container with the proper configuration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on these concepts, the main container remains unchanged, and even if the
    sidecar fails, it wouldn’t have an impact on the main container, which could continue
    to work.
  prefs: []
  type: TYPE_NORMAL
- en: When to use a Sidecar design pattern?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When considering the usage of sidecar containers, they prove particularly beneficial
    in the following scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Network proxies**: Network proxies can be configured to initialize before
    other containers in the Pod, ensuring their services are available immediately.
    The Istio “Envoy” proxy is a great example of a sidecar container used as a proxy.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhanced logging**: Log collection sidecars can start early and persist until
    the Pod terminates, capturing logs reliably even in case of Pod crashes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Jobs**: Sidecars can be deployed alongside Kubernetes Jobs without affecting
    Job completion. No additional configuration is required for sidecars to run within
    Jobs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Credential management**: Many third-party credential management platforms
    utilize sidecar Pods to inject and manage credentials within workloads. They can
    also facilitate secure credential rotation and revocation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sidecar multi-container Pod – an example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Just like the ambassador design pattern, the sidecar makes use of multi-container
    Pods. We will define two containers in the same Pod as follows – an NGINX container,
    which acts as the application container, and a `Fluentd container`, which acts
    as the sidecar to collect the logs from the NGINX web server:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Please note, for the Fluentd to work properly, we need to pass the configuration
    via ConfigMap; a typical configuration can be found in the following code (you
    will learn more about ConfigMaps in *Chapter 7*, *Configuring your Pods using
    ConfigMaps and Secrets):*
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '**Fluentd** is a popular open-source log collection and forwarding agent, often
    used as a sidecar container in Kubernetes deployments. It efficiently collects
    logs from various sources, parses them for structure, and forwards them to centralized
    logging platforms like Elasticsearch, Google Cloud Logging, or Amazon CloudWatch
    Logs. This allows for streamlined log management, improved observability, and
    easier analysis of application health and performance. While this example demonstrates
    sending logs to a dummy Elasticsearch server (e.g., `elastic.lab.example.com`),
    Fluentd offers flexibility to integrate with various external logging solutions
    depending on your specific needs.'
  prefs: []
  type: TYPE_NORMAL
- en: In the following section of this chapter, we will discuss the adapter design
    pattern.
  prefs: []
  type: TYPE_NORMAL
- en: The adapter design pattern
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As its name suggests, the adapter design pattern is going to *adapt* an entry
    from a source format to a target format.
  prefs: []
  type: TYPE_NORMAL
- en: 'As with the ambassador and sidecar design patterns, this one expects that you
    run at least two containers:'
  prefs: []
  type: TYPE_NORMAL
- en: The first one is the main container.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second one is the adapter container.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This design pattern is helpful and should be used whenever the main containers
    emit data in a format, A, that should be sent to another application that is expecting
    the data in another format, B. As the name suggests, the adapter container is
    here to *adapt*.
  prefs: []
  type: TYPE_NORMAL
- en: Again, this design pattern is especially well suited for log or monitoring management.
    Imagine a Kubernetes cluster where you have dozens of applications running; they
    are writing logs in Apache format, which you need to convert into JSON so that
    they can be indexed by a search engine. This is exactly where the adapter design
    pattern comes into play. Running an adapter container next to the application
    containers will help you get these logs adapted to the source format before they
    are sent somewhere else.
  prefs: []
  type: TYPE_NORMAL
- en: Just like for the sidecar design pattern, this one can only work if both the
    containers in your Pod are accessing the same directory using volumes.
  prefs: []
  type: TYPE_NORMAL
- en: Adapter multi-container Pod – an example
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this example, we are going to use a Pod that uses an adapter container with
    a shared directory mounted as a Kubernetes volume.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22019_05_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.5: Adapter design pattern in Kubernetes'
  prefs: []
  type: TYPE_NORMAL
- en: 'This Pod is going to run two containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '`alpine-writer`: Main app container, which writes logs to `/var/log/app`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`log-adapter`: Adapter container, which will read the log and convert it to
    another format (e.g., append a `PROCESSED` string at the end of each log).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following YAML file contains the definition for an adapter multi-container
    Pod with multiple containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Apply the YAML and check the Pod status as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the Pod is created, the logs will be generated, and we can verify the
    logs from both containers. The following command will display the logs by the
    `alpine-writer` container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also check the converted logs by using `log-adapter`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: By using the adapter containers, it is possible to handle complex operations
    without modifying your original application containers.
  prefs: []
  type: TYPE_NORMAL
- en: Before we conclude the chapter, in the next section, let us learn about one
    more feature in Kubernetes related to multi-container Pods.
  prefs: []
  type: TYPE_NORMAL
- en: Sidecars versus Kubernetes Native Sidecars
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditionally, sidecars in Kubernetes have been regular containers deployed
    alongside the main application in a Pod, as we learned in the previous sections.
    This approach offers additional functionalities but has limitations. For instance,
    sidecars might continue running even after the main application exits, wasting
    resources. Additionally, Kubernetes itself isn’t inherently aware of sidecars
    and their relationship with the primary application.
  prefs: []
  type: TYPE_NORMAL
- en: 'To address these limitations, Kubernetes v1.28 introduced a new concept: native
    sidecars. These leverage existing `init` containers with special configurations.
    This allows you to define a `restartPolicy` for containers within the Pod’s `initContainers`
    section. These special sidecar containers can be independently started, stopped,
    or restarted without affecting the main application or other init containers,
    offering more granular control over their life cycle.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following Deployment definition file explains how native sidecar containers
    can be configured in Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: This approach ensures synchronized startup and shutdown of the sidecar with
    the main container, optimizing resource usage. More importantly, Kubernetes gains
    awareness of the sidecar’s role in the Pod, potentially enabling future features
    for tighter integration.
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging multi-container Pods with init containers, sidecars, and the adapter
    or ambassador patterns, Kubernetes empowers you to build complex applications
    as modular units. This streamlines deployments and promotes efficient resource
    utilization within your containerized environment.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter was quite a long one, but you should now have a good understanding
    of what Pods are and how to use them, especially when it comes to managing multiple
    containers in the same Pod.
  prefs: []
  type: TYPE_NORMAL
- en: We recommend that you focus on mastering the declarative way of creating Kubernetes
    resources. As you have noticed in this chapter, the key to achieving the most
    complex things with Kubernetes resides in writing YAML files. One example is that
    you simply cannot easily create a multi-container Pod without writing YAML files.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter complements the previous one: *Chapter 4*, *Running Your Containers
    in Kubernetes*. You need to understand that everything we will do with Kubernetes
    will be Pod management because everything in Kubernetes revolves around them.
    Keep in mind that containers are never created directly, but always through a
    Pod object, and that all the containers within the same Pod are created on the
    same Kubernetes node. If you understand that, then you can continue to the next
    chapter!'
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we’re going to cover another important aspect of Kubernetes
    called namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'How Pods manage multiple containers: https://kubernetes.io/docs/concepts/workloads/pods/#how-pods-manage-multiple-containers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kubernetes volumes: [https://kubernetes.io/docs/concepts/storage/volumes/](https://kubernetes.io/docs/concepts/storage/volumes/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sidecar containers: [https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/](https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code1190011064790816561.png)'
  prefs: []
  type: TYPE_IMG
