<html><head></head><body>
		<div id="_idContainer013">
			<h1 id="_idParaDest-16" class="chapter-number"><a id="_idTextAnchor015"/>1</h1>
			<h1 id="_idParaDest-17"><a id="_idTextAnchor016"/>From Cloud to Cloud Native  and Kubernetes</h1>
			<p>In this chapter, you’ll see how computing has evolved over the past 20 or so years, what the <strong class="bold">cloud</strong> is and how it appeared, and how IT landscapes have changed with the introduction of containers. You’ll learn about fundamentals such as <strong class="bold">Infrastructure-as-a-Service</strong> (<strong class="bold">IaaS</strong>), <strong class="bold">Platform-as-a-Service</strong> (<strong class="bold">PaaS</strong>), <strong class="bold">Software-as-a-Service</strong> (<strong class="bold">SaaS</strong>), and <strong class="bold">Function-as-a-Service</strong> (<strong class="bold">FaaS</strong>), as well as learning about the transition from monolithic to microservice architectures and getting a first glimpse <span class="No-Break">at Kubernetes.</span></p>
			<p>This chapter does not map directly to a specific KCNA exam objective, but these topics are crucial for anyone who’d like to tie their career to modern infrastructures. If you are already familiar with the basic terms, feel free to quickly verify your knowledge by going directly to the recap questions. If not, don’t be surprised that things are not covered in great detail, as this is an introductory chapter, and we’ll dive deeper into all of the topics in later chapters. </p>
			<p>We’re going to cover the following topics in this chapter:  </p>
			<ul>
				<li>The cloud and <strong class="bold">Before Cloud</strong> (<strong class="bold">B.C.</strong>) </li>
				<li>Evolution of the cloud <span class="No-Break">and cloud-native</span></li>
				<li>Containers and <span class="No-Break">container orchestration</span></li>
				<li>Monolithic versus <span class="No-Break">microservices applications</span></li>
				<li>Kubernetes and <span class="No-Break">its origins</span></li>
			</ul>
			<p>Let’s <span class="No-Break">get started!</span></p>
			<h1 id="_idParaDest-18"><a id="_idTextAnchor017"/>The cloud and Before Cloud (B.C.)</h1>
			<p>The cloud has<a id="_idIndexMarker000"/> triggered a major revolution and accelerated innovation, but before we learn about the cloud, let’s see how things were done before the era of <span class="No-Break">the cloud.</span></p>
			<p>In the times before the term <em class="italic">cloud computing</em> was used, one physical server would only be able to run a single <strong class="bold">operating system</strong> (<strong class="bold">OS</strong>) at a time. These systems would typically host a single application, meaning <span class="No-Break">two things:</span></p>
			<ul>
				<li>If an application was not used, the computing resources of the server where it ran <span class="No-Break">were wasted</span></li>
				<li>If an application was used very actively and needed a larger server or more servers, it would take days or even weeks to get new hardware procured, delivered, cabled, <span class="No-Break">and installed</span></li>
			</ul>
			<p>Moving on, let’s have a look at an important aspect of computing – <span class="No-Break">virtualization.</span></p>
			<h2 id="_idParaDest-19"><a id="_idTextAnchor018"/>Virtualization</h2>
			<p>Virtualization<a id="_idIndexMarker001"/> technology and <strong class="bold">virtual machines</strong> (<strong class="bold">VMs</strong>) first<a id="_idIndexMarker002"/> appeared back in the 1960s, but it was not until the early 2000s that virtualization technologies such <a id="_idIndexMarker003"/>as XEN and <strong class="bold">Kernel-based Virtual Machines</strong> (<strong class="bold">KVMs</strong>) started to <span class="No-Break">become mainstream.</span></p>
			<p>Virtualization would allow us to run multiple VMs on a single physical server using hypervisors, where a hypervisor is a software that acts as an emulator of the hardware resources, such as the CPU and RAM. Effectively, it allows you to share the processor time and memory of the underlying physical server by slicing it between <span class="No-Break">multiple VMs.</span></p>
			<p>It means that each VM will be very similar to the physical server, but with a virtual CPU, memory, disks, and network cards instead of physical ones. Each VM will also have an OS on which you can install applications. The following figure demonstrates a virtualized deployment with two VMs running on the same <span class="No-Break">physical server:</span></p>
			<div>
				<div id="_idContainer008" class="IMG---Figure">
					<img src="image/B18970_01_01.jpg" alt="Figure 1.1 – Comparison of traditional and virtualized deployments"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – Comparison of traditional and virtualized deployments</p>
			<p>This concept of sharing hardware resources between the<a id="_idIndexMarker004"/> so-called <em class="italic">guest VMs</em> is what made it possible to utilize hardware more effectively and reduce any waste of computing resources. It means we might not need to purchase a whole new server in order to run <span class="No-Break">another application.</span></p>
			<p>The obvious <a id="_idIndexMarker005"/>benefits that came along with virtualization are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Less physical <span class="No-Break">hardware required</span></li>
				<li>Fewer data center <span class="No-Break">personnel required</span></li>
				<li>Lower acquisition and <span class="No-Break">maintenance costs</span></li>
				<li>Lower <span class="No-Break">power consumption</span></li>
			</ul>
			<p>Besides, provisioning a new VM would take minutes and not days or weeks of waiting for new hardware. However, to scale beyond the capacities of the hardware already installed in the corporate data center, we would still need to order, configure, and cable new physical servers and network equipment – and that has all changed with the introduction of <span class="No-Break">cloud computing.</span></p>
			<h2 id="_idParaDest-20"><a id="_idTextAnchor019"/>The cloud</h2>
			<p>At a very <a id="_idIndexMarker006"/>basic level, the cloud is virtualization on demand. It allows us to spawn VMs accessible over the network as a service, when requested by <span class="No-Break">the customers.</span></p>
			<p class="callout-heading">Cloud computing</p>
			<p class="callout">This is the delivery of computational resources as a service, where the actual hardware is owned and managed by the cloud provider rather than a corporate <span class="No-Break">IT department.</span></p>
			<p>The cloud has ignited a major revolution in computing. It became unnecessary to buy and manage your own hardware anymore to build and run applications and VMs. The cloud provider takes full care of hardware procurement, installation, and maintenance and ensures the efficient utilization of resources by serving hundreds and thousands of customers on shared hardware securely. Each customer will only pay for the resources they use. Today, it is common to distinguish the following three <span class="No-Break">cloud types:</span></p>
			<ul>
				<li><strong class="bold">Public</strong> – The <a id="_idIndexMarker007"/>most popular<a id="_idIndexMarker008"/> type. A public cloud is operated by a third-party company and available for use by any paying customer. Public clouds are typically used by thousands of organizations at the same time. Examples <a id="_idIndexMarker009"/>of<a id="_idIndexMarker010"/> public cloud <a id="_idIndexMarker011"/>providers include <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>), <strong class="bold">Microsoft Azure</strong>, and <strong class="bold">Google Cloud </strong><span class="No-Break"><strong class="bold">Platform</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">GCP</strong></span><span class="No-Break">).</span></li>
				<li><strong class="bold">Private</strong> – Used<a id="_idIndexMarker012"/> by one typically large organization or an enterprise. The<a id="_idIndexMarker013"/> operations and maintenance might be done by the organization itself or a private cloud provider. Examples include Rackspace Private Cloud and VMware <span class="No-Break">Private Cloud.</span></li>
				<li><strong class="bold">Hybrid</strong> – This<a id="_idIndexMarker014"/> is the combination of a public and private cloud, in a <a id="_idIndexMarker015"/>case where an organization has a private cloud but uses some of the services from a public cloud at the <span class="No-Break">same time.</span></li>
			</ul>
			<p>However, the cloud is not just VMs reachable over the network. There are tens and hundreds of services offered by cloud providers. Today, you can request and use network-attached storage, virtual network devices, firewalls, load balancers, VMs with GPUs or specialized hardware, managed databases, and more <span class="No-Break">almost immediately.</span></p>
			<p>Now, let’s see in more detail how cloud services can be delivered <span class="No-Break">and consumed.</span></p>
			<h1 id="_idParaDest-21"><a id="_idTextAnchor020"/>Evolution of the cloud and cloud-native</h1>
			<p>Besides the<a id="_idIndexMarker016"/> huge variety of cloud services you can find today, there is also a difference in how the services are offered. It is common to distinguish between four cloud service delivery models that help meet <span class="No-Break">different needs:</span></p>
			<ul>
				<li><strong class="bold">IaaS</strong> – The <a id="_idIndexMarker017"/>most flexible model with the basic <a id="_idIndexMarker018"/>services provided: VMs, virtual routers, block devices, load balancers, and so on. This model also assumes the most customer responsibility. Users of IaaS have access to their VMs and must configure their OS, install updates, and set up, manage, and secure their applications. AWS <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>), AWS <strong class="bold">Elastic Block Store</strong> (<strong class="bold">EBS</strong>), and Google Compute Engine VMs are all examples <span class="No-Break">of IaaS.</span></li>
				<li><strong class="bold">PaaS</strong> – This <a id="_idIndexMarker019"/>helps to focus on the development <a id="_idIndexMarker020"/>and management of applications by taking away the need to install OS upgrades or do any lower-level maintenance. As a PaaS customer, you are still responsible for your data, identity and access, and your application life cycle. Examples include Heroku and Google <span class="No-Break">App Engine.</span></li>
				<li><strong class="bold">SaaS</strong> – Takes<a id="_idIndexMarker021"/> the responsibilities even further <a id="_idIndexMarker022"/>away from the customers. Typically, these are fully managed applications that <em class="italic">just work</em>, such as Slack <span class="No-Break">or Gmail.</span></li>
				<li><strong class="bold">FaaS</strong> – A <a id="_idIndexMarker023"/>newer delivery model that appeared <a id="_idIndexMarker024"/>around 2010. It is also known as <strong class="bold">Serverless</strong> today. A <a id="_idIndexMarker025"/>FaaS customer is responsible for defining the functions that are triggered by the events. Functions can be written in one of the popular programming languages and customers don’t have to worry about server or OS management, deployment, or scaling. Examples of FaaS include AWS Lambda, Google Cloud Functions, and Microsoft <span class="No-Break">Azure Functions.</span></li>
			</ul>
			<p>These models might sound a bit complicated, so let’s draw a simple analogy with cars <span class="No-Break">and transportation.</span></p>
			<p><em class="italic">On-premises, traditional data centers</em> are like having your own car. You are buying it, and you are responsible for its insurance and maintenance, the replacement of broken parts, passing regular inspections, and <span class="No-Break">so on.</span></p>
			<p><em class="italic">IaaS</em> is <a id="_idIndexMarker026"/>more like leasing a car for some period of time. You pay monthly lease payments, you drive it, you fill it with gas, and you wash it, but you don’t actually own the car and you can give it back when you don’t need <span class="No-Break">it anymore.</span></p>
			<p><em class="italic">PaaS</em> can<a id="_idIndexMarker027"/> be compared with car-sharing. You don’t own the car, you don’t need to wash it, do any maintenance, or even refill it most of the time, but you still drive <span class="No-Break">it yourself.</span></p>
			<p>Following the analogy, <em class="italic">SaaS</em> is like <a id="_idIndexMarker028"/>calling a taxi. You don’t need to own the car or even <span class="No-Break">drive it.</span></p>
			<p>Finally, <em class="italic">Serverless</em> or <em class="italic">FaaS</em> can<a id="_idIndexMarker029"/> be compared to a bus from a user perspective. You just hop on and ride to your destination – no maintenance, no driving, and <span class="No-Break">no ownership.</span></p>
			<p>Hopefully, this makes things clearer. The big difference between traditional on-premises setups where a company is solely responsible for the organization, hardware maintenance, data security, and more is that a so-called shared responsibility model applies in <span class="No-Break">the cloud.</span></p>
			<p class="callout-heading">Shared responsibility model</p>
			<p class="callout">Defines <a id="_idIndexMarker030"/>the obligations of the cloud provider and the cloud customer. These responsibilities depend on the service provided – in the case of an IaaS service, the customer has more responsibility compared to PaaS or SaaS. For example, the cloud provider is always responsible for preventing unauthorized access to data center facilities and the stability of the power supply and underlying <span class="No-Break">network connectivity.</span></p>
			<p>The following figure visually demonstrates the difference between <span class="No-Break">the responsibilities:</span></p>
			<div>
				<div id="_idContainer009" class="IMG---Figure">
					<img src="image/B18970_01_02.jpg" alt="Figure 1.2 – Comparison of cloud delivery models"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – Comparison of cloud delivery models</p>
			<p>As cloud<a id="_idIndexMarker031"/> technologies and providers evolved over the past 20 years, so did the architectures of the applications that run on the cloud; a new term has emerged – <strong class="bold">cloud-native</strong>. Most of the time, it refers to the architectural approach, but<a id="_idIndexMarker032"/> you will often encounter cloud-native applications or cloud-native software <span class="No-Break">as well.</span></p>
			<p class="callout-heading">Cloud-native</p>
			<p class="callout">Is an approach to building and running applications on modern, dynamic infrastructures such as clouds. It is emphasizing application workloads with high resiliency, scalability, high degree of automation, ease of management, <span class="No-Break">and observability.</span></p>
			<p>Despite the presence of the word <em class="italic">cloud</em>, it does not mean that a cloud-native application must run strictly in a public, private, or hybrid cloud. You can develop a cloud-native application and run it on-premises with Kubernetes as <span class="No-Break">an example.</span></p>
			<p>Cloud-native should not be confused <a id="_idIndexMarker033"/>with <strong class="bold">Cloud Service Providers</strong> (<strong class="bold">CSPs</strong>), or simply cloud providers, and cloud-native is also not the same as cloud-first, so remember <span class="No-Break">the following:</span></p>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><strong class="bold">Cloud-native ≠ CSP ≠ cloud-first</strong></p>
			<p>For the sake of completeness, let’s define the <span class="No-Break">other two.</span></p>
			<p>A CSP is a third-party company offering cloud computing services such as IaaS, PaaS, SaaS, or FaaS. Cloud-first simply stands for a strategy where the cloud is the default choice for either optimizing existing IT infrastructure or for launching <span class="No-Break">new applications.</span></p>
			<p>Don’t worry if those definitions do not make total sense just yet – we will dedicate a whole section to cloud-native that explains all its aspects in detail. For now, let’s have a quick introduction to containers and <span class="No-Break">their orchestration.</span></p>
			<h1 id="_idParaDest-22"><a id="_idTextAnchor021"/>Containers and container orchestration</h1>
			<p>At a very high level, containers are another form of lightweight virtualization, also known<a id="_idIndexMarker034"/> as <strong class="bold">OS-level virtualization</strong>. However, containers<a id="_idIndexMarker035"/> are different from VMs with their own advantages <span class="No-Break">and disadvantages.</span></p>
			<p>The major difference is that with VMs, we can slice and share one physical server between many VMs, each running their own OS. With containers, we can slice and share an OS kernel between multiple containers and each container will have its own virtual OS. Let’s see this in <span class="No-Break">more detail.</span></p>
			<p class="callout-heading">Containers</p>
			<p class="callout">These are portable units of software that include application code with runtimes, dependencies, and system libraries. Containers share one OS kernel, but each container can have its own isolated OS environment with different packages, system libraries, tools, its own storage, networking, users, processes, <span class="No-Break">and groups.</span></p>
			<p><em class="italic">Portable</em> is important and needs to be elaborated. An application packaged into a container image is guaranteed to run on another host because the container includes its own isolated environment. Starting a container on another host does not interfere with its environment or the <span class="No-Break">application containerized.</span></p>
			<p>A major advantage is also that containers are a lot more lightweight and efficient compared to VMs. They <a id="_idIndexMarker036"/>consume less resources (the CPU and RAM) than VMs and start almost instantly because they don’t need to bootstrap a complete OS with a kernel. For example, if a physical server is capable of running 10 VMs, then the same physical server might be able to run 30, 40, or possibly even more containers, each with its own application (the exact number depends on many factors, including the type of workload, so those values are for demonstration purposes only and do not represent <span class="No-Break">any formula).</span></p>
			<p>Containers are also much smaller than VMs in disk size, because they don’t package a full OS with thousands of libraries. Only applications with dependencies and a minimal set of OS packages are included in container images. That makes container images small, portable, and easy to download or share. </p>
			<p class="callout-heading">Container images</p>
			<p class="callout">These are <a id="_idIndexMarker037"/>essentially templates of container OS environments that we can use to create multiple containers with the same application and environment. Every time we execute an image, a container <span class="No-Break">is created.</span></p>
			<p>Speaking in numbers, a container image of a popular Linux distribution such as <em class="italic">Ubuntu Server 20.04</em> weighs about 70 MB, whereas a KVM QCOW2 virtual machine image of the same Ubuntu Server will weigh roughly 500 MB. Specialized Linux container images such as <em class="italic">Alpine</em> can be as small as 5 to 10 MB and provide the bare minimum functionality to install and <span class="No-Break">run applications.</span></p>
			<p>Containers are also agnostic to where they run – whether on physical servers, on-premises VMs, or the cloud, containers can run in any of these locations with the help of <span class="No-Break">container runtimes.</span></p>
			<p class="callout-heading">Container runtimes</p>
			<p class="callout">A container runtime<a id="_idIndexMarker038"/> is a special software needed to run containers on a host OS. It is responsible for creating, starting, stopping, and deleting containers based on the container images it downloads. Examples of container runtimes include containerd, CRI-O, and <span class="No-Break">Docker Engine.</span></p>
			<p><span class="No-Break"><em class="italic">Figure 1</em></span><em class="italic">.3</em> demonstrates the differences between virtualized and <span class="No-Break">containerized deployments:</span></p>
			<div>
				<div id="_idContainer010" class="IMG---Figure">
					<img src="image/B18970_01_03.jpg" alt="Figure 1.3 – Comparison of virtualized and container deployments"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – Comparison of virtualized and container deployments</p>
			<p>Now, a <a id="_idIndexMarker039"/>question you might be asking yourself is if containers are so great, why would anyone use VMs and why do cloud providers still offer so many <span class="No-Break">VM types?</span></p>
			<p>Here is the scenario where VMs have an advantage over containers: they provide better security due to stronger isolation because they don’t directly share the same host kernel. That means if an application running in a container has been breached by a hacker, the chances that they can get to all the other containers on the same host are much higher than compared to <span class="No-Break">regular VMs.</span></p>
			<p>We will dive deeper into the technology behind OS-level virtualization and explore the low-level differences between VMs and containers in <span class="No-Break">later chapters.</span></p>
			<p>As containers gained momentum and received wider adoption over the years, it quickly became apparent that managing containers on a large scale can be quite a challenge. The industry needed tools to orchestrate and manage the life cycle of <span class="No-Break">container-based applications.</span></p>
			<p>This had to do with the increasing number of containers that companies and teams had to operate because as the infrastructure tools evolved, so did the application architectures too, transforming from large monolithic architectures into small, distributed, and loosely <span class="No-Break">coupled microservices.</span></p>
			<h1 id="_idParaDest-23"><a id="_idTextAnchor022"/>Monolithic versus microservices applications</h1>
			<p>To<a id="_idIndexMarker040"/> understand the difference between monolithic and microservice-based applications, let us reflect on a real-world example. Imagine that a company runs an online hotel booking business. All reservations are made and paid for by the customers via a corporate <span class="No-Break">web service.</span></p>
			<p>The traditional monolithic architecture for this kind of web application would have bundled all the functionality into one single, complex software that might have included <span class="No-Break">the following:</span></p>
			<ul>
				<li><span class="No-Break">Customer dashboard</span></li>
				<li>Customer identity and <span class="No-Break">access management</span></li>
				<li>Search engine for hotels based <span class="No-Break">on criteria</span></li>
				<li>Billing and integration with <span class="No-Break">payment providers</span></li>
				<li>Reservation system <span class="No-Break">for hotels</span></li>
				<li>Ticketing and <span class="No-Break">support chat</span></li>
			</ul>
			<p>A monolithic application will be tightly coupled (bundled) with all the business and user logic and must be developed and updated at once. That means if a change to a billing code has to be made, the entire application will have to be updated with the changes. After that, it should be carefully tested and released to the production environment. Each (even a small) change could potentially break the whole application and impact business by making it unavailable for a <span class="No-Break">longer time.</span></p>
			<p>With a microservices architecture, this very same application could be split into several smaller pieces communicating with each other over the network and fulfilling its own purpose. Billing, for example, can be performed by four <span class="No-Break">smaller services:</span></p>
			<ul>
				<li><span class="No-Break">Currency converter</span></li>
				<li>Credit card <span class="No-Break">provider integration</span></li>
				<li>Bank wire <span class="No-Break">transfer processing</span></li>
				<li><span class="No-Break">Refund processing</span></li>
			</ul>
			<p>Essentially, microservices are a group of small applications where each is responsible for its own small task. These small applications communicate with each other over the network and work together as a part of a <span class="No-Break">larger application.</span></p>
			<p>The<a id="_idIndexMarker041"/> following figure demonstrates the differences between monolithic and <span class="No-Break">microservice architectures:</span></p>
			<div>
				<div id="_idContainer011" class="IMG---Figure">
					<img src="image/B18970_01_04.jpg" alt="Figure 1.4 – Comparison of monolithic and microservice architectures"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4 – Comparison of monolithic and microservice architectures</p>
			<p>This way, all other parts of the web application can also be split into multiple smaller independent applications (microservices) communicating over the network. The advantages of this approach include <span class="No-Break">the following:</span></p>
			<ul>
				<li>Each microservice can be developed by its <span class="No-Break">own team</span></li>
				<li>Each microservice can be released and <span class="No-Break">updated separately</span></li>
				<li>Each microservice can be deployed and scaled independently <span class="No-Break">of others</span></li>
				<li>A single microservice outage will only impact a small part of the overall functionality of <span class="No-Break">the app</span></li>
			</ul>
			<p>Microservices are an important part of cloud-native architectures, and we will review in detail the benefits as well as the challenges associated with microservices in <a href="B18970_09.xhtml#_idTextAnchor095"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>, <em class="italic">Understanding Cloud Native Architectures</em>. For the moment, let’s get back to containers and why they need to <span class="No-Break">be orchestrated.</span></p>
			<p>When<a id="_idIndexMarker042"/> each microservice is packaged into a container, the total number of containers can easily reach tens or even hundreds for especially large and complex applications. In such a complex distributed environment, things can quickly get out of <span class="No-Break">our control.</span></p>
			<p>A container orchestration system is<a id="_idIndexMarker043"/> what helps us to keep control over a large number of containers. It simplifies the management of containers by grouping application containers into deployments and automating operations such as <span class="No-Break">the following:</span></p>
			<ul>
				<li>Scaling microservices depending on <span class="No-Break">the workload</span></li>
				<li>Releasing new versions of microservices and <span class="No-Break">their updates</span></li>
				<li>Scheduling containers based on host utilizations <span class="No-Break">and requirements</span></li>
				<li>Automatically restarting containers that fail or failing over <span class="No-Break">the traffic</span></li>
			</ul>
			<p>As of today, there are many container and workload orchestration systems available, <span class="No-Break">including these:</span></p>
			<ul>
				<li><span class="No-Break">Kubernetes</span></li>
				<li>OpenShift (also known as <strong class="bold">Open Kubernetes </strong><span class="No-Break"><strong class="bold">Distribution</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="bold">OKD</strong></span><span class="No-Break">))</span></li>
				<li><span class="No-Break">Hashicorp Nomad</span></li>
				<li><span class="No-Break">Docker Swarm</span></li>
				<li><span class="No-Break">Apache Mesos</span></li>
			</ul>
			<p>As you already know from the book title, we will only focus on Kubernetes and there won’t be any sort of comparison made between these five. In fact, Kubernetes has overwhelmingly higher market shares and over the years, has become the de facto platform for orchestrating containers. With a high degree of confidence, you can concentrate on learning about Kubernetes and forget about the others, at least for <span class="No-Break">the moment.</span></p>
			<h1 id="_idParaDest-24"><a id="_idTextAnchor023"/>Kubernetes and its origins</h1>
			<p>Let’s start with a<a id="_idIndexMarker044"/> brief history first. The name Kubernetes originates from Greek and means <em class="italic">pilot</em> or <em class="italic">helmsman</em> – a person steering a ship (that is why there is a steering wheel in the logo). The steering wheel has seven bars and the number seven has a special meaning for <a id="_idIndexMarker045"/>Kubernetes. The team originally working on Kubernetes called it <em class="italic">Project Seven</em> – named after seven of nine characters from the well-known TV series,<em class="italic"> </em><span class="No-Break"><em class="italic">Star Trek</em></span><span class="No-Break">.</span></p>
			<div>
				<div id="_idContainer012" class="IMG---Figure">
					<img src="image/B18970_01_05.jpg" alt="Figure 1.5 – The Kubernetes logo"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.5 – The Kubernetes logo</p>
			<p>Kubernetes was initially developed by Google and released as an open source project in 2014. Google has been a pioneer, having run its services in containers already for more than a decade by that time, and the release of Kubernetes triggered another small revolution in the industry. By that time, many businesses had realized the benefits of using containers and were in need of a solution that would simplify container orchestration at scale. Kubernetes turned out to be this solution, as we will <span class="No-Break">see soon.</span></p>
			<p class="callout-heading">Kubernetes (K8s)</p>
			<p class="callout">Kubernetes is an open source platform for container orchestration. Kubernetes features an extensible and declarative API that allows you to automatically reach the desired state of resources. It allows flexible scheduling, autoscaling, rolling update, and self-healing of <span class="No-Break">container-based payloads.</span></p>
			<p>(Online and in documentation, a shorter abbreviation, K8s, can often be encountered – where eight is the number of letters between “K” <span class="No-Break">and “s”.)</span></p>
			<p>Kubernetes has inherited many of its features and best ideas from Borg – an internal container cluster management system <a id="_idIndexMarker046"/>powering thousands of different applications at Google. Many Borg engineers participated in the development of Kubernetes and were able to address relevant pain points based on their experience of operating a huge fleet of containers over <span class="No-Break">the years.</span></p>
			<p>Soon after its initial release, Kubernetes rapidly gained the attention of the open source community and attracted many talented contributors from all over the world. Today, Kubernetes is among the top three biggest open source projects on GitHub (<a href="https://github.com/kubernetes">https://github.com/kubernetes</a>) with more than 80,000 stars and 3,000 contributors. It was also the first project to graduate<a id="_idIndexMarker047"/> from the <strong class="bold">Cloud Native Computing Foundation</strong> (<strong class="bold">CNCF</strong>), a non-profit organization that split off from the Linux Foundation created with the goal of advancing container and <span class="No-Break">cloud-native technologies.</span></p>
			<p>One of the most important features of Kubernetes is the concept of the desired state. Kubernetes operates in a way where we define the state of the application containers we want to have, and Kubernetes will automatically ensure the state is reached. Kubernetes constantly observes the state of all deployed containers and makes sure this state matches what we’ve requested. </p>
			<p>Let’s consider the following example. Imagine that we run a simple microservice-based application on Kubernetes cluster with three hosts. We define a specification that requires Kubernetes to <span class="No-Break">run these:</span></p>
			<ul>
				<li>Two identical containers for <span class="No-Break">the frontend</span></li>
				<li>Three identical containers for <span class="No-Break">the backend</span></li>
				<li>Two containers with volumes serving the <span class="No-Break">data persistence</span></li>
			</ul>
			<p>Unexpectedly, one of the three hosts fails, and two containers running on the frontend and backend become unavailable. Kubernetes observes the changed number of hosts in the cluster and reduced number of containers responsible for the frontend and the backend. Kubernetes automatically starts one frontend and one backend container on the other two operational hosts to bring the system back to its desired state. This process is known<a id="_idIndexMarker048"/> <span class="No-Break">as </span><span class="No-Break"><strong class="bold">self-healing</strong></span><span class="No-Break">.</span></p>
			<p>Kubernetes can do way more than scheduling and restarting failed containers – we can also define a Kubernetes specification that requires the number of microservice containers to automatically increase based on the current demand. For example, in the preceding example, we can specify that with an increased workload, we want to run five replicas of the frontend and five replicas of the backend. Alternatively, in case of low application demand, we can automatically decrease the number of each microservice containers to two. This process is known <a id="_idIndexMarker049"/><span class="No-Break">as </span><span class="No-Break"><strong class="bold">autoscaling</strong></span><span class="No-Break">.</span></p>
			<p>This example demonstrates the basic capabilities of Kubernetes. In <em class="italic">Part 3</em>, we will explore more Kubernetes features and try some of them firsthand. </p>
			<p class="callout-heading">Important note </p>
			<p class="callout">While being a container orchestrator, Kubernetes does not have its own container runtime. Instead, it has integration with popular container runtimes such as <em class="italic">containerd</em> and can work with multiple runtimes within a Kubernetes cluster. </p>
			<p>You often see references to<a id="_idIndexMarker050"/> Kubernetes clusters because a typical Kubernetes installation will be used to manage hundreds of containers spread across multiple hosts. Single-host Kubernetes installations are only suitable for learning or local development, but not for <span class="No-Break">production usage.</span></p>
			<p>To sum up, Kubernetes has laid down the path for massive container adoption and is a thriving open source ecosystem that is still growing with new projects graduating from the CNCF every year. In this book, we will cover the Kubernetes API, components, resources, features, and operational aspects in depth, and learn more about projects that can be used with Kubernetes to extend <span class="No-Break">its functionality.</span></p>
			<h1 id="_idParaDest-25"><a id="_idTextAnchor024"/>Summary</h1>
			<p>In this chapter, we learned about the concepts of the cloud and containers, and the evolution of computing over the last 20 to 30 years. In the era before the cloud, traditional deployments with one or a few applications per physical server caused a lot of inefficiency and wasted resources with underutilized hardware and high costs <span class="No-Break">of ownership.</span></p>
			<p>When virtualization technologies came along, it became possible to run many applications per physical server using VMs. This addressed the pitfalls of traditional deployments and allowed us to deliver new applications more quickly and with significantly <span class="No-Break">lower costs.</span></p>
			<p>Virtualization paved the way for the cloud services that are delivered via four different models today: IaaS, PaaS, SaaS, and FaaS or Serverless. Customer responsibilities differ by cloud service and <span class="No-Break">delivery model.</span></p>
			<p>This progress never stopped – now, cloud-native as an approach to building and running applications has emerged. Cloud-native applications are designed and built with an emphasis on scalability, resilience, ease of management, and a high degree of automation. </p>
			<p>Over recent years, container technology has developed and gained momentum. Containers use virtualization at the OS level and each container represents a virtual OS environment. Containers are faster, more efficient, and more portable compared <span class="No-Break">to VMs.</span></p>
			<p>Containers enabled us to develop and manage modern applications based on a microservices architecture. Microservices were a step ahead compared to traditional monoliths – <em class="italic">all-in-one, </em><span class="No-Break"><em class="italic">behemoth</em></span><span class="No-Break"> applications.</span></p>
			<p>While containers are one of the most efficient ways to run cloud-native applications, it becomes hard to manage large numbers of containers. Therefore, containers are best managed using an orchestrator such <span class="No-Break">as Kubernetes.</span></p>
			<p>Kubernetes is an open source container orchestration system that originated from Google and automates many operational aspects of containers. Kubernetes will schedule, start, stop, and restart containers and increase or decrease the number of containers based on the provided specification automatically. Kubernetes makes it possible to implement self-healing and autoscaling based on the <span class="No-Break">current demand.</span></p>
			<h1 id="_idParaDest-26"><a id="_idTextAnchor025"/>Questions</h1>
			<p>At the end of each chapter, you’ll find recap questions that allow to test your understanding. Questions might have multiple correct answers. Correct answers can be found in the <em class="italic">Assessment</em> section of <span class="No-Break">the </span><span class="No-Break"><em class="italic">Appendix</em></span><span class="No-Break">:</span></p>
			<ol>
				<li>Which of the following describes traditional deployments on physical servers (<span class="No-Break">pick two)?</span><ol><li><span class="No-Break">Easy maintenance</span></li><li><span class="No-Break">Underutilized hardware</span></li><li>Low <span class="No-Break">energy consumption</span></li><li>High <span class="No-Break">upfront costs</span></li></ol></li>
				<li>Which advantages do VMs have compared <span class="No-Break">to containers?</span><ol><li>They are <span class="No-Break">more reliable</span></li><li>They are <span class="No-Break">more portable</span></li><li>They are <span class="No-Break">more secure</span></li><li>They are <span class="No-Break">more lightweight</span></li></ol></li>
				<li>What describes the difference between VMs and containers (<span class="No-Break">pick two)?</span><ol><li>VM images are small and container images <span class="No-Break">are large</span></li><li>VM images are large and container images <span class="No-Break">are small</span></li><li>VMs share the OS kernel and <span class="No-Break">containers don’t</span></li><li>Containers share the OS kernel and <span class="No-Break">VMs don’t</span></li></ol></li>
				<li>At which level do <span class="No-Break">containers operate?</span><ol><li>The <span class="No-Break">orchestrator level</span></li><li>The <span class="No-Break">hypervisor level</span></li><li>The programming <span class="No-Break">language level</span></li><li>The <span class="No-Break">OS level</span></li></ol></li>
				<li>What is typically included in a container image (<span class="No-Break">pick two)?</span><ol><li>An <span class="No-Break">OS kernel</span></li><li>A minimal set of OS libraries <span class="No-Break">and packages</span></li><li>A graphical <span class="No-Break">desktop environment</span></li><li>A <span class="No-Break">packaged microservice</span></li></ol></li>
				<li>Which advantages do containers have compared to VMs (<span class="No-Break">pick multiple)?</span><ol><li>They are <span class="No-Break">more secure</span></li><li>They are <span class="No-Break">more lightweight</span></li><li>They are <span class="No-Break">more portable</span></li><li>They are faster <span class="No-Break">to start</span></li></ol></li>
				<li>Which software is needed to start and <span class="No-Break">run containers?</span><ol><li>A <span class="No-Break">container runtime</span></li><li><span class="No-Break">A hypervisor</span></li><li><span class="No-Break">Kubernetes</span></li><li><span class="No-Break">VirtualBox</span></li></ol></li>
				<li>Which of the following can be used to <span class="No-Break">orchestrate containers?</span><ol><li><span class="No-Break">containerd</span></li><li><span class="No-Break">CRI-O</span></li><li><span class="No-Break">Kubernetes</span></li><li><span class="No-Break">Serverless</span></li></ol></li>
				<li>Which of the following is a cloud service delivery model (<span class="No-Break">pick multiple)?</span><ol><li><span class="No-Break">IaaS, PaaS</span></li><li><span class="No-Break">SaaS, FaaS</span></li><li><span class="No-Break">DBaaS</span></li><li><span class="No-Break">Serverless</span></li></ol></li>
				<li>Which of the following statements about cloud-native <span class="No-Break">is true?</span><ol><li>It is an <span class="No-Break">architectural approach</span></li><li>It is the same as a <span class="No-Break">cloud provider</span></li><li>It is similar <span class="No-Break">to cloud-first</span></li><li>It is software that only runs in <span class="No-Break">the cloud</span></li></ol></li>
				<li>Which of the following descriptors applies to cloud-native applications (<span class="No-Break">pick two)?</span><ol><li>High degree <span class="No-Break">of automation</span></li><li>High scalability <span class="No-Break">and resiliency</span></li><li>Can only run in a <span class="No-Break">private cloud</span></li><li>Can only run in a <span class="No-Break">public cloud</span></li></ol></li>
				<li>Which of the following statements is true about <span class="No-Break">monolithic applications?</span><ol><li>They are easy <span class="No-Break">to update</span></li><li>Their components communicate with each other over <span class="No-Break">the network</span></li><li>They include all the business logic <span class="No-Break">and interfaces</span></li><li>They can be <span class="No-Break">scaled easily</span></li></ol></li>
				<li>Which of the following statements is true for microservices (<span class="No-Break">pick multiple)?</span><ol><li>They can only be used for <span class="No-Break">the backend</span></li><li>They work together as a part of a <span class="No-Break">bigger application</span></li><li>They can be developed by <span class="No-Break">multiple teams</span></li><li>They can be <span class="No-Break">deployed independently</span></li></ol></li>
				<li>Which of the following can be done with Kubernetes (<span class="No-Break">pick multiple)?</span><ol><li>Self-healing in case <span class="No-Break">of failure</span></li><li><span class="No-Break">Autoscaling containers</span></li><li><span class="No-Break">Spawning VMs</span></li><li>Scheduling containers on <span class="No-Break">different hosts</span></li></ol></li>
				<li>Which project served as an inspiration <span class="No-Break">for Kubernetes?</span><ol><li><span class="No-Break">OpenStack</span></li><li><span class="No-Break">Docker</span></li><li><span class="No-Break">Borg</span></li><li><span class="No-Break">OpenShift</span></li></ol></li>
			</ol>
		</div>
	</body></html>