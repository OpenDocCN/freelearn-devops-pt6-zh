<html><head></head><body>
		<div>
			<div id="_idContainer452" class="Content">
			</div>
		</div>
		<div id="_idContainer453" class="Content">
			<h1 id="_idParaDest-159">14. <a id="_idTextAnchor164"/>Serverless functions</h1>
		</div>
		<div id="_idContainer489" class="Content">
			<p>Serverless computing and serverless functions have gained tremendous traction over the past few years due to scalability and reduced management overhead. Cloud services such as Azure Functions, AWS Lambda, and GCP Cloud Run have made it very easy for users to run their code as serverless functions.</p>
			<p>The word <strong class="bold">serverless</strong> refers to any solution where you don't need to manage servers. Serverless functions refer to a subset of serverless computing where you can run your code as a function on-demand. This means that your code in the function will only run and be executed when there is a demand. This architectural style is called event-driven architecture. In an event-driven architecture, the event consumers are triggered when there is an event. In the case of serverless functions, the event consumers will be these serverless functions. An event can be anything from a message in a queue to a new object uploaded to storage, or even an HTTP call.</p>
			<p>Serverless functions are frequently used for backend processing. A common example of serverless functions is creating thumbnails of a picture that is uploaded to storage, as shown in <em class="italics">Figure 14.1</em>. Since you cannot predict how many pictures will be uploaded and when they will be uploaded, it is hard to plan traditional infrastructure and how many servers you should have available for this process. If you implement the creation of that thumbnail as a serverless function, this function will be called on each picture that is uploaded. You don't have to plan the number of functions since each new picture will trigger a new function to be executed.</p>
			<div>
				<div id="_idContainer454" class="IMG---Figure">
					<img src="image/B17338_14_01.jpg" alt="Example architecture of a serverless function to generate thumbnails of images"/>
				</div>
			</div>
			<p class="figure">Figure 14.1: Example architecture of a serverless function to generate thumbnails of images</p>
			<p>As you saw in the previous example, functions will automatically scale to meet increased or decreased demand. Additionally, each function can scale independently from other functions. However, this automatic scaling is just one benefit of using serverless functions. Another benefit of serverless functions is the ease of development. Using serverless functions, you can focus on writing the code and don't have to deal with the underlying infrastructure. Serverless functions allow code to be deployed without worrying about managing servers and middleware. Finally, in public cloud serverless functions, you pay per execution of the function. This means that you pay each time your functions are run, and you are charged nothing for the idle time when your functions are not run.</p>
			<p>The popularity of public cloud serverless function platforms has caused multiple open-source frameworks to be created to enable users to create serverless functions on top of Kubernetes. In this chapter, you will learn how to deploy serverless functions on <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>) directly using the open-source version of Azure Functions. You will start by running a simple function that is triggered based on an HTTP message. Afterward, you will install a function <strong class="bold">autoscaler</strong> feature on your cluster. You will also integrate AKS-deployed applications with Azure storage queues. We will be covering the following topics:</p>
			<ul>
				<li>Overview of different functions platforms</li>
				<li>Deploying an HTTP-triggered function</li>
				<li>Deploying a queue-triggered function</li>
			</ul>
			<p>Let's start this chapter by exploring the various functions platforms that are available for Kubernetes.</p>
			<h2 id="_idParaDest-160"><a id="_idTextAnchor165"/>Various functions platforms</h2>
			<p>Functions platforms, such as Azure Functions, AWS Lambda, and Google Cloud Functions, have gained tremendous popularity. The ability to run code without the need to manage servers and having virtually limitless scale is very popular. The downside of using the functions implementation of a cloud provider is that you are locked into the cloud provider's infrastructure and their programming model. Also, you can only run your functions in the public cloud and not in your own datacenter.</p>
			<p>A number of open-source functions frameworks have been launched to solve these downsides. There are a number of popular frameworks that can be run on Kubernetes:</p>
			<ul>
				<li><strong class="bold">Knative</strong> (<a href="">https://cloud.google.com/knative/</a>): Knative is a serverless platform written in the Go language and developed by Google. You can run Knative functions either fully managed on Google Cloud or on your own Kubernetes cluster.</li>
				<li><strong class="bold">OpenFaaS</strong> (<a href="">https://www.openfaas.com/</a>): OpenFaaS is a serverless framework that is Kubernetes-native. It can run on either managed Kubernetes environments such as AKS or on a self-hosted cluster. OpenFaaS is also available as a managed cloud service using <strong class="inline">OpenFaaSCloud</strong>. The platform is written in the Go language.</li>
				<li><strong class="bold">Serverless</strong> (<a href="">https://serverless.com/</a>): This is a Node.js-based serverless application framework that can deploy and manage functions on multiple cloud providers, including Azure. Kubernetes support is provided via <strong class="inline">Kubeless</strong>.</li>
				<li><strong class="bold">Fission.io</strong> (<a href="">https://fission.io/</a>): Fission is a serverless framework backed by the company Platform9. It is written in the Go language and is Kubernetes-native. It can run on any Kubernetes cluster.</li>
				<li><strong class="bold">Apache OpenWhisk</strong> (<a href="">https://openwhisk.apache.org/</a>): OpenWhisk is an open-source, distributed serverless platform maintained by the Apache organization. It can be run on Kubernetes, Mesos, or Docker Compose. It is primarily written in the Scala language.</li>
			</ul>
			<p>Microsoft has taken an interesting strategy with its functions platform. Microsoft operates Azure Functions as a managed service on Azure and has open-sourced the complete solution and made it available to run on any system (<a href="">https://github.com/Azure/azure-functions-host</a>). This also makes the Azure Functions programming model available on top of Kubernetes.</p>
			<p>Microsoft has also released an additional open-source project in partnership with Red Hat called <strong class="bold">Kubernetes Event-driven Autoscaling</strong> (<strong class="bold">KEDA</strong>) to make scaling functions on top of Kubernetes easier. KEDA is a custom autoscaler that can allow deployments on Kubernetes to scale down to and up from zero pods, which is not possible using the default <strong class="bold">Horizontal Pod Autoscaler</strong> (<strong class="bold">HPA</strong>) in Kubernetes. The ability to scale from zero to one pod is important so that your application can start processing events, but scaling down to zero instances is useful for preserving resources in your cluster. KEDA also makes additional metrics available to the Kubernetes HPA to make scaling decisions based on metrics from outside the cluster (for example, the number of messages in a queue).</p>
			<h4>Note</h4>
			<p class="callout">We introduced and explained the HPA in <em class="italics">Chapter 4</em>, <em class="italics">Building scalable applications</em>.</p>
			<p>In this chapter, you will deploy Azure Functions to Kubernetes with two examples:</p>
			<ul>
				<li>An HTTP-triggered function (without KEDA)</li>
				<li>A queue-triggered function (with KEDA)</li>
			</ul>
			<p>Before starting with these functions, the next section will consider the necessary prerequisites for these deployments.</p>
			<h2 id="_idParaDest-161"><a id="_idTextAnchor166"/>Setting up the prerequisites</h2>
			<p>In this section, you will set up the prerequisites needed to build and run functions on your Kubernetes cluster. You need to set up an <strong class="bold">Azure container registry</strong> (<strong class="bold">ACR</strong>) and a <strong class="bold">virtual machine</strong> (<strong class="bold">VM</strong>) in Azure that will be used to develop the functions. The ACR will be used to store custom container images that contain the functions you will develop. You will also use a VM to build the functions and create Docker images, since you cannot do this from Azure Cloud Shell.</p>
			<p>Container images and a container registry were introduced in <em class="italics">Chapter 1</em>, <em class="italics">Introduction to containers and Kubernetes</em>, in the section on <em class="italics">Container images</em>. A container image contains all the software required to start an actual running container. In this chapter, you will build custom container images that contain your functions. You need a place to store these images so that Kubernetes can pull them and run the containers at scale. You will use ACR for this. ACR is a private container registry that is fully managed by Azure.</p>
			<p>Up to now in this book, you have run all the examples on Azure Cloud Shell. For the example in this chapter, you will need a separate VM because Azure Cloud Shell doesn't allow you to build container images. You will create a new VM in Azure to do these tasks.</p>
			<p>Let's begin by creating an ACR.</p>
			<h3 id="_idParaDest-162"><a id="_idTextAnchor167"/>Azure Container Registry</h3>
			<p>Azure Functions on Kubernetes needs an image registry to store its container images. In this section, you will create an ACR and configure your Kubernetes cluster to have access to this cluster:</p>
			<ol>
				<li>In the Azure search bar, search for <strong class="inline">container registry</strong> and click on <span class="P---Screen-Text">Container registries</span>, as shown in <em class="italics">Figure 14.2</em>:<div id="_idContainer455" class="IMG---Figure"><img src="image/B17338_14_02.jpg" alt="Navigating to Container registries through the Azure portal"/></div><p class="figure">Figure 14.2: Navigating to Container registry services through the Azure portal</p></li>
				<li>Click the <span class="P---Screen-Text">Add</span> button at the top to create a new registry. To organize the resources in this chapter together, create a new resource group. To do this, click on <span class="P---Screen-Text">Create new</span> under the <span class="P---Screen-Text">Resource group</span> field to create a new resource group, and call it <strong class="inline">Functions-KEDA</strong>, as shown in <em class="italics">Figure 14.3</em>:<div id="_idContainer456" class="IMG---Figure"><img src="image/B17338_14_03.jpg" alt="Creating a new resource group to create the registry"/></div><p class="figure">Figure 14.3: Creating a new resource group</p><p>Provide the details to create the registry. The registry name needs to be globally unique, so consider adding your initials to the registry name. It is recommended to create the registry in the same location as your cluster. To reduce spending for the demo, you can change <span class="P---Screen-Text">SKU</span> to <span class="P---Screen-Text">Basic</span>. Select the <span class="P---Screen-Text">Review + create</span> button at the bottom to create the registry, as shown in <em class="italics">Figure 14.4</em>:</p><div id="_idContainer457" class="IMG---Figure"><img src="image/B17338_14_04.jpg" alt="Review the details provided and hit Review + create to create the registry"/></div><p class="figure">Figure 14.4: Providing details to create the registry</p><p>In the resulting pane, click the <span class="P---Screen-Text">Create</span> button to create the registry.</p></li>
				<li>Once your registry is created, open Cloud Shell so that you can configure your AKS cluster to get access to your container registry. Use the following command to give AKS permissions to your registry:<p class="snippet">az aks update -n handsonaks \</p><p class="snippet">-g rg-handsonaks --attach-acr &lt;acrName&gt;</p><p>This will return an output similar to <em class="italics">Figure 14.5</em>. The figure has been cropped to show only the top part of the output:</p></li>
			</ol>
			<div>
				<div id="_idContainer458" class="IMG---Figure">
					<img src="image/B17338_14_05.jpg" alt="Giving AKS permissions on your registry"/>
				</div>
			</div>
			<p class="figure">Figure 14.5: Allowing AKS cluster to access the container registry</p>
			<p>You now have an ACR that is integrated with AKS. In the next section, you will create a VM that will be used to build the Azure functions.</p>
			<h3 id="_idParaDest-163"><a id="_idTextAnchor168"/>Creating a VM</h3>
			<p>In this section, you will create a VM and install the tools necessary to run Azure Functions on this machine:</p>
			<ul>
				<li>The Docker runtime</li>
				<li>The Azure CLI</li>
				<li>Azure Functions</li>
				<li>Kubectl<h4>Note</h4><p class="callout">To ensure a consistent experience, you will be creating a VM on Azure that will be used for development. If you prefer to run the sample on your local machine, you can install all the required tools locally.</p></li>
			</ul>
			<p>Let's get started with creating the VM:</p>
			<ol>
				<li value="1">To ensure this example works with the Azure trial subscription, you will need to scale down your cluster to one node. You can do this using the following command:<p class="snippet">az aks scale -n handsonaks -g rg-handsonaks --node-count 1</p></li>
				<li>To authenticate to the VM you are going to create, you'll need a set of SSH keys. If you followed the example in <em class="italics">Chapter 9</em>, <em class="italics">Azure Active Directory pod-managed identities in AKS</em> in the <em class="italics">Setting up a new cluster with AAD pod-managed identity</em> section, you will already have a set of SSH keys. To verify that you have SSH keys, run the following command:<p class="snippet">ls ~/.ssh</p><p>This should show you the presence of an SSH private key (<strong class="inline">id_rsa</strong>) and a public key (<strong class="inline">id_rsa.pub</strong>), as shown in <em class="italics">Figure 14.6</em>:</p><div id="_idContainer459" class="IMG---Figure"><img src="image/B17338_14_06.jpg" alt="Verifying the SSH keys that are present"/></div><p class="figure">Figure 14.6: Verifying SSH keys are present</p><p>If you do not have these keys already available, you will need to generate a set of SSH keys using the following command:</p><p class="snippet">ssh-keygen</p><p>You will be prompted for a location and a passphrase. Keep the default location and input an empty passphrase.</p></li>
				<li>You will now create the VM. You will create an Ubuntu VM using the following command:<p class="snippet">az vm create -g Functions-KEDA -n devMachine \</p><p class="snippet">  --image UbuntuLTS --ssh-key-value ~/.ssh/id_rsa.pub \</p><p class="snippet">  --admin-username handsonaks --size Standard_D1_v2</p></li>
				<li>This will take a couple of minutes to complete. Once the VM is created, Cloud Shell should show you its public IP, as displayed in <em class="italics">Figure 14.7</em>:<div id="_idContainer460" class="IMG---Figure"><img src="image/B17338_14_07.jpg" alt="Running the az vm create command and getting the public ip of the VM from the command"/></div><p class="figure">Figure 14.7: Creating the development VM</p><p>Connect to the VM using the following command:</p><p class="snippet">ssh handsonaks@&lt;public IP&gt;</p><p>You will be prompted about whether you trust the machine's identity. Type <strong class="inline">yes</strong> to confirm.</p></li>
				<li>You're now connected to a new VM on Azure. On this machine, we will begin by installing Docker:<p class="snippet">sudo apt-get update</p><p class="snippet">sudo apt-get install docker.io -y</p><p class="snippet">sudo systemctl enable docker</p><p class="snippet">sudo systemctl start docker</p></li>
				<li>To make the operation smoother, add the user to the Docker group. This will ensure you can run Docker commands without <strong class="inline">sudo</strong>:<p class="snippet">sudo usermod -aG docker handsonaks</p><p class="snippet">newgrp docker</p><p>You should now be able to run the <strong class="inline">hello-world</strong> command:</p><p class="snippet">docker run hello-world</p><p>This will show you an output similar to <em class="italics">Figure 14.8</em>:</p><div id="_idContainer461" class="IMG---Figure"><img src="image/B17338_14_08.jpg" alt="Verifying that Docker runs on the virtual machine"/></div><p class="figure">Figure 14.8: Verifying Docker runs on the VM</p></li>
				<li>Next, you will install the Azure CLI on this VM. You can install the CLI using the following command:<p class="snippet">curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash</p></li>
				<li>Verify that the CLI was installed successfully by signing in:<p class="snippet">az login</p><p>This will display a login code that you need to enter at <a href="">https://microsoft.com/devicelogin</a>:</p><div id="_idContainer462" class="IMG---Figure"><img src="image/B17338_14_09.jpg" alt="Logging in to the Azure CLI"/></div><p class="figure">Figure 14.9: Signing in to the Azure CLI</p><p>Browse to that website and paste in the login code that was provided to you to enable you to sign in to Cloud Shell. Make sure to do this in a browser you are signed in to with the user who has access to your Azure subscription.</p><p>You can now use the CLI to authenticate your machine to ACR. This can be done using the following command:</p><p class="snippet">az acr login -n &lt;registryname&gt;</p><p>The credentials to ACR expire after 3 hours. If you run into the following error during this demonstration, you can sign in to ACR again using the following command:</p><div id="_idContainer463" class="IMG---Figure"><img src="image/B17338_14_10.jpg" alt="Potential error that you might get while authenticating your machine to ACR"/></div><p class="figure">Figure 14.10: Potential authentication error in the future</p></li>
				<li>Next, you'll install <strong class="inline">kubectl</strong> on your machine. The Azure CLI has a shortcut to install the CLI, which you can use to install it:<p class="snippet">sudo az aks install-cli</p><p>Let's verify that <strong class="inline">kubectl</strong> can connect to our cluster. For this, we'll first get the credentials and then execute a <strong class="inline">kubectl</strong> command:</p><p class="snippet">az aks get-credentials -n handsonaks -g rg-handsonaks</p><p class="snippet">kubectl get nodes</p></li>
				<li>Now, you can install the Azure Functions tools on this machine. To do this, run the following commands:<p class="snippet">wget -q https://packages.microsoft.com/config/ubuntu/18.04/packages-microsoft-prod.deb</p><p class="snippet">sudo dpkg -i packages-microsoft-prod.deb</p><p class="snippet">sudo apt-get update</p><p class="snippet">sudo apt-get install azure-functions-core-tools-3 -y</p><p>This will return an output similar to <em class="italics">Figure 14.11</em>:</p></li>
			</ol>
			<div>
				<div id="_idContainer464" class="IMG---Figure">
					<img src="image/B17338_14_11.jpg" alt="Installing Azure Functions Core Tools"/>
				</div>
			</div>
			<p class="figure">Figure 14.11: Installing Functions core tools</p>
			<h4>Note</h4>
			<p class="callout">If you are running a newer version of Ubuntu than 18.04, please make sure that you download the correct <strong class="inline">dpkg</strong> package by changing the URL in the first line to reflect your Ubuntu version.</p>
			<p>You now have the prerequisites to start working with functions on Kubernetes. You created an ACR to store custom container images, and you have a VM that will be used to create and build Azure functions. In the next section, you will build your first function, which is HTTP-triggered.</p>
			<h2 id="_idParaDest-164"><a id="_idTextAnchor169"/>Creating an HTTP-triggered Azure function</h2>
			<p>In this first example, you will create an HTTP-triggered Azure function. This means that you can browse to the page hosting the actual function:</p>
			<ol>
				<li value="1">To begin, create a new directory and navigate to that directory:<p class="snippet">mkdir http</p><p class="snippet">cd http</p></li>
				<li>Now, you will initialize a function using the following command:<p class="snippet">func init --docker</p><p>The <strong class="inline">––docker</strong> parameter specifies that you will build the function as a Docker container. This will result in a Dockerfile being created. Select the Python language, which is option <span class="P---Screen-Text">3</span> in the following screenshot:</p><div id="_idContainer465" class="IMG---Figure"><img src="image/B17338_14_12.jpg" alt="Creating a Python function"/></div><p class="figure">Figure 14.12: Creating a Python function</p><p>This will create the required files for your function to work.</p></li>
				<li>Next, you will create the actual function. Enter the following command:<p class="snippet">func new</p><p>This should result in an output like the following. Select the eighth option, <span class="P---Screen-Text">HTTP trigger</span>, and name the function <strong class="inline">python-http</strong>:</p><div id="_idContainer466" class="IMG---Figure"><img src="image/B17338_14_13.jpg" alt="Creating an HTTP-triggered function using the required option"/></div><p class="figure">Figure 14.13: Creating an HTTP-triggered function</p></li>
				<li>The code of the function is stored in the directory called <strong class="inline">python-http</strong>. You are not going to make code changes to this function. If you want to check out the source code of the function, you can run the following command:<p class="snippet">cat python-http/__init__.py</p></li>
				<li>You will need to make one change to the function's configuration file. By default, functions require an authenticated request. You will change this to <strong class="inline">anonymous</strong> for this demo. Make the change using the <strong class="inline">vi</strong> command by executing the following command:<p class="snippet">vi python-http/function.json</p><p>Replace <strong class="inline">authLevel</strong> on <em class="italics">line 5</em> with <strong class="inline">anonymous</strong>. To make that change, press <em class="italics">I</em> to go into insert mode, then remove <strong class="inline">function</strong> and replace it with <strong class="inline">anonymous</strong>:</p><div id="_idContainer467" class="IMG---Figure"><img src="image/B17338_14_14.jpg" alt="Modifying the configuration file by changing the authLevelfunction to anonymous"/></div><p class="figure">Figure 14.14: Changing the authLevel function to anonymous</p><p>Hit <em class="italics">Esc</em>, type <strong class="inline">:wq!</strong>, and then hit <em class="italics">Enter</em> to save and quit <strong class="inline">vi</strong>.</p><h4>Note</h4><p class="callout">You changed the authentication requirement for your function to <strong class="inline">anonymous</strong>. This will make the demo easier to execute. If you plan to release functions to production, you need to carefully consider this setting, since this controls who has access to your function.</p></li>
				<li>You are now ready to deploy your function to AKS. You can deploy the function using the following command:<p class="snippet">func kubernetes deploy --name python-http \</p><p class="snippet">--registry &lt;registry name&gt;.azurecr.io</p><p>This will cause the functions runtime to do a couple of steps. First, it will build a container image, then it will push that image to the registry, and finally, it will deploy the function to Kubernetes:</p><div id="_idContainer468" class="IMG---Figure"><img src="image/B17338_14_15.jpg" alt="Using the func kubernetes deploy command for deploying the function to AKS"/></div><p class="figure">Figure 14.15: Deploying the function to AKS</p><p>You can click the <span class="P---Screen-Text">Invoke url</span> URL that is shown to get access to your function. Before doing so, however, let's explore what was created on the cluster.</p></li>
				<li>To create the function, a regular deployment on top of Kubernetes was used. To check the deployment, you can run the following command:<p class="snippet">kubectl get deployment</p><p>This will show you the deployment, as in <em class="italics">Figure 14.16</em>:</p><div id="_idContainer469" class="IMG---Figure"><img src="image/B17338_14_16.jpg" alt="Checking the deployment"/></div><p class="figure">Figure 14.16: Deployment details</p></li>
				<li>This process also created a service on top of your Kubernetes cluster. You can get the public IP of the service that was deployed and connect to it:<p class="snippet">kubectl get service</p><p>This will show you the service and its public IP, as shown in <em class="italics">Figure 14.17</em>. Notice how this public IP is the same as the one shown in the output of <em class="italics">Step 4</em>.</p></li>
			</ol>
			<div>
				<div id="_idContainer470" class="IMG---Figure">
					<img src="image/B17338_14_17.jpg" alt="Getting the service’s public IP"/>
				</div>
			</div>
			<p class="figure">Figure 14.17: Getting the service's public IP</p>
			<p>Open a web browser and browse to <strong class="inline">http://&lt;external-ip&gt;/api/python-http?name=handsonaks</strong>. You should see a web page showing you <span class="P---Screen-Text">Hello, handsonaks. This HTTP triggered function executed successfully</span>. This is shown in <em class="italics">Figure 14.18</em>:</p>
			<div>
				<div id="_idContainer471" class="IMG---Figure">
					<img src="image/B17338_14_18.jpg" alt="Navigating to the external IP will return the HTTP function output"/>
				</div>
			</div>
			<p class="figure">Figure 14.18: Output of the HTTP triggered function</p>
			<p>You have now created a function with an HTTP trigger. Using an HTTP-triggered function is useful in scenarios where you are providing an HTTP API with unpredictable load patterns. Let's clean up this deployment before moving on to the next section:</p>
			<p class="snippet">kubectl delete deployment python-http-http</p>
			<p class="snippet">kubectl delete service python-http-http</p>
			<p class="snippet">kubectl delete secret python-http</p>
			<p>In this section, you created a sample function using an HTTP trigger. Let's take that one step further and integrate a new function with storage queues and set up the KEDA autoscaler in the next section.</p>
			<h2 id="_idParaDest-165"><a id="_idTextAnchor170"/>Creating a queue-triggered function</h2>
			<p>In the previous section, you created a sample HTTP function. In this section, you'll build another sample using a queue-triggered function. Queues are often used to pass messages between different components of an application. A function can be triggered based on messages in a queue to then perform additional processing on these messages.</p>
			<p>In this section, you'll create a function that is integrated with Azure storage queues to consume events. You will also configure KEDA to allow scaling to/from zero pods in the case of low traffic.</p>
			<p>Let's start by creating a queue in Azure.</p>
			<h3 id="_idParaDest-166"><a id="_idTextAnchor171"/>Creating a queue</h3>
			<p>In this section, you will create a new storage account and a new queue in that storage account. You will connect functions to that queue in the next section, <em class="italics">Creating a queue-triggered function</em>.</p>
			<ol>
				<li value="1">To begin, create a new storage account. Search for <strong class="inline">storage accounts</strong> in the Azure search bar and select <span class="P---Screen-Text">Storage accounts</span>:<div id="_idContainer472" class="IMG---Figure"><img src="image/B17338_14_19.jpg" alt="Navigating to the storage account services through the Azure portal"/></div><p class="figure">Figure 14.19: Navigating to Storage accounts service through the Azure portal</p></li>
				<li>Click the <span class="P---Screen-Text">+ New</span> button at the top to create a new storage account. Provide the details to create the storage account. The storage account name has to be globally unique, so consider adding your initials. It is recommended to create the storage account in the same region as your AKS cluster. Finally, to save on costs, you are recommended to downgrade the replication setting to <span class="P---Screen-Text">Locally-redundant storage (LRS)</span> as shown in <em class="italics">Figure 14.20</em>:<div id="_idContainer473" class="IMG---Figure"><img src="image/B17338_14_20.jpg" alt="Providing resource group and storage account details to create the storage account "/></div><p class="figure">Figure 14.20: Providing the details to create the storage account</p><p>Once you're ready, click the <span class="P---Screen-Text">Review + create</span> button at the bottom. On the resulting screen, select <span class="P---Screen-Text">Create</span> to start the creation process.</p></li>
				<li>It will take about a minute to create the storage account. Once it is created, open the account by clicking on the <span class="P---Screen-Text">Go to resource</span> button. In the <span class="P---Screen-Text">Storage account</span> pane, select <span class="P---Screen-Text">Access keys</span> in the left-hand navigation, click on <span class="P---Screen-Text">Show keys</span>, and copy the primary connection string, as shown in <em class="italics">Figure 14.21</em>. Note down this string for now:<div id="_idContainer474" class="IMG---Figure"><img src="image/B17338_14_21.jpg" alt="Navigating to Access keys and copying the Connection string"/></div><p class="figure">Figure 14.21: Copying the primary connection string</p><h4>Note</h4><p class="callout">For production use cases, it is not recommended to connect to Azure Storage using the access key. Any user with that access key has full access to the storage account and can read and delete all files on it. It is recommended to either generate a <strong class="bold">shared access signatures</strong> (<strong class="bold">SAS</strong>) token to connect to storage or to use Azure AD-integrated security. To learn more about SAS token authentication to storage, refer to <a href="">https://docs.microsoft.com/rest/api/storageservices/delegate-access-with-shared-access-signature</a>. To learn more about Azure AD authentication to Azure Storage, please refer to <a href="">https://docs.microsoft.com/rest/api/storageservices/authorize-with-azure-active-directory</a>.</p></li>
				<li>The final step is to create our queue in the storage account. Look for <strong class="inline">queue</strong> in the left-hand navigation, click the <span class="P---Screen-Text">+ Queue</span> button to add a queue, and provide it with a name. To follow along with this demo, use <strong class="inline">function</strong> as the queue name:</li>
			</ol>
			<div>
				<div id="_idContainer475" class="IMG---Figure">
					<img src="image/B17338_14_22.jpg" alt="Creating a Queue service"/>
				</div>
			</div>
			<p class="figure">Figure 14.22: Creating a new queue</p>
			<p>You have now created a storage account in Azure and have its connection string. You created a queue in this storage account. In the next section, you will create a function that will consume messages from the queue.</p>
			<h3 id="_idParaDest-167"><a id="_idTextAnchor172"/>Creating a queue-triggered function</h3>
			<p>In the previous section, you created a queue in Azure. In this section, you will create a new function that will monitor this queue and remove messages from the queue. You will need to configure this function with the connection string to this queue:</p>
			<ol>
				<li value="1">From within the VM, begin by creating a new directory and navigating to it:<p class="snippet">cd ..</p><p class="snippet">mkdir js-queue</p><p class="snippet">cd js-queue</p></li>
				<li>Now we can create the function. We will start with the initialization:<p class="snippet">func init --docker</p><p>This will ask you two questions now. For the runtime, select <span class="P---Screen-Text">node</span> (option 2), and for the language, select <span class="P---Screen-Text">JavaScript</span> (option 1). This should result in the output shown in <em class="italics">Figure 14.23</em>:</p><div id="_idContainer476" class="IMG---Figure"><img src="image/B17338_14_23.jpg" alt="Creating a new javaScript function of type javaScript"/></div><p class="figure">Figure 14.23: Initializing a new function</p><p>Following the initialization, you can create the actual function:</p><p class="snippet">func new</p><p>This will ask you for a trigger. Select <span class="P---Screen-Text">Azure Queue Storage trigger</span> (option 10). Give the name <strong class="inline">js-queue</strong> to the new function. This should result in the output shown in <em class="italics">Figure 14.24</em>:</p><div id="_idContainer477" class="IMG---Figure"><img src="image/B17338_14_24.jpg" alt="Creating a new function using the Azure Queue Storage trigger"/></div><p class="figure">Figure 14.24: Creating a queue-triggered function</p></li>
				<li>You will now need to make a couple of configuration changes. You need to provide the function you created the connection string on to Azure Storage and provide the queue name. First, open the <strong class="inline">local.settings.json</strong> file to configure the connection strings for storage:<p class="snippet">vi local.settings.json</p><p>To make the changes, follow these instructions:</p><ul><li>Hit <em class="italics">I</em> to go into insert mode.</li><li>Replace the connection string for <strong class="inline">AzureWebJobsStorage</strong> with the connection string you copied earlier. Add a comma to the end of this line.</li><li>Add a new line and then add the following text on that line:</li></ul><p class="snippet">"QueueConnString": "&lt;your connection string&gt;"</p><p>The result should look like <em class="italics">Figure 14.25</em>:</p><div id="_idContainer478" class="IMG---Figure"><img src="image/B17338_14_25.jpg" alt="Editing the Queue connection string in the local.settings.json file "/></div><p class="figure">Figure 14.25: Editing the local.settings.json file</p><ul><li>Save and close the file by hitting the <em class="italics">Esc</em> key, type <strong class="inline">:wq!</strong>, and then press <em class="italics">Enter</em>.</li></ul></li>
				<li>The next file you need to edit is the function configuration itself. Here, you will refer to the connection string from earlier, and provide the queue name we chose in the <em class="italics">Creating a queue</em> section. To do that, use the following command:<p class="snippet">vi js-queue/function.json</p><p>To make the changes, follow these instructions:</p><ul><li>Hit <em class="italics">I</em> to go into insert mode.</li><li>Change the queue name to the name of the queue you created (<strong class="inline">function</strong>).</li><li>Next, add <strong class="inline">QueueConnString</strong> to the <strong class="inline">connection</strong> field.</li></ul><p>Your configuration should now look like <em class="italics">Figure 14.26</em>:</p><div id="_idContainer479" class="IMG---Figure"><img src="image/B17338_14_26.jpg" alt="Editing the js-queue/function.json file"/></div><p class="figure">Figure 14.26: Editing the js-queue/function.json file</p><ul><li>Save and close the file by hitting the <em class="italics">Esc</em> key, type <strong class="inline">:wq!</strong>, and then press <em class="italics">Enter</em>.</li></ul></li>
				<li>You are now ready to publish your function to Kubernetes. You will start by setting up KEDA on your Kubernetes cluster:<p class="snippet">kubectl create ns keda</p><p class="snippet">func kubernetes install --keda --namespace keda</p><p>This should return an output similar to <em class="italics">Figure 14.27</em>:</p><div id="_idContainer480" class="IMG---Figure"><img src="image/B17338_14_27.jpg" alt="Setting up KEDA on your Kubernetes cluster"/></div><p class="figure">Figure 14.27: Installing KEDA on Kubernetes</p><p>This will set up KEDA on your cluster. The installation doesn't take long. To verify that the installation was successful, make sure that the KEDA pod is running in the <strong class="inline">keda</strong> namespace:</p><p class="snippet">kubectl get pod -n keda</p><p>This should return an output similar to <em class="italics">Figure 14.28</em>:</p><div id="_idContainer481" class="IMG---Figure"><img src="image/B17338_14_28.jpg" alt="Ensuring that the KEDA pod is running in the keda namespace"/></div><p class="figure">Figure 14.28: Verifying the KEDA installation succeeded</p></li>
				<li>You can now deploy the function to Kubernetes. You will configure KEDA to look at the number of queue messages every 5 seconds (<strong class="inline">polling-interval=5</strong>) to have a maximum of 15 replicas (<strong class="inline">max-replicas=15</strong>), and to wait 15 seconds before removing pods (<strong class="inline">cooldown-period=15</strong>). To deploy and configure KEDA in this way, use the following command:<p class="snippet">func kubernetes deploy --name js-queue \</p><p class="snippet">--registry &lt;registry name&gt;.azurecr.io \</p><p class="snippet">--polling-interval=5 --max-replicas=15 --cooldown-period=15</p><p>This will return an output similar to <em class="italics">Figure 14.29</em>:</p><div id="_idContainer482" class="IMG---Figure"><img src="image/B17338_14_29.jpg" alt="Deploying the queue-triggered function"/></div><p class="figure">Figure 14.29: Deploying the queue-triggered function</p><p>To verify that the setup completed successfully, you can run the following command:</p><p class="snippet">kubectl get all</p><p>This will show you all the resources that were deployed. As you can see in <em class="italics">Figure 14.30</em>, this setup created a deployment, ReplicaSet, and an HPA. In the HPA, you should see that there are no replicas currently running:</p><div id="_idContainer483" class="IMG---Figure"><img src="image/B17338_14_30.jpg" alt="Verifying that the setup created a deployment, a ReplicaSet, and an HPA"/></div><p class="figure">Figure 14.30: Verifying the objects created by the setup</p></li>
				<li>Now you will create a message in the queue to trigger KEDA and create a pod. To see the scaling event, run the following command:<p class="snippet">kubectl get hpa -w</p></li>
				<li>To create a message in the queue, we are going to use the Azure portal. To create a new message, open the queue in the storage that you created earlier. Click on the <span class="P---Screen-Text">+ Add message</span> button at the top of your screen, create a test message, and click on <span class="P---Screen-Text">OK</span>. This is shown in <em class="italics">Figure 14.31</em>:</li>
			</ol>
			<div>
				<div id="_idContainer484" class="IMG---Figure">
					<img src="image/B17338_14_31.jpg" alt="Adding a message to the queue"/>
				</div>
			</div>
			<p class="figure">Figure 14.31: Adding a message to the queue</p>
			<p>After creating this message, have a look at the output of the previous command you issued. It might take a couple of seconds, but soon enough, your HPA should scale to one replica. Afterward, it should also scale back down to zero replicas:</p>
			<div>
				<div id="_idContainer485" class="IMG---Figure">
					<img src="image/B17338_14_32.jpg" alt="KEDA scaling from 0 to 1 and back to 0 replicas"/>
				</div>
			</div>
			<p class="figure">Figure 14.32: KEDA scaling from 0 to 1 and back to 0 replicas</p>
			<p>This has shown you that KEDA enabled the Kubernetes HPA to scale from zero to one pod when there are messages in the queue, and also from one to zero pods when those messages are processed.</p>
			<p>You have now created a function that is triggered by messages being added to a queue. You were able to verify that KEDA scaled the pods from 0 to 1 when you created a message in the queue, and back down to 0 when there were no messages left. In the next section, you will execute a scale test, and you will create multiple messages in the queue and see how the functions react.</p>
			<h3 id="_idParaDest-168"><a id="_idTextAnchor173"/>Scale testing functions</h3>
			<p>In the previous section, you saw how functions reacted when there was a single message in the queue. In this example, you are going to send 1,000 messages into the queue and see how KEDA will first scale out the function, and then scale back in, and eventually scale back down to zero:</p>
			<ol>
				<li value="1">In the current Cloud Shell, watch the HPA using the following command:<p class="snippet">kubectl get hpa -w</p></li>
				<li>To start pushing the messages, you are going to open a new Cloud Shell session. To open a new session, select the <span class="P---Screen-Text">Open new session</span> button in Cloud Shell:<div id="_idContainer486" class="IMG---Figure"><img src="image/B17338_14_33.jpg" alt="Opening a new Cloud Shell instance"/></div><p class="figure">Figure 14.33: Opening a new Cloud Shell instance</p><p>To send the 1,000 messages into the queue, a Python script has been provided called <strong class="inline">sendMessages.py</strong> in <em class="italics">Chapter 15</em> of the code examples in the GitHub repo accompanying this book. To make the script work, you'll need to install <strong class="inline">azure-storage-queue package using pip</strong>:</p><p class="snippet">pip install azure-storage-queue==12.1.5</p><p>Once that is installed, you will need to provide this script with your storage account connection string. To do this, open the file using:</p><p class="snippet">code sendMessages.py</p><p>Edit the storage connection string on <em class="italics">line 8</em> to your connection string:</p><div id="_idContainer487" class="IMG---Figure"><img src="image/B17338_14_34.jpg" alt="Pasting in your connection string for your storage account on line 8"/></div><p class="figure">Figure 14.34: Pasting in your connection string for your storage account on line 8</p></li>
				<li>Once you have pasted in your connection string, you can execute the Python script and send 1,000 messages to your queue:<p class="snippet">python sendMessages.py</p><p>While the messages are being sent, switch back to the previous Cloud Shell instance and watch KEDA scale from 0 to 1, and then watch the HPA scale to the number of replicas. The HPA uses metrics provided by KEDA to make scaling decisions. Kubernetes, by default, doesn't know about the number of messages in an Azure storage queue that KEDA provides to the HPA.</p><h4>Note</h4><p class="callout">Depending on how quickly KEDA in your cluster scales up the application, your deployment might not scale to the 15 replicas that are shown in <em class="italics">Figure 14.29</em>.</p><p>Once the queue is empty, KEDA will scale back down to zero replicas:</p></li>
			</ol>
			<div>
				<div id="_idContainer488" class="IMG---Figure">
					<img src="image/B17338_14_35.jpg" alt="KEDA will scale from 0 to 1, and the HPA will scale to 15 pods . When the load has decreased, KEDA scaled down to 0 again"/>
				</div>
			</div>
			<p class="figure">Figure 14.35: KEDA will scale from 0 to 1, and the HPA will scale to 15 pods</p>
			<p>As you can see in the output of this command, the deployment was scaled first from zero to one replica, and then gradually got scaled out to a maximum of 15 replicas. When there were no more messages in the queue, the deployment was scaled down again to zero replicas.</p>
			<p>This concludes the examples of running serverless functions on top of Kubernetes. Let's make sure to clean up the objects that were created. Run the following command from within the VM you created (the final step will delete this VM; if you want to keep the VM, don't run the final step):</p>
			<p class="snippet">kubectl delete secret js-queue</p>
			<p class="snippet">kubectl delete scaledobject js-queue</p>
			<p class="snippet">kubectl delete deployment js-queue</p>
			<p class="snippet">func kubernetes remove --namespace keda</p>
			<p class="snippet">az group delete -n Functions-KEDA  --yes</p>
			<p>In this section, you ran a function that was triggered by messages in a storage queue on top of Kubernetes. You used a component called KEDA to achieve scaling based on the number of queue messages. You saw how KEDA can scale from 0 to 1 and back down to 0. You also saw how the HPA can use metrics provided by KEDA to scale out a deployment.</p>
			<h2 id="_idParaDest-169"><a id="_idTextAnchor174"/>Summary</h2>
			<p>In this chapter, you deployed serverless functions on top of your Kubernetes cluster. To achieve this, you first created a VM and an ACR.</p>
			<p>You started the functions deployments by deploying a function that used an HTTP trigger. The Azure Functions core tools were used to create that function and to deploy it to Kubernetes.</p>
			<p>Afterward, you installed an additional component on your Kubernetes cluster called KEDA. KEDA allows serverless scaling in Kubernetes. It allows deployments to and from zero pods, and it also provides additional metrics to the HPA. You used a function that was triggered on messages in an Azure storage queue.</p>
			<p>In the next – and final – chapter of this book, you'll learn how to integrate containers and Kubernetes in a <strong class="bold">continuous integration and continuous delivery</strong> (<strong class="bold">CI/CD</strong>) pipeline using GitHub Actions.</p>
		</div>
	</body></html>