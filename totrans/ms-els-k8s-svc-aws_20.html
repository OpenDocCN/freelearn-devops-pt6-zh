<html><head></head><body>
		<div id="_idContainer200">
			<h1 id="_idParaDest-301" class="chapter-number"><a id="_idTextAnchor331"/>20</h1>
			<h1 id="_idParaDest-302"><a id="_idTextAnchor332"/>Troubleshooting Common Issues</h1>
			<p>Throughout the book, we have created clusters and added controllers, add-ons, workloads, and so on, but not everything has gone according to plan. And while K8s does a great job of being easy to use, you will probably have at least one issue following this book or in your <span class="No-Break">day job.</span></p>
			<p>Understanding how to troubleshoot and what tools to use to identify root causes and hopefully fix them <a id="_idIndexMarker1224"/>is an important part of using or running <strong class="bold">Elastic Kubernetes Service </strong>(<strong class="bold">EKS</strong>). In this chapter, we will look at the common techniques and tools used with EKS, as well as the frequent errors you may see when using <span class="No-Break">Amazon EKS.</span></p>
			<p>In this chapter, we will cover a couple of common questions when you start using Amazon EKS, walk through the details, and learn how to do troubleshooting such as <span class="No-Break">the following:</span></p>
			<ul>
				<li>Common K8s tools/techniques for <span class="No-Break">troubleshooting EKS</span></li>
				<li>Common cluster <span class="No-Break">access problems</span></li>
				<li>Common <span class="No-Break">Node/compute problems</span></li>
				<li>Common Pod <span class="No-Break">networking problems</span></li>
				<li>Common <span class="No-Break">workload problems</span></li>
			</ul>
			<p>Let’s <span class="No-Break">get started!</span></p>
			<h1 id="_idParaDest-303"><a id="_idTextAnchor333"/>Technical requirements</h1>
			<p>The reader should have a familiarity with YAML, AWS IAM, and EKS architecture. Before getting started with this chapter, please ensure <span class="No-Break">the following:</span></p>
			<ul>
				<li>You have network connectivity to your EKS cluster <span class="No-Break">API endpoint</span></li>
				<li>The AWS CLI, Docker, and <strong class="source-inline">kubectl</strong> binary is installed on your workstation and have <span class="No-Break">administrator access</span></li>
			</ul>
			<h1 id="_idParaDest-304"><a id="_idTextAnchor334"/>Common K8s tools/techniques for troubleshooting EKS</h1>
			<p>Any troubleshooting process begins with trying to understand the problem and differentiate <a id="_idIndexMarker1225"/>between symptoms and the root cause of the problem. Symptoms can often be mistaken for the root cause, so the troubleshooting process tends to be iterative, with constant testing and observation as you focus on what the actual problem is and disregard the symptoms and <span class="No-Break">false positives.</span></p>
			<p>Once you understand the problem, it’s now a case of understanding how to mitigate, solve, or ignore it. Not all problems can be solved then and there, so you may need a strategy to work around them for the <span class="No-Break">time being.</span></p>
			<p>The final stage will be the resolution/fixing of the problem. This might require an update to your cluster, application code, or both, and depending on the nature of the problem, the number of clusters you manage and the impact on the users/customers may be quite an <span class="No-Break">involved process.</span></p>
			<p>Generally, I use the following checklist when trying to understand <span class="No-Break">the problem:</span></p>
			<ul>
				<li><em class="italic">What has changed?</em> – The mantra for most support engineers; has there been a new deployment? A cluster or add-on upgrade? An AWS/on-premises infrastructure change? We’ll look at tools next but having a record of any changes (in production at least) is a good practice to help engineers determine what has changed across these <span class="No-Break">three areas.</span></li>
				<li><em class="italic">Investigate the impact</em> – Here, you look at the symptoms. What problem is being observed? A slowdown of processing or a complete failure? What’s the scope? Limited to one namespace? One cluster? One VPC? Combined with an understanding of what has changed, this normally allows an engineer to narrow down the problem to the root cause but may require you to iterate through several hypotheses. Is it the new node type added to the cluster? No, it’s the new deployment on the node! Or, it’s the application library in <span class="No-Break">the deployment!</span></li>
				<li><em class="italic">Plan your fix or mitigation</em> – Can you fix it easily with no impact or do you need to plan your change? Form a plan and discuss it with your team, application owner, and any customer representatives. If you can replicate the problem and the fix in a non-production environment prior to any production change, then you should, and this will help with the <span class="No-Break">overall plan.</span></li>
			</ul>
			<p>Now we’ve got a basic understanding of the steps you would typically go through to troubleshoot EKS problems. Next, let’s look at some of the tools you might use to <span class="No-Break">do so.</span></p>
			<h2 id="_idParaDest-305"><a id="_idTextAnchor335"/>Common EKS troubleshooting tools</h2>
			<p>The following <a id="_idIndexMarker1226"/>table provides a list of common troubleshooting tools; it’s not exhaustive as the K8s ecosystem is large and has lots of contributors, but these are the ones I use or have used in the past. (Sorry if your favorite one <span class="No-Break">isn’t included!)</span></p>
			<table id="table001-9" class="No-Table-Style _idGenTablePara-1">
				<colgroup>
					<col/>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Phase</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Tool</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="bold">Description</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style" rowspan="4">
							<p>What <span class="No-Break">has changed?</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">AWS CloudTrail</span></p>
						</td>
						<td class="No-Table-Style">
							<p>CloudTrail can provide logs of every API call made in your AWS accounts; this includes AWS EKS API calls (not K8s API), API calls to load balancers, IAM, and <span class="No-Break">so on.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">AWS CloudWatch</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Provides dashboards and logs for the control and (optionally) <span class="No-Break">data planes.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Grafana <span class="No-Break">Loki </span><a href="https://grafana.com/oss/loki/"><span class="No-Break">https://grafana.com/oss/loki/</span></a></p>
						</td>
						<td class="No-Table-Style">
							<p>An open source <span class="No-Break">log aggregator.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break"><strong class="source-inline">kubectl diff</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="source-inline">kubectl diff</strong> allows you to compare a local manifest file with the running configuration to see what will change (or has changed) and is a useful tool if you have access to previous manifest files <span class="No-Break">or commits.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style" rowspan="5">
							<p>Investigating <span class="No-Break">the impact</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Linux <span class="No-Break">command-line tools</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Any of the standard Linux tools such as <strong class="source-inline">dig</strong>, <strong class="source-inline">ping</strong>, <strong class="source-inline">tcpdump</strong>, and so on should be used to determine the scope <span class="No-Break">and impact.</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">kubectl</span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="source-inline">kubectl describe</strong>, <strong class="source-inline">kubectl get events</strong>, and <strong class="source-inline">kubectl logs</strong> are fundamental to any troubleshooting process. <strong class="source-inline">kubectl top</strong> can be used to look at Pod- and Node-level stats (as long as the metrics servers <span class="No-Break">are installed)</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Ktop: </span><a href="https://github.com/vladimirvivien/ktop"><span class="No-Break">https://github.com/vladimirvivien/ktop</span></a></p>
						</td>
						<td class="No-Table-Style">
							<p>A useful CLI for <span class="No-Break">cluster management</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">k9s: </span><a href="https://github.com/derailed/k9s"><span class="No-Break">https://github.com/derailed/k9s</span></a></p>
						</td>
						<td class="No-Table-Style">
							<p>A useful CLI for <span class="No-Break">cluster management</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>AWS <span class="No-Break">Log Collector</span></p>
							<p><a href="https://github.com/awslabs/amazon-eks-ami/tree/master/log-collector-script/linux"><span class="No-Break">https://github.com/awslabs/amazon-eks-ami/tree/master/log-collector-script/linux</span></a></p>
						</td>
						<td class="No-Table-Style">
							<p>AWS support script that can be used to collect OS and <span class="No-Break">K8s logs.</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 20.1 – Common EKS troubleshooting tools</p>
			<p class="callout-heading">Note</p>
			<p class="callout">You can also now use <strong class="source-inline">kubectl debug</strong> to inject a troubleshooting container into a running pod to do live debugging of running pods in K8s 1.25 <span class="No-Break">and above.</span></p>
			<p>Along with <a id="_idIndexMarker1227"/>technical tools/services, AWS provides a number of support services, which are <span class="No-Break">listed here.</span></p>
			<h3>AWS Premium Support</h3>
			<p>AWS provides technical support service for all customers and offers 24/7 service 365 days a year. It is designed to give you the right mix of tools and access to AWS expertise, so you can <a id="_idIndexMarker1228"/>focus on business growth while <a id="_idIndexMarker1229"/>optimizing system performance, learning how to cut unnecessary infrastructure costs, and reducing the complexity for doing troubleshooting when using each <span class="No-Break">AWS service.</span></p>
			<p>The support plan includes different levels, such as <em class="italic">Developer</em>, <em class="italic">Business</em>, and <em class="italic">Enterprise</em>. Depending on what support plan you have, you can use email, phone calls, or even chat to reach out to AWS experts for consulting on technical or operational issues through the AWS Support <span class="No-Break">case console.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">If you are <a id="_idIndexMarker1230"/>interested in the AWS Premium Support plan and would like to learn more detail, you can check out their service feature <span class="No-Break">page: </span><a href="https://aws.amazon.com/premiumsupport/plans/"><span class="No-Break">https://aws.amazon.com/premiumsupport/plans/</span></a><span class="No-Break">.</span></p>
			<p>Part of the support model is access to Knowledge Center, which has a lot of additional information on all the AWS platform products, not <span class="No-Break">just EKS.</span></p>
			<h3>AWS Support Knowledge Center</h3>
			<p>AWS Support Knowledge Center is maintained by AWS and comprises a centralized resource <a id="_idIndexMarker1231"/>center to help you better learn how to fix operational <a id="_idIndexMarker1232"/>issues or your configuration <a id="_idIndexMarker1233"/>when using AWS services. It lists the most frequent questions and requests that AWS support receives from its customers. You can check more details by accessing the following <span class="No-Break">link: </span><a href="https://aws.amazon.com/premiumsupport/knowledge-center/"><span class="No-Break">https://aws.amazon.com/premiumsupport/knowledge-center/</span></a><span class="No-Break">.</span></p>
			<p>You can review the section on Amazon EKS to find out the common issues in Amazon EKS. Some articles also include featured videos with complete step-by-step tutorials. Now we’ve looked at some common tools for troubleshooting, let’s look at some typical cluster <span class="No-Break">access problems.</span></p>
			<h1 id="_idParaDest-306"><a id="_idTextAnchor336"/>Common cluster access problems</h1>
			<p>This section <a id="_idIndexMarker1234"/>lists common issues when trying to access your EKS cluster. The next few sections describe common symptoms and how to <span class="No-Break">fix them.</span></p>
			<h2 id="_idParaDest-307"><a id="_idTextAnchor337"/>You cannot access your cluster using kubectl</h2>
			<p>Interacting <a id="_idIndexMarker1235"/>with your cluster API through <strong class="bold">kubectl</strong> or as part <a id="_idIndexMarker1236"/>of a CI/CD pipeline or tool is a critical part of using EKS! Some <a id="_idIndexMarker1237"/>common problems are listed next, along with <span class="No-Break">potential solutions.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">While the errors shown next may point to a specific problem, they may also be related to an issue not <span class="No-Break">documented here.</span></p>
			<p>In the error message shown, the shell has no credentials configured as environment variables or as a profile in the <strong class="source-inline">~/.</strong><span class="No-Break"><strong class="source-inline">aws</strong></span><span class="No-Break"> directory:</span></p>
			<pre class="source-code">
$ kubectl get node
Unable to locate credentials. You can configure credentials by running "aws configure".
$ aws eks update-kubeconfig --name mycluster  --region eu-central-1
Unable to locate credentials. You can configure credentials by running "aws configure".</pre>
			<p>You may also get the following error message, which is different but means the same thing – the shell has no credentials configured as environment variables or as a profile in the <strong class="source-inline">~/.</strong><span class="No-Break"><strong class="source-inline">aws</strong></span><span class="No-Break"> directory:</span></p>
			<pre class="source-code">
$ kubectl get node
Unable to locate credentials. You can configure credentials by running "aws configure".</pre>
			<p>In the error message shown next, the credentials configured in the shell don’t have the right IAM privilege or <span class="No-Break">K8s privileges:</span></p>
			<pre class="source-code">
$ kubectl get node
error: You must be logged in to the server (Unauthorized)</pre>
			<p>In this <a id="_idIndexMarker1238"/>error message, the most likely issue is a network <a id="_idIndexMarker1239"/>connectivity issue, with the client having restricted network access to a private EKS cluster or with an IP whitelist. This error is sometimes seen if an IAM role is used without the <span class="No-Break">relevant access:</span></p>
			<pre class="source-code">
$ kubectl get node
Unable to connect to the server: dial tcp 3.69.90.98:443: i/o timeout</pre>
			<p>Now we’ve looked at some common cluster access problems let’s look at some typical <span class="No-Break">Node/compute problems.</span></p>
			<h1 id="_idParaDest-308"><a id="_idTextAnchor338"/>Common Node/compute problems</h1>
			<p>This section <a id="_idIndexMarker1240"/>lists common issues you might see with worker nodes in <a id="_idIndexMarker1241"/>your EKS cluster, along with <span class="No-Break">potential solutions.</span></p>
			<h2 id="_idParaDest-309"><a id="_idTextAnchor339"/>Node/Nodes can’t join the cluster</h2>
			<p>For this problem, what has changed, for example, a new node being added or an IP whitelist being changed, will determine what needs fixing. Often, the error is simply nodes being in a <strong class="source-inline">NotReady</strong>/<strong class="source-inline">Unknown</strong> state, shown next, which has a number of different <span class="No-Break">root causes:</span></p>
			<pre class="source-code">
$ kubectl get node
NAME  STATUS   ROLES    AGE    VERSION
ip-172-31-10-50.x.internal    NotReady    &lt;none&gt;   7d4h   v1.24.13-eks-0a21954
ip-172-31-11-89.x.internal    Unknown    &lt;none&gt;   7d4h   v1.24.13-eks-0a21954</pre>
			<p>If you’re running self-managed nodes, did EC2 run the <strong class="source-inline">bootstrap.sh</strong> script? With a managed node, this will happen automatically, but if not, your EC2 instance will not <span class="No-Break">register automatically.</span></p>
			<p>If you have an IP whitelist on a public cluster, did you include the public address of your nodes or the NAT gateway to the whitelist? If not, then your nodes will not be able to communicate with the <span class="No-Break">K8s cluster.</span></p>
			<p>For a private or private/public cluster, was your worker node security group registered with <a id="_idIndexMarker1242"/>the cluster security group? If not, then your nodes will not be able to communicate with the <span class="No-Break">K8s cluster.</span></p>
			<pre class="source-code">
Dec 23 17:42:36 ... kubelet[92039]: E1223 17:42:36.551307 92039 kubelet.go:2240] node "XXXXXXXXX" not found</pre>
			<p>In the error message shown previously from the <strong class="source-inline">kubelet</strong> logs, the most likely issue is a VPC DNS issue where the VPC hasn’t been configured with DNS hostnames <span class="No-Break">or resolution.</span></p>
			<pre class="source-code">
Error: Kubernetes cluster unreachable: Get "https://XXXXXXXXXX.gr7.eu-central-1.eks.amazonaws.com/version?timeout=32s": dial tcp &lt;API_SERVER_IP&gt;:443: i/o timeout</pre>
			<p>In the error message shown previously from the <strong class="source-inline">kubelet</strong> logs, the most likely issue is a networking issue where a security group, NACL, NAT gateway, or endpoint is misconfigured or <span class="No-Break">doesn’t exist.</span></p>
			<pre class="source-code">
Jan 01 12:23:01 XXXXXXXXX kubelet[4445]: E1012 12:23:01.369732    4445 kubelet_node_status.go:377] Error updating node status, will retry: error getting node "XXXXXXXXX": Unauthorized</pre>
			<p>In the error message shown previously from the <strong class="source-inline">kubelet</strong> logs, the most likely issue is an IAM authentication issue where the node’s IAM role has not been added to the <strong class="source-inline">aws-auth</strong> <span class="No-Break">config map.</span></p>
			<pre class="source-code">
onditions:Type   Status  LastHeartbeatTime  LastTransitionTime     Reason          Message
  MemoryPressure   False   Tue, 12 Jul 2022 03:10:33 +0000   Wed, 29 Jun 2022 13:21:17 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     True    Tue, 12 Jul 2022 03:10:33 +0000   Wed, 06 Jul 2022 19:46:54 +0000   KubeletHasDiskPressure       kubelet has disk pressure</pre>
			<p>In the error <a id="_idIndexMarker1243"/>message shown previously from the <strong class="source-inline">describe node</strong> command, the most likely issue is a disk issue due to low disk space (normally due to out-of-control logging). Now we’ve looked at some common cluster compute problems, let’s look at some typical <span class="No-Break">networking problems.</span></p>
			<h1 id="_idParaDest-310"><a id="_idTextAnchor340"/>Common Pod networking problems</h1>
			<p>In previous sections, we’ve discussed networking problems in the context of the API/control <a id="_idIndexMarker1244"/>plane and worker nodes. This section lists common issues you might see with pod networking in an EKS cluster, along with <span class="No-Break">potential solutions.</span></p>
			<pre class="source-code">
* connect to 172.16.24.25 port 8080 failed: Connection timed out
* Closing connection 0
curl: (7) Failed to connect to 172.16.24.25 port 8080 failed: Connection timed out</pre>
			<p>In the error message shown previously from the pod logs, the most likely issue is a worker (or pod) security group issue. Check that the worker security group is configured to allow all the needed ports, IP CIDR ranges, and other security groups (including itself). If you using NACLs, make sure ephemeral ports are allowed out, as well as any <span class="No-Break">ingress ports.</span></p>
			<pre class="source-code">
Error: RequestError: send request failed caused by: Post dial tcp: i/o timeout</pre>
			<p>In the error message shown previously from the pod logs, the most likely issue is a DNS issue. Make sure <strong class="source-inline">clusterDNS</strong> and <strong class="source-inline">CoreDNS</strong> are working and the VPC has been enabled with DNS resolution <span class="No-Break">and hostnames.</span></p>
			<pre class="source-code">
Error: RequestError: send request failed caused by: Post dial tcp 172.16.24.25:443: i/o timeout</pre>
			<p>In the error <a id="_idIndexMarker1245"/>message shown previously from the pod logs, the most likely issue is a <span class="No-Break">connectivity issue.</span></p>
			<pre class="source-code">
Failed create pod mypod: rpc error: code = Unknown desc = NetworkPlugin cni failed to set up pod network: add cmd: failed to assign an IP address to container</pre>
			<p>The previous error message from the <strong class="source-inline">pod describe</strong> command shows the pod stuck in a <strong class="source-inline">ContainerCreating</strong> status; the most likely issue is that the VPC has no more free IP addresses. If prefix addressing is not being used, then the EC2 instance type may have exhausted the number of IP addresses it <span class="No-Break">can support.</span></p>
			<pre class="source-code">
NAME    READY     STATUS             RESTARTS    AGE
aws-node-bbwpq   0/1     CrashLoopBackOff     12         51m
aws-node-nw7v8  0/1     CrashLoopBackOff     12         51m
coredns-12     0/1     Pending         0         54m
coredns-13     0/1     Pending         0         54m</pre>
			<p>In the error message shown previously from the <strong class="source-inline">get pod</strong> command, the most likely issue is a VPC or security group issue, which has a knock-on effect for the CNI or DNS operations in <span class="No-Break">the pod.</span></p>
			<pre class="source-code">
"msg"="Reconciler error" "error"="failed to build LoadBalancer configuration due to retrieval of subnets failed to resolve 2 qualified subnets.</pre>
			<p>In the error <a id="_idIndexMarker1246"/>message from the <strong class="source-inline">describe deployment</strong> command, the most likely issue is a subnet has not been tagged for an internal or external load balancer so it cannot be discovered. Now we’ve looked at some common pod networking problems, let’s look at some typical <span class="No-Break">workload problems.</span></p>
			<h1 id="_idParaDest-311"><a id="_idTextAnchor341"/>Common workload problems</h1>
			<p>This section lists <a id="_idIndexMarker1247"/>common issues you might see with pods and/or deployments in an EKS cluster, along with <span class="No-Break">potential solutions.</span></p>
			<pre class="source-code">
State:  Running
Started: Sun, 16 Feb 2020 10:20:09 +0000
Last State: Terminated
Reason: OOMKilled</pre>
			<p>In the preceding error message from the <strong class="source-inline">kubectl describe pod</strong> command, the most likely issue is a connectivity issue or a memory issue, as <strong class="source-inline">OOMKilled</strong> means that the pod has reached its memory limit, so it restarts. You need to increase the memory setting in the deployment or <span class="No-Break">pod specification.</span></p>
			<pre class="source-code">
NAME            READY  STATUS            RESTARTS   AGE
myDeployment1-123... 1/1    Running           1     17m
myDeployment1-234... 0/1    CrashLoopBackOff  2     1m</pre>
			<p>In the error message from <strong class="source-inline">kubectl get po</strong> command, there are several possible issues, whether from a bad DockerFile, pulling the image file, and so on. Run the <strong class="source-inline">kubectl logs</strong> command to get more information about what caused <span class="No-Break">the error.</span></p>
			<pre class="source-code">
  Warning  FailedScheduling  22s (x14 over 13m)  default-scheduler  0/3 nodes are available: 3 Insufficient cpu.</pre>
			<p>The error message shown previously from the <strong class="source-inline">kubectl describe po</strong> command shows the pod in a <strong class="source-inline">Pending</strong> status. The most likely issue is insufficient CPU available in your <span class="No-Break">worker nodes.</span></p>
			<pre class="source-code">
  Warning  FailedScheduling  80s (x14 over 15m)  default-scheduler  0/3 nodes are available: 3 Insufficient memory.</pre>
			<p>The <strong class="source-inline">kubectl describe po</strong> command’s error message shows the pod in a <strong class="source-inline">Pending</strong> status; the most likely issue is insufficient memory available in your <span class="No-Break">worker nodes.</span></p>
			<pre class="source-code">
    State:          Waiting
      Reason:       ErrImagePull</pre>
			<p>The preceding <a id="_idIndexMarker1248"/>error message from the <strong class="source-inline">kubectl describe po</strong> command shows the pod in a <strong class="source-inline">Pending</strong> status. The most likely issue is the container image is incorrect, not available, or hosted in a private repository that has not been configured in your <span class="No-Break">worker nodes.</span></p>
			<pre class="source-code">
Warning  FailedScheduling  77s (x3 over 79s)  default-scheduler  0/1 nodes are available: 1 node(s) had taint {node-typee: high-memory}, that the pod didn't tolerate.</pre>
			<p>The preceding error message from the <strong class="source-inline">kubectl describe po</strong> command shows the pod in a <strong class="source-inline">Pending</strong> status. The most likely issue is the pod doesn’t match a corresponding node toleration.This chapter won’t touch all the possible symptoms and root causes you will encounter with K8s/EKS but hopefully, you have enough information to cover the common problems you <span class="No-Break">will encounter.</span></p>
			<p>In this section, we looked at tools and techniques for troubleshooting EKS and common problems you may encounter. We’ll now revisit the key learning points from <span class="No-Break">this chapter.</span></p>
			<h1 id="_idParaDest-312"><a id="_idTextAnchor342"/>Summary</h1>
			<p>In this chapter, we started by looking at a general approach to troubleshooting EKS clusters and some common tools that can be used to determine what has changed and the scope/impact of <span class="No-Break">the problem.</span></p>
			<p>We then moved on to common problems/symptoms you may encounter in connecting to your EKS cluster, compute nodes, pod networking, and workloads and used <strong class="bold">kubectl</strong> commands to identify these issues and provide some <span class="No-Break">possible resolutions.</span></p>
			<p>This is the final chapter and by now, you should have all the knowledge required to build and manage EKS clusters and the workloads that run <span class="No-Break">on them.</span></p>
			<p>Congratulations on completing this book! We hope you have found it informative <span class="No-Break">and useful.</span></p>
			<h1 id="_idParaDest-313"><a id="_idTextAnchor343"/>Further reading</h1>
			<ul>
				<li>Debugging <span class="No-Break">K8s Tools:</span></li>
			</ul>
			<p><a href="https://www.cncf.io/blog/2022/09/15/10-critical-kubernetes-tools-and-how-to-debug-them/"><span class="No-Break">https://www.cncf.io/blog/2022/09/15/10-critical-kubernetes-tools-and-how-to-debug-them/</span></a></p>
			<ul>
				<li>EKS official <span class="No-Break">troubleshooting guide:</span></li>
			</ul>
			<p><a href="https://docs.aws.amazon.com/eks/latest/userguide/troubleshooting.html"><span class="No-Break">https://docs.aws.amazon.com/eks/latest/userguide/troubleshooting.html</span></a></p>
		</div>
	</body></html>