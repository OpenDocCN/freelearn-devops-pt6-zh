<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer261">
<h1 class="chapter-number" id="_idParaDest-135"><a id="_idTextAnchor136"/>9</h1>
<h1 id="_idParaDest-136"><a id="_idTextAnchor137"/>Using Kubeflow to Run AI/MLOps Workloads</h1>
<p>In the previous chapter, we looked at several logging, monitoring, and alerting options to gain comprehensive visibility into our container infrastructure and workloads. Regarding tools for setting up a monitoring and alerting stack, we looked at Prometheus, Grafana, and Alert Manager. We also looked at how to use the EFK toolset to set up a centralized, cluster-level logging stack that can handle large volumes of log data. Finally, we discussed the key indicators to keep a close eye on so that you can effectively manage your infrastructure and applications.</p>
<p>In this chapter, we will go through the steps for creating a <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) pipeline that will build and deploy a sample ML model using the Kubeflow MLOps platform. ML is an AI subfield. The purpose of ML is to teach computers to learn from the data you provide. Instead of describing the action, the machine will take your code and provide an algorithm that adjusts, depending on samples of expected behavior. A trained model is the code that results from the combination of the algorithm and the learned parameters.</p>
<p>The following is a high-level overview of the stages in a typical ML workflow:</p>
<ol>
<li>Source and prepare relevant data</li>
<li>Develop the ML model</li>
<li>Train the model, evaluate model accuracy, and tune the model</li>
<li>Deploy the trained model</li>
<li>Get predictions from the model</li>
<li>Monitor the ongoing predictions</li>
<li>Manage the models and their versions</li>
</ol>
<p>These are iterative stages. At any time during the procedure, you may need to rethink and return to a prior phase. </p>
<p>ML pipelines assist in automating the ML workflow and allowing sequence data to be converted and correlated together in a model so that it can be evaluated. It also allows outputs to be generated. The ML pipeline is designed to allow data to go from raw data format to meaningful information. It provides a way for constructing a multi-ML parallel pipeline system to investigate the outputs of various ML algorithms. There are various stages in a pipeline. Each stage of a pipeline receives data that’s been processed from the stage before it – for example, the output of a processing unit is fed into the next phase. </p>
<p>Kubeflow is a platform for data scientists to build and experiment with ML pipelines. It allows you to deploy and build ML workflows. You can specify the ML tools required for your workflow using the Kubeflow configuration. The workflow can then be deployed to the cloud, local, and on-premises multiple platforms for testing and production use.</p>
<p>Data scientists and ML engineers use Kubeflow on MicroK8s to quickly prototype, construct, and deploy ML pipelines. Kubeflow makes MLOps more manageable by bridging the gap between AI workloads and Kubernetes. </p>
<p>Furthermore, Kubeflow on MicroK8s is straightforward to set up and configure, as well as lightweight and capable of simulating production conditions for pipeline creation, migration, and deployment.</p>
<p>In this chapter, we’re going to cover the following main topics: </p>
<ul>
<li>Overview of the ML workflow </li>
<li>Deploying Kubeflow </li>
<li>Accessing the Kubeflow dashboard</li>
<li><a id="_idTextAnchor138"/>Creating a Kubeflow pipeline to build, train, and deploy a sample ML model</li>
<li>Recommendations – running AL/ML workloads on Kubernetes </li>
</ul>
<h1 id="_idParaDest-137"><a id="_idTextAnchor139"/>Overview of the ML workflow</h1>
<p>Kubeflow aims <a id="_idIndexMarker727"/>to be your Kubernetes ML toolkit. The ML tools that are required for your workflow can then be specified using the Kubeflow configurations and the workflow can be deployed to various platforms for testing and production use as required.</p>
<p>Let’s have a look at the Kubeflow components before we get into the intricacies of ML workflows. </p>
<h2 id="_idParaDest-138"><a id="_idTextAnchor140"/>Introduction – Kubeflow and its components</h2>
<p>Kubeflow is a <a id="_idIndexMarker728"/>system for deploying, scaling, and managing complex systems based on Kubernetes. For data scientists, Kubeflow is the go-to platform for building and testing ML pipelines. It is also for ML developers and operations teams who wish to deploy ML systems in a variety of contexts for development, testing, and production.</p>
<p>Kubeflow is a <a id="_idIndexMarker729"/>framework for establishing the components of your ML system on top of Kubernetes, as shown in the following diagram:</p>
<div>
<div class="IMG---Figure" id="_idContainer219">
<img alt="Figure 9.1 – Kubeflow components on top of Kubernetes " height="1124" src="image/Figure_9.1_B18115.jpg" width="1645"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – Kubeflow components on top of Kubernetes</p>
<p>We can specify the ML tools required for our workflow by utilizing the Kubeflow configuration interfaces. The workflow can then be deployed to multiple clouds, local, and on-premises platforms for testing and production use.</p>
<p>The following ML tools are supported by Kubeflow:</p>
<ul>
<li><strong class="bold">Chainer</strong>: Python-based <a id="_idIndexMarker730"/>deep <a id="_idIndexMarker731"/>learning framework.</li>
<li><strong class="bold">Jupyter</strong>: Interactive <a id="_idIndexMarker732"/>development environment <a id="_idIndexMarker733"/>for notebooks, code, and data that is accessible through the web. Users can create and arrange workflows in data science, scientific computing, computational journalism, and ML using its versatile interface.</li>
<li><strong class="bold">MPI</strong>: This is <a id="_idIndexMarker734"/>a message-passing standard that is standardized <a id="_idIndexMarker735"/>and portable and can be used on parallel computing platforms.</li>
<li><strong class="bold">MXNet</strong>: This is <a id="_idIndexMarker736"/>an open source deep learning <a id="_idIndexMarker737"/>software framework that’s used to train and deploy deep neural networks.</li>
<li><strong class="bold">PyTorch</strong>: This is <a id="_idIndexMarker738"/>an open source ML framework <a id="_idIndexMarker739"/>based on the Torch library that’s used for applications such as computer vision and natural language processing.</li>
<li><strong class="bold">Scikit-learn</strong>: This is <a id="_idIndexMarker740"/>an ML library for Python that <a id="_idIndexMarker741"/>includes support-vector machines, random forests, gradient boosting, k-means, and DBSCAN, among other classification, regression, and clustering techniques, and is designed to work with the Python numerical and scientific libraries known as NumPy and SciPy.</li>
<li><strong class="bold">TensorFlow</strong>: This is <a id="_idIndexMarker742"/>an ML and AI software <a id="_idIndexMarker743"/>library that is free and open source. It can be used for a variety of applications, but it focuses on deep neural network training and inference.</li>
<li><strong class="bold">XGBoost</strong>: This is <a id="_idIndexMarker744"/>an open source software library that provides a regularizing <a id="_idIndexMarker745"/>gradient boosting framework for C++, Java, Python, R, Julia, Perl, and Scala.</li>
</ul>
<p>The following are the logical components that make up Kubeflow:</p>
<ul>
<li><strong class="bold">Dashboard</strong> allows <a id="_idIndexMarker746"/>you to quickly access the Kubeflow components installed in your cluster.</li>
<li><strong class="bold">Kubeflow Notebooks</strong> allows you to run web-based development environments <a id="_idIndexMarker747"/>within your Kubernetes cluster by encapsulating them in pods. </li>
<li><strong class="bold">Kubeflow Pipelines</strong> is a <a id="_idIndexMarker748"/>Docker-based platform for creating and deploying portable, scalable ML workflows.</li>
<li><strong class="bold">KServing</strong> provides <a id="_idIndexMarker749"/>performant, high abstraction interfaces for serving models using standard ML frameworks such as TensorFlow, XGBoost, scikit-learn, PyTorch, and ONNX to tackle production model serving use cases.</li>
<li><strong class="bold">TensorFlow Serving</strong> takes <a id="_idIndexMarker750"/>care of serving functionality for TensorFlow models.</li>
<li><strong class="bold">PyTorch Serving</strong> takes <a id="_idIndexMarker751"/>care of serving functionality for the PyTorch model with Seldon.</li>
<li><strong class="bold">Seldon</strong> manages, serves, and <a id="_idIndexMarker752"/>scales models in any language or framework on Kubernetes.</li>
<li><strong class="bold">Katib</strong> is a scalable <a id="_idIndexMarker753"/>and flexible hyperparameter tuning framework that is tightly integrated with Kubernetes.</li>
<li><strong class="bold">Training operators</strong> train ML <a id="_idIndexMarker754"/>models through operators.</li>
<li><strong class="bold">Istio Integration</strong> (for TF Serving) provides <a id="_idIndexMarker755"/>functionalities such as metrics, auth and quota, rollout and A/B testing, and more.</li>
<li><strong class="bold">Argo workflows</strong> is a <a id="_idIndexMarker756"/>workflow engine that Kubeflow pipelines use to carry out various actions, such as monitoring pod logs, collecting artifacts, managing container life cycles, and more.</li>
<li><strong class="bold">Prometheus</strong> takes <a id="_idIndexMarker757"/>care of logging and monitoring for Kubeflow metrics and Kubernetes components.</li>
<li><strong class="bold">Multi-Tenancy</strong> is self-served – a new user can self-register to create and own their <a id="_idIndexMarker758"/>workspace through the UI. It is currently built around <em class="italic">user namespaces</em>.</li>
</ul>
<p>Now that we’ve seen the various Kubeflow components and ML tools, let’s get into the specifics of understanding the ML workflow.</p>
<h2 id="_idParaDest-139"><a id="_idTextAnchor141"/>Introduction to the ML workflow</h2>
<p>The ML workflow <a id="_idIndexMarker759"/>is typically comprised of multiple stages while developing and deploying an ML system. It is an iterative procedure for developing an ML system. To guarantee that the model continues to produce the results you require, you must review the output of various phases of the ML workflow and adjust the model and parameters as needed.</p>
<p>The following diagram shows the experimental phase workflow stages in sequence:</p>
<div>
<div class="IMG---Figure" id="_idContainer220">
<img alt="Figure 9.2 – Experimental phase workflow stages " height="843" src="image/Figure_9.02_B18115.jpg" width="1131"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – Experimental phase workflow stages</p>
<p>In the <a id="_idIndexMarker760"/>experimental phase, the model would be built based on initial assumptions and tested and updated iteratively to achieve the desired results:</p>
<ol>
<li value="1">Determine the problem that needs to be solved by the ML system.</li>
<li>Collect and analyze the data required to train the ML model.</li>
<li>Select an ML framework and algorithm, and then code the first version of the model.</li>
<li>Experiment with the data and model’s training.</li>
<li>Tune the model’s hyperparameters.</li>
</ol>
<p>The following diagram shows the production phase workflow stages in sequence:</p>
<div>
<div class="IMG---Figure" id="_idContainer221">
<img alt="Figure 9.3 – Production phase workflow stages " height="990" src="image/Figure_9.03_B18115.jpg" width="1334"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – Production phase workflow stages</p>
<p>During the <a id="_idIndexMarker761"/>production phase, a system will be deployed that handles the following tasks:</p>
<ul>
<li>Transform the data into the format required by the training system. To ensure that the model behaves consistently during training and prediction, the transformation process in the experimental and production phases must be the same.</li>
<li>Develop the ML model.</li>
<li>Serve the model for online prediction or batch processing.</li>
<li>Monitor the model’s performance and feed the results into the model for tuning or retraining processes.</li>
</ul>
<p>Now that we know what all the activities in the experimental and production stages involve, let’s look at the Kubeflow components that are involved in each phase.</p>
<h2 id="_idParaDest-140"><a id="_idTextAnchor142"/>Kubeflow components in each phase</h2>
<p>The following <a id="_idIndexMarker762"/>diagram shows the experimental phase workflow stages and the Kubeflow components involved in each stage:</p>
<div>
<div class="IMG---Figure" id="_idContainer222">
<img alt="Figure 9.4 – Experimental phase stages and Kubeflow components " height="850" src="image/Figure_9.04_B18115.jpg" width="1147"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4 – Experimental phase stages and Kubeflow components</p>
<p>The following diagram shows the production phase workflow stages and the Kubeflow components involved in each stage:</p>
<div>
<div class="IMG---Figure" id="_idContainer223">
<img alt="Figure 9.5 – Production phase stages and Kubeflow components " height="1055" src="image/Figure_9.05_B18115.jpg" width="1200"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5 – Production phase stages and Kubeflow components</p>
<p>Some of Kubeflow’s <a id="_idIndexMarker763"/>most important components are as follows:</p>
<ul>
<li>Jupyter notebooks can be spawned and managed using Kubeflow’s services. Notebooks are used for interactive data science and ML workflow experiments.</li>
<li>Kubeflow Pipelines is a container-based platform for creating, deploying, and managing multi-step ML processes based on Docker containers.</li>
<li>Kubeflow has several components that can be used for ML training, hyperparameter tweaking, and workload serving across many platforms.</li>
</ul>
<p>Now that we’ve looked at the various Kubeflow components and steps involved in the ML process stages, let’s look at Kubeflow Pipelines.</p>
<h2 id="_idParaDest-141"><a id="_idTextAnchor143"/>Kubeflow Pipelines</h2>
<p>Kubeflow Pipelines <a id="_idIndexMarker764"/>are one of the most essential elements of Kubeflow that make AI/ML experiments reproducible, composable, scalable, and easily shareable. Each pipeline component, denoted by a block, is a self-contained piece of code that is packaged as a Docker image. It has inputs (arguments) and outputs, and it completes one stage in the pipeline.</p>
<p>Finally, when the pipeline is run, each container will be executed across the cluster per Kubernetes scheduling, while dependencies are considered. This containerized architecture makes it easy to reuse, share, and swap out components as and when the workflow changes, which is common.</p>
<p>After running the pipeline, the results can be examined in the pipeline’s UI on the Kubeflow dashboard. Here, you can debug and tweak parameters and create additional “runs.” </p>
<p>To recap, Kubeflow is your ML kit for Kubernetes that offers the following:</p>
<ul>
<li>A platform for data scientists who want to build and experiment with ML pipelines</li>
<li>A platform for ML engineers and operational teams who want to deploy ML systems to various environments for development, testing, and production-level serving</li>
<li>Services for spawning and managing Jupyter notebooks for interactive data science and experimenting with ML workflows</li>
<li>A platform for building, deploying, and managing multi-step ML workflows based on Docker containers</li>
<li>Several components that can be used to build your ML training, hyperparameter tuning, and serving workloads across multiple platforms</li>
</ul>
<p>In the next section, we’ll go over the steps for deploying Kubeflow.</p>
<h1 id="_idParaDest-142"><a id="_idTextAnchor144"/>Deploying Kubeflow </h1>
<p>Since MicroK8s version 1.22, Kubeflow is no longer available as an add-on; instead, Ubuntu has <a id="_idIndexMarker765"/>released Charmed Kubeflow (<a href="https://charmed-kubeflow.io/">https://charmed-kubeflow.io/</a>), which is a <a id="_idIndexMarker766"/>complete collection of Kubernetes operators for delivering the 30+ apps and services that make up the latest version of Kubeflow for easy operations anywhere, from desktops to on-premises, public cloud, and the edge.</p>
<p>Kubeflow is available as a charm, which is a software package that contains a Kubernetes operator as well as information that allows you to integrate many operators into a <a id="_idIndexMarker767"/>unified system. This technology utilizes the Juju <strong class="bold">Operator Lifecycle Manager</strong> (<strong class="bold">OLM</strong>) to provide Kubeflow operations from day 0 to day 2.</p>
<p>To give an overview of Juju<a id="_idIndexMarker768"/>, it is an open source modeling tool for cloud-based software operations. It enables you to rapidly and efficiently deploy, set up, manage, maintain, and scale cloud applications on public clouds, as well as physical servers, OpenStack, and containers. More details can be found at <a href="https://ubuntu.com/blog/what-is-juju-introduction-video">https://ubuntu.com/blog/what-is-juju-introduction-video</a>.</p>
<p>Juju provides a centralized view of a deployment’s Kubernetes operators, including their configuration, scalability, and status, as well as the integration lines that connect them. It keeps track of prospective upgrades and updates for each operator, as well as coordinates the flow of events and communications between them.</p>
<p>Charmed Kubeflow is available in two bundles:</p>
<ul>
<li><strong class="bold">Full</strong> (<a href="https://charmhub.io/kubeflow">https://charmhub.io/kubeflow</a>): Each Kubeflow service is included. At least 14 GB of RAM and 60 GB of storage space is required.</li>
<li><strong class="bold">Lite</strong> (<a href="https://charmhub.io/kubeflow-lite">https://charmhub.io/kubeflow-lite</a>): Removes less frequently used services <a id="_idIndexMarker769"/>from the complete bundle while maintaining a user-friendly dashboard. This bundle is designed for environments with limited resources.</li>
</ul>
<p>Now that have a better grasp of Charmed Kubeflow, let's go over the deployment procedure for Kubeflow.</p>
<h2 id="_idParaDest-143"><a id="_idTextAnchor145"/>What we are trying to achieve </h2>
<p>We wish <a id="_idIndexMarker770"/>to do the following in this section: </p>
<ol>
<li value="1">Install and configure Microk8s.</li>
<li>Install Juju Operator Lifecycle Manager.</li>
<li>Deploy Kubeflow.</li>
</ol>
<p>Now that we <a id="_idIndexMarker771"/>know what we want to do, let’s look at the prerequisites for setting up the Kubeflow platform:</p>
<ul>
<li>A virtual machine with Ubuntu 20.04 (focal) or later</li>
<li>At least 16 GB of free memory and 20 GB of disk space</li>
<li>Access to the internet for downloading the snaps and charms required</li>
</ul>
<p>Now that we’ve established the prerequisites, let’s learn how to set up the Kubeflow platform.</p>
<h2 id="_idParaDest-144"><a id="_idTextAnchor146"/>Step 1 – Installing and configuring MicroK8s</h2>
<p>The following <a id="_idIndexMarker772"/>steps are similar to the ones we followed in <a href="B18115_05.xhtml#_idTextAnchor070"><em class="italic">Chapter 5</em></a><em class="italic">,</em> <em class="italic">Creating and Implementing Updates on Multi-Node Raspberry Pi Kubernetes Clusters</em> for creating a MicroK8s cluster. </p>
<p>We’ll set <a id="_idIndexMarker773"/>the snap to install the 1.21 release of Kubernetes <a id="_idIndexMarker774"/>since Kubeflow doesn’t support the newer 1.22 version yet.</p>
<p>Use the <a id="_idIndexMarker775"/>following command to install MicroK8s:</p>
<p class="source-code">sudo snap install microk8s --classic --channel=1.21/stable</p>
<p>The following output indicates MicroK8s has been installed successfully: </p>
<div>
<div class="IMG---Figure" id="_idContainer224">
<img alt="Figure 9.6 – MicroK8s installation " height="90" src="image/Figure_9.06_B18115.jpg" width="741"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.6 – MicroK8s installation</p>
<p>As we saw previously, MicroK8s creates a group called <strong class="source-inline">microk8s</strong> so that it can work without having to use <strong class="source-inline">sudo</strong> for every command. We will be adding the current user to this group to make it easier to run commands:</p>
<p class="source-code">sudo usermod -a -G microk8s $USER</p>
<p class="source-code">newgrp microk8s</p>
<p>Make sure <a id="_idIndexMarker776"/>there is proper access to kubectl configuration <a id="_idIndexMarker777"/>files as well:</p>
<p class="source-code">sudo chown -f -R $USER ~/.kube</p>
<p>As soon <a id="_idIndexMarker778"/>as MicroK8s is installed, it will start up. The Kubernetes <a id="_idIndexMarker779"/>cluster is now fully operational, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer225">
<img alt="Figure 9.7 – MicroK8s is fully operational " height="236" src="image/Figure_9.07_B18115.jpg" width="714"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.7 – MicroK8s is fully operational</p>
<p>Before installing Kubeflow, let’s enable some add-ons. We’ll set up a DNS service so that the applications can discover one other, as well as storage, an ingress controller for accessing Kubeflow components, and the MetalLB load balancer application. All of these can be enabled at the same time using the following command:</p>
<p class="source-code">microk8s enable dns storage ingress metallb:10.64.140.43-10.64.140.49</p>
<p>With this command, we’ve instructed MetalLB to give out addresses in the <strong class="source-inline">10.64.140.43 - 10.64.140.49</strong> range. </p>
<p>The following output shows that add-ons are being enabled:</p>
<div>
<div class="IMG---Figure" id="_idContainer226">
<img alt="Figure 9.8 – Add-ons enabled successfully " height="313" src="image/Figure_9.08_B18115.jpg" width="870"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.8 – Add-ons enabled successfully</p>
<p>MicroK8s <a id="_idIndexMarker780"/>may take a few minutes to install and configure <a id="_idIndexMarker781"/>these extra features. Before we go any further, we should <a id="_idIndexMarker782"/>double-check that the add-ons have been correctly activated <a id="_idIndexMarker783"/>and that MicroK8s is ready to use. From the following output, we can infer that all the required add-ons are enabled:</p>
<div>
<div class="IMG---Figure" id="_idContainer227">
<img alt="Figure 9.9 – Add-ons enabled successfully " height="258" src="image/Figure_9.09_B18115.jpg" width="743"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.9 – Add-ons enabled successfully</p>
<p>We can achieve this by using the <strong class="source-inline">microk8s status</strong> command and specifying the <strong class="source-inline">--wait-ready</strong> option, which <a id="_idIndexMarker784"/>instructs MicroK8s to complete <a id="_idIndexMarker785"/>whatever processes it is currently working <a id="_idIndexMarker786"/>on before returning.</p>
<p>Now that <a id="_idIndexMarker787"/>we have a running Kubernetes cluster, let’s install Juju.</p>
<h2 id="_idParaDest-145"><a id="_idTextAnchor147"/>Step 2 – Installing Juju Operator Lifecycle Manager </h2>
<p>As we discussed previously, Juju is an OLM for the cloud, bare metal, or Kubernetes. It can be <a id="_idIndexMarker788"/>used to deploy and manage the various <a id="_idIndexMarker789"/>components that make up Kubeflow.</p>
<p>Like MicroK8s, Juju can be installed from a snap package using the following command:</p>
<p class="source-code">sudo snap install juju –-classic</p>
<p>The following output shows that the Juju snap has been installed successfully:</p>
<div>
<div class="IMG---Figure" id="_idContainer228">
<img alt="Figure 9.10 – Juju installed " height="84" src="image/Figure_9.10_B18115.jpg" width="795"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.10 – Juju installed</p>
<p>No further setup or configuration is required since the Juju OLM recognizes MicroK8s. To deploy a Juju controller to the Kubernetes session we put up with MicroK8s, all we must do is run the following command:</p>
<p class="source-code">juju bootstrap microk8s --agent-version="2.9.22"</p>
<p class="callout-heading">Note</p>
<p class="callout">In the latest versions, you can just use <strong class="source-inline">latest</strong> instead of specifying the agent version.</p>
<p>The following output shows that the Juju OLM bootstrap configuration has been successful:</p>
<div>
<div class="IMG---Figure" id="_idContainer229">
<img alt="Figure 9.11 – Juju OLM bootstrap " height="349" src="image/Figure_9.11_B18115.jpg" width="790"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.11 – Juju OLM bootstrap</p>
<p>The controller <a id="_idIndexMarker790"/>is Juju’s Kubernetes-based <a id="_idIndexMarker791"/>agent, which may be used to deploy and control Kubeflow components. The controller can work with a variety of models, which correspond to Kubernetes namespaces. Setting up a new model for Kubeflow is the recommended option:</p>
<p class="source-code">juju add-model kubeflow</p>
<p class="callout-heading">Note</p>
<p class="callout">At the time of writing, the model must be named <strong class="source-inline">kubeflow</strong>, but this is planned to be addressed in future versions.</p>
<p>The following output shows that the <strong class="source-inline">kubeflow</strong> model was added successfully:</p>
<div>
<div class="IMG---Figure" id="_idContainer230">
<img alt="Figure 9.12 – Juju model addition " height="82" src="image/Figure_9.12_B18115.jpg" width="720"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.12 – Juju model addition</p>
<p>Now that the Kubeflow model has been added, our next step is to deploy the Charmed Kubeflow bundle. Charmed Kubeflow is essentially a charm collection. Each charm deploys and controls a single application that makes up Kubeflow. You can just install the components that are required by deploying the charms individually and linking them together to create Kubeflow. However, three bundles are offered for your convenience. These bundles are essentially a recipe for a certain Kubeflow deployment, setting and connecting the applications in such a way that you end up with a working deployment with the least amount of effort.</p>
<p>The full <a id="_idIndexMarker792"/>Kubeflow bundle will necessitate <a id="_idIndexMarker793"/>a lot of resources (at least 4 CPUs, 14 GB of free RAM, and 60 GB of disk space), so starting with the <strong class="source-inline">kubeflow-lite</strong> bundle is the best alternative:</p>
<p class="source-code">juju deploy kubeflow-lite –-trust</p>
<p>The following output shows that Juju will start acquiring the apps and start deploying them to the MicroK8s Kubernetes cluster. This procedure can take quite some time but can vary based on your hardware configuration:</p>
<div>
<div class="IMG---Figure" id="_idContainer231">
<img alt="Figure 9.13 – Juju deployment " height="274" src="image/Figure_9.13_B18115.jpg" width="747"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.13 – Juju deployment</p>
<p>By running the <strong class="source-inline">juju status</strong> command, you can keep track of the deployment’s progress:</p>
<div>
<div class="IMG---Figure" id="_idContainer232">
<img alt="Figure 9.14 – Juju deployment successful " height="166" src="image/Figure_9.14_B18115.jpg" width="787"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.14 – Juju deployment successful</p>
<p>There <a id="_idIndexMarker794"/>could be error messages since many of <a id="_idIndexMarker795"/>the components rely on the operation of others, so it may take some time before everything is up and running.</p>
<p>Now the bundle has been deployed, let’s complete some of the post-installation configurations.</p>
<h2 id="_idParaDest-146"><a id="_idTextAnchor148"/>Step 3 – Post-installation configurations</h2>
<p>Some configuration needs to be set with the URL so that we have authentication and access to <a id="_idIndexMarker796"/>the dashboard service. This is dependent on the underlying network provider, but for this local deployment, we know what the URL will be for running on a local MicroK8s. The following commands can be used to configure it in Juju:</p>
<p class="source-code">juju config dex-auth public-url=http://10.64.140.43.nip.io</p>
<p class="source-code">juju config oidc-gatekeeper public-url=http://10.64.140.43.nip.io</p>
<p>The following output confirms that <strong class="source-inline">dex-auth public-url</strong> and <strong class="source-inline">oidc-gatekeeper public-url</strong> have been set successfully:</p>
<div>
<div class="IMG---Figure" id="_idContainer233">
<img alt="Figure 9.15 – Setting public-url for the dashboard service " height="90" src="image/Figure_9.15_B18115.jpg" width="670"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.15 – Setting public-url for the dashboard service</p>
<p>Run the following commands to enable basic authentication and create a username and password for the Kubeflow deployment:</p>
<p class="source-code">juju config dex-auth static-username=admin</p>
<p class="source-code">juju config dex-auth static-password=admin</p>
<p>The following output confirms that the username and password of the Kubeflow deployment have been set successfully:</p>
<div>
<div class="IMG---Figure" id="_idContainer234">
<img alt="Figure 9.16 – Setting the username and password for the Kubeflow deployment " height="73" src="image/Figure_9.16_B18115.jpg" width="600"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.16 – Setting the username and password for the Kubeflow deployment</p>
<p>With that, we have <a id="_idIndexMarker797"/>installed and configured MicroK8s. We have also deployed the Juju Charmed Operator Framework to manage apps and automate operations and also integrated all the required Kubeflow components. Finally, we configured the Kubeflow dashboard service’s authentication. Now, let’s learn how to access the Kubeflow dashboard.</p>
<h1 id="_idParaDest-147"><a id="_idTextAnchor149"/>Accessing the Kubeflow dashboard</h1>
<p>The Kubeflow <a id="_idIndexMarker798"/>dashboard gives you easy access to all the Kubeflow components installed on the cluster. Point your browser to <strong class="source-inline">http://10.64.140.43.nip.io</strong> (the URL that we set earlier) to be taken to the login screen, where we can input <strong class="source-inline">admin</strong> as the username and <strong class="source-inline">admin</strong> as the password (we set these components up previously). </p>
<p>The <strong class="bold">Welcome</strong> page should appear. Clicking <strong class="bold">Start Setup</strong> will lead you to the <strong class="bold">Create namespace</strong> screen. When you enter the namespace and click the <strong class="bold">Finish</strong> button, the dashboard will appear, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer235">
<img alt="Figure 9.17 – Kubeflow dashboard " height="601" src="image/Figure_9.17_B18115.jpg" width="1185"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.17 – Kubeflow dashboard</p>
<p>Great! We have <a id="_idIndexMarker799"/>just installed Kubeflow.</p>
<p>Now that Kubeflow has been installed and is operational, let’s learn how to translate an ML model into a Kubeflow pipeline.</p>
<h1 id="_idParaDest-148"><a id="_idTextAnchor150"/>Creating a Kubeflow pipeline to build, train, and deploy a sample ML model</h1>
<p>In this <a id="_idIndexMarker800"/>section, we will be using the <a id="_idIndexMarker801"/>Fashion MNIST dataset and TensorFlow’s <a id="_idIndexMarker802"/>Basic classification to build <a id="_idIndexMarker803"/>the pipeline step by step <a id="_idIndexMarker804"/>and turn the example ML <a id="_idIndexMarker805"/>model into a Kubeflow pipeline.</p>
<p>Before <a id="_idIndexMarker806"/>deploying Kubeflow, we will look at the dataset that we are going to use. Fashion-MNIST (<a href="https://github.com/zalandoresearch/fashion-mnist">https://github.com/zalandoresearch/fashion-mnist</a>) is a Zalando article image dataset that includes a training set of 60,000 samples and a test set of 10,000 examples. Each sample is a 28 x 28 grayscale image with a label from one of 10 categories.</p>
<p>Each <a id="_idIndexMarker807"/>training <a id="_idIndexMarker808"/>or test <a id="_idIndexMarker809"/>item in <a id="_idIndexMarker810"/>the dataset <a id="_idIndexMarker811"/>is assigned to one of <a id="_idIndexMarker812"/>the following labels:</p>
<div>
<div class="IMG---Figure" id="_idContainer236">
<img alt="Table 9.1 – Categories in the Fashion MNIST dataset " height="380" src="image/B18115_Table_9.1a.jpg" width="1650"/>
</div>
</div>
<div>
<div class="IMG---Figure" id="_idContainer237">
<img alt="Table 9.1 – Categories in the Fashion MNIST dataset " height="497" src="image/B18115_Table_9.1b.jpg" width="667"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 9.1 – Categories in the Fashion MNIST dataset</p>
<p>Now that our dataset is ready, we can launch a new notebook server via the Kubeflow dashboard.</p>
<h2 id="_idParaDest-149"><a id="_idTextAnchor151"/>Step 1 – launching a new notebook server from the Kubeflow dashboard</h2>
<p>You can <a id="_idIndexMarker813"/>start a new notebook <a id="_idIndexMarker814"/>by clicking <strong class="bold">New Server</strong> on the <strong class="bold">Notebook Servers</strong> tab. Select a Docker <strong class="bold">Image</strong> for the notebook server and give it a <strong class="bold">Name</strong>. Choose the appropriate <strong class="bold">CPU</strong>, <strong class="bold">RAM</strong>, and <strong class="bold">Workspace volume</strong> values and click <strong class="bold">Launch</strong>.</p>
<p>To browse the web interface that’s been exposed by your server, click <strong class="bold">CONNECT</strong>:</p>
<div>
<div class="IMG---Figure" id="_idContainer238">
<img alt="Figure 9.18 – Launch new notebook server " height="227" src="image/Figure_9.18_B18115.jpg" width="1132"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.18 – Launch new notebook server</p>
<p>Ensure that <strong class="bold">Allow access to Kubeflow Pipelines</strong> is enabled on the new notebook so that we can use the Kubeflow Pipelines SDK in the next step:</p>
<div>
<div class="IMG---Figure" id="_idContainer239">
<img alt="Figure 9.19 – New notebook configurations " height="168" src="image/Figure_9.19_B18115.jpg" width="783"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.19 – New notebook configurations</p>
<p>Launch a new terminal from the right-hand menu (<strong class="bold">New</strong> | <strong class="bold">Terminal</strong>) while you’re in the notebook server. Download the notebook from GitHub in the terminal using the following <strong class="source-inline">git</strong> command:</p>
<p class="source-code">$ git clone https://github.com/manceps/manceps-canonical.git</p>
<p>This will clone and open the <strong class="source-inline">KF_Fashion_MNIST</strong> notebook, as shown in the following screenshot:</p>
<div>
<div class="IMG---Figure" id="_idContainer240">
<img alt="Figure 9.20 – Fashion MNIST notebook " height="431" src="image/Figure_9.20_B18115.jpg" width="702"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.20 – Fashion MNIST notebook</p>
<p>In <strong class="bold">Section 1</strong> of <a id="_idIndexMarker815"/>the notebook, we <a id="_idIndexMarker816"/>can familiarize ourselves with the dataset that we have; we’ll perform a quick analysis by exploring the data. Here’s a quick refresher on the dataset:</p>
<ul>
<li>There are 60,000 training labels and 10,000 test labels</li>
<li>Each label corresponds to one of the 10 class names and is a number between 0 and 9</li>
</ul>
<p>Before starting any form of analysis, it’s always a good idea to comprehend the data. In <strong class="source-inline">section 1.4</strong> of the notebook, we will preprocess the data – that is, the data must be normalized so that each value falls between 0 and 1 to successfully train the model.</p>
<p>The following screenshot shows that the values are between 0 and 255:</p>
<div>
<div class="IMG---Figure" id="_idContainer241">
<img alt="Figure 9.21 – The first image from the dataset " height="121" src="image/Figure_9.21_B18115.jpg" width="538"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.21 – The first image from the dataset</p>
<p>In the <a id="_idIndexMarker817"/>next step, we must <a id="_idIndexMarker818"/>divide the training and test values by <strong class="source-inline">255</strong> to scale the data. It’s critical that the training and testing sets are both preprocessed the same way:</p>
<div>
<div class="IMG---Figure" id="_idContainer242">
<img alt="Figure 9.22 – Dividing the training and test values by 255 " height="85" src="image/Figure_9.22_B18115.jpg" width="531"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.22 – Dividing the training and test values by 255</p>
<p>The following is the execution output from the Jupyter notebook for the preceding code:</p>
<div>
<div class="IMG---Figure" id="_idContainer243">
<img alt="Figure 9.23 – Preprocessing the data " height="288" src="image/Figure_9.23_B18115.jpg" width="573"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.23 – Preprocessing the data</p>
<p>Let’s inspect the first 25 images from the training set, together with the class name, to make <a id="_idIndexMarker819"/>sure the data is in the <a id="_idIndexMarker820"/>right format. Then, we will be ready to build and train the network:</p>
<div>
<div class="IMG---Figure" id="_idContainer244">
<img alt="Figure 9.24 – Plot for the first 25 images from the training set " height="181" src="image/Figure_9.24_B18115.jpg" width="560"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.24 – Plot for the first 25 images from the training set</p>
<p>The following is the output from the Jupyter notebook for the preceding code:</p>
<div>
<div class="IMG---Figure" id="_idContainer245">
<img alt="Figure 9.25 – Inspecting 25 images from the training set " height="572" src="image/Figure_9.25_B18115.jpg" width="573"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.25 – Inspecting 25 images from the training set</p>
<p>Now <a id="_idIndexMarker821"/>that the data has been <a id="_idIndexMarker822"/>preprocessed, we can build the model. </p>
<p>The TensorFlow <a id="_idIndexMarker823"/>model we’re working on is an example of basic classification<strong class="bold"> </strong>(<a href="https://www.tensorflow.org/tutorials/keras/classification">https://www.tensorflow.org/tutorials/keras/classification</a>).</p>
<h2 id="_idParaDest-150"><a id="_idTextAnchor152"/>Step 2 – creating a Kubeflow pipeline</h2>
<p>We will be <a id="_idIndexMarker824"/>using the Kubeflow Pipelines SDK, which is a set of Python packages for specifying and running ML workflows. A pipeline is a description of an ML workflow that includes all the components that make up the steps in the workflow, as well as how they interact.</p>
<p>Install the Kubeflow Pipelines SDK (<strong class="source-inline">kfp</strong>) in the current userspace to ensure that you have access to the necessary packages in your Jupyter notebook instance:</p>
<div>
<div class="IMG---Figure" id="_idContainer246">
<img alt="Figure 9.26 – Installing the Kubeflow Pipelines SDK " height="44" src="image/Figure_9.26_B18115.jpg" width="489"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.26 – Installing the Kubeflow Pipelines SDK</p>
<p>Now that we have installed the Kubeflow Pipelines SDK, the next step is to create Python scripts for Docker containers using <strong class="source-inline">func_to_container_op</strong>.</p>
<p>To package <a id="_idIndexMarker825"/>our Python code inside containers, we must create a standard Python function that contains a logical step in your pipeline. In this case, two functions have been defined: <strong class="source-inline">train</strong> and <strong class="source-inline">predict.</strong> Our model will be trained, evaluated, and saved by the train component (refer to <strong class="source-inline">Section 2.2</strong> in the notebook):</p>
<div>
<div class="IMG---Figure" id="_idContainer247">
<img alt="Figure 9.27 – Model trained and saved " height="233" src="image/Figure_9.27_B18115.jpg" width="618"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.27 – Model trained and saved</p>
<p>The layers of the neural network must be configured before the model can be compiled. The layers are the most fundamental components of a neural network. Data is put into layers, and then representations are extracted from it:</p>
<div>
<div class="IMG---Figure" id="_idContainer248">
<img alt="Figure 9.28 – Neural network layers to be configured " height="72" src="image/Figure_9.28_B18115.jpg" width="588"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.28 – Neural network layers to be configured</p>
<p>The predict component takes the model and applies it to an image from the test dataset to create a prediction:</p>
<div>
<div class="IMG---Figure" id="_idContainer249">
<img alt="Figure 9.29 – Predicting from the test dataset " height="207" src="image/Figure_9.29_B18115.jpg" width="683"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.29 – Predicting from the test dataset</p>
<p>Our final <a id="_idIndexMarker826"/>step is to convert these functions into container components. The <strong class="source-inline">func_to_container_op</strong> method can be used to accomplish this:</p>
<div>
<div class="IMG---Figure" id="_idContainer250">
<img alt="Figure 9.30 – Converting Python scripts into Docker containers " height="79" src="image/Figure_9.30_B18115.jpg" width="851"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.30 – Converting Python scripts into Docker containers</p>
<p>After converting Python scripts into Docker containers, the next step is to define a Kubeflow pipeline.</p>
<p>Kubeflow makes use of YAML templates to define Kubernetes resources. Without having to manually alter YAML files, the Kubeflow Pipelines SDK allows you to describe how our code is run. It generates a compressed YAML file that defines our pipeline at compile time. This file can then be reused or shared in the future, making the workflow scalable and repeatable.</p>
<p>Our first step is to launch a Kubeflow client, which includes client libraries for the Kubeflow Pipelines API, allowing us to construct more experiments and run within those experiments directly from the Jupyter notebook:</p>
<div>
<div class="IMG---Figure" id="_idContainer251">
<img alt="Figure 9.31 – Launching the Kubeflow client " height="48" src="image/Figure_9.31_B18115.jpg" width="654"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.31 – Launching the Kubeflow client</p>
<p>The preceding components build a client to communicate with the pipeline's API server. The next step will be to design the pipeline’s various components.</p>
<p>The pipeline function has been defined, and it contains several parameters that will be passed to our various components during execution. Kubeflow Pipelines are built declaratively. This means that the code will not be executed until the pipeline has been compiled:</p>
<div>
<div class="IMG---Figure" id="_idContainer252">
<img alt="Figure 9.32 – Defining the pipeline " height="480" src="image/Figure_9.32_B18115.jpg" width="874"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.32 – Defining the pipeline</p>
<p>To save and <a id="_idIndexMarker827"/>persist data between components, a Persistent Volume Claim can be quickly created using the <strong class="source-inline">VolumeOp</strong> method. </p>
<p><strong class="source-inline">VolumeOp</strong>’s <a id="_idIndexMarker828"/>parameters include the following:</p>
<ul>
<li><strong class="source-inline">name</strong>: The name that’s displayed for the volume creation operation </li>
<li><strong class="source-inline">resource_name</strong>: The name that can be referenced by other resources</li>
<li><strong class="source-inline">size</strong>: The size of the volume claim</li>
<li><strong class="source-inline">modes</strong>: The access mode for the volume </li>
</ul>
<p>It’s finally time to define our pipeline’s components and dependencies. This can be accomplished using <strong class="source-inline">ContainerOp</strong>, an object that defines a pipeline component from a container:</p>
<div>
<div class="IMG---Figure" id="_idContainer253">
<img alt="Figure 9.33 – Creating the training and prediction components " height="136" src="image/Figure_9.33_B18115.jpg" width="751"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.33 – Creating the training and prediction components</p>
<p>The <strong class="source-inline">train_op</strong> and <strong class="source-inline">predict_op</strong> components accept arguments from the original Python function. We attach our <strong class="source-inline">VolumeOp</strong> at the end of the function with a dictionary of paths and associated Persistent Volumes to be mounted to the container before execution.</p>
<p>While <strong class="source-inline">train_op</strong> is using the <strong class="source-inline">pvolumes</strong> dictionary’s <strong class="source-inline">vop.volume</strong> value, <strong class="source-inline">&lt;Container Op&gt;</strong>, the <strong class="source-inline">pvolume</strong> argument, which is used by the other components, ensures that <a id="_idIndexMarker829"/>the volume from the previous <strong class="source-inline">ContainerOp</strong> is used instead of creating a new one:</p>
<div>
<div class="IMG---Figure" id="_idContainer254">
<img alt="Figure 9.34 – Attaching a volume to the container " height="132" src="image/Figure_9.34_B18115.jpg" width="644"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.34 – Attaching a volume to the container</p>
<p>ContainerOp’s parameters <a id="_idIndexMarker830"/>include the following:</p>
<ul>
<li><strong class="source-inline">name</strong>: The name displayed for the component’s execution during runtime</li>
<li><strong class="source-inline">image</strong>: The image tag for the Docker container to be used</li>
<li><strong class="source-inline">pvolumes</strong>: A dictionary of paths and associated <em class="italic">Persistent Volumes</em> to be mounted to the container before execution</li>
<li><strong class="source-inline">arguments</strong>: The command to be run by the container at runtime</li>
</ul>
<p>Now that we’ve created separate components for training and prediction, we can start compiling and running the pipeline code in the notebook.</p>
<h2 id="_idParaDest-151"><a id="_idTextAnchor153"/>Step 3 – compiling and running</h2>
<p>Finally, it’s time to compile and run the pipeline code in the notebook. The notebook specifies <a id="_idIndexMarker831"/>the name of the run and the experiment (a group of runs), which is <a id="_idIndexMarker832"/>then displayed in the Kubeflow dashboard. By clicking on the notebook’s run link , you can see the pipeline running in the Kubeflow Pipelines UI:</p>
<div>
<div class="IMG---Figure" id="_idContainer255">
<img alt="Figure 9.35 – Compiling and running the pipeline " height="297" src="image/Figure_9.35_B18115.jpg" width="735"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.35 – Compiling and running the pipeline</p>
<p>Now that the pipeline has been created and set to run, we can look at its results. By clicking on the notebook’s run link, we can get to the Kubeflow Pipelines dashboard. The pipeline’s defined components will be displayed. The path of the data pipeline will be updated as they complete:</p>
<div>
<div class="IMG---Figure" id="_idContainer256">
<img alt="Figure 9.36 – Kubeflow Pipelines dashboard " height="265" src="image/Figure_9.36_B18115.jpg" width="667"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.36 – Kubeflow Pipelines dashboard</p>
<p>To view the <a id="_idIndexMarker833"/>details of a component, we can click on it directly <a id="_idIndexMarker834"/>and navigate through a few tabs. To view the logs that were generated while running the component, go to the <strong class="bold">Logs</strong> tab:</p>
<div>
<div class="IMG---Figure" id="_idContainer257">
<img alt="Figure 9.37 – Model training logs " height="248" src="image/Figure_9.37_B18115.jpg" width="777"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.37 – Model training logs</p>
<p>The loss and accuracy metrics are displayed as the model trains. On the training data, the model achieves an accuracy of about 0.91 (or 91%), as shown in <em class="italic">Figure 9.37</em>.</p>
<p>Once the <strong class="source-inline">echo_result</strong> component has finished executing, you can inspect the component’s logs to see what happened. It will show the class of the image being predicted, the model’s confidence in its prediction, and the image’s actual label:</p>
<div>
<div class="IMG---Figure" id="_idContainer258">
<img alt="Figure 9.38 – Final prediction result from the pipeline " height="186" src="image/Figure_9.38_B18115.jpg" width="454"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.38 – Final prediction result from the pipeline</p>
<p>With that, we have <a id="_idIndexMarker835"/>made use of the Fashion MNIST dataset and <a id="_idIndexMarker836"/>TensorFlow’s Basic classification to turn the example model into a Kubeflow pipeline.</p>
<p>Now, let’s look at the best practices for running AI/ML workloads on Kubernetes. </p>
<h1 id="_idParaDest-152"><a id="_idTextAnchor154"/>Recommendations – running AL/ML workloads on Kubernetes </h1>
<p>If you’re a data scientist or ML engineer, you’re probably thinking about how to deploy your ML <a id="_idIndexMarker837"/>models efficiently. You would essentially look for ways to scale models, distribute them across server clusters, and optimize <a id="_idIndexMarker838"/>model performance with a variety of techniques.</p>
<p>These are all tasks that Kubernetes is very good at. But Kubernetes was not designed to be an ML deployment platform. However, as more data scientists turn to Kubernetes to run their models, Kubernetes and ML are becoming popular stacks. </p>
<p>As a platform for training and deploying ML models, Kubernetes provides several key advantages. To understand those benefits, let’s compare some of the major challenges and Kubernetes solution offerings:</p>
<div>
<div class="IMG---Figure" id="_idContainer259">
<img alt="Table 9.2 – Kubernetes solution offerings " height="1433" src="image/B18115_Table_9.2a.jpg" width="1643"/>
</div>
</div>
<div>
<div class="IMG---Figure" id="_idContainer260">
<img alt="Table 9.2 – Kubernetes solution offerings " height="1605" src="image/B18115_Table_9.2b.jpg" width="1638"/>
</div>
</div>
<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Table 9.2 – Kubernetes solution offerings</p>
<p>Kubernetes <a id="_idIndexMarker839"/>helps offset some of the most <a id="_idIndexMarker840"/>significant challenges that data scientists face when running models at scale in each of these ways. Now, let’s look at some of the best practices for running AI/ML workloads.</p>
<h2 id="_idParaDest-153"><a id="_idTextAnchor155"/>Best practices for running AI/ML workloads </h2>
<p>As ML progresses from research to practical applications, we must improve the maturity of its <a id="_idIndexMarker841"/>operational processes. To crack these challenges, we’ll need to integrate DevOps and data engineering methods, as well as ones that are specific to ML. </p>
<p>MLOps blends ML, DevOps, and data engineering into a set of approaches. MLOps seeks to deploy and manage ML systems in production reliably and efficiently. The following are some of MLOps’s main practices:</p>
<ul>
<li><strong class="bold">Data Pipelines</strong>: ML models always require some type of data transformation, which <a id="_idIndexMarker842"/>is typically accomplished through scripts or even cells in a notebook, making them difficult to manage and run consistently. Creating a separate data pipeline offers numerous benefits in terms of code reuse, runtime visibility, management, and scalability.</li>
<li><strong class="bold">Pipeline Versions</strong>: Most ML models require two pipeline versions: one for training <a id="_idIndexMarker843"/>and one for serving. This is because data formats and the methods for accessing them are typically very different from each other, particularly for models that need to be served in real-time requests (as opposed to batch prediction runs). The ML pipeline should be a pure code artifact that is independent of any specific data. This means that it is possible to track its versions in source control and automate its deployment with a regular CI/CD pipeline. This would enable us to connect the code and data planes in a structured and automated manner.</li>
<li><strong class="bold">Multiple Pipelines</strong>: At this point, it’s clear that there are two types of ML pipelines: training <a id="_idIndexMarker844"/>pipelines and serving pipelines. They have one thing in common: the data transformations that are performed must produce data in the same format, but their implementations can differ greatly. For example, the training pipeline typically runs over batch files containing all features, whereas the serving pipeline frequently runs online and receives only a portion of the features in the requests, retrieving the remainder from a database. It is critical, however, to ensure that these two pipelines are consistent, so code and data should be reused whenever possible.</li>
<li><strong class="bold">Model and Data Versioning</strong>: Consistent version tracking is essential for reproducibility. In a traditional software world, versioning code is sufficient because <a id="_idIndexMarker845"/>it defines all behavior. In ML, we must also keep track of model versions, as well as the data used to train them and some meta information such as training hyperparameters. It’s also necessary to version the data and associate each trained model with the exact versions of code, data, and hyperparameters that we used.</li>
<li><strong class="bold">Model Validation</strong>: To determine whether a model is suitable for deployment, the right <a id="_idIndexMarker846"/>metrics to track and the threshold of acceptable values must be determined, usually empirically and frequently compared to previous models or benchmarks.</li>
<li><strong class="bold">Data Validation</strong>: A good data pipeline will typically begin by validating the input data. File format and size, column types, null or empty values, and invalid values are <a id="_idIndexMarker847"/>all common validations. All of these are required for ML training and prediction; otherwise, you may have a misbehaving model. Higher-level statistical properties of the input should also be validated by ML pipelines. For example, if the average or standard deviation of a feature varies significantly from one training dataset to the next, the trained model and its predictions will most likely be affected.</li>
<li><strong class="bold">Monitoring</strong>: Monitoring becomes important for ML systems because their performance <a id="_idIndexMarker848"/>is dependent not only on factors over which we have some control, such as infrastructure and our software, but also on data, over which we have much less control. In addition to standard metrics such as latency, traffic, errors, and saturation, we must also monitor model prediction performance. To detect problems that affect specific segments, we must monitor metrics across slices (rather than just globally), just as we do when validating the model.</li>
</ul>
<p>To summarize, deploying ML in a production context entails more than just publishing the model as a prediction API. Rather, it entails establishing an ML pipeline capable of automating <a id="_idIndexMarker849"/>the retraining and deployment <a id="_idIndexMarker850"/>of new models. Setting up a CI/CD system allows you to test and release new pipeline implementations automatically. This system enables us to deal with quick data and business environment changes. MLOps, as a new area, is quickly gaining traction among data scientists, ML engineers, and AI enthusiasts.</p>
<h1 id="_idParaDest-154"><a id="_idTextAnchor156"/>Summary</h1>
<p>To summarize, Kubeflow provides an easy-to-deploy, easy-to-use toolchain that will allow data scientists to integrate the various resources they will need to run models on Kubernetes, such as Jupyter Notebooks, Kubernetes deployment files, and ML libraries such as PyTorch and TensorFlow.</p>
<p>Another popular ML task that Kubeflow considerably simplifies is working with Jupyter Notebooks. You can build notebooks and share them with your team or teams using Kubeflow’s built-in notebook services, which you can access via the UI. In this chapter, we learned how to set up an ML pipeline that will develop and deploy an example model using the Kubeflow ML platform. We also recognized that Kubeflow on MicroK8s is easy to set up and configure, as well as lightweight and capable of simulating real-world conditions while constructing, migrating, and deploying pipelines.</p>
<p>In the next chapter, you will learn how to deploy and run serverless applications using the Knative and OpenFaaS frameworks.</p>
</div>
<div>
<div id="_idContainer262">
</div>
</div>
</div>
</body></html>