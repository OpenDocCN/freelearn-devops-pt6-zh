<html><head></head><body>
		<div id="_idContainer348">
			<h1 id="_idParaDest-145"><em class="italic"><a id="_idTextAnchor144"/>Chapter 10</em>: Building, Deploying, and Monitoring Your Model</h1>
			<p>In the previous chapter, you built the data pipeline and created a basic flight dataset that can be used by your data science team. In this chapter, your data science team will use the flight dataset to build a <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) model. The model will be used to predict the on-time performance of the flights.</p>
			<p>In this chapter, you will see how the platform assists you in visualizing and experimenting with the data to build the right model. You will see how to tune hyperparameters and compare the results of different runs of model training. You will see how to register and version models using the components provided by the platform. You will deploy the model as a REST service and start monitoring the deployed model using the components provided by the platform.</p>
			<p>Remember that this book is not about data science, instead, the focus is on enabling teams to work autonomously and efficiently. You may see some concepts and steps being repeated from earlier chapters. This is intentional to show you how the concepts provided in the previous chapters help you build a full life cycle.</p>
			<p>Keeping the goal in mind, you will learn about the following topics:</p>
			<ul>
				<li>Visualizing and exploring data using JupyterHub</li>
				<li>Building and tuning your model using JupyterHub</li>
				<li>Tracking model experiments and versioning using MLflow</li>
				<li>Deploying your model as a service via Seldon and Airflow</li>
				<li>Monitoring your model using Prometheus and Grafana</li>
			</ul>
			<h1 id="_idParaDest-146"><a id="_idTextAnchor145"/>Technical requirements</h1>
			<p>This chapter includes some hands-on setup and exercises. You will need a running Kubernetes cluster configured with the <strong class="bold">Operator Lifecycle Manager</strong> (<strong class="bold">OLM</strong>). Building such a Kubernetes environment is covered in <a href="B18332_03_ePub.xhtml#_idTextAnchor040"><em class="italic">Chapter 3</em></a>, <em class="italic">Exploring Kubernetes</em>. Before attempting the technical exercises in this chapter, please make sure that you have a working Kubernetes cluster and <strong class="bold">Open Data Hub</strong> (<strong class="bold">ODH</strong>) is installed on your Kubernetes cluster. Installing ODH is covered in <a href="B18332_04_ePub.xhtml#_idTextAnchor055"><em class="italic">Chapter 4</em></a>, <em class="italic">The Anatomy of a Machine Learning Platform</em>.</p>
			<h1 id="_idParaDest-147"><a id="_idTextAnchor146"/>Visualizing and exploring data using JupyterHub</h1>
			<p>Recall<a id="_idIndexMarker864"/> from <a href="B18332_09_ePub.xhtml#_idTextAnchor132"><em class="italic">Chapter 9</em></a>, <em class="italic">Building Your Data Pipeline</em>, that<a id="_idIndexMarker865"/> the data engineer has worked with the SME of the business and prepared the flight data that can be used to predict the flights' on-time performance. </p>
			<p>In this section, you will understand the data produced by the data engineering team. This is the role of the data scientist who is responsible for building the model. You will see how the platform enables your data science and data engineering teams to collaborate and how the data scientist can use the platform to build a model for the given problem.</p>
			<p>Let's do some base data exploring using the platform. Keep in mind that the focus of this book is to enable your team to work efficiently. The focus is not on data science or data engineering but on building and using the platform:</p>
			<ol>
				<li>Launch JupyterHub, but this time select the image that is relative to the data science life cycle. SciKit is one such image available on the platform. Do not click on the <strong class="bold">Start server</strong> button just yet.</li>
			</ol>
			<div>
				<div id="_idContainer289" class="IMG---Figure">
					<img src="image/B18332_10_001.jpg" alt="Figure 10.1 – JupyterHub landing page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.1 – JupyterHub landing page</p>
			<ol>
				<li value="2">On<a id="_idIndexMarker866"/> the<a id="_idIndexMarker867"/> JupyterHub landing page, add an <strong class="source-inline">AWS_SECRET_ACCESS_KEY</strong> variable and populate it with the password for your S3 environment. The value for this key for this exercise would be <strong class="source-inline">minio123</strong>. Notice that we have used the <strong class="bold">Medium</strong> container size to accommodate the dataset. Now, hit the <strong class="bold">Start server</strong> button to start your JupyterHub IDE.</li>
			</ol>
			<div>
				<div id="_idContainer290" class="IMG---Figure">
					<img src="image/B18332_10_002.jpg" alt="Figure 10.2 – JupyterHub landing page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.2 – JupyterHub landing page</p>
			<ol>
				<li value="3">Open the <strong class="source-inline">chapter10/visualize.ipynb</strong> file notebook in your JupyterHub IDE.</li>
				<li>The first <a id="_idIndexMarker868"/>step<a id="_idIndexMarker869"/> is to read the data provided by the data engineering team. Note that the data is available on the same platform, which improves the velocity of the teams. <em class="italic">Cell 2</em> in the notebook is using the <strong class="source-inline">PyArrow</strong> library to read the data as a pandas data frame. You will read the data from the <strong class="source-inline">flights-data</strong> bucket, where data is placed by the data team. You can see the data read code as follows:</li>
			</ol>
			<div>
				<div id="_idContainer291" class="IMG---Figure">
					<img src="image/B18332_10_003.jpg" alt="Figure 10.3 – Cell 2 for the chapter10/visualize notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.3 – Cell 2 for the chapter10/visualize notebook</p>
			<ol>
				<li value="5">The first thing you will do is to look at the data. Trying to make sense of it and familiarizing yourself with what is available can be the ideal take here. You can see in <em class="italic">Cell 3</em> that the DataFrame's <strong class="source-inline">head</strong> function has been used to see the first few rows. You will notice the field names and the data in them and see whether you can understand one record. Notice that some fields are <strong class="source-inline">NaN</strong> and some are <strong class="source-inline">None</strong>. This gives you a clue that the dataset may not yet be ready for building models. The<a id="_idIndexMarker870"/> following <a id="_idIndexMarker871"/>screen captures partial output, and it is expected that you run this code in your environment to get the full picture:</li>
			</ol>
			<div>
				<div id="_idContainer292" class="IMG---Figure">
					<img src="image/B18332_10_004.jpg" alt="Figure 10.4 – Cell 3 for the chapter10/visualize notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.4 – Cell 3 for the chapter10/visualize notebook</p>
			<ol>
				<li value="6">The next stage is to do a simple verification to see how much data is available for you and if you are reading all the records. You can see in <em class="italic">Cell 4</em> that the DataFrame's <strong class="source-inline">count</strong> function has been used for this. The following screen captures partial output, and it is expected that you run this code in your environment to get the full picture:</li>
			</ol>
			<div>
				<div id="_idContainer293" class="IMG---Figure">
					<img src="image/B18332_10_005.jpg" alt="Figure 10.5 – Cell 4 for the chapter10/visualize notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.5 – Cell 4 for the chapter10/visualize notebook</p>
			<ol>
				<li value="7"><em class="italic">Cells 5</em> and <em class="italic">6</em> are<a id="_idIndexMarker872"/> using <a id="_idIndexMarker873"/>the DataFrame's shape and the columns' functions are self-explanatory. </li>
				<li><em class="italic">Cell 7</em> is using the DataFrame's <strong class="source-inline">describe</strong> function to generate some basic statistics for the dataset. You may use this to verify whether there is some data that may not make sense. An example could be an exceedingly high value as maximum for the <strong class="source-inline">taxi_in</strong> time. In such cases, you will work with your SME to clarify and adjust the records as needed. The following screen captures partial output, and it is expected that you run this code in your environment to get the full picture:</li>
			</ol>
			<div>
				<div id="_idContainer294" class="IMG---Figure">
					<img src="image/B18332_10_006.jpg" alt="Figure 10.6 – Cell 7 for the chapter10/visualize notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.6 – Cell 7 for the chapter10/visualize notebook</p>
			<ol>
				<li value="9">Next, you want to see whether the data has null values. You have seen in <em class="italic">Step 3</em>, that there are some <strong class="source-inline">NaN</strong> and <strong class="source-inline">None</strong> values in the data. You have found out that there are many columns with missing data problems. The following screen captures <a id="_idIndexMarker874"/>partial <a id="_idIndexMarker875"/>output, and it is expected that you run this code in your environment to get the full picture:</li>
			</ol>
			<div>
				<div id="_idContainer295" class="IMG---Figure">
					<img src="image/B18332_10_007.jpg" alt="Figure 10.7 – Cell 8 for the chapter10/visualize notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.7 – Cell 8 for the chapter10/visualize notebook</p>
			<ol>
				<li value="10">You will use the Dataframe's <strong class="source-inline">isnull</strong> function to find out how many records have this missing data. Using the output from the <strong class="source-inline">df.isnull().sum().sort_values(ascending = False)</strong> code, there are two different groups. The first six rows of the output show column names that have a very high missing data rate and for these columns, you may talk to data engineering and the SME to find resources from where you can fetch the data for them. For our example, we will just drop these columns. </li>
			</ol>
			<div>
				<div id="_idContainer296" class="IMG---Figure">
					<img src="image/B18332_10_008.jpg" alt="Figure 10.8 – Cell 9 for the chapter10/visualize notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.8 – Cell 9 for the chapter10/visualize notebook</p>
			<ol>
				<li value="11">In the <a id="_idIndexMarker876"/>second <a id="_idIndexMarker877"/>group, starting from the <strong class="source-inline">wheels_on</strong> column, you may either choose to drop the rows containing no data or try to fill the data with a suitable statistics function. For example, the missing <strong class="source-inline">taxi_in</strong> columns could be the mean for the same airport and same time. The strategy must be discussed with the team. For this exercise, we will just drop the rows.</li>
			</ol>
			<div>
				<div id="_idContainer297" class="IMG---Figure">
					<img src="image/B18332_10_009.jpg" alt="Figure 10.9 – Cell 9 for the chapter10/visualize notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.9 – Cell 9 for the chapter10/visualize notebook</p>
			<ol>
				<li value="12">Often, it is a good idea to investigate sample rows where a particular column has no data. You may find a pattern in the data that could be extremely useful in further understanding the data. You have chosen to see the rows where the <strong class="source-inline">tail_number</strong> field has no value and see whether you can find any patterns. The <a id="_idIndexMarker878"/>following<a id="_idIndexMarker879"/> screen captures partial output, and it is expected that you run this code in your environment to get the full picture:</li>
			</ol>
			<div>
				<div id="_idContainer298" class="IMG---Figure">
					<img src="image/B18332_10_010.jpg" alt="Figure 10.10 – Cell 10 for the chapter10/visualize notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.10 – Cell 10 for the chapter10/visualize notebook</p>
			<ol>
				<li value="13">You will then run the Dataframe's <strong class="source-inline">info</strong> function to find out the data types of the columns. A lot of times, the data types of columns are not the ones that you are expecting. You will then talk to the SME and data teams to improve the data quality. The following screen captures partial output, and it is expected that you run this code in your environment to get the full picture:</li>
			</ol>
			<div>
				<div id="_idContainer299" class="IMG---Figure">
					<img src="image/B18332_10_011.jpg" alt="Figure 10.11 – Cell 11 for the chapter10/visualize notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.11 – Cell 11 for the chapter10/visualize notebook</p>
			<ol>
				<li value="14">Visualization<a id="_idIndexMarker880"/> is <a id="_idIndexMarker881"/>one particularly important tool to understand data. You can use any of the libraries that you feel comfortable with. For example, in the last cell of this notebook, you build a graph to find out the data distribution for the <strong class="source-inline">DELAYED</strong> column. Imagine that 99% of the records are with the <strong class="source-inline">DELAYED</strong> column as <strong class="source-inline">0</strong>. If that is the case, the data may not be enough to predict the flights' on-time performance and you will need to engage the SME and data teams to get more data. For this exercise, we will use the existing data distribution.</li>
			</ol>
			<div>
				<div id="_idContainer300" class="IMG---Figure">
					<img src="image/B18332_10_012.jpg" alt="Figure 10.12 – Cell 12 for the chapter10/visualize notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.12 – Cell 12 for the chapter10/visualize notebook</p>
			<p>Now that we understand flight data a bit better, let's start building our model. In the real world, you <a id="_idIndexMarker882"/>would invest a lot more<a id="_idIndexMarker883"/> time to understand the data. The focus of this book is to show you how to execute the model development life cycle and so we kept the examples to a minimum.</p>
			<h1 id="_idParaDest-148"><a id="_idTextAnchor147"/>Building and tuning your model using JupyterHub</h1>
			<p>As a data <a id="_idIndexMarker884"/>scientist, you will want to try different <a id="_idIndexMarker885"/>models with different parameters to find the right fit. Before you start building the model, recall from <a href="B18332_08_ePub.xhtml#_idTextAnchor116"><em class="italic">Chapter 8</em></a>, <em class="italic">Building a Complete ML Project Using the Platform</em>, that you need to define the evaluation criteria, and that <strong class="bold">accuracy</strong> may be a misleading criterion for a lot of use cases.</p>
			<p>For the flight use case, let's assume that your team and the SME agree on the <strong class="bold">PRECISION</strong> metric. Note that precision measures the portion of correct positive identification in the provided dataset.</p>
			<p>Let's start writing our model and see how the platform enables data scientists to perform their work efficiently:</p>
			<ol>
				<li value="1">Open the <strong class="source-inline">chapter10/experiments.ipynb</strong> file notebook in your JupyterHub environment.</li>
				<li>In <em class="italic">Cell 2</em>, add the connection information to MLflow. Recall that MLflow is the component in the platform that records the model experiments and works as the model registry. In the code, you will configure <strong class="source-inline">EXPERIMENT_NAME</strong>, which provides a name for your experiment runs. The last line of this cell mentions how MLflow will record the experiment run. The <strong class="source-inline">autolog</strong> feature enables MLflow to register automatic callbacks during training to record the parameters for later use.</li>
			</ol>
			<p>You<a id="_idIndexMarker886"/> also<a id="_idIndexMarker887"/> provide the configuration for the S3 bucket, which will be used by MLflow to store the artifacts of your experiments:</p>
			<div>
				<div id="_idContainer301" class="IMG---Figure">
					<img src="image/B18332_10_013.jpg" alt="Figure 10.13 – Cell 2 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.13 – Cell 2 for the chapter10/experiments notebook</p>
			<ol>
				<li value="3"><em class="italic">Cell 3</em> reads the data available from the data engineering team, and <em class="italic">Cell 4</em> is again providing the information on the missing data from multiple columns. In this notebook, you will use this information to drop the columns that you do not find useful. The following screen captures partial output, and it is expected that you run this code in your environment to get the full picture:</li>
			</ol>
			<div>
				<div id="_idContainer302" class="IMG---Figure">
					<img src="image/B18332_10_014.jpg" alt="Figure 10.14 – Cell 3 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.14 – Cell 3 for the chapter10/experiments notebook</p>
			<ol>
				<li value="4"><em class="italic">Cell 5</em> is <a id="_idIndexMarker888"/>dropping<a id="_idIndexMarker889"/> two sets of columns. The first set drops the columns for which you do not have data in most of the rows. You selected these columns based on the previous step. We kept it simple here and dropped the columns; however, it is highly recommended that you work with data teams to find the reason for this anomaly and aim to get as much data as possible. The columns you are dropping are <strong class="source-inline">"cancellation_reason"</strong>, <strong class="source-inline">"late_aircraft_delay"</strong>, <strong class="source-inline">"weather_delay"</strong>, <strong class="source-inline">"airline_delay"</strong>, <strong class="source-inline">"security_delay"</strong>, and <strong class="source-inline">"air_system_delay"</strong>, and are shown in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer303" class="IMG---Figure">
					<img src="image/B18332_10_015.jpg" alt="Figure 10.15 – Cell 5 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.15 – Cell 5 for the chapter10/experiments notebook</p>
			<p>The second <strong class="source-inline">drop</strong> statement is dropping the <strong class="source-inline">tail_number</strong> column. This column may not play any role in flights getting delayed. In a real-world scenario, you will need to discuss this with the SMEs: </p>
			<div>
				<div id="_idContainer304" class="IMG---Figure">
					<img src="image/B18332_10_016.jpg" alt="Figure 10.16 – Cell 5 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.16 – Cell 5 for the chapter10/experiments notebook</p>
			<ol>
				<li value="5"><em class="italic">Cell 6</em> is dropping rows for which the data is not available using the Dataframe's <strong class="source-inline">dropna</strong> function. Recall, from <em class="italic">Step 3</em>, that the number of rows where data is missing<a id="_idIndexMarker890"/> from<a id="_idIndexMarker891"/> these columns is less compared to the total rows available. <strong class="source-inline">air_time</strong>, <strong class="source-inline">arrival_delay</strong>, and <strong class="source-inline">elapsed_time</strong> are examples of such columns from <em class="italic">Step 5</em>. We have adopted this approach to keep things simple; a better way would be to find a way to get the missing data or to create this data from existing values.</li>
			</ol>
			<div>
				<div id="_idContainer305" class="IMG---Figure">
					<img src="image/B18332_10_017.jpg" alt="Figure 10.17 – Cell 6 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.17 – Cell 6 for the chapter10/experiments notebook</p>
			<ol>
				<li value="6">In <em class="italic">Cell 7</em>, you are dropping columns for which you do not have data for future flights. Recall that the model aims to predict the future flight on-time performance. However, columns such as <strong class="source-inline">departure_time</strong> and <strong class="source-inline">arrival_time</strong> contain the actual departure and arrival times. For predicting future flights, you will not have such data available at the time of prediction, and so you need to drop these columns while training your model.</li>
			</ol>
			<div>
				<div id="_idContainer306" class="IMG---Figure">
					<img src="image/B18332_10_018.jpg" alt="Figure 10.18 – Cell 7 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.18 – Cell 7 for the chapter10/experiments notebook</p>
			<ol>
				<li value="7">In the dataset, the scheduled departure and arrival time is available in HHMM format, where HH is hours and MM is minutes. In <em class="italic">Cell 8</em>, as a data scientist, you may choose to split this data into two different columns where one column represents the hours and the other one represents the minutes. Doing this may simplify the dataset and improve the model performance if some correlation exists between the expected classification and split data. You may do it out of your intuition, or <a id="_idIndexMarker892"/>you may discuss this <a id="_idIndexMarker893"/>option with the SMEs.</li>
			</ol>
			<p>You have chosen to split the <strong class="source-inline">scheduled_departure</strong> and<strong class="source-inline"> scheduled_arrival</strong> columns:</p>
			<div>
				<div id="_idContainer307" class="IMG---Figure">
					<img src="image/B18332_10_019.jpg" alt="Figure 10.19 – Cell 8 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.19 – Cell 8 for the chapter10/experiments notebook</p>
			<ol>
				<li value="8">In <em class="italic">Cell 9</em>, you drop a few more columns. The first set contains columns for which we have to split the time into hours and minutes, such as <strong class="source-inline">scheduled_arrival</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer308" class="IMG---Figure">
					<img src="image/B18332_10_020.jpg" alt="Figure 10.20 – Cell 9 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.20 – Cell 9 for the chapter10/experiments notebook</p>
			<p>The second set contains the columns that are represented in other columns. For example, the <strong class="source-inline">origin_airport</strong> column has a key for the airport, and the <strong class="source-inline">ORIG_AIRPORT</strong> column is a descriptive name. Both these columns represent the same information:</p>
			<div>
				<div id="_idContainer309" class="IMG---Figure">
					<img src="image/B18332_10_021.jpg" alt="Figure 10.21 – Cell 9 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.21 – Cell 9 for the chapter10/experiments notebook</p>
			<ol>
				<li value="9">In <em class="italic">Cell 10</em>, you visually see the dataset again using the <strong class="source-inline">head</strong> statement. You have <a id="_idIndexMarker894"/>noticed<a id="_idIndexMarker895"/> that you have some data in string format, such as the <strong class="source-inline">airline</strong> column:</li>
			</ol>
			<div>
				<div id="_idContainer310" class="IMG---Figure">
					<img src="image/B18332_10_022.jpg" alt="Figure 10.22 – Cell 10 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.22 – Cell 10 for the chapter10/experiments notebook</p>
			<p>You choose to encode that data to convert it into numbers. There are many techniques available, such as <strong class="bold">ordinal encoding</strong> or <strong class="bold">one-hot encoding</strong>, to name a couple. For this example, we choose to use the simple <strong class="source-inline">OrdinalEncoder</strong>. This encoder encodes categorical values as an integer array. In <em class="italic">Cell 12</em>, you have applied the category encoding to the selected fields such as <strong class="source-inline">airline</strong> and <strong class="source-inline">origin_airport</strong>:</p>
			<div>
				<div id="_idContainer311" class="IMG---Figure">
					<img src="image/B18332_10_023.jpg" alt="Figure 10.23 – Cell 12 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.23 – Cell 12 for the chapter10/experiments notebook</p>
			<p>This means that the input string data for these fields will be converted into integers. This is good for training; however, at inferencing time, the caller may not know about this encoding that you have just performed. One way is to save this encoder and use it at inferencing time to convert the value from string to integers. So, your inferencing pipeline would consist of two steps. The first step is to apply the encoding and the second step is to predict the response using the saved mode. In<a id="_idIndexMarker896"/> the<a id="_idIndexMarker897"/> last four lines of <em class="italic">Cell 12</em>, you have saved the encoder and have to register it with MLflow:</p>
			<div>
				<div id="_idContainer312" class="IMG---Figure">
					<img src="image/B18332_10_024.jpg" alt="Figure 10.24 – Cell 12 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.24 – Cell 12 for the chapter10/experiments notebook</p>
			<ol>
				<li value="10">In <em class="italic">Cell 13</em>, you validate the data using the <strong class="source-inline">head</strong> statement. Notice that the <strong class="source-inline">airline</strong> column (one of the columns that you have applied the category encoding to) has changed. For example, compare the value of the <strong class="source-inline">airline</strong> column from <em class="italic">Cell 10</em> and <em class="italic">Cell 13</em> and notice that the value of <strong class="bold">WN</strong> in the <strong class="source-inline">airline</strong> column has been changed to <strong class="source-inline">1</strong>. This confirms that the encoding has been applied to the dataset successfully:</li>
			</ol>
			<div>
				<div id="_idContainer313" class="IMG---Figure">
					<img src="image/B18332_10_025.jpg" alt="Figure 10.25 – Cell 13 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.25 – Cell 13 for the chapter10/experiments notebook</p>
			<ol>
				<li value="11">In <em class="italic">Cell 14</em>, you used the <strong class="source-inline">dftype</strong> statement to validate the data types of each column in the dataset. Many algorithms need data to be in a numerical format and, based on the available models, you may need to move all the fields to a numerical format.</li>
				<li>In <em class="italic">Cell 15</em>, you have split your data into training and testing sets. You will train the model using the <strong class="source-inline">X_Train</strong> and <strong class="source-inline">y_train</strong> set and use the <strong class="source-inline">X_Test</strong> and <strong class="source-inline">y_test</strong> for validation of your model performance. You can perform cross-validation<a id="_idIndexMarker898"/> to<a id="_idIndexMarker899"/> further assess the model performance on unseen data. We assume that you, as a data scientist, are aware of such concepts and, therefore, will not provide more details on this.</li>
			</ol>
			<div>
				<div id="_idContainer314" class="IMG---Figure">
					<img src="image/B18332_10_026.jpg" alt="Figure 10.26 – Cell 15 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.26 – Cell 15 for the chapter10/experiments notebook</p>
			<ol>
				<li value="13">In <em class="italic">Cell 16</em>, you visualize the data distribution of the dataset. The following screenshot captures partial output, and it is expected that you run this code in your environment to get the full picture:</li>
			</ol>
			<div>
				<div id="_idContainer315" class="IMG---Figure">
					<img src="image/B18332_10_027.jpg" alt="Figure 10.27 – Cell 16 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.27 – Cell 16 for the chapter10/experiments notebook</p>
			<p>You can<a id="_idIndexMarker900"/> see<a id="_idIndexMarker901"/> from the preceding chart that the data is biased towards the on-time flights. This may impact the performance of the model. Luckily, the <strong class="source-inline">RandomForestClassifier</strong> object of the <strong class="source-inline">SciKit</strong> library provides a <strong class="source-inline">class_weight</strong> parameter. It can take a Python <strong class="source-inline">dictionary</strong> object where we can provide the desired weights for respective labels. One such example would be to allocate less weight for a value of <strong class="source-inline">0</strong> in the <strong class="source-inline">DELAYED</strong> column, which represents the on-time flight. A different value for <strong class="source-inline">class_weight</strong> could be <strong class="source-inline">balanced</strong>, which will direct the algorithm to weigh the labels as per the inverse proportion to their occurrence frequency. Simply, for our case, the <strong class="source-inline">balanced</strong> value will put more weight on the value of <strong class="source-inline">1</strong> as compared to the value of <strong class="source-inline">0</strong> in the <strong class="source-inline">DELAYED</strong> column.</p>
			<ol>
				<li value="14">In <em class="italic">Cell 19</em>, you define a random forest classification model and in <em class="italic">Cell 20</em>, you train the model. You have noticed that we have defined very minimal hyperparameters and then used <strong class="source-inline">GridSearchCV</strong> to find the best estimator for the given dataset. We have placed a separate set of hyperparameters in the comments of this cell. You are encouraged to try different combinations.</li>
			</ol>
			<div>
				<div id="_idContainer316" class="IMG---Figure">
					<img src="image/B18332_10_028.jpg" alt="Figure 10.28 – Cell 19 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.28 – Cell 19 for the chapter10/experiments notebook</p>
			<p><em class="italic">Figure 10.29</em> shows how the model training is performed by executing the <strong class="source-inline">model.fit()</strong> function:</p>
			<div>
				<div id="_idContainer317" class="IMG---Figure">
					<img src="image/B18332_10_029.jpg" alt="Figure 10.29 – Cell 20 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.29 – Cell 20 for the chapter10/experiments notebook</p>
			<p>The training<a id="_idIndexMarker902"/> will <a id="_idIndexMarker903"/>take some time to complete, so for <em class="italic">Cell 20</em>, where you are training your model, be patient.</p>
			<ol>
				<li value="15">In <em class="italic">Cell 21</em>, you have used the <strong class="source-inline">predict</strong> method to capture the model prediction for the test data. Note that the <strong class="source-inline">rf_best_model</strong> model is the output of the <strong class="source-inline">GridSearchCV</strong> object:</li>
			</ol>
			<div>
				<div id="_idContainer318" class="IMG---Figure">
					<img src="image/B18332_10_030.jpg" alt="Figure 10.30 – Cell 21 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.30 – Cell 21 for the chapter10/experiments notebook</p>
			<ol>
				<li value="16">In <em class="italic">Cell 22</em>, you have used the <strong class="source-inline">confusion_matrix</strong> function to calculate the matrix and validate the performance of your model: </li>
			</ol>
			<div>
				<div id="_idContainer319" class="IMG---Figure">
					<img src="image/B18332_10_031.jpg" alt="Figure 10.31 – Cell 22 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.31 – Cell 22 for the chapter10/experiments notebook</p>
			<ol>
				<li value="17">In <em class="italic">Cell 23</em>, you have used the <strong class="source-inline">precision_score</strong> function to calculate <strong class="source-inline">recallscore</strong> for your model on the test dataset. You can see that you have achieved 72% precision, which is good for the first experiment run. You can run more <a id="_idIndexMarker904"/>experiments and improve the<a id="_idIndexMarker905"/> metrics for your model using the platform:</li>
			</ol>
			<div>
				<div id="_idContainer320" class="IMG---Figure">
					<img src="image/B18332_10_032.jpg" alt="Figure 10.32 – Cell 23 for the chapter10/experiments notebook&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.32 – Cell 23 for the chapter10/experiments notebook</p>
			<p>You have completed one experiment run with multiple parameters and the <strong class="source-inline">RandomForestClassifier</strong> model. At this stage, you may want to check MLflow and see all the runs the grid search has performed, captured parameters, and model performance data.</p>
			<p>Typically, data scientists try multiple algorithms to find the right fit for the given problem. It is up to you to execute and enhance the code and use MLflow to compare different algorithms.</p>
			<p>Let's see what MLflow has recorded for us.</p>
			<h1 id="_idParaDest-149"><a id="_idTextAnchor148"/>Tracking model experiments and versioning using MLflow</h1>
			<p>In this <a id="_idIndexMarker906"/>section, you will <a id="_idIndexMarker907"/>use MLflow to track your experiment and version your model. This small section is a review of the capabilities highlighted to you in <a href="B18332_06_ePub.xhtml#_idTextAnchor086"><em class="italic">Chapter 6</em></a>,<em class="italic"> Machine Learning Engineering</em>, where we discussed MLflow in detail.</p>
			<h2 id="_idParaDest-150"><a id="_idTextAnchor149"/>Tracking model experiments</h2>
			<p>In this <a id="_idIndexMarker908"/>section, you <a id="_idIndexMarker909"/>will see the data recorded by MLflow for your experiment. Note that you have just registered the MLflow and called the <strong class="source-inline">autolog</strong> function, and MLflow automatically records all your data. This is a powerful capability in your platform through which you can compare multiple runs and share your findings with your team members.</p>
			<p>The following steps shows you how experiment tracking is performed in MLflow:</p>
			<ol>
				<li value="1">Log in to the MLflow UI of the platform.</li>
				<li>On the left-hand side, you will see the <strong class="bold">Experiments</strong> section and it contains your experiment named <strong class="bold">FlightsDelay-mluser</strong>. Click on it and you will see the following screen. The right-hand side shows all the runs. Recall that we have used GridSearchCV so there will be multiple runs:</li>
			</ol>
			<div>
				<div id="_idContainer321" class="IMG---Figure">
					<img src="image/B18332_10_033.jpg" alt="Figure 10.33 – The model tracking details in MLflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.33 – The model tracking details in MLflow</p>
			<ol>
				<li value="3">Click<a id="_idIndexMarker910"/> on<a id="_idIndexMarker911"/> the <strong class="bold">+</strong> icon and it will show you all the runs. Based on the hyperparameters, we have four runs, and the best run is automatically selected. As a data scientist, this capability will improve the way you work and provide a system where all the experiments can be recorded, and it is available without too many changes. You have just enabled the <strong class="source-inline">autolog</strong> feature and MLflow will capture the bulk of the metrics automatically. Select all four runs and hit the <strong class="bold">Compare</strong> button.</li>
			</ol>
			<p><em class="italic">Figure 10.34</em> shows the comparison of each run and the hyperparameters associated with the run:</p>
			<div>
				<div id="_idContainer322" class="IMG---Figure">
					<img src="image/B18332_10_034.jpg" alt="Figure 10.34 – Comparing models in MLflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.34 – Comparing models in MLflow</p>
			<ol>
				<li value="4">Click on the run <a id="_idIndexMarker912"/>next <a id="_idIndexMarker913"/>to the <strong class="bold">+</strong> icon, and MLflow will display the details of this run. In the <em class="italic">artifacts</em> section, you will find that the model file is available. You can also see that the ordinal encoder file is also available with the name <strong class="source-inline">FlightsDelayOrdinalEncoder.pkl</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer323" class="IMG---Figure">
					<img src="image/B18332_10_035.jpg" alt="Figure 10.35 – Files and data captured by MLflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.35 – Files and data captured by MLflow</p>
			<p>In this section, you have seen that MLflow captured all the metrics from your training run and assisted<a id="_idIndexMarker914"/> you<a id="_idIndexMarker915"/> in selecting the right model by providing a comparison function.</p>
			<p>The next stage is to version your model.</p>
			<h2 id="_idParaDest-151"><a id="_idTextAnchor150"/>Versioning models</h2>
			<p>After giving some <a id="_idIndexMarker916"/>thought to the model performance <a id="_idIndexMarker917"/>and sharing the data with other team members, you have selected the model that can be used for this project. In this section, you will version your model to be used. Refer to <a href="B18332_06_ePub.xhtml#_idTextAnchor086"><em class="italic">Chapter 6</em></a>, <em class="italic">Machine Learning Engineering</em>, where we discussed model versioning in detail.</p>
			<p>The following steps will guide you on how to version your model:</p>
			<ol>
				<li value="1">Go to MLflow and click on the <strong class="bold">FlightDelay-mluser</strong> experiment on the left-hand side.</li>
				<li>Then, on<a id="_idIndexMarker918"/> the right-hand side of the screen, click <a id="_idIndexMarker919"/>on the <strong class="bold">+</strong> icon for your run. You will see the following screen:</li>
			</ol>
			<div>
				<div id="_idContainer324" class="IMG---Figure">
					<img src="image/B18332_10_036.jpg" alt="Figure 10.36 – Files and data captured by MLflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.36 – Files and data captured by MLflow</p>
			<ol>
				<li value="3">Click on the <strong class="bold">model</strong> folder under artifacts and a blue button with the <strong class="bold">Register Model</strong> label will appear:</li>
			</ol>
			<div>
				<div id="_idContainer325" class="IMG---Figure">
					<img src="image/B18332_10_037.jpg" alt="Figure 10.37 – Versioning your models in MLflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.37 – Versioning your models in MLflow</p>
			<ol>
				<li value="4">Click on the <strong class="bold">Register Model</strong> button and enter a name that identifies your model. One example would be <strong class="source-inline">flights-ontime</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer326" class="IMG---Figure">
					<img src="image/B18332_10_038.jpg" alt="Figure 10.38 – Model registration in MLflow&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.38 – Model registration in MLflow</p>
			<p>As a data scientist, you<a id="_idIndexMarker920"/> have registered your model for <a id="_idIndexMarker921"/>predicting flight delays onto the model registry. The next step is to deploy your model.</p>
			<h1 id="_idParaDest-152"><a id="_idTextAnchor151"/>Deploying the model as a service</h1>
			<p>In this<a id="_idIndexMarker922"/> section, you will deploy your model as a REST service. You will see that using the details mentioned in <a href="B18332_07_ePub.xhtml#_idTextAnchor098"><em class="italic">Chapter 7</em></a>, <em class="italic">Model Deployment and Automation</em>, the team can package and deploy the model as a service. This service will then be consumed by users of your model. We highly encourage you to refresh your knowledge from <a href="B18332_07_ePub.xhtml#_idTextAnchor098"><em class="italic">Chapter 7</em></a>, <em class="italic">Model Deployment and Automation</em> before proceeding to this section.</p>
			<p>In <a href="B18332_07_ePub.xhtml#_idTextAnchor098"><em class="italic">Chapter 7</em></a>, <em class="italic">Model Deployment and Automation</em>, you have deployed the model with a <strong class="source-inline">Predictor</strong> class, which exposes the model as a REST service. You will use the same class here, however, in the flight project, you applied categorical encoding to the data before it was used for model training. This means that you will need to apply the same encoding to the input data at the inferencing time. Recall that, earlier in this chapter, you saved the file as <strong class="source-inline">FlightsDelayOrdinalEncoder.pkl</strong> and it is available in the MLflow repository.</p>
			<p>The next step is to write a simple class that can apply the transformation to the input data. Once this class is defined, you will define your inference pipeline using Seldon and then package your model as a container. So, your inference pipeline will consist of two stages; the first stage is to apply the encoding and the second stage is to use the model to predict the class.</p>
			<p>Sounds difficult? You will see that the platform abstracts most of the details, and you will provide a few configuration parameters to package and deploy your model as a service. </p>
			<p>Let's first see the <strong class="source-inline">Transformer</strong> class, which will load the <strong class="source-inline">FlightsDelayOrdinalEncoder.pkl</strong> file and apply the encoding to the input data. Open the <strong class="source-inline">chapter10/model_deploy_pipeline/model_build_push/Transformer.py</strong> file. You will see <a id="_idIndexMarker923"/>that the <strong class="source-inline">__init__</strong> function loads the encoder file and the <strong class="source-inline">transform_input</strong> function applies the transformation to the input data using the standard <strong class="source-inline">transform</strong> function. This is the same function you have used during the model training. <em class="italic">Figure 10.39</em> shows the code file:</p>
			<div>
				<div id="_idContainer327" class="IMG---Figure">
					<img src="image/B18332_10_039.jpg" alt="Figure 10.39 – Transformer class&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.39 – Transformer class</p>
			<p>The second artifact is to define the model inference graph. Recall from <a href="B18332_07_ePub.xhtml#_idTextAnchor098"><em class="italic">Chapter 7</em></a>, <em class="italic">Model Deployment and Automation</em>, that you have defined a container and one stage in your inference graph using the <strong class="source-inline">SeldonDeploy.yaml</strong> file. In this section, you will extend the inference graph to cater to the transformation and the prediction part of the inference pipeline. Naturally, when you define a new component in your graph, you will also need to define the corresponding container that will be the service for the graph node. </p>
			<p>Note that you may choose to execute the transformation logic in <strong class="source-inline">Predict.py</strong> to keep things simple. However, we wanted to show how Seldon can build complicated graphs and each graph could be a separate instance of a container. This approach brings versatility to running your production models in an elastic fashion.</p>
			<p>So, let's look into the <strong class="source-inline">chapter10/model_deploy_pipeline/model_deploy/SeldonDeploy.yaml</strong> file. This file<a id="_idIndexMarker924"/> has been copied from <a href="B18332_07_ePub.xhtml#_idTextAnchor098"><em class="italic">Chapter 7</em></a>, <em class="italic">Model Deployment and Automation</em>, and the following changes have been made to it.</p>
			<p>The first change is to build the inference graph. You need to apply the transformation first and then run the model prediction. <em class="italic">Figure 10.40</em> displays this graph. Note that the root element for the graph is of the <strong class="source-inline">TRANSFORMER</strong> type with the name <strong class="source-inline">transformer</strong>, and there is a <strong class="source-inline">children</strong> node in the graph. The <strong class="source-inline">children</strong> node will be executed after the root node. This setup allows you to have different graphs as per your model requirements. The child node in this example is the actual prediction:</p>
			<div>
				<div id="_idContainer328" class="IMG---Figure">
					<img src="image/B18332_10_040.jpg" alt="Figure 10.40 – Seldon deployment YAML&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.40 – Seldon deployment YAML</p>
			<p>The second change to the <strong class="source-inline">chapter10/model_deploy_pipeline/model_deploy/SeldonDeploy.yaml</strong> file is registering the containers for both the root and the child node. The <strong class="source-inline">name</strong> field in the graph is the one that associates the container to the graph node. So, we will have two<a id="_idIndexMarker925"/> instances of a container, one for <strong class="source-inline">transformer</strong> and the second for <strong class="source-inline">predictor</strong>. The <strong class="source-inline">transformer</strong> instance will execute the <strong class="source-inline">Transformer.py</strong> file and the <strong class="source-inline">predictor</strong> instance will execute the <strong class="source-inline">Predictor.py</strong> file. What we have done is create a single container image with all these files, so our container image is the same. You can examine the <strong class="source-inline">chapter10/model_deploy_pipeline/model_build_push/Dockerfile.py</strong> file where you package all the files into a container image. <em class="italic">Figure 10.41</em> highlights the part of <strong class="source-inline">SeldonDeploy.yaml</strong> where the containers have been configured.</p>
			<p>Note that the first container is with the name <strong class="source-inline">transformer</strong>. The <strong class="source-inline">MODEL_NAME</strong> variable mentions the name of the Python file and the <strong class="source-inline">SERVICE_TYPE</strong> variable mentions the type of callback to call by Seldon. Recall that <strong class="source-inline">Transformer.py</strong> has a <strong class="source-inline">transform_input</strong> method, and <strong class="source-inline">SERVICE_TYPE</strong> guides the Seldon system to call the right function. The same is applied to the <strong class="source-inline">predictor</strong> container instance, and note how <strong class="source-inline">MODEL_NAME</strong> and <strong class="source-inline">SERVICE_TYPE</strong> are different for the <strong class="source-inline">predictor</strong> instance:</p>
			<div>
				<div id="_idContainer329" class="IMG---Figure">
					<img src="image/B18332_10_041.jpg" alt="Figure 10.41 – Seldon deployment YAML&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.41 – Seldon deployment YAML</p>
			<p>That is it! For<a id="_idIndexMarker926"/> some of you, this may be a little overwhelming, but once you have defined the structure for your projects, these files can be standardized, and the data scientists will not need to change them for every project. You have seen how the ML platform allows you to be self-sufficient in not only building the models but also packaging them.</p>
			<p>The next step is to write a simple Airflow pipeline to deploy your model. Before you start this section, we recommend refreshing your knowledge of deploying the models using Airflow as detailed in <a href="B18332_07_ePub.xhtml#_idTextAnchor098"><em class="italic">Chapter 7</em></a>, <em class="italic">Model Deployment and Automation</em>. There is no change required in the pipeline that you have built, and you will just be changing a few configuration parameters to provide the right model name and version to the pipeline.</p>
			<p>We have prebuilt this pipeline for you, so, open the <strong class="source-inline">chapter10/model_deploy_pipeline/flights_model.pipeline</strong> file. Open this file and validate that it has the same two stages as mentioned in <a href="B18332_07_ePub.xhtml#_idTextAnchor098"><em class="italic">Chapter 7</em></a><em class="italic">, Model Deployment and Automation</em>. The first stage builds and pushes the container image to a<a id="_idIndexMarker927"/> container registry and the second stage deploys the model using Seldon.</p>
			<p><em class="italic">Figure 10.42</em> displays the first stage with the parameters used for building and pushing the container image. <strong class="bold">Runtime Image</strong> and <strong class="bold">File Dependencies</strong> have the same values as shown earlier. Notice the <strong class="bold">Environment Variables</strong> section, where you have the same variable names but different values:</p>
			<div>
				<div id="_idContainer330" class="IMG---Figure">
					<img src="image/B18332_10_042.jpg" alt="Figure 10.42 – Flights model deploy pipeline&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.42 – Flights model deploy pipeline</p>
			<p>Let's see <a id="_idIndexMarker928"/>each of them:</p>
			<ul>
				<li><strong class="source-inline">MODEL_NAME</strong> has a value of <strong class="source-inline">flights-ontime</strong>. This is the name of the model you were given when you registered the model with MLflow.</li>
				<li><strong class="source-inline">MODEL_VERSION</strong> has a value of <strong class="source-inline">1</strong>. This is the version of the model you would like to deploy. This version is recorded in the MLflow system.</li>
				<li><strong class="source-inline">CONTAINER_DETAILS</strong> has a value of <strong class="source-inline">flights-ontime</strong>. This is the name of the model you were given when you registered the model with MLflow.</li>
				<li><strong class="source-inline">CONTAINER_REGISTRY</strong> is the container registry API endpoint. For DockerHub, this is at <a href="https://index.docker.io/v1">https://index.docker.io/v1</a>. Set the value of this variable to <a href="https://index.docker.io/v1/">https://index.docker.io/v1/</a>. In this example, we have used <a href="http://quay.io">quay.io</a> as the registry. This is another free registry that you can use.</li>
				<li><strong class="source-inline">CONTAINER_REGISTRY_USER</strong> is the username of the user that will push images to the image registry. Set this to your DockerHub username or Quay username.</li>
				<li><strong class="source-inline">CONTAINER_REGISTRY_PASSWORD</strong> is the password of your container registry user. In<a id="_idIndexMarker929"/> production, you do not want to do this. You may use secret management tools to serve your password. </li>
			</ul>
			<p><strong class="source-inline">CONTAINER_DETAILS</strong> is also the name of the repository to where the image will be pushed and the image name and image tag. <em class="italic">Figure 10.43</em> displays the second stage with the parameters used for deploying the container image using Seldon. <strong class="bold">Runtime Image</strong> and <strong class="bold">File Dependencies</strong> have the same values as shown earlier. Notice the <strong class="bold">Environment Variable</strong> is the section where you have variable values set for this deployment. The required variables are <strong class="source-inline">MODEL_NAME</strong>, <strong class="source-inline">MODEL_VERSION</strong>, <strong class="source-inline">CONTAINER_DETAILS</strong>, and <strong class="source-inline">CLUSTER_DOMAIN</strong>. You have seen all the variables in the preceding paragraph, but <strong class="source-inline">CLUSTER_DOMAIN</strong> is the DNS name of your Kubernetes cluster. In this case, the IP address of minikube is <strong class="source-inline">&lt;Minikube IP&gt;.nip.io</strong>.</p>
			<div>
				<div id="_idContainer331" class="IMG---Figure">
					<img src="image/B18332_10_043.jpg" alt="Figure 10.43 – Flights model deploy pipeline&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.43 – Flights model deploy pipeline</p>
			<p>Save and deploy<a id="_idIndexMarker930"/> this DAG to your Airflow environment and the model will be available for consumption when the Airflow DAG has finished execution. Validate that this DAG has been executed correctly by logging into Airflow and checking the status of the DAG. <em class="italic">Figure 10.44</em> shows the Airflow UI where you have validated the DAG's status. Notice that we have saved the DAG under the name <strong class="source-inline">flights-model-deploy</strong>; if you have chosen some other name, your DAG name will reflect accordingly.</p>
			<div>
				<div id="_idContainer332" class="IMG---Figure">
					<img src="image/B18332_10_044.jpg" alt="Figure 10.44 – Airflow DAG for the flights pipeline&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.44 – Airflow DAG for the flights pipeline</p>
			<p>Recall that MLflow associates a run ID for each of the experiments. You register one of these experiments in the model registry so it can be deployed. Refer to <em class="italic">Figure 10.34</em>, which shows a screenshot of the run ID for this model.</p>
			<p>This model run will be associated with the deployed model, so your team can track the models running in the environment to an individual run. This capability provides a trace back on what version of the model is running in different environments. Run the following <a id="_idIndexMarker931"/>command to see the resources created by the model:</p>
			<p class="source-code"><strong class="bold">kubectl get service,ingress,SeldonDeployment -n ml-workshop | grep bf32</strong></p>
			<p>You should get the following response. As you can see, the Kubernetes service and ingress have a run ID that starts with <strong class="source-inline">bf32</strong> for this example. Note that it will have a different value for your case, and you will need to adjust the run ID in the preceding command:</p>
			<div>
				<div id="_idContainer333" class="IMG---Figure">
					<img src="image/B18332_10_045.jpg" alt="Figure 10.45 – Kubernetes objects created by the platform&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.45 – Kubernetes objects created by the platform</p>
			<p>Now, the model<a id="_idIndexMarker932"/> is deployed; you now test the model by running a RESTful call to your model.</p>
			<h2 id="_idParaDest-153"><a id="_idTextAnchor152"/>Calling your model</h2>
			<p>Recall that<a id="_idIndexMarker933"/> the model is exposed via the Kubernetes Ingress, which is created by automation. In order to test whether the model is running properly as a RESTful API, follow these steps:</p>
			<ol>
				<li value="1">Run the following command to get the <strong class="source-inline">ingress</strong> object. Note that the name of the <strong class="source-inline">ingress</strong> object will be different for your setup:<p class="source-code"><strong class="bold">kubectl get ingress &lt;INGRESS_NAME&gt; –n ml-workshop</strong></p></li>
				<li>Now, make an HTTP call to the location where your model is available for inference. Run the following commands. The <strong class="source-inline">chapter10/inference</strong> folder contains a payload for the flight data and in return, the model will predict the probability of the flight getting delayed.</li>
				<li>First, change the directory to the <strong class="source-inline">chapter10/inference</strong> folder:<p class="source-code"><strong class="bold">cd chapter10/inference</strong></p></li>
				<li>Then, run a <strong class="source-inline">curl</strong> command to send the payload to the model. Note to change the HTTP address as per your setup:<p class="source-code"><strong class="bold">curl -vvvvk --header "content-type: application/json" -X POST -d @data.json https://flights-ontime.192.168.39.216.nip.io/api/v1.0/predictions; done</strong></p></li>
			</ol>
			<p>Windows users may choose to use the excellent Postman application (<a href="https://www.postman.com/">https://www.postman.com/</a>) to make an HTTP call. </p>
			<ol>
				<li value="5">Open the <strong class="source-inline">chapter10/inference/data.json</strong> file to see the payload that we are sending to the model. You will notice that there are two sections of the <strong class="source-inline">json</strong> payload. The first part is with the <strong class="source-inline">names</strong> key, which captures the feature columns that you have used to train the model. Notice that there is no <strong class="source-inline">DELAYED</strong> column here because the model will predict the probability of the <strong class="source-inline">DELAYED</strong> column. The second part is with the <strong class="source-inline">ndarrray</strong> key, which has the values for the feature columns. Note that the values for the categorical columns are in the original form and the inference pipeline will convert them into the categorical values before executing the model. <em class="italic">Figure 10.46</em> shows the following file:</li>
			</ol>
			<div>
				<div id="_idContainer334" class="IMG---Figure">
					<img src="image/B18332_10_046.jpg" alt="Figure 10.46 – Sample payload for flights model inferencing&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.46 – Sample payload for flights model inferencing</p>
			<p>Now that you have <a id="_idIndexMarker934"/>successfully performed an inference call over HTTP, let's see how the information has been captured by the monitoring system.</p>
			<h1 id="_idParaDest-154"><a id="_idTextAnchor153"/>Monitoring your model</h1>
			<p>In this last section, you <a id="_idIndexMarker935"/>will see how the platform automatically starts capturing the typical performance metrics of your model. The platform also helps you visualize the performance of the inference. The platform uses Seldon to package the model, and Seldon exposes default metrics to be captured. Seldon also allows you to write custom metrics for specific models; however, it is out of the scope of this book.</p>
			<p>Let's start by understanding how the metrics capture and visualization work.</p>
			<h2 id="_idParaDest-155"><a id="_idTextAnchor154"/>Understanding monitoring components</h2>
			<p>The way<a id="_idIndexMarker936"/> metrics capture works is that your model is wrapped by Seldon. Seldon then exposes the metrics to a well-defined URL endpoint, which was detailed in <a href="B18332_07_ePub.xhtml#_idTextAnchor098"><em class="italic">Chapter 7</em></a>,<em class="italic"> Model Deployment and Automation</em>. Prometheus harvests this information and stores it in its database. The platform's Grafana connects to Prometheus and helps you visualize the recorded metrics.</p>
			<p><em class="italic">Figure 10.47</em> summarizes the relationship between the model and monitoring components:</p>
			<div>
				<div id="_idContainer335" class="IMG---Figure">
					<img src="image/B18332_10_047.jpg" alt="Figure 10.47 – ML platform monitoring components &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.47 – ML platform monitoring components </p>
			<p>Let's understand each component of this diagram:</p>
			<ul>
				<li><strong class="bold">Open Data Hub (ODH) Operator</strong>: This is the base operator for our platform. Its role is to provision all the different components for your platform. We have discussed this operator in various chapters of this book and so we do not describe it in this section.</li>
				<li><strong class="bold">Prometheus Operator</strong>: Prometheus operator is responsible for creating the Prometheus server. The ODH operator creates the Kubernetes subscriptions for the Prometheus operators. You can find the subscription file at <strong class="source-inline">manifests/prometheus/base/subscription.yaml</strong>. The following snippet shows<a id="_idIndexMarker937"/> that it uses the OLM mechanism to install the Prometheus operator:</li>
			</ul>
			<div>
				<div id="_idContainer336" class="IMG---Figure">
					<img src="image/B18332_10_048.jpg" alt="Figure 10.48 – Subscription for Prometheus operator&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.48 – Subscription for Prometheus operator</p>
			<ul>
				<li><strong class="bold">Prometheus Server</strong>: The Prometheus operator installs and configures the Prometheus server for you. The platform configures the file that directs the Prometheus operator to create the Prometheus server. You can find the file at <strong class="source-inline">manifests/prometheus/base/prometheus.yaml</strong>. The following snippet shows the file:</li>
			</ul>
			<div>
				<div id="_idContainer337" class="IMG---Figure">
					<img src="image/B18332_10_049.jpg" alt="Figure 10.49 – Prometheus server configuration&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.49 – Prometheus server configuration</p>
			<ul>
				<li><strong class="bold">Service Monitors</strong>: Service monitors are objects by which you configure the Prometheus<a id="_idIndexMarker938"/> server to find and harvest information from the running Kubernetes services and pod. The service monitors are defined by the platform, and you can find one example at <strong class="source-inline">manifests/prometheus/base/prometheus.yaml</strong>. The following snippet shows the file. Note that the configuration uses port <strong class="source-inline">8000</strong>, which is the port at which Seldon exposes the metrics information. The <strong class="source-inline">selector</strong> object defines the filter by which Prometheus will decide what pods to scrape data from: </li>
			</ul>
			<div>
				<div id="_idContainer338" class="IMG---Figure">
					<img src="image/B18332_10_050.jpg" alt="Figure 10.50 – Prometheus server monitors for Seldon pods&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.50 – Prometheus server monitors for Seldon pods</p>
			<ul>
				<li><strong class="bold">Grafana Server</strong>: Grafana is the component that provides the visualization for the data captured by Prometheus. Grafana is preferred to create dashboards when using Prometheus and is continuously improving its Prometheus support. The platform deploys Grafana via the <strong class="source-inline">manifests/grafana/base/deployment.yaml</strong> file. </li>
			</ul>
			<p>In this section, you<a id="_idIndexMarker939"/> have seen how the platform provides and wires different components to provide you with a visualization framework for your observability requirements.</p>
			<p>Next is to configure Grafana.</p>
			<h2 id="_idParaDest-156"><a id="_idTextAnchor155"/>Configuring Grafana and a dashboard</h2>
			<p>In this <a id="_idIndexMarker940"/>section, you<a id="_idIndexMarker941"/> will <a id="_idIndexMarker942"/>configure Grafana to connect to Prometheus and build a dashboard to visualize the model's metrics. What is a dashboard? It is a set of graphs, tables, and other visualizations of your model. You will create a dashboard for the flight model.</p>
			<p>Note that this is a one-time configuration, and it does not need to be repeated for every model. This means that once you have a dashboard, you can use it for multiple models. Your team may create a few standard dashboards and as soon as a new model is deployed, the platform will automatically find it and make it available for monitoring.</p>
			<p>Let's start<a id="_idIndexMarker943"/> with<a id="_idIndexMarker944"/> the configuration<a id="_idIndexMarker945"/> of the Grafana instance:</p>
			<ol>
				<li value="1">Log in to Grafana using https://grafna.192.128.36.219.nip.io. Notice that you will need to change the IP address as per your setup. On the login page, click the <strong class="bold">Sign in With KeyCloak</strong> button, which is at the bottom of the login window:</li>
			</ol>
			<div>
				<div id="_idContainer339" class="IMG---Figure">
					<img src="image/B18332_10_051.jpg" alt="Figure 10.51 – Grafana login page&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.51 – Grafana login page</p>
			<ol>
				<li value="2">First, you<a id="_idIndexMarker946"/> will <a id="_idIndexMarker947"/>need to <a id="_idIndexMarker948"/>add a data source. A data source is a system that will provide the data that Grafana will help you visualize. The data provider in Prometheus scrapes the metrics data from your models. Select the <strong class="bold">Configuration</strong> | <strong class="bold">Data sources</strong> option from the left-hand menu:</li>
			</ol>
			<div>
				<div id="_idContainer340" class="IMG---Figure">
					<img src="image/B18332_10_052.jpg" alt="Figure 10.52 – Grafana Data sources menu option&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.52 – Grafana Data sources menu option</p>
			<ol>
				<li value="3">Click <a id="_idIndexMarker949"/>on <a id="_idIndexMarker950"/>the <strong class="bold">Add data source</strong> button, as<a id="_idIndexMarker951"/> shown in the following screenshot: </li>
			</ol>
			<div>
				<div id="_idContainer341" class="IMG---Figure">
					<img src="image/B18332_10_053.jpg" alt="Figure 10.53 – Add new Grafana data source&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.53 – Add new Grafana data source</p>
			<ol>
				<li value="4">Select the data source type, which will be Prometheus for your case. You may notice that Grafana can talk to a variety of data sources, including InfluxDB and YYYY, to name a couple.</li>
			</ol>
			<div>
				<div id="_idContainer342" class="IMG---Figure">
					<img src="image/B18332_10_054.jpg" alt="Figure 10.54 – Add new Prometheus Grafana data source&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.54 – Add new Prometheus Grafana data source</p>
			<ol>
				<li value="5">Now, you need <a id="_idIndexMarker952"/>to<a id="_idIndexMarker953"/> add<a id="_idIndexMarker954"/> the details for the Prometheus server. Grafana will use these details to connect and fetch data from the Prometheus server. Add the following properties in the screen mentioned:<ul><li><strong class="bold">Name</strong>: <strong class="source-inline">Prometheus</strong></li><li><strong class="bold">URL</strong>: http://prometheus-operated:9090</li></ul></li>
				<li>Then click the <strong class="bold">Save &amp; test</strong> button. The URL is the location of the Prometheus service created by the platform. Because the Grafana pod will talk to the Prometheus pod using the internal Kubernetes network, this URL will be the same for your setup too: </li>
			</ol>
			<div>
				<div id="_idContainer343" class="IMG---Figure">
					<img src="image/B18332_10_055.jpg" alt="Figure 10.55 – Configuration for the Prometheus Grafana data source&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.55 – Configuration for the Prometheus Grafana data source</p>
			<p>You can <a id="_idIndexMarker955"/>find <a id="_idIndexMarker956"/>the <strong class="source-inline">prometheus</strong> service<a id="_idIndexMarker957"/> details by issuing the following command:</p>
			<p class="source-code"><strong class="bold">kubectl get service –n ml-platform | grep prometheus</strong></p>
			<ol>
				<li value="7">After you configure Grafana to connect to Prometheus, the next step is to build the dashboard. As mentioned earlier, a dashboard is a set of visualizations, and each visualization is backed by a query. Grafana runs those queries and plots the data for you. Building dashboards is out of the scope of this book, but we have provided a dashboard that you can use. Select the <strong class="bold">Import</strong> option from the left-hand menu:</li>
			</ol>
			<div>
				<div id="_idContainer344" class="IMG---Figure">
					<img src="image/B18332_10_056.jpg" alt="Figure 10.56 – Adding a new dashboard in Grafana&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.56 – Adding a new dashboard in Grafana</p>
			<ol>
				<li value="8">On<a id="_idIndexMarker958"/> the <strong class="bold">Import</strong> screen, copy<a id="_idIndexMarker959"/> the<a id="_idIndexMarker960"/> contents from the <strong class="source-inline">chapter10/grafana-dashboard/sample-seldon-dashboard.json</strong> file and paste it into the <strong class="bold">Import via panel json</strong> textbox. Click on the <strong class="bold">Load</strong> button to import the dashboard:</li>
			</ol>
			<div>
				<div id="_idContainer345" class="IMG---Figure">
					<img src="image/B18332_10_057.jpg" alt="Figure 10.57 – Importing a Seldon dashboard in Grafana&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.57 – Importing a Seldon dashboard in Grafana</p>
			<ol>
				<li value="9">Set the name<a id="_idIndexMarker961"/> for<a id="_idIndexMarker962"/> your <a id="_idIndexMarker963"/>imported dashboard and click on the <strong class="bold">Import</strong> button to complete the import process for the dashboard. You can give the name as per your liking; we have chosen the name <strong class="source-inline">Flights Prediction Analytics</strong>, as you can see in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer346" class="IMG---Figure">
					<img src="image/B18332_10_058.jpg" alt="Figure 10.58 – Importing Seldon dashboard in Grafana&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.58 – Importing Seldon dashboard in Grafana</p>
			<ol>
				<li value="10">After you import<a id="_idIndexMarker964"/> the <a id="_idIndexMarker965"/>dashboard, Grafana <a id="_idIndexMarker966"/>will start displaying the dashboard immediately. You can see a few metrics such as response times, success rate, and other relative metrics for your deployed model. You may need to hit your model a few times to start populating this board. Refer to the <em class="italic">Calling your model</em> section earlier in this chapter on how to make calls to your deployed models.</li>
			</ol>
			<div>
				<div id="_idContainer347" class="IMG---Figure">
					<img src="image/B18332_10_059.jpg" alt="Figure 10.59 – Dashboard for Seldon models&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 10.59 – Dashboard for Seldon models</p>
			<p>You can see that the board captures the metrics that have been emitted by your model wrapped in Seldon. As more models get deployed, they will be available in this dashboard, and you can filter the models through the filters provided in the top bar of the dashboard.</p>
			<p>Your flights on-time prediction service is now available for consumption. You will now work with the product development team and the website team of your organization so that they can integrate this functionality and provide a better service for your customers. Your work<a id="_idIndexMarker967"/> does<a id="_idIndexMarker968"/> not finish<a id="_idIndexMarker969"/> here; you will need to continuously see how the model is performing and bring on improvements via new data and/or optimizing your models further. The platform will help you to perform this cycle with higher velocity and continuously improve the offerings to your customers.</p>
			<h1 id="_idParaDest-157"><a id="_idTextAnchor156"/>Summary</h1>
			<p>This was another long chapter that covered the model development and deployment life cycle for the flights on-time performance project. You have seen how the platform enables you and your team to become autonomous in EDA, model experimentation and tracking, model registry, and model deployment.</p>
			<p>In the next chapter, we will take a step back and summarize our journey of the overall platform and how you can use it as your own solution that fits your vertical. You can use the concepts and tools to build a platform for your team and enable your business to realize the power of AI.</p>
		</div>
	</body></html>