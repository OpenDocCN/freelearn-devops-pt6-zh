<html><head></head><body>
		<div>
			<div id="_idContainer058" class="Content">
			</div>
		</div>
		<div id="_idContainer059" class="Content">
			<h1 id="_idParaDest-38">3. <a id="_idTextAnchor039"/>Application deployment on AKS</h1>
		</div>
		<div id="_idContainer087" class="Content">
			<p>In this chapter, you will deploy two applications on <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>). An application consists of multiple parts, and you will build the applications one step at a time while the conceptual model behind them is explained. You will be able to easily adapt the steps in this chapter to deploy any other application on AKS.</p>
			<p>To deploy the applications and make changes to them, you will be using <strong class="bold">YAML</strong> files. YAML is a recursive acronym for <strong class="bold">YAML Ain't Markup Language</strong>. YAML is a language that is used to create configuration files to deploy to Kubernetes. Although you can use either JSON or YAML files to deploy applications to Kubernetes, YAML is the most commonly used language to do so. YAML became popular because it is easier for a human to read when compared to JSON or XML. You will see multiple examples of YAML files throughout this chapter and throughout the book.</p>
			<p>During the deployment of the sample guestbook application, you will see Kubernetes concepts in action. You will see how a <strong class="bold">deployment</strong> is linked to a <strong class="bold">ReplicaSet</strong>, and how that is linked to the <strong class="bold">pods</strong> that are deployed. A deployment is an object in Kubernetes that is used to define the desired state of an application. A <strong class="bold">deployment</strong> will create a ReplicaSet. A <strong class="bold">ReplicaSet</strong> is an object in Kubernetes that guarantees that a certain number of <strong class="bold">pods</strong> will always be available. Hence, a ReplicaSet will create one or more pods. A pod is an object in Kubernetes that is a group of one or more containers. Let's revisit the relationship between deployments, ReplicaSets, and pods:</p>
			<div>
				<div id="_idContainer060" class="IMG---Figure">
					<img src="image/B17338_01_06.jpg" alt="Relationship showing that a deployment creates a replicaset, which in turn creates multiple pods"/>
				</div>
			</div>
			<p class="figure">Figure 3.1: Relationship between a deployment, a ReplicaSet, and pods</p>
			<p>While deploying the sample applications, you will use the <strong class="bold">service</strong> object to connect to the application. A service in Kubernetes is an object that is used to provide a static IP address and DNS name to an application. Since a pod can be killed and moved to different nodes in the cluster, a service ensures you can connect to a static endpoint for your application.</p>
			<p>You will also edit the sample applications to provide configuration details using a <strong class="bold">ConfigMap</strong>. A ConfigMap is an object that is used to provide configuration details to pods. It allows you to keep configuration settings outside of the actual container. You can then provide these configuration details to your application by connecting the ConfigMap to your deployment.</p>
			<p>Finally, you will be introduced to Helm. Helm is a package manager for Kubernetes that helps to streamline the deployment process. You will deploy a WordPress site using Helm and gain an understanding of the value Helm brings to Kubernetes. This WordPress installation makes use of persistent storage in Kubernetes and you will learn how persistent storage in AKS is set up.</p>
			<p>The following topics will be covered in this chapter:</p>
			<ul>
				<li>Deploying the sample guestbook application step by step</li>
				<li>Full deployment of the sample guestbook application</li>
				<li>Using Helm to install complex Kubernetes applications</li>
			</ul>
			<p>We'll begin with the sample guestbook application.</p>
			<h2 id="_idParaDest-39"><a id="_idTextAnchor040"/>Deploying the sample guestbook application step by step</h2>
			<p>In this chapter, you will deploy the classic guestbook sample Kubernetes application. You will be mostly following the steps from <a href="https://kubernetes.io/docs/tutorials/stateless-application/guestbook/">https://kubernetes.io/docs/tutorials/stateless-application/guestbook/</a> with some modifications. You will employ these modifications to show additional concepts, such as ConfigMaps, that are not present in the original sample.</p>
			<p>The sample guestbook application is a simple, multi-tier web application. The different tiers in this application will have multiple instances. This is beneficial for both high availability and scalability. The guestbook's front end is a stateless application because the front end doesn't store any state. The Redis cluster in the back end is stateful as it stores all the guestbook entries.</p>
			<p>You will be using this application as the basis for testing out the scaling of the back end and the front end, independently, in the next chapter.</p>
			<p>Before we get started, let's consider the application that we'll be deploying.</p>
			<h3 id="_idParaDest-40"><a id="_idTextAnchor041"/>Introducing the application</h3>
			<p>The application stores and displays guestbook entries. You can use it to record the opinion of all the people who visit your hotel or restaurant, for example.</p>
			<p><em class="italics">Figure 3.2</em> shows you a high-level overview of the application. The application uses PHP as a front end. The front end will be deployed using multiple replicas. The application uses Redis for its data storage. Redis is an in-memory key-value database. Redis is most often used as a cache.</p>
			<div>
				<div id="_idContainer061" class="IMG---Figure">
					<img src="image/B17338_03_02.jpg" alt="Architecture of the multi-tier guestbook application"/>
				</div>
			</div>
			<p class="figure">Figure 3.2: High-level overview of the guestbook application</p>
			<p>We will begin deploying this application by deploying the Redis master.</p>
			<h3 id="_idParaDest-41"><a id="_idTextAnchor042"/>Deploying the Redis master</h3>
			<p>In this section, you are going to deploy the Redis master. You will learn about the YAML syntax that is required for this deployment. In the next section, you will make changes to this YAML. Before making changes, let's start by deploying the Redis master.</p>
			<p>Perform the following steps to complete the task:</p>
			<ol>
				<li>Open your friendly Azure Cloud Shell, as highlighted in <em class="italics">Figure 3.3</em>:<div id="_idContainer062" class="IMG---Figure"><img src="image/B17338_03_03.jpg" alt="Opening Cloud Shell from the Azure portal"/></div><p class="figure">Figure 3.3: Opening the Cloud Shell</p></li>
				<li>If you have not cloned the GitHub repository for this book, please do so now by using the following command:<p class="snippet">git clone https: //github.com/PacktPublishing/Hands-on-Kubernetes-on-Azure-Third-Edition/</p></li>
				<li>Change into the directory for Chapter 3 using the following command:<p class="snippet">cd Hands-On-Kubernetes-on-Azure/Chapter03/</p></li>
				<li>Enter the following command to deploy the master:<p class="snippet">kubectl apply -f redis-master-deployment.yaml</p><p>It will take some time for the application to download and start running. While you wait, let's understand the command you just typed and executed. Let's start by exploring the content of the YAML file that was used (the line numbers are used for explaining key elements from the code snippets):</p><p class="snippet">1   apiVersion: apps/v1</p><p class="snippet">2   kind: Deployment</p><p class="snippet">3   metadata:</p><p class="snippet">4     name: redis-master</p><p class="snippet">5     labels:</p><p class="snippet">6       app: redis</p><p class="snippet">7   spec:</p><p class="snippet">8     selector:</p><p class="snippet">9       matchLabels:</p><p class="snippet">10        app: redis</p><p class="snippet">11        role: master</p><p class="snippet">12        tier: backend</p><p class="snippet">13    replicas: 1</p><p class="snippet">14    template:</p><p class="snippet">15      metadata:</p><p class="snippet">16        labels:</p><p class="snippet">17          app: redis</p><p class="snippet">18          role: master</p><p class="snippet">19          tier: backend</p><p class="snippet">20      spec:</p><p class="snippet">21        containers:</p><p class="snippet">22        - name: master</p><p class="snippet">23          image: k8s.gcr.io/redis:e2e </p><p class="snippet">24          resources:</p><p class="snippet">25            requests:</p><p class="snippet">26              cpu: 100m</p><p class="snippet">27              memory: 100Mi</p><p class="snippet">28            limits:</p><p class="snippet">29              cpu: 250m</p><p class="snippet">30              memory: 1024Mi</p><p class="snippet">31          ports:</p><p class="snippet">32          - containerPort: 6379</p><p>Let's dive deeper into the code line by line to understand the provided parameters:</p><ul><li><strong class="bold">Line 2</strong>: This states that we are creating a deployment. As explained in <em class="italics">Chapter 1, Introduction to containers and Kubernetes</em>, a deployment is a wrapper around pods that makes it easy to update and scale pods.</li><li><strong class="bold">Lines 4-6</strong>: Here, the <strong class="inline">deployment</strong> is given a name, which is <strong class="inline">redis-master</strong>.</li><li><strong class="bold">Lines 7-12</strong>: These lines let us specify the containers that this deployment will manage. In this example, the deployment will select and manage all containers for which labels match (<strong class="inline">app: redis, role: master, and tier: backend</strong>). The preceding label exactly matches the labels provided in lines <em class="italics">14-19</em>.</li><li><strong class="bold">Line 13</strong>: This line tells Kubernetes that we need exactly one copy of the running Redis master. This is a key aspect of the declarative nature of Kubernetes. You provide a description of the containers your applications need to run (in this case, only one replica of the Redis master), and Kubernetes takes care of it.</li><li><strong class="bold">Line 14-19</strong>: These lines add labels to the running instance so that it can be grouped and connected to other pods. We will discuss them later to see how they are used.</li><li><strong class="bold">Line 22</strong>: This line gives the single container in the pod a name, which is <strong class="inline">master</strong>. In the case of a multi-container pod, each container in a pod requires a unique name.</li><li><strong class="bold">Line 23</strong>: This line indicates the container image that will be run. In this case, it is the <strong class="inline">redis</strong> image tagged with <strong class="inline">e2e</strong> (the latest Redis image that successfully passed its end-to-end [<strong class="inline">e2e</strong>] tests).</li><li><strong class="bold">Lines 24-30</strong>: These lines set the <strong class="inline">cpu/memory</strong> resources requested for the container. A request in Kubernetes is a reservation of resources that cannot be used by other pods. If those resources are not available in the cluster, the pod will not start. In this case, the request is 0.1 CPU, which is equal to <strong class="inline">100m</strong> and is also often referred to as 100 millicores. The memory requested is <strong class="inline">100Mi</strong>, or 104,857,600 bytes, which is equal to ~105 MB. CPU and memory limits are set in a similar way. Limits are caps on what a container can use. If your pod hits the CPU limit, it'll get throttled, whereas if it hits the memory limits, it'll get restarted. Setting requests and limits is a best practice in Kubernetes. For more info, refer to <a href="https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/">https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/</a>.</li><li><strong class="bold">Lines 31-32</strong>: These two lines indicate that the container is going to listen on port <strong class="inline">6379</strong>.</li></ul></li>
			</ol>
			<p>As you can see, the YAML definition for the deployment contains several settings and parameters that Kubernetes will use to deploy and configure your application.</p>
			<h4>Note</h4>
			<p class="callout">The Kubernetes YAML definition is similar to the arguments given to Docker to run a particular container image. If you had to run this manually, you would define this example in the following way:</p>
			<p class="callout"><strong class="inline"># Run a container named master, listening on port 6379, with 100M memory and 100m CPU using the redis:e2e image.</strong></p>
			<p class="callout"><strong class="inline">docker run --name master -p 6379:6379 -m 100M -c 100m -d k8s.gcr.io/redis:e2e</strong></p>
			<p>In this section, you have deployed the Redis master and learned about the syntax of the YAML file that was used to create this deployment. In the next section, you will examine the deployment and learn about the different elements that were created.</p>
			<h3 id="_idParaDest-42"><a id="_idTextAnchor043"/>Examining the deployment</h3>
			<p>The <strong class="inline">redis-master</strong> deployment should be complete by now. Continue in the Azure Cloud Shell that you opened in the previous section and type the following:</p>
			<p class="snippet">kubectl get all</p>
			<p>You should get an output similar to the one displayed in <em class="italics">Figure 3.4</em>. In your case, the name of the pod and the ReplicaSet might contain different IDs at the end of the name. If you do not see a pod, a deployment, and a ReplicaSet, please run the code as explained in step 4 in the previous section again.</p>
			<div>
				<div id="_idContainer063" class="IMG---Figure">
					<img src="image/B17338_03_04.jpg" alt="A list of objects that were created by your deployment"/>
				</div>
			</div>
			<p class="figure">Figure 3.4: Objects that were created by your deployment</p>
			<p>You can see that you created a deployment named <strong class="inline">redis-master</strong>. It controls a ReplicaSet named <strong class="inline">redis-master-f46ff57fd</strong>. On further examination, you will also find that the ReplicaSet is controlling a pod, <strong class="inline">redis- master-f46ff57fd-b8cjp</strong>. <em class="italics">Figure 3.1</em> has a graphical representation of this relationship.</p>
			<p>More details can be obtained by executing the <strong class="inline">kubectl describe &lt;object&gt; &lt;instance-name&gt;</strong> command, as follows:</p>
			<p class="snippet">kubectl describe deployment/redis-master</p>
			<p>This will generate an output as follows:</p>
			<div>
				<div id="_idContainer064" class="IMG---Figure">
					<img src="image/B17338_03_05.jpg" alt="Using the kubectl describe command to fetch the details of the deployment"/>
				</div>
			</div>
			<p class="figure">Figure 3.5: Description of the deployment</p>
			<p>You have now launched a Redis master with the default configuration. Typically, you would launch an application with an environment-specific configuration.</p>
			<p>In the next section, you will get acquainted with a new concept called ConfigMaps and then recreate the Redis master. So, before proceeding, clean up the current version, which you can do by running the following command:</p>
			<p class="snippet">kubectl delete deployment/redis-master</p>
			<p>Executing this command will produce the following output:</p>
			<p class="snippet">deployment.apps "redis-master" deleted</p>
			<p>In this section, you examined the Redis master deployment you created. You saw how a deployment relates to a ReplicaSet and how a ReplicaSet relates to pods. In the following section, you will recreate this Redis master with an environment-specific configuration provided via a ConfigMap.</p>
			<h3 id="_idParaDest-43"><a id="_idTextAnchor044"/>Redis master with a ConfigMap</h3>
			<p>There was nothing wrong with the previous deployment. In practical use cases, it would be rare that you would launch an application without some configuration settings. In this case, you are going to set the configuration settings for <strong class="inline">redis-master</strong> using a ConfigMap.</p>
			<p>A ConfigMap is a portable way of configuring containers without having specialized images for each environment. It has a key-value pair for data that needs to be set on a container. A ConfigMap is used for non-sensitive configuration. Kubernetes has a separate object called a <strong class="bold">Secret</strong>. A Secret is used for configurations that contain critical data such as passwords. This will be explored in detail in <em class="italics">Chapter 10, Storing Secrets in AKS</em> of this book.</p>
			<p>In this example, you are going to create a ConfigMap. In this ConfigMap, you will configure <strong class="inline">redis-config</strong> as the key and the value will be the following two lines:</p>
			<p class="snippet">maxmemory 2mb</p>
			<p class="snippet">maxmemory-policy allkeys-lru</p>
			<p>Now, let's create this ConfigMap. There are two ways to create a ConfigMap:</p>
			<ul>
				<li>Creating a ConfigMap from a file</li>
				<li>Creating a ConfigMap from a YAML file</li>
			</ul>
			<p>In the following two sections, you'll explore both.</p>
			<h3>Creating a ConfigMap from a file</h3>
			<p>The following steps will help us create a ConfigMap from a file:</p>
			<ol>
				<li value="1">Open the Azure Cloud Shell code editor by typing <strong class="inline">code redis-config</strong> in the terminal. Copy and paste the following two lines and save  the file as <strong class="inline">redis-config</strong>:<p class="snippet">maxmemory 2mb</p><p class="snippet">maxmemory-policy allkeys-lru</p></li>
				<li>Now you can create the ConfigMap using the following code:<p class="snippet">kubectl create configmap \</p><p class="snippet">  example-redis-config --from-file=redis-config</p><p>You should get an output as follows:</p><p class="snippet">configmap/example-redis-config created</p></li>
				<li>You can use the same command to describe this ConfigMap:<p class="snippet">kubectl describe configmap/example-redis-config</p><p>The output will be as shown in <em class="italics">Figure 3.6</em>:</p></li>
			</ol>
			<div>
				<div id="_idContainer065" class="IMG---Figure">
					<img src="image/B17338_03_06.jpg" alt="Using the kubectl describe command to fetch the description of the ConfigMap"/>
				</div>
			</div>
			<p class="figure">Figure 3.6: Description of the ConfigMap</p>
			<p>In this example, you created the ConfigMap by referring to a file on disk. A different way to deploy ConfigMaps is by creating them from a YAML file. Let's have a look at how this can be done in the following section.</p>
			<h3>Creating a ConfigMap from a YAML file</h3>
			<p>In this section, you will recreate the ConfigMap from the previous section using a YAML file:</p>
			<ol>
				<li value="1">To start, delete the previously created ConfigMap:<p class="snippet">kubectl delete configmap/example-redis-config</p></li>
				<li>Copy and paste the following lines into a file named <strong class="inline">example-redis-config.yaml</strong>, and then save the file:<p class="snippet">1  apiVersion: v1</p><p class="snippet">2  data:</p><p class="snippet">3    redis-config: |-</p><p class="snippet">4      maxmemory 2mb</p><p class="snippet">5      maxmemory-policy allkeys-lru</p><p class="snippet">6  kind: ConfigMap</p><p class="snippet">7  metadata:</p><p class="snippet">8    name: example-redis-config</p></li>
				<li>You can now create your ConfigMap via the following command:<p class="snippet">kubectl create -f example-redis-config.yaml</p><p>You should get an output as follows:</p><p class="snippet">configmap/example-redis-config created</p></li>
				<li>Next, run the following command:<p class="snippet">kubectl describe configmap/example-redis-config</p><p>This command returns the same output as the previous one, as shown in <em class="italics">Figure 3.6</em>.</p></li>
			</ol>
			<p>As you can see, using a YAML file, you were able to create the same ConfigMap.</p>
			<h4>Note</h4>
			<p class="callout"><strong class="inline">kubectl get </strong>has the useful <strong class="inline">-o</strong> option, which can be used to get the output of an object in either YAML or JSON. This is very useful in cases where you have made manual changes to a system and want to see the resulting object in YAML format. You can get the current ConfigMap in YAML using the following command:</p>
			<p class="callout"><strong class="inline">kubectl get -o yaml configmap/example-redis-config</strong></p>
			<p>Now that you have the ConfigMap defined, let's use it.</p>
			<h3>Using a ConfigMap to read in configuration data</h3>
			<p>In this section, you will reconfigure the <strong class="inline">redis-master</strong> deployment to read configuration from the ConfigMap:</p>
			<ol>
				<li value="1">To start, modify <strong class="inline">redis-master-deployment.yaml</strong> to use the ConfigMap as follows. The changes you need to make will be explained after the source code:<p class="snippet">1  apiVersion: apps/v1</p><p class="snippet">2  kind: Deployment</p><p class="snippet">3  metadata:</p><p class="snippet">4    name: redis-master</p><p class="snippet">5    labels:</p><p class="snippet">6      app: redis</p><p class="snippet">7  spec:</p><p class="snippet">8    selector:</p><p class="snippet">9      matchLabels:</p><p class="snippet">10       app: redis</p><p class="snippet">11       role: master</p><p class="snippet">12       tier: backend</p><p class="snippet">13   replicas: 1</p><p class="snippet">14   template:</p><p class="snippet">15     metadata:</p><p class="snippet">16       labels:</p><p class="snippet">17         app: redis</p><p class="snippet">18         role: master</p><p class="snippet">19         tier: backend</p><p class="snippet">20     spec:</p><p class="snippet">21       containers:</p><p class="snippet">22       - name: master</p><p class="snippet">23         image: k8s.gcr.io/redis:e2e</p><p class="snippet">24         command:</p><p class="snippet">25         - redis-server</p><p class="snippet">26         - "/redis-master/redis.conf"</p><p class="snippet">27         env:</p><p class="snippet">28         - name: MASTER</p><p class="snippet">29           value: "true"</p><p class="snippet">30         volumeMounts:</p><p class="snippet">31         - mountPath: /redis-master</p><p class="snippet">32           name: config</p><p class="snippet">33         resources:</p><p class="snippet">34           requests:</p><p class="snippet">35             cpu: 100m</p><p class="snippet">36             memory: 100Mi</p><p class="snippet">37         ports:</p><p class="snippet">38         - containerPort: 6379</p><p class="snippet">39       volumes:</p><p class="snippet">40         - name: config</p><p class="snippet">41           configMap:</p><p class="snippet">42             name: example-redis-config</p><p class="snippet">43             items:</p><p class="snippet">44             - key: redis-config</p><p class="snippet">45               path: redis.conf</p><h4>Note</h4><p class="callout">If you downloaded the source code accompanying this book, there is a file in <em class="italics">Chapter 3, Application deployment on AKS</em>, called <strong class="inline">redis-master-deployment_Modified.yaml</strong>, that has the necessary changes applied to it.</p><p>Let's dive deeper into the code to understand the different sections:</p><ul><li><strong class="bold">Lines 24-26</strong>: These lines introduce a command that will be executed when your pod starts. In this case, this will start the <strong class="inline">redis-server</strong> pointing to a specific configuration file.</li><li><strong class="bold">Lines 27-29</strong>: These lines show how to pass configuration data to your running container. This method uses environment variables. In Docker form, this would be equivalent to <strong class="inline">docker run -e "MASTER=true". --name master -p 6379:6379 -m 100M -c 100m -d Kubernetes /redis:v1</strong>. This sets the environment variable <strong class="inline">MASTER</strong> to <strong class="inline">true</strong>. Your application can read the environment variable settings for its configuration.</li><li><strong class="bold">Lines 30-32</strong>: These lines mount the volume called <strong class="inline">config</strong> (this volume is defined in lines 39-45) on the <strong class="inline">/redis-master</strong> path on the running container. It will hide whatever exists on <strong class="inline">/redis-master</strong> on the original container.</li><li>In Docker terms, it would be equivalent to  <strong class="inline">docker run -v config:/redis-master. -e "MASTER=TRUE" --name master -p 6379:6379 -m 100M -c 100m -d Kubernetes /redis:v1</strong>.</li><li><strong class="bold">Line 40</strong>: This gives the volume the name <strong class="inline">config</strong>. This name will be used within the context of this pod.</li><li><strong class="bold">Lines 41-42</strong>: This declares that this volume should be loaded from the <strong class="inline">example-redis-config</strong> ConfigMap. This ConfigMap should already exist in the system. You have already defined this, so you are good.</li><li><strong class="bold">Lines 43-45</strong>: Here, you are loading the value of the <strong class="inline">redis-config</strong> key (the two-line <strong class="inline">maxmemory</strong> settings) as a <strong class="inline">redis.conf</strong> file.</li></ul></li>
			</ol>
			<p>By adding the ConfigMap as a volume and mounting the volume, you are able to load dynamic configuration.</p>
			<ol>
				<li value="1">Let's create this updated deployment:<p class="snippet">kubectl create -f redis-master-deployment_Modified.yaml</p><p>This should output the following:</p><p class="snippet">deployment.apps/redis-master created</p></li>
				<li>Let's now make sure that the configuration was successfully applied. First, get the pod's name:<p class="snippet">kubectl get pods</p><p>This should return an output similar to <em class="italics">Figure 3.7</em>:</p><div id="_idContainer066" class="IMG---Figure"><img src="image/B17338_03_07.jpg" alt="Fetching the details of the Redis-master pod using the kubectl get pods command"/></div><p class="figure">Figure 3.7: Details of the pod</p></li>
				<li>Then <strong class="inline">exec</strong> into the pod and verify that the settings were applied:<p class="snippet">kubectl exec -it redis-master-&lt;pod-id&gt; -- redis-cli</p><p>This open a <strong class="inline">redis-cli</strong> session with the running pod. Now you can get the <strong class="inline">maxmemory</strong> configuration:</p><p class="snippet">CONFIG GET maxmemory</p><p>And then you can get the <strong class="inline">maxmemory-policy</strong> configuration:</p><p class="snippet">CONFIG GET maxmemory-policy</p><p>This should give you an output similar to <em class="italics">Figure 3.8</em>:</p><div id="_idContainer067" class="IMG---Figure"><img src="image/B17338_03_08.jpg" alt="Verifying the maxmemoery and maxmemory-policy custom configuration"/></div><p class="figure">Figure 3.8: Verifying the Redis configuration in the pod</p></li>
				<li>To leave the Redis shell, type the <strong class="inline">exit</strong> command.</li>
			</ol>
			<p>To summarize, you have just performed an important part of configuring cloud-native applications, namely providing dynamic configuration data to an application. You will have also noticed that the apps have to be configured to read config dynamically. After you set up your app with configuration, you accessed a running container to verify the running configuration. You will use this methodology frequently throughout this book to verify the functionality of running applications.</p>
			<h4>Note</h4>
			<p class="callout">Connecting to a running container by using the <strong class="inline">kubectl exec</strong> command is useful for troubleshooting and doing diagnostics. Due to the ephemeral nature of containers, you should never connect to a container to do additional configuration or installation. This should either be part of your container image or configuration you provide via Kubernetes (as you just did).</p>
			<p>In this section, you configured the Redis master to load configuration data from a ConfigMap. In the next section, we will deploy the end-to-end application.</p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor045"/>Complete deployment of the sample guestbook application</h2>
			<p>Having taken a detour to understand the dynamic configuration of applications using a ConfigMap, you will now return to the deployment of the rest of the guestbook application. You will once again come across the concepts of deployment, ReplicaSets, and pods. Apart from this, you will also be introduced to another key concept, called a service.</p>
			<p>To start the complete deployment, we are going to create a service to expose the Redis master service.</p>
			<h3 id="_idParaDest-45"><a id="_idTextAnchor046"/>Exposing the Redis master service</h3>
			<p>When exposing a port in plain Docker, the exposed port is constrained to the host it is running on. With Kubernetes networking, there is network connectivity between different pods in the cluster. However, pods themselves are ephemeral in nature, meaning they can be shut down, restarted, or even moved to other hosts without maintaining their IP address. If you were to connect to the IP of a pod directly, you might lose connectivity if that pod was moved to a new host.</p>
			<p>Kubernetes provides the <strong class="inline">service</strong> object, which handles this exact problem. Using label-matching selectors, it sends traffic to the right pods. If there are multiple pods serving traffic to a service, it will also do load balancing. In this case, the master has only one pod, so it just ensures that the traffic is directed to the pod independent of the node the pod runs on. To create the service, run the following command:</p>
			<p class="snippet">kubectl apply -f redis-master-service.yaml</p>
			<p>The <strong class="inline">redis-master-service.yaml</strong> file has the following content:</p>
			<p class="snippet">1   apiVersion: v1</p>
			<p class="snippet">2   kind: Service</p>
			<p class="snippet">3   metadata:</p>
			<p class="snippet">4     name: redis-master</p>
			<p class="snippet">5     labels:</p>
			<p class="snippet">6       app: redis</p>
			<p class="snippet">7       role: master</p>
			<p class="snippet">8       tier: backend</p>
			<p class="snippet">9   spec:</p>
			<p class="snippet">10   ports:</p>
			<p class="snippet">11   - port: 6379</p>
			<p class="snippet">12     targetPort: 6379</p>
			<p class="snippet">13    selector:</p>
			<p class="snippet">14      app: redis</p>
			<p class="snippet">15      role: master</p>
			<p class="snippet">16      tier: backend</p>
			<p>Let's now see what you have created using the preceding code:</p>
			<ul>
				<li><strong class="bold">Lines 1-8</strong>: These lines tell Kubernetes that we want a service called <strong class="inline">redis-master</strong>, which has the same labels as our <strong class="inline">redis-master</strong> server pod.</li>
				<li><strong class="bold">Lines 10-12</strong>: These lines indicate that the service should handle traffic arriving at port <strong class="inline">6379</strong> and forward it to port <strong class="inline">6379</strong> of the pods that match the selector defined between lines 13 and 16.</li>
				<li><strong class="bold">Lines 13-16</strong>: These lines are used to find the pods to which the incoming traffic needs to be sent. So, any pod with labels matching (<strong class="inline">app: redis, role: master and tier: backend</strong>) is expected to handle port <strong class="inline">6379</strong> traffic. If you look back at the previous example, those are the exact labels we applied to that deployment.</li>
			</ul>
			<p>You can check the properties of the service by running the following command:</p>
			<p class="snippet">kubectl get service</p>
			<p>This will give you an output as shown in <em class="italics">Figure 3.9</em>:</p>
			<div>
				<div id="_idContainer068" class="IMG---Figure">
					<img src="image/B17338_03_09.jpg" alt="Obtaining the properties of the Redis-master service using the kubectl get service command"/>
				</div>
			</div>
			<p class="figure">Figure 3.9: Properties of the created service</p>
			<p>You see that a new service, named <strong class="inline">redis-master</strong>, has been created. It has a Cluster-IP of <strong class="inline">10.0.106.207</strong> (in your case, the IP will likely be different). Note that this IP will work only within the cluster (hence the <strong class="inline">ClusterIP</strong> type).</p>
			<h4>Note</h4>
			<p class="callout">You are now creating a service of type <strong class="inline">ClusterIP</strong>. There are other types of service as well, which will be introduced later in this chapter.</p>
			<p>A service also introduces a <strong class="bold">Domain Name Server</strong> (<strong class="bold">DNS</strong>) name for that service. The DNS name is of the form <strong class="inline">&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local</strong>; in this case, it would be <strong class="inline">redis-master.default.svc.cluster.local</strong>. To see this in action, we'll do a name resolution on our <strong class="inline">redis-master</strong> pod. The default image doesn't have <strong class="inline">nslookup</strong> installed, so we'll bypass that by running a <strong class="inline">ping</strong> command. Don't worry if that traffic doesn't return; this is because you didn't expose <strong class="inline">ping</strong> on your service, only the <strong class="inline">redis</strong> port. The command is, however, useful to see the full DNS name and the name resolution work. Let's have a look:</p>
			<p class="snippet">kubectl get pods</p>
			<p class="snippet">#note the name of your redis-master pod</p>
			<p class="snippet">kubectl exec -it redis-master-&lt;pod-id&gt; -- bash</p>
			<p class="snippet">ping redis-master</p>
			<p>This should output the resulting name resolution, showing you the <strong class="bold">Fully Qualified Domain Name</strong> (<strong class="bold">FQDN</strong>) of your service and the IP address that showed up earlier. You can stop the ping command from running by pressing <em class="italics">Ctrl</em>+<em class="italics">C</em>. You can exit the pod via the <strong class="inline">exit</strong> command, as shown in <em class="italics">Figure 3.10</em>:</p>
			<div>
				<div id="_idContainer069" class="IMG---Figure">
					<img src="image/B17338_03_10.jpg" alt="Using a ping command to view the FQDN of your service"/>
				</div>
			</div>
			<p class="figure">Figure 3.10: Using a ping command to view the FQDN of your service</p>
			<p>In this section, you exposed the Redis master using a service. This ensures that even if a pod moves to a different host, it can be reached through the service's IP address. In the next section, you will deploy the Redis replicas, which help to handle more read traffic.</p>
			<h3 id="_idParaDest-46"><a id="_idTextAnchor047"/>Deploying the Redis replicas</h3>
			<p>Running a single back end on the cloud is not recommended. You can configure Redis in a leader-follower (master-slave) setup. This means that you can have a master that will serve write traffic and multiple replicas that can handle read traffic. It is useful for handling increased read traffic and high availability.</p>
			<p>Let's set this up:</p>
			<ol>
				<li value="1">Create the deployment by running the following command:<p class="snippet">kubectl apply -f redis-replica-deployment.yaml</p></li>
				<li>Let's check all the resources that have been created now:<p class="snippet">kubectl get all</p><p>The output would be as shown in <em class="italics">Figure 3.11</em>:</p><div id="_idContainer070" class="IMG---Figure"><img src="image/B17338_03_11.jpg" alt="Using the kubectl get all command to show all objects created"/></div><p class="figure">Figure 3.11: Deploying the Redis replicas creates a number of new objects</p></li>
				<li>Based on the preceding output, you can see that you created two replicas of the <strong class="inline">redis-replica</strong> pods. This can be confirmed by examining the <strong class="inline">redis-replica- deployment.yaml</strong> file:<p class="snippet">1   apiVersion: apps/v1</p><p class="snippet">2   kind: Deployment</p><p class="snippet">3   metadata:</p><p class="snippet">4     name: redis-replica</p><p class="snippet">5     labels:</p><p class="snippet">6       app: redis</p><p class="snippet">7   spec:</p><p class="snippet">8     selector:</p><p class="snippet">9       matchLabels:</p><p class="snippet">10       app: redis</p><p class="snippet">11       role: replica</p><p class="snippet">12       tier: backend</p><p class="snippet">13   replicas: 2</p><p class="snippet">14   template:</p><p class="snippet">15     metadata:</p><p class="snippet">16       labels:</p><p class="snippet">17         app: redis</p><p class="snippet">18         role: replica</p><p class="snippet">19         tier: backend</p><p class="snippet">20     spec:</p><p class="snippet">21       containers:</p><p class="snippet">22       - name: replica</p><p class="snippet">23         image: gcr.io/google-samples/gb-redis-follower:v1 24         resources:</p><p class="snippet">25           requests:</p><p class="snippet">26             cpu: 100m</p><p class="snippet">27             memory: 100Mi</p><p class="snippet">28         env:</p><p class="snippet">29         - name: GET_HOSTS_FROM</p><p class="snippet">30           value: dns</p><p class="snippet">31         ports:</p><p class="snippet">32         - containerPort: 6379</p><p>Everything is the same except for the following:</p><ul><li><strong class="bold">Line 13</strong>: The number of replicas is 2.</li><li><strong class="bold">Line 23</strong>: You are now using a specific replica (follower) image.</li><li><strong class="bold">Lines 29-30</strong>: Setting <strong class="inline">GET_HOSTS_FROM</strong> to <strong class="inline">dns</strong>. This is a setting that specifies that Redis should get the hostname of the master using DNS.</li></ul><p>As you can see, this is similar to the Redis master you created earlier.</p></li>
				<li>Like the master service, you need to expose the replica service by running the following:<p class="snippet">kubectl apply -f redis-replica-service.yaml</p><p>The only difference between this service and the <strong class="inline">redis-master</strong> service is that this service proxies traffic to pods that have the <strong class="inline">role:replica</strong> label.</p></li>
				<li>Check the <strong class="inline">redis-replica</strong> service by running the following command:<p class="snippet">kubectl get service</p><p>This should give you the output shown in <em class="italics">Figure 3.12</em>:</p></li>
			</ol>
			<div>
				<div id="_idContainer071" class="IMG---Figure">
					<img src="image/B17338_03_12.jpg" alt="Redis master and Redis replica configuration details"/>
				</div>
			</div>
			<p class="figure">Figure 3.12: Redis-master and redis-replica service</p>
			<p>You now have a Redis cluster up and running, with a single master and two replicas. In the next section, you will deploy and expose the front end.</p>
			<h3 id="_idParaDest-47"><a id="_idTextAnchor048"/>Deploying and exposing the front end</h3>
			<p>Up to now, you have focused on the Redis back end. Now you are ready to deploy the front end. This will add a graphical web page to your application that you'll be able to interact with.</p>
			<p>You can create the front end using the following command:</p>
			<p class="snippet">kubectl apply -f frontend-deployment.yaml</p>
			<p>To verify the deployment, run this command:</p>
			<p class="snippet">kubectl get pods</p>
			<p>This will display the output shown in <em class="italics">Figure 3.13</em>:</p>
			<div>
				<div id="_idContainer072" class="IMG---Figure">
					<img src="image/B17338_03_13.jpg" alt="Details of the frontend deployment"/>
				</div>
			</div>
			<p class="figure">Figure 3.13: Verifying the front end deployment </p>
			<p>You will notice that this deployment specifies <strong class="inline">3</strong> replicas. The deployment has the usual aspects with minor changes, as shown in the following code:</p>
			<p class="snippet">1  apiVersion: apps/v1</p>
			<p class="snippet">2   kind: Deployment</p>
			<p class="snippet">3   metadata:</p>
			<p class="snippet">4     name: frontend</p>
			<p class="snippet">5     labels:</p>
			<p class="snippet">6       app: guestbook</p>
			<p class="snippet">7   spec:</p>
			<p class="snippet">8     selector:</p>
			<p class="snippet">9       matchLabels:</p>
			<p class="snippet">10        app: guestbook</p>
			<p class="snippet">11        tier: frontend</p>
			<p class="snippet">12    replicas: 3</p>
			<p class="snippet">13    template:</p>
			<p class="snippet">14      metadata:</p>
			<p class="snippet">15        labels:</p>
			<p class="snippet">16          app: guestbook</p>
			<p class="snippet">17          tier: frontend</p>
			<p class="snippet">18      spec:</p>
			<p class="snippet">19        containers:</p>
			<p class="snippet">20        - name: php-redis</p>
			<p class="snippet">21          image: gcr.io/google-samples/gb-frontend:v4</p>
			<p class="snippet">22          resources:</p>
			<p class="snippet">23            requests:</p>
			<p class="snippet">24              cpu: 100m</p>
			<p class="snippet">25              memory: 100Mi</p>
			<p class="snippet">26          env:</p>
			<p class="snippet">27          - name: GET_HOSTS_FROM</p>
			<p class="snippet">28            value: env</p>
			<p class="snippet">29          - name: REDIS_SLAVE_SERVICE_HOST</p>
			<p class="snippet">30            value: redis-replica</p>
			<p class="snippet">31          ports:</p>
			<p class="snippet">32          - containerPort: 80</p>
			<p>Let's see these changes:</p>
			<ul>
				<li><strong class="bold">Line 11</strong>: The replica count is set to 3.</li>
				<li><strong class="bold">Line 8-10 and 14-16</strong>: The labels are set to <strong class="inline">app: guestbook</strong> and <strong class="inline">tier: frontend</strong>.</li>
				<li><strong class="bold">Line 20</strong>: <strong class="inline">gb-frontend:v4</strong> is used as the image.</li>
			</ul>
			<p>You have now created the front-end deployment. You now need to expose it as a service.</p>
			<h3>Exposing the front-end service</h3>
			<p>There are multiple ways to define a Kubernetes service. The two Redis services we created were of the type <strong class="inline">ClusterIP</strong>. This means they are exposed on an IP that is reachable only from the cluster, as shown in <em class="italics">Figure 3.14</em>:</p>
			<div>
				<div id="_idContainer073" class="IMG---Figure">
					<img src="image/B17338_03_14.jpg" alt="Kubernetes service of type ClusterIP"/>
				</div>
			</div>
			<p class="figure">Figure 3.14: Kubernetes service of type ClusterIP</p>
			<p>Another type of service is the type <strong class="inline">NodePort</strong>. A service of type NodePort is accessible from outside the cluster, by connecting to the IP of a node and the specified port. This service is exposed on a static port on each node as shown in <em class="italics">Figure 3.15</em>:</p>
			<div>
				<div id="_idContainer074" class="IMG---Figure">
					<img src="image/B17338_03_15.jpg" alt="Kubernetes service of type NodePort"/>
				</div>
			</div>
			<p class="figure">Figure 3.15: Kubernetes service of type NodePort</p>
			<p>A final type – which will be used in this example – is the <strong class="inline">LoadBalancer</strong> type. This will create an <strong class="bold">Azure Load Balancer</strong> that will get a public IP that you can use to connect to, as shown in <em class="italics">Figure 3.16</em>:</p>
			<div>
				<div id="_idContainer075" class="IMG---Figure">
					<img src="image/B17338_03_16.jpg" alt="Kubernetes service of type LoadBalancer"/>
				</div>
			</div>
			<p class="figure">Figure 3.16: Kubernetes service of type LoadBalancer</p>
			<p>The following code will help you to understand how the frontend service is exposed:</p>
			<p class="snippet">1   apiVersion: v1</p>
			<p class="snippet">2   kind: Service</p>
			<p class="snippet">3   metadata:</p>
			<p class="snippet">4     name: frontend</p>
			<p class="snippet">5     labels:</p>
			<p class="snippet">6       app: guestbook</p>
			<p class="snippet">7       tier: frontend</p>
			<p class="snippet">8   spec:</p>
			<p class="snippet">9     type: LoadBalancer # line uncommented</p>
			<p class="snippet">10    ports:</p>
			<p class="snippet">11    - port: 80</p>
			<p class="snippet">12    selector:</p>
			<p class="snippet">13      app: guestbook</p>
			<p class="snippet">14      tier: frontend</p>
			<p>This definition is similar to the services you created earlier, except that in <em class="italics">line 9</em> you defined <strong class="inline">type: Load Balancer</strong>. This will create a service of that type, which will cause AKS to add rules to the Azure load balancer.</p>
			<p>Now that you have seen how a front-end service is exposed, let's make the guestbook application ready for use with the following steps:</p>
			<ol>
				<li value="1">To create the service, run the following command:<p class="snippet">kubectl create -f frontend-service.yaml</p><p>This step takes some time to execute when you run it for the first time. In the background, Azure must perform a couple of actions to make it seamless. It has to create an Azure load balancer and a public IP and set the port-forwarding rules to forward traffic on port <strong class="inline">80</strong> to internal ports of the cluster.</p></li>
				<li>Run the following until there is a value in the <strong class="inline">EXTERNAL-IP</strong> column:<p class="snippet">kubectl get service -w</p><p>This should display the output shown in <em class="italics">Figure 3.17</em>:</p><div id="_idContainer076" class="IMG---Figure"><img src="image/B17338_03_17.jpg" alt="Fetching the external IP value of the front-end deployment"/></div><p class="figure">Figure 3.17: External IP value</p></li>
				<li>In the Azure portal, if you click on <span class="P---Screen-Text">All Resources</span> and filter on <span class="P---Screen-Text">Load balancer</span>, you will see a <span class="P---Screen-Text">kubernetes Load balancer</span>. Clicking on it shows you something similar to <em class="italics">Figure 3.18</em>. The highlighted sections show you that there is a load balancing rule accepting traffic on <strong class="inline">port 80</strong> and you have two public IP addresses:</li>
			</ol>
			<div>
				<div id="_idContainer077" class="IMG---Figure">
					<img src="image/B17338_03_18.jpg" alt="Azure load balancer showing the load balancing rule accepting traffic on port 80 "/>
				</div>
			</div>
			<p class="figure">Figure 3.18: kubernetes Load balancer in the Azure portal</p>
			<p>If you click through on the two public IP addresses, you'll see both IP addresses linked to your cluster. One of those will be the IP address of your actual front-end service; the other one is used by AKS to make outbound connections.</p>
			<h4>Note</h4>
			<p class="callout">Azure has two types of load balancers: basic and standard.</p>
			<p class="callout">Virtual machines behind a basic load balancer can make outbound connections without any specific configuration. Virtual machines behind a standard load balancer (which is the default for AKS now) need an outbound rule on the load balancer to make outbound connections. This is why you see a second IP address configured.</p>
			<p>You're finally ready to see your guestbook app in action!</p>
			<h3 id="_idParaDest-48"><a id="_idTextAnchor049"/>The guestbook application in action</h3>
			<p>Type the public IP of the service in your favorite browser. You should get the output shown in <em class="italics">Figure 3.19</em>:</p>
			<div>
				<div id="_idContainer078" class="IMG---Figure">
					<img src="image/B17338_03_19.jpg" alt="Using the public IP address to see the Guestbook application in action"/>
				</div>
			</div>
			<p class="figure">Figure 3.19: The guestbook application in action</p>
			<p>Go ahead and record your messages. They will be saved. Open another browser and type the same IP; you will see all the messages you typed.</p>
			<p>Congratulations – you have completed your first fully deployed, multi-tier, cloud-native Kubernetes application!</p>
			<p>To conserve resources on your free-trial virtual machines, it is better to delete the created deployments to run the next round of the deployments by using the following commands:</p>
			<p class="snippet">kubectl delete deployment frontend redis-master redis-replica</p>
			<p class="snippet">kubectl delete service frontend redis-master redis-replica</p>
			<p>Over the course of the preceding sections, you have deployed a Redis cluster and deployed a publicly accessible web application. You have learned how deployments, ReplicaSets, and pods are linked, and you have learned how Kubernetes uses the <strong class="inline">service</strong> object to route network traffic. In the next section of this chapter, you will use Helm to deploy a more complex application on top of Kubernetes.</p>
			<h2 id="_idParaDest-49"><a id="_idTextAnchor050"/>Installing complex Kubernetes applications using Helm</h2>
			<p>In the previous section, you used static YAML files to deploy an application. When deploying more complicated applications, across multiple environments (such as dev/test/prod), it can become cumbersome to manually edit YAML files for each environment. This is where the Helm tool comes in.</p>
			<p>Helm is the package manager for Kubernetes. Helm helps you deploy, update, and manage Kubernetes applications at scale. For this, you write something called Helm Charts.</p>
			<p>You can think of Helm Charts as parameterized Kubernetes YAML files. If you think about the Kubernetes YAML files we wrote in the previous section, those files were static. You would need to go into the files and edit them to make changes.</p>
			<p>Helm Charts allow you to write YAML files with certain parameters in them, which you can dynamically set. This setting of the parameters can be done through a values file or as a command-line variable when you deploy the chart.</p>
			<p>Finally, with Helm, you don't necessarily have to write Helm Charts yourself; you can also use a rich library of pre-written Helm Charts and install popular software in your cluster through a simple command such as <strong class="inline">helm install --name my-release stable/mysql</strong>.</p>
			<p>This is exactly what you are going to do in the next section. You will install WordPress on your cluster by issuing only two commands. In the next chapters, you'll also dive into custom Helm Charts that you'll edit.</p>
			<h4>Note</h4>
			<p class="callout">On November 13, 2019, the first stable release of Helm v3 was released. We will be using Helm v3 in the following examples. The biggest difference between Helm v2 and Helm v3 is that Helm v3 is a fully client-side tool that no longer requires the server-side tool called <strong class="bold">Tiller</strong>.</p>
			<p>Let's start by installing WordPress on your cluster using Helm. In this section, you'll also learn about persistent storage in Kubernetes.</p>
			<h3 id="_idParaDest-50"><a id="_idTextAnchor051"/>Installing WordPress using Helm</h3>
			<p>As mentioned in the introduction, Helm has a rich library of pre-written Helm Charts. To access this library, you'll have to add a repo to your Helm client:</p>
			<ol>
				<li value="1">Add the repo that contains the stable Helm Charts using the following command:<p class="snippet">helm repo add bitnami \</p><p class="snippet">  https://charts.bitnami.com/bitnami</p></li>
				<li>To install WordPress, run the following command:<p class="snippet">helm install handsonakswp bitnami/wordpress</p><p>This execution will cause Helm to install the chart detailed at <a href="https://github.com/bitnami/charts/tree/master/bitnami/wordpress">https://github.com/bitnami/charts/tree/master/bitnami/wordpress</a>.</p></li>
			</ol>
			<p>It takes some time for Helm to install and the site to come up. Let's look at a key concept, <strong class="inline">PersistentVolumeClaims</strong>, while the site is loading. After covering this, we'll go back and look at your site that got created.</p>
			<h3>PersistentVolumeClaims</h3>
			<p>A typical process requires compute, memory, network, and storage. In the guestbook example, we saw how Kubernetes helps us abstract the compute, memory, and network. The same YAML files work across all cloud providers, including a cloud-specific setup of public-facing load balancers. The WordPress example shows how the last piece, namely storage, is abstracted from the underlying cloud provider.</p>
			<p>In this case, the WordPress Helm Chart depends on the MariaDB helm chart (<a href="https://github.com/bitnami/charts/tree/master/bitnami/mariadb">https://github.com/bitnami/charts/tree/master/bitnami/mariadb</a>) for its database installation.</p>
			<p>Unlike stateless applications, such as our front ends, MariaDB requires careful handling of storage. To make Kubernetes handle stateful workloads, it has a specific object called a <strong class="bold">StatefulSet</strong>. A StatefulSet (<a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/</a>) is like a deployment with the additional capability of ordering, and the uniqueness of the pods. This means that Kubernetes will ensure that the pod and its storage are kept together. Another way that StatefulSets help is with the consistent naming of pods in a StatefulSet. The pods are named <strong class="inline">&lt;pod-name&gt;-#</strong>, where <strong class="inline">#</strong> starts from <strong class="inline">0</strong> for the first pod, and <strong class="inline">1</strong> for the second pod.</p>
			<p>Running the following command, you can see that MariaDB has a predictable number attached to it, whereas the WordPress deployment has a random number attached to the end:</p>
			<p class="snippet">kubectl get pods</p>
			<p>This will generate the output shown in <em class="italics">Figure 3.20</em>:</p>
			<div>
				<div id="_idContainer079" class="IMG---Figure">
					<img src="image/B17338_03_20.jpg" alt="Naming of pods using a StatefulSet"/>
				</div>
			</div>
			<p class="figure">Figure 3.20: Numbers attached to MariaDB and WordPress pods</p>
			<p>The numbering reinforces the ephemeral nature of the deployment pods versus the StatefulSet pods.</p>
			<p>Another difference is how pod deletion is handled. When a deployment pod is deleted, Kubernetes will launch it again anywhere it can, whereas when a StatefulSet pod is deleted, Kubernetes will relaunch it only on the node it was running on. It will relocate the pod only if the node is removed from the Kubernetes cluster.</p>
			<p>Often, you will want to attach storage to a StatefulSet. To achieve this, a StatefulSet requires a <strong class="bold">PersistentVolume</strong> (<strong class="bold">PV</strong>). This volume can be backed by many mechanisms (including blocks, such as Azure Blob, EBS, and iSCSI, and network filesystems, such as AFS, NFS, and GlusterFS). StatefulSets require either a pre-provisioned volume or a dynamically provisioned volume handled by a <strong class="bold">PersistentVolumeClaim</strong> (<strong class="bold">PVC</strong>). A PVC allows a user to dynamically request storage, which will result in a PV being created.</p>
			<p>Please refer to <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">https://kubernetes.io/docs/concepts/storage/persistent-volumes/</a> for more detailed information.</p>
			<p>In this WordPress example, you are using a PVC. A PVC provides an abstraction over the underlying storage mechanism. Let's look at what the MariaDB Helm Chart did by running the following:</p>
			<p class="snippet">kubectl get statefulset -o yaml &gt; mariadbss.yaml</p>
			<p class="snippet">code mariadbss.yaml</p>
			<p>In the preceding command, you got the YAML definition of the StatefulSet that was created and stored it in a file called <strong class="inline">mariadbss.yaml</strong>. Let's look at the most relevant parts of that YAML file. The code has been truncated to only show the most relevant parts:</p>
			<p class="snippet">1   apiVersion: v1</p>
			<p class="snippet">2   items:</p>
			<p class="snippet">3   - apiVersion: apps/v1</p>
			<p class="snippet">4     kind: StatefulSet</p>
			<p class="snippet">...</p>
			<p class="snippet">285           volumeMounts:</p>
			<p class="snippet">286           - mountPath: /bitnami/mariadb</p>
			<p class="snippet">287             name: data</p>
			<p class="snippet">...           </p>
			<p class="snippet">306 volumeClaimTemplates:</p>
			<p class="snippet">307 - apiVersion: v1</p>
			<p class="snippet">308   kind: PersistentVolumeClaim</p>
			<p class="snippet">309   metadata:</p>
			<p class="snippet">310     creationTimestamp: null</p>
			<p class="snippet">311     labels:</p>
			<p class="snippet">312       app.kubernetes.io/component: primary</p>
			<p class="snippet">313       app.kubernetes.io/instance: handsonakswp</p>
			<p class="snippet">314       app.kubernetes.io/name: mariadb</p>
			<p class="snippet">315     name: data</p>
			<p class="snippet">316   spec:</p>
			<p class="snippet">317     accessModes:</p>
			<p class="snippet">318     - ReadWriteOnce</p>
			<p class="snippet">319     resources:</p>
			<p class="snippet">320       requests:</p>
			<p class="snippet">321         storage: 8Gi</p>
			<p class="snippet">322     volumeMode: Filesystem</p>
			<p class="snippet">...</p>
			<p>Most of the elements of the preceding code have been covered earlier in the deployment. In the following points, we will highlight the key differences, to take a look at just the PVC:</p>
			<h4>Note</h4>
			<p class="callout">PVC can be used by any pod, not just StatefulSet pods.</p>
			<p>Let's discuss the different elements of the preceding code in detail:</p>
			<ul>
				<li><strong class="bold">Line 4</strong>: This line indicates the <strong class="inline">StatefulSet</strong> declaration.</li>
				<li><strong class="bold">Lines 285-287</strong>: These lines mount the volume defined as <strong class="inline">data</strong> and mount it under the <strong class="inline">/bitnami/mariadb</strong> path.</li>
				<li><strong class="bold">Lines 306-322</strong>: These lines declare the PVC. Note specifically:<ul><li><strong class="bold">Line 315</strong>: This line gives it the name <strong class="inline">data</strong>, which is reused at <em class="italics">line 285</em>.</li><li><strong class="bold">Line 318</strong>: This line gives the access mode <strong class="inline">ReadWriteOnce</strong>, which will create block storage, which on Azure is a disk. There are other access modes as well, namely <strong class="inline">ReadOnlyMany</strong> and <strong class="inline">ReadWriteMany</strong>. As the name suggests, a <strong class="inline">ReadWriteOnce</strong> volume can only be attached to a single pod, while a <strong class="inline">ReadOnlyMany</strong> or <strong class="inline">ReadWriteMany</strong> volume can be attached to multiple pods at the same time. These last two types require a different underlying storage mechanism such as Azure Files or Azure Blob.</li><li><strong class="bold">Line 321</strong>: This line defines the size of the disk.</li></ul></li>
			</ul>
			<p>Based on the preceding information, Kubernetes dynamically requests and binds an 8 GiB volume to this pod. In this case, the default dynamic-storage provisioner backed by the Azure disk is used. The dynamic provisioner was set up by Azure when you created the cluster. To see the storage classes available on your cluster, you can run the following command:</p>
			<p class="snippet">kubectl get storageclass</p>
			<p>This will show you an output similar to <em class="italics">Figure 3.21</em>:</p>
			<div>
				<div id="_idContainer080" class="IMG---Figure">
					<img src="image/B17338_03_21.jpg" alt="List of storage classes available on your cluster"/>
				</div>
			</div>
			<p class="figure">Figure 3.21: Different storage classes in your cluster</p>
			<p>We can get more details about the PVC by running the following:</p>
			<p class="snippet">kubectl get pvc</p>
			<p>The output generated is displayed in <em class="italics">Figure 3.22</em>:</p>
			<div>
				<div id="_idContainer081" class="IMG---Figure">
					<img src="image/B17338_03_22.jpg" alt="A list of PVCs in the created cluster"/>
				</div>
			</div>
			<p class="figure">Figure 3.22: Different PVCs in the cluster</p>
			<p>When we asked for storage in the StatefulSet description (<em class="italics">lines 128-143</em>), Kubernetes performed Azure-disk-specific operations to get the Azure disk with 8 GiB of storage. If you copy the name of the PVC and paste that in the Azure search bar, you should find the disk that was created:</p>
			<div>
				<div id="_idContainer082" class="IMG---Figure">
					<img src="image/B17338_03_23.jpg" alt="Getting the disk linked to a PVC"/>
				</div>
			</div>
			<p class="figure">Figure 3.23: Getting the disk linked to a PVC</p>
			<p>The concept of a PVC abstracts cloud provider storage specifics. This allows the same Helm template to work across Azure, AWS, or GCP. On AWS, it will be backed by <strong class="bold">Elastic Block Store</strong> (<strong class="bold">EBS</strong>), and on GCP it will be backed by Persistent Disk.</p>
			<p>Also, note that PVCs can be deployed without using Helm.</p>
			<p>In this section, the concept of storage in Kubernetes using <strong class="bold">PersistentVolumeClaim </strong>(<strong class="bold">PVC</strong>) was introduced. You saw how they were created by the WordPress Helm deployment, and how Kubernetes created an Azure disk to support the PVC used by MariaDB. In the next section, you will explore the WordPress application on Kubernetes in more detail.</p>
			<h3>Checking the WordPress deployment</h3>
			<p>After our analysis of the PVCs, let's check back in with the Helm deployment. You can check the status of the deployment using:</p>
			<p class="snippet">helm ls</p>
			<p>This should return the output shown in <em class="italics">Figure 3.24</em>:</p>
			<div>
				<div id="_idContainer083" class="IMG---Figure">
					<img src="image/B17338_03_24.jpg" alt="Checking status of the WordPress application deployment in Helm"/>
				</div>
			</div>
			<p class="figure">Figure 3.24: WordPress application deployment status</p>
			<p>We can get more info from our deployment in Helm using the following command:</p>
			<p class="snippet">helm status handsonakswp</p>
			<p>This will return the output shown in <em class="italics">Figure 3.25</em>:</p>
			<div>
				<div id="_idContainer084" class="IMG---Figure">
					<img src="image/B17338_03_25.jpg" alt="Fetching further details of the WordPress deployment using the helm status command"/>
				</div>
			</div>
			<p class="figure">Figure 3.25: Getting more details about the deployment</p>
			<p>This shows you that your chart was deployed successfully. It also shows more info on how you can connect to your site. You won't be using these steps for now; you will revisit these steps in <em class="italics">Chapter 5, Handling common failures in AKS</em>, in the section where we cover fixing storage mount issues. For now, let's look into everything that Helm created for you:</p>
			<p class="snippet">kubectl get all</p>
			<p>This will generate an output similar to <em class="italics">Figure 3.26</em>:</p>
			<div>
				<div id="_idContainer085" class="IMG---Figure">
					<img src="image/B17338_03_26.jpg" alt="List of objects created by Helm"/>
				</div>
			</div>
			<p class="figure">Figure 3.26: List of objects created by Helm</p>
			<p>If you don't have an external IP yet, wait for a couple of minutes and retry the command.</p>
			<p>You can then go ahead and connect to your external IP and access your WordPress site. <em class="italics">Figure 3.27</em> is the resulting output:</p>
			<div>
				<div id="_idContainer086" class="IMG---Figure">
					<img src="image/B17338_03_27.jpg" alt="Connecting to the WordPress site using the external IP"/>
				</div>
			</div>
			<p class="figure">Figure 3.27: WordPress site being displayed on connection with the external IP</p>
			<p>To make sure you don't run into issues in the following chapters, let's delete the WordPress site. This can be done in the following way:</p>
			<p class="snippet">helm delete handsonakswp</p>
			<p>By design, the PVCs won't be deleted. This ensures persistent data is kept. As you don't have any persistent data, you can safely delete the PVCs as well:</p>
			<p class="snippet">kubectl delete pvc --all</p>
			<h4>Note</h4>
			<p class="callout">Be very careful when executing <strong class="inline">kubectl delete &lt;object&gt; --all</strong> as it will delete all the objects in a namespace. This is not recommended on a production cluster.</p>
			<p>In this section, you have deployed a full WordPress site using Helm. You also learned how Kubernetes handles persistent storage using PVCs.</p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor052"/>Summary</h2>
			<p>In this chapter, you deployed two applications. You started the chapter by deploying the guestbook application. During that deployment, the details of pods, ReplicaSets, and deployments were explored. You also used dynamic configuration using ConfigMaps. Finally, you looked into how services are used to route traffic to the deployed applications.</p>
			<p>The second application you deployed was a WordPress application. You deployed it via the Helm package manager. As part of this deployment, PVCs were used, and you explored how they were used in the system and how they were linked to disks on Azure.</p>
			<p>In <em class="italics">Chapter 4, Building scalable applications</em>, you will look into scaling applications and the cluster itself. You will first learn about the manual and automatic scaling of the application, and afterward, you'll learn about the manual and automatic scaling of the cluster itself. Finally, different ways in which applications can be updated on Kubernetes will be explained.</p>
		</div>
	</body></html>