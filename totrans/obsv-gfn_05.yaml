- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Monitoring with Metrics Using Grafana Mimir and Prometheus
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Grafana Mimir 和 Prometheus 进行指标监控
- en: This chapter will introduce the **Prometheus query language** (**PromQL**).
    Like LogQL, PromQL can be used to select and filter metrics streams and process
    numeric data with operators and functions, enabling you to build quick and efficient
    queries that will support establishing an observable system. We will also explore
    and compare the various protocols that can be used to output metrics from systems.
    Finally, we will explore the architecture of **Prometheus** and **Mimir** to understand
    how Mimir fills the need for a highly scalable system.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍 **Prometheus 查询语言**（**PromQL**）。与 LogQL 类似，PromQL 可以用来选择和筛选指标流，并使用运算符和函数处理数值数据，使您能够构建快速高效的查询，从而支持建立可观察系统。我们还将探索并比较用于输出系统指标的各种协议。最后，我们将探索
    **Prometheus** 和 **Mimir** 的架构，以了解 Mimir 如何满足高可扩展系统的需求。
- en: 'We will cover the following main topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将覆盖以下主要内容：
- en: Updating the OpenTelemetry collector for metrics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 更新 OpenTelemetry 采集器以收集指标
- en: Introducing PromQL
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 PromQL
- en: Exploring data collection and metric protocols
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索数据收集和指标协议
- en: Understanding data storage architectures
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解数据存储架构
- en: Using exemplars in Grafana
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Grafana 中使用示例数据
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, you will need the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，您将需要以下内容：
- en: The OpenTelemetry demo application set up in [*Chapter 3*](B18277_03.xhtml#_idTextAnchor063)
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 [*第 3 章*](B18277_03.xhtml#_idTextAnchor063) 中设置的 OpenTelemetry 演示应用程序
- en: The Grafana Cloud instance set up in [*Chapter 3*](B18277_03.xhtml#_idTextAnchor063)
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 [*第 3 章*](B18277_03.xhtml#_idTextAnchor063) 中设置的 Grafana Cloud 实例
- en: Docker and Kubernetes
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker 和 Kubernetes
- en: You'll find the code for this chapter in the GitHub repository at [https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter5](https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter5).
    You'll find the *Code in Action* videos for this chapter at [https://packt.link/A2g91](https://packt.link/A2g91).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 GitHub 仓库中的 [https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter5](https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter5)
    找到本章的代码。您可以在 [https://packt.link/A2g91](https://packt.link/A2g91) 找到本章的 *Code
    in Action* 视频。
- en: Updating the OpenTelemetry demo application
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新 OpenTelemetry 演示应用程序
- en: 'For this chapter, we have prepared an updated version of `OTEL-Collector.yaml`,
    which will add additional labels to metrics for you to explore. Full details on
    this process are available from the Git repository in the `README.md` file. This
    process will apply the new version of the collector configuration to your demo
    application:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 对于本章，我们已经准备了更新版本的 `OTEL-Collector.yaml` 文件，该文件将为您添加更多的标签，以便您进一步探索。有关此过程的详细信息，请参阅
    Git 仓库中的 `README.md` 文件。此过程将把新的采集器配置应用于您的演示应用程序：
- en: 'Using Helm, we will apply the updated configuration file to our Kubernetes
    cluster:'
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Helm，我们将更新的配置文件应用于我们的 Kubernetes 集群：
- en: '[PRE0]'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Validate upgrade was successful:'
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证升级是否成功：
- en: '[PRE1]'
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This new configuration adds the collection of metrics from the Kubernetes cluster
    and the OpenTelemetry collector. The configuration also does some necessary relabeling.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这个新配置增加了从 Kubernetes 集群和 OpenTelemetry 采集器收集指标的功能。该配置还做了一些必要的重新标记。
- en: Now that we are collecting more data from our local demo application, let’s
    introduce the language used to query that data.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们从本地演示应用程序收集更多的数据，让我们介绍用于查询这些数据的语言。
- en: Introducing PromQL
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 PromQL
- en: '**Prometheus** was initially developed by SoundCloud in 2012; the project was
    accepted by the *Cloud Native Computing Foundation* in 2016 as the second incubated
    project (after Kubernetes), and version 1.0 was released shortly after. PromQL
    is an integral part of Prometheus, which is used to query stored data and produce
    dashboards and alerts.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '**Prometheus** 最初由 SoundCloud 于 2012 年开发；该项目于 2016 年被 *Cloud Native Computing
    Foundation* 接受成为第二个孵化项目（继 Kubernetes 之后），并且很快发布了 1.0 版本。PromQL 是 Prometheus 的一个重要组成部分，用于查询存储的数据并生成仪表盘和警报。'
- en: 'Before we delve into the details of the language, let’s briefly look at the
    following ways in which Prometheus-compatible systems interact with metrics data:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨语言的细节之前，让我们简要地看一下 Prometheus 兼容系统与指标数据交互的几种方式：
- en: '**Ingesting metrics**: Prometheus-compatible systems accept a timestamp, key-value
    labels, and a sample value. As the details of the **Prometheus Time Series Database**
    (**TSDB**) are quite complicated, the following diagram shows a simplified example
    of how an individual sample for a metric is stored once it has been ingested:'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 5.1 – A simplified view of metric data stored in the TSDB](img/B18277_05_1.jpg)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – A simplified view of metric data stored in the TSDB
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: '`__name__` value creates a `app_frontend_requests`.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each unique set of labels creates a **time series**. In the preceding figure,
    the set of all labels is the time series.
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A time series will contain multiple **samples**, each with a unique timestamp.
    The preceding figure shows a single sample, but over time, multiple samples will
    be collected for each time series.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The number of unique values for a metric label is referred to as the **cardinality**
    of the label. Highly cardinal labels should be avoided, as they significantly
    increase the storage costs of the metric.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following diagram shows a single metric containing two time series and
    five samples:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – An example of samples from multiple time series](img/B18277_05_2.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – An example of samples from multiple time series
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: 'In Grafana, we can see a representation of the time series and samples from
    a metric. To do this, follow these steps:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: In your Grafana instance, select **Explore** in the menu.
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Choose your Prometheus data source, which will be labeled as `grafanacloud-<team>-prom
    (default)`.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'In the **Metric** dropdown, choose **app_frontend_requests_total**, and under
    **Options**, set **Format** to **Table**, and then click on **Run query**. This
    will show you all the samples and time series in the metric over the selected
    time range. You should see data like this:'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Visualizing the samples and time series that make up a metric](img/B18277_05_3.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – Visualizing the samples and time series that make up a metric
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand the data structure, let’s explore PromQL.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: An overview of PromQL features
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will take you through the features that PromQL has. We will
    start with an explanation of the data types, and then we will look at how to select
    data, how to work on multiple datasets, and how to use functions. As PromQL is
    a query language, it’s important to know how to manipulate data to produce alerts
    and dashboards.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: Data types
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'PromQL offers three data types, which are important, as the functions and operators
    in PromQL will work differently depending on the data types presented:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: '**Instant vectors** are a data type that stores a set of time series containing
    a single sample, all sharing the same timestamp – that is, it presents values
    at a specific instant in time:'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 5.4 – An instant vector](img/B18277_05_4.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – An instant vector
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '**Range vectors** store a set of time series, each containing a range of samples
    with different timestamps:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Range vectors](img/B18277_05_5.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – Range vectors
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '**Scalars** are simple numeric values, with no labels or timestamps involved.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting data
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'PromQL offers several tools for you to select data to show in a dashboard or
    alert, or just to understand a system’s state. Some of these are described in
    the following table:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Syntax** | **Operators** | **Scope** |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
- en: '| Metric selector | `metric_name` |  | Selects a metric |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
- en: '| Range selector | `[``5m]` | `ms`, `s`, `m`, `h`, `d`, `w`, and `y` | Selects
    samples |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
- en: '| Label selector | `{``label="value", foo!="bar"}` | `=`, `!=`, `=~`, and `!~`
    | Selects and filters time series using labels |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: '| Offset modifier | `offset 5m` | `ms`, `s`, `m`, `h`, `d`, `w`, and `y` |
    Offsets the evaluation time from the current point in time by the specified amount
    |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
- en: '| `@` modifier | `@` `1686561123` | `@` | Sets the evaluation time to a specific
    time for instant or range vectors. This modifier uses epoch timestamps |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
- en: Table 5.1 – The selection operators available in PromQL
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: In addition to the operators that allow us to select data, PromQL offers a selection
    of operators to compare multiple sets of data.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: Operators between two datasets
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some data is easily provided by a single metric, while other useful information
    needs to be created from multiple metrics. The following operators allow you to
    combine datasets.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '| **Name** | **Syntax** | **Operators** | **Scope** |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
- en: '| Arithmetic operators | `a + b` | `+`, `-`, `*`, `/`, `%`, and `^` | Arithmetic
    operations on instant vectors and scalars; scope depends on the data type of `a`
    and `b`. It’s important to note that vectors are matched on *all* labels. |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
- en: '| Comparison operators | `a == b` | `==`, `!=`, `>`, `<`, `>=`, and `<=` |
    Filters instant vectors and scalars based on the comparison; scope depends on
    the data type of `a` and `b`. |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
- en: '| Aggregation operators | `sum by (``label) (a)` | `sum()`, `min()`, `max()`,
    `avg()`, `group()`, `stddev()`, `stdvar()`, `count()`, `count_values()`, `bottomk()`,
    `topk()`, and `quantile()` | Aggregation operations on a single instant vector.These
    operators offer the `without` and `by` clauses to modify how results are grouped
    by label. |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
- en: '| One-to-one vector matching | `a +` `on b` | `on()` and `ignoring()` | Modifies
    vector matching to specific labels (`on`) or ignoring a label (ignoring) |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
- en: '| One-to-many/many-to-one vector matching using group modifiers | `a +` `group_left
    b` | `group_left()` and `group_right()` | Modifies the vector matching in cases
    of many-to-one or one-to-many matching.Grouping can use a label list to include
    a label in the results. |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
- en: '| Many-to-many vector matching using logical operators | `a` `and b` | `and`,
    `or`, and `unless` | Modifies vector matching in cases of many-to-many matching,
    based on logical operations between labels and the values of `a` and `b` |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
- en: Table 5.2 – The comparison operators available in PromQL
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: Vector matching is an initially confusing topic; to clarify it, let’s consider
    examples for the three cases of vector matching – *one-to-one*, *one-to-many*/*many-to-one*,
    and *many-to-many*.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, when combining vectors, all label names and values are matched.
    This means that for each element of the vector, the operator will try to find
    a single matching element from the second vector. Let’s consider a simple example:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '`10{color=blue,smell=ocean}`'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`31{color=red,smell=cinnamon}`'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`27{color=green,smell=grass}`'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`19{color=blue,smell=ocean}`*   `8{color=red,smell=cinnamon}`*   `14{color=green,smell=jungle}`*   `29{color=blue,smell=ocean}`*   `39
    {color=red,smell=cinnamon}`*   `29{color=blue}`*   `39{color=red}`*   `41{color=green}`'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When `color=blue` and `smell=ocean`, `A{} + B{}` gives `10 + 19 = 29`, and when
    `color=red` and `smell=cinnamon`, `A{} + B{}` gives `31 + 8 = 29`. The other elements
    do not match the two vectors so are ignored.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: When we sum the vectors using `on (color)`, we will only match on the `color`
    label; so now, the two green elements match and are summed.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: 'This example works when there is a *one-to-one* relationship of labels between
    vector **A** and vector **B**. However, sometimes there may be a *many-to-one*
    or *one-to-many* relationship – that is, vector A or vector B may have more than
    one element that matches the other vector. In these cases, Prometheus will give
    an error, and grouping syntax must be used. Let’s look at another example to illustrate
    this:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: '`7{color=blue,smell=ocean}`'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`5{color=red,smell=cinamon}`'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`2{color=blue,smell=powder}`'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`20{color=blue,smell=ocean}`*   `8{color=red,smell=cinamon}`*   `14{color=green,smell=jungle}`*   `27{color=blue,smell=ocean}`*   `13{color=red,smell=cinamon}`*   `22{color=blue,smell=powder}`'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, we have two different elements in vector `color=blue`. The `group_left`
    command will use the labels from vector `22`, when the item matching in vector
    `group_right` operator will behave in the opposite direction.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: 'The final option is a *many-to-many* vector match. These matches use the logical
    operators `and`, `unless`, and `or` to combine parts of vectors **A** and **B**.
    Let’s see some examples:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '`10{color=blue,smell=ocean}`'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`31{color=red,smell=cinamon}`'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`27{color=green,smell=grass}`'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`19{color=blue,smell=ocean}`*   `8{color=red,smell=cinamon}`*   `14{color=green,smell=jungle}`*   `10{color=blue,smell=ocean}`*   `31{color=red,smell=cinamon}`*   `27{color=green,smell=grass}`*   `10{color=blue,smell=ocean}`*   `31{color=red,smell=cinamon}`*   `27{color=green,smell=grass}`*   `14{color=green,smell=jungle}`'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unlike the previous examples, mathematical operators are not being used here,
    so the values of the elements are the values from vector **A**, but only the elements
    of **A** that match the logical condition in **B** are returned.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand the operators, let’s quickly introduce PromQL functions
    before we look at a practical example of writing PromQL. We will explore a practical
    example of their use in the *Writing* *PromQL* section.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: Functions
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'PromQL offers about 60 different functions. The full list of functions can
    be found on the Prometheus w[ebsite: https://prometheus.io/docs/prometheus/latest/querying/f](https://prometheus.io/docs/prometheus/latest/querying/functions)unctions.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve looked at the functions available in PromQL, let’s explore writing
    a PromQL query.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Writing PromQL
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: While technical descriptions of a language are useful for reference, this section
    will follow the process of building a query so that the language can be seen in
    context. Having your Grafana instance open in **Explorer** will help you follow
    along. In the following sections, we’ll write practical examples using the selectors,
    operators, and modifiers we introduced in the previous section.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: Metric selection
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When we looked at metric labels, we saw how you can select metrics in PromQL
    with the `metric_name{}` syntax. This can be typed directly into a query using
    the `app_frontend_requests_total`. If it does not, use the **Metric** dropdown
    to select this metric. You should see results like in *Figure 5**.3*. This method
    of selection returns an instant vector, as described in *Figure 5**.4*.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: 'The syntax is similar for returning a range vector, as described in *Figure
    5**.5*. We just need to add the range we are interested in – `metric_name[range]`.
    The range must include the time units, which can range from milliseconds (ms)
    to years (y). It’s important to note that queries using range vectors need to
    be run with a query type of **Instant**. If a query type of **Range** or **Both**
    (the default) is selected, then you will receive an error. Here is an example
    of the error you will see:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – An error when using a range vector in a range query](img/B18277_05_6.jpg)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – An error when using a range vector in a range query
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: Time series selection and operators
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As time series are made up of a unique set of labels, we can expand our query
    to only look at specific data – for example, only requests that target the cart
    API of the OpenTelemetry demo application. The following steps will filter our
    query to show only the requests that target the `/``api/cart` endpoint:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: 'Switch to the **Table** view at the top right of the **Results** panel:'
  id: totrans-107
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Using the Table view in the PromQL results](img/B18277_05_7.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: Figure 5.7 – Using the Table view in the PromQL results
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'Hover your mouse over a value for the target; you should see this icon:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.8 – Filter for value](img/B18277_05_8.jpg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – Filter for value
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on the plus icon, and you will see that we have a new label filter and
    our PromQL now says the following: `app_frontend_requests_total{target="/api/cart"}`.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Let’s only show the `GET` method requests as well; you can do this by using
    the `=`: Checks for an exact match of a string. For example, `target="/api/cart"`
    will match only when the `target` label is `/api/cart/`.'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`!=`: Checks for anything other than an exact match. `target!="/api/cart"`
    will match everything except when the `target` label is `/api/cart/`.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`=~`: Checks for a regex match. For example, `target=~"/api/.*"` will match
    when the `target` label starts with `/api/`. This includes `/api/cart/`, `/api/horse/`,
    and `/api/cart/foo/bar/`.'
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`!~`: Checks for anything other than a regex match. `target!~"/api/.+"` will
    match when the `target` label is `/api/` or `/checkout/` but will not match `/api/cart/`,
    `/api/horse/`, and `/api/cart/foo/bar/`.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While we’re looking at the table, you should also see a column titled `metric_name{}`
    is equivalent to `{__name__="metric_name"}`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now selected data and filtered it to the endpoint we’re interested in,
    but a raw count of the requests that were made is difficult to interpret. Let’s
    look at how to transform this count into something more useful, using a function.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Functions, aggregation, and operators
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'PromQL is a nested language, so to apply a function to a selected set of data,
    you simply enclose the data selection with the function. Our query so far looks
    like this:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This query returns the count of requests at each sample point. For most purposes,
    we are more interested in the rate of requests that hit that endpoint. This will
    allow us to answer questions such as what the peak rate is, or whether the rate
    is higher now or lower than at another point in time. The function to get this
    information is the `rate()` function. We can plug our current query into the function
    like this:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The rate function takes an input of a range vector, so we have added the special
    `[$__rate_interval]` time variable. This is a Grafana feature that instructs Grafana
    to pick an appropriate interval, based on the scrape interval of the data source
    we have selected. This feature simplifies the technicalities of selecting the
    correct rate interval. A similar process is used for aggregation and other operators.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know how to get the rate of requests to the `/api/cart` endpoint,
    let’s have a look at another example query.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: HTTP success rate
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A common **Service Level Indicator** (**SLI**) for a web application is the
    **success rate** of HTTP requests. In plain language, this is the number of successful
    HTTP requests/total HTTP requests. We will discuss the process of choosing good
    SLIs in [*Chapter 9*](B18277_09.xhtml#_idTextAnchor183).
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 'A PromQL query like the following will produce the success rate SLI for the
    `app_frontend_requests_total` metric:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can break this code down as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Using `app_frontend_requests_total{status=~"2[0-9]{2}"}[5m]`, we select samples
    of the `app_frontend_requests` metric that have the `status` label, with a value
    between `200` and `299`. This uses regex to select the label range, and it is
    a range vector over a five-minute range. For those of you familiar with regex,
    Grafana requires the escaping of backslashes.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `rate()` function calculates the per-second average rate of successful requests.
    This function returns an instant vector.
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The previous functions have left all data grouped into the initial time series
    from it. However, for this query, we are not interested in the method, target,
    or any other labels. Instead, we are interested in knowing whether a particular
    instance of the application is failing, as a failing instance could be masked
    by many good instances. To achieve this, we use the `sum by (instance) ()` aggregation.
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The last line of the query mirrors the first line but removes the label selector,
    so we get the *total* requests.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use the arithmetic operator (`/`) to divide the successful requests
    by the total requests. The output of this query gives us a number that will be
    close to 1 when most requests are successful; as we see failures, this will trend
    downward to 0 when every request fails.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Another common item to measure is the **duration** of requests made to the
    service. Durations are frequently represented as histogram data, and PromQL offers
    us many statistical tools we can use to understand our user’s experience. Let’s
    look at the following query:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-138
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The `http_server_duration_milliseconds_bucket` metric is a histogram, which
    is indicated by the naming convention of `_bucket`. The `histogram_quantile()`
    function takes this histogram data and gives us the 95th percentile duration.
    This is calculated using the `le` (less than or equal to) label in the histogram
    data. While it might be tempting to use averages for this kind of calculation,
    percentiles offer us a more nuanced understanding of the data. The 95th percentile
    means that 95% of samples have a duration less than or equal to the value returned.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'Grafana offers several helpful functions to understand a query:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Above the query component is a slider titled **Explain**. Toggling this on will
    present a step-by-step breakdown of what a query is doing.
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, above the query component is a button titled **Kick start your query**.
    Clicking this will give a number of starter queries.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Below the **Options** section is the query **Inspector**. This will give detailed
    information about the query, such as its total request time and the data returned.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here is a screenshot showing the location of these options:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9 – Helpful functions for queries](img/B18277_05_9.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – Helpful functions for queries
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Hopefully, you have a good grasp of the fundamentals of PromQL now and know
    what resources you have available to learn more. Whilst querying data is a major
    part of the day-to-day work in Grafana, it is good to have an understanding of
    how metrics data is collected.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: The OpenTelemetry demo that has been set up also produces metrics from the single-node
    Kubernetes cluster, the kubelet instance on the node, and the underlying host.
    We encourage you to explore these metrics and see what you can find.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: We’ve seen how to query the data stored in Prometheus-compatible systems. Now,
    let’s see how to collect data from your services.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: Exploring data collection and metric protocols
  id: totrans-150
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 2*](B18277_02.xhtml#_idTextAnchor043), we introduced four common
    protocols in use to collect data from today’s software – **StatsD** and **DogStatsD**,
    **OpenTelemetry Protocol** (**OTLP**), and **Prometheus**. We also introduced
    **Simple Network Management Protocol** (**SNMP**), which is used in the networking
    and compute spaces. In this section, we’ll explore some of the features of these
    protocols.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: There are two methods that metrics can be collected, push and pull. In a **push
    protocol**, the application or infrastructure must be configured with a destination
    to send metrics. In a **pull protocol**, the application or infrastructure is
    configured to expose metrics for another service to request. Both methods have
    advantages and disadvantages, it is also important to be aware of the potential
    security implications. In the following subsections, let’s delve into each protocol.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: StatsD and DogStatsD
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have grouped StatsD and DogStatsD together, as they are identical for the
    purposes of what we are discussing in this chapter.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '`8125` in its default settings. These are things to consider when using StatsD:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: StatsD uses UDP for transmission. This favors the speed of transmission over
    the guarantee of delivery.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The protocol offers no support for authentication between the application and
    the receiving service. Depending on the environment, this could be a security
    concern.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s worth noting that common practice, especially in Kubernetes, is to expose
    the StatsD receiver on `localhost:8125`, thus limiting exposure and offering a
    standard for applications to use.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: StatsD has quite wide support in data collection agents, usually via contributed
    receivers. The OpenTelemetry collector, FluentBit, Vector, Beats, Telegraf, and
    the StatsD daemon all support the protocol. Prometheus offers an exporter that
    takes StatsD format metrics and exposes them as a Prometheus scrape endpoint;
    this is recommended as an intermediate step to a full Prometheus migration.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: '**DogStatsD** is less well supported than the StatsD format it is derived from;
    it provides an expanded set of metrics to StatsD. The data collection agents that
    natively support DogStatsD are **Vector** and Datadog’s own agent. The OpenTelemetry
    collector currently has no support, but there are discussions in progress on adding
    this, and Datadog is an active participant in the OpenTelemetry project, so this
    is likely to change.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: OTLP
  id: totrans-161
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: OTLP is also a *push protocol*, so destination knowledge is necessary. Like
    StatsD, OTLP is often implemented using the standard receiving endpoint of `localhost:4317`
    (`localhost:4318` (HTTP). OTLP supports both gRPC and HTTP and offers support
    for the authentication and acknowledgment between the client and server. OTLP
    also offers several quality-of-life items, such as **server-controlled throttling**
    and **GZIP compression**.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: OpenTelemetry is in very active development, so this information is liable to
    change. As the project is a collaboration between several major vendors, agents
    from those vendors are increasingly supporting OTLP metrics. While other collection
    tools do not support OTLP input, the OpenTelemetry collector supports input from
    many sources. This means the OTEL collector is ideal for supporting a mixed estate.
    The vector collection agent also offers this versatility, and most things said
    about the OTEL collector can be applied to it as well.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Unlike StatsD and OTLP, Prometheus is a *pull protocol*. A client application
    needs to be configured to serve metrics on an endpoint, and then a Prometheus-compatible
    scraper is configured to collect those metrics at specific intervals. These metrics
    are commonly exposed on the `/metrics` endpoint, although some frameworks implement
    this differently (e.g., `/actuator/Prometheus` for Spring Boot).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: It may seem that using a pull configuration increases the configuration steps
    required. However, using a pull method does reduce the information needed by the
    application of its running environment. For example, the application configuration
    would remain the same if 0 or 10 clients read its metrics. This pull pattern also
    matches very closely with the pattern of liveness and readiness endpoints for
    applications in Kubernetes.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: To assist in the server configuration, Prometheus offers a wide range of service
    discovery options, across many different platforms, including Kubernetes, DNS,
    and Consul. These discovery options include matching a specific name and collecting
    data if a label is present, and this range of options allows for quite complex
    architectures where needed.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: The Prometheus format has good collector support; Prometheus, the OTEL Collector,
    Grafana Agent, Vector, Beats, and Telegraf all support the collection of these
    metrics.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: SNMP
  id: totrans-169
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SNMP is more complex than the other protocols discussed here, as it includes
    a lot of functionality for the management and monitoring of network-connected
    devices, such as switches and physical servers. The *monitoring* aspect of SNMP
    is a *pull protocol*, where a manager instance connects to agent software on devices
    and pulls data. There is additional functionality in **SNMP traps**, which allow
    a device to inform the manager about items as a data push. These traps are often
    of interest to track metrics from. It is worth noting that security can be a concern
    using SNMP, depending on how it is configured. SNMP offers a significant attack
    surface if configured incorrectly.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: SNMP is very well supported, as the protocol has been active since 1988 and
    has good support from hardware vendors.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: We’ve now covered querying data using PromQL, and how data is produced and collected,
    so let’s now explore how Grafana stores metric data.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Understanding data storage architectures
  id: totrans-173
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Time Series Databases** (**TSDBs**) are ideally suited to handle metric data,
    as metrics need to record data at specific points in time, and TSDBs are structured
    to make this data easy to record and query. There are several TSDBs available,
    but as this book is focused on Grafana, we will only discuss **Graphite**, **Prometheus**,
    and **Mimir** in this section. This is aimed at giving you an understanding of
    the structure of data as it is stored, as well as an overview of how Mimir allows
    organizations to scale their data beyond the capabilities of Graphite and Prometheus.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Graphite architecture
  id: totrans-175
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Graphite has several components; we will discuss the storage component **Whisper**
    here. The Whisper TSDB uses a flat file structure, where each unique time series
    is a fixed-size file. This size is determined by the configuration of resolution
    and retention configured in Whisper. Gathering this data for a search requires
    each of these files to be read, which quickly becomes expensive in disk I/O. As
    there are no inbuilt items that manage data redundancy, Graphite is also unable
    to guarantee that data written to it will be protected from loss or corruption.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: However, the protocols introduced by Graphite to write data are still relevant
    although aging, so Grafana Cloud offers a Graphite ingest endpoint and query endpoint
    for teams that are already using this technology.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Graphite was an early example of metrics, introduced in 2008; the limitations
    of query speed and data integrity outlined previously led to the creation of Prometheus,
    which we will discuss next.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: Prometheus architecture
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Prometheus stores data in an immutable `block`, which covers a fixed time range
    (by default, two hours). Inside a block are several `chunks`, which are capped
    at 512 MB; these files contain the sampled value. Alongside these `chunks` are
    metadata files – `index` and `meta.json`. The `index` file contains a table that
    records the labels contained in the block and a reference to the position of all
    samples, with these labels in the associated chunks. Highly cardinal metric labels
    cause a huge increase in the size of the `index` file and degrade read performance.
    The `meta.json` file contains metadata such as the min and max timestamp contained
    in the `block` and stats on the samples, series, and chunks contained and the
    version used.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: To process data as it’s received, Prometheus also uses a `head block`, which
    is similar to the `block` used for storage, but it allows writes. This allows
    for the collection of a full two-hour block of data, ready for the index and metadata
    to be created when the block is finished. This process includes functionality
    to persist data on disk to prevent data loss. The `head block` consists of a `meta.json`
    file that records what has been received. When the end of the two-hour time block
    is reached, a new `head block` is created, and the old `head block` is transformed
    into a standard `block`, with the creation of an `index` and `chunks`.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure shows the structure of a fictional Prometheus TSDB, with
    the `blocks`, `chunks`, `index`, and metadata files and the WAL highlighted:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.10 – The Prometheus TSDB](img/B18277_05_10.jpg)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – The Prometheus TSDB
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: The implementation of the Prometheus TSDB in Prometheus itself is limited, as
    it uses local storage, which is not clustered or replicated natively. While it
    is possible to improve the aspects of this, there is a fundamental limitation
    of only a single node carrying out reads and writes. These limitations are perfectly
    acceptable in the correct circumstances. However, when scaling the TSDB to accept
    many active time series, changes are needed. Handling these situations is what
    Mimir was designed to do.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: Mimir architecture
  id: totrans-186
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Mimir uses the same fundamental TSDB storage structures. However, unlike Prometheus,
    Mimir natively supports object stores for block files. The supported stores include
    Amazon S3, Google Cloud Storage, Microsoft Azure Storage, and OpenStack Swift.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: By leveraging **object storage**, which is massively scalable, Mimir can handle
    the scaling problem experienced with Prometheus by adding new instances of the
    data-ingesting service. Mimir separates the incoming streams of data to a specific
    per-tenant TSDB, and each of these is assigned to an instance of the ingesting
    service. Like Prometheus, data is written to memory and the WAL by the ingester,
    and when the block is complete, it is written to object storage. To provide resilience
    Mimir will write each of these streams to multiple ingesters, and a compactor
    service will handle the process of merging the redundant blocks in object storage
    and removing duplicate samples.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Like the horizontal scalability of the write pathway, Mimir also scales the
    read pathway. It does this by splitting an incoming query into shorter time ranges.
    Then, it distributes these smaller units of the query to multiple querier instances.
    By doing this, Mimir again leverages the benefits of the underlying object storage
    for a quick return of data.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows the read and write pathways for Mimir:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.11 – Mimir architecture](img/B18277_05_11.jpg)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – Mimir architecture
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Metrics show us aggregated data, such as the total count of requests. It is
    helpful when exploring an *odd* metric value to be able to look at an example.
    In applications that are instrumented with traces and metrics, exemplars allow
    us to record a sample trace in our metric data. Let’s see this capability in action.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Using exemplars in Grafana
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Exemplars** are functions in Grafana that allow us to pivot from an aggregated
    view of the system, given by metrics, to a detailed view of a single request,
    given by traces. Exemplars need to be configured at the *collection layer* and
    then sent to the *storage layer*.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'When they are available, you can view exemplars by doing the following:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: 'Open **Options** under the query, and toggle the **Exemplars** slider:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.12 – The Exemplars toggle](img/B18277_05_12.jpg)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – The Exemplars toggle
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: 'Exemplars will appear as stars on the metrics chart:'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.13 – An exemplar in metrics](img/B18277_05_13.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 – An exemplar in metrics
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'Hovering over an individual exemplar will expand on the metrics data by showing
    information from the exemplar trace in the metrics view. We will explain these
    fields in more detail in [*Chapter 6*](B18277_06.xhtml#_idTextAnchor134), but
    some notable fields are the name and version of the process runtime and `span_id`,
    which would not usually be available in a purely metric view:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.14 – Exemplar information](img/B18277_05_14.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
- en: Figure 5.14 – Exemplar information
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: 'From an exemplar, you can also pivot from viewing metric data to looking at
    the trace in question by clicking on the **Query with Tempo (****Tempo)** button:'
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 5.15 – Opening an exemplar in Tempo](img/B18277_05_15.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
- en: Figure 5.15 – Opening an exemplar in Tempo
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: We’ll discuss the details of tracing in more detail in [*Chapter 6*](B18277_06.xhtml#_idTextAnchor134),
    but this should give you a good introduction to using this kind of data in your
    metrics.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-210
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we explored metrics in detail. We saw all the operators available
    in PromQL and wrote two queries using the language. With that foundation of querying
    knowledge, we looked at the tools available to collect data and the various protocols
    with which applications can share data. We then looked at the architecture for
    Prometheu, and saw how Mimir takes the concepts of Prometheus and turns them into
    a highly scalable data processing tool, able to meet the needs of organizations
    of any size. Our final exploration was of Exemplars, giving us a concrete data
    example to add context to the aggregated data seen in metrics.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will explore how traces work in Grafana Tempo, which will show
    you how powerful the use of exemplars and logging trace and span information can
    be to create a truly observable system for your organization’s customers.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
