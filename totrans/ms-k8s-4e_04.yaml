- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Securing Kubernetes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保护Kubernetes
- en: In *Chapter 3*, *High Availability and Reliability*, we looked at reliable and
    highly available Kubernetes clusters, the basic concepts, the best practices,
    and the many design trade-offs regarding scalability, performance, and cost.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第3章*，*高可用性与可靠性*中，我们探讨了可靠且高可用的Kubernetes集群、基本概念、最佳实践，以及与可扩展性、性能和成本相关的许多设计权衡。
- en: In this chapter, we will explore the important topic of security. Kubernetes
    clusters are complicated systems composed of multiple layers of interacting components.
    The isolation and compartmentalization of different layers is very important when
    running critical applications. To secure a system and ensure proper access to
    resources, capabilities, and data, we must first understand the unique challenges
    facing Kubernetes as a general-purpose orchestration platform that runs unknown
    workloads. Then we can take advantage of various securities, isolation, and access
    control mechanisms to make sure the cluster, the applications running on it, and
    the data are all safe. We will discuss various best practices and when it is appropriate
    to use each mechanism.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨安全这个重要话题。Kubernetes集群是由多个交互组件组成的复杂系统。不同层次的隔离和分区在运行关键应用程序时非常重要。为了确保系统的安全并确保对资源、功能和数据的适当访问，我们必须首先了解Kubernetes作为一个通用编排平台，面临的独特挑战，它运行的是未知的工作负载。然后，我们可以利用各种安全性、隔离和访问控制机制，确保集群、运行其上的应用程序以及数据的安全。我们将讨论各种最佳实践，并在适当的时候使用每种机制。
- en: 'This chapter will explore the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨以下主要主题：
- en: Understanding Kubernetes security challenges
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解Kubernetes的安全挑战
- en: Hardening Kubernetes
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加固Kubernetes
- en: Running multi-tenant clusters
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行多租户集群
- en: By the end of this chapter, you will have a good understanding of Kubernetes
    security challenges. You will gain practical knowledge of how to harden Kubernetes
    against various potential attacks, establishing defense in depth, and will even
    be able to safely run a multi-tenant cluster while providing different users full
    isolation as well as full control over their part of the cluster.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将对Kubernetes的安全挑战有一个良好的理解。你将获得如何加固Kubernetes以防范各种潜在攻击的实用知识，建立纵深防御，并能够安全地运行一个多租户集群，同时为不同用户提供完全的隔离和对其集群部分的完全控制。
- en: Understanding Kubernetes security challenges
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解Kubernetes的安全挑战
- en: Kubernetes is a very flexible system that manages very low-level resources in
    a generic way. Kubernetes itself can be deployed on many operating systems and
    hardware or virtual machine solutions, on-premises, or in the cloud. Kubernetes
    runs workloads implemented by runtimes it interacts with through a well-defined
    runtime interface, but without understanding how they are implemented. Kubernetes
    manipulates critical resources such as networking, DNS, and resource allocation
    on behalf of or in service of applications it knows nothing about.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes是一个非常灵活的系统，以通用方式管理非常底层的资源。Kubernetes本身可以部署在多种操作系统、硬件或虚拟机解决方案上，无论是本地部署还是云环境。Kubernetes通过与运行时交互的明确定义的运行时接口运行工作负载，但无需理解它们是如何实现的。Kubernetes代表或服务于其不了解的应用程序，操作着关键资源，如网络、DNS和资源分配。
- en: This means that Kubernetes is faced with the difficult task of providing good
    security mechanisms and capabilities in a way that application developers and
    cluster administrators can utilize, while protecting itself, the developers, and
    the administrators from common mistakes.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着Kubernetes面临着一个艰巨的任务：在提供良好的安全机制和能力的同时，确保应用程序开发人员和集群管理员可以使用这些机制，同时保护自己、开发人员和管理员免受常见错误的影响。
- en: 'In this section, we will discuss security challenges in several layers or components
    of a Kubernetes cluster: nodes, network, images, pods, and containers. Defense
    in depth is an important security concept that requires systems to protect themselves
    at each level, both to mitigate attacks that penetrate other layers and to limit
    the scope and damage of a breach. Recognizing the challenges in each layer is
    the first step toward defense in depth.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论Kubernetes集群中几个层次或组件的安全挑战：节点、网络、镜像、Pods和容器。纵深防御是一个重要的安全概念，要求系统在每个层级都能够自我保护，既能缓解渗透其他层的攻击，又能限制破坏的范围和程度。认识到每个层次的挑战是实现纵深防御的第一步。
- en: 'This is often described as the 4 Cs of cloud-native security:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这通常被描述为云原生安全的4个C：
- en: '![Table  Description automatically generated with medium confidence](img/B18998_04_01.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
  zh: '![中等置信度自动生成的表说明](img/B18998_04_01.png)'
- en: 'Figure 4.1: The 4 Cs of cloud-native security'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.1：云原生安全的四个关键C
- en: 'However, the 4 Cs model is a coarse-grained approach for security. Another
    approach is building a threat model based on the security challenges across different
    dimensions, such as:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，四个C模型是安全性的一种粗粒度方法。另一种方法是基于不同维度的安全挑战建立威胁模型，例如：
- en: Node challenges
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点挑战
- en: Network challenges
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络挑战
- en: Image challenges
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像挑战
- en: Deployment and configuration challenges
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署和配置挑战
- en: Pod and container challenges
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod 和容器的挑战
- en: Organizational, cultural, and process challenges
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织、文化和流程挑战
- en: Let’s examine these challenges.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查这些挑战。
- en: Node challenges
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 节点挑战
- en: The nodes are the hosts of the runtime engines. If an attacker gets access to
    a node, this is a serious threat. They can control at least the host itself and
    all the workloads running on it. But it gets worse.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 节点是运行时引擎的主机。如果攻击者访问节点，这是一个严重威胁。他们至少可以控制主机本身和运行在其上的所有工作负载。但情况可能会更糟。
- en: The node has a kubelet running that talks to the API server. A sophisticated
    attacker can replace the kubelet with a modified version and effectively evade
    detection by communicating normally with the Kubernetes API server while running
    their own workloads instead of the scheduled workloads, collecting information
    about the overall cluster, and disrupting the API server and the rest of the cluster
    by sending malicious messages. The node will have access to shared resources and
    to secrets that may allow the attacker to infiltrate even deeper. A node breach
    is very serious, because of both the possible damage and the difficulty of detecting
    it after the fact.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 节点上运行一个与 API 服务器通信的 kubelet。一个高级的攻击者可以用修改过的 kubelet 替换它，并通过正常通信与 Kubernetes
    API 服务器通信，而运行他们自己的工作负载而不是计划的工作负载，收集关于整个集群的信息，并通过发送恶意消息干扰 API 服务器和集群的其余部分。攻击者将访问共享资源和可能允许其更深入渗透的秘密。节点入侵非常严重，因为可能造成的损害和事后检测的困难性。
- en: Nodes can be compromised at the physical level too. This is more relevant on
    bare-metal machines where you can tell which hardware is assigned to the Kubernetes
    cluster.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 节点也可以在物理级别上受到损害。这在裸机上更为相关，您可以查看哪些硬件分配给了 Kubernetes 集群。
- en: Another attack vector is resource drain. Imagine that your nodes become part
    of a bot network that, unrelated to your Kubernetes cluster, just runs its own
    workloads like cryptocurrency mining and drains CPU and memory. The danger here
    is that your cluster will choke and run out of resources to run your workloads
    or, alternatively, your infrastructure may scale automatically and allocate more
    resources.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个攻击向量是资源耗尽。想象一下，您的节点成为一个与您的 Kubernetes 集群无关的机器人网络的一部分，只运行自己的工作负载，如加密货币挖矿，耗尽
    CPU 和内存。这里的危险在于，您的集群将窒息并耗尽运行工作负载所需的资源，或者您的基础架构可能会自动扩展并分配更多资源。
- en: Another problem is the installation of debugging and troubleshooting tools or
    modifying the configuration outside of an automated deployment. Those are typically
    untested and, if left behind and active, can lead to at least degraded performance,
    but can also cause more sinister problems. At the least, it increases the attack
    surface.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是在自动化部署之外安装调试和故障排除工具或修改配置。这些通常是未经测试的，如果留下并保持活跃状态，至少会导致性能下降，但也可能导致更严重的问题。至少，它会增加攻击面。
- en: 'Where security is concerned, it’s a numbers game. You want to understand the
    attack surface of the system and where you’re vulnerable. Let’s list some possible
    node challenges:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在关注安全性时，这是一个数字游戏。您需要了解系统的攻击面和脆弱性所在。让我们列出一些可能的节点挑战：
- en: An attacker takes control of the host
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击者控制主机
- en: An attacker replaces the kubelet
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击者替换 kubelet
- en: An attacker takes control of a node that runs master components (such as the
    API server, scheduler, or controller manager)
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击者控制运行主控组件的节点（例如 API 服务器、调度器或控制器管理器）
- en: An attacker gets physical access to a node
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击者获得对节点的物理访问
- en: An attacker drains resources unrelated to the Kubernetes cluster
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 攻击者耗尽与 Kubernetes 集群无关的资源
- en: Self-inflicted damage occurs through the installation of debugging and troubleshooting
    tools or a configuration change
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装调试和故障排除工具或配置更改会造成自我损害
- en: Mitigating node challenges requires several layers of defense such as controlling
    physical access, preventing privilege escalation, and reducing the attack surface
    by controlling the OS and software installed on the node.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 缓解节点挑战需要多层防御，例如控制物理访问、阻止权限升级以及通过控制节点上安装的操作系统和软件来减少攻击面。
- en: Network challenges
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网络挑战
- en: Any non-trivial Kubernetes cluster spans at least one network. There are many
    challenges related to networking. You need to understand how your system components
    are connected at a very fine level. Which components are supposed to talk to each
    other? What network protocols do they use? What ports? What data do they exchange?
    How is your cluster connected to the outside world?
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 任何一个非简单的Kubernetes集群至少跨越一个网络。与网络相关的挑战很多。你需要非常细致地了解你的系统组件是如何连接的。哪些组件应该互相通信？它们使用哪些网络协议？使用哪些端口？它们交换哪些数据？你的集群如何与外界连接？
- en: 'There is a complex chain of exposing ports and capabilities or services:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 曝露端口和能力或服务的过程复杂：
- en: Container to host
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器到主机
- en: Host to host within the internal network
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内部网络中的主机对主机
- en: Host to the world
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 主机对世界
- en: Using overlay networks (which will be discussed more in *Chapter 10*, *Exploring
    Kubernetes Networking*) can help with defense in depth where, even if an attacker
    gains access to a container, they are sandboxed and can’t escape to the underlay
    network’s infrastructure.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 使用覆盖网络（将在*第10章*《探索Kubernetes网络》中详细讨论）有助于增强防御深度，即使攻击者获得了对容器的访问权限，他们也被沙箱隔离，无法逃逸到底层网络的基础设施。
- en: Discovering components is a big challenge too. There are several options here,
    such as DNS, dedicated discovery services, and load balancers. Each comes with
    a set of pros and cons that take careful planning and insight to get right for
    your situation. Making sure two containers can find each other and exchange information
    is not trivial.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 发现组件也是一个巨大的挑战。这里有几个选项，例如DNS、专用发现服务和负载均衡器。每个选项都有一组优缺点，需要仔细的规划和洞察才能根据你的情况正确配置。确保两个容器能够互相发现并交换信息并非易事。
- en: You need to decide which resources and endpoints should be publicly accessible.
    Then you need to come up with a proper way to authenticate users, services, and
    authorize them to operate on resources. Often you may want to control access between
    internal services too.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要决定哪些资源和端点应该对外部可访问。然后，你需要想出一种合适的方式来验证用户、服务身份，并授权它们操作资源。你可能还需要控制内部服务之间的访问。
- en: Sensitive data must be encrypted on the way into and out of the cluster and
    sometimes at rest, too. That means key management and safe key exchange, which
    is one of the most difficult problems to solve in security.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 敏感数据必须在进出集群的过程中进行加密，有时在静态存储时也需要加密。这意味着密钥管理和安全密钥交换，这是解决安全问题中最困难的问题之一。
- en: If your cluster shares networking infrastructure with other Kubernetes clusters
    or non-Kubernetes processes, then you have to be diligent about isolation and
    separation.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你的集群与其他Kubernetes集群或非Kubernetes进程共享网络基础设施，那么你必须小心隔离和分离。
- en: 'The ingredients are network policies, firewall rules, and **software-defined
    networking** (**SDN**). The recipe is often customized. This is especially challenging
    with on-premises and bare-metal clusters. Here are some of the network challenges
    you will face:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 解决方案包括网络策略、防火墙规则和**软件定义网络**（**SDN**）。这套方案通常需要定制化。对于本地部署和裸机集群来说，这尤其具有挑战性。以下是你将面临的一些网络挑战：
- en: Coming up with a connectivity plan
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 制定连接计划
- en: Choosing components, protocols, and ports
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择组件、协议和端口
- en: Figuring out dynamic discovery
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定动态发现
- en: Public versus private access
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 公共访问与私有访问
- en: Authentication and authorization (including between internal services)
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 身份验证和授权（包括内部服务之间）
- en: Designing firewall rules
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设计防火墙规则
- en: Deciding on a network policy
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 决定网络策略
- en: Key management and exchange
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 密钥管理和交换
- en: Encrypted communication
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 加密通信
- en: There is a constant tension between making it easy for containers, users, and
    services to find and talk to each other at the network level versus locking down
    access and preventing attacks through the network or attacks on the network itself.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络层面上，容器、用户和服务之间互相发现和通信的便利性与通过网络或对网络本身的攻击进行访问控制之间始终存在着一种紧张关系。
- en: Many of these challenges are not Kubernetes-specific. However, the fact that
    Kubernetes is a generic platform that manages key infrastructure and deals with
    low-level networking makes it necessary to think about dynamic and flexible solutions
    that can integrate system-specific requirements into Kubernetes. These solutions
    often involve monitoring and automatically injecting firewall rules or applying
    network policies based on namespaces and pod labels.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 许多这些挑战并非 Kubernetes 特有。然而，Kubernetes 作为一个管理关键基础设施并处理低层次网络的通用平台，使得我们必须考虑动态和灵活的解决方案，这些方案可以将系统特定的需求整合进
    Kubernetes 中。这些解决方案通常涉及监控，并根据命名空间和 Pod 标签自动注入防火墙规则或应用网络策略。
- en: Image challenges
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 镜像挑战
- en: 'Kubernetes runs containers that comply with one of its runtime engines. It
    has no idea what these containers are doing (except collecting metrics). You can
    put certain limits on containers via quotas. You can also limit their access to
    other parts of the network via network policies. But, in the end, containers do
    need access to host resources, other hosts in the network, distributed storage,
    and external services. The image determines the behavior of a container. The infamous
    software supply chain problem is at the core of how these container images are
    created. There are two categories of problems with images:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 运行符合其某个运行时引擎标准的容器。它并不知道这些容器在做什么（除了收集度量数据）。你可以通过配额对容器设置某些限制。你还可以通过网络策略限制它们对网络其他部分的访问。但最终，容器确实需要访问主机资源、网络中的其他主机、分布式存储和外部服务。镜像决定了容器的行为。臭名昭著的软件供应链问题正是这些容器镜像创建方式的核心。镜像存在两类问题：
- en: Malicious images
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恶意镜像
- en: Vulnerable images
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 脆弱的镜像
- en: Malicious images are images that contain code or configuration that was designed
    by an attacker to do some harm, collect information, or just take advantage of
    your infrastructure for their purposes (for example, crypto mining). Malicious
    code can be injected into your image preparation pipeline, including any image
    repositories you use. Alternatively, you may install third-party images that were
    compromised themselves and now contain malicious code.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 恶意镜像是指那些包含攻击者设计的代码或配置，目的是造成伤害、收集信息，或者仅仅是利用你的基础设施为其目的服务（例如，进行加密货币挖矿）。恶意代码可能会被注入到你的镜像准备流程中，包括你使用的任何镜像仓库。或者，你可能会安装那些已经被攻击并且现在包含恶意代码的第三方镜像。
- en: Vulnerable images are images you designed (or third-party images you install)
    that just happen to contain some vulnerability that allows an attacker to take
    control of the running container or cause some other harm, including injecting
    their own code later.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 脆弱的镜像是你设计的镜像（或你安装的第三方镜像），它恰巧包含了一些漏洞，允许攻击者控制正在运行的容器或造成其他伤害，包括稍后注入他们自己的代码。
- en: It’s hard to tell which category is worse. At the extreme, they are equivalent
    because they allow seizing total control of the container. The other defenses
    that are in place (remember defense in depth?) and the restrictions you put on
    the container will determine how much damage it can do. Minimizing the danger
    of bad images is very challenging. Fast-moving companies utilizing microservices
    may generate many images daily. Verifying an image is not an easy task either.
    In addition, some containers require wide permissions to do their legitimate job.
    If such a container is compromised it can do extreme damage.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 很难判断哪种情况更糟。极端情况下，它们是等价的，因为它们都允许完全控制容器。现有的其他防御措施（记得深度防御吗？）以及你对容器设置的限制将决定它能造成多大的损害。最大限度地减少不良镜像的危害非常具有挑战性。快速发展的公司使用微服务可能每天都会生成许多镜像。验证镜像也不是一项简单的任务。此外，一些容器需要广泛的权限来完成其合法工作。如果这样的容器被攻破，它可以造成极大的损害。
- en: The base images that contain the operating system may become vulnerable any
    time a new vulnerability is discovered. Moreover, if you rely on base images prepared
    by someone else (very common) then malicious code may find its way into those
    base images, which you have no control over and you trust implicitly.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 包含操作系统的基础镜像可能会在发现新的漏洞时变得脆弱。此外，如果你依赖于他人准备的基础镜像（这非常常见），那么恶意代码可能会进入这些你无法控制的基础镜像，而你却会完全信任它们。
- en: When a vulnerability in a third-party dependency is discovered, ideally there
    is already a fixed version and you should patch it as soon as possible.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 当发现第三方依赖项中的漏洞时，理想情况下已经有了修复版本，你应该尽快进行修补。
- en: 'We can summarize the image challenges that developers are likely to face as
    follows:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes doesn’t know what containers are doing
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes must provide access to sensitive resources for the designated function
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s difficult to protect the image preparation and delivery pipeline (including
    image repositories)
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The speed of development and deployment of new images conflict with the careful
    review of changes
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Base images that contain the OS or other common dependencies can easily get
    out of date and become vulnerable
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Base images are often not under your control and might be more prone to the
    injection of malicious code
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integrating a static image analyzer like CoreOS Clair or the Anchore Engine
    into your CI/CD pipeline can help a lot. In addition, minimizing the blast radius
    by limiting the resource access of containers only to what they need to perform
    their job can reduce the impact on your system if a container gets compromised.
    You must also be diligent about patching known vulnerabilities.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Configuration and deployment challenges
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes clusters are administered remotely. Various manifests and policies
    determine the state of the cluster at each point in time. If an attacker gets
    access to a machine with administrative control over the cluster, they can wreak
    havoc, such as collecting information, injecting bad images, weakening security,
    and tampering with logs. As usual, bugs and mistakes can be just as harmful; by
    neglecting important security measures, you leave the cluster open for attack.
    It is very common these days for employees with administrative access to the cluster
    to work remotely from home or from a coffee shop and have their laptops with them,
    where you are just one kubectl command from opening the floodgates.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s reiterate the challenges:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes is administered remotely
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An attacker with remote administrative access can gain complete control over
    the cluster
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuration and deployment is typically more difficult to test than code
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remote or out-of-office employees risk extended exposure, allowing an attacker
    to gain access to their laptops or phones with administrative access
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are some best practices to minimize this risk, such as a layer of indirection
    in the form of a jump box where a developer connects from the outside to a dedicated
    machine in the cluster with tight controls that manages secure interaction with
    internal services, requiring a VPN connection (which authenticates and encrypts
    all communication), and using multi-factor authentication and one-time passwords
    to protect against trivial password cracking attacks.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Pod and container challenges
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Kubernetes, pods are the unit of work and contain one or more containers.
    The pod is a grouping and deployment construct. But often, containers that are
    deployed together in the same pod interact through direct mechanisms. The containers
    all share the same localhost network and often share mounted volumes from the
    host. This easy integration between containers in the same pod can result in exposing
    parts of the host to all the containers. This might allow one bad container (either
    malicious or just vulnerable) to open the way for an escalated attack on other
    containers in the pod, later taking over the node itself and the entire cluster.
    Control plane add-ons are often collocated with control plane components and present
    that kind of danger, especially because many of them are experimental. The same
    goes for DaemonSets that run pods on every node. The practice of sidecar containers
    where additional containers are deployed in a pod along with your application
    container is very popular, especially with service meshes. This increases that
    risk because the sidecar containers are often outside your control, and if compromised,
    can provide access to your infrastructure.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，pod 是工作单元，包含一个或多个容器。pod 是一个组合和部署结构。但通常，在同一个 pod 中部署的容器会通过直接机制进行交互。这些容器共享相同的
    localhost 网络，并且通常共享来自主机的挂载卷。在同一个 pod 中容器之间的这种简单集成可能会导致将主机的部分内容暴露给所有容器。这可能会使一个坏容器（无论是恶意的还是仅仅是脆弱的）为
    pod 中其他容器的升级攻击打开道路，最终接管节点本身和整个集群。控制平面插件通常与控制平面组件共同部署，这样的风险尤其明显，特别是因为它们中的许多是实验性的。对于在每个节点上运行
    pod 的 DaemonSets 同样适用。Sidecar 容器的做法，指的是与应用程序容器一起部署在 pod 中的附加容器，尤其在服务网格中非常流行。这增加了风险，因为
    sidecar 容器通常在你的控制之外，如果被攻破，可能会为你的基础设施提供访问权限。
- en: 'Multi-container pod challenges include the following:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 多容器 pod 的挑战包括以下几个方面：
- en: The same pod containers share the localhost network
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一 pod 中的容器共享 localhost 网络
- en: The same pod containers sometimes share a mounted volume on the host filesystem
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一 pod 中的容器有时共享主机文件系统中的挂载卷
- en: Bad containers might poison other containers in the pod
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 坏容器可能会对 pod 中的其他容器造成危害
- en: Bad containers have an easier time attacking the node if collocated with another
    container that accesses crucial node resources
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果与访问关键节点资源的其他容器共存，坏容器更容易攻击节点
- en: Experimental add-ons that are collocated with master components might be experimental
    and less secure
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与主控组件共同部署的实验性插件可能不够安全
- en: Service meshes introduce a sidecar container that might become an attack vector
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格引入了可能成为攻击向量的 sidecar 容器
- en: Consider carefully the interaction between containers running in the same pod.
    You should realize that a bad container might try to compromise its sibling containers
    in the same pod as its first attack. This means that you should be able to detect
    rogue containers injected into a pod (e.g. by a malicious admission control webhook
    or a compromised CI/CD pipeline). You should also apply the least privilege principle
    and minimize the damage such a rogue container can do.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 仔细考虑在同一 pod 中运行的容器之间的交互。你应该意识到，坏容器可能会把破坏同 pod 中的其他容器作为首要攻击目标。这意味着你应该能够检测到被注入到
    pod 中的恶意容器（例如通过恶意的准入控制 webhook 或被攻破的 CI/CD 管道）。你还应该应用最小权限原则，并将恶意容器能够造成的损害降到最低。
- en: Organizational, cultural, and process challenges
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 组织、文化和流程方面的挑战
- en: Security is often held in contrast to productivity. This is a normal trade-off
    and nothing to worry about. Traditionally, when developers and operations were
    separate, this conflict was managed at an organizational level. Developers pushed
    for more productivity and treated security requirements as the cost of doing business.
    Operations controlled the production environment and were responsible for access
    and security procedures. The DevOps movement brought down the wall between developers
    and operations. Now, speed of development often takes a front-row seat. Concepts
    such as continuous deployment deploying multiple times a day without human intervention
    were unheard of in most organizations. Kubernetes was designed for this new world
    of cloud-native applications. But, it was developed based on Google’s experience.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性通常与生产力相对立。这是一个正常的权衡，不必担心。传统上，当开发和运维分开时，这种冲突是在组织层面管理的。开发人员推动更多的生产力，并将安全要求视为做生意的成本。运维控制生产环境，并负责访问和安全流程。DevOps
    运动打破了开发和运维之间的壁垒。现在，开发速度通常占据了最前沿的位置。诸如持续部署、每天多次自动部署的概念在大多数组织中都是闻所未闻的。Kubernetes
    就是为这种新的云原生应用场景设计的。但它是基于 Google 的经验开发的。
- en: Google had a lot of time and skilled experts to develop the proper processes
    and tooling to balance rapid deployments with security. For smaller organizations,
    this balancing act might be very challenging and security could be weakened by
    focusing too much on productivity.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Google 有大量的时间和技术专家来开发适当的流程和工具，以平衡快速部署与安全性。对于小型组织来说，这种平衡可能非常具有挑战性，过于专注于生产力可能会削弱安全性。
- en: 'The challenges facing organizations that adopt Kubernetes are as follows:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 采用 Kubernetes 的组织面临的挑战如下：
- en: Developers that control the operation of Kubernetes might be less security-oriented
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 控制 Kubernetes 操作的开发人员可能不那么关注安全性
- en: The speed of development might be considered more important than security
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 开发速度可能被认为比安全性更重要
- en: Continuous deployment might make it difficult to detect certain security problems
    before they reach production
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持续部署可能使得在问题到达生产环境之前难以发现某些安全问题
- en: Smaller organizations might not have the knowledge and expertise to manage security
    properly in Kubernetes clusters
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小型组织可能没有足够的知识和专业能力来在 Kubernetes 集群中正确管理安全性
- en: There are no easy answers here. You should be deliberate in striking the right
    balance between security and agility. I recommend having a dedicated security
    team (or at least one person focused on security) participate in all planning
    meetings and advocate for security. It’s important to bake security into your
    system from the get-go.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 这里没有简单的答案。你应该在安全性和敏捷性之间找到合适的平衡。我建议有一个专门的安全团队（或至少一个专注于安全的人）参与所有的规划会议，并倡导安全。重要的是从一开始就将安全性融入到系统中。
- en: In this section, we reviewed the many challenges you face when you try to build
    a secure Kubernetes cluster. Most of these challenges are not specific to Kubernetes,
    but using Kubernetes means there is a large part of your system that is generic
    and unaware of what the system is doing.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们回顾了在构建安全的 Kubernetes 集群时你所面临的许多挑战。这些挑战大多数并非 Kubernetes 特有，但使用 Kubernetes
    意味着系统的很大一部分是通用的，并且无法知道系统正在做什么。
- en: 'This can pose problems when trying to lock down a system. The challenges are
    spread across different levels:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试锁定系统时，这可能会带来问题。这些挑战分布在不同的层级：
- en: Node challenges
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Node 挑战
- en: Network challenges
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络挑战
- en: Image challenges
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 镜像挑战
- en: Configuration and deployment challenges
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置和部署挑战
- en: Pod and container challenges
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pod 和容器挑战
- en: Organizational and process challenges
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组织和流程挑战
- en: In the next section, we will look at the facilities Kubernetes provides to address
    some of those challenges. Many of the challenges require solutions at the larger
    system scope. It is important to realize that just utilizing all of Kubernetes’
    security features is not enough.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将查看 Kubernetes 提供的设施，解决其中的一些挑战。许多挑战需要在更大的系统范围内找到解决方案。重要的是要意识到，仅仅利用 Kubernetes
    所有的安全功能还不够。
- en: Hardening Kubernetes
  id: totrans-114
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加固 Kubernetes
- en: The previous section cataloged and listed the variety of security challenges
    facing developers and administrators deploying and maintaining Kubernetes clusters.
    In this section, we will hone in on the design aspects, mechanisms, and features
    offered by Kubernetes to address some of the challenges. You can get to a pretty
    good state of security by judicious use of capabilities such as service accounts,
    network policies, authentication, authorization, admission control, AppArmor,
    and secrets.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节列出了部署和维护 Kubernetes 集群时开发人员和管理员面临的各种安全挑战。在本节中，我们将重点介绍 Kubernetes 提供的设计方面、机制和功能，以应对一些挑战。通过明智地使用服务账户、网络策略、身份验证、授权、准入控制、AppArmor
    和机密等能力，你可以达到相当不错的安全状态。
- en: Remember that a Kubernetes cluster is one part of a bigger system that includes
    other software systems, people, and processes. Kubernetes can’t solve all problems.
    You should always keep in mind general security principles, such as defense in
    depth, a need-to-know basis, and the principle of least privilege.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，Kubernetes 集群是一个更大系统的一部分，包含其他软件系统、人员和流程。Kubernetes 不能解决所有问题。你应该始终牢记一般的安全原则，如深度防御、按需知情和最小权限原则。
- en: In addition, log everything you think may be useful in the event of an attack
    and have alerts for early detection when the system deviates from its state. It
    may be just a bug or it may be an attack. Either way, you want to know about it
    and respond.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，记录下你认为在发生攻击时可能有用的所有信息，并设置警报以便在系统偏离其状态时进行早期检测。可能只是一个 bug，也可能是一次攻击。无论哪种情况，你都应该知道并做出响应。
- en: Understanding service accounts in Kubernetes
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 中的服务账户
- en: Kubernetes has regular users that are managed outside the cluster for humans
    connecting to the cluster (for example, via the `kubectl` command), and it has
    service accounts.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 有常规用户账户，这些账户在集群外部管理，供人类通过 `kubectl` 命令连接到集群使用，同时也有服务账户。
- en: Regular user accounts are global and can access multiple namespaces in the cluster.
    Service accounts are constrained to one namespace. This is important. It ensures
    namespace isolation, because whenever the API server receives a request from a
    pod, its credentials will apply only to its own namespace.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 常规用户账户是全局的，可以访问集群中的多个命名空间。服务账户仅限于一个命名空间。这一点很重要。它确保了命名空间的隔离，因为每当 API 服务器收到来自
    Pod 的请求时，其凭证仅适用于其所在的命名空间。
- en: Kubernetes manages service accounts on behalf of the pods. Whenever Kubernetes
    instantiates a pod, it assigns the pod a service account unless the service account
    or the pod explicitly opted out by setting `automountServiceAccountToken` to `False`.
    The service account identifies all the pod processes when they interact with the
    API server. Each service account has a set of credentials mounted in a secret
    volume. Each namespace has a default service account called default. When you
    create a pod, it is automatically assigned the default service account unless
    you specify a different service account.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 代表 Pod 管理服务账户。每当 Kubernetes 实例化一个 Pod 时，它会分配一个服务账户，除非服务账户或 Pod 明确通过设置`automountServiceAccountToken`为`False`来选择退出。服务账户在与
    API 服务器交互时标识所有 Pod 进程。每个服务账户都有一组凭证，挂载在一个机密卷中。每个命名空间都有一个默认的服务账户，称为 `default`。当你创建一个
    Pod 时，它会自动分配默认的服务账户，除非你指定一个不同的服务账户。
- en: You can create additional service accounts if you want different pods to have
    different identities and permissions. Then you can bind different service accounts
    to different roles.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望不同的 Pod 拥有不同的身份和权限，可以创建额外的服务账户。然后，你可以将不同的服务账户绑定到不同的角色。
- en: 'Create a file called `custom-service-account.yaml` with the following content:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个名为 `custom-service-account.yaml` 的文件，内容如下：
- en: '[PRE0]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Now type the following:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 现在输入以下命令：
- en: '[PRE1]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Here is the service account listed alongside the default service account:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 这是与默认服务账户一起列出的服务账户：
- en: '[PRE2]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Note that a secret was created automatically for your new service account:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，为你的新服务账户自动创建了一个机密：
- en: '[PRE3]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To get more detail, type the following:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取更多细节，请输入以下命令：
- en: '[PRE4]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'You can see the secret itself, which includes a `ca.crt` file and a token,
    by typing the following:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过输入以下命令查看包含`ca.crt`文件和令牌的机密信息：
- en: '[PRE5]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: How does Kubernetes manage service accounts?
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Kubernetes 如何管理服务账户？
- en: The API server has a dedicated component called the service account admission
    controller. It is responsible for checking, at pod creation time, if the API server
    has a custom service account and, if it does, that the custom service account
    exists. If there is no service account specified, then it assigns the default
    service account.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: API 服务器有一个专用组件称为服务账户准入控制器。它负责在创建 pod 时检查 API 服务器是否具有自定义服务账户，如果有的话，检查该自定义服务账户是否存在。如果未指定服务账户，则分配默认服务账户。
- en: It also ensures the pod has `ImagePullSecrets`, which are necessary when images
    need to be pulled from a remote image registry. If the pod spec doesn’t have any
    secrets, it uses the service account’s `ImagePullSecrets`.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 它还确保 pod 具有`ImagePullSecrets`，这在需要从远程镜像注册表拉取镜像时是必需的。如果 pod 规范没有任何 secrets，它将使用服务账户的`ImagePullSecrets`。
- en: Finally, it adds a `volume` with an API token for API access and a `volumeSource`
    mounted at `/var/run/secrets/kubernetes.io/serviceaccount`.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，它添加了一个包含 API 访问令牌的`volume`和一个`volumeSource`，挂载到`/var/run/secrets/kubernetes.io/serviceaccount`。
- en: The API token is created and added to the secret by another component called
    the **token controller** whenever a service account is created. The token controller
    also monitors secrets and adds or removes tokens wherever secrets are added to
    or removed from a service account.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 每当创建服务账户时，另一个名为**令牌控制器**的组件会创建并添加 API 令牌到密钥中。令牌控制器还监视 secrets，并在将 secrets 添加到或从服务账户中移除时添加或移除令牌。
- en: The **service account controller** ensures the default service account exists
    for every namespace.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '**服务账户控制器**确保每个命名空间存在默认服务账户。'
- en: Accessing the API server
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问 API 服务器
- en: Accessing the API server requires a chain of steps that include authentication,
    authorization, and admission control. At each stage, the request may be rejected.
    Each stage consists of multiple plugins that are chained together.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 访问 API 服务器需要一系列步骤，包括认证、授权和准入控制。在每个阶段，请求可能会被拒绝。每个阶段由多个插件串联在一起。
- en: 'The following diagram illustrates this:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表说明了这一过程：
- en: '![Diagram  Description automatically generated with medium confidence](img/B18998_04_02.png)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
  zh: '![具有中等信心自动生成的图表描述](img/B18998_04_02.png)'
- en: 'Figure 4.2: Accessing the API server'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2：访问 API 服务器
- en: Authenticating users
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 用户认证
- en: 'When you first create the cluster, some keys and certificates are created for
    you to authenticate against the cluster. These credentials are typically stored
    in the file `~/.kube/config`, which may contain credentials for multiple clusters.
    You can also have multiple configuration files and control which file will be
    used by setting the `KUBECONFIG` environment variable or passing the `--kubeconfig`
    flag to kubectl. kubectl uses the credentials to authenticate itself to the API
    server and vice versa over TLS (an encrypted HTTPS connection). Let’s create a
    new KinD cluster and store its credentials in a dedicated config file by setting
    the `KUBECONFIG` environment variable:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 当您首次创建集群时，会为您创建一些密钥和证书，用于对集群进行身份验证。这些凭据通常存储在文件`~/.kube/config`中，该文件可能包含多个集群的凭据。您也可以拥有多个配置文件，并通过设置`KUBECONFIG`环境变量或向
    kubectl 传递`--kubeconfig`标志来控制使用哪个文件。kubectl 使用这些凭据通过 TLS（加密的 HTTPS 连接）与 API 服务器进行双向身份验证。让我们创建一个新的
    KinD 集群，并通过设置`KUBECONFIG`环境变量将其凭据存储在专用配置文件中：
- en: '[PRE6]'
  id: totrans-148
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You can view your configuration using this command:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以使用以下命令查看您的配置：
- en: '[PRE7]'
  id: totrans-150
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: This is the configuration for a KinD cluster. It may look different for other
    types of clusters.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 KinD 集群的配置。其他类型的集群可能看起来不同。
- en: Note that if multiple users need to access the cluster, the creator should provide
    the necessary client certificates and keys to the other users in a secure manner.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，如果多个用户需要访问集群，则创建者应以安全的方式向其他用户提供必要的客户端证书和密钥。
- en: This is just establishing basic trust with the Kubernetes API server itself.
    You’re not authenticated yet. Various authentication modules may look at the request
    and check for various additional client certificates, passwords, bearer tokens,
    and JWT tokens (for service accounts). Most requests require an authenticated
    user (either a regular user or a service account), although there are some anonymous
    requests too. If a request fails to authenticate with all the authenticators it
    will be rejected with a 401 HTTP status code (unauthorized, which is a bit of
    a misnomer).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 这只是与 Kubernetes API 服务器本身建立基本信任。你还没有完成身份验证。各种身份验证模块可能会查看请求，并检查是否有附加的客户端证书、密码、承载令牌和
    JWT 令牌（用于服务帐户）。大多数请求需要已验证的用户（无论是常规用户还是服务帐户），尽管也有一些匿名请求。如果请求在所有身份验证器中无法进行身份验证，它将被拒绝，并返回
    401 HTTP 状态码（未授权，这个名称可能有点误导）。
- en: 'The cluster administrator determines what authentication strategies to use
    by providing various command-line arguments to the API server:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 集群管理员通过向 API 服务器提供各种命令行参数来确定使用哪些身份验证策略：
- en: '`--client-ca-file=` (for x509 client certificates specified in a file)'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--client-ca-file=`（用于从文件中指定的 x509 客户端证书）'
- en: '`--token-auth-file=` (for bearer tokens specified in a file)'
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--token-auth-file=`（用于从文件中指定的承载令牌）'
- en: '`--basic-auth-file=` (for user/password pairs specified in a file)'
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--basic-auth-file=`（用于文件中指定的用户名/密码对）'
- en: '`--enable-bootstrap-token-auth` (for bootstrap tokens used by kubeadm)'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--enable-bootstrap-token-auth`（用于 kubeadm 使用的引导令牌）'
- en: 'Service accounts use an automatically loaded authentication plugin. The administrator
    may provide two optional flags:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 服务帐户使用自动加载的身份验证插件。管理员可以提供两个可选标志：
- en: '`--service-account-key-file=` (If not specified, the API server’s TLS private
    key will be utilized as the PEM-encoded key for signing bearer tokens.)'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--service-account-key-file=`（如果未指定，API 服务器将使用其 TLS 私钥作为 PEM 编码的密钥来签名承载令牌。）'
- en: '`--service-account-lookup` (When enabled, the revocation of tokens will take
    place if they are deleted from the API.)'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--service-account-lookup`（启用时，如果令牌被删除，API 将会撤销这些令牌。）'
- en: There are several other methods, such as OpenID Connect, webhooks, Keystone
    (the OpenStack identity service), and an authenticating proxy. The main theme
    is that the authentication stage is extensible and can support any authentication
    mechanism.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 还有其他几种方法，例如 OpenID Connect、webhooks、Keystone（OpenStack 身份服务）和身份验证代理。主要特点是身份验证阶段是可扩展的，可以支持任何身份验证机制。
- en: 'The various authentication plugins will examine the request and, based on the
    provided credentials, will associate the following attributes:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 各种身份验证插件会检查请求，并根据提供的凭证关联以下属性：
- en: '**Username** (a user-friendly name)'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户名**（用户友好的名称）'
- en: '**UID** (a unique identifier and more consistent than the username)'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**UID**（一个唯一标识符，比用户名更稳定）'
- en: '**Groups** (a set of group names the user belongs to)'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**组**（用户所属的组名称集合）'
- en: '**Extra fields** (these map string keys to string values)'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**额外字段**（这些字段将字符串键映射到字符串值）'
- en: In Kubernetes 1.11, kubectl gained the ability to use credential plugins to
    receive an opaque token from a provider such as an organizational LDAP server.
    These credentials are sent by kubectl to the API server that typically uses a
    webhook token authenticator to authenticate the credentials and accept the request.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 1.11 中，kubectl 增加了使用凭证插件的功能，可以从提供者（如组织的 LDAP 服务器）获取不透明令牌。kubectl
    会将这些凭证发送到 API 服务器，API 服务器通常使用 webhook 令牌验证器来验证凭证并接受请求。
- en: The authenticators have no knowledge whatsoever of what a particular user is
    allowed to do. They just map a set of credentials to a set of identities. The
    authenticators run in an unspecified order; the first authenticator to accept
    the passed credentials will associate an identity with the incoming request and
    the authentication is considered successful. If all authenticators reject the
    credentials then authentication failed.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 身份验证器根本不知道特定用户被允许做什么。它们只是将一组凭证映射到一组身份。身份验证器按未指定的顺序运行；第一个接受传入凭证的身份验证器将与传入请求关联身份，并且身份验证被视为成功。如果所有身份验证器都拒绝凭证，则身份验证失败。
- en: It’s interesting to note that Kubernetes has no idea who its regular users are.
    There is no list of users in etcd. Authentication is granted to any user who presents
    a valid certificate that has been signed by the **certificate authority** (**CA**)
    associated with the cluster.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，Kubernetes 完全不知道谁是它的常规用户。etcd 中没有用户列表。任何提供由与集群关联的**证书颁发机构**（**CA**）签名的有效证书的用户都会获得身份验证。
- en: Impersonation
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 冒充
- en: 'It is possible for users to impersonate different users (with proper authorization).
    For example, an admin may want to troubleshoot some issue as a different user
    with fewer privileges. This requires passing impersonation headers to the API
    request. The headers are as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 用户可以冒充不同的用户（前提是拥有适当的授权）。例如，管理员可能希望以具有较少权限的其他用户身份进行故障排除。这需要向 API 请求传递冒充头部。头部信息如下：
- en: '**Impersonate-User**: Specifies the username to act on behalf of.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Impersonate-User**: 指定要代表其执行操作的用户名。'
- en: '**Impersonate-Group**: Specifies a group name to act on behalf of. Multiple
    groups can be provided by specifying this option multiple times. This option is
    optional but requires Impersonate-User to be set.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Impersonate-Group**: 指定要代表其执行操作的组名。可以通过多次指定此选项来提供多个组。此选项是可选的，但需要设置 Impersonate-User。'
- en: '**Impersonate-Extra-(extra name)**: A dynamic header used to associate additional
    fields with the user. This option is optional but requires Impersonate-User to
    be set.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Impersonate-Extra-(extra name)**: 一个动态头部，用于将附加字段与用户关联。此选项是可选的，但需要设置 Impersonate-User。'
- en: With kubectl, you pass the `–-as` and `--as-group` parameters.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 kubectl 时，可以传递 `--as` 和 `--as-group` 参数。
- en: 'To impersonate a service account, type the following:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 要冒充服务帐户，请输入以下内容：
- en: '[PRE8]'
  id: totrans-178
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Authorizing requests
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 授权请求
- en: Once a user is authenticated, authorization commences. Kubernetes has generic
    authorization semantics. A set of authorization modules receives the request,
    which includes information such as the authenticated username and the request’s
    verb (list, get, watch, create, and so on). Unlike authentication, all authorization
    plugins will get a shot at any request. If a single authorization plugin rejects
    the request or no plugin had an opinion then it will be rejected with a 403 HTTP
    status code (forbidden). A request will continue only if at least one plugin accepts
    it and no other plugin rejected it.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 用户通过身份验证后，授权开始。Kubernetes 具有通用的授权语义。一组授权模块会接收请求，其中包括已验证的用户名和请求的操作动词（如 list、get、watch、create
    等）。与身份验证不同，所有授权插件都会处理每个请求。如果任何一个授权插件拒绝该请求，或者没有插件发表意见，则该请求会被拒绝，并返回 403 HTTP 状态码（禁止访问）。只有当至少一个插件接受请求且没有其他插件拒绝时，请求才会继续。
- en: The cluster administrator determines what authorization plugins to use by specifying
    the `--authorization-mode` command-line flag, which is a comma-separated list
    of plugin names.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 集群管理员通过指定 `--authorization-mode` 命令行标志来确定使用哪些授权插件，该标志是一个以逗号分隔的插件名称列表。
- en: 'The following modes are supported:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 支持以下模式：
- en: '`--authorization-mode=AlwaysDeny` rejects all requests. Use if you don’t need
    authorization.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--authorization-mode=AlwaysDeny` 拒绝所有请求。如果不需要授权，可以使用此选项。'
- en: '`--authorization-mode=AlwaysAllow` allows all requests. Use if you don’t need
    authorization. This is useful during testing.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--authorization-mode=AlwaysAllow` 允许所有请求。如果不需要授权，可以使用此选项。这在测试期间非常有用。'
- en: '`--authorization-mode=ABAC` allows for a simple, local-file-based, user-configured
    authorization policy. ABAC stands for Attribute-Based Access Control.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--authorization-mode=ABAC` 允许基于简单的本地文件、用户配置的授权策略。ABAC 代表基于属性的访问控制。'
- en: '`--authorization-mode=RBAC` is a role-based mechanism where authorization policies
    are stored and driven by the Kubernetes API. RBAC stands for Role-Based Access
    Control.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--authorization-mode=RBAC` 是一种基于角色的机制，授权策略由 Kubernetes API 存储并驱动。RBAC 代表基于角色的访问控制。'
- en: '`--authorization-mode=Node` is a special mode designed to authorize API requests
    made by kubelets.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--authorization-mode=Node` 是一种特殊模式，旨在授权 kubelet 发出的 API 请求。'
- en: '`--authorization-mode=Webhook` allows for authorization to be driven by a remote
    service using REST.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--authorization-mode=Webhook` 允许通过远程服务使用 REST 来驱动授权。'
- en: 'You can add your own custom authorization plugin by implementing the following
    straightforward Go interface:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过实现以下简单的 Go 接口，添加自定义授权插件：
- en: '[PRE9]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The `Attributes` input argument is also an interface that provides all the
    information you need to make an authorization decision:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '`Attributes` 输入参数也是一个接口，提供做出授权决策所需的所有信息：'
- en: '[PRE10]'
  id: totrans-192
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: You can find the source code at [https://github.com/kubernetes/apiserver/blob/master/pkg/authorization/authorizer/interfaces.go](https://github.com/kubernetes/apiserver/blob/master/pkg/authorization/authorizer/interfaces.go).
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 [https://github.com/kubernetes/apiserver/blob/master/pkg/authorization/authorizer/interfaces.go](https://github.com/kubernetes/apiserver/blob/master/pkg/authorization/authorizer/interfaces.go)
    找到源代码。
- en: 'Using the `kubectl can-i` command, you can check what actions you can perform
    and even impersonate other users:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `kubectl can-i` 命令，你可以检查你可以执行的操作，甚至可以假扮其他用户：
- en: '[PRE11]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'kubectl supports plugins. We will discuss plugins in depth later in *Chapter
    15*, *Extending Kubernetes*. In the meantime, I’ll just mention that one of my
    favorite plugins is rolesum. This plugin gives you a summary of all the permissions
    a user or service account has. Here is an example:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: kubectl 支持插件。稍后我们将在*第15章*中深入讨论插件，*扩展 Kubernetes*。同时，我先提一下我最喜欢的插件之一是 rolesum。这个插件为你提供了用户或服务账户所有权限的总结。以下是一个例子：
- en: '[PRE12]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Check it out here: [https://github.com/Ladicle/kubectl-rolesum](https://github.com/Ladicle/kubectl-rolesum).'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在此查看：[https://github.com/Ladicle/kubectl-rolesum](https://github.com/Ladicle/kubectl-rolesum)。
- en: Using admission control plugins
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用准入控制插件
- en: 'OK. The request was authenticated and authorized, but there is one more step
    before it can be executed. The request must go through a gauntlet of admission-control
    plugins. Similar to the authorizers, if a single admission controller rejects
    a request, it is denied. Admission controllers are a neat concept. The idea is
    that there may be global cluster concerns that could be grounds for rejecting
    a request. Without admission controllers, all authorizers would have to be aware
    of these concerns and reject the request. But, with admission controllers, this
    logic can be performed once. In addition, an admission controller may modify the
    request. Admission controllers run in either validating mode or mutating mode.
    As usual, the cluster administrator decides which admission control plugins run
    by providing a command-line argument called `admission-control`. The value is
    a comma-separated and ordered list of plugins. Here is the list of recommended
    plugins for Kubernetes >= 1.9 (the order matters):'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 好的。请求已通过身份验证和授权，但在执行之前还有一步。请求必须通过一系列准入控制插件的检查。与授权器类似，如果任何一个准入控制器拒绝了请求，则请求会被拒绝。准入控制器是一个很棒的概念。其核心思想是，可能存在一些全局集群问题，可以作为拒绝请求的依据。如果没有准入控制器，所有授权器都必须意识到这些问题并拒绝请求。但有了准入控制器，这些逻辑可以集中执行。此外，准入控制器还可以修改请求。准入控制器可以在验证模式或变更模式下运行。通常，集群管理员通过提供一个名为
    `admission-control` 的命令行参数来决定运行哪些准入控制插件。其值是一个以逗号分隔且有序的插件列表。以下是 Kubernetes >= 1.9
    推荐的插件列表（顺序很重要）：
- en: '[PRE13]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Let’s look at some available plugins (more are added all the time):'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下可用的插件（不断有新的插件加入）：
- en: '`DefaultStorageClass`: Adds a default storage class to requests for the creation
    of a `PersistentVolumeClaim` that doesn’t specify a storage class.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DefaultStorageClass`：为创建未指定存储类的 `PersistentVolumeClaim` 请求添加默认存储类。'
- en: '`DefaultTolerationSeconds`: Sets the default toleration of pods for taints
    (if not set already): `notready:NoExecute` and `notreachable:NoExecute`.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`DefaultTolerationSeconds`：设置 Pods 对于污点的默认容忍时间（如果尚未设置）：`notready:NoExecute`
    和 `notreachable:NoExecute`。'
- en: '`EventRateLimit`: Limits flooding of the API server with events.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`EventRateLimit`：限制事件泛滥对 API 服务器的影响。'
- en: '`ExtendedResourceToleration`: Combines taints on nodes with special resources
    such as GPUs and **Field Programmable Gate Arrays** (**FPGAs**) with toleration
    on pods that request those resources. The end result is that the node with the
    extra resources will be dedicated for pods with the proper toleration.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ExtendedResourceToleration`：将节点上带有特殊资源（如 GPU 和 **现场可编程门阵列** (**FPGAs**)）的污点与请求这些资源的
    Pods 上的容忍相结合。最终结果是，带有额外资源的节点将专门用于具有正确容忍的 Pods。'
- en: '`ImagePolicyWebhook`: This complicated plugin connects to an external backend
    to decide whether a request should be rejected based on the image.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ImagePolicyWebhook`：这个复杂的插件连接到一个外部后端，根据镜像决定是否应该拒绝请求。'
- en: '`LimitPodHardAntiAffinity`: In the `requiredDuringSchedulingRequiredDuringExecution`
    field, any pod that specifies an AntiAffinity topology key other than `kubernetes.io/hostname`
    will be denied.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LimitPodHardAntiAffinity`：在 `requiredDuringSchedulingRequiredDuringExecution`
    字段中，任何指定非 `kubernetes.io/hostname` 的 AntiAffinity 拓扑键的 Pod 将被拒绝。'
- en: '`LimitRanger`: Rejects requests that violate resource limits.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LimitRanger`：拒绝违反资源限制的请求。'
- en: '`MutatingAdmissionWebhook`: Calls registered mutating webhooks that are able
    to modify their target object. Note that there is no guarantee that the change
    will be effective due to potential changes by other mutating webhooks.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`MutatingAdmissionWebhook`：调用已注册的变更 Webhook，这些 Webhook 可以修改其目标对象。请注意，由于其他变更
    Webhook 的潜在更改，无法保证更改会生效。'
- en: '`NamespaceAutoProvision`: Creates the namespace in the request if it doesn’t
    exist already.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NamespaceAutoProvision`：如果请求中的命名空间不存在，则会创建该命名空间。'
- en: '`NamespaceLifecycle`: Rejects object creation requests in namespaces that are
    in the process of being terminated or don’t exist.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NamespaceLifecycle`：拒绝在正在终止或不存在的命名空间中创建对象的请求。'
- en: '`ResourceQuota`: Rejects requests that violate the namespace’s resource quota.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ResourceQuota`：拒绝违反命名空间资源配额的请求。'
- en: '`ServiceAccount`: Automation for service accounts.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ServiceAccount`：服务账户的自动化。'
- en: '`ValidatingAdmissionWebhook`: The admission controller invokes validating webhooks
    that match the request. The matching webhooks are called concurrently, and if
    any of them reject the request, the overall request fails.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ValidatingAdmissionWebhook`：准入控制器调用与请求匹配的验证Webhook。匹配的Webhook会并行调用，如果任何一个Webhook拒绝请求，则整个请求失败。'
- en: As you can see, the admission control plugins have very diverse functionality.
    They support namespace-wide policies and enforce the validity of requests mostly
    from the resource management and security points of view. This frees up the authorization
    plugins to focus on valid operations. `ImagePolicyWebHook` is the gateway to validating
    images, which is a big challenge. `MutatingAdmissionWebhook` and `ValidatingAdmissionWebhook`
    are the gateways to dynamic admission control, where you can deploy your own admission
    controller without compiling it into Kubernetes. Dynamic admission control is
    suitable for tasks like semantic validation of resources (do all pods have the
    standard set of labels?). We will discuss dynamic admission control in depth later,
    in *Chapter 16*, *Governing Kubernetes*, as this is the foundation of policy management
    governance in Kubernetes.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，准入控制插件有非常多样的功能。它们支持命名空间级的策略，并从资源管理和安全角度强制执行请求的有效性。这使得授权插件能够专注于有效的操作。`ImagePolicyWebHook`是验证镜像的门户，这是一个大挑战。`MutatingAdmissionWebhook`和`ValidatingAdmissionWebhook`是动态准入控制的门户，你可以在不将其编译到Kubernetes中的情况下部署自己的准入控制器。动态准入控制适用于资源的语义验证等任务（所有Pod是否都有标准的标签集合？）。我们将在*第16章*《Kubernetes治理》中深入讨论动态准入控制，因为它是Kubernetes中策略管理治理的基础。
- en: The division of responsibility for validating an incoming request through the
    separate stages of authentication, authorization, and admission, each with its
    own plugins, makes a complicated process much more manageable to understand, use,
    and extend.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 通过认证、授权和准入等不同阶段的责任划分来验证传入请求，每个阶段都有自己的插件，这使得复杂的过程更容易理解、使用和扩展。
- en: The mutating admission controllers provide a lot of flexibility and the ability
    to automatically enforce certain policies without burdening the users (for example,
    creating a namespace automatically if it doesn’t exist).
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 变更型准入控制器提供了大量的灵活性，并能够自动执行某些策略，而不会给用户带来负担（例如，如果命名空间不存在，则自动创建命名空间）。
- en: Securing pods
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安全保障Pod
- en: Pod security is a major concern, since Kubernetes schedules the pods and lets
    them run. There are several independent mechanisms for securing pods and containers.
    Together these mechanisms support defense in depth, where, even if an attacker
    (or a mistake) bypasses one mechanism, it will get blocked by another.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: Pod安全是一个重要问题，因为Kubernetes调度Pod并让它们运行。为了保护Pod和容器，有几种独立的机制。通过这些机制的配合支持深度防御，即使攻击者（或错误）绕过了某个机制，也会被另一个机制阻止。
- en: Using a private image repository
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用私有镜像仓库
- en: This approach gives you a lot of confidence that your cluster will only pull
    images that you have previously vetted, and you can manage upgrades better. In
    light of the rise in software supply chain attacks it is an important countermeasure.
    You can configure your `HOME/.docker/config.json` on each node. But, on many cloud
    providers, you can’t do this because nodes are provisioned automatically for you.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法让你对集群的信心大增，确保它只拉取你之前审核过的镜像，同时也能更好地管理升级。考虑到软件供应链攻击的增加，这是一种重要的防御措施。你可以在每个节点上配置`HOME/.docker/config.json`。但是，在许多云服务提供商的环境下，你无法这么做，因为节点是自动为你提供的。
- en: ImagePullSecrets
  id: totrans-223
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ImagePullSecrets
- en: This approach is recommended for clusters on cloud providers. The idea is that
    the credentials for the registry will be provided by the pod, so it doesn’t matter
    what node it is scheduled to run on. This circumvents the problem with `.dockercfg`
    at the node level.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法推荐用于云服务提供商上的集群。其理念是，由Pod提供注册表凭证，因此无论Pod调度在哪个节点上运行都不重要。这解决了节点级别的`.dockercfg`问题。
- en: 'First, you need to create a secret object for the credentials:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，您需要为凭证创建一个 secret 对象：
- en: '[PRE14]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: You can create secrets for multiple registries (or multiple users for the same
    registry) if needed. The kubelet will combine all `ImagePullSecrets`.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，您可以为多个注册中心（或相同注册中心的多个用户）创建 secrets。kubelet 将合并所有 `ImagePullSecrets`。
- en: 'But, since pods can access secrets only in their own namespace, you must create
    a secret on each namespace where you want the pod to run. Once the secret is defined,
    you can add it to the pod spec and run some pods on your cluster. The pod will
    use the credentials from the secret to pull images from the target image registry:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，由于 Pod 只能访问自己命名空间中的 secrets，因此必须在每个希望运行 Pod 的命名空间中创建一个 secret。一旦定义了 secret，就可以将其添加到
    Pod 规格中，并在集群上运行一些 Pod。Pod 将使用 secret 中的凭证从目标镜像注册中心拉取镜像：
- en: '[PRE15]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Specifying a security context for pods and containers
  id: totrans-230
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为 Pod 和容器指定安全上下文
- en: Kubernetes allows setting a security context at the pod level and additional
    security contexts at the container level. The pod security context is a set of
    operating-system-level security settings such as UID, GID, capabilities, and SELinux
    role. The pod security context can also apply its security settings (in particular,
    `fsGroup` and `seLinuxOptions`) to volumes.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 允许在 Pod 级别设置安全上下文，并在容器级别设置额外的安全上下文。Pod 安全上下文是一组操作系统级的安全设置，例如 UID、GID、能力和
    SELinux 角色。Pod 安全上下文还可以将其安全设置（特别是 `fsGroup` 和 `seLinuxOptions`）应用于卷。
- en: 'Here is an example of a pod security context:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个 Pod 安全上下文的示例：
- en: '[PRE16]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: For the complete list of pod security context fields, check out [https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podsecuritycontext-v1-core](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podsecuritycontext-v1-core).
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 Pod 安全上下文字段的完整列表，请查看 [https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podsecuritycontext-v1-core](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#podsecuritycontext-v1-core)。
- en: The container security context is applied to each container and it adds container-specific
    settings. Some fields of the container security context overlap with fields in
    the pod security context. If the container security context specifies these fields
    they override the values in the pod security context. Container context settings
    can’t be applied to volumes, which remain at the pod level even if mounted into
    specific containers only.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 容器安全上下文应用于每个容器，并添加容器特定的设置。容器安全上下文中的某些字段与 Pod 安全上下文中的字段重叠。如果容器安全上下文指定了这些字段，它们将覆盖
    Pod 安全上下文中的值。容器上下文设置不能应用于卷，卷即使仅挂载到特定容器中，也仍然保持在 Pod 级别。
- en: 'Here is a pod with a container security context:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个包含容器安全上下文的 Pod：
- en: '[PRE17]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: For the complete list of container security context fields, check out [https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#securitycontext-v1-core](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#securitycontext-v1-core).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 有关容器安全上下文字段的完整列表，请查看 [https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#securitycontext-v1-core](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#securitycontext-v1-core)。
- en: Pod security standards
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pod 安全标准
- en: Kubernetes defines security profiles that are appropriate for different security
    needs and aggregates recommended settings. The privileged profile provides all
    permissions and is, unfortunately, the default. The baseline profile is a minimal
    security profile that just prevents privilege escalation. The restricted profile
    follows hardening best practices.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 定义了适用于不同安全需求的安全配置文件，并汇总了推荐的设置。特权配置文件提供所有权限，并且不幸的是，它是默认配置。基础配置文件是一个最小的安全配置文件，只是防止特权提升。受限配置文件遵循强化最佳实践。
- en: 'See more info here: [https://kubernetes.io/docs/concepts/security/pod-security-standards/](https://kubernetes.io/docs/concepts/security/pod-security-standards/).'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在此处查看更多信息：[https://kubernetes.io/docs/concepts/security/pod-security-standards/](https://kubernetes.io/docs/concepts/security/pod-security-standards/)。
- en: Protecting your cluster with AppArmor
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用 AppArmor 保护您的集群
- en: AppArmor is a Linux kernel security module. With AppArmor, you can restrict
    a process running in a container to a limited set of resources such as network
    access, Linux capabilities, and file permissions. You configure AppArmor through
    profiles.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: AppArmor 是一个 Linux 内核安全模块。通过 AppArmor，您可以将容器中运行的进程限制在一组有限的资源中，例如网络访问、Linux 能力和文件权限。您可以通过配置文件来配置
    AppArmor。
- en: AppArmor requirements
  id: totrans-244
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: AppArmor 要求
- en: AppArmor support was added as beta in Kubernetes 1.4\. It is not available for
    every OS, so you must choose a supported OS distribution in order to take advantage
    of it. Ubuntu and SUSE Linux support AppArmor and enable it by default. Other
    distributions have optional support.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: AppArmor支持在Kubernetes 1.4中作为Beta功能加入。它并非在所有操作系统中都可用，因此你必须选择一个支持的操作系统发行版才能使用它。Ubuntu和SUSE
    Linux支持AppArmor，并默认启用它。其他发行版则是可选支持。
- en: 'To check if AppArmor is enabled connect to a node (e.g. via `ssh`) and type
    the following:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 要检查AppArmor是否启用，请连接到节点（例如通过`ssh`）并输入以下命令：
- en: '[PRE18]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: If the result is `Y` then it’s enabled. If the file doesn’t exist or the result
    is not `Y` it is not enabled.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 如果结果是`Y`，则表示已启用。如果文件不存在或结果不是`Y`，则表示未启用。
- en: 'The profile must be loaded into the kernel. Check the following file:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 该配置文件必须加载到内核中。检查以下文件：
- en: '[PRE19]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Kubernetes doesn’t provide a built-in mechanism to load profiles to nodes. You
    typically need a DaemonSet with node-level privileges to load the necessary AppArmor
    profiles into the nodes.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes没有提供内建机制来将配置文件加载到节点中。通常你需要一个具有节点级别权限的DaemonSet来将必要的AppArmor配置文件加载到节点中。
- en: 'Check out the following link for more details on loading AppArmor profiles
    into nodes: [https://kubernetes.io/docs/tutorials/security/apparmor/#setting-up-nodes-with-profiles](https://kubernetes.io/docs/tutorials/security/apparmor/#setting-up-nodes-with-profiles).'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 有关将AppArmor配置文件加载到节点中的更多详细信息，请查看以下链接：[https://kubernetes.io/docs/tutorials/security/apparmor/#setting-up-nodes-with-profiles](https://kubernetes.io/docs/tutorials/security/apparmor/#setting-up-nodes-with-profiles)。
- en: Securing a pod with AppArmor
  id: totrans-253
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 使用AppArmor保护Pod
- en: Since AppArmor is still in beta, you specify the metadata as annotations and
    not as bonafide fields. When it gets out of beta, this will change.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 由于AppArmor仍处于Beta阶段，因此你需要将元数据作为注释而非正式字段来指定。当它脱离Beta阶段后，这一点将会改变。
- en: 'To apply a profile to a container, add the following annotation:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 要将配置文件应用到容器，请添加以下注释：
- en: '[PRE20]'
  id: totrans-256
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The profile reference can be either the `default` profile, `runtime/default`,
    or a profile file on the host/localhost.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件的引用可以是`default`配置文件、`runtime/default`或主机/本地主机上的配置文件。
- en: 'Here is a sample profile that prevents writing to files:'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例配置文件，防止写入文件：
- en: '[PRE21]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: AppArmor is not a Kubernetes resource, so the format is not the YAML or JSON
    you’re familiar with.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: AppArmor不是Kubernetes资源，因此其格式并不是你熟悉的YAML或JSON格式。
- en: 'To verify the profile was attached correctly, check the attributes of process
    1:'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 要验证配置文件是否正确附加，请检查进程1的属性：
- en: '[PRE22]'
  id: totrans-262
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Pods can be scheduled on any node in the cluster by default. This means the
    profile should be loaded into every node. This is a classic use case for a DaemonSet.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Pod可以在集群中的任何节点上调度。这意味着配置文件应加载到每个节点中。这是DaemonSet的经典用例。
- en: Writing AppArmor profiles
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 编写AppArmor配置文件
- en: 'Writing profiles for AppArmor by hand is not trivial. There are some tools
    that can help: `aa-genprof` and `aa-logprof` can generate a profile for you and
    assist in fine-tuning it by running your application with AppArmor in complain
    mode. The tools keep track of your application’s activity and AppArmor warnings
    and create a corresponding profile. This approach works, but it feels clunky.'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 手动编写AppArmor配置文件并不简单。有一些工具可以提供帮助：`aa-genprof`和`aa-logprof`可以为你生成配置文件，并通过在投诉模式下运行应用程序来协助微调。工具会跟踪应用程序的活动和AppArmor警告，并创建相应的配置文件。这种方法有效，但感觉有些笨重。
- en: 'My favorite tool is bane, which generates AppArmor profiles from a simpler
    profile language based on the TOML syntax. bane profiles are very readable and
    easy to grasp. Here is a sample bane profile:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 我最喜欢的工具是bane，它通过基于TOML语法的简化配置语言生成AppArmor配置文件。bane配置文件非常易读，且易于理解。以下是一个示例bane配置文件：
- en: '[PRE23]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The generated AppArmor profile is pretty gnarly (verbose and complicated).
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的AppArmor配置文件相当复杂（冗长且复杂）。
- en: 'You can find more information about bane here: [https://github.com/genuinetools/bane](https://github.com/genuinetools/bane).'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到有关bane的更多信息：[https://github.com/genuinetools/bane](https://github.com/genuinetools/bane)。
- en: Pod Security Admission
  id: totrans-270
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Pod安全准入
- en: Pod Security Admission is an admission controller that is responsible for managing
    the Pod Security Standards ([https://kubernetes.io/docs/concepts/security/pod-security-standards/](https://kubernetes.io/docs/concepts/security/pod-security-standards/)).
    The pod security restrictions are applied at the namespace level. All pods in
    the target namespace will be checked for the same security profile (**privileged**,
    **baseline**, or **restricted**).
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 安全准入控制是一个负责管理 Pod 安全标准的准入控制器（[https://kubernetes.io/docs/concepts/security/pod-security-standards/](https://kubernetes.io/docs/concepts/security/pod-security-standards/)）。Pod
    安全限制应用于命名空间级别。目标命名空间中的所有 Pod 都将根据相同的安全配置文件进行检查（**特权**、**基线**或**限制**）。
- en: Note that Pod Security Admission doesn’t set the relevant security contexts.
    It only validates that the pod conforms to the target policy.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Pod 安全准入控制不会设置相关的安全上下文。它仅验证 Pod 是否符合目标策略。
- en: 'There are three modes:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 有三种模式：
- en: '`enforce`: Policy violations will result in the rejection of the pod.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`enforce`：策略违反将导致 Pod 被拒绝。'
- en: '`audit`: Policy violations will result in the addition of an audit annotation
    to the event recorded in the audit log, but the pod will still be allowed.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`audit`：策略违反将导致在审计日志中记录的事件中添加审计注释，但 Pod 仍将被允许。'
- en: '`warn`: Policy violations will trigger a warning for the user, but the pod
    will still be allowed.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`warn`：策略违反将触发用户警告，但 Pod 仍将被允许。'
- en: 'To activate Pod Security Admission on a namespace you simply add a label to
    the target namespace:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 要在命名空间中启用 Pod 安全准入控制，你只需为目标命名空间添加一个标签：
- en: '[PRE24]'
  id: totrans-278
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Managing network policies
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理网络策略
- en: Node, pod, and container security are imperative, but it’s not enough. Network
    segmentation is critical to design secure Kubernetes clusters that allow multi-tenancy,
    as well as to minimize the impact of security breaches. Defense in depth mandates
    that you compartmentalize parts of the system that don’t need to talk to each
    other, while also carefully managing the direction, protocols, and ports of network
    traffic.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 节点、Pod 和容器的安全性至关重要，但这还不够。网络分段对于设计安全的 Kubernetes 集群至关重要，它不仅允许多租户的支持，还能最小化安全漏洞的影响。深度防御要求你将系统中不需要相互通信的部分进行隔离，同时仔细管理网络流量的方向、协议和端口。
- en: Network policies allow the fine-grained control and proper network segmentation
    of your cluster. At the core, a network policy is a set of firewall rules applied
    to a set of namespaces and pods selected by labels. This is very flexible because
    labels can define virtual network segments and be managed at the Kubernetes resource
    level.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 网络策略允许你对集群进行精细化控制和适当的网络分段。从核心上讲，网络策略是一组应用于通过标签选择的一组命名空间和 Pod 的防火墙规则。这非常灵活，因为标签可以定义虚拟网络段，并且可以在
    Kubernetes 资源级别进行管理。
- en: This is a huge improvement over trying to segment your network using traditional
    approaches like IP address ranges and subnet masks, where you often run out of
    IP addresses or allocate too many just in case.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 这相比于使用传统方法（如 IP 地址范围和子网掩码）来对网络进行分段是一项巨大的改进，后者常常导致 IP 地址用完或仅仅为了以防万一而分配过多的 IP
    地址。
- en: However, if you use a service mesh you may not need to use network policies
    since the service mesh can fulfill the same role. More on service meshes later,
    in *Chapter 14*, *Utilizing Service Meshes*.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如果你使用服务网格，你可能不需要使用网络策略，因为服务网格可以执行相同的角色。更多关于服务网格的内容，请参见*第14章*，*使用服务网格*。
- en: Choosing a supported networking solution
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 选择一个支持的网络解决方案
- en: 'Some networking backends (network plugins) don’t support network policies.
    For example, the popular Flannel can’t be used to apply policies. This is critical.
    You will be able to define network policies even if your network plugin doesn’t
    support them. Your policies will simply have no effect, giving you a false sense
    of security. Here is a list of network plugins that support network policies (both
    ingress and egress):'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 一些网络后端（网络插件）不支持网络策略。例如，流行的 Flannel 无法用来应用策略。这一点至关重要。即使你的网络插件不支持网络策略，你仍然可以定义网络策略。只是这些策略不会产生任何效果，从而给你一种错误的安全感。以下是支持网络策略（包括入站和出站）的一些网络插件列表：
- en: Calico
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calico
- en: WeaveNet
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: WeaveNet
- en: Canal
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Canal
- en: Cillium
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cillium
- en: Kube-Router
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kube-Router
- en: Romana
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Romana
- en: Contiv
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Contiv
- en: If you run your cluster on a managed Kubernetes service then the choice has
    already been made for you, although you can also install custom CNI plugins on
    some managed Kubernetes offerings.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在托管 Kubernetes 服务上运行你的集群，那么选择已经为你做出了，尽管在某些托管 Kubernetes 服务上你也可以安装自定义 CNI
    插件。
- en: We will explore the ins and outs of network plugins in *Chapter 10*, *Exploring
    Kubernetes Networking*. Here we focus on network policies.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在*第十章*，*探索 Kubernetes 网络* 中深入探讨网络插件的细节。在这里，我们重点关注网络策略。
- en: Defining a network policy
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定义网络策略
- en: You define a network policy using a standard YAML manifest. The supported protocols
    are TCP, UDP, and SCTP (since Kubernetes 1.20).
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用标准的 YAML 清单来定义网络策略。支持的协议包括 TCP、UDP 和 SCTP（自 Kubernetes 1.20 起）。
- en: 'Here is a sample policy:'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个示例策略：
- en: '[PRE25]'
  id: totrans-298
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The `spec` part has two important parts, the `podSelector` and the `ingress`.
    The `podSelector` governs which pods this network policy applies to. The `ingress`
    governs which namespaces and pods can access these pods and which protocols and
    ports they can use.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '`spec` 部分包含两个重要部分，`podSelector` 和 `ingress`。`podSelector` 决定该网络策略适用于哪些 pods，`ingress`
    决定哪些命名空间和 pods 可以访问这些 pods，以及它们可以使用哪些协议和端口。'
- en: 'In the preceding sample network policy, the pod selector specified the target
    for the network policy to be all the pods that are labeled `role: db`. The `ingress`
    section has a `from` sub-section with a namespace selector and a pod selector.
    All the namespaces in the cluster that are labeled `project: cool-project`, and
    within these namespaces, all the pods that are labeled `role: frontend`, can access
    the target pods labeled `role: db`. The `ports` section defines a list of pairs
    (protocol and port) that further restrict what protocols and ports are allowed.
    In this case, the protocol is `tcp` and the port is `6379` (the standard Redis
    port). If you want to target a range of ports, you can use `endPort`, as in:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '在前面的示例网络策略中，pod 选择器指定了网络策略的目标是所有标记为 `role: db` 的 pods。`ingress` 部分有一个 `from`
    子部分，包含命名空间选择器和 pod 选择器。集群中所有标记为 `project: cool-project` 的命名空间，以及这些命名空间中所有标记为 `role:
    frontend` 的 pods，都可以访问标记为 `role: db` 的目标 pods。`ports` 部分定义了一个协议和端口的配对列表，进一步限制了允许使用的协议和端口。在这种情况下，协议是
    `tcp`，端口是 `6379`（标准的 Redis 端口）。如果你想针对一系列端口，可以使用 `endPort`，如下所示：'
- en: '[PRE26]'
  id: totrans-301
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Note that the network policy is cluster-wide, so pods from multiple namespaces
    in the cluster can access the target namespace. The current namespace is always
    included, so even if it doesn’t have the `project:cool` label, pods with `role:frontend`
    can still have access.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，网络策略是集群范围的，因此集群中多个命名空间的 pods 可以访问目标命名空间。当前命名空间始终包括在内，即使它没有 `project:cool`
    标签，标记为 `role:frontend` 的 pods 仍然可以访问。
- en: It’s important to realize that the network policy operates in a whitelist fashion.
    By default, all access is forbidden, and the network policy can open certain protocols
    and ports to certain pods that match the labels. However, the whitelist nature
    of the network policy applies only to pods that are selected for at least one
    network policy. If a pod is not selected it will allow all access. Always make
    sure all your pods are covered by a network policy.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 重要的是要认识到，网络策略是以白名单方式操作的。默认情况下，所有访问都是禁止的，网络策略可以为匹配标签的某些 pods 打开特定的协议和端口。然而，网络策略的白名单特性仅适用于至少为一个网络策略所选中的
    pods。如果一个 pod 没有被选中，它将允许所有访问。始终确保你的所有 pods 都被网络策略覆盖。
- en: Another implication of the whitelist nature is that, if multiple network policies
    exist, then the unified effect of all the rules applies. If one policy gives access
    to port `1234` and another gives access to port `5678` for the same set of pods,
    then a pod may be accessed through either `1234` or `5678`.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 白名单特性带来的另一个影响是，如果存在多个网络策略，则所有规则的统一效果将一起生效。如果一个策略允许访问端口 `1234`，而另一个策略允许访问端口 `5678`，那么一个
    pod 可以通过 `1234` 或 `5678` 访问。
- en: 'To use network policies responsibly, consider starting with a `deny-all` network
    policy:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 为了负责任地使用网络策略，可以考虑从 `deny-all` 网络策略开始：
- en: '[PRE27]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Then, start adding network policies to allow ingress to specific pods explicitly.
    Note that you must apply the `deny-all` policy for each namespace:'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，开始添加网络策略，以明确允许某些 pods 访问。请注意，你必须为每个命名空间应用 `deny-all` 策略：
- en: '[PRE28]'
  id: totrans-308
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Limiting egress to external networks
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 限制出口流量到外部网络
- en: 'Kubernetes 1.8 added egress network policy support, so you can control outbound
    traffic too. Here is an example that prevents access to the external IP `1.2.3.4`.
    The `order: 999` ensures the policy is applied before other policies:'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 'Kubernetes 1.8 增加了出口网络策略的支持，因此你也可以控制出站流量。以下是一个示例，防止访问外部 IP `1.2.3.4`。`order:
    999` 确保在其他策略之前应用该策略：'
- en: '[PRE29]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Cross-namespace policies
  id: totrans-312
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 跨命名空间策略
- en: If you divide your cluster into multiple namespaces, it can come in handy sometimes
    if pods can communicate across namespaces. You can specify the `ingress.namespaceSelector`
    field in your network policy to enable access from multiple namespaces. This is
    useful, for example, if you have production and staging namespaces and you periodically
    populate your staging environments with snapshots of your production data.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将集群分为多个命名空间，当 Pod 需要跨命名空间通信时，这有时会派上用场。你可以在网络策略中指定 `ingress.namespaceSelector`
    字段，以启用来自多个命名空间的访问。例如，如果你有生产和预发布命名空间，并且定期将生产数据的快照填充到预发布环境中，这会非常有用。
- en: The costs of network policies
  id: totrans-314
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络策略的成本
- en: 'Network policies are not free. Your CNI plugin may install additional components
    in your cluster and on every node. These components use precious resources and
    in addition may cause your pods to get evicted due to insufficient capacity. For
    example, the Calico CNI plugin installs several deployments in the `kube-system`
    namespace:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 网络策略并非免费的。你的 CNI 插件可能会在集群中的每个节点上安装额外的组件。这些组件使用宝贵的资源，并且可能会导致你的 Pod 因容量不足而被驱逐。例如，Calico
    CNI 插件会在`kube-system`命名空间中安装多个部署：
- en: '[PRE30]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'It also provisions a DaemonSet that runs a pod on every node:'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 它还会配置一个 DaemonSet，在每个节点上运行一个 Pod：
- en: '[PRE31]'
  id: totrans-318
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Using secrets
  id: totrans-319
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用机密
- en: Secrets are paramount in secure systems. They can be credentials such as usernames
    and passwords, access tokens, API keys, certificates, or crypto keys. Secrets
    are typically small. If you have large amounts of data you want to protect, you
    should encrypt it and keep the encryption/decryption keys as secrets.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 在安全系统中，机密至关重要。它们可以是凭证，如用户名和密码、访问令牌、API 密钥、证书或加密密钥。机密通常很小。如果你有大量的数据需要保护，你应该加密它，并将加密/解密密钥作为机密保存。
- en: Storing secrets in Kubernetes
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中存储机密
- en: Kubernetes used to store secrets in etcd as plaintext by default. This means
    that direct access to etcd should be limited and carefully guarded. Starting with
    Kubernetes 1.7, you can now encrypt your secrets at rest (when they’re stored
    by etcd).
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 默认会将机密以明文存储在 etcd 中。这意味着应当限制直接访问 etcd，并加以谨慎保护。从 Kubernetes 1.7 开始，你现在可以在静态存储时加密你的机密（当它们被
    etcd 存储时）。
- en: Secrets are managed at the namespace level. Pods can mount secrets either as
    files via secret volumes or as environment variables. From a security standpoint,
    this means that any user or service that can create a pod in a namespace can have
    access to any secret managed for that namespace. If you want to limit access to
    a secret, put it in a namespace accessible to a limited set of users or services.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 机密是在命名空间级别进行管理的。Pod 可以通过机密卷作为文件或作为环境变量挂载机密。从安全角度来看，这意味着任何可以在命名空间中创建 Pod 的用户或服务，都可以访问该命名空间中管理的任何机密。如果你想限制对某个机密的访问，可以将其放在一个只有有限用户或服务可以访问的命名空间中。
- en: When a secret is mounted into a container, it is never written to disk. It is
    stored in `tmpfs`. When the kubelet communicates with the API server, it normally
    uses TLS, so the secret is protected in transit.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 当机密挂载到容器中时，它从不写入磁盘。它存储在 `tmpfs` 中。当 kubelet 与 API 服务器通信时，通常使用 TLS，因此机密在传输过程中受到保护。
- en: Kubernetes secrets are limited to 1 MB.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的机密限制为 1 MB。
- en: Configuring encryption at rest
  id: totrans-326
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置静态加密
- en: 'You need to pass this argument when you start the API server: `--encryption-provider-config`.'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 启动 API 服务器时，需要传递此参数：`--encryption-provider-config`。
- en: 'Here is a sample encryption config:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个示例加密配置：
- en: '[PRE32]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Creating secrets
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建机密
- en: Secrets must be created before you try to create a pod that requires them. The
    secret must exist; otherwise, the pod creation will fail.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在尝试创建需要机密的 Pod 之前，必须先创建机密。机密必须存在，否则 Pod 创建将失败。
- en: 'You can create secrets with the following command: `kubectl create secret`.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用以下命令创建机密：`kubectl create secret`。
- en: 'Here I create a generic secret called `hush-hush`, which contains two keys,
    a username and password:'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我创建了一个名为`hush-hush`的通用机密，其中包含两个键，一个用户名和一个密码：
- en: '[PRE33]'
  id: totrans-334
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'The resulting secret is opaque:'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的机密是不可见的：
- en: '[PRE34]'
  id: totrans-336
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: You can create secrets from files using `--from-file` instead `--from-literal`,
    and you can also create secrets manually if you encode the secret value as base64.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `--from-file` 而不是 `--from-literal` 从文件创建机密，如果你将机密值编码为 base64，还可以手动创建机密。
- en: Key names inside a secret must follow the rules for DNS sub-domains (without
    the leading dot).
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 机密中的键名必须遵循 DNS 子域的规则（没有前导点）。
- en: Decoding secrets
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 解码机密
- en: 'To get the content of a secret you can use `kubectl get secret`:'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取机密的内容，可以使用 `kubectl get secret`：
- en: '[PRE35]'
  id: totrans-341
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The values are base64-encoded. You need to decode them yourself:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 这些值是 base64 编码的。你需要自行解码：
- en: '[PRE36]'
  id: totrans-343
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: Using secrets in a container
  id: totrans-344
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在容器中使用秘密
- en: Containers can access secrets as files by mounting volumes from the pod. Another
    approach is to access the secrets as environment variables. Finally, a container
    (given that its service account has the permission) can access the Kubernetes
    API directly or use `kubectl get secret`.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 容器可以通过挂载来自 Pod 的卷以文件的形式访问秘密。另一种方法是将秘密作为环境变量访问。最后，如果容器（假设其服务帐户有权限）可以直接访问 Kubernetes
    API 或使用 `kubectl get secret`。
- en: 'To use a secret mounted as a volume, the pod manifest should declare the volume
    and it should be mounted in the container’s spec:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用作为卷挂载的秘密，Pod 清单应声明该卷，并且应在容器的规范中挂载它：
- en: '[PRE37]'
  id: totrans-347
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The volume name (secret-volume) binds the pod volume to the mount in the container.
    Multiple containers can mount the same volume. When this pod is running, the username
    and password are available as files under `/etc/hush-hush`:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 卷名（secret-volume）将 Pod 卷绑定到容器中的挂载点。多个容器可以挂载相同的卷。当此 Pod 正在运行时，用户名和密码作为文件保存在 `/etc/hush-hush`
    目录下：
- en: '[PRE38]'
  id: totrans-349
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Managing secrets with Vault
  id: totrans-350
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Vault 管理秘密
- en: Kubernetes secrets are a good foundation for storing and managing sensitive
    data on Kubernetes. However, storing encrypted data in etcd is just the tip of
    the iceberg of an industrial-strength secret management solution. This is where
    Vault comes in.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes secrets 是存储和管理 Kubernetes 上敏感数据的良好基础。然而，将加密数据存储在 etcd 中只是工业级秘密管理解决方案的冰山一角。这就是
    Vault 发挥作用的地方。
- en: Vault is an identity-based source secret management system developed by HashiCorp
    since 2015\. Vault is considered best in class and doesn’t really have any significant
    non-proprietary competitors. It exposes an HTTP API, CLI, and UI to manage your
    secrets. Vault is a mature and battle-tested solution that is being used by a
    large number of enterprise organizations as well as smaller companies. Vault has
    well-defined security and threat models that cover a lot of ground. Practically,
    as long as you can ensure the physical security of your Vault deployment, Vault
    will keep your secrets safe and make it easy to manage and audit them.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: Vault 是一个基于身份的源秘密管理系统，由 HashiCorp 自 2015 年以来开发。Vault 被认为是业内最好的，并且几乎没有什么非专有的竞争对手。它提供了一个
    HTTP API、CLI 和 UI 来管理你的秘密。Vault 是一个成熟且经过实战检验的解决方案，已被大量企业组织和较小的公司所使用。Vault 拥有良好的安全性和威胁模型，覆盖了大量的内容。从实际操作角度看，只要你能确保
    Vault 部署的物理安全性，Vault 就能保持你的秘密安全，并使其易于管理和审计。
- en: 'When running Vault on Kubernetes there are several other important measures
    to ensure the Vault security model remains intact such as:'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上运行 Vault 时，还需要采取一些其他重要措施，以确保 Vault 安全模型保持完整，例如：
- en: Considerations for multi-tenant clusters (single Vault will be shared by all
    tenants)
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多租户集群的注意事项（单一 Vault 将被所有租户共享）
- en: End-to-end TLS (Kubernetes may skip TLS under some conditions)
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 端到端 TLS（在某些情况下 Kubernetes 可能跳过 TLS）
- en: Turn off process core dumps to avoid revealing Vault encryption keys
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关闭进程核心转储以避免泄露 Vault 加密密钥
- en: Ensure mlock is enabled to avoid swapping memory to disk and revealing Vault
    encryption keys
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保启用 mlock 以避免将内存交换到磁盘并泄露 Vault 加密密钥
- en: Container supervisor and pods should run as non-root
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 容器主管和 Pod 应以非 root 用户身份运行
- en: 'You can find a lot of information about Vault here: [https://www.vaultproject.io/](https://www.vaultproject.io/).'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这里找到关于 Vault 的大量信息：[https://www.vaultproject.io/](https://www.vaultproject.io/)。
- en: 'Deploying and configuring Vault is pretty straightforward. If you want to try
    it out, follow this tutorial: [https://learn.hashicorp.com/tutorials/vault/kubernetes-minikube-raft](https://learn.hashicorp.com/tutorials/vault/kubernetes-minikube-raft).'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: Vault 的部署和配置非常简单。如果你想尝试，跟着这个教程来做：[https://learn.hashicorp.com/tutorials/vault/kubernetes-minikube-raft](https://learn.hashicorp.com/tutorials/vault/kubernetes-minikube-raft)。
- en: Running a multi-tenant cluster
  id: totrans-361
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行多租户集群
- en: In this section, we will look briefly at the option to use a single cluster
    to host systems for multiple users or multiple user communities (which is also
    known as multi-tenancy). The idea is that those users are totally isolated and
    may not even be aware that they share the cluster with other users.
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将简要地看一下使用单个集群托管多个用户或多个用户社区的系统的选项（这也被称为多租户）。其理念是，这些用户是完全隔离的，甚至可能不知道他们与其他用户共享同一个集群。
- en: Each user community will have its own resources, and there will be no communication
    between them (except maybe through public endpoints). The Kubernetes namespace
    concept is the ultimate expression of this idea. But, they don’t provide absolute
    isolation. Another solution is to use virtual clusters where each namespace appears
    as a completely independent cluster to the users.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 每个用户社区将拥有自己的资源，并且它们之间不会有任何通信（除了可能通过公共端点）。Kubernetes命名空间的概念是这一理念的最终体现。但它们并不提供绝对的隔离。另一种解决方案是使用虚拟集群，其中每个命名空间对用户来说看起来像是一个完全独立的集群。
- en: Check out [https://www.vcluster.com/](https://www.vcluster.com/) for more details
    about virtual clusters.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 查看[https://www.vcluster.com/](https://www.vcluster.com/)了解有关虚拟集群的更多详细信息。
- en: The case for multi-tenant clusters
  id: totrans-365
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多租户集群的案例
- en: 'Why should you run a single cluster for multiple isolated users or deployments?
    Isn’t it simpler to just have a dedicated cluster for each user? There are two
    main reasons: cost and operational complexity. If you have many relatively small
    deployments and you want to create a dedicated cluster for each one, then you’ll
    have a separate control plane node and possibly a three-node etcd cluster for
    each one. The cost can add up. Operational complexity is very important too. Managing
    tens, hundreds, or thousands of independent clusters is no picnic. Every upgrade
    and every patch needs to be applied to each cluster. Operations might fail and
    you’ll have to manage a fleet of clusters where some of them are in a slightly
    different state than the others. Meta-operations across all clusters may be more
    difficult. You’ll have to aggregate and write your tools to perform operations
    and collect data from all clusters.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 为什么要为多个隔离的用户或部署运行一个集群？直接为每个用户创建一个专用集群不是更简单吗？主要有两个原因：成本和操作复杂性。如果你有许多相对较小的部署，并且想为每个部署创建一个专用集群，那么你将为每个集群配置一个独立的控制平面节点，可能还会有一个三节点的etcd集群。成本会逐渐增加。操作复杂性也非常重要。管理数十个、数百个甚至数千个独立集群绝非易事。每次升级和每个补丁都需要应用到每个集群。操作可能会失败，而你还得管理一个集群舰队，其中一些集群可能处于与其他集群略有不同的状态。跨所有集群的元操作可能更为困难。你需要汇总并编写工具来执行操作并收集所有集群的数据。
- en: 'Let’s look at some use cases and requirements for multiple isolated communities
    or deployments:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看一些多租户隔离社区或部署的使用案例和需求：
- en: A platform or service provider for software-as-a-service
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个为软件即服务提供平台或服务的提供商
- en: Managing separate testing, staging, and production environments
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理独立的测试、预发布和生产环境
- en: Delegating responsibility to community/deployment admins
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将责任委派给社区/部署管理员
- en: Enforcing resource quotas and limits on each community
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 强制对每个社区施行资源配额和限制
- en: Users see only resources in their community
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户只会看到他们社区中的资源
- en: Using namespaces for safe multi-tenancy
  id: totrans-373
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用命名空间实现安全的多租户
- en: Kubernetes namespaces are a good start for safe multi-tenant clusters. This
    is not a surprise, as this was one of the design goals of namespaces.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes命名空间是安全的多租户集群的良好起点。这并不令人惊讶，因为命名空间的设计目标之一就是如此。
- en: 'You can easily create namespaces in addition to the built-in `kube-system`
    and default. Here is a YAML file that will create a new namespace called `custom-namespace`.
    All it has is a metadata item called name. It doesn’t get any simpler:'
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 除了内置的`kube-system`和default命名空间外，你可以轻松创建新的命名空间。以下是一个YAML文件，将创建一个名为`custom-namespace`的新命名空间。它只有一个名为name的元数据项。没有比这更简单的了：
- en: '[PRE39]'
  id: totrans-376
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Let’s create the namespace:'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建命名空间：
- en: '[PRE40]'
  id: totrans-378
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We can see the default namespace, our new `custom-namespace`, and a few other
    system namespaces prefixed with `kube-`.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到默认命名空间、我们的新`custom-namespace`，以及其他几个以`kube-`为前缀的系统命名空间。
- en: The status field can be `Active` or `Terminating`. When you delete a namespace,
    it will move into the `Terminating` state. When the namespace is in this state,
    you will not be able to create new resources in this namespace. This simplifies
    the clean-up of namespace resources and ensures the namespace is really deleted.
    Without it, the replication controllers might create new pods when existing pods
    are deleted.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 状态字段可以是`Active`或`Terminating`。当你删除一个命名空间时，它将进入`Terminating`状态。当命名空间处于该状态时，你将无法在该命名空间中创建新资源。这简化了命名空间资源的清理，并确保命名空间被真正删除。如果没有这一点，复制控制器在现有Pod被删除时可能会创建新的Pod。
- en: Sometimes, namespaces may hang during termination. I wrote a little Go tool
    called k8s-namespace-deleter to delete stubborn namespaces.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 有时，命名空间可能会在终止时挂起。我写了一个名为k8s-namespace-deleter的小Go工具来删除顽固的命名空间。
- en: 'Check it out here: [https://github.com/the-gigi/k8s-namespace-deleter](https://github.com/the-gigi/k8s-namespace-deleter)'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: It can also be used as kubectl plugin.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: 'To work with a namespace, you add the `--namespace` (or `-n` for short) argument
    to kubectl commands. Here is how to run a pod in interactive mode in the `custom-namespace`
    namespace:'
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-385
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Listing pods in the `custom-namespace` returns only the pod we just launched:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: Avoiding namespace pitfalls
  id: totrans-388
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Namespaces are great, but they can add some friction. When you use just the
    default namespace, you can simply omit the namespace. When using multiple namespaces,
    you must qualify everything with the namespace. This can add some burden but doesn’t
    present any danger.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: However, if some users (for example, cluster administrators) can access multiple
    namespaces, then you’re open to accidentally modifying or querying the wrong namespace.
    The best way to avoid this situation is to hermetically seal the namespace and
    require different users and credentials for each namespace, just like you should
    use a user account for most operations on your machine or remote machines and
    use root via sudo only when you have to.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: In addition, you should use tools that help make it clear what namespace you’re
    operating on (for example, shell prompt if working from the command line or listing
    the namespace prominently in a web interface). One of the most popular tools is
    kubens (available along with kubectx), available at [https://github.com/ahmetb/kubectx](https://github.com/ahmetb/kubectx).
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that users that can operate on a dedicated namespace don’t have access
    to the default namespace. Otherwise, every time they forget to specify a namespace,
    they’ll operate quietly on the default namespace.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: Using virtual clusters for strong multi-tenancy
  id: totrans-393
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Namespaces are fine, but they don’t really cut it for strong multi-tenancy.
    Namespace isolation obviously works for namespaced resources only. But, Kubernetes
    has many cluster-level resources (in particular CRDs). Tenants will share those.
    In addition, the control plane version, security, and audit will be shared.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: One trivial solution is not to use multi-tenancy. Just have a separate cluster
    for each tenant. But, that is not efficient especially if you have a lot of small
    tenants.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: The vcluster project ([https://www.vcluster.com](https://www.vcluster.com))
    from Loft.sh utilizes an innovative approach where a physical Kubernetes cluster
    can host multiple virtual clusters that appear as regular Kubernetes clusters
    to their users, totally isolated from the other virtual clusters and the host
    cluster. This reaps all benefits of multi-tenancy without the downsides of namespace-level
    isolation.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the vcluster architecture:'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: '![Timeline  Description automatically generated](img/B18998_04_03.png)'
  id: totrans-398
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.3: vcluster architecture'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a couple of virtual clusters. First install the vcluster CLI:
    [https://www.vcluster.com/docs/getting-started/setup](https://www.vcluster.com/docs/getting-started/setup).'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建几个虚拟集群。首先安装vcluster CLI：[https://www.vcluster.com/docs/getting-started/setup](https://www.vcluster.com/docs/getting-started/setup)。
- en: 'Make sure it’s installed correctly:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 确保它已正确安装：
- en: '[PRE43]'
  id: totrans-402
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: Now, we can create some virtual clusters. You can create virtual clusters using
    the vcluster CLI, Helm, or kubectl. Let’s go with the vcluster CLI.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以创建一些虚拟集群。你可以使用vcluster CLI、Helm或kubectl创建虚拟集群。我们选择vcluster CLI。
- en: '[PRE44]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Let’s create another virtual cluster:'
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建另一个虚拟集群：
- en: '[PRE45]'
  id: totrans-406
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'Oops. After creating the `tenant-1` virtual cluster the Kubernetes context
    changed to this cluster. When I tried to create `tenant-2`, the vcluster CLI was
    smart enough to warn me. Let’s try again:'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 哎呀。在创建`tenant-1`虚拟集群后，Kubernetes上下文切换到了这个集群。当我尝试创建`tenant-2`时，vcluster CLI足够聪明地提醒了我。让我们再试一次：
- en: '[PRE46]'
  id: totrans-408
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Let’s check our clusters:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下我们的集群：
- en: '[PRE47]'
  id: totrans-410
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Yes, our two virtual clusters are available. Let’s see the namespaces in our
    host `kind` cluster:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 是的，我们的两个虚拟集群已经可以使用。让我们看看主机`kind`集群中的命名空间：
- en: '[PRE48]'
  id: totrans-412
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'We can see the two new namespaces for the virtual clusters. Let’s see what’s
    running in the `vcluster-tenant-1` namespace:'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到虚拟集群的两个新命名空间。让我们看看`vcluster-tenant-1`命名空间中运行了什么：
- en: '[PRE49]'
  id: totrans-414
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Now, let’s see what namespaces are in the virtual cluster:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看虚拟集群中有哪些命名空间：
- en: '[PRE50]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Just the default namespaces of a k3s cluster (vcluster is based on k3s). Let’s
    create a new namespace and verify it shows up only in the virtual cluster:'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 只是k3s集群的默认命名空间（vcluster基于k3s）。让我们创建一个新的命名空间并验证它是否仅出现在虚拟集群中：
- en: '[PRE51]'
  id: totrans-418
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: The new namespace is only visible in the virtual cluster it was created in as
    expected.
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 新的命名空间只在它创建的虚拟集群中可见，正如预期的那样。
- en: In this section, we covered multi-tenant clusters, why they are useful, and
    different approaches for isolating tenants such as namespaces and virtual clusters.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了多租户集群，它们的用途，以及不同的租户隔离方法，如命名空间和虚拟集群。
- en: Summary
  id: totrans-421
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we covered the many security challenges facing developers and
    administrators building systems and deploying applications on Kubernetes clusters.
    But we also explored the many security features and the flexible plugin-based
    security model that provides many ways to limit, control, and manage containers,
    pods, and nodes. Kubernetes already provides versatile solutions to most security
    challenges, and it will only get better as capabilities such as AppArmor and various
    plugins move from alpha/beta status to general availability. Finally, we considered
    how to use namespaces and virtual clusters to support multi-tenant communities
    or deployments in the same Kubernetes cluster.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了开发人员和管理员在构建系统和部署应用程序时面临的众多安全挑战。我们还探讨了许多安全特性和灵活的基于插件的安全模型，它提供了多种限制、控制和管理容器、Pod和节点的方法。Kubernetes已经提供了针对大多数安全挑战的多种解决方案，随着AppArmor和各种插件从alpha/beta版本过渡到正式发布，这些解决方案将会变得更好。最后，我们考虑了如何使用命名空间和虚拟集群来支持在同一个Kubernetes集群中进行多租户社区或部署。
- en: In the next chapter, we will look in detail into many Kubernetes resources and
    concepts and how to use them and combine them effectively. The Kubernetes object
    model is built on top of a solid foundation of a small number of generic concepts
    such as resources, manifests, and metadata. This empowers an extensible, yet surprisingly
    consistent, object model to expose a very diverse set of capabilities for developers
    and administrators.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将详细研究许多Kubernetes资源和概念，以及如何有效地使用和组合它们。Kubernetes对象模型建立在少数通用概念（如资源、清单和元数据）坚实的基础之上。这使得Kubernetes具备了一个可扩展而又出奇一致的对象模型，能够为开发者和管理员提供一系列多样化的能力。
- en: Join us on Discord!
  id: totrans-424
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们的Discord！
- en: Read this book alongside other users, cloud experts, authors, and like-minded
    professionals.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他用户、云计算专家、作者以及志同道合的专业人士一起阅读本书。
- en: Ask questions, provide solutions to other readers, chat with the authors via.
    Ask Me Anything sessions and much more.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 提问、为其他读者提供解决方案、通过“问我任何问题”环节与作者交流等等。
- en: Scan the QR code or visit the link to join the community now.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 扫描二维码或访问链接立即加入社区。
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
- en: '![](img/QR_Code844810820358034203.png)'
  id: totrans-429
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code844810820358034203.png)'
