- en: '12'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '12'
- en: Observability – Getting Visibility into GenAI on K8s
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可观察性 – 获取 GenAI 在 K8s 上的可见性
- en: In this chapter, we will cover key observability concepts for monitoring GenAI
    applications in **Kubernetes** (**K8s**). We’ll dive into why monitoring is critical
    for optimizing GenAI workloads, examining both system-level metrics and application-specific
    signals. By integrating tools such as **Prometheus** for metrics collection and
    **Grafana** for visualization, and leveraging the debugging capabilities of **LangChain**,
    you’ll learn how to construct a comprehensive monitoring framework that provides
    real-time and actionable insights.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖监控 GenAI 应用程序在 **Kubernetes**（**K8s**）中的关键可观察性概念。我们将深入探讨为什么监控对优化 GenAI
    工作负载至关重要，分析系统级指标和特定应用信号。通过集成 **Prometheus** 进行指标收集，使用 **Grafana** 进行可视化，并利用 **LangChain**
    的调试功能，你将学习如何构建一个全面的监控框架，提供实时和可操作的洞察。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: Observability key concepts
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可观察性关键概念
- en: Monitoring tools in K8s
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: K8s 中的监控工具
- en: Visualization and debugging
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可视化和调试
- en: Observability key concepts
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可观察性关键概念
- en: '**Observability** is the foundational framework for identifying, investigating,
    and remediating issues in a system, as shown in *Figure 12**.1*. It provides a
    holistic view of system behavior and performance. Observability is built on three
    core pillars: **logs**, **metrics**, and **traces**. Logs capture detailed event
    information, metrics quantify system performance, and traces provide an end-to-end
    view of request flows. Together, these components enable efficient monitoring
    and troubleshooting of complex distributed systems. This integration ensures actionable
    insights for maintaining system reliability and performance.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**可观察性** 是用于识别、调查和修复系统问题的基础框架，如 *图 12.1* 所示。它提供了系统行为和性能的整体视图。可观察性建立在三个核心支柱上：**日志**、**指标**
    和 **追踪**。日志捕捉详细的事件信息，指标量化系统性能，追踪提供请求流程的端到端视图。这些组件共同作用，实现了对复杂分布式系统的高效监控和故障排除。这一整合确保了对维护系统可靠性和性能的可操作性洞察。'
- en: '![Figure 12.1 – Observability framework](img/B31108_12_01.jpg)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.1 – 可观察性框架](img/B31108_12_01.jpg)'
- en: Figure 12.1 – Observability framework
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.1 – 可观察性框架
- en: Logs
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 日志
- en: '**System logs** cover events such as transactions, system errors, and user
    actions. K8s generates logs at different layers, such as container logs, node
    logs, and cluster-level logs. You can use the following command to see logs for
    a Pod:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**系统日志** 包括诸如事务、系统错误和用户操作等事件。K8s 在不同层级生成日志，如容器日志、节点日志和集群级别日志。你可以使用以下命令查看 Pod
    的日志：'
- en: '[PRE0]'
  id: totrans-13
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If the Pod has multiple containers, a specific container log can be observed
    with the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 Pod 中有多个容器，可以使用以下命令观察特定容器的日志：
- en: '[PRE1]'
  id: totrans-15
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: By default, logs in K8s are ephemeral and are lost when Pods restart. To persist
    logs, one can use sidecar containers or logging agents that forward logs to a
    centralized storage backend such as **Amazon CloudWatch Logs**, **Elasticsearch**,
    or **Loki**.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，K8s 中的日志是临时的，Pod 重启时会丢失。为了持久化日志，可以使用 sidecar 容器或将日志转发到集中存储后端（如 **Amazon
    CloudWatch Logs**、**Elasticsearch** 或 **Loki**）的日志代理。
- en: K8s does not provide cluster-wide logging by default. To implement logging at
    the cluster level, one can use solutions such as Loki or managed services such
    as **Datadog**, **Splunk**, **Amazon CloudWatch**, and **New Relic**.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: K8s 默认不提供集群级别的日志记录。为了实现集群级日志记录，可以使用 Loki 等解决方案，或者使用 **Datadog**、**Splunk**、**Amazon
    CloudWatch** 和 **New Relic** 等托管服务。
- en: Standard logs provide great insights into pod-level events and errors; however,
    they don’t cover a complete trace of an API response. That’s where K8s audit logs
    come in, offering a more granular view of API interactions for security and compliance
    purposes. We will cover K8s audit logs in the next section.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 标准日志能提供关于 Pod 级事件和错误的宝贵信息；然而，它们无法涵盖 API 响应的完整跟踪。这时，K8s 审计日志就派上用场了，它提供了更详细的 API
    交互视图，主要用于安全性和合规性目的。我们将在下一节中讨论 K8s 审计日志。
- en: K8s audit logs
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: K8s 审计日志
- en: K8s provides *audit log capabilities* to track all API requests made to the
    K8s API server. This provides a detailed record of actions performed by users,
    service accounts, and controllers and can help with security, compliance, and
    troubleshooting.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: K8s 提供 *审计日志功能*，跟踪所有对 K8s API 服务器的 API 请求。这提供了一个详细的记录，记录了用户、服务账户和控制器执行的操作，帮助进行安全性、合规性和故障排除。
- en: 'To enable audit logs, modify the K8s API server configuration by adding the
    following:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 要启用审计日志，请通过添加以下内容修改 K8s API 服务器配置：
- en: '[PRE2]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following YAML shows a sample audit policy that will log the request metadata
    without the request body:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下YAML示例展示了一个审计策略，它将在不记录请求正文的情况下记录请求元数据：
- en: '[PRE3]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: In managed K8s offerings such as Amazon EKS, control plane audit logs can be
    configured to stream to Amazon CloudWatch Logs. Refer to the EKS documentation
    at [https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html](https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html)
    for instructions on how to set up the audit logs.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在托管的K8s服务中，如Amazon EKS，控制平面审计日志可以配置为流式传输到Amazon CloudWatch日志。有关如何设置审计日志的说明，请参考[EKS文档](https://docs.aws.amazon.com/eks/latest/userguide/control-plane-logs.html)。
- en: While logs provide a detailed view of discrete events, such as errors, system
    activity, and user actions, metrics offer a complementary perspective by capturing
    continuous performance data over time. In the next section, we shift our focus
    from event-based insights to performance monitoring using metrics.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然日志提供了有关离散事件（如错误、系统活动和用户操作）的详细视图，但指标通过捕捉随时间变化的持续性能数据，提供了互补的视角。在下一节中，我们将焦点从基于事件的洞察转向使用指标进行性能监控。
- en: Metrics
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 指标
- en: Metrics involve *time-series data* that tracks system performance indicators
    such as memory usage and latency. In K8s, metrics provide real-time performance
    data about the cluster, nodes, Pods, and containers. These metrics help with monitoring,
    scaling, and troubleshooting workloads running inside a K8s cluster.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 指标涉及*时间序列数据*，用于跟踪系统性能指标，如内存使用情况和延迟。在K8s中，指标提供有关集群、节点、Pod和容器的实时性能数据。这些指标有助于监控、扩展和故障排除在K8s集群中运行的工作负载。
- en: 'Metrics in K8s are collected at different layers:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: K8s中的指标在不同层级进行收集：
- en: '**Node metrics**, such as CPU, memory, disk, and network usage at the node
    level'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**节点指标**，例如节点级别的CPU、内存、磁盘和网络使用情况'
- en: '**Pod and container metrics**, such as resource consumption of each Pod and
    container'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pod和容器指标**，例如每个Pod和容器的资源消耗'
- en: '**Cluster-level metrics**, such as the overall health and performance of the
    cluster'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**集群级指标**，例如集群的整体健康状况和性能'
- en: '**Application-level metrics**, which are custom application metrics such as
    request latency and error rates'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**应用层指标**，例如请求延迟和错误率等自定义应用程序指标'
- en: In [*Chapter 6*](B31108_06.xhtml#_idTextAnchor075), we covered the key metrics
    that are critical for application scaling and end user experiences. We covered
    both conventional metrics, such as CPU and memory usage, and custom metrics, such
    as queue length and HTTP request rates. Prometheus is a common way of collecting
    metrics in the K8s environment; we will discuss this in a later section.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第6章*](B31108_06.xhtml#_idTextAnchor075)中，我们讨论了对于应用程序扩展和最终用户体验至关重要的关键指标。我们涵盖了传统指标，如CPU和内存使用情况，也涉及了自定义指标，如队列长度和HTTP请求率。Prometheus是K8s环境中常用的收集指标的方式，我们将在后面的部分讨论这一点。
- en: Traces
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 跟踪
- en: Traces provide a visual representation of how a single request flows through
    a distributed system, tracking its interactions with various services, APIs, databases,
    and components. Tracing in K8s helps track requests as they propagate through
    different services, containers, and nodes within a distributed system. Traces
    provide end-to-end visibility into the lifecycle of a request, allowing developers
    and operators to understand latency issues, failures, and dependencies in microservices
    architectures.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 跟踪提供了一个视觉化表示，展示了单个请求如何在分布式系统中流动，跟踪其与各种服务、API、数据库和组件的交互。在K8s中，跟踪有助于跟踪请求如何在不同的服务、容器和节点之间传播。跟踪提供了对请求生命周期的端到端可视化，使开发人员和运维人员能够理解微服务架构中的延迟问题、故障和依赖关系。
- en: In K8s, tracing is crucial because applications often consist of multiple microservices
    communicating over the network. Unlike logs and metrics, which provide snapshots
    of system behavior, tracing provides contextual insights into request flows.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在K8s中，跟踪至关重要，因为应用程序通常由多个微服务组成，这些微服务通过网络进行通信。与日志和指标不同，日志和指标提供的是系统行为的快照，而跟踪则提供了关于请求流的上下文洞察。
- en: '**OpenTelemetry** (**OTel**) ([https://opentelemetry.io/](https://opentelemetry.io/))
    is a common framework used for collecting traces. Once collected, OTel can export
    the traces to **Zipkin** ([https://zipkin.io/](https://zipkin.io/)), **Jaeger**
    ([https://www.jaegertracing.io/](https://www.jaegertracing.io/)), and **AWS X-Ray**
    ([https://aws.amazon.com/xray/](https://aws.amazon.com/xray/)). We will cover
    OTel in detail in later sections.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**OpenTelemetry**（**OTel**）([https://opentelemetry.io/](https://opentelemetry.io/))是一个常用的框架，用于收集追踪。一旦收集，OTel可以将追踪数据导出到**Zipkin**([https://zipkin.io/](https://zipkin.io/))、**Jaeger**([https://www.jaegertracing.io/](https://www.jaegertracing.io/))和**AWS
    X-Ray**([https://aws.amazon.com/xray/](https://aws.amazon.com/xray/))。我们将在后续章节中详细介绍OTel。'
- en: In this section, we explored the fundamentals of observability in K8s and the
    three core pillars – logs, metrics, and traces. In the next section, we will explore
    various tools in the K8s landscape to monitor GenAI workloads.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们探讨了K8s中可观测性的基础知识以及三个核心支柱——日志、指标和追踪。在下一节中，我们将探讨K8s环境中用于监控GenAI工作负载的各种工具。
- en: Monitoring tools in K8s
  id: totrans-40
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: K8s中的监控工具
- en: Achieving true observability in K8s requires a holistic approach that integrates
    logs, metrics, and traces. Each pillar offers unique strengths and is suited for
    specific use cases. By adopting the best practices for combining logs, metrics,
    and traces, one can optimize monitoring strategies and achieve better system reliability
    and resilience, ultimately enhancing the user experience.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 在K8s中实现真正的可观测性需要一种整体的方法，集成日志、指标和追踪。每个支柱都有其独特的优势，适用于特定的使用场景。通过采用最佳实践来结合日志、指标和追踪，可以优化监控策略，提高系统的可靠性和弹性，最终增强用户体验。
- en: 'The following is a sample stack for observability, as depicted in *Figure 12**.2*:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是可观测性的示例堆栈，如*图12.2*所示：
- en: '**Fluentd and Fluent Bit** collect logs from Kubernetes nodes, Pods, and applications
    and forwards them to Amazon CloudWatch/Loki/OpenSearch for storage.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Fluentd和Fluent Bit**收集来自Kubernetes节点、Pods和应用程序的日志，并将其转发到Amazon CloudWatch/Loki/OpenSearch进行存储。'
- en: '**OTel** collects traces and application-specific metrics, exporting them to
    Prometheus (for metrics) and Jaeger/AWS X-Ray/Zipkin (for traces).'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**OTel**收集追踪和特定应用程序的指标，并将其导出到Prometheus（用于指标）和Jaeger/AWS X-Ray/Zipkin（用于追踪）。'
- en: '**Grafana** provides a single interface to visualize logs (from Loki), metrics
    (from Prometheus), and traces (from AWS X-Ray). Developers and operators use Grafana
    dashboards to analyze performance, debug issues, and set up alerts based on logs,
    metrics, and traces.'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Grafana**提供了一个单一的界面，用于可视化日志（来自Loki）、指标（来自Prometheus）和追踪（来自AWS X-Ray）。开发人员和运维人员使用Grafana仪表板来分析性能、调试问题，并根据日志、指标和追踪设置告警。'
- en: '![Figure 12.2 – Observability stack in K8s](img/B31108_12_02.jpg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图12.2 – K8s中的可观测性堆栈](img/B31108_12_02.jpg)'
- en: Figure 12.2 – Observability stack in K8s
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图12.2 – K8s中的可观测性堆栈
- en: We will discuss each of these tools in the following sections.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在接下来的章节中讨论这些工具。
- en: Fluentd and Fluent Bit
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Fluentd和Fluent Bit
- en: '`/var/log/containers`, K8s API server events, and system logs. It then parses,
    filters, and routes these logs to destinations such as Elasticsearch, Loki, Splunk,
    Amazon S3, and cloud-based logging solutions such as Amazon CloudWatch.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '`/var/log/containers`、K8s API服务器事件和系统日志。然后，它会解析、过滤并将这些日志路由到Elasticsearch、Loki、Splunk、Amazon
    S3和云端日志解决方案（如Amazon CloudWatch）等目的地。'
- en: Fluentd is highly configurable through a plugin-based architecture. There are
    100+ plugins available to support different log formats and backends ([https://www.fluentd.org/plugins](https://www.fluentd.org/plugins)).
    It uses a structured logging approach, allowing logs to be processed in JSON format
    for better searchability and indexing. Fluentd supports log enrichment by attaching
    K8s metadata, such as the namespace or Pod/container name, before sending logs
    to a storage system. It also supports log filtering, buffering, and compression,
    which helps in optimizing resource usage in large-scale K8s environments. In K8s
    logging pipelines, Fluentd is often used alongside Loki (for efficient log storage)
    or Elasticsearch (for full-text log searching).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: Fluentd通过基于插件的架构高度可配置。提供100多个插件，支持不同的日志格式和后端（[https://www.fluentd.org/plugins](https://www.fluentd.org/plugins)）。它采用结构化日志方式，使日志以JSON格式处理，从而提高可搜索性和索引效率。Fluentd支持通过附加K8s元数据（如命名空间或Pod/容器名称）来丰富日志，然后再将日志发送到存储系统。它还支持日志过滤、缓冲和压缩，有助于在大规模K8s环境中优化资源使用。在K8s日志管道中，Fluentd通常与Loki（用于高效的日志存储）或Elasticsearch（用于全文日志搜索）一起使用。
- en: '**Fluent Bit** ([https://fluentbit.io/](https://fluentbit.io/)) is a lightweight
    version of Fluentd, optimized for low-resource environments and edge computing
    with much smaller memory footprint requirements. The following table provides
    a high-level comparison of Fluentd and Fluent Bit, highlighting their key differences
    and typical use cases:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '| **Features** | **Fluentd** | **Fluent Bit** |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
- en: '| **Resource usage** | Significant CPU and memory usage | Lightweight; minimal
    CPU and memory usage |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
- en: '| **Architecture** | Written in Ruby and C | Written in C |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
- en: '| **Plugin ecosystem** | Large plugin library with more than 1,000 external
    plugins | Over 100 built-in plugins |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
- en: '| **Deployment model** | Deployed as a K8s DaemonSet or sidecar with multiple
    plugins | Deployed as a K8s DaemonSet or sidecar with multiple plugins |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
- en: '| **Scalability** | Requires more resources at scale | Very scalable in environments
    with constrained resources |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
- en: '| **Use cases** | Containers/servers | Embedded Linux/containers/servers |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
- en: Loki
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Loki** ([https://github.com/grafana/loki](https://github.com/grafana/loki))
    is a lightweight, scalable log aggregation system designed for the K8s environment.
    Unlike traditional log management systems such as Elasticsearch, Loki indexes
    only metadata (labels) instead of the full log content, making it efficient and
    cost-effective for large-scale deployments. Loki integrates with Prometheus and
    Grafana, allowing users to correlate logs with metrics for better troubleshooting
    and observability.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: Loki collects logs from K8s Pods using agents such as Fluentd or Fluent Bit,
    which run as DaemonSets to forward logs to Loki for storage and querying, as shown
    in *Figure 12**.3*. This enables developers and operators to search logs efficiently
    using **log query language** (**LogQL**) ([https://grafana.com/docs/loki/latest/query/](https://grafana.com/docs/loki/latest/query/)),
    filter logs by namespace, Pod, or container, and visualize them in Grafana.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 12.3 – Fluent Bit/Loki deployment in K8s](img/B31108_12_03.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
- en: Figure 12.3 – Fluent Bit/Loki deployment in K8s
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
- en: OpenTelemetry
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**OTel** is a collection of APIs, SDKs, and tools that you can use to instrument,
    generate, collect, and export telemetry data (metrics, logs, and traces). It is
    commonly used for collecting and exporting telemetry data to various backend services,
    such as Prometheus, Jaeger, Datadog, and AWS X-Ray.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
- en: In K8s, OTel enables unified observability by collecting metrics, traces, and
    logs, which can be collected from Pods, containers, or nodes. It supports multiple
    backends for data storage and works with auto-instrumentation for programming
    languages such as Go, Java, Python, and Node.js. Refer to the OTel documentation
    at [https://opentelemetry.io/docs/platforms/kubernetes/operator/automatic/](https://opentelemetry.io/docs/platforms/kubernetes/operator/automatic/)
    for a detailed walkthrough of auto-instrumentation.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: '**OTel collectors** ([https://opentelemetry.io/docs/collector/](https://opentelemetry.io/docs/collector/))
    act as central agents that receive, process, and export telemetry data. These
    collectors support all three telemetry signals (metrics, traces, and logs), making
    it a powerful unified observability solution. **OTel exporters** ([https://opentelemetry.io/docs/languages/go/exporters/](https://opentelemetry.io/docs/languages/go/exporters/))
    are used to send collected data to backend systems such as Prometheus, Jaeger,
    and Datadog.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '**OTel 收集器** ([https://opentelemetry.io/docs/collector/](https://opentelemetry.io/docs/collector/))
    充当中央代理，接收、处理并导出遥测数据。这些收集器支持三种遥测信号（指标、追踪和日志），使其成为一个强大的统一可观测性解决方案。**OTel 导出器** ([https://opentelemetry.io/docs/languages/go/exporters/](https://opentelemetry.io/docs/languages/go/exporters/))
    用于将收集的数据发送到后端系统，如 Prometheus、Jaeger 和 Datadog。'
- en: To deploy OTel in K8s, one can start by installing OTel collectors using a Helm
    chart and configure the collectors to define the receivers, processors, and exporters
    for telemetry data. Please visit the documentation at [https://opentelemetry.io/docs/demo/kubernetes-deployment/](https://opentelemetry.io/docs/demo/kubernetes-deployment/)
    for OTel deployment in K8s. Alternatively, you can use the AWS distribution of
    the OTel project – **AWS Distro for OpenTelemetry** (**ADOT**) ([https://aws-otel.github.io/](https://aws-otel.github.io/))
    – for a secure, production-ready, open source distribution with predictable performance.
    To deploy ADOT on Amazon EKS, install the ADOT-managed add-on and configure collectors
    to forward observability data to your preferred destinations. Refer to the ADOT
    documentation at [https://aws-otel.github.io/docs/getting-started/adot-eks-add-on](https://aws-otel.github.io/docs/getting-started/adot-eks-add-on)
    for detailed installation instructions.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 K8s 中部署 OTel，可以通过使用 Helm 图表安装 OTel 收集器，并配置收集器以定义遥测数据的接收器、处理器和导出器。请访问 [https://opentelemetry.io/docs/demo/kubernetes-deployment/](https://opentelemetry.io/docs/demo/kubernetes-deployment/)
    了解 K8s 中的 OTel 部署文档。或者，您也可以使用 AWS 发行版的 OTel 项目——**AWS Distro for OpenTelemetry**（**ADOT**）([https://aws-otel.github.io/](https://aws-otel.github.io/))——以获得一个安全、生产就绪的开源发行版，具备可预测的性能。要在
    Amazon EKS 上部署 ADOT，请安装 ADOT 管理的附加组件，并配置收集器将可观测性数据转发到您的首选目标。请参考 [https://aws-otel.github.io/docs/getting-started/adot-eks-add-on](https://aws-otel.github.io/docs/getting-started/adot-eks-add-on)
    获取详细的安装说明。
- en: Prometheus
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**Prometheus**'
- en: '**Prometheus** ([https://prometheus.io/](https://prometheus.io/)) is an open
    source monitoring and alerting tool designed for collecting and querying time-series
    metrics. It was originally built by **SoundCloud** ([https://soundcloud.com/](https://soundcloud.com/))
    in 2012, to address the challenges of dynamic and distributed systems, and later
    joined the **Cloud Native Computing Foundation** (**CNCF**) in 2016 as the second
    hosted project after K8s. Prometheus collects and stores metrics as time-series
    data, where each data point is recorded with a timestamp and key-value pairs known
    as labels. It is widely used in K8s environments to provide real-time insights
    into system performance and resource utilization. In [*Chapter 10*](B31108_10.xhtml#_idTextAnchor128),
    we briefly discussed the Prometheus agent and adapters; let’s take a deeper look
    now.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '**Prometheus** ([https://prometheus.io/](https://prometheus.io/)) 是一个开源监控和报警工具，旨在收集和查询时间序列指标。它最初由**SoundCloud**
    ([https://soundcloud.com/](https://soundcloud.com/)) 于2012年开发，解决动态和分布式系统的挑战，并于2016年作为K8s之后的第二个托管项目加入了**Cloud
    Native Computing Foundation**（**CNCF**）。Prometheus 收集并存储指标作为时间序列数据，其中每个数据点都记录了时间戳和被称为标签的键值对。它在K8s环境中被广泛使用，为系统性能和资源利用提供实时洞察。在[*第10章*](B31108_10.xhtml#_idTextAnchor128)中，我们简要讨论了
    Prometheus 代理和适配器；现在我们来深入了解一下。'
- en: 'The following diagram illustrates the high-level architecture of Prometheus
    and some of the key components in its ecosystem:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了 Prometheus 的高层架构及其生态系统中的一些关键组件：
- en: '![Figure 12.4 – Prometheus architecture](img/B31108_12_04.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![图 12.4 – Prometheus 架构](img/B31108_12_04.jpg)'
- en: Figure 12.4 – Prometheus architecture
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12.4 – Prometheus 架构
- en: 'The following are the key components of the Prometheus architecture:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Prometheus 架构的关键组件：
- en: '**Prometheus server** ([https://github.com/prometheus/prometheus](https://github.com/prometheus/prometheus)):
    The Prometheus server is a central component that scrapes metrics from configured
    endpoints, such as nodes, Pods, or services. It stores these metrics in a time-series
    database, which can be queried using **Prometheus Query Language** (**PromQL**).
    Prometheus performs automatic target discovery in K8s to simplify monitoring in
    dynamic, containerized environments. Instead of manually specifying the endpoints
    for monitoring, Prometheus uses K8s APIs to dynamically discover targets such
    as Pods, Endpoints, and Services. This ensures that as workloads scale or shift
    within the cluster, Prometheus automatically adjusts to continue monitoring them
    without requiring configuration changes.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus 服务器** ([https://github.com/prometheus/prometheus](https://github.com/prometheus/prometheus)):
    Prometheus 服务器是一个核心组件，它从配置的端点（如节点、Pod 或服务）抓取指标，并将这些指标存储在时间序列数据库中，可以通过 **Prometheus
    查询语言**（**PromQL**）进行查询。Prometheus 在 K8s 中执行自动目标发现，以简化在动态的容器化环境中的监控。Prometheus
    不需要手动指定监控的端点，而是通过 K8s API 动态发现目标，如 Pod、端点和服务。这确保了当工作负载在集群内扩展或迁移时，Prometheus 能自动调整并继续监控，而无需更改配置。'
- en: '**Prometheus exporters** ([https://prometheus.io/docs/instrumenting/exporters/](https://prometheus.io/docs/instrumenting/exporters/)):
    Prometheus exporters are libraries that expose metrics in a format compatible
    with Prometheus. Exporters are essential for integrating Prometheus with systems
    or applications that do not natively expose metrics in the Prometheus format.
    They act as intermediaries, collecting data from the target system and exposing
    it on an HTTP endpoint for Prometheus to scrape. In K8s, exporters are widely
    used to monitor various components of the cluster, including nodes, applications,
    and external systems. For GenAI workloads, exporters are especially critical for
    monitoring GPUs, inference latency, and resource utilization. **NVIDIA DCGM exporter**
    exposes GPU metrics such as utilization, memory usage, temperature, and power
    consumption, critical for monitoring GPU workloads. We deployed this add-on on
    our EKS cluster setup in [*Chapter 10*](B31108_10.xhtml#_idTextAnchor128).'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus 导出器** ([https://prometheus.io/docs/instrumenting/exporters/](https://prometheus.io/docs/instrumenting/exporters/)):
    Prometheus 导出器是以 Prometheus 格式暴露指标的库。导出器对于将 Prometheus 与本身不原生暴露指标的系统或应用程序集成至关重要。它们充当中介，收集目标系统的数据并通过
    HTTP 端点将其暴露出来供 Prometheus 抓取。在 K8s 中，导出器被广泛用于监控集群的各个组件，包括节点、应用程序和外部系统。对于 GenAI
    工作负载，导出器尤为关键，用于监控 GPU、推理延迟和资源利用率。**NVIDIA DCGM 导出器**暴露了 GPU 的指标，如利用率、内存使用、温度和功耗，这对监控
    GPU 工作负载至关重要。我们在 [*第 10 章*](B31108_10.xhtml#_idTextAnchor128) 中的 EKS 集群设置中部署了此附加组件。'
- en: '**Prometheus Alertmanager** ([https://prometheus.io/docs/alerting/latest/overview/](https://prometheus.io/docs/alerting/latest/overview/)):
    Prometheus Alertmanager handles alerts generated by Prometheus, sending notifications
    to different channels such as **Slack** ([https://slack.com/](https://slack.com/)),
    email, or **PagerDuty** ([https://www.pagerduty.com/](https://www.pagerduty.com/)).
    It can be configured for GenAI use cases such as resource saturation alerts or
    higher inference latency. Prometheus Alertmanager supports deduplication, which
    consolidates duplicate alerts generated by multiple Prometheus instances to prevent
    notification flooding, and alert grouping, which groups similar alerts into a
    single notification for better readability.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus 警报管理器** ([https://prometheus.io/docs/alerting/latest/overview/](https://prometheus.io/docs/alerting/latest/overview/)):
    Prometheus 警报管理器处理由 Prometheus 生成的警报，将通知发送到不同的渠道，如 **Slack** ([https://slack.com/](https://slack.com/))、电子邮件或
    **PagerDuty** ([https://www.pagerduty.com/](https://www.pagerduty.com/))。它可以配置用于
    GenAI 用例，如资源饱和警报或更高的推理延迟。Prometheus 警报管理器支持去重功能，能够整合由多个 Prometheus 实例生成的重复警报，防止通知泛滥，还支持警报归组，将相似的警报归为一个通知，以提高可读性。'
- en: '**Prometheus Pushgateway** ([https://prometheus.io/docs/instrumenting/pushing/](https://prometheus.io/docs/instrumenting/pushing/)):
    This is a component of the Prometheus ecosystem that lets short-lived jobs push
    their metrics to Prometheus. This is especially useful for ephemeral workloads,
    such as short GenAI tasks, that cannot be directly scraped by Prometheus. In K8s
    environments, the Pushgateway acts as an intermediary, allowing batch jobs, cron
    jobs, and other transient workloads to publish metrics to a persistent endpoint.
    Prometheus then scrapes this endpoint at regular intervals.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus Pushgateway** ([https://prometheus.io/docs/instrumenting/pushing/](https://prometheus.io/docs/instrumenting/pushing/))：这是
    Prometheus 生态系统的一个组件，允许短暂的作业将它们的指标推送到 Prometheus。这对于短暂的工作负载（如无法直接被 Prometheus
    抓取的短 GenAI 任务）特别有用。在 K8s 环境中，Pushgateway 充当中间件，允许批处理作业、cron 作业和其他短暂工作负载将指标发布到持久端点。然后，Prometheus
    定期从这个端点抓取数据。'
- en: '**PromQL** ([https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/)):
    PromQL is a powerful and flexible query language used to extract and analyze time-series
    data stored in the Prometheus ecosystem, such as the Prometheus server itself
    or tools that rely on Prometheus as a backend, such as Grafana. It allows users
    to perform computations on metrics, filter and aggregate them based on labels,
    and derive insights through queries.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**PromQL** ([https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/))：PromQL
    是一种强大而灵活的查询语言，用于提取和分析存储在 Prometheus 生态系统中的时间序列数据，例如 Prometheus 服务器本身或依赖 Prometheus
    作为后端的工具（如 Grafana）。它允许用户对指标执行计算、基于标签过滤和聚合，并通过查询推断出洞察。'
- en: Now that we have covered the key components of the Prometheus stack, let’s discuss
    how to deploy it within the K8s environment.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经介绍了 Prometheus stack 的关键组件，让我们讨论如何在 K8s 环境中部署它。
- en: Deploying the Prometheus stack
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署 Prometheus stack
- en: In K8s, it is recommended to deploy the Prometheus server as a **StatefulSet**.
    A StatefulSet is a K8s controller used to manage stateful applications that require
    stable identities and persistent storage. Unlike Deployments, which treat Pods
    as interchangeable, StatefulSets assign each Pod a unique, stable hostname and
    ensure that storage volumes persist across Pod restarts. This ensures consistency
    and reliability for workloads that rely on maintaining state across restarts or
    rescheduling. Deploying the Prometheus server as a StatefulSet ensures that it
    has persistent storage access for metrics, using a **PersistentVolumeClaim** (**PVC**).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在 K8s 中，推荐将 Prometheus 服务器部署为 **StatefulSet**。StatefulSet 是一个 K8s 控制器，用于管理需要稳定标识和持久存储的有状态应用程序。与
    Deployments 不同，StatefulSets 为每个 Pod 分配一个唯一的、稳定的主机名，并确保存储卷在 Pod 重新启动时保持持久。这确保了依赖于在重新启动或重新调度时保持状态的工作负载的一致性和可靠性。将
    Prometheus 服务器部署为 StatefulSet 可以确保其具有用于指标的持久存储访问，使用 **PersistentVolumeClaim**
    (**PVC**)。
- en: To streamline the K8s setup, the Prometheus community has developed Helm charts
    to deploy all essential components, which are available at [https://github.com/prometheus-community/helm-charts](https://github.com/prometheus-community/helm-charts).
    In our setup, we will deploy `kube-prometheus-stack` using the **Terraform Helm
    provider**. This Helm chart deploys Prometheus and Grafana instances in our EKS
    cluster, as shown in *Figure 12**.5*. After deployment, we will configure Prometheus
    to scrape metrics from various components within the cluster, such as the NVIDIA
    DCGM exporter, Qdrant vector database, Ray Serve deployments, and so on. Prometheus
    automatically discovers the relevant target endpoints and collects metrics at
    regular intervals. Using the Grafana web console, we can then visualize and query
    these metrics, build and import interactive dashboards, and define alerting rules.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化 K8s 设置，Prometheus 社区开发了 Helm charts 来部署所有必要的组件，可以在 [https://github.com/prometheus-community/helm-charts](https://github.com/prometheus-community/helm-charts)
    找到。在我们的设置中，我们将使用 **Terraform Helm provider** 部署 `kube-prometheus-stack`。这个 Helm
    chart 在我们的 EKS 集群中部署了 Prometheus 和 Grafana 实例，如 *Figure 12**.5* 所示。部署完成后，我们将配置
    Prometheus 从集群内各个组件（如 NVIDIA DCGM exporter、Qdrant 向量数据库、Ray Serve 部署等）中抓取指标。Prometheus
    会自动发现相关的目标端点，并定期收集指标。通过 Grafana web 控制台，我们可以可视化和查询这些指标，构建和导入交互式仪表板，并定义警报规则。
- en: '![Figure 12.5 – Prometheus and Grafana setup in EKS cluster](img/B31108_12_05.jpg)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![Figure 12.5 – 在 EKS 集群中设置 Prometheus 和 Grafana](img/B31108_12_05.jpg)'
- en: Figure 12.5 – Prometheus and Grafana setup in EKS cluster
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Figure 12.5 – 在 EKS 集群中设置 Prometheus 和 Grafana
- en: 'To get started, download the `addons.tf` and `kube-prometheus.yaml` files from
    the GitHub repository at [https://github.com/PacktPublishing/Kubernetes-for-Gen-AI-Models/tree/main/ch12/](https://github.com/PacktPublishing/Kubernetes-for-Gen-AI-Models/tree/main/ch12/).
    The `kube-prometheus-stack` Helm chart, along with `prometheus-adapter`, will
    be deployed in the *monitoring* namespace, as shown in the following code snippet:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'The Prometheus setup is customized using the `kube-prometheus.yaml` Helm values
    file. It does the following things:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '`gp3` storage class'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`alertmanager.enabled` value to `true`*   **Grafana configuration**:'
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploys Grafana and enables the default monitoring dashboards
  id: totrans-92
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Execute the following `terraform` commands to deploy the `kube-prometheus-stack`
    and `prometheus-adapter` Helm charts in the EKS cluster:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Verify the installation using the following `kubectl` command. The output should
    confirm that the Prometheus StatefulSet, node exporter DaemonSet, Grafana, `kube-state-metrics`,
    `prometheus-adapter`, and `prometheus-operator` deployments are in a **READY**
    status:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In larger environments, it is recommended to assign sufficient CPU and memory
    resources and use appropriate scrape intervals for different metrics to optimize
    resource usage. For example, for critical metrics such as CPU or memory utilization,
    it is recommended to use intervals of 10 to 15 seconds, whereas for less critical
    metrics, this interval could be in minutes.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered how to deploy the Prometheus stack in an EKS cluster.
    However, to gain deeper insights into GPU performance (critical for AI/ML workloads),
    we need to enable metric scraping for GPUs. In the next section, we’ll cover integrating
    NVIDIA’s DCGM exporter with Prometheus by configuring Service monitors.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Enabling GPU monitoring
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In [*Chapter 10*](B31108_10.xhtml#_idTextAnchor128), we deployed the **NVIDIA
    DCGM Exporter add-on** to gain visibility into GPU utilization metrics. During
    the setup, we disabled the service monitors that enable Prometheus to scrape the
    metrics at regular intervals. **Prometheus Service Monitors** ([https://prometheus-operator.dev/docs/developer/getting-started/#using-servicemonitors](https://prometheus-operator.dev/docs/developer/getting-started/#using-servicemonitors))
    and **Pod Monitors** ([https://prometheus-operator.dev/docs/developer/getting-started/#using-podmonitors](https://prometheus-operator.dev/docs/developer/getting-started/#using-podmonitors))
    are **CustomResourceDefinitions** (**CRDs**) that allow the Prometheus Operator
    to automatically discover and configure monitoring targets within a K8s cluster.
    By leveraging label selectors on K8s services and Pods, these monitors streamline
    the process of collecting metrics.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s update the Terraform code to enable the scraping of `dcgm-exporter` metrics
    using Service Monitors. Begin by downloading `aiml-addons.tf` from the GitHub
    repository at [https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch12/aiml-addons.tf](https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/blob/main/ch12/aiml-addons.tf):'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: $ terraform init
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: $ terraform plan
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
- en: $ terraform apply -auto-approve
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: $ kubectl port-forward svc/kube-prometheus-stack-prometheus -n monitoring 9090:9090
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: Forwarding from 127.0.0.1:9090 -> 9090
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Forwarding from [::1]:9090 -> 9090
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: $ kubectl apply -f <replace with service monitor file name>
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: $ kubectl port-forward svc/kube-prometheus-stack-grafana -n monitoring 8080:80
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Forwarding from 127.0.0.1:8080 -> 80
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Forwarding from [::1]:8080 -> 80
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '$ kubectl get secret kube-prometheus-stack-grafana -n monitoring -o go-template=''{{printf
    "Username: %s\nPassword: %s\n" (index .data "admin-user" | base64decode) (index
    .data "admin-password" | base64decode)}}'''
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: $ kubectl apply -f gpu-rules.yaml
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: $ kubectl apply -f ray-serve-rules.yaml
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: import time
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: from langchain.callbacks.base import BaseCallbackHandler
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: from langchain.chains import LLMChain
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: from langchain_openai import OpenAI
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: from langchain.prompts import PromptTemplate
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: 'class DebugCallbackHandler(BaseCallbackHandler):'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 'def __init__(self):'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: self.start_time = None
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: 'def on_chain_start(self, inputs, **kwargs):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '"""Triggered when the chain starts execution."""'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: self.start_time = time.time()
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: print("\n[DEBUG] Chain started...")
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'print(f" Inputs: {inputs}")'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: 'def on_chain_end(self, outputs, **kwargs):'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: '"""Triggered when the chain successfully completes execution."""'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: elapsed_time = time.time() - self.start_time
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: print(f"\n[DEBUG] Chain finished in {elapsed_time:.2f} seconds")
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: 'print(f"Outputs: {outputs}")'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: 'def on_chain_error(self, error, **kwargs):'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: print("\n [ERROR] Chain encountered an error!")
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'print(f"  Error Message: {error}")'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: debug_handler = DebugCallbackHandler()
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-145
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
