- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Orchestrating Containers across Clouds with Tanzu Kubernetes Grid
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Tanzu Kubernetes Grid在云之间编排容器
- en: 'In the previous chapter, we learned about Harbor, a container registry, that
    is covered as a part of the Tanzu product bundle. After learning about hosting
    our container images with Harbor, let’s learn how to deploy them on Kubernetes
    in this chapter with Tanzu Kubernetes Grid, a multi-cloud and enterprise-ready
    Kubernetes distribution of Tanzu. Kubernetes has become widely accepted and the
    default norm in the industry to run containers in the past few years. As per a
    recent survey by the **Cloud Native Computing Foundation** (**CNCF**), 96% of
    the responding organizations were either evaluating or already using Kubernetes
    (source: [https://www.cncf.io/wp-content/uploads/2022/02/CNCF-Annual-Survey-2021.pdf](https://www.cncf.io/wp-content/uploads/2022/02/CNCF-Annual-Survey-2021.pdf))!
    Additionally, a large sum of them used Kubernetes on different cloud platforms
    for reasons such as risk mitigation, avoiding vendor lock-ins, and efficient operational
    expenditure. But operating large Kubernetes platforms on one or more clouds is
    a non-trivial effort for various reasons. Each cloud platform has APIs and distinct
    ways to manage Kubernetes services. The complexity increases when the organizations
    also need to run Kubernetes services on-premises. For such on-premises Kubernetes
    deployments, many enterprises build their own platforms with custom automation.
    While building such custom platforms using open source tools brings initial cost
    savings, maintaining them for a long time is very difficult when the original
    people who built the platforms move out of the organizations. Rather, the organizations
    could better utilize their talents to build more revenue-generating custom applications
    for their businesses by using an enterprise-grade product such as **Tanzu Kubernetes
    Grid** (**TKG**) for such below-value-line concerns.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解了作为Tanzu产品包一部分的容器注册中心Harbor。通过了解如何使用Harbor托管容器镜像，接下来我们将在本章学习如何使用Tanzu
    Kubernetes Grid（Tanzu的多云且企业级的Kubernetes分发版）将它们部署到Kubernetes上。近年来，Kubernetes已经广泛被接受，成为行业运行容器的默认规范。根据**Cloud
    Native Computing Foundation**（**CNCF**）的最新调查，96%的受访组织要么正在评估，要么已经在使用Kubernetes（来源：[https://www.cncf.io/wp-content/uploads/2022/02/CNCF-Annual-Survey-2021.pdf](https://www.cncf.io/wp-content/uploads/2022/02/CNCF-Annual-Survey-2021.pdf)）！此外，许多受访者在不同的云平台上使用Kubernetes，原因包括风险缓解、避免厂商锁定以及提高运营支出效率。但在一个或多个云上运营大型Kubernetes平台是一个复杂的任务，原因多种多样。每个云平台都有各自的API和管理Kubernetes服务的独特方式。当组织还需要在本地运行Kubernetes服务时，复杂性会进一步增加。对于这种本地Kubernetes部署，许多企业会使用自定义自动化构建自己的平台。虽然使用开源工具构建这样的自定义平台可以带来初期的成本节省，但当最初构建平台的人离开组织后，长期维护这些平台将变得非常困难。相比之下，组织可以更好地利用其人才，使用**Tanzu
    Kubernetes Grid**（**TKG**）这样的企业级产品，专注于构建更多具有收入创造潜力的定制应用程序，而不是为这些低价值的工作分心。
- en: 'TKG is VMware’s Kubernetes distribution that comes with all the bells and whistles
    to deploy enterprise-grade container platforms on vSphere-based on-premises data
    centers, **Amazon Web Services** (**AWS**), and Azure public cloud infrastructure.
    In this chapter, we will learn about this product in detail and will cover the
    following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: TKG是VMware的Kubernetes发行版，提供了部署企业级容器平台所需的一切功能，适用于基于vSphere的本地数据中心、**Amazon Web
    Services**（**AWS**）和Azure公有云基础设施。在本章中，我们将详细了解此产品，并涵盖以下主题：
- en: '**Why Tanzu Kubernetes Grid?**: A walkthrough of the features and capabilities
    of TKG'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**为什么选择Tanzu Kubernetes Grid？**：深入了解TKG的功能和能力'
- en: '**Unboxing Tanzu Kubernetes Grid**: A detailed overview of the components and
    the concepts of TKG'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开箱Tanzu Kubernetes Grid**：详细概述TKG的组件和概念'
- en: '**Getting started with Tanzu Kubernetes Grid**: Learn how to install and configure
    TKG'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开始使用Tanzu Kubernetes Grid**：学习如何安装和配置TKG'
- en: '**Common day-2 operations with Tanzu Kubernetes Grid**: Learn how to perform
    various cluster life cycle activities with TKG'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Tanzu Kubernetes Grid的常见日常操作**：学习如何使用TKG执行各种集群生命周期活动'
- en: Let’s get started by learning about the background of Tanzu Kubernetes Grid.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从了解Tanzu Kubernetes Grid的背景开始。
- en: Why Tanzu Kubernetes Grid?
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为什么选择Tanzu Kubernetes Grid？
- en: In a nutshell, TKG is an enterprise-supported flavor of the open source Kubernetes
    platform. Like many other distributions, TKG uses the upstream Kubernetes distributions
    without modifying the open source code base. However, there are a few good reasons
    why an enterprise would like to use TKG over the open source community – *vanilla*
    – distribution of Kubernetes. We’ll explore those reasons in this section.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，TKG 是企业支持的开源 Kubernetes 平台的一个版本。与其他许多发行版一样，TKG 使用上游 Kubernetes 发行版，而不修改开源代码库。然而，有几个充分的理由使得企业更倾向于使用
    TKG 而非开源社区的 *原生* Kubernetes 发行版。我们将在本节中探讨这些原因。
- en: Multi-cloud application deployments
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多云应用部署
- en: As per a survey done by Gartner ([https://www.gartner.com/smarterwithgartner/why-organizations-choose-a-multicloud-strategy](https://www.gartner.com/smarterwithgartner/why-organizations-choose-a-multicloud-strategy)),
    over 81% of respondents said that they have a multi-cloud deployment or strategy.
    Enterprises have multi-cloud strategies for reasons such as avoiding vendor lock-ins
    and using the best services offered by the respective cloud provider. Additionally,
    the enterprises have applications that may not be deployed on a public cloud platform
    and hence deployed on-premises. Kubernetes offers a great option to allow application
    deployments in multi-cloud and hybrid cloud platforms. Once an application is
    ready to run in Kubernetes wrapped in a container, it can be deployed on any upstream
    conformant Kubernetes platform deployed in any cloud or data center. Kubernetes
    made the multi-cloud deployment of applications almost trivial. Kubernetes manages
    containerized applications well, but at its core, it does not know how to manage
    the infrastructure on which it is deployed. That makes the platform and infrastructure
    management an external concern. All major cloud providers offer Kubernetes as
    a service in addition to the option of just using their infrastructure to deploy
    a self-managed Kubernetes platform. However, every platform has its own interfaces
    and hence a different user experience. Additionally, every platform has its own
    flavors of operating systems, networks, storage, and compute-level differences.
    Managing large Kubernetes platforms itself is a hard problem to solve, which is
    amplified even more when we need to manage a multi-cloud environment. While learning
    the details of one cloud platform is not complex enough, now, the infrastructure
    and the platform teams need to learn the same for more than one cloud platform
    if they aim to deploy Kubernetes in a multi-cloud fashion. Because of these reasons
    and the complexities involved, several enterprises avoid going multi-cloud despite
    the involved risks in using just one platform.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Gartner 的一项调查（[https://www.gartner.com/smarterwithgartner/why-organizations-choose-a-multicloud-strategy](https://www.gartner.com/smarterwithgartner/why-organizations-choose-a-multicloud-strategy)），超过
    81% 的受访者表示他们有多云部署或策略。企业采用多云策略的原因包括避免供应商锁定，并使用各个云服务提供商提供的最佳服务。此外，企业有些应用程序可能无法部署在公共云平台上，因此选择在本地部署。Kubernetes
    提供了一个很好的选项，允许在多云和混合云平台上部署应用程序。一旦应用程序准备好在 Kubernetes 中运行并包装在容器中，它就可以部署到任何符合上游标准的
    Kubernetes 平台，不论是在任何云环境还是数据中心中。Kubernetes 使得应用程序的多云部署几乎变得轻而易举。Kubernetes 可以很好地管理容器化应用程序，但从本质上讲，它并不懂得如何管理其所部署的基础设施。这使得平台和基础设施的管理成为一个外部问题。所有主要的云服务提供商除了提供
    Kubernetes 作为服务之外，还提供仅使用其基础设施来部署自我管理 Kubernetes 平台的选项。然而，每个平台都有其独特的接口，因此用户体验也各不相同。此外，每个平台在操作系统、网络、存储和计算等方面都有各自的差异。管理大型
    Kubernetes 平台本身就是一个难题，当我们需要管理一个多云环境时，这个问题会更加复杂。虽然学习一个云平台的细节并不复杂，但现在，基础设施和平台团队如果计划以多云方式部署
    Kubernetes，就需要学习多个云平台的相同内容。由于这些原因和所涉及的复杂性，许多企业尽管使用单一平台所带来的风险较高，仍然避免走向多云。
- en: TKG addresses these challenges by providing a uniform experience to operate
    Kubernetes on vSphere (for on-premises deployment), AWS, and Azure cloud platforms.
    One of the core components of TKG is the Cluster API ([https://cluster-api.sigs.k8s.io/](https://cluster-api.sigs.k8s.io/)),
    a CNCF open source project that provides an abstraction layer on top of the infrastructure.
    The Cluster API deploys and manages Kubernetes nodes with the required storage
    and network configuration for the selected cloud platform. Additionally, TKG exposes
    its interfaces using the `tanzu` CLI by providing the same user interface to perform
    different Kubernetes cluster life cycle operations, irrespective of the infrastructure
    provider. TKG also bundles VMware-supported operating system layers for the three
    supported cloud providers. With all these characteristics, TKG provides an easy-to-consume
    multi-cloud Kubernetes platform.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: TKG 通过提供统一的体验来解决这些挑战，使得在 vSphere（用于本地部署）、AWS 和 Azure 云平台上操作 Kubernetes 成为可能。TKG
    的核心组件之一是集群 API（[https://cluster-api.sigs.k8s.io/](https://cluster-api.sigs.k8s.io/)），这是一个由
    CNCF 维护的开源项目，提供了一个基础设施之上的抽象层。集群 API 部署并管理 Kubernetes 节点，确保所选云平台所需的存储和网络配置。此外，TKG
    通过 `tanzu` CLI 来暴露其接口，提供相同的用户界面来执行不同的 Kubernetes 集群生命周期操作，无论基础设施提供商是什么。TKG 还为三大支持的云提供商捆绑了
    VMware 支持的操作系统层。凭借这些特性，TKG 提供了一个易于使用的多云 Kubernetes 平台。
- en: Open source alignment
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开源对齐
- en: Another of the main benefits of using TKG is its usage of open source tools
    for different use cases. As its core component, TKG uses the upstream open source
    Kubernetes distribution maintained by the CNCF community. TKG does not fork the
    source code of any of its open source components to add its own flavor and customization.
    This characteristic provides TKG consumers with all the benefits of using open
    source software, including avoidance of vendor lock-ins via portability, and an
    avenue to enrich the functionalities to their needs via open source contributions.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TKG 的另一个主要好处是，它使用了适用于不同用例的开源工具。作为其核心组件，TKG 使用由 CNCF 社区维护的上游开源 Kubernetes
    发行版。TKG 并没有从任何开源组件中派生代码并加入自己的定制特性。这一特点为 TKG 用户提供了使用开源软件的所有好处，包括通过可移植性避免厂商锁定，并通过开源贡献为其需求丰富功能的途径。
- en: 'Considering these benefits, all enterprises have wanted to use open source
    solutions as much as possible in the past few years. However, the cloud-native
    ecosystem is very crowded with open source products that solve similar problems
    and have different levels of maturity to be used in production setups. *Figure
    7**.1* is a screenshot taken from the CNCF website ([https://landscape.cncf.io/](https://landscape.cncf.io/))
    showing an extremely crowded space with tools solving different problems running
    containerized applications. Picking the right tool for the right problem with
    acceptable maturity, a vibrant community, and enterprise-level support is a challenging
    task. And the landscape is constantly changing by adding new solutions to the
    list very frequently. Adding more to the complexity, the compatibility of one
    tool working with another is not always the case. So, there are three possible
    solutions to this issue:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到这些好处，近年来所有企业都希望尽可能使用开源解决方案。然而，云原生生态系统中充满了许多开源产品，这些产品解决相似的问题，并且在生产环境中使用时成熟度不同。*图
    7.1* 是一张来自CNCF官网的截图（[https://landscape.cncf.io/](https://landscape.cncf.io/)），展示了一个非常拥挤的空间，里面有许多解决不同问题的工具，运行容器化应用程序。为特定问题选择合适的工具，并且该工具具有可接受的成熟度、活跃的社区和企业级支持，是一项具有挑战性的任务。而且，这个生态系统在不断变化，新解决方案频繁地被添加到列表中。更复杂的是，一个工具与另一个工具的兼容性并不总是能得到保证。因此，解决这个问题有三种可能的方案：
- en: Enterprises would build their custom container platforms by carefully evaluating
    their options in this diverse and crowded landscape by running long proof-of-concept
    projects to narrow down their choices. While this would provide all the control
    and possible short-term cost benefits, there are some considerable drawbacks to
    this approach. One of them is that enterprises may need to spend a lot of productive
    time with their engineers to build a custom container platform. Finding right
    talents from the market and building required skills internally are hard and expensive
    challenges. Additionally, such skilled people would be in high demand in the market
    and may not stay with the enterprise for a long time to support what they have
    built internally. And then, such custom-built solutions quickly become an expensive
    liability for the organization.
  id: totrans-17
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 企业通过仔细评估这个多样化且竞争激烈的生态系统中的各项选择，运行长期的概念验证项目来缩小选择范围，从而构建定制的容器平台。虽然这种方式能提供完全的控制权和可能的短期成本优势，但这种方法也有一些相当大的缺点。其中之一是，企业可能需要花费大量的工程师时间来构建定制的容器平台。从市场上找到合适的人才并在内部培养所需的技能是一个艰难且昂贵的挑战。此外，这些技能人才在市场上需求旺盛，可能无法长时间留在企业内支持他们所构建的系统。最终，这些定制构建的解决方案很快就会成为企业的一项昂贵的负担。
- en: 'Enterprises would choose all the solutions provided by a cloud provider, where
    the enterprises no longer need to spend time selecting the tools and worry about
    the support and compatibility of those tools. This way, an enterprise can build
    a robust and production-grade container platform using all the services provided
    by a single hyper-scaler such as AWS, Azure, or Google Cloud Platform. However,
    this approach could result in potential vendor lock-ins. The *divorce* would be
    very painful in the long term and it would be an expensive *marriage* with one
    cloud provider:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 企业可以选择由云服务提供商提供的所有解决方案，在这种方式下，企业不再需要花时间选择工具，也不必担心这些工具的支持和兼容性。通过这种方式，企业可以使用AWS、Azure或Google
    Cloud Platform等单一云服务商提供的所有服务来构建一个强大且符合生产要求的容器平台。然而，这种方法可能会导致潜在的厂商锁定问题。长期来看，*脱离*将非常痛苦，而且这将成为与一个云服务商的昂贵的*婚姻*：
- en: '![Figure 7.1 – CNCF landscape](img/B18145_07_01.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.1 – CNCF 生态图](img/B18145_07_01.jpg)'
- en: Figure 7.1 – CNCF landscape
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – CNCF 生态图
- en: Enterprises would pick a multi-cloud platform such as Tanzu that would abstract
    an infrastructure provider, resulting in the portability of workloads deployed
    on the platform. Like the first two approaches, this one also has a drawback.
    Using such multi-cloud platforms might result in a vendor lock-in situation for
    the vendor of the multi-cloud platform provider itself. There is no foolproof
    solution to avoid vendor lock-ins when we use any third-party product. However,
    this risk could be somewhat mitigated if the third-party solution is fully backed
    by open source components, which is exactly the case with TKG.
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 企业可以选择像Tanzu这样的多云平台，它可以抽象化基础设施提供商，从而使部署在平台上的工作负载具备可移植性。与前两种方式类似，这种方式也有缺点。使用这种多云平台可能会导致多云平台提供商本身的厂商锁定问题。在使用任何第三方产品时，避免厂商锁定没有万无一失的解决方案。然而，如果第三方解决方案完全由开源组件支持，这种风险可能会在一定程度上得到缓解，而TKG恰好就是这种情况。
- en: TKG is a bundle of many different popular open source projects, including Kubernetes
    as a container runtime, the Cluster API for Kubernetes cluster life cycle management,
    Antrea for container overlay networking, Ubuntu and Photon as the node operating
    systems, Fluent Bit for logging, Prometheus and Grafana for monitoring, and many
    others. We will cover them all in the next section. VMware supplies signed binaries
    for all these open source tools that work together for a given release of TKG.
    This way, TKG helps enterprises avoid going through the painful process of tool
    selection, makes them work together, gets them supported, and avoids vendor lock-ins
    to a good extent.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: TKG是许多流行的开源项目的集合，包括作为容器运行时的Kubernetes、用于Kubernetes集群生命周期管理的Cluster API、用于容器覆盖网络的Antrea、作为节点操作系统的Ubuntu和Photon、用于日志记录的Fluent
    Bit、用于监控的Prometheus和Grafana等。我们将在下一部分详细介绍它们。VMware为所有这些开源工具提供签名的二进制文件，这些工具会协同工作并适用于特定版本的TKG。通过这种方式，TKG帮助企业避免了痛苦的工具选择过程，使工具能够协同工作，获得支持，并在很大程度上避免了厂商锁定。
- en: With this, we have answered the question *Why Tanzu Kubernetes Grid?* Now, let’s
    understand what is included in the TKG bundle and its core concepts.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们已经回答了*为什么选择 Tanzu Kubernetes Grid？*的问题。现在，让我们了解TKG包中包含的内容及其核心概念。
- en: Unboxing Tanzu Kubernetes Grid
  id: totrans-24
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 解开 Tanzu Kubernetes Grid
- en: In this section, we will review all the building blocks of TKG, including its
    interface and core and extension components. After that, we will understand the
    core concepts of this platform to understand how it works. We have a long way
    to go, so let’s start.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾 TKG 的所有构建模块，包括其接口、核心组件和扩展组件。之后，我们将理解该平台的核心概念，从而理解其工作原理。我们还有很长的路要走，所以让我们开始吧。
- en: Building blocks of Tanzu Kubernetes Grid
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Tanzu Kubernetes Grid 的构建模块
- en: 'As mentioned in the previous section, TKG is a collection of many open source
    tools that solve different problems that, together, make an enterprise-grade Kubernetes
    platform. We can distribute these components into three categories – interface,
    core, and extensions – as shown in *Figure 7**.2*:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 正如上一节所提到的，TKG 是由许多开源工具集合而成，这些工具分别解决不同的问题，共同构建出一个企业级的 Kubernetes 平台。我们可以将这些组件分为三类——接口、核心和扩展——如*图
    7.2*所示：
- en: '![Figure 7.2 – Tanzu Kubernetes Grid bundle](img/B18145_07_02.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.2 – Tanzu Kubernetes Grid 包](img/B18145_07_02.jpg)'
- en: Figure 7.2 – Tanzu Kubernetes Grid bundle
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – Tanzu Kubernetes Grid 包
- en: Let’s review all these components to learn about their roles in the TKG bundle.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾这些组件，了解它们在 TKG 包中的角色。
- en: Interface components of Tanzu Kubernetes Grid
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Tanzu Kubernetes Grid 的接口组件
- en: As the name suggests, these components include TKG’s interfaces with users and
    infrastructure providers, including vSphere, AWS, and Azure. The following section
    specifies these tools in more detail.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名称所示，这些组件包括 TKG 与用户及基础设施提供者（包括 vSphere、AWS 和 Azure）之间的接口。接下来的章节将更详细地说明这些工具。
- en: Tanzu command-line interface (CLI)
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Tanzu 命令行界面（CLI）
- en: 'Like a few other products in the Tanzu product portfolio, TKG also uses the
    `tanzu` CLI as its primary user interface. The `tanzu` CLI has a plugin structure
    that allows different Tanzu products to use the same interface. TKG uses the `tanzu`
    CLI for all cluster operations, such as viewing, creating, scaling, deleting,
    and upgrading TKG clusters. We will use this CLI in the next section when we set
    up our TKG foundation. The `tanzu` CLI is a part of the broader open source project
    named Tanzu Framework ([https://github.com/vmware-tanzu/tanzu-framework](https://github.com/vmware-tanzu/tanzu-framework)).
    You can learn more about this CLI here: [https://github.com/vmware-tanzu/tanzu-framework/tree/main/docs/cli](https://github.com/vmware-tanzu/tanzu-framework/tree/main/docs/cli).'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Tanzu 产品组合中的其他一些产品类似，TKG 也使用 `tanzu` CLI 作为其主要用户界面。`tanzu` CLI 采用插件结构，允许不同的
    Tanzu 产品使用相同的界面。TKG 使用 `tanzu` CLI 执行所有集群操作，例如查看、创建、扩展、删除和升级 TKG 集群。我们将在下一节中使用这个
    CLI 设置我们的 TKG 基础平台。`tanzu` CLI 是名为 Tanzu Framework 的更广泛开源项目的一部分（[https://github.com/vmware-tanzu/tanzu-framework](https://github.com/vmware-tanzu/tanzu-framework)）。你可以在这里了解更多关于该
    CLI 的信息：[https://github.com/vmware-tanzu/tanzu-framework/tree/main/docs/cli](https://github.com/vmware-tanzu/tanzu-framework/tree/main/docs/cli)。
- en: In addition to this CLI, the Tanzu portfolio includes a **graphical user interface**
    (**GUI**) tool named **Tanzu Mission Control** for all TKG cluster operations.
    We will learn about this tool in detail in *Chapter 9*, *Managing and Controlling
    Kubernetes Clusters with Tanzu* *Mission Control*.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这个 CLI，Tanzu 产品组合还包括一个名为 **Tanzu Mission Control** 的图形用户界面（**GUI**）工具，用于所有
    TKG 集群操作。我们将在*第 9 章*《使用 Tanzu Mission Control 管理和控制 Kubernetes 集群》中详细了解这个工具。
- en: Tanzu Kubernetes Grid installer
  id: totrans-36
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Tanzu Kubernetes Grid 安装程序
- en: The TKG installer is a GUI component that provides a wizard for installing TKG
    on a selected infrastructure, which could be either vSphere, AWS, or Azure at
    the time of writing. During the initial setup of TKG, a very small bootstrapped
    Kubernetes cluster is deployed on the operator’s workstation (also called a **bootstrap
    machine**). The TKG installer pods get deployed on that local Kubernetes cluster
    to deploy and start the GUI in the bootstrap machine. The operator then uses the
    locally running TKG installer’s GUI to deploy the actual TKG foundation on the
    targeted cloud infrastructure. It seems to be confusing because here, TKG uses
    a (small) Kubernetes platform to deploy a (large) Kubernetes platform. We will
    use this GUI during our TKG installation steps in the next section.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: TKG 安装程序是一个图形用户界面组件，提供了一个向导，用于在选定的基础设施上安装 TKG，撰写时该基础设施可以是 vSphere、AWS 或 Azure。在
    TKG 的初始设置过程中，一个非常小的引导 Kubernetes 集群会被部署在操作员的工作站上（也称为**引导机器**）。TKG 安装程序 Pod 会在该本地
    Kubernetes 集群上部署，以部署并启动引导机器上的图形用户界面。然后，操作员使用本地运行的 TKG 安装程序图形用户界面，在目标云基础设施上部署实际的
    TKG 基础平台。这看起来可能会让人困惑，因为在这里，TKG 使用一个（小型）Kubernetes 平台来部署一个（大型）Kubernetes 平台。在下一节的
    TKG 安装步骤中，我们将使用这个图形用户界面。
- en: It is worth noting that TKG also provides a way to install the foundation using
    the `tanzu` CLI as well, along with the GUI experience. However, it is recommended
    to use the GUI for the first installation as the wizard that’s used in the GUI
    generates an installation configuration file that can later be used with little
    modifications to quickly install other similar TKG foundations using the `tanzu`
    CLI.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，TKG 还提供了一种使用 `tanzu` CLI 安装基础设施的方法，同时也提供了图形用户界面（GUI）体验。然而，建议在第一次安装时使用
    GUI，因为 GUI 中使用的向导会生成一个安装配置文件，该文件可以稍作修改后用于通过 `tanzu` CLI 快速安装其他类似的 TKG 基础设施。
- en: kind
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: kind
- en: '**kind** stands for **Kubernetes inside Docker**. kind is an open source project
    under the umbrella of Kubernetes **Special Interest Groups** (**SIGs**) ([https://kind.sigs.k8s.io/](https://kind.sigs.k8s.io/))
    that allows you to deploy a very tiny Kubernetes cluster as a container running
    inside a Docker environment. kind is a CNCF-conformant Kubernetes installer and
    typically gets deployed in local desktop environments to deploy a small Kubernetes
    cluster. The TKG installer pods get deployed in a kind cluster for bootstrap purposes
    only. Once the actual TKG foundation has been installed, the kind cluster is destroyed,
    along with the running installer components, since their purpose has come to an
    end.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**kind** 代表 **Kubernetes inside Docker**。kind 是一个在 Kubernetes **特殊兴趣小组** (**SIGs**)
    旗下的开源项目 ([https://kind.sigs.k8s.io/](https://kind.sigs.k8s.io/))，它允许你在 Docker
    环境中运行一个非常小型的 Kubernetes 集群。kind 是一个符合 CNCF 标准的 Kubernetes 安装工具，通常部署在本地桌面环境中，用于部署一个小型的
    Kubernetes 集群。TKG 安装器 Pods 仅在 kind 集群中用于引导目的。一旦实际的 TKG 基础设施安装完成，kind 集群以及运行的安装器组件会被销毁，因为它们的用途已经结束。'
- en: Cluster API
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Cluster API
- en: Kubernetes includes a tool named **Kubeadm** ([https://kubernetes.io/docs/reference/setup-tools/kubeadm/](https://kubernetes.io/docs/reference/setup-tools/kubeadm/))
    that helps configure a server to make it a Kubernetes cluster node. It does this
    by installing the required Kubernetes-specific components. Kubeadm helps the node
    join the cluster as best practice *fast paths* for creating Kubernetes clusters.
    However, Kubeadm does not know how to provision the required infrastructure for
    the given cloud provider. Kubeadm requires the servers to be created with the
    required compute, storage, and networking setup before it can convert those servers
    into Kubernetes nodes. This gap in infrastructure management in Kubeadm is filled
    by the **Cluster API**.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 包含一个名为 **Kubeadm** 的工具 ([https://kubernetes.io/docs/reference/setup-tools/kubeadm/](https://kubernetes.io/docs/reference/setup-tools/kubeadm/))，该工具帮助配置服务器，将其转换为
    Kubernetes 集群节点。它通过安装所需的 Kubernetes 特定组件来实现这一目标。Kubeadm 有助于节点以最佳实践 *快速路径* 的方式加入集群，用于创建
    Kubernetes 集群。然而，Kubeadm 并不知道如何为特定云提供商配置所需的基础设施。Kubeadm 需要在将服务器转换为 Kubernetes
    节点之前，先确保服务器已经创建并配置了所需的计算、存储和网络环境。Kubeadm 在基础设施管理方面的这一空白由 **Cluster API** 填补。
- en: A TKG user would never directly use the Cluster API, but it is one of the most
    important building blocks of TKG that interfaces with and abstracts the underlying
    cloud infrastructure. The term **API** stands for **application program interface**
    – a well-known term in the field of computer programming. The Cluster API is also
    a SIG project ([https://cluster-api.sigs.k8s.io/](https://cluster-api.sigs.k8s.io/)).
    The purpose of this project is to provide an interface layer to platforms such
    as TKG to perform various Kubernetes life cycle operations, including cluster
    provisioning, upgrading, and operating. As we know, different cloud providers
    have different ways of operating their infrastructure. A virtual machine in the
    world of vSphere is called an EC2 machine in the world of AWS. A virtual network
    boundary in AWS is known as a **Virtual Private Cloud** (**VPC**) but it is called
    a **Virtual Network** (**VNet**) in Azure. The implementation of the Cluster API
    interfaces abstracts such cloud-specific terminologies and operational differences.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: TKG 用户通常不会直接使用 Cluster API，但它是 TKG 中最重要的构建模块之一，它与底层云基础设施进行交互并进行抽象。**API** 这个术语代表
    **应用程序编程接口**，这是计算机编程领域中一个广为人知的术语。Cluster API 也是一个 SIG 项目 ([https://cluster-api.sigs.k8s.io/](https://cluster-api.sigs.k8s.io/))。该项目的目的是为像
    TKG 这样的平台提供一个接口层，以执行各种 Kubernetes 生命周期操作，包括集群配置、升级和运行。正如我们所知，不同的云提供商在操作其基础设施方面有不同的方式。在
    vSphere 中，虚拟机称为 EC2 机器，而在 AWS 中，它则是 EC2 机器。在 AWS 中，虚拟网络边界称为 **虚拟私有云** (**VPC**)，但在
    Azure 中则称为 **虚拟网络** (**VNet**)。Cluster API 接口的实现通过抽象这些云特定的术语和操作差异来进行统一。
- en: To provide fully automated Kubernetes cluster life cycle management, TKG uses
    the Cluster API; the Cluster API uses Kubeadm internally. This way, TKG fully
    leverages different open source projects to provide a uniform multi-cloud Kubernetes
    cluster management experience.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提供完全自动化的 Kubernetes 集群生命周期管理，TKG 使用了 Cluster API；Cluster API 内部使用 Kubeadm。通过这种方式，TKG
    完全利用不同的开源项目，提供统一的多云 Kubernetes 集群管理体验。
- en: Carvel
  id: totrans-45
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Carvel
- en: '**Carvel** ([https://carvel.dev/](https://carvel.dev/)) is one additional open
    source package management toolkit that TKG uses for installing itself and other
    optional packages. Carvel is a very powerful and flexible packaging tool for Kubernetes
    deployments. Carvel contains multiple tools for different package management and
    deployment tasks, as listed in the following points:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**Carvel** ([https://carvel.dev/](https://carvel.dev/)) 是 TKG 用于安装自身及其他可选包的一个额外开源包管理工具包。Carvel
    是一个非常强大且灵活的 Kubernetes 部署打包工具。Carvel 包含多个用于不同包管理和部署任务的工具，如下所列：'
- en: '*kapp-controller*: To provide continuous delivery for apps and packages deployed
    on Kubernetes clusters in a GitOps way'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*kapp-controller*：以 GitOps 方式提供 Kubernetes 集群中应用和包的持续交付'
- en: '*ytt*: To create and use templatized YAML configurations for package deployment,
    allowing package configuration customization during their installations on Kubernetes
    clusters'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*ytt*：用于创建和使用模板化的 YAML 配置文件进行包部署，允许在 Kubernetes 集群安装时自定义包配置'
- en: '*kapp*: To bundle multiple Kubernetes resources as one application package
    that can be installed, upgraded, or deleted as one unit'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*kapp*：将多个 Kubernetes 资源捆绑为一个可以作为整体安装、升级或删除的应用包'
- en: '*kbld*: To build or reference container images used in the Kubernetes resource
    configuration in an immutable way'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*kbld*：以不可变的方式构建或引用 Kubernetes 资源配置中使用的容器镜像'
- en: '*imgpkg*: To package, distribute, and relocate Kubernetes configuration and
    the associated container images as one bundle'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*imgpkg*：用于打包、分发和重新定位 Kubernetes 配置及相关的容器镜像作为一个整体'
- en: '*vendir*: To declaratively state a directory’s contents'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*vendir*：声明目录的内容'
- en: '*secretgen-controller*: To manage various types of secrets used by the packages'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*secretgen-controller*：用于管理包所使用的各种类型的秘密'
- en: After learning about the interface related components of TKG, let’s review the
    core components of TKG now.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了与 TKG 相关的接口组件后，我们现在来回顾一下 TKG 的核心组件。
- en: Core components of Tanzu Kubernetes Grid
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Tanzu Kubernetes Grid 的核心组件
- en: In addition to the interfacing components that we saw previously, TKG contains
    a set of core components that are the most basic building blocks for a Kubernetes
    platform. Let’s learn about them here.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 除了之前看到的接口组件，TKG 还包含了一组核心组件，它们是 Kubernetes 平台最基本的构建模块。让我们在这里了解它们。
- en: Operating systems
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 操作系统
- en: One of the many advantages of using TKG is that you get a supported and hardened
    operating system from VMware for Kubernetes nodes. TKG supports Photon and Ubuntu
    Linux-based operating systems. Additionally, TKG allows you to build among the
    supported and a few other flavors of Linux and Windows operating systems with
    a certain level of customization.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 TKG 的众多优势之一是，您可以获得来自 VMware 的 Kubernetes 节点支持和加固的操作系统。TKG 支持基于 Photon 和 Ubuntu
    Linux 的操作系统。此外，TKG 还允许您在支持的几种 Linux 和 Windows 操作系统中构建，并提供一定的自定义功能。
- en: Kubernetes
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Kubernetes
- en: 'Kubernetes is the main ingredient of TKG. Each version of TKG includes one
    or more versions of upstream open source Kubernetes distributions without any
    modifications. This component is the main Kubernetes platform, including the main
    set of tools that make the platform. It includes the following tools:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 是 TKG 的主要组成部分。每个版本的 TKG 包括一个或多个上游开源 Kubernetes 发行版，且没有任何修改。这个组件是主要的
    Kubernetes 平台，包含了构建该平台的主要工具集。它包括以下工具：
- en: '*kube-apiserver*: An API interface for the Kubernetes control plane'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*kube-apiserver*：Kubernetes 控制平面的 API 接口'
- en: '*etcd*: A key-value store to persist the state of the Kubernetes cluster and
    its workload configuration'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*etcd*：一个键值存储，用于持久化 Kubernetes 集群的状态及其工作负载配置'
- en: '*kube-scheduler*: To host newly created pods in a node based on various selection
    criteria'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*kube-scheduler*：根据各种选择标准将新创建的 pod 安排到节点上'
- en: '*kube-controller-manager*: To run different control processes to manage nodes,
    jobs, service endpoints, and service accounts'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*kube-controller-manager*：运行不同的控制过程来管理节点、任务、服务端点和服务账户'
- en: '*cloud-controller-manager*: To run different cloud/infrastructure-specific
    processes to manage node health checks, routes, and cloud-specific service load
    balancers'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*cloud-controller-manager*：运行不同的云/基础设施特定进程，以管理节点健康检查、路由和云特定的服务负载均衡器'
- en: '*kubelet*: A node-residing agent to ensure pods’ running status and report
    back to the control plane'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*kubelet*：一种驻留在节点上的代理，确保Pod的运行状态并将其报告给控制平面'
- en: '*kube-proxy*: A node-residing network proxy that ensures service routes to
    their endpoint pods running on the node'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*kube-proxy*：一种驻留在节点上的网络代理，确保服务路由到运行在节点上的终端Pod'
- en: '*Container runtime*: A node-residing software (**containerd** in the case of
    TKG) that runs and manages containers'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*容器运行时*：一种驻留在节点上的软件（在TKG中是**containerd**），用于运行和管理容器'
- en: In addition to these core components of Kubernetes, there are a few more core
    components that TKG includes that are required for the platform to operate. Let’s
    take a look.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 除了Kubernetes的核心组件外，还有一些TKG包含的其他核心组件，平台需要这些组件才能正常运行。让我们来看看。
- en: Metrics Server
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 指标服务器
- en: Metrics Server aggregates resource usage data, such as container, node CPU,
    and memory usage, in a Kubernetes cluster and makes it available via the Metrics
    API defined in Kubernetes. This component is required to pull details after using
    the `kubectl top node` or `kubectl top` `pod` command.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 指标服务器聚合Kubernetes集群中容器、节点CPU和内存使用等资源使用数据，并通过Kubernetes中定义的指标API提供这些数据。在使用`kubectl
    top node`或`kubectl top` `pod`命令后，需要此组件来获取详细信息。
- en: Container Storage Interface (CSI)
  id: totrans-72
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 容器存储接口（CSI）
- en: '**Container Storage Interface** (**CSI**) is a Kubernetes specification that
    requires implementation from the storage infrastructure provider. This will be
    used in the Kubernetes platform to provide persistent volumes for the workloads
    that need them. It provides Kubernetes users with more options for different storage
    solutions. One Kubernetes cluster may have different types of storage, including
    **solid-state drives** (**SSDs**), **magnetic drives** (**HDDs**), and other variants
    that provide different rates of data input and output. TKG uses the infrastructure-specific
    storage driver for vSphere, AWS, or Azure.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**容器存储接口**（**CSI**）是一个Kubernetes规范，要求存储基础设施提供商进行实现。它将在Kubernetes平台中用于为需要持久存储的工作负载提供持久卷。它为Kubernetes用户提供了更多不同存储解决方案的选择。一个Kubernetes集群可以拥有不同类型的存储，包括**固态硬盘**（**SSDs**）、**机械硬盘**（**HDDs**）以及其他提供不同数据输入和输出速率的变种。TKG使用专门针对vSphere、AWS或Azure的存储驱动程序。'
- en: CoreDNS
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: CoreDNS
- en: '**CoreDNS** ([https://coredns.io/](https://coredns.io/)) is an open source
    DNS server that is used to provide Kubernetes service name resolution. The open
    source Kubernetes installs kube-dns for this purpose but allows you to replace
    kube-dns with CoreDNS, which is a more enhanced DNS server. TKG clusters get deployed
    with CoreDNS.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '**CoreDNS**（[https://coredns.io/](https://coredns.io/)）是一个开源DNS服务器，用于提供Kubernetes服务名称解析。开源的Kubernetes为此目的安装了kube-dns，但允许您用CoreDNS替换kube-dns，CoreDNS是一个更为增强的DNS服务器。TKG集群默认部署CoreDNS。'
- en: Container Network Interface (CNI)
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 容器网络接口（CNI）
- en: As per the Kubernetes networking specification, every pod in a cluster should
    have a unique IP address and should be able to communicate with other pods on
    any other node of the cluster without any **network address translation** (**NAT**).
    Additionally, all the agents running in nodes, such as kubelet, should be able
    to communicate with each pod running on their respective node. These requirements
    ensure smooth communication between apps deployed on the same cluster. However,
    we need a specific networking arrangement to implement this specification. This
    is the CNI implementation, which is also known as the overlay network for Kubernetes
    clusters. There are many CNI implementations that we can choose from to be used
    in Kubernetes clusters. Out of them, TKG supports **Antrea** ([https://antrea.io/](https://antrea.io/))
    and **Calico** ([https://www.tigera.io/project-calico/](https://www.tigera.io/project-calico/)),
    which we can choose from during platform setup.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 根据Kubernetes网络规范，集群中的每个Pod应具有唯一的IP地址，并且应能够与集群中任何其他节点上的其他Pod进行通信，而无需进行**网络地址转换**（**NAT**）。此外，运行在节点上的所有代理，例如kubelet，应该能够与其各自节点上运行的每个Pod进行通信。这些要求确保同一集群上部署的应用程序之间的顺畅通信。然而，我们需要一个特定的网络配置来实现这一规范。这就是CNI实现，也称为Kubernetes集群的覆盖网络。有许多CNI实现可供选择用于Kubernetes集群，其中TKG支持**Antrea**（[https://antrea.io/](https://antrea.io/)）和**Calico**（[https://www.tigera.io/project-calico/](https://www.tigera.io/project-calico/)），我们可以在平台设置期间选择其中之一。
- en: Control plane load balancers
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 控制平面负载均衡器
- en: TKG can create multi-master Kubernetes clusters for high availability of the
    control plane objects of a Kubernetes cluster. Such clusters typically have three
    Kubernetes control plane (master) nodes serving Kubernetes API traffic and performing
    crucial workload management activities. For a TKG deployment on AWS and Azure,
    TKG creates their respective virtual load balancer objects to front these control
    plane nodes for the API server traffic distribution. For vSphere, TKG includes
    **NSX Advanced Load Balancer** ([https://www.vmware.com/products/nsx-advanced-load-balancer.html](https://www.vmware.com/products/nsx-advanced-load-balancer.html))
    to create a virtual load balancer for the same purpose. However, if TKG is not
    configured with NSX Advanced Load Balancer on vSphere, it uses an open source
    and lightweight virtual load balancer named **kube-vip** ([https://kube-vip.io/](https://kube-vip.io/)).
    kube-vip is also a CNCF-governed project.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: TKG 可以创建多主节点的 Kubernetes 集群，以实现 Kubernetes 集群控制平面对象的高可用性。这类集群通常有三个 Kubernetes
    控制平面（主节点）节点，负责处理 Kubernetes API 流量并执行重要的工作负载管理活动。对于 AWS 和 Azure 上的 TKG 部署，TKG
    会创建各自的虚拟负载均衡器对象，将其置于这些控制平面节点前面，用于分配 API 服务器流量。对于 vSphere，TKG 包含了**NSX 高级负载均衡器**（[https://www.vmware.com/products/nsx-advanced-load-balancer.html](https://www.vmware.com/products/nsx-advanced-load-balancer.html)）来为同一目的创建虚拟负载均衡器。然而，如果
    TKG 在 vSphere 上没有配置 NSX 高级负载均衡器，它会使用一个名为 **kube-vip** 的开源轻量级虚拟负载均衡器（[https://kube-vip.io/](https://kube-vip.io/)）。kube-vip
    也是一个 CNCF 监管的项目。
- en: Extension packages of Tanzu Kubernetes Grid
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Tanzu Kubernetes Grid 的扩展包
- en: The open source Kubernetes distribution comes with the minimal components required
    to deploy a Kubernetes platform. However, to deploy a production-grade Kubernetes
    environment, we need several other capabilities, such as logging, monitoring,
    access control, backup and restore, and more. Since TKG is an enterprise-grade
    Kubernetes distribution, it also comes with many such open source extension packages
    with VMware-signed binaries. Let’s check these components out.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 开源的 Kubernetes 发行版包括部署 Kubernetes 平台所需的最小组件。然而，要部署一个生产级的 Kubernetes 环境，我们还需要一些其他的功能，例如日志记录、监控、访问控制、备份和恢复等。由于
    TKG 是一个企业级的 Kubernetes 发行版，它还附带了许多这样的开源扩展包，并提供 VMware 签名的二进制文件。让我们来了解这些组件。
- en: Logging
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 日志记录
- en: '**Fluent Bit** ([https://fluentbit.io/](https://fluentbit.io/)) is a high-performance-focused
    open source log forwarding tool for different flavors of Linux and Windows operating
    systems. Fluent Bit is also a CNCF sub-project. The purpose of this tool is to
    process logs emitted from Kubernetes nodes and the workload pods and can be configured
    to plumb them to a long list of possible log aggregation destinations, including
    Splunk, Elasticsearch, Amazon CloudWatch, Kafka, and many more.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '**Fluent Bit** （[https://fluentbit.io/](https://fluentbit.io/)）是一个高性能的开源日志转发工具，支持不同版本的
    Linux 和 Windows 操作系统。Fluent Bit 也是一个 CNCF 子项目。该工具的目的是处理从 Kubernetes 节点和工作负载 Pod
    发出的日志，并可以配置将其转发到多种日志聚合目的地，包括 Splunk、Elasticsearch、Amazon CloudWatch、Kafka 等。'
- en: Ingress controller
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: Ingress 控制器
- en: TKG supplies **Contour** ([https://projectcontour.io/](https://projectcontour.io/))
    binaries as an extended package to provide an ingress type of routing for the
    external-facing services deployed on Kubernetes clusters. Contour is an open source
    project under the CNCF umbrella that internally uses the **Envoy proxy** ([https://www.envoyproxy.io/](https://www.envoyproxy.io/)),
    another CNCF open source project. Together with Envoy (as the data plane), Contour
    (as the control plane) provides the required implementation of the ingress controller
    to provide the HTTP-level (network layer 7) service routing defined using the
    ingress resources of Kubernetes.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: TKG 提供了 **Contour** （[https://projectcontour.io/](https://projectcontour.io/)）二进制文件，作为扩展包提供用于部署在
    Kubernetes 集群上的面向外部服务的入口路由。Contour 是一个开源项目，属于 CNCF 旗下，内部使用 **Envoy 代理**（[https://www.envoyproxy.io/](https://www.envoyproxy.io/)），这是另一个
    CNCF 开源项目。结合 Envoy（作为数据平面）和 Contour（作为控制平面），提供了入口控制器所需的实现，通过 Kubernetes 的入口资源定义提供
    HTTP 层（网络层 7）服务路由。
- en: Identity and authentication
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 身份验证与认证
- en: TKG includes **Pinniped** ([https://pinniped.dev/](https://pinniped.dev/)),
    another CNCF open source project backed by VMware to provide an easy button for
    the Kubernetes cluster’s user identity and authentication management. The upstream
    Kubernetes distribution does not include any authentication mechanism and only
    provides the configuration for authorization. Hence, to allow cluster users to
    get authenticated using existing identity providers based on a **Lightweight Directory
    Access Protocol** (**LDAP**) server or **Open ID Connect** (**OIDC**), TKG supplies
    Pinniped as an extension package.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: TKG还包括了**Pinniped**（[https://pinniped.dev/](https://pinniped.dev/)），另一个由VMware支持的CNCF开源项目，用于提供Kubernetes集群用户身份和认证管理的便捷按钮。上游Kubernetes发行版不包含任何身份验证机制，仅提供授权配置。因此，TKG提供了Pinniped作为一个扩展包，允许集群用户使用基于**轻量级目录访问协议**（**LDAP**）服务器或**Open
    ID Connect**（**OIDC**）的现有身份提供者进行认证。
- en: Observability
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 可观测性
- en: For cluster observability, TKG also supplies the signed binaries for **Prometheus**
    ([https://prometheus.io/](https://prometheus.io/)) and **Grafana** ([https://github.com/grafana/grafana](https://github.com/grafana/grafana)),
    two very popular open source monitoring tools for the Kubernetes ecosystem. Here,
    Prometheus is a metrics aggregator engine and Grafana is a metrics rendering tool
    for visualization. In addition to these *batteries included* monitoring tools,
    TKG also supports first-class integration with VMware Aria operations for Applications,
    a **Software-as-a-Service** (**SaaS**) platform in the VMware portfolio, for more
    capabilities around scaling, functionality, and power for full stack observability.
    We will cover this product in detail in [*Chapter 10*](B18145_10.xhtml#_idTextAnchor193),
    *Realizing Full-Stack Visibility with VMware Aria Operations* *for Applications*.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 对于集群的可观测性，TKG还提供了**Prometheus**（[https://prometheus.io/](https://prometheus.io/)）和**Grafana**（[https://github.com/grafana/grafana](https://github.com/grafana/grafana)）的签名二进制文件，这两个在Kubernetes生态系统中非常流行的开源监控工具。在这里，Prometheus是一个指标聚合引擎，而Grafana是用于可视化的指标渲染工具。除了这些*内置的*监控工具外，TKG还支持与VMware
    Aria Operations for Applications进行一流集成，这是VMware组合中的**软件即服务**（**SaaS**）平台，提供更多关于扩展、功能和全栈可观测性的能力。我们将在[*第10章*](B18145_10.xhtml#_idTextAnchor193)*，使用VMware
    Aria Operations实现全栈可见性* *详细介绍此产品*。
- en: Container registry
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 容器注册表
- en: TKG also comes with **Harbor**, a purpose-built container registry, as an extended
    package that can be installed in the cluster if required. We covered Harbor extensively
    in [*Chapter 6*](B18145_06.xhtml#_idTextAnchor112)*, Managing Container Images*
    *with Harbor*.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: TKG还包含了**Harbor**，一个专为容器注册表的定制扩展包，如果需要，可以在集群中安装。我们在[*第6章*](B18145_06.xhtml#_idTextAnchor112)*，使用Harbor管理容器镜像*
    *详细介绍了Harbor*。
- en: Backup and restore
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 备份和恢复
- en: Disaster recovery is a very important aspect of platform-supporting production
    applications. A Kubernetes cluster is not any different running critical production
    workloads. However, Kubernetes does not include anything to back up and restore
    the state of the workloads running on its clusters. To fill this gap, TKG includes
    **Velero** ([https://velero.io/](https://velero.io/)) as an extension package
    in the bundle. Velero is also an open source project under the CNCF umbrella.
    Velero provides ways to take backups and restore them later at the cluster level,
    Kubernetes namespace level, or for specific workloads based on their attached
    metadata. Velero can also take backups of the persistent volumes containing stateful
    application data and restore them when required. This is the tool that is used
    under the hood of Tanzu Mission Control for backup and recovery features. We will
    cover this in detail in *Chapter 9**, Managing and Controlling Kubernetes Clusters
    with Tanzu* *Mission Control*.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 灾难恢复是支持生产应用的平台中非常重要的一个方面。Kubernetes集群运行关键生产工作负载时也不例外。然而，Kubernetes本身并未包含任何用于备份和恢复其集群中工作负载状态的工具。为填补这一空白，TKG在捆绑包中包含了**Velero**（[https://velero.io/](https://velero.io/)），作为一个扩展包。Velero也是一个CNCF项目下的开源项目。Velero提供了在集群级别、Kubernetes命名空间级别或基于附加元数据的特定工作负载级别进行备份和稍后恢复的方法。Velero还可以对包含有状态应用数据的持久卷进行备份和在需要时进行恢复。这是在Tanzu
    Mission Control中用于备份和恢复功能的工具。我们将在*第9章*详细介绍，*使用Tanzu管理和控制Kubernetes集群*。
- en: ExternalDNS
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: ExternalDNS
- en: TKG also supplies **ExternalDNS** ([https://github.com/kubernetes-sigs/external-dns](https://github.com/kubernetes-sigs/external-dns)),
    an open source Kubernetes SIG project, as an extension package. ExternalDNS allows
    you to control the DNS records dynamically for the external-facing services deployed
    on the cluster using a Kubernetes resource definition file in a way that is agnostic
    to a DNS provider. The external services running on a Kubernetes cluster can get
    the required DNS record binding handled by ExternalDNS on a linked DNS server
    such as AWS Route53 or Google Cloud DNS. In a way, it provides a way to control
    external DNS configurations using Kubernetes resource definitions.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: TKG 还提供了**ExternalDNS** ([https://github.com/kubernetes-sigs/external-dns](https://github.com/kubernetes-sigs/external-dns))，这是一个开源的
    Kubernetes SIG 项目，作为扩展包使用。ExternalDNS 允许你动态控制集群中部署的外部服务的 DNS 记录，使用 Kubernetes
    资源定义文件的方式，独立于 DNS 提供商。运行在 Kubernetes 集群上的外部服务可以通过 ExternalDNS 在连接的 DNS 服务器（如 AWS
    Route53 或 Google Cloud DNS）上处理所需的 DNS 记录绑定。可以说，它提供了一种使用 Kubernetes 资源定义来控制外部 DNS
    配置的方式。
- en: cert-manager
  id: totrans-96
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: cert-manager
- en: '**cert-manager** ([https://cert-manager.io/](https://cert-manager.io/)) is
    another CNCF open source project that TKG includes as an extension to manage X.509
    (identity) certificates used in a Kubernetes cluster. cert-manager obtains certificates
    from a variety of configured certificate issuers, ensures certificate validity,
    and tries to renew them before expiry.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '**cert-manager** ([https://cert-manager.io/](https://cert-manager.io/)) 是另一个
    CNCF 开源项目，TKG 将其作为扩展包来管理 Kubernetes 集群中使用的 X.509（身份）证书。cert-manager 从多种配置的证书颁发机构获取证书，确保证书的有效性，并在证书到期前尝试自动续期。'
- en: Now that we have seen what components TKG contains, let’s learn about some of
    the important concepts of this platform.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 TKG 包含的组件，接下来我们来学习这个平台的一些重要概念。
- en: Important concepts of Tanzu Kubernetes Grid
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Tanzu Kubernetes Grid 的重要概念
- en: TKG is a distributed system with several moving parts. To understand how TKG
    works, we need to learn a few concepts of this system. Let’s take a look.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: TKG 是一个分布式系统，包含多个组成部分。为了理解 TKG 的工作原理，我们需要了解这个系统的一些概念。让我们来看看。
- en: Bootstrap cluster
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 启动集群
- en: As discussed earlier in this chapter, TKG uses a kind cluster to deploy a TKG
    foundation on the selected infrastructure. This kind cluster is very small and
    runs in a Docker container in the operator’s workstation, which is typically a
    personal computer. This kind cluster contains the required machinery, including
    the Tanzu installation portal and other components that help bootstrap a TKG foundation.
    Because of this, this kind cluster is also known as a bootstrap cluster.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如本章前面所述，TKG 使用一个 kind 集群在选定的基础设施上部署 TKG 基础平台。这个 kind 集群非常小，运行在操作员的工作站中的 Docker
    容器里，通常是个人电脑。这个 kind 集群包含所需的设备，包括 Tanzu 安装门户和其他帮助启动 TKG 基础平台的组件。正因为如此，这个 kind 集群也被称为启动集群（bootstrap
    cluster）。
- en: Tanzu Kubernetes releases (TKrs)
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Tanzu Kubernetes 版本（TKrs）
- en: A TKG deployment may support multiple different versions of Kubernetes. A TKr
    is a custom resource definition under TKG that contains a reference to one such
    Kubernetes version that TKG can deploy and manage. TKrs include components such
    as Antrea with its linked version definition for the given Kubernetes version.
    The management cluster of TKG runs a TKr controller that keeps checking the public
    registry for a new Kubernetes version availability. Once a new version is available,
    the TKr controller downloads the required artifacts on the TKG management cluster
    to make it available for use. This way, one TKG management cluster may deploy
    and manage multiple versions of Kubernetes clusters supported under that TKG version.
    This arrangement provides flexibility to different teams wanting to run their
    applications on different Kubernetes versions that are still managed by the same
    TKG control plane.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: TKG 部署可能支持多个不同版本的 Kubernetes。TKr 是 TKG 下的一个自定义资源定义，包含一个 Kubernetes 版本的引用，TKG
    可以部署和管理该版本。TKr 包括组件，如 Antrea 及其与给定 Kubernetes 版本相关的版本定义。TKG 的管理集群运行一个 TKr 控制器，持续检查公共注册表中是否有新的
    Kubernetes 版本可用。一旦新版本可用，TKr 控制器会在 TKG 管理集群中下载所需的工件，以供使用。通过这种方式，一个 TKG 管理集群可以部署和管理多个
    Kubernetes 版本，这些版本都在该 TKG 版本下受到支持。这样的安排为不同的团队提供了灵活性，允许他们在不同版本的 Kubernetes 上运行自己的应用，同时仍由同一个
    TKG 控制平面进行管理。
- en: Management cluster
  id: totrans-105
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 管理集群
- en: 'Every TKG foundation has one management cluster. A management cluster is nothing
    but a Kubernetes cluster running specific workloads used to life cycle other Kubernetes
    clusters. A TKG foundation and thus its management cluster is infrastructure specific.
    Because of that, we need one management cluster for vSphere, one for AWS, and
    one for Azure if we want to deploy TKG clusters on all the platforms. This is
    because a management cluster contains underlying cloud-specific Cluster API configuration.
    This way, a management cluster can create multiple Kubernetes workload clusters
    on the same cloud platform where it is deployed. In addition to creating, scaling,
    upgrading, and deleting a Kubernetes cluster, the management cluster also keeps
    track of the actual versus the desired state of the Kubernetes cluster nodes if
    it is configured to do so. The management cluster restarts or recreates an unhealthy
    or missing node from a cluster it manages. A management cluster is just a normal
    Kubernetes cluster and can also run any custom app, but it should only be used
    for its main purpose, which is to operate a large number of Kubernetes clusters.
    Its access and permission should be very much restrictive to the TKG platform
    operations team considering the level of access it has over other Kubernetes clusters
    managed by it. The TKG platform operators may give limited access to a management
    cluster using Kubernetes namespaces under the management cluster. This way, different
    teams can use the same management cluster to life cycle their Kubernetes clusters
    linked with a specific namespace of the management cluster. In addition to the
    upstream Kubernetes components, a TKG management cluster has the following TKG-specific
    components deployed into it:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 TKG 基础设施都有一个管理集群。管理集群仅仅是一个运行特定工作负载的 Kubernetes 集群，用于管理其他 Kubernetes 集群的生命周期。一个
    TKG 基础设施及其管理集群是与基础设施相关的。因此，如果我们想在所有平台上部署 TKG 集群，我们需要为 vSphere、AWS 和 Azure 各自配置一个管理集群。这是因为管理集群包含底层特定云平台的集群
    API 配置。通过这种方式，管理集群可以在其部署的同一云平台上创建多个 Kubernetes 工作负载集群。除了创建、扩展、升级和删除 Kubernetes
    集群之外，管理集群还会跟踪 Kubernetes 集群节点的实际状态与期望状态之间的差异（如果配置了此功能）。管理集群会重启或重新创建它所管理的集群中的不健康或丢失的节点。管理集群只是一个正常的
    Kubernetes 集群，也可以运行任何自定义应用，但它应该仅用于其主要目的，即操作大量的 Kubernetes 集群。考虑到它对其他 Kubernetes
    集群的管理权限，管理集群的访问权限应该严格限制在 TKG 平台操作团队中。TKG 平台操作人员可以通过在管理集群下使用 Kubernetes 命名空间来授予管理集群有限的访问权限。这样，不同的团队可以使用相同的管理集群来管理与特定命名空间关联的
    Kubernetes 集群的生命周期。除了上游 Kubernetes 组件外，TKG 管理集群还部署了以下 TKG 特定组件：
- en: Cluster API components
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群 API 组件
- en: cert-manager
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: cert-manager
- en: secretgen-controller
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: secretgen-controller
- en: kapp-controller
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kapp-controller
- en: tkr-controller
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: tkr-controller
- en: Workload cluster
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 工作负载集群
- en: A workload cluster is a normal Kubernetes cluster created by a management cluster.
    A workload cluster is where we deploy our apps. Depending on the organization’s
    practices and scale, different teams and their application environments may use
    separate workload clusters. The size in terms of the number of nodes in a workload
    cluster is only limited to the infrastructure availability. However, it is recommended
    to keep a cluster size as small as possible to reduce the blast radius if something
    goes wrong and for quicker maintenance time. TKG makes it very easy to manage
    many Kubernetes clusters. As we discussed previously, workload clusters under
    a management cluster may have different supported versions of Kubernetes based
    on the requirements of the teams using them.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 工作负载集群是由管理集群创建的正常 Kubernetes 集群。工作负载集群是我们部署应用程序的地方。根据组织的实践和规模，不同的团队及其应用环境可能会使用独立的工作负载集群。工作负载集群的节点数量仅受基础设施可用性的限制。然而，建议将集群规模保持尽可能小，以减少出现问题时的影响范围，并加快维护时间。TKG
    使得管理多个 Kubernetes 集群变得非常简单。正如我们之前讨论的那样，管理集群下的工作负载集群可能会根据使用它们的团队的需求，支持不同版本的 Kubernetes。
- en: Node pool
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 节点池
- en: A TKG cluster may have different types of worker nodes that have different configurations
    and resources attached to a cluster. Such heterogeneous node types allow different
    kinds of workloads to leverage them for specific resource requirements or just
    for isolation purposes. For example, a workload cluster may have some number of
    nodes with a consumable **graphical processing unit** (**GPU**) that can be utilized
    by extremely compute-hungry machine learning workloads deployed on the cluster.
    We can add such different types of nodes to a workload cluster using **node pools**
    in TKG. Later, we can configure such nodes with taints and tolerations to only
    allow the workloads that need to use certain types of nodes to be scheduled.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 TKG 集群可能有不同类型的工作节点，这些节点具有不同的配置和附加的资源。这样的异构节点类型使得不同类型的工作负载可以根据特定的资源需求或仅为了隔离目的来利用它们。例如，一个工作负载集群可能有一些带有可用
    **图形处理单元**（**GPU**）的节点，这些节点可以被极度依赖计算的机器学习工作负载使用。我们可以通过 TKG 中的 **节点池** 将这些不同类型的节点添加到工作负载集群中。之后，我们可以配置这些节点的污点和容忍度，以便只允许需要使用某些类型节点的工作负载进行调度。
- en: Deployment topologies
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署拓扑
- en: 'TKG supports two different deployment topologies for creating the management
    and workload clusters:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: TKG 支持两种不同的部署拓扑，用于创建管理集群和工作负载集群：
- en: '**Dev Plan**: In this topology, TKG creates a single control plane node and
    the required number of worker nodes. This plan is used for non-critical deployments
    that can tolerate the unavailability of the Kubernetes API server, etcd, and other
    control plane functions. This topology requires fewer resources and is typically
    used for lab environments.'
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**开发计划**：在此拓扑中，TKG 创建一个控制平面节点和所需数量的工作节点。此计划用于非关键性部署，可以容忍 Kubernetes API 服务器、etcd
    和其他控制平面功能的不可用。该拓扑需要较少的资源，通常用于实验环境。'
- en: '**Prod Plan**: In this topology, TKG creates three control plane nodes and
    fronts them with a load balancer to provide a highly available Kubernetes control
    plane. As the name suggests, it is used for clusters that will host critical workloads
    and may not tolerate any control plane downtime for cluster operations.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**生产计划**：在此拓扑中，TKG 创建三个控制平面节点，并通过负载均衡器将其前置，提供高可用的 Kubernetes 控制平面。如其名所示，它用于承载关键工作负载的集群，并且不能容忍任何控制平面停机。'
- en: '*Figure 7**.3* shows how TKG works at a high level. As shown in this figure,
    an operator uses either the `tanzu` CLI or the TKG bootstrap UI to supply the
    required configuration for the foundation. Once the management cluster has been
    created, the operator can directly use it to create the required number of workload
    clusters:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 7.3* 显示了 TKG 在高层次上的工作原理。如图所示，操作员使用 `tanzu` CLI 或 TKG 引导 UI 提供基础设施所需的配置。一旦管理集群创建完成，操作员可以直接使用它来创建所需数量的工作负载集群：'
- en: '![Figure 7.3 – TKG layout](img/B18145_07_03.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3 – TKG 布局](img/B18145_07_03.jpg)'
- en: Figure 7.3 – TKG layout
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3 – TKG 布局
- en: In the next section, we will learn how to create a TKG management cluster on
    AWS and understand the operation flow in detail.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习如何在 AWS 上创建 TKG 管理集群，并详细了解操作流程。
- en: Getting started with Tanzu Kubernetes Grid
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开始使用 Tanzu Kubernetes Grid
- en: 'TKG, being a multi-cloud solution, can be installed on a vSphere-based on-premises
    environment, or Microsoft Azure and **Amazon Web Services** (**AWS**)-based public
    cloud platforms. To keep this chapter to an acceptable length, we will only cover
    how to install and configure a TKG foundation on AWS. You may find additional
    TKG installation and configuration details here: [https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-prepare-deployment.html](https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-prepare-deployment.html).'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个多云解决方案，TKG 可以安装在基于 vSphere 的本地环境中，或者在 Microsoft Azure 和 **亚马逊 Web 服务**（**AWS**）等公有云平台上。为了保持本章的长度适中，我们将仅介绍如何在
    AWS 上安装和配置 TKG 基础设施。您可以在此链接中找到更多 TKG 安装和配置的详细信息：[https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-prepare-deployment.html](https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-mgmt-clusters-prepare-deployment.html)。
- en: 'We will perform the following tasks in this section:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将执行以下任务：
- en: Configure the bootstrap machine – the operator workstation from where the installation
    will be triggered
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置引导机器 —— 安装将从中触发的操作员工作站
- en: Deploy the TKG management cluster
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署 TKG 管理集群
- en: Create a TKG workload cluster using the management cluster
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用管理集群创建 TKG 工作负载集群
- en: Obtain access to the workload cluster
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 获取访问工作负载集群的权限
- en: But before we do that, we need to ensure that the following prerequisites are
    met to complete these tasks.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 但在我们开始之前，我们需要确保满足以下前提条件，以完成这些任务。
- en: Prerequisites
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 前提条件
- en: 'The following are the prerequisites to follow the TKG installation instructions
    given in this section:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是遵循本节中 TKG 安装说明的前提条件：
- en: 'An AWS account with the following:'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 AWS 账户，包含以下内容：
- en: An access key and an access key secret
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个访问密钥和访问密钥的秘密
- en: An SSH key pair registered with the account for the region where TKG is being
    installed
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 注册了用于 TKG 安装区域的 SSH 密钥对
- en: Permission to create a CloudFormation stack that defines **Identity and Access
    Management** (**IAM**) resources and their permissions
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有权限创建一个 CloudFormation 堆栈，该堆栈定义了**身份与访问管理**（**IAM**）资源及其权限
- en: A sufficient resource quota that’s allowed to create two **Virtual Private Clouds**
    (**VPCs**), nine subnets (two internet-facing and one internal per availability
    zone) in the VPC, four EC2 security groups, two internet gateways, three NAT gateways,
    and three Elastic IP addresses in the selected region for TKG deployment
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 足够的资源配额，允许在选定区域中创建两个**虚拟私有云**（**VPC**）、九个子网（每个可用区两个互联网-facing 和一个内部）、四个 EC2
    安全组、两个互联网网关、三个 NAT 网关和三个弹性 IP 地址用于 TKG 部署
- en: 'A Linux or Mac workstation with the following:'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台运行以下配置的 Linux 或 Mac 工作站：
- en: Internet access
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 互联网访问
- en: Command-line access
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命令行访问
- en: Web browser access
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: Web 浏览器访问
- en: Port `6443` access to all the EC2 instances to access Kubernetes APIs
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有 EC2 实例对端口`6443`的访问权限，以访问 Kubernetes APIs
- en: Docker Desktop installed and running with 6 GB allocated
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已安装并运行 Docker Desktop，分配了 6 GB 内存
- en: 2-core CPU
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2 核 CPU
- en: The kubectl CLI v1.22 or higher
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: kubectl CLI v1.22 或更高版本
- en: Access to a **Network Time Protocol** (**NTP**) server
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问**网络时间协议**（**NTP**）服务器
- en: Access to [https://my.vmware.com/](https://my.vmware.com/) with an account set
    up to download the required binaries
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问 [https://my.vmware.com/](https://my.vmware.com/) 并设置账户以下载所需的二进制文件
- en: Let’s start with the first task, which is to prepare the bootstrap machine that
    will be used for this installation. We will need a few tools and environmental
    configurations before we begin the installation.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从第一个任务开始，那就是准备将用于此安装的引导机器。在开始安装之前，我们需要一些工具和环境配置。
- en: Configuring the bootstrap machine
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置引导机器
- en: The following sub-tasks prepare a bootstrap machine with the required tools
    and configuration for TKG setup on AWS.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 以下子任务为 AWS 上的 TKG 安装准备一个配置了所需工具和设置的引导机器。
- en: Installing Tanzu and the Kubectl CLI
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 Tanzu 和 Kubectl CLI
- en: 'Follow these steps:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤操作：
- en: 'Create a directory on your local machine where you will store the required
    artifacts:'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本地计算机上创建一个目录，用于存储所需的文件：
- en: '[PRE0]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Go to [https://my.vmware.com/](https://my.vmware.com/) and log in using your
    My VMware credentials.
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 [https://my.vmware.com/](https://my.vmware.com/) 并使用您的 My VMware 凭证登录。
- en: Go to [https://customerconnect.vmware.com/downloads/details?downloadGroup=TKG-154&productId=1162](https://customerconnect.vmware.com/downloads/details?downloadGroup=TKG-154&productId=1162)
    to download the required artifacts.
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 访问 [https://customerconnect.vmware.com/downloads/details?downloadGroup=TKG-154&productId=1162](https://customerconnect.vmware.com/downloads/details?downloadGroup=TKG-154&productId=1162)
    下载所需的文件。
- en: 'Make sure that the selected version in the dropdown is **1.5.4**:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保下拉菜单中选择的版本是**1.5.4**：
- en: '![Figure 7.4 – Selecting a download version](img/B18145_07_04.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.4 – 选择下载版本](img/B18145_07_04.jpg)'
- en: Figure 7.4 – Selecting a download version
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4 – 选择下载版本
- en: 'Under the **Product Downloads** tab, scroll to the **VMware Tanzu CLI 1.5.4**
    section and download the binary for your operating system. Note that the procedure
    followed in this chapter is being done on a macOS machine. While most of the commands
    listed in this chapter should work on the other platforms, there could be some
    minor differences:'
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在**产品下载**标签下，滚动至**VMware Tanzu CLI 1.5.4**部分并下载适用于您操作系统的二进制文件。请注意，本章所采用的操作步骤是在
    macOS 机器上进行的。虽然本章中列出的大多数命令在其他平台上也应有效，但可能会有一些小的差异：
- en: '![Figure 7.5 – Downloading the appropriate Tanzu CLI](img/B18145_07_05.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.5 – 下载适当的 Tanzu CLI](img/B18145_07_05.jpg)'
- en: Figure 7.5 – Downloading the appropriate Tanzu CLI
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5 – 下载适当的 Tanzu CLI
- en: 'Accept the End User License Agreement:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接受最终用户许可协议：
- en: '![Figure 7.6 – Accepting the End User License Agreement](img/B18145_07_06.jpg)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.6 – 接受最终用户许可协议](img/B18145_07_06.jpg)'
- en: Figure 7.6 – Accepting the End User License Agreement
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6 – 接受最终用户许可协议
- en: Download the binary into the `$HOME/tkg-154` directory that we created in *step
    1*.
  id: totrans-167
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将二进制文件下载到我们在 *第 1 步* 中创建的 `$HOME/tkg-154` 目录。
- en: 'Now, on the same page when you downloaded the binaries, go to the **Kubectl
    1.22.9 for VMware Tanzu Kubernetes Grid** **1.5.4** section:'
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在你下载二进制文件的同一页面，进入 **Kubectl 1.22.9 for VMware Tanzu Kubernetes Grid** **1.5.4**
    部分：
- en: '![Figure 7.7 – Downloading the appropriate Kubectl CLI](img/B18145_07_07.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.7 – 下载适当的 Kubectl CLI](img/B18145_07_07.jpg)'
- en: Figure 7.7 – Downloading the appropriate Kubectl CLI
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7 – 下载适当的 Kubectl CLI
- en: Download the binary into the same `$``HOME/tkg-154` directory.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将二进制文件下载到相同的 `$``HOME/tkg-154` 目录。
- en: 'Go into the `$HOME/tkg-154` directory and extract the CLI binaries you downloaded
    previously. Run the following commands to do this:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入 `$HOME/tkg-154` 目录，并解压你之前下载的 CLI 二进制文件。运行以下命令进行此操作：
- en: '[PRE1]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[PRE2]'
  id: totrans-174
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Install the Tanzu CLI on you local system:'
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在本地系统上安装 Tanzu CLI：
- en: '[PRE4]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Verify the installation by running the following command:'
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令验证安装：
- en: '[PRE5]'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: You should see version 0.11.6 in the output.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在输出中看到版本 0.11.6。
- en: 'Initialize the Tanzu CLI:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 初始化 Tanzu CLI：
- en: '[PRE6]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Clean up any pre-existing Tanzu plugins for a clean start:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 清理任何现有的 Tanzu 插件，以便从头开始：
- en: '[PRE7]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Make sure you are under the `$HOME/tkg-154` directory, which contains the extracted
    `cli` directory:'
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你在 `$HOME/tkg-154` 目录下，该目录包含解压的 `cli` 目录：
- en: '[PRE8]'
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Run the following command to install all the required plugins for this TKG
    release:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令安装此 TKG 版本所需的所有插件：
- en: '[PRE9]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'You should be able to see the following output for the command’s execution:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够看到以下命令执行的输出：
- en: '[PRE10]'
  id: totrans-190
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Verify the plugin’s installation status by running the following command:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令验证插件的安装状态：
- en: '[PRE11]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You should be able to see all the plugins listed, along with their versions
    and statuses, as shown in the following screenshot:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够看到所有插件列出，包括它们的版本和状态，如下图所示：
- en: '![Figure 7.8 – Installed TKG plugin list](img/B18145_07_08.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.8 – 已安装的 TKG 插件列表](img/B18145_07_08.jpg)'
- en: Figure 7.8 – Installed TKG plugin list
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.8 – 已安装的 TKG 插件列表
- en: Now, let’s install the Kubectl CLI.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们安装 Kubectl CLI。
- en: 'Run the following commands from the `$HOME/tkg-154` directory, which is where
    we downloaded and extracted the Kubectl CLI:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 `$HOME/tkg-154` 目录运行以下命令，这里是我们下载并解压 Kubectl CLI 的地方：
- en: '[PRE12]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[PRE13]'
  id: totrans-199
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Verify the installation by running the `kubectl version` command. You should
    see the client version as v1.22.9+vmware.1.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行 `kubectl version` 命令验证安装。你应该看到客户端版本为 v1.22.9+vmware.1。
- en: Installing Carvel tools
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 Carvel 工具
- en: 'As we discussed in the previous section, TKG uses the Carvel toolkit for its
    packaging and installation. For that reason, we will need some of the Carvel tool’s
    CLI binaries installed in the bootstrap machine. The Tanzu CLI bundle that we
    previously downloaded and extracted contains all these tools. The following steps
    describe the procedure to install them:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中讨论的，TKG 使用 Carvel 工具包进行打包和安装。因此，我们需要在引导机上安装一些 Carvel 工具的 CLI 二进制文件。我们之前下载并解压的
    Tanzu CLI 包含了所有这些工具。以下步骤描述了安装这些工具的过程：
- en: 'Go to the `cli` directory under `$HOME/tkg-154`:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入 `$HOME/tkg-154` 下的 `cli` 目录：
- en: '[PRE14]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Install **ytt** with the following commands:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令安装 **ytt**：
- en: '[PRE15]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-207
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '[PRE17]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Verify the `ytt --``version` command.
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证 `ytt --``version` 命令。
- en: 'Install **kapp** with the following commands:'
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令安装 **kapp**：
- en: '[PRE18]'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: '[PRE19]'
  id: totrans-212
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: '[PRE20]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Verify the `kapp --``version` command.
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证 `kapp --``version` 命令。
- en: 'Install **kbld** with the following commands:'
  id: totrans-215
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令安装 **kbld**：
- en: '[PRE21]'
  id: totrans-216
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: '[PRE22]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-218
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: Verify the `kbld --``version` command.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证 `kbld --``version` 命令。
- en: 'Install **imgpkg** with the following commands:'
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令安装 **imgpkg**：
- en: '[PRE24]'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '[PRE26]'
  id: totrans-223
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Verify the `imgpkg --``version` command.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证 `imgpkg --``version` 命令。
- en: Installing AWS-specific tools
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 AWS 特定工具
- en: 'Deploying a TKG foundation on the AWS platform requires the **aws** CLI to
    be installed on the bootstrap machine. Let’s configure this:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AWS 平台上部署 TKG 基础设施需要在引导机上安装 **aws** CLI。让我们进行配置：
- en: Install the **aws** CLI using the instructions provided at [https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html).
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下说明安装 **aws** CLI：[https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html](https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)。
- en: 'Verify the installation of the **aws** CLI by running the following command:'
  id: totrans-228
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令验证 **aws** CLI 的安装：
- en: '[PRE27]'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You should be able to see the CLI version listed, as shown in the following
    output. The version could be different in your case, depending on when it is installed,
    but it should be v2.x:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该能够看到 CLI 版本，如下所示的输出。版本可能会有所不同，取决于安装时的时间，但应该是 v2.x 版本：
- en: '[PRE28]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Run the following command to configure the access profile for your AWS account
    to be used for this installation with the previously defined permissions and quotas:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令，配置你的 AWS 账户访问配置文件，以便用于此次安装，且具有先前定义的权限和配额：
- en: '[PRE29]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Supply the values of the access key, secret access key, region, and command
    output format, as shown in the following code:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供访问密钥、秘密访问密钥、区域和命令输出格式的值，如下所示的代码：
- en: '[PRE30]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: '[PRE31]'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: '[PRE32]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: '[PRE33]'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Here, you may replace `us-east-1` with any other AWS region of your choice with
    the previously listed prerequisites fulfilled.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，你可以将 `us-east-1` 替换为任何其他符合先前列出要求的 AWS 区域。
- en: 'Run the following command to ensure you can see the existing SSH key pair in
    the region as it was listed in the prerequisites:'
  id: totrans-240
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令，确保你能看到该区域中列出的现有 SSH 密钥对，如先前要求中所列：
- en: '[PRE34]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE34]'
- en: This command’s output should show at least one key pair listed.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令的输出应至少显示列出的一个密钥对。
- en: We now have all the required tools configured in the bootstrap machine to begin
    installing the TKG management cluster. Let’s begin.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经在引导机器上配置了所有所需的工具，可以开始安装 TKG 管理集群了。让我们开始吧。
- en: Installing the management cluster
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装管理集群
- en: In this section, we will use the Tanzu installer UI to deploy the management
    cluster on the configured AWS account.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 Tanzu 安装程序 UI 在配置好的 AWS 账户上部署管理集群。
- en: Important note
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'By default, the upstream Kubernetes distribution does not come with user authentication
    capabilities and allows the user to have admin-level access. To fill this gap,
    TKG comes with Pinniped to integrate an external LDAP or OIDC identity provider.
    To minimize installation prerequisites and complexity, we will not use such an
    integration, which requires a pre-existing LDAP or OIDC setup access. A real-life
    TKG cluster should never be configured without such integration with an external
    identity provider. You can learn more about this topic here: [https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-iam-configure-id-mgmt.html](https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-iam-configure-id-mgmt.html).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，上游 Kubernetes 发行版不包含用户身份验证功能，并且允许用户拥有管理员级别的访问权限。为了填补这一空白，TKG 配备了 Pinniped，用于集成外部
    LDAP 或 OIDC 身份提供者。为了简化安装前提条件和复杂度，我们将不使用此类集成，因为它需要预先配置好的 LDAP 或 OIDC 设置访问。现实中的
    TKG 集群绝不应在没有外部身份提供者集成的情况下配置。你可以在此了解更多相关内容：[https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-iam-configure-id-mgmt.html](https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-iam-configure-id-mgmt.html)。
- en: Additionally, despite aiming for minimal complexity and an infrastructure footprint,
    following this **TKG configuration on AWS will incur cloud service usage charges
    in your AWS account** as it will use the EC2 instance types that are not qualified
    for the free-tier credits, along with some other chargeable services such as Elastic
    IP, NAT gateways, EBS volumes, Elastic Load Balancers, and a few others. If you
    plan to follow this guide to install TKG on AWS, it is recommended that you also
    clean up the resources using the procedure described later in this chapter, followed
    by a manual inspection to verify the removal of all provisioned resources.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，尽管旨在最小化复杂性和基础设施占用，但遵循此**在 AWS 上配置 TKG 会产生云服务使用费用**，因为它将使用不符合免费额度资格的 EC2 实例类型，并且还会使用一些其他收费服务，如
    Elastic IP、NAT 网关、EBS 卷、Elastic Load Balancer 等。如果你计划按照本指南在 AWS 上安装 TKG，建议你在本章稍后的过程中清理资源，并手动检查以验证所有配置的资源已被移除。
- en: 'The following steps outline the installation procedure:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤概述了安装过程：
- en: Ensure the local Docker daemon is running to deploy and run containers on the
    bootstrap machine.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保本地的 Docker 守护进程正在运行，以便在引导机器上部署和运行容器。
- en: 'Run the following command to start the installer UI in the default browser
    window of the bootstrap workstation. This UI supports Chrome, Safari, Firefox,
    Internet Explorer, and Edge, along with their considerably newer versions:'
  id: totrans-251
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令以在引导工作站的默认浏览器窗口中启动安装程序 UI。此 UI 支持 Chrome、Safari、Firefox、Internet Explorer
    和 Edge，以及它们的较新版本：
- en: '[PRE35]'
  id: totrans-252
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: This command should automatically open the browser window with the UI running.
    Otherwise, it can be accessed using `http://127.0.0.1:8080/`.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令应自动打开浏览器窗口并运行 UI。否则，可以通过 `http://127.0.0.1:8080/` 访问。
- en: 'Click on the **DEPLOY** button under **Amazon Web Services**, as highlighted
    in the following screenshot:'
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**Amazon Web Services**下的**DEPLOY**按钮，如下图所示：
- en: '![Figure 7.9 – Selecting Amazon Web Services for deployment](img/B18145_07_09.jpg)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.9 – 选择用于部署的 Amazon Web Services](img/B18145_07_09.jpg)'
- en: Figure 7.9 – Selecting Amazon Web Services for deployment
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9 – 选择用于部署的 Amazon Web Services
- en: 'Select the necessary AWS account details by following these sub-steps; these
    are highlighted in the following screenshot:'
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下子步骤选择必要的 AWS 账户详细信息；这些已在下图中突出显示：
- en: Set **AWS CREDENTIAL TYPE** to **Credential Profile**.
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将**AWS CREDENTIAL TYPE**设置为**Credential Profile**。
- en: Select **tkg** from the **AWS CREDENTIAL PROFILE** dropdown and its associated
    **REGION** that we configured during the **aws** CLI setup earlier in this chapter.
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 **AWS CREDENTIAL PROFILE** 下拉菜单中选择 **tkg**，并选择我们在本章 **aws** CLI 配置期间配置的相关
    **REGION**。
- en: Click the **CONNECT** button to ensure the UI can connect to the select AWS
    account using the previously created configuration.
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**CONNECT**按钮，以确保 UI 能通过先前创建的配置连接到选定的 AWS 账户。
- en: 'Click the **NEXT** button to move to the next configuration section:'
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**NEXT**按钮进入下一个配置部分：
- en: '![Figure 7.10 – Selecting an AWS account for the installation](img/B18145_07_10.jpg)'
  id: totrans-262
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.10 – 选择用于安装的 AWS 账户](img/B18145_07_10.jpg)'
- en: Figure 7.10 – Selecting an AWS account for the installation
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10 – 选择用于安装的 AWS 账户
- en: 'Click the **NEXT** button to choose the default VPC configuration, as shown
    in the following screenshot:'
  id: totrans-264
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**NEXT**按钮选择默认的 VPC 配置，如下图所示：
- en: '![Figure 7.11 – Choosing the default VPC configuration](img/B18145_07_11.jpg)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.11 – 选择默认 VPC 配置](img/B18145_07_11.jpg)'
- en: Figure 7.11 – Choosing the default VPC configuration
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11 – 选择默认 VPC 配置
- en: 'Set the management cluster deployment plan to **Development** and **INSTANCE
    TYPE** to **t3.large**. This instance type has 2 vCPUs and 8 GiB memory, which
    is just good enough for a lab-like setup:'
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将管理集群部署计划设置为**开发**，并将**实例类型**设置为**t3.large**。此实例类型具有 2 个 vCPU 和 8 GiB 内存，足够用于实验室级别的设置：
- en: '![Figure 7.12 – Selecting the management cluster’s deployment plan and instance
    type](img/B18145_07_12.jpg)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.12 – 选择管理集群的部署计划和实例类型](img/B18145_07_12.jpg)'
- en: Figure 7.12 – Selecting the management cluster’s deployment plan and instance
    type
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12 – 选择管理集群的部署计划和实例类型
- en: 'Enter other details of the management cluster, as listed in the following sub-steps
    and shown in the following screenshot:'
  id: totrans-270
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入管理集群的其他详细信息，如下述子步骤所示，并在下图中显示：
- en: Enter a short name under `tkg-aws-mgmt-cluster`.
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `tkg-aws-mgmt-cluster` 下输入一个简短的名称。
- en: Enter the name of the SSH key-pair that’s available to the account you obtained
    in *step 5* of the **aws** CLI configuration under **EC2** **KEY PAIR**.
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入在 **aws** CLI 配置的**步骤 5**中获得的 SSH 密钥对名称，在**EC2** **KEY PAIR**下提供。
- en: Leave the default selection as-is for the checkbox options.
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持复选框选项的默认选择不变。
- en: Select one of the availability zones from the **AVAILABILITY ZONE 1** dropdown
    for the selected region to deploy the management cluster into. For the **Production**
    deployment plan, we need to select three availability zones for the three control
    plane nodes of the management cluster.
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从所选区域的 **AVAILABILITY ZONE 1** 下拉菜单中选择一个可用区以部署管理集群。对于**生产**部署计划，我们需要为管理集群的三个控制平面节点选择三个可用区。
- en: Select **t3.large** as the worker node instance type from the **AZ1 WORKER NODE
    INSTANCE** **TYPE** dropdown.
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 从 **AZ1 WORKER NODE INSTANCE** **TYPE** 下拉菜单中选择**t3.large**作为工作节点实例类型。
- en: 'Click the **NEXT** button to move on:'
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**NEXT**按钮继续：
- en: '![Figure 7.13 – Entering the management cluster’s details](img/B18145_07_13.jpg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.13 – 输入管理集群的详细信息](img/B18145_07_13.jpg)'
- en: Figure 7.13 – Entering the management cluster’s details
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13 – 输入管理集群的详细信息
- en: 'Optionally, enter management cluster metadata and click the **NEXT** button:'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，输入管理集群的元数据并点击**NEXT**按钮：
- en: '![Figure 7.14 – Entering the management cluster’s metadata](img/B18145_07_14.jpg)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.14 – 输入管理集群的元数据](img/B18145_07_14.jpg)'
- en: Figure 7.14 – Entering the management cluster’s metadata
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14 – 输入管理集群的元数据
- en: 'Leave the default Kubernetes container network configuration as-is and click
    the **NEXT** button:'
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持默认的 Kubernetes 容器网络配置不变，并点击**NEXT**按钮：
- en: '![Figure 7.15 – Leaving the default Kubernetes network configuration as-is](img/B18145_07_15.jpg)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.15 – 保持默认的 Kubernetes 网络配置不变](img/B18145_07_15.jpg)'
- en: Figure 7.15 – Leaving the default Kubernetes network configuration as-is
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.15 – 保持默认的 Kubernetes 网络配置不变
- en: 'Disable the identity management settings and click the **NEXT** button:'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 禁用身份管理设置后，点击**下一步**按钮：
- en: '![Figure 7.16 – Disabling identity management settings](img/B18145_07_16.jpg)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.16 – 禁用身份管理设置](img/B18145_07_16.jpg)'
- en: Figure 7.16 – Disabling identity management settings
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.16 – 禁用身份管理设置
- en: 'Select the management cluster’s operating system image, as highlighted in the
    screenshot, and click the **NEXT** button:'
  id: totrans-288
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择管理集群的操作系统镜像，如截图所示，然后点击**下一步**按钮：
- en: '![Figure 7.17 – Selecting the management cluster’s operating system](img/B18145_07_17.jpg)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.17 – 选择管理集群的操作系统](img/B18145_07_17.jpg)'
- en: Figure 7.17 – Selecting the management cluster’s operating system
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.17 – 选择管理集群的操作系统
- en: 'Optionally, choose to participate in VMware’s **Customer Experience Improvement
    Program** (**CEIP**) and click the **NEXT** button:'
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可选地，选择参与 VMware 的**客户体验改进计划**（**CEIP**），然后点击**下一步**按钮：
- en: '![Figure 7.18 – Choosing to participate in the Customer Experience Improvement
    Program](img/B18145_07_18.jpg)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.18 – 选择参与客户体验改进计划](img/B18145_07_18.jpg)'
- en: Figure 7.18 – Choosing to participate in the Customer Experience Improvement
    Program
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.18 – 选择参与客户体验改进计划
- en: 'Click the **REVIEW CONFIGURATION** button to verify the inputs before triggering
    the management cluster creation on AWS:'
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击**审查配置**按钮，验证输入后再触发 AWS 上的管理集群创建：
- en: '![Figure 7.19 – Opening the configuration summary for review](img/B18145_07_19.jpg)'
  id: totrans-295
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.19 – 打开配置摘要进行审查](img/B18145_07_19.jpg)'
- en: Figure 7.19 – Opening the configuration summary for review
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.19 – 打开配置摘要进行审查
- en: 'The following screenshot shows the bottom of the verification summary page.
    The command that’s displayed can be used in the future to trigger the same deployment
    again using the Tanzu CLI. The **EXPORT CONFIGURATION** link at the bottom-right
    corner allows us to export this configuration in a file that can be used as a
    reference to deploy other management clusters on AWS with the required modifications.
    Finally, click the **DEPLOY MANAGEMENT CLUSTER** button to trigger the deployment:'
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下截图显示了验证摘要页面的底部。所显示的命令可以在未来用于通过 Tanzu CLI 重新触发相同的部署。右下角的**导出配置**链接允许我们将此配置导出为文件，以便作为参考，在
    AWS 上部署其他管理集群并进行必要的修改。最后，点击**部署管理集群**按钮以触发部署：
- en: '![Figure 7.20 – Triggering the management cluster’s deployment](img/B18145_07_20.jpg)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.20 – 启动管理集群的部署](img/B18145_07_20.jpg)'
- en: Figure 7.20 – Triggering the management cluster’s deployment
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.20 – 启动管理集群的部署
- en: 'You will see various deployment logs and their installation statuses, as shown
    in the following screenshot. As you can see in the logs, the Cluster API is creating
    the required infrastructure component to deploy the management cluster on AWS:'
  id: totrans-300
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 您将看到各种部署日志及其安装状态，如下图所示。如日志中所示，Cluster API 正在创建所需的基础设施组件，以便在 AWS 上部署管理集群：
- en: '![Figure 7.21 – Deployment status with logs](img/B18145_07_21.jpg)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.21 – 部署状态及日志](img/B18145_07_21.jpg)'
- en: Figure 7.21 – Deployment status with logs
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.21 – 部署状态及日志
- en: 'The installation should ideally be completed in about 10 to 15 minutes and
    you should see a success message, as shown in the following screenshot. As highlighted
    in this screenshot, the logs also highlight how to access the management cluster
    from the bootstrap machine to perform different TKG operations. You should also
    be able to see these logs on the command line from where you fired the `tanzu
    mc create --ui` command, which brought up the installation browser window:'
  id: totrans-303
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装应该在大约 10 到 15 分钟内完成，您应该会看到一个成功消息，如下图所示。如图中所示，日志还显示了如何从引导机访问管理集群并执行不同的 TKG
    操作。您还应该能够在运行 `tanzu mc create --ui` 命令的命令行中看到这些日志，这个命令会弹出安装浏览器窗口：
- en: '![Figure 7.22 – Successful management cluster installation](img/B18145_07_22.jpg)'
  id: totrans-304
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.22 – 成功安装管理集群](img/B18145_07_22.jpg)'
- en: Figure 7.22 – Successful management cluster installation
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.22 – 成功安装管理集群
- en: Now that we have finished installing the management cluster, let’s learn how
    to use it to create our first TKG workload cluster.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成了管理集群的安装，让我们来学习如何使用它创建第一个 TKG 工作负载集群。
- en: Creating a workload cluster
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建工作负载集群
- en: 'The following steps outline the procedure to access the newly created TKG management
    cluster using the bootstrap machine from where we triggered the management cluster
    installation. As a part of the installation steps, TKG adds the `kubeconfig` details
    to the bootstrap machine to allow administrator-level access to the management
    cluster and hence the Tanzu CLI pointing to the management cluster. Let’s use
    the management cluster and the Tanzu CLI to create our first workload cluster.
    The following steps will be performed on the bootstrap machine:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤概述了如何使用从安装管理集群时启动的引导机器访问新创建的TKG管理集群。作为安装步骤的一部分，TKG将`kubeconfig`详细信息添加到引导机器，以便允许管理员级别访问管理集群，从而使Tanzu
    CLI指向管理集群。让我们使用管理集群和Tanzu CLI创建我们的第一个工作负载集群。以下步骤将在引导机器上执行：
- en: 'Run the following command to set the kubectl context pointing to the newly
    created TKG management cluster:'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令设置指向新创建的TKG管理集群的kubectl上下文：
- en: '[PRE36]'
  id: totrans-310
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Run the `tanzu mc get` command to view the details of the management cluster.
    The command will show that the management cluster has one control plane and one
    worker node created:'
  id: totrans-311
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行` tanzu mc get`命令查看管理集群的详细信息。该命令将显示管理集群已创建一个控制平面和一个工作节点：
- en: '![Figure 7.23 – Management cluster details](img/B18145_07_23.jpg)'
  id: totrans-312
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.23 – 管理集群详细信息](img/B18145_07_23.jpg)'
- en: Figure 7.23 – Management cluster details
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.23 – 管理集群详细信息
- en: 'To create a workload cluster, we need to supply the workload cluster configuration
    file to the management cluster. It contains the following details:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建工作负载集群，我们需要将工作负载集群配置文件提供给管理集群。该文件包含以下详细信息：
- en: Cluster name
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群名称
- en: Cluster deployment plan (Development or Production)
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群部署计划（开发或生产）
- en: Worker node count
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作节点数量
- en: Worker node EC2 type
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工作节点EC2类型
- en: AWS-specific configurations such as region, AZ, network, and SSH key
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS特定配置，如区域、可用区、网络和SSH密钥
- en: Node operating system
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点操作系统
- en: Node health check configuration
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点健康检查配置
- en: Node-level auto-scaling configuration
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 节点级别自动扩展配置
- en: We do not need to include all the attributes in the configuration file and may
    specify only the required attributes. For a broader list of attributes for the
    configuration file, visit [https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-tanzu-k8s-clusters-aws.html#tanzu-kubernetes-cluster-template-0](https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-tanzu-k8s-clusters-aws.html#tanzu-kubernetes-cluster-template-0).
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不需要在配置文件中包含所有属性，只需要指定必需的属性。有关配置文件的更多属性列表，请访问[https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-tanzu-k8s-clusters-aws.html#tanzu-kubernetes-cluster-template-0](https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-tanzu-k8s-clusters-aws.html#tanzu-kubernetes-cluster-template-0)。
- en: We will download a preconfigured file from this book’s GitHub repository and
    use it to create a workload cluster.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从本书的GitHub仓库下载一个预配置文件，并使用它来创建工作负载集群。
- en: 'Copy the workload cluster configuration file into the bootstrap machine using
    the following command:'
  id: totrans-325
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将工作负载集群配置文件复制到引导机器：
- en: '[PRE37]'
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The config file should be available in the `$HOME/tkg-154/` directory and be
    called `tkg-workload-cluster-config.yaml`. Open the file in your choice of editor
    and update the following parameter values:'
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置文件应位于`$HOME/tkg-154/`目录中，并命名为`tkg-workload-cluster-config.yaml`。使用您选择的编辑器打开该文件，并更新以下参数值：
- en: Update **AWS_NODE_AZ**, **AWS_NODE_AZ_1** and **AWS_NODE_AZ_2** based on the
    selected region if you have used any AWS region other than **us-east-1**.
  id: totrans-328
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您使用的AWS区域不是**us-east-1**，请根据所选区域更新**AWS_NODE_AZ**、**AWS_NODE_AZ_1**和**AWS_NODE_AZ_2**。
- en: Update **AWS_REGION** as per your **AWS_PROFILE** configuration if applicable.
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果适用，请根据您的**AWS_PROFILE**配置更新**AWS_REGION**。
- en: Update **AWS_SSH_KEY_NAME** to use the SSH key in your AWS account in the selected
    region. This is a must-change.
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更新**AWS_SSH_KEY_NAME**以使用选定区域中您AWS帐户的SSH密钥。这是必须更改的。
- en: 'Run the following command to create the workload cluster using the configuration
    file we prepared in the previous step. Here, we are creating the cluster with
    Kubernetes v1.21.11 using the `--tkr` option so that we can learn how to upgrade
    the cluster later to v.1.22.9:'
  id: totrans-331
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令使用我们在上一步中准备的配置文件创建工作负载集群。这里，我们使用`--tkr`选项创建一个Kubernetes v1.21.11的集群，以便我们稍后学习如何将集群升级到v1.22.9：
- en: '[PRE38]'
  id: totrans-332
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: The workload cluster should be created in about 10 to 15 minutes if all the
    configuration changes are done correctly.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 如果所有配置更改都正确完成，工作负载集群应在大约 10 到 15 分钟内创建完成。
- en: 'Verify the cluster’s creation status using the following command:'
  id: totrans-334
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令验证集群的创建状态：
- en: '[PRE39]'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'You should see that the cluster is running, as shown in the following screenshot:'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到集群正在运行，如下面的截图所示：
- en: '![Figure 7.24 – Verifying the workload cluster’s creation](img/B18145_07_24.jpg)'
  id: totrans-337
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.24 – 验证工作负载集群的创建](img/B18145_07_24.jpg)'
- en: Figure 7.24 – Verifying the workload cluster’s creation
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.24 – 验证工作负载集群的创建
- en: With that, the TKG workload cluster has been created. Now, let’s access the
    workload cluster.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 到此，TKG 工作负载集群已创建。现在，让我们访问工作负载集群。
- en: 'Run the following command to obtain `kubeconfig` for the workload cluster:'
  id: totrans-340
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令获取工作负载集群的 `kubeconfig`：
- en: '[PRE40]'
  id: totrans-341
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Run the following command to switch the `kubectl` context so that it points
    to the workload cluster:'
  id: totrans-342
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令切换 `kubectl` 上下文，使其指向工作负载集群：
- en: '[PRE41]'
  id: totrans-343
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Run the following command to list the nodes of the workload cluster to ensure
    connectivity:'
  id: totrans-344
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令列出工作负载集群的节点以确保连通性：
- en: '[PRE42]'
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'You should be able to see the list of Kubernetes nodes, as shown in the following
    screenshot:'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该能够看到 Kubernetes 节点列表，如下面的截图所示：
- en: '![Figure 7.25 – Verifying the workload cluster’s connectivity](img/B18145_07_25.jpg)'
  id: totrans-347
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.25 – 验证工作负载集群的连通性](img/B18145_07_25.jpg)'
- en: Figure 7.25 – Verifying the workload cluster’s connectivity
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.25 – 验证工作负载集群的连通性
- en: With this, we have completed all the tasks required to get started with TKG.
    We started with the bootstrap machine’s configuration by installing all the required
    tools and CLIs. After that, we created a TKG management cluster on AWS using the
    Tanzu installer UI. And finally, we created a TKG workload cluster using the management
    cluster that we created. It is worth noting that one bootstrap machine may have
    a reference to more than one TKG management cluster. The operator may use different
    management clusters to manage the workload clusters under them by just switching
    the `kubectl` context to an appropriate management cluster config, followed by
    using the `tanzu login` command to get authenticated for the management cluster
    usage. Now, in the next and the last section of this chapter, we will learn about
    some of the most common day-2 activities around TKG.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 到此，我们已经完成了开始使用 TKG 所需的所有任务。我们从引导机器的配置开始，安装了所有必需的工具和 CLI。然后，我们使用 Tanzu 安装器 UI
    在 AWS 上创建了一个 TKG 管理集群。最后，我们使用我们创建的管理集群创建了一个 TKG 工作负载集群。值得注意的是，一个引导机器可能会引用多个 TKG
    管理集群。操作员可以通过切换 `kubectl` 上下文到适当的管理集群配置，然后使用 `tanzu login` 命令进行管理集群的身份验证，来管理其下的工作负载集群。现在，在本章的下一部分也是最后一部分中，我们将学习关于
    TKG 周围一些最常见的 Day-2 活动。
- en: Common day-2 operations with Tanzu Kubernetes Grid
  id: totrans-350
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与 Tanzu Kubernetes Grid 的常见 Day-2 操作
- en: 'Now that we have a fully configured and running TKG foundation on AWS, let’s
    learn how to perform some of the day-2 operations on it. TKG makes these operations
    very trivial as they do all the heavy lifting behind the scenes:'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们在 AWS 上有一个完全配置和运行的 TKG 基础设施，让我们学习如何在其上执行一些 Day-2 操作。TKG 通过在幕后执行所有繁重的工作使这些操作变得非常简单：
- en: Scale a cluster to add or remove nodes
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 缩放集群以添加或移除节点
- en: Upgrade a cluster to bump up the Kubernetes version
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 升级集群以提升 Kubernetes 版本
- en: Delete a cluster
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除一个集群
- en: Delete the entire TKG foundation
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除整个 TKG 基础设施
- en: Let’s start by scaling the workload cluster so that it has three worker nodes
    instead of just one.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始扩展工作负载集群，使其具有三个工作节点，而不仅仅是一个。
- en: Scaling a Tanzu Kubernetes Grid cluster
  id: totrans-357
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 缩放 Tanzu Kubernetes Grid 集群
- en: 'Run the following commands to scale the workload cluster we created:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令以扩展我们创建的工作负载集群：
- en: 'Switch the `kubectl` context so that it’s pointing to the management cluster
    that we previously created, which we used to create the workload cluster:'
  id: totrans-359
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换 `kubectl` 上下文，使其指向我们之前创建的管理集群，该集群用于创建工作负载集群：
- en: '[PRE43]'
  id: totrans-360
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Ensure that the workload cluster has only one worker node by running the following
    command:'
  id: totrans-361
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令确保工作负载集群仅有一个工作节点：
- en: '[PRE44]'
  id: totrans-362
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'You should see the following output, which shows 1/1 worker nodes:'
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下输出，显示 1/1 个工作节点：
- en: '![Figure 7.26 – Ensuring the worker node count](img/B18145_07_26.jpg)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.26 – 确保工作节点计数](img/B18145_07_26.jpg)'
- en: Figure 7.26 – Ensuring the worker node count
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.26 – 确保工作节点计数
- en: 'Run the following command to add two more worker nodes, creating the desired
    total count of three:'
  id: totrans-366
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令添加两个工作节点，将总数增加到三：
- en: '[PRE45]'
  id: totrans-367
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'You should see the following message, showing that the scaling is in progress:'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下消息，显示扩展正在进行中：
- en: '![Figure 7.27 – Worker node scaling in progress](img/B18145_07_27.jpg)'
  id: totrans-369
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.27 – 工作节点扩展进行中](img/B18145_07_27.jpg)'
- en: Figure 7.27 – Worker node scaling in progress
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.27 – 工作节点扩展进行中
- en: 'Verify that the scaling has been done by running the following cluster listing
    command:'
  id: totrans-371
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下集群列出命令来验证扩展是否已完成：
- en: '[PRE46]'
  id: totrans-372
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'You should now see 3/3 worker nodes in the output:'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你应该在输出中看到 3/3 个工作节点：
- en: '![Figure 7.28 – Confirming that the cluster scaling has been done](img/B18145_07_28.jpg)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.28 – 确认集群扩展已完成](img/B18145_07_28.jpg)'
- en: Figure 7.28 – Confirming that the cluster scaling has been done
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.28 – 确认集群扩展已完成
- en: These steps showed you how to scale up a TKG cluster. The same procedure is
    also applicable to scale down a cluster. The `-w` option of the `scale` command
    declares the desired count of the worker nodes. And depending on the changes in
    the desired count, TKG adds or removes the worker nodes. The scaling command also
    has options to scale the control plane nodes or the nodes of a specific node pool.
    You can learn more about scaling by running the `tanzu cluster scale --``help`
    command.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 这些步骤展示了如何扩展 TKG 集群。相同的过程也适用于缩减集群。`scale` 命令的 `-w` 选项声明了所需的工作节点数量。根据所需数量的变化，TKG
    会添加或删除工作节点。扩展命令还提供了扩展控制平面节点或特定节点池节点的选项。你可以通过运行 `tanzu cluster scale --help` 命令了解更多关于扩展的信息。
- en: Upgrading a Tanzu Kubernetes Grid cluster
  id: totrans-377
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 升级 Tanzu Kubernetes Grid 集群
- en: 'Now that we’ve scaled, let’s learn how to upgrade the TKG workload cluster
    to deploy a newer version of Kubernetes. TKG allows such on-demand upgrades of
    selected clusters under a management cluster. Here, the owners of the cluster
    have the choice of which Kubernetes version they need so that they have enough
    time to prepare to upgrade their workload clusters. The following steps outline
    the upgrade procedure:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经完成扩展，让我们学习如何将 TKG 工作负载集群升级到部署一个更新版本的 Kubernetes。TKG 允许在管理集群下按需升级选定集群。在这里，集群的所有者可以选择他们需要的
    Kubernetes 版本，以便有足够的时间准备升级他们的工作负载集群。以下步骤概述了升级过程：
- en: 'Switch the `kubectl` context so that it’s pointing to the management cluster
    that we previously created, which we used to create the workload cluster:'
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换 `kubectl` 上下文，使其指向我们之前创建的管理集群，该集群用于创建工作负载集群：
- en: '[PRE47]'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Ensure that the workload cluster is deployed with Kubernetes v1.21.11 by using
    the following command:'
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令确保工作负载集群部署的是 Kubernetes v1.21.11：
- en: '[PRE48]'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'You should see the following output, showing that the cluster has been deployed
    with Kubernetes version 1.21.11:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下输出，显示集群已部署 Kubernetes 版本 1.21.11：
- en: '![Figure 7.29 – Checking the current Kubernetes version of the cluster](img/B18145_07_29.jpg)'
  id: totrans-384
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.29 – 检查集群当前的 Kubernetes 版本](img/B18145_07_29.jpg)'
- en: Figure 7.29 – Checking the current Kubernetes version of the cluster
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.29 – 检查集群当前的 Kubernetes 版本
- en: 'Run the following command to check the available Kubernetes version(s) for
    the upgrade:'
  id: totrans-386
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令检查可用的 Kubernetes 版本以进行升级：
- en: '[PRE49]'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'You should see the following output, which shows v1.22.9 as an option to upgrade
    v1.21.11, as highlighted in the following screenshot:'
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下输出，显示 v1.22.9 作为升级 v1.21.11 的选项，如下图所示：
- en: '![Figure 7.30 – Checking the available version upgrade options](img/B18145_07_30.jpg)'
  id: totrans-389
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.30 – 检查可用的版本升级选项](img/B18145_07_30.jpg)'
- en: Figure 7.30 – Checking the available version upgrade options
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.30 – 检查可用的版本升级选项
- en: 'Run the following command to upgrade the workload cluster to Kubernetes version
    1.22.9:'
  id: totrans-391
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令将工作负载集群升级到 Kubernetes 版本 1.22.9：
- en: '[PRE50]'
  id: totrans-392
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The `--tkr` option mentions the target version for the upgrade that we picked
    from the available version list in the previous step. This command will upgrade
    the workload cluster in a rolling manner, one node at a time, to minimize workload
    downtime. The applications running with more than one pod would not face any downtime
    during such rolling upgrades. After firing the preceding command, you should see
    the following confirmation message in about 15 to 20 minutes:'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '`--tkr` 选项指定了我们从之前步骤中可用版本列表中选择的升级目标版本。此命令将以滚动方式升级工作负载集群，一次升级一个节点，以最大程度减少工作负载停机时间。运行多个
    Pod 的应用程序在这种滚动升级过程中不会面临任何停机。执行上述命令后，你应该在大约 15 到 20 分钟后看到以下确认消息：'
- en: '![Figure 7.31 – Cluster upgrade log](img/B18145_07_31.jpg)'
  id: totrans-394
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.31 – 集群升级日志](img/B18145_07_31.jpg)'
- en: Figure 7.31 – Cluster upgrade log
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.31 – 集群升级日志
- en: 'The following screenshot shows the recycling of the workload cluster nodes
    to create the new version on the AWS EC2 console. Here, you can see that the old
    nodes got terminated and that the new nodes with newer versions were created to
    replace them:'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示了在 AWS EC2 控制台上回收工作负载集群节点以创建新版本的过程。这里可以看到，旧节点已被终止，新的版本节点已创建并替换它们：
- en: '![Figure 7.32 – Cluster node recycling on the AWS EC2 console](img/B18145_07_32.jpg)'
  id: totrans-397
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.32 – 在 AWS EC2 控制台上回收集群节点](img/B18145_07_32.jpg)'
- en: Figure 7.32 – Cluster node recycling on the AWS EC2 console
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.32 – 在 AWS EC2 控制台上回收集群节点
- en: 'Run the following command to ensure the workload cluster is running with the
    newer Kubernetes version:'
  id: totrans-399
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令确保工作负载集群正在使用较新的 Kubernetes 版本：
- en: '[PRE51]'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'The following screenshot shows that the workload cluster is running on Kubernetes
    version 1.22.9:'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图显示工作负载集群正在运行 Kubernetes 版本 1.22.9：
- en: '![Figure 7.33 – Confirming the workload cluster’s upgrade](img/B18145_07_33.jpg)'
  id: totrans-402
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.33 – 确认工作负载集群的升级](img/B18145_07_33.jpg)'
- en: Figure 7.33 – Confirming the workload cluster’s upgrade
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.33 – 确认工作负载集群的升级
- en: 'In addition to allowing the Kubernetes release to be upgraded, the `tanzu cluster
    upgrade` command also allows you to upgrade the cluster for a specific operating
    system and its versions. Run the `tanzu cluster upgrade –help` command to learn
    more about it. In addition to upgrading a TKG cluster for these reasons, there
    is also another dimension for the upgrades – upgrading the TKG version itself.
    Upgrading a TKG version (from TKG v1.5.x to v1.5.y or from v1.4.x to v1.5.y) is
    beyond the scope of this book. However, you can learn more about that here: [https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-upgrade-tkg-index.html](https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-upgrade-tkg-index.html).'
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
  zh: 除了允许 Kubernetes 版本进行升级，`tanzu cluster upgrade`命令还允许你升级特定操作系统及其版本的集群。运行`tanzu
    cluster upgrade –help`命令了解更多信息。除了为了这些原因升级 TKG 集群外，还有一个升级维度——升级 TKG 版本本身。升级 TKG
    版本（从 TKG v1.5.x 到 v1.5.y 或从 v1.4.x 到 v1.5.y）超出了本书的范围。然而，你可以在这里了解更多：[https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-upgrade-tkg-index.html](https://docs.vmware.com/en/VMware-Tanzu-Kubernetes-Grid/1.5/vmware-tanzu-kubernetes-grid-15/GUID-upgrade-tkg-index.html)。
- en: Deleting a Tanzu Kubernetes Grid workload cluster
  id: totrans-405
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除 Tanzu Kubernetes Grid 工作负载集群
- en: 'Destructions are always easier than constructions. This is the same case with
    TKG workload clusters. The following simple steps outline the procedure to delete
    the TKG workload cluster that we have used so far in this chapter:'
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 毁灭总是比建设容易。这对于 TKG 工作负载集群也是如此。以下简单步骤概述了删除本章中我们使用过的 TKG 工作负载集群的过程：
- en: 'Switch the `kubectl` context so that it’s pointing to the management cluster
    that we previously created, which we used to create the workload cluster:'
  id: totrans-407
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 切换`kubectl`上下文，使其指向我们之前创建的管理集群，该集群用于创建工作负载集群：
- en: '[PRE52]'
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Run the following command to delete the workload cluster, along with its resources
    on your AWS account:'
  id: totrans-409
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令删除工作负载集群及其在 AWS 账户上的资源：
- en: '[PRE53]'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'You should see the following confirmation message on the console for the cluster
    deletion in progress:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该在控制台看到以下确认信息，表示集群删除正在进行中：
- en: '![Figure 7.34 – Cluster deletion in progress](img/B18145_07_34.jpg)'
  id: totrans-412
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.34 – 集群删除进行中](img/B18145_07_34.jpg)'
- en: Figure 7.34 – Cluster deletion in progress
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.34 – 集群删除进行中
- en: 'The following screenshot from the AWS EC2 console shows that all the nodes
    for the workload clusters have been terminated:'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 以下来自 AWS EC2 控制台的截图显示，所有工作负载集群的节点已被终止：
- en: '![Figure 7.35 – Terminated cluster nodes on the AWS EC2 console](img/B18145_07_35.jpg)'
  id: totrans-415
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.35 – 在 AWS EC2 控制台上终止的集群节点](img/B18145_07_35.jpg)'
- en: Figure 7.35 – Terminated cluster nodes on the AWS EC2 console
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.35 – 在 AWS EC2 控制台上终止的集群节点
- en: 'Along with the EC2 instances, TKG (with the help of the Cluster API) also deletes
    other network resources that have been created for the deleted cluster on your
    AWS account. As you may have assumed, deleting a Kubernetes cluster is an extremely
    sensitive operation that could result in extended downtime for the applications
    running on it. Extensive measures should be taken to prevent access to such operations
    from environments other than a lab. Now, let’s look at an even more destructive
    operation: deleting the entire TKG foundation, including the management cluster.'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 EC2 实例外，TKG（借助 Cluster API）还会删除在你的 AWS 账户中为已删除集群创建的其他网络资源。正如你可能已经猜到的，删除 Kubernetes
    集群是一个非常敏感的操作，可能会导致正在运行的应用程序长时间停机。因此，应采取广泛的措施，防止在实验环境之外的其他环境访问此类操作。现在，让我们看一个更具破坏性的操作：删除整个
    TKG 基础设施，包括管理集群。
- en: Deleting a Tanzu Kubernetes Grid foundation
  id: totrans-418
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除 Tanzu Kubernetes Grid 基础设施
- en: 'You would rarely need to delete a TKG foundation from its roots except in such
    a lab environment. Nevertheless, we will cover this TKG life cycle activity in
    this chapter. To delete a TKG foundation, we just need to delete the management
    cluster that we created for the same. And like deleting a workload cluster, deleting
    a management cluster is also a simple but highly destructive process. The following
    steps outline the procedure for this:'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
  zh: 除非在这样的实验环境中，否则你很少需要从根本上删除 TKG 基础设施。不过，我们将会在本章中讲解这一 TKG 生命周期活动。要删除一个 TKG 基础设施，我们只需要删除为其创建的管理集群。和删除工作负载集群一样，删除管理集群也是一个简单但高度破坏性的过程。以下步骤概述了这一过程：
- en: 'Ensure you are pointing to the right Kubernetes cluster for the `kubectl` context
    by running the following command:'
  id: totrans-420
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令，确保你指向的是正确的 Kubernetes 集群的 `kubectl` 上下文：
- en: '[PRE54]'
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Run the following command to delete the management cluster, along with its
    resources on your AWS account:'
  id: totrans-422
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行以下命令删除管理集群及其在 AWS 账户中的资源：
- en: '[PRE55]'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'You may need to replace the region name in the command based on the deployed
    region of the management cluster. Upon command execution, you should see the following
    logs on the console for the cluster deletion in progress because of the `--verbose`
    option, followed by the logging detail level. This command takes the log verbose
    level from 0 to 9, with 9 being the most detailed log:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 根据管理集群的部署区域，你可能需要在命令中替换区域名称。执行命令后，你应该在控制台上看到如下日志，这表明由于 `--verbose` 选项，集群删除正在进行，并随后显示日志的详细级别。此命令的日志详细级别从
    0 到 9，9 表示最详细的日志：
- en: '![Figure 7.36 – Management cluster deletion logs](img/B18145_07_36.jpg)'
  id: totrans-425
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.36 – 管理集群删除日志](img/B18145_07_36.jpg)'
- en: Figure 7.36 – Management cluster deletion logs
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.36 – 管理集群删除日志
- en: You may have figured out from the logs that TKG created a kind cluster on the
    bootstrap machine to do all the required cleanup to delete the TKG foundation
    from the AWS account. This is the same approach that TKG uses while creating a
    management cluster, as we saw earlier in this chapter.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能从日志中了解到，TKG 在引导机器上创建了一个 kind 集群，以执行所有必要的清理操作，将 TKG 基础设施从 AWS 账户中删除。这与我们在本章早些时候看到的
    TKG 创建管理集群时使用的方法相同。
- en: With that, we have completed some of the important day-2 activities around TKG
    clusters. Now, let’s wrap up this chapter with a quick summary of what we have
    learned.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 至此，我们已经完成了关于 TKG 集群的一些重要的第2天活动。现在，让我们通过快速总结一下我们所学到的内容来结束这一章节。
- en: Summary
  id: totrans-429
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: At the beginning of this chapter, we discussed some of the reasons why TKG could
    be a good choice for being a Kubernetes-based container platform. As we saw during
    the hands-on activities, TKG makes Kubernetes platform deployment and management
    very easy and operationally efficient by providing a uniform interface – the Tanzu
    CLI. All the Tanzu CLI-based operations we performed in this chapter were infrastructure-agnostic,
    providing the required muti-cloud ease of operations.
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的开始，我们讨论了 TKG 作为基于 Kubernetes 的容器平台可能是一个不错选择的一些原因。正如我们在动手实践中所看到的，TKG 通过提供统一的接口——Tanzu
    CLI，使 Kubernetes 平台的部署和管理变得非常简便且在操作上高效。在本章中我们执行的所有基于 Tanzu CLI 的操作都是基础设施无关的，提供了所需的多云操作简便性。
- en: Because of the limited scope of TKG in this book, we could not install and use
    all the optional extensions that TKG provides, but we covered them briefly to
    understand their applications. We saw how extensively TKG uses various cherry-picked
    open source tools from the CNCF ecosystem. This way, TKG is a solution completely
    backed by the open source community.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本书中TKG的范围有限，我们无法安装和使用TKG提供的所有可选扩展，但我们简要介绍了它们，以便了解它们的应用。我们看到TKG如何广泛使用来自CNCF生态系统的各种精心挑选的开源工具。通过这种方式，TKG成为一个完全由开源社区支持的解决方案。
- en: Finally, we learned about the common day-1 and day-2 activities on the TKG platform,
    starting with installing a platform on AWS and creating a workload cluster to
    host actual application containers. Following this, we learned how to add more
    capacity for that workload cluster with on-demand scaling. We also learned how
    easily we can upgrade the cluster for different reasons and finally how to delete
    the cluster and the foundation if required.
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们了解了在TKG平台上的常见第1天和第2天活动，从在AWS上安装平台并创建工作负载集群以托管实际应用容器开始。接下来，我们学习了如何通过按需扩展为该工作负载集群增加更多容量。我们还了解了如何轻松地升级集群以应对不同的需求，最后还学会了如何在需要时删除集群及其基础设施。
- en: As you may have assumed, we have not covered many topics around this subject
    to keep this chapter’s length concise. However, we will learn about TKG clusters’
    backup and restore, compliance scanning, and governance policy configurations
    in *Chapter 9**, Managing and Controlling Kubernetes Clusters with Tanzu Mission
    Control,* for Tanzu Mission Control, a single pane of glass that controls hundreds
    of Kubernetes clusters.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所料，为了使本章的内容简洁，我们并未涵盖关于该主题的许多内容。然而，我们将在*第9章《使用Tanzu Mission Control管理和控制Kubernetes集群》*中学习关于TKG集群的备份与恢复、合规性扫描和治理策略配置，Tanzu
    Mission Control是一个控制数百个Kubernetes集群的单一视图平台。
- en: TKG is a commercially available licensed software provided by VMware. In the
    next chapter we will go deep into the Tanzu developer experience with **Tanzu**
    **Application Platform**.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: TKG是VMware提供的商业许可软件。在下一章中，我们将深入探讨与**Tanzu** **应用平台**相关的Tanzu开发者体验。
