["```\n# resource-limit/nginx-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nginx-deployment-example\nspec:\n  replicas: 5\n.\n...<removed for brevity>...\n    spec:\n      containers:\n        - name: nginx\n          image: nginx:1.17\n          ports:\n            - containerPort: 80\n          **resources:**\n            **limits:**\n              **cpu:****200m**\n              **memory:****60Mi**\n            **requests:**\n              **cpu:****100m**\n              **memory:****50Mi** \n```", "```\n$ kubectl describe node minikube-m03\n...<removed for brevity>...\nNon-terminated Pods:          (5 in total)\n  Namespace                   Name                                         CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age\n  ---------                   ----                                         ------------  ----------  ---------------  -------------  ---\n  default                     nginx-deployment-example-6d444cfd96-f5tnq    100m (5%)     200m (10%)  50Mi (2%)        60Mi (3%)      23s\n  default                     nginx-deployment-example-6d444cfd96-k6j9d    100m (5%)     200m (10%)  50Mi (2%)        60Mi (3%)      23s\n  default                     nginx-deployment-example-6d444cfd96-mqxxp    100m (5%)     200m (10%)  50Mi (2%)        60Mi (3%)      23s\n  kube-system                 calico-node-92bdc                            250m (12%)    0 (0%)      0 (0%)           0 (0%)         6d23h\n  kube-system                 kube-proxy-5cd4x                             0 (0%)        0 (0%)      0 (0%)           0 (0%)         6d23h\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                550m (27%)  600m (30%)\n  memory             150Mi (7%)  180Mi (9%)\n  ephemeral-storage  0 (0%)      0 (0%)\n  hugepages-2Mi      0 (0%)      0 (0%)\nEvents:              <none> \n```", "```\n...\n          resources:\n            limits:\n              **cpu:****2000m**\n              memory: 60Mi\n            requests:\n              **cpu:****2000m**\n              memory: 50Mi\n... \n```", "```\n$ kubectl apply -f resource-limit/nginx-deployment.yaml\ndeployment.apps/nginx-deployment-example configured \n```", "```\n$ kubectl get pod\nNAME                                        READY   STATUS    RESTARTS   AGE\nnginx-deployment-example-59b669d85f-cdptx   1/1     Running   0          52s\nnginx-deployment-example-59b669d85f-hdzdf   1/1     Running   0          54s\nnginx-deployment-example-59b669d85f-ktn59   1/1     Running   0          54s\nnginx-deployment-example-59b669d85f-vdn87   1/1     Running   0          52s\nnginx-deployment-example-69bd6d55b4-n2mzq   0/1     Pending   0          3s\nnginx-deployment-example-69bd6d55b4-qb62p   0/1     Pending   0          3s\nnginx-deployment-example-69bd6d55b4-w7xng   0/1     Pending   0          3s \n```", "```\n$ kubectl describe pod nginx-deployment-example-69bd6d55b4-n2mzq\n...\nEvents:\n  Type     Reason            Age                  From               Message\n  ----     ------            ----                 ----               -------\n  Warning  FailedScheduling  23m (x21 over 121m)  default-scheduler  **0/3 nodes are available:** 1 node(s) had untolerated taint {machine-check-exception: memory}, 2 Insufficient cpu. preemption: 0/3 nodes are available: 1 Preemption is not helpful for scheduling, 2 No preemption victims found for incoming pod. \n```", "```\n    # /etc/kubernetes/manifests/kube-apiserver.yaml\n    ...\n      - command:\n        - kube-apiserver\n       ...<removed for brevity>...\n        - --feature-gates=InPlacePodVerticalScaling=true \n    ```", "```\n$ minikube start --feature-gates=InPlacePodVerticalScaling=true \n```", "```\n$ gcloud container clusters update <cluster-name> --enable-vertical-pod-autoscaling \n```", "```\n$ gcloud container clusters create k8sforbeginners --num-nodes=2 --zone=us-central1-a --enable-vertical-pod-autoscaling \n```", "```\n    $ git clone https://github.com/kubernetes/autoscaler \n    ```", "```\n    $ cd autoscaler/vertical-pod-autoscaler \n    ```", "```\n    $ ./hack/vpa-up.sh \n    ```", "```\n    $ kubectl get pods -n kube-system | grep vpa\n    vpa-admission-controller-5b64b4f4c4-vsn9j   1/1     Running   0             5m34s\n    vpa-recommender-54c76554b5-m7wnk            1/1     Running   0             5m34s\n    vpa-updater-7d5f6fbf9b-rkwlb                1/1     Running   0             5m34s \n    ```", "```\n    $ minikube addons enable metrics-server \n    ```", "```\n    # vpa/vpa-demo-ns.yaml\n    ---\n    apiVersion: v1\n    kind: Namespace\n    metadata:\n      labels:\n        project: vpa-demo\n      name: vpa-demo \n    ```", "```\n$ kubectl apply -f vpa/vpa-demo-ns.yaml\nnamespace/vpa-demo created \n```", "```\n    # vpa/hamster-deployment.yaml\n    apiVersion: apps/v1\n    kind: Deployment\n    metadata:\n      name: hamster\n      namespace: vpa-demo\n    spec:\n      selector:\n        matchLabels:\n          app: hamster\n      replicas: 5\n      template:\n        metadata:\n          labels:\n            app: hamster\n        spec:\n          containers:\n            - name: hamster\n              image: ubuntu:20.04\n              resources:\n                requests:\n                  cpu: 100m\n                  memory: 50Mi\n              command:\n                - /bin/sh\n                - -c\n                - while true; do timeout 0.5s yes >/dev/null; sleep 0.5s; done \n    ```", "```\n    $ kubectl apply -f vpa/hamster-deployment.yaml\n    deployment.apps/hamster created \n    ```", "```\n    $  kubectl get po -n vpa-demo\n    NAME                      READY   STATUS    RESTARTS   AGE\n    hamster-7fb7dbff7-hmzt5   1/1     Running   0          8s\n    hamster-7fb7dbff7-lbk9f   1/1     Running   0          8s\n    hamster-7fb7dbff7-ql6gd   1/1     Running   0          8s\n    hamster-7fb7dbff7-qmxd8   1/1     Running   0          8s\n    hamster-7fb7dbff7-qtrpp   1/1     Running   0          8s \n    ```", "```\n    $ kubectl top pod -n vpa-demo\n    NAME                      CPU(cores)   MEMORY(bytes)\n    hamster-7fb7dbff7-hmzt5   457m         0Mi            \n    hamster-7fb7dbff7-lbk9f   489m         0Mi            \n    hamster-7fb7dbff7-ql6gd   459m         0Mi            \n    hamster-7fb7dbff7-qmxd8   453m         0Mi            \n    hamster-7fb7dbff7-qtrpp   451m         0Mi \n    ```", "```\n    # vpa/hamster-vpa.yaml\n    apiVersion: autoscaling.k8s.io/v1\n    kind: VerticalPodAutoscaler\n    metadata:\n      name: hamster-vpa\n      namespace: vpa-demo\n    spec:\n      targetRef:\n        apiVersion: apps/v1\n        kind: Deployment\n        name: hamster\n      updatePolicy:\n        updateMode: 'Off'\n      resourcePolicy:\n        containerPolicies:\n          - containerName: '*'\n            minAllowed:\n              cpu: 100m\n              memory: 50Mi\n            maxAllowed:\n              cpu: 1\n              memory: 500Mi\n            controlledResources:\n              - cpu\n              - memory \n    ```", "```\n    $ kubectl apply -f vpa/hamster-vpa.yaml\n    verticalpodautoscaler.autoscaling.k8s.io/hamster-vpa created \n    ```", "```\n    $ kubectl describe vpa hamster-vpa -n vpa-demo\n    ...<removed for brevity>...\n    Status:\n      Conditions:\n        Last Transition Time:  2024-08-11T09:20:44Z\n        Status:                True\n        Type:                  RecommendationProvided\n      Recommendation:\n        Container Recommendations:\n          Container Name:  hamster\n          Lower Bound:\n            Cpu:     461m\n            Memory:  262144k\n          Target:\n            Cpu:     587m\n            Memory:  262144k\n          Uncapped Target:\n            Cpu:     587m\n            Memory:  262144k\n          Upper Bound:\n            Cpu:     1\n            Memory:  500Mi\n    Events:          <none> \n    ```", "```\n    # vpa/hamster-vpa.yaml\n    apiVersion: autoscaling.k8s.io/v1\n    kind: VerticalPodAutoscaler\n    metadata:\n      name: hamster-vpa\n      namespace: vpa-demo\n    spec:\n    ...\n      updatePolicy:\n    **updateMode:****Auto**\n    ... \n    ```", "```\n    $ kubectl apply -f vpa/hamster-vpa.yaml\n    verticalpodautoscaler.autoscaling.k8s.io/hamster-vpa configured \n    ```", "```\n    $ kubectl get po -n vpa-demo -w\n    NAME                      READY   STATUS              RESTARTS   AGE\n    hamster-7fb7dbff7-24p89   0/1     ContainerCreating   0          2s\n    hamster-7fb7dbff7-6nz8f   0/1     ContainerCreating   0          2s\n    hamster-7fb7dbff7-hmzt5   1/1     Running             0          20m\n    hamster-7fb7dbff7-lbk9f   1/1     Running             0          20m\n    hamster-7fb7dbff7-ql6gd   1/1     Terminating         0          20m\n    hamster-7fb7dbff7-qmxd8   1/1     Terminating         0          20m\n    hamster-7fb7dbff7-qtrpp   1/1     Running             0          20m\n    hamster-7fb7dbff7-24p89   1/1     Running             0          2s\n    hamster-7fb7dbff7-6nz8f   1/1     Running             0          2s \n    ```", "```\n    $ kubectl describe pod hamster-7fb7dbff7-24p89 -n vpa-demo\n    ...\n    Annotations:      ...<removed for brevity>...\n                      vpaObservedContainers: hamster\n                      vpaUpdates: Pod resources updated by hamster-vpa: container 0: memory request, cpu request\n    ...\n    Containers:\n      hamster:\n        ...\n        Requests:\n          cpu:        587m\n          memory:     262144k\n    ...<removed for brevity>... \n    ```", "```\n$ minikube addons enable metrics-server \n```", "```\n    # hpa/hpa-demo-ns.yaml\n    ---\n    apiVersion: v1\n    kind: Namespace\n    metadata:\n      labels:\n        project: hpa-demo\n      name: hpa-demo \n    ```", "```\n    $ kubectl apply -f hpa/hpa-demo-ns.yaml\n    namespace/hpa-demo created \n    ```", "```\n    ---\n    # hpa/todo-deployment.yaml\n    apiVersion: apps/v1\n    kind: Deployment\n    metadata:\n      name: todo-app\n      namespace: hpa-demo\n    spec:\n      replicas: 1  # Adjust as needed\n      selector:\n        matchLabels:\n          app: todo\n      template:\n        metadata:\n          labels:\n            app: todo\n        spec:\n          containers:\n            - name: todoapp\n              image: quay.io/ginigangadharan/todo-app:2.0\n              ports:\n                - containerPort: 3000\n              resources:\n                requests:\n                  memory: \"50Mi\"   # Request 50 MiB of memory\n                  cpu: \"50m\"      # Request 0.05 CPU core\n                limits:\n                  memory: \"100Mi\"  # Request 100 MiB of memory\n                  cpu: \"100m\"      # Request 0.1 CPU core \n    ```", "```\n    $ kubectl apply -f hpa/todo-deployment.yaml\n    deployment.apps/todo-app created\n    $ kubectl get po -n hpa-demo\n    NAME                        READY   STATUS    RESTARTS   AGE\n    todo-app-5cfb496d77-l6r69   1/1     Running   0          8s \n    ```", "```\n    # hpa/todo-service.yaml\n    apiVersion: v1\n    kind: Service\n    metadata:\n      name: todo-app\n      namespace: hpa-demo\n    spec:\n      type: ClusterIP\n      selector:\n        app: todo\n      ports:\n        - port: 8081          # Port exposed within the cluster\n          targetPort: 3000    # containerPort on the pods \n    ```", "```\n    $ kubectl apply -f hpa/todo-service.yaml\n    service/todo-app created\n    $ kubectl get svc -n hpa-demo\n    NAME       TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE\n    todo-app   ClusterIP   10.96.171.71   <none>        8081/TCP   15s \n    ```", "```\n    $ kubectl port-forward svc/todo-app -n hpa-demo 8081:8081\n    Forwarding from 127.0.0.1:8081 -> 3000\n    Forwarding from [::1]:8081 -> 3000 \n    ```", "```\n$ kubectl run -i --tty load-generator --rm --image=busybox:1.28 --restart=Never -- /bin/sh -c \"while sleep 0.01; do wget -q -O- http://todo-app; done\" \n```", "```\n    # hpa/todo-hpa.yaml\n    apiVersion: autoscaling/v2\n    kind: HorizontalPodAutoscaler\n    metadata:\n      name: todo-hpa\n      namespace: hpa-demo\n    spec:\n      scaleTargetRef:\n        apiVersion: apps/v1\n        kind: Deployment\n        name: todo-app\n      minReplicas: 1\n      maxReplicas: 5\n      metrics:\n        - resource:\n            name: cpu\n            target:\n              averageUtilization: 80\n              type: Utilization\n          type: Resource \n    ```", "```\n    $ kubectl apply -f hpa/todo-hpa.yaml\n    horizontalpodautoscaler.autoscaling/todo-hpa created\n    $ kubectl get hpa -n hpa-demo\n    NAME       REFERENCE             TARGETS              MINPODS   MAXPODS   REPLICAS   AGE\n    todo-hpa   Deployment/todo-app   cpu: <unknown>/80%   1         5         0          6s \n    ```", "```\n    $ kubectl port-forward svc/todo-app -n hpa-demo 8081:8081\n    Forwarding from 127.0.0.1:8081 -> 3000\n    Forwarding from [::1]:8081 -> 3000 \n    ```", "```\n    $ hey -z 4m -c 25 http://localhost:8081 \n    ```", "```\n    $ watch 'kubectl get po -n hpa-demo;kubectl top pods -n hpa-demo'\n    Every 2.0s: kubectl get po -n hpa-demo;kubectl top pods -n hpa-demo\n    NAME                        READY   STATUS    RESTARTS   AGE\n    todo-app-5cfb496d77-5kc27   1/1     Running   0          76s\n    todo-app-5cfb496d77-l6r69   1/1     Running   0          10m\n    todo-app-5cfb496d77-pb7tx   1/1     Running   0          76s\n    NAME                        CPU(cores)   MEMORY(bytes)\n    todo-app-5cfb496d77-5kc27   10m          14Mi\n    todo-app-5cfb496d77-l6r69   100m         48Mi\n    todo-app-5cfb496d77-pb7tx   7m           14Mi \n    ```", "```\n    $ kubectl describe deployments.apps todo-app -n hpa-demo\n    Name:                   todo-app\n    ...<removed for brevity>...\n    Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable\n    StrategyType:           RollingUpdate\n    ...<removed for brevity>...\n    Events:\n      Type    Reason             Age   From                   Message\n      ----    ------             ----  ----                   -------\n      Normal  ScalingReplicaSet  16m   deployment-controller  Scaled up replica set todo-app-749854577d to 1\n      Normal  ScalingReplicaSet  13m   deployment-controller  Scaled up replica set todo-app-5cfb496d77 to 1\n      Normal  ScalingReplicaSet  13m   deployment-controller  Scaled down replica set todo-app-749854577d to 0 from 1\n      Normal  ScalingReplicaSet  4m9s  deployment-controller  Scaled up replica set todo-app-5cfb496d77 to 3 from 1 \n    ```", "```\n$ gcloud container clusters create k8sbible \\\n  --enable-autoscaling \\\n  --num-nodes 3 \\\n  --min-nodes 2 \\\n  --max-nodes 10 \\\n  --region=us-central1-a\n...<removed for brevity>...\nCreating cluster k8sbible in us-central1-a... Cluster is being health-checked (master is healthy)...done.\nCreated [https://container.googleapis.com/v1/projects/k8sbible-project/zones/us-central1-a/clusters/k8sbible].\nTo inspect the contents of your cluster, go to: https://console.cloud.google.com/kubernetes/workload_/gcloud/us-central1-a/k8sbible?project=k8sbible-project\nkubeconfig entry generated for k8sbible.\nNAME      LOCATION       MASTER_VERSION      MASTER_IP      MACHINE_TYPE  NODE_VERSION        NUM_NODES  STATUS\nk8sbible  us-central1-a  1.29.7-gke.1008000  <removed>      e2-medium     1.29.7-gke.1008000  3          RUNNING \n```", "```\n$ gcloud container clusters update k8sforbeginners --enable-autoscaling --min-nodes=2 --max-nodes=10 --zone=us-central1-a --node-pool=nodepool1 \n```", "```\n$ gcloud container node-pools describe default-pool --cluster=k8sdemo |grep autoscaling -A 1\nautoscaling:\n  enabled: true \n```", "```\n$ az aks create --resource-group k8sforbeginners-rg \\\n  --name k8sforbeginners-aks \\\n  --node-count 1 \\\n  --enable-cluster-autoscaler \\\n  --min-count 1 \\\n  --max-count 10 \\\n  --vm-set-type VirtualMachineScaleSets \\\n  --load-balancer-sku standard \\\n  --generate-ssh-keys \n```", "```\n$ az aks update --resource-group k8sforbeginners-rg --name k8sforbeginners-aks --enable-cluster-autoscaler --min-count 2 --max-count 10 \n```", "```\n$ kubectl get nodes -o custom-columns=NAME:.metadata.name,CPU_ALLOCATABLE:.status.allocatable.cpu,MEMORY_ALLOCATABLE:.status.allocatable.memory\nNAME                                     CPU_ALLOCATABLE   MEMORY_ALLOCATABLE\ngke-k8sdemo-default-pool-1bf4f185-6422   940m              2873304Ki\ngke-k8sdemo-default-pool-1bf4f185-csv0   940m              2873312Ki \n```", "```\n    # ca/ca-demo-ns.yaml\n    ---\n    apiVersion: v1\n    kind: Namespace\n    metadata:\n      labels:\n        project: ca-demo\n      name: ca-demo \n    ```", "```\n    # ca/deployment-reader-role.yaml\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: Role\n    metadata:\n      namespace: ca-demo\n      name: deployment-reader\n    rules:\n    - apiGroups: [\"apps\"]\n      resources: [\"deployments\"]\n      verbs: [\"get\", \"watch\", \"list\"] \n    ```", "```\n    # ca/elastic-hamster-serviceaccount.yaml\n    apiVersion: v1\n    kind: ServiceAccount\n    metadata:\n      name: elastic-hamster\n      namespace: ca-demo \n    ```", "```\n    # ca/read-deployments-rolebinding.yaml\n    apiVersion: rbac.authorization.k8s.io/v1\n    kind: RoleBinding\n    metadata:\n      name: read-deployments\n      namespace: ca-demo\n    subjects:\n    - kind: ServiceAccount\n      name: elastic-hamster\n      namespace: default\n    roleRef:\n      kind: Role\n      name: deployment-reader\n      apiGroup: rbac.authorization.k8s.io \n    ```", "```\n    ...\n        spec:\n          serviceAccountName: elastic-hamster\n          containers:\n            - name: hamster\n              image: quay.io/iamgini/elastic-hamster:1.0\n              resources:\n                requests:\n                  cpu: 500m\n                  memory: 50Mi\n              env:\n                - name: TOTAL_HAMSTER_USAGE\n                  value: \"1.0\" \n    ```", "```\n    # elastic-hamster-hpa.yaml\n    apiVersion: autoscaling/v1\n    kind: HorizontalPodAutoscaler\n    metadata:\n      name: elastic-hamster-hpa\n      namespace: ca-demo\n    spec:\n      minReplicas: 1\n      maxReplicas: 25\n      metrics:\n        - resource:\n            name: cpu\n            target:\n              averageUtilization: 75\n              type: Utilization\n          type: Resource\n      scaleTargetRef:\n        apiVersion: apps/v1\n        kind: Deployment\n        name: elastic-hamster \n    ```", "```\n    $ kubectl apply -f ca/\n    namespace/ca-demo created\n    role.rbac.authorization.k8s.io/deployment-reader created\n    deployment.apps/elastic-hamster created\n    horizontalpodautoscaler.autoscaling/elastic-hamster-hpa created\n    serviceaccount/elastic-hamster created\n    rolebinding.rbac.authorization.k8s.io/read-deployments created \n    ```", "```\n    $ kubectl get po -n ca-demo\n    NAME                              READY   STATUS    RESTARTS   AGE\n    elastic-hamster-87d4db7fd-4tmxn   0/1     Pending   0          7m20s\n    elastic-hamster-87d4db7fd-59lcd   1/1     Running   0          8m4s\n    elastic-hamster-87d4db7fd-5d2gf   0/1     Pending   0          7m20s\n    elastic-hamster-87d4db7fd-5m27q   0/1     Pending   0          8m4s\n    elastic-hamster-87d4db7fd-7nc48   0/1     Pending   0          7m19s\n    ...<removed for brevity>...\n    elastic-hamster-87d4db7fd-st7r5   0/1     Pending   0          7m34s\n    elastic-hamster-87d4db7fd-twb86   1/1     Running   0          8m48s\n    elastic-hamster-87d4db7fd-xrppp   0/1     Pending   0          7m34s \n    ```", "```\n    $ kubectl top pod -n ca-demo\n    NAME                                     CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%  \n    gke-k8sdemo-default-pool-1bf4f185-6422   196m         20%    1220Mi          43%      \n    gke-k8sdemo-default-pool-1bf4f185-csv0   199m         21%    1139Mi          40%      \n    gke-k8sdemo-default-pool-1bf4f185-fcsd   751m         79%    935Mi           33%      \n    gke-k8sdemo-default-pool-1bf4f185-frq6   731m         77%    879Mi           31%      \n    gke-k8sdemo-default-pool-1bf4f185-h8hw   742m         78%    846Mi           30%      \n    gke-k8sdemo-default-pool-1bf4f185-j99r   733m         77%    923Mi           32%      \n    gke-k8sdemo-default-pool-1bf4f185-k6xq   741m         78%    986Mi           35%      \n    ...<removed for brevity>... \n    ```", "```\n    $ kubectl patch hpa elastic-hamster-hpa -n ca-demo -p '{\"spec\": {\"maxReplicas\": 2}}'\n    horizontalpodautoscaler.autoscaling/elastic-hamster-hpa patch \n    ```", "```\n    $ kubectl get pod -n ca-demo\n    NAME                              READY   STATUS    RESTARTS   AGE\n    elastic-hamster-87d4db7fd-2qghf   1/1     Running   0          20m\n    elastic-hamster-87d4db7fd-mdvpx   1/1     Running   0          19m \n    ```", "```\n    $ kubectl get nodes\n    NAME                                     STATUS   ROLES    AGE    VERSION\n    gke-k8sdemo-default-pool-1bf4f185-6422   Ready    <none>   145m   v1.29.7-gke.1008000\n    gke-k8sdemo-default-pool-1bf4f185-csv0   Ready    <none>   145m   v1.29.7-gke.1008000 \n    ```"]