<html><head></head><body>
		<div id="_idContainer141">
			<h1 class="chapter-number" id="_idParaDest-173"><a id="_idTextAnchor176"/>9</h1>
			<h1 id="_idParaDest-174"><a id="_idTextAnchor177"/>GitOps for Azure and AWS Deployments</h1>
			<p>In the evolving landscape of cloud computing, the adoption of GitOps practices stands out as a transformative approach to streamlining the deployment and management of applications and infrastructure. This chapter embarks on a detailed exploration of applying GitOps principles within the robust ecosystems of Azure and <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>), two of the world’s leading cloud platforms. This chapter aims to unravel the complexities of leveraging cloud-native capabilities, providing readers with a comprehensive understanding of how to harness the full potential of <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>), <strong class="bold">Azure DevOps</strong>, <strong class="bold">Elastic Kubernetes Service</strong> (<strong class="bold">EKS</strong>), and <strong class="bold">AWS CodePipeline</strong> in a <span class="No-Break">GitOps workflow.</span></p>
			<p>Through real-world case studies, expert insights, and practical guidance, we delve into the nuances of setting up <strong class="bold">continuous integration/continuous deployment</strong> (<strong class="bold">CI/CD</strong>) pipelines, managing configurations, and ensuring consistent, automated deployments across these platforms. By the end of this chapter, readers will be equipped with the knowledge to implement efficient, secure, and scalable GitOps workflows, marking a significant step forward in their <span class="No-Break">cloud-native journey.</span></p>
			<p>In this chapter, we’ll focus on these <span class="No-Break">key areas:</span></p>
			<ul>
				<li>Cloud GitOps essentials – Azure <span class="No-Break">and AWS</span></li>
				<li>Deployment on Azure and AWS <span class="No-Break">with GitOps</span></li>
				<li>Integrating Azure and AWS in <span class="No-Break">GitOps workflows</span></li>
				<li>GitOps applications in <span class="No-Break">cloud environments</span></li>
				<li>GitOps strategies for Azure and AWS deployments <span class="No-Break">for Kubernetes</span></li>
			</ul>
			<h1 id="_idParaDest-175"><a id="_idTextAnchor178"/>Technical requirements</h1>
			<p>Before delving into the intricacies of implementing GitOps for Azure and AWS deployments, it’s important to build upon the foundational knowledge established in the preceding chapters of this book. The principles of GitOps, containerization technologies such as Docker, Kubernetes concepts, and CI/CD principles discussed earlier provide a solid starting point for understanding the advanced applications highlighted in this chapter. Additionally, access to Azure and AWS accounts and a basic understanding of their services will be crucial for following along with practical exercises and case studies. Familiarity with version control systems, especially Git, will not only enhance comprehension but also facilitate the effective application of the GitOps practices detailed in our exploration of cloud-native deployments across Azure <span class="No-Break">and AWS.</span></p>
			<p>The relevant code and resource files for this chapter can be found in the <strong class="source-inline">Chapter09</strong> folder of our dedicated GitHub <span class="No-Break">repository: </span><a href="https://github.com/PacktPublishing/Implementing-GitOps-with-Kubernetes"><span class="No-Break">https://github.com/PacktPublishing/Implementing-GitOps-with-Kubernetes</span></a><span class="No-Break">.</span></p>
			<h2 id="_idParaDest-176"><a id="_idTextAnchor179"/>Azure and AWS accounts</h2>
			<p>While this book delves into the intricacies of implementing GitOps within Azure and AWS ecosystems, providing a comprehensive exploration of their respective tools and practices, a detailed, step-by-step guide for creating Azure and AWS accounts falls beyond our scope. To embark on the practical journey of applying the concepts and examples outlined in the upcoming sections, it is essential for readers to have active Azure and AWS accounts. We encourage you to consult the official documentation provided by Azure at <a href="https://azure.microsoft.com/en-us/">https://azure.microsoft.com/en-us/</a>, and AWS at <a href="https://aws.amazon.com/">https://aws.amazon.com/</a>, for the most current and detailed instructions on setting up your accounts. These accounts are indispensable for deploying the examples and applying the GitOps practices discussed, serving as the foundation upon which you can build and experiment with the cloud-native capabilities of Azure <span class="No-Break">and AWS.</span></p>
			<p>In the forthcoming section, we will assume that readers possess an active and properly configured Azure or AWS account, along with basic knowledge of the <strong class="bold">Azure CLI</strong>, <strong class="bold">AWS CLI</strong>, or their respective <span class="No-Break">web portals.</span></p>
			<h1 id="_idParaDest-177"><a id="_idTextAnchor180"/>Cloud GitOps essentials – Azure and AWS</h1>
			<p>As the cloud computing landscape continues to evolve, the adoption of GitOps principles has become a cornerstone for achieving operational excellence and automation<a id="_idIndexMarker747"/> in <strong class="bold">cloud-native deployments</strong>. This chapter introduces the GitOps essentials for both Azure and AWS, showcasing how these leading cloud platforms support the seamless integration of GitOps workflows to enhance deployment speed, reliability, <span class="No-Break">and scalability.</span></p>
			<p class="callout-heading">Cloud-native developments and deployments</p>
			<p class="callout">Cloud-native development<a id="_idIndexMarker748"/> represents a transformative approach to building and deploying applications that fully exploit the advantages of the cloud computing model. At its core, it involves leveraging managed services, microservices architectures, containers, and declarative APIs to create applications that are scalable, resilient, and easily updated. This paradigm shift encourages organizations to move away from monolithic architectures, enabling faster development cycles, enhanced scalability, and greater flexibility in responding to market demands. Cloud-native technologies, including Kubernetes, Docker, and serverless functions, play pivotal roles in this ecosystem, providing the tools necessary for developers to build applications that are not only highly available and fault tolerant but also capable of thriving in the dynamic environment of the cloud. By adopting cloud-native practices, businesses can accelerate their digital transformation journeys, enhancing their ability to innovate and compete in an increasingly <span class="No-Break">digital world.</span></p>
			<p>Azure and <a id="_idIndexMarker749"/>AWS each offer unique tools and services – such as AKS, Azure DevOps, EKS, and AWS CodePipeline – that empower teams to implement GitOps practices effectively. Through a comprehensive<a id="_idIndexMarker750"/> exploration of these essentials, readers will gain insight into leveraging the cloud-native capabilities of Azure and AWS to streamline their deployment processes, ensuring that infrastructure and application management is as efficient and error free as possible. This unified approach provides a solid foundation for understanding how GitOps can be optimally applied within the distinct but complementary ecosystems of Azure <span class="No-Break">and AWS.</span></p>
			<h2 id="_idParaDest-178"><a id="_idTextAnchor181"/>Azure GitOps essentials</h2>
			<p>Azure, with its<a id="_idIndexMarker751"/> rich ecosystem and integration capabilities, offers fertile ground for implementing GitOps principles, enhancing <a id="_idIndexMarker752"/>automation, consistency, and scalability in deployments. At the heart of Azure’s GitOps capabilities lies the AKS, which simplifies the deployment, management, and operations of Kubernetes, enabling a seamless GitOps workflow. Coupled <a id="_idIndexMarker753"/>with <strong class="bold">Azure DevOps</strong> – a suite that provides a range of tools<a id="_idIndexMarker754"/> including <strong class="bold">Azure Repos</strong> for Git hosting<a id="_idIndexMarker755"/> and <strong class="bold">Azure Pipelines</strong> for CI/CD – developers can establish a robust GitOps pipeline that ensures continuous integration and deployment with minimal manual intervention. Leveraging these services, users can maintain a high degree of control and visibility over their deployments, benefiting from the declarative nature of GitOps to manage infrastructure and <span class="No-Break">applications efficiently.</span></p>
			<h3>Azure DevOps</h3>
			<p>Azure DevOps <a id="_idIndexMarker756"/>represents a suite of development tools provided by Microsoft, designed to support the complete software development life cycle. At its core, Azure DevOps facilitates CI/CD practices, enabling teams to automate the build, test, and deployment phases of their applications. Specifically, in the context of GitOps, Azure DevOps becomes a powerful ally, allowing teams to manage infrastructure and application code in a Git repository, automatically apply changes to Kubernetes environments, and maintain a consistent state across development, testing, and <span class="No-Break">production environments.</span></p>
			<p>For<a id="_idIndexMarker757"/> implementing Kubernetes GitOps deployment with Azure DevOps, the following base steps can guide you through <span class="No-Break">the process:</span></p>
			<ol>
				<li><strong class="bold">Set up a Git repository</strong>: Begin by setting up a Git repository within Azure Repos or any other<a id="_idIndexMarker758"/> Git hosting service. This repository will hold your Kubernetes manifest files, representing the desired state of your application and infrastructure in a <span class="No-Break">declarative manner.</span></li>
				<li><strong class="bold">Create Azure Pipelines</strong>: Utilize Azure Pipelines to define your CI/CD workflows. For GitOps, the CD pipeline plays a crucial role. It should be configured to trigger automatically upon changes to the main branch of your repository, where your Kubernetes manifest files <span class="No-Break">are stored.</span></li>
				<li><strong class="bold">Define environments</strong>: In Azure DevOps, define environments to represent your deployment targets, such as development, staging, and production. These environments <a id="_idIndexMarker759"/>can be linked to your Kubernetes clusters managed by AKS or any <span class="No-Break">Kubernetes clusters.</span></li>
				<li><strong class="bold">Automate deployment with Helm or Kustomize</strong>: Use Helm charts or Kustomize for <a id="_idIndexMarker760"/>managing complex Kubernetes applications. Azure Pipelines can be configured to use Helm or Kustomize to package and deploy applications, adhering to the GitOps principle of <span class="No-Break">declarative configuration.</span></li>
				<li><strong class="bold">Implement CD</strong>: The CD pipeline should be designed to automatically apply changes to your Kubernetes environment using <strong class="source-inline">kubectl</strong>, Helm, or a GitOps tool such as Flux or Argo CD. This step involves fetching the latest configuration from your Git repository and applying it to the designated environment, ensuring that the actual state matches the desired state declared <span class="No-Break">in Git.</span></li>
				<li><strong class="bold">Monitor and rollback</strong>: Finally, leverage Azure Monitor and other observability tools to keep an eye on your deployments. In case of any issues, your GitOps workflow should support easy rollbacks by simply reverting changes in your Git repository and re-running the pipeline to restore the <span class="No-Break">previous state.</span></li>
			</ol>
			<h3>Kubernetes deployment with Azure DevOps</h3>
			<p>In this section, we<a id="_idIndexMarker761"/> embark on a hands-on journey to deploy a Kubernetes cluster on Azure, leveraging the powerful combination of Terraform, <strong class="bold">Azure Container Registry</strong> (<strong class="bold">ACR</strong>), and Azure DevOps pipelines. We’ll start <a id="_idIndexMarker762"/>by creating a straightforward AKS cluster and an ACR, and then establish a system-managed identity between them to facilitate secure interactions. The climax of our journey involves orchestrating the deployment of this image to the AKS cluster using a meticulously crafted Azure DevOps pipeline. This practical walkthrough is designed to illuminate the seamless integration of these components, illustrating how they converge to streamline the deployment process within a GitOps framework. Through this example, readers will gain a comprehensive understanding of deploying applications to Kubernetes using Azure’s robust ecosystem. The following are the necessary steps to successfully complete <span class="No-Break">this example.</span></p>
			<p>In a real-world scenario, executing<a id="_idIndexMarker763"/> the <a id="_idIndexMarker764"/>Terraform script would involve <a id="_idIndexMarker765"/>creating an <strong class="bold">Azure service principal</strong> with the appropriate permissions to provision resources. However, for this example, we are simplifying the process by using an Azure administrator account with full authorizations. It’s important to note that this approach is not recommended for production environments due to security concerns. Log in to Azure by typing the following command in a new <span class="No-Break">terminal window:</span></p>
			<pre class="console">
$ az login</pre>			<p>To initialize Terraform, we use the <strong class="source-inline">terraform init</strong> command. For this step, we will utilize the <strong class="source-inline">main.tf</strong> and <strong class="source-inline">versions.tf</strong> Terraform files located in the <strong class="source-inline">iac/azure</strong> folder of the GitHub repository accompanying <span class="No-Break">this chapter.</span></p>
			<p class="callout-heading">Why Terraform?</p>
			<p class="callout">Terraform<a id="_idIndexMarker766"/> is a preferred tool for <strong class="bold">infrastructure as code</strong> (<strong class="bold">IaC</strong>) because it uses a declarative configuration language, which simplifies defining and managing complex environments by specifying the desired end state of the infrastructure. It supports multiple cloud providers, including AWS, Azure, and Google Cloud, enabling consistent IaC practices across different platforms. Additionally, Terraform’s state management feature keeps track of the current infrastructure status, allowing it to efficiently plan and apply changes while minimizing errors. Its extensive module ecosystem and robust community support further enhance its capability to automate and manage infrastructure <span class="No-Break">at scale.</span></p>
			<p>The <strong class="source-inline">main.tf</strong> file orchestrates the setup of essential Azure services for a Kubernetes-based deployment. Initially, it establishes a resource group called <strong class="source-inline">aks-k8s-deployments-rg</strong> in the <strong class="source-inline">switzerlandnorth</strong> region, serving as a container for all related Azure resources. Following this, an ACR named <strong class="source-inline">aksgitops3003204acr</strong> is provisioned within the same resource group and region, with the <strong class="bold">Basic SKU</strong> option and administrative access disabled for enhanced security. The core of the deployment, an <strong class="source-inline">AKS</strong> cluster named <strong class="source-inline">aksgitopscluster</strong>, is then created, featuring a single default node pool configured with minimal resources to ensure cost efficiency. The cluster is set up with a system-assigned identity, streamlining the authentication process across <span class="No-Break">Azure services.</span></p>
			<p>Finally, the<a id="_idIndexMarker767"/> Terraform configuration secures the integration between the AKS cluster and the ACR by assigning the necessary role permissions, enabling seamless container image pulls from the registry to the Kubernetes environment. Feel free to modify the names of the resource <a id="_idIndexMarker768"/>group or ACR and the region where the resources are deployed. In a terminal window, execute the following commands. The entire process will take a few minutes <span class="No-Break">to complete:</span></p>
			<pre class="console">
$ terraform init
$ terraform plan -out aksplan
$ terraform apply -auto-approve aksplan</pre>			<p>Await the successful provisioning of resources, then integrate the <strong class="source-inline">kubectl</strong> configuration for <span class="No-Break">cluster management:</span></p>
			<pre class="console">
$ az aks get-credentials --resource-group aks-k8s-deployments-rg --name aksgitopscluster</pre>			<p>The following are the necessary steps to create a new Azure DevOps project and properly set up an Azure <span class="No-Break">DevOps pipeline:</span></p>
			<ol>
				<li>Establish a new Azure DevOps project, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.1</em>, within your existing Azure account to manage the CI/CD pipeline and project artifacts, opting for <a id="_idIndexMarker769"/>a <strong class="bold">Private Azure DevOps</strong> project setting. For more information on setting up Azure DevOps, please visit https://learn.microsoft.com/en-us/azure/devops/user-guide/sign-up-invite-teammates?view=azure-devops&amp;tabs=microsoft-account. Assign a name to the project, such as <strong class="source-inline">gitops-k8s-deployment</strong>, and optionally add a project description. Select <strong class="bold">Private</strong> for <strong class="bold">Visibility</strong>, and then click the <span class="No-Break"><strong class="bold">Create</strong></span><span class="No-Break"> button.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer112">
					<img alt="Figure 9.1 – The Azure DevOps window for creating a new project" src="image/B22100_09_01.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – The Azure DevOps window for creating a new project</p>
			<ol>
				<li value="2">In<a id="_idIndexMarker770"/> the <strong class="bold">Where is your code?</strong> window, select <strong class="bold">Pick</strong> next to the GitHub option to choose the correct GitHub repository you wish to associate with the Azure DevOps project<a id="_idIndexMarker771"/> you previously created. You can directly use the GitHub repository associated with this chapter or select one that you have created, as seen in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer113">
					<img alt="Figure 9.2 – Selecting a repository panel" src="image/B22100_09_02.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – Selecting a repository panel</p>
			<ol>
				<li value="3">At this <a id="_idIndexMarker772"/>stage, we’re <a id="_idIndexMarker773"/>prepared to configure the pipeline. In the configuration panel, select <strong class="bold">Deploy to Azure Kubernetes Service</strong> as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.3</em></span><span class="No-Break">.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer114">
					<img alt="Figure 9.3 – Configure your pipeline section of the wizard" src="image/B22100_09_03.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – Configure your pipeline section of the wizard</p>
			<ol>
				<li value="4">When prompted, as visible in <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.4</em>, select the Azure subscription where the AKS cluster <a id="_idIndexMarker774"/>was previously configured and deployed using the <span class="No-Break">Terraform script.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer115">
					<img alt="Figure 9.4 – Popup window for selecting the Azure subscription" src="image/B22100_09_04.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4 – Popup window for selecting the Azure subscription</p>
			<ol>
				<li value="5">In the <strong class="bold">Deploy to Azure Kubernetes Service</strong> window, enter the required information<a id="_idIndexMarker775"/> as shown in <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.5</em>. Deploy the application into a new namespace, such <span class="No-Break">as </span><span class="No-Break"><strong class="source-inline">weather-app-namespace</strong></span><span class="No-Break">.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer116">
					<img alt="Figure 9.5 – Deploy to AKS settings window" src="image/B22100_09_05.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5 – Deploy to AKS settings window</p>
			<ol>
				<li value="6">Click the <strong class="bold">Validate and configure</strong> button to review the YAML pipeline. Before continuing, since<a id="_idIndexMarker776"/> the<a id="_idIndexMarker777"/> Dockerfile is not present in the root of the directory, but in the <strong class="source-inline">src</strong> subdirectory, we need to edit the last line of the <span class="No-Break">following code:</span><pre class="source-code">
variables:
# Container registry service connection …
dockerfilePath: '**/Dockerfile'</pre><p class="list-inset">We edit the preceding code <span class="No-Break">this way:</span></p><pre class="source-code">dockerfilePath: '**/src/dockerfile'</pre></li>				<li>Then, click the <strong class="bold">Save and run</strong> button, leave the default values as they are, and click the <strong class="bold">Save and run</strong> button again. The pipeline will be triggered as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer117">
					<img alt="Figure 9.6 – Example of a triggered Azure DevOps pipeline" src="image/B22100_09_06.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.6 – Example of a triggered Azure DevOps pipeline</p>
			<ol>
				<li value="8">Click <a id="_idIndexMarker778"/>on the <strong class="bold">Build</strong> stage to view more details, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.7</em>. This time, there’s no need to build the image locally and then push it to the registry, as everything is handled within the Azure <span class="No-Break">DevOps pipeline.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer118">
					<img alt="Figure 9.7 – Details of building and pushing an image to the container registry" src="image/B22100_09_07.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.7 – Details of building and pushing an image to the container registry</p>
			<p class="list-inset">If required, authorize<a id="_idIndexMarker779"/> permissions for the pipeline, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.8</em></span><span class="No-Break">.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer119">
					<img alt="Figure 9.8 – Popup window to grant permissions for the current and subsequent runs of the pipeline" src="image/B22100_09_08.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.8 – Popup window to grant permissions for the current and subsequent runs of the pipeline</p>
			<ol>
				<li value="9">At this<a id="_idIndexMarker780"/> point, after a few seconds, the pipeline should complete successfully, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.9</em>. An email should be sent to your account notifying you of the pipeline’s <span class="No-Break">successful completion.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer120">
					<img alt="Figure 9.9 – Successful completion of the pipeline" src="image/B22100_09_09.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.9 – Successful completion of the pipeline</p>
			<ol>
				<li value="10">To verify the <a id="_idIndexMarker781"/>deployment, you can utilize tools such as Visual Studio Code or execute the following command in <span class="No-Break">the terminal:</span><pre class="source-code">
<strong class="bold">$ kubectl get pods --namespace weather-app-namespace</strong></pre><p class="list-inset">The output should be <span class="No-Break">as follows:</span></p><pre class="source-code">NAME                 READY   STATUS    RESTARTS   AGE
myweathera…        1/1     Running   0          7m50s</pre><p class="list-inset">At this juncture, we can execute a <strong class="source-inline">port-forward</strong> command to display the app in the browser, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.10</em></span><span class="No-Break">.</span></p></li>			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer121">
					<img alt="Figure 9.10 – A screenshot of weather-app running as a container on AKS" src="image/B22100_09_10.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.10 – A screenshot of weather-app running as a container on AKS</p>
			<ol>
				<li value="11">Now, to<a id="_idIndexMarker782"/> explore<a id="_idIndexMarker783"/> the CI/CD capabilities of Azure DevOps, you could, for example, edit the <strong class="source-inline">data.csv</strong> file, changing the value for the <strong class="source-inline">2023-01-04</strong> day from <strong class="source-inline">4.0</strong> to, say, <strong class="source-inline">5.0</strong> (see <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.11</em>). This file can be edited directly in your GitHub repository or by cloning the repository locally and <span class="No-Break">using Git.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer122">
					<img alt="Figure 9.11 – The updated data.csv file used as a data source from our weather-app application" src="image/B22100_09_11.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.11 – The updated data.csv file used as a data source from our weather-app application</p>
			<p class="list-inset">At this stage, the <a id="_idIndexMarker784"/>pipeline will be automatically triggered once more, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.12</em></span><span class="No-Break">.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer123">
					<img alt="Figure 9.12 – New execution of the pipeline after pushing the updated data.csv file" src="image/B22100_09_12.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.12 – New execution of the pipeline after pushing the updated data.csv file</p>
			<ol>
				<li value="12">By <a id="_idIndexMarker785"/>executing a new <strong class="source-inline">port-forward</strong> command targeting the newly deployed pod, we will have the opportunity to visualize the updated chart (see <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.13</em></span><span class="No-Break">).</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer124">
					<img alt="Figure 9.13 – The weather-app application after a new deployment, triggered by pushing the updated data.csv file" src="image/B22100_09_13.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.13 – The weather-app application after a new deployment, triggered by pushing the updated data.csv file</p>
			<ol>
				<li value="13">To avoid<a id="_idIndexMarker786"/> incurring unnecessary costs, remember to destroy all Azure resources created for this example by typing the following command (or using the <span class="No-Break">Azure portal):</span><pre class="source-code">
<strong class="bold">$ terraform destroy --auto-approve</strong></pre></li>			</ol>
			<p>Congratulations! You<a id="_idIndexMarker787"/> have successfully completed your Azure DevOps CI/CD pipeline with deployment to AKS using an ACR instance. Now, it’s time to transition to the AWS ecosystem to explore how things operate on <span class="No-Break">that side.</span></p>
			<h2 id="_idParaDest-179"><a id="_idTextAnchor182"/>AWS GitOps essentials</h2>
			<p>AWS <a id="_idIndexMarker788"/>embraces the GitOps model by offering a<a id="_idIndexMarker789"/> suite of services designed to facilitate the management of cloud-native applications and infrastructure with high efficiency and reliability. The EKS stands out as AWS’s managed Kubernetes service, compared to other major cloud providers’ offerings such <a id="_idIndexMarker790"/>as <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>) from Google Cloud and AKS from Microsoft Azure. Each provides similar functionalities but with unique features tailored to their respective ecosystems, optimizing the deployment process and ensuring the automatic scaling and management of containerized applications. Integrating EKS with AWS CodePipeline, a service that automates the build, test, and deploy phases of your release process, enables <a id="_idIndexMarker791"/>a GitOps approach where the entire infrastructure is treated as code. This integration empowers teams to implement CD practices, allowing for rapid and safe application updates. AWS’s commitment to GitOps is evident in its tooling and services, which support immutable infrastructure, automated deployments, and detailed monitoring, aligning with the GitOps principles of declarative configuration and <span class="No-Break">version control.</span></p>
			<h3>AWS CodePipepline</h3>
			<p><strong class="bold">AWS CodePipeline</strong> (https://aws.amazon.com/codepipeline/) is a fully managed CI/CD service <a id="_idIndexMarker792"/>that automates the build, test, and deployment phases of your release process. It allows you to create pipelines that automate <a id="_idIndexMarker793"/>the steps required to release your software changes continuously. With CodePipeline, you can define your release process as a series of stages, where each stage performs a specific action, such as fetching source code from a version control system, building and testing your application, and deploying it to <span class="No-Break">your infrastructure.</span></p>
			<p>One of the key features of AWS CodePipeline is its flexibility and integration with other AWS services. You can easily integrate CodePipeline with services such as <strong class="bold">AWS CodeBuild</strong> for<a id="_idIndexMarker794"/> building your application, <strong class="bold">AWS CodeDeploy</strong> for <a id="_idIndexMarker795"/>deploying it to EC2 instances<a id="_idIndexMarker796"/> or <strong class="bold">AWS Lambda functions</strong>, and <strong class="bold">AWS Elastic Beanstalk</strong> for<a id="_idIndexMarker797"/> deploying and managing <span class="No-Break">web applications.</span></p>
			<p>CodePipeline also supports integration with third-party tools and services through custom actions, allowing you to extend its capabilities to fit your specific requirements. Additionally, it provides visibility into your release process through its web-based console, allowing you to monitor the progress of your pipelines and troubleshoot any issues that arise. The <a id="_idIndexMarker798"/>following are the steps for implementing Kubernetes GitOps deployment <a id="_idIndexMarker799"/>with <span class="No-Break">AWS CodePipeline:</span></p>
			<ol>
				<li><strong class="bold">Set up AWS CodePipeline</strong>: Begin by setting up AWS CodePipeline, which orchestrates the CI/CD workflow for your <span class="No-Break">Kubernetes deployment.</span></li>
				<li><strong class="bold">Connect to the GitHub repository</strong>: In the CodePipeline configuration, connect to your GitHub repository where your Kubernetes manifests and deployment scripts <span class="No-Break">are stored.</span></li>
				<li><strong class="bold">Configure source stage</strong>: Define the source stage in the CodePipeline configuration, specifying the GitHub repository and branch to pull the Kubernetes <a id="_idIndexMarker800"/><span class="No-Break">manifests from.</span></li>
				<li><strong class="bold">Add build stage</strong>: Create a build stage in the CodePipeline configuration to execute any <a id="_idIndexMarker801"/>necessary build steps for your Kubernetes deployment, such as compiling code or <span class="No-Break">packaging artifacts.</span></li>
				<li><strong class="bold">Integrate with EKS</strong>: Incorporate EKS into your CodePipeline workflow. This may involve setting up connections or permissions between AWS services <span class="No-Break">and CodePipeline.</span></li>
				<li><strong class="bold">Implement GitOps principles</strong>: Ensure that your CI/CD pipeline adheres to GitOps principles, such as storing all configuration and deployment manifests in version control, automating deployment processes, and using pull-based synchronization for <span class="No-Break">cluster updates.</span></li>
				<li><strong class="bold">Define deployment strategy</strong>: Define the deployment strategy for your Kubernetes application, specifying parameters such as rollout strategy, scaling options, and <span class="No-Break">health checks.</span></li>
				<li><strong class="bold">Trigger deployments</strong>: Configure AWS CodePipeline to trigger deployments automatically whenever changes are pushed to the GitHub repository, maintaining the CD of your <span class="No-Break">Kubernetes application.</span></li>
				<li><strong class="bold">Monitor and debug</strong>: Implement monitoring and logging mechanisms to track the performance and health of your Kubernetes deployments. Ensure that you have tools in place to debug and troubleshoot any issues that may arise <span class="No-Break">during deployment.</span></li>
				<li><strong class="bold">Iterate and improve</strong>: Continuously iterate on your CI/CD pipeline, incorporating feedback and making improvements to enhance the efficiency, reliability, and security<a id="_idIndexMarker802"/> of your Kubernetes deployments <span class="No-Break">over time.</span></li>
			</ol>
			<p>Wrapping up, AWS CodePipeline <a id="_idIndexMarker803"/>streamlines the release process, empowering teams to deliver software changes more rapidly and reliably. By automating the deployment pipeline, CodePipeline helps accelerate time to market and enhances overall productivity, enabling organizations to respond swiftly to customer needs and <span class="No-Break">market demands.</span></p>
			<h3>Kubernetes deployment with AWS CodePipeline</h3>
			<p>In this section, we embark on a hands-on journey to deploy a Kubernetes cluster on AWS, leveraging Terraform, EKS, and AWS CodePipeline. We’ll start by provisioning an EKS cluster and an<a id="_idIndexMarker804"/> Amazon <strong class="bold">Elastic Container Registry</strong> (<strong class="bold">ECR</strong>). The highlight of our journey involves orchestrating the deployment of this image to the EKS cluster using AWS CodePipeline. As done for Azure in the <em class="italic">Kubernetes deployment with Azure DevOps</em> section, this practical walkthrough demonstrates the seamless integration of these components, showcasing how they streamline the deployment process within a GitOps framework. Through this example, readers will gain a comprehensive understanding of deploying applications to Kubernetes using AWS’s <span class="No-Break">powerful services.</span></p>
			<p>For the following walkthrough example, we assume that the reader has a valid AWS account and <a id="_idIndexMarker805"/>has already installed and configured AWS CLI version 2. Please review the following<a id="_idIndexMarker806"/> AWS links <span class="No-Break">for reference:</span></p>
			<ul>
				<li><strong class="bold">AWS CLI user </strong><span class="No-Break"><strong class="bold">guide</strong></span><span class="No-Break">: </span><a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html"><span class="No-Break">https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html</span></a></li>
				<li><strong class="bold">AWS CLI </strong><span class="No-Break"><strong class="bold">examples</strong></span><span class="No-Break">: </span><a href="https://docs.aws.amazon.com/cli/latest/userguide/welcome-examples.html"><span class="No-Break">https://docs.aws.amazon.com/cli/latest/userguide/welcome-examples.html</span></a></li>
			</ul>
			<p>The following are the necessary steps to successfully complete <span class="No-Break">this example:</span></p>
			<ol>
				<li>Ensure that AWS CLI is correctly configured by typing the <span class="No-Break">following command:</span><pre class="source-code">
<strong class="bold">$ aws –version</strong></pre><p class="list-inset">The output should resemble <span class="No-Break">the following:</span></p><pre class="source-code"><strong class="bold">aws-cli/2.15.35 Python/3.11.8 Windows/10 exe/AMD64 prompt/off</strong></pre></li>				<li>To <a id="_idIndexMarker807"/>initialize <a id="_idIndexMarker808"/>Terraform, we use the <strong class="source-inline">terraform init</strong> command. For this step, we will utilize the <strong class="source-inline">main.tf</strong> Terraform files located in the <strong class="source-inline">iac/aws</strong> folder of the GitHub repository accompanying <span class="No-Break">this chapter.</span><p class="list-inset">This <strong class="source-inline">main.tf</strong> Terraform configuration file orchestrates the setup of essential AWS infrastructure components for deploying a Kubernetes cluster and managing container images. It begins by defining the AWS provider and version required for the deployment. Following this, it creates an ECR repository named <strong class="source-inline">eksgitops3003204ecr</strong> to store Docker images with mutable tag mutability. Next, the configuration<a id="_idIndexMarker809"/> provisions a <strong class="bold">virtual private cloud</strong> (<strong class="bold">VPC</strong>) and associated subnets using the <strong class="source-inline">terraform-aws-modules/vpc/aws</strong> module. This VPC, named <strong class="source-inline">eks-cluster-vpc</strong>, spans across two availability zones in the <strong class="source-inline">eu-central-1</strong> AWS region. Subsequently, the configuration sets up an EKS cluster utilizing the <strong class="source-inline">terraform-aws-modules/eks/aws</strong> module. The cluster, named <strong class="source-inline">eksgitopscluster</strong>, operates on version 1.29 and allows public access to its endpoint. It’s integrated with the previously created VPC and utilizes private subnets for <span class="No-Break">enhanced security.</span></p><p class="list-inset">Additionally, the configuration establishes a managed node group within the EKS cluster, configured with one instance of the <strong class="source-inline">t3.small</strong> type. This node group provides the computing resources necessary for running containerized applications within the Kubernetes environment. To facilitate seamless interaction between the EKS cluster and the ECR repository, an <strong class="bold">identity and access management</strong> (<strong class="bold">IAM</strong>) policy named <strong class="source-inline">ecr-pull-policy</strong> is created. This policy grants EKS nodes the permissions required to pull container images from the specified <span class="No-Break">ECR repository.</span></p><p class="list-inset">Finally, the<a id="_idIndexMarker810"/> IAM policy is attached to the IAM role associated with the EKS cluster, ensuring that the cluster nodes have the necessary permissions to retrieve<a id="_idIndexMarker811"/> container images <span class="No-Break">for deployment.</span></p></li>
			</ol>
			<p class="callout-heading">IAM policy</p>
			<p class="callout">An IAM policy<a id="_idIndexMarker812"/> is a document that defines permissions and is used to manage access to AWS resources. IAM policies grant specific rights to users, groups, or roles, determining what actions they can perform on which resources. These policies are made up of statements that include components such as <strong class="bold">Effect</strong> (allow or deny), <strong class="bold">Action</strong> (the specific actions permitted or denied), and <strong class="bold">Resource</strong> (the specific resources to which the actions apply). IAM policies help ensure secure and granular access control within an AWS environment, enabling administrators to enforce the principle of least privilege by giving entities only the permissions they need to perform <span class="No-Break">their tasks.</span></p>
			<ol>
				<li value="3">Type the following commands to start the <span class="No-Break">cluster creation:</span><pre class="source-code">
<strong class="bold">$ terraform init</strong>
<strong class="bold">$ terraform plan -out aksplan</strong>
<strong class="bold">$ terraform apply -auto-approve aksplan</strong></pre><p class="list-inset">The entire process will take nearly 10 minutes to complete. <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.14</em> illustrates the EKS cluster in the AWS console, while <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.15</em> shows the created <span class="No-Break">ECR registry.</span></p></li>			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer125">
					<img alt="Figure 9.14 – The EKS cluster after the execution of the Terraform script" src="image/B22100_09_14.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.14 – The EKS cluster after the execution of the Terraform script</p>
			<div>
				<div class="IMG---Figure" id="_idContainer126">
					<img alt="Figure 9.15 – The ECR registry after the execution of the Terraform script" src="image/B22100_09_15.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.15 – The ECR registry after the execution of the Terraform script</p>
			<ol>
				<li value="4">Integrate<a id="_idIndexMarker813"/> the <strong class="source-inline">kubectl</strong> configuration for <span class="No-Break">cluster management:</span><pre class="source-code">
<strong class="bold">$ aws eks --region eu-central-1 update-kubeconfig --name eksgitopscluster</strong></pre></li>				<li>Type<a id="_idIndexMarker814"/> the following command to test <span class="No-Break">the access:</span><pre class="source-code">
<strong class="bold">$ kubectl cluster-info</strong></pre><p class="list-inset">The output should be <span class="No-Break">as follows:</span></p><pre class="source-code">Kubernetes control plane is running at https://54CE9D2FAC3008E8E5B3D4873E92E7B2.yl4.eu-central-1.eks.amazonaws.com
CoreDNS is running at https://54CE9D2FAC3008E8E5B3D4873E92E7B2.yl4.eu-central-1.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy</pre></li>			</ol>
			<p>If you encounter authentication issues or generic issues after merging the cluster management, you need to add an access entry for the EKS cluster. This involves adding the following permissions to the user configured for the AWS CLI, as specified at the beginning of <span class="No-Break">this section:</span></p>
			<ol>
				<li>In the AWS console, navigate to the <strong class="bold">Access</strong> tab of the EKS cluster (e.g., <strong class="source-inline">eksgitopscluster</strong>) and click on the <strong class="bold">Create access entry</strong> button, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.16</em></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer127">
					<img alt="Figure 9.16 – The EKS cluster page and the Access tab for creating a n﻿ew access entry" src="image/B22100_09_16.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.16 – The EKS cluster page and the Access tab for creating a n<a id="_idTextAnchor183"/>ew access entry</p>
			<ol>
				<li value="2">In <a id="_idIndexMarker815"/>the <strong class="bold">IAM Principal ARN</strong> field, you have to select the IAM ARN that has been <a id="_idIndexMarker816"/>used to configure the AWS CLI and execute AWS CLI commands, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.17</em></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer128">
					<img alt="Figure 9.17 – The IAM principal ARN selection for AWS CLI configuration" src="image/B22100_09_17.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.17 – The IAM principal ARN selection for AWS CLI configuration</p>
			<ol>
				<li value="3">Then, click the <strong class="bold">Next</strong> button at the bottom of the page, and for this example, add all the following policy names (see <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.18</em>) with <strong class="bold">Cluster</strong> as the selected <span class="No-Break"><strong class="bold">Access scope</strong></span><span class="No-Break">:</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer129">
					<img alt="Figure 9.18 – The Access policies section for attaching permissions to the new IAM principal" src="image/B22100_09_18.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.18 – The Access policies section for attaching permissions to the new IAM principal</p>
			<ol>
				<li value="4">Click<a id="_idIndexMarker817"/> the <strong class="bold">Next</strong> button<a id="_idIndexMarker818"/> and then <strong class="bold">Create</strong>. Now, you should be able to administer the cluster using AWS CLI without any issues. For more information and details, please refer to the official <span class="No-Break">documentation: </span><span class="No-Break">https://docs.aws.amazon.com/eks/latest/userguide/access-entries.html#updating-access-entries</span><span class="No-Break">.</span></li>
				<li>Before proceeding with the creation of an instance of AWS CodePipeline, we first need to create <a id="_idIndexMarker819"/>an <strong class="bold">IAM role</strong> named <strong class="source-inline">GitOpsCodeBuildRole</strong>. This role will allow the pipeline to build a new image for our <strong class="source-inline">weather-app</strong> application whenever new code is committed to the repository, push the image to the created ECR, and deploy it to EKS. In the AWS console, navigate to <strong class="bold">IAM</strong> |<strong class="bold">Roles</strong>, and click on the <strong class="bold">Create role</strong> button, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.19</em></span><span class="No-Break">.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer130">
					<img alt="Figure 9.19 – The Roles page in the AWS Management Console, where you can begin creating a new IAM role" src="image/B22100_09_19.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.19 – The Roles page in the AWS Management Console, where you can begin creating a new IAM role</p>
			<p class="callout-heading">IAM role</p>
			<p class="callout">An <strong class="bold">IAM role</strong> in<a id="_idIndexMarker820"/> AWS is a set of permissions that define what actions can be performed on AWS resources. Roles are used to delegate access to users, applications, or services within AWS, allowing them to interact securely with various AWS services. Roles are defined with policies that specify the actions allowed or denied, and they are assumed by entities such as AWS services, IAM users, or AWS resources. This approach ensures secure access control and helps enforce the principle of least privilege, where users and services have only the permissions necessary to perform <span class="No-Break">their tasks.</span></p>
			<ol>
				<li value="6">In<a id="_idIndexMarker821"/> the <strong class="bold">Select trusted entity</strong> section, choose <strong class="bold">AWS service</strong>, and in the <strong class="bold">Use case</strong> panel, select <strong class="bold">CodeBuild</strong>, as<a id="_idIndexMarker822"/> shown in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.20</em></span><span class="No-Break">.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer131">
					<img alt="Figure 9.20 – The Trusted entity type and Use case section on the Create role page" src="image/B22100_09_20.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.20 – The Trusted entity type and Use case section on the Create role page</p>
			<ol>
				<li value="7">On <a id="_idIndexMarker823"/>the <strong class="bold">Add permissions</strong> page, add <a id="_idIndexMarker824"/>the <span class="No-Break">following permissions:</span><ul><li><span class="No-Break"><strong class="source-inline">AmazonEC2ContainerRegistryFullAccess</strong></span></li><li><span class="No-Break"><strong class="source-inline">AmazonS3FullAccess</strong></span></li><li><span class="No-Break"><strong class="source-inline">AWSCodeBuildAdminAccess</strong></span></li><li><span class="No-Break"><strong class="source-inline">AWSCodeCommitFullAccess</strong></span></li><li><span class="No-Break"><strong class="source-inline">CloudWatchLogsFullAccess</strong></span></li></ul><p class="list-inset">Then, add the<a id="_idIndexMarker825"/> following <span class="No-Break"><strong class="bold">inline policy</strong></span><span class="No-Break">:</span></p><pre class="source-code">
{
     "Version": "2012-10-17",
     "Statement": [
          {
               "Effect": "Allow",
               "Action": "eks:Describe*",
               "Resource": "*"
          }
     ]
}</pre></li>			</ol>
			<p class="callout-heading">Inline policy</p>
			<p class="callout">An <strong class="bold">inline policy</strong> is a<a id="_idIndexMarker826"/> set of permissions that can be directly attached to an IAM user, group, or role. Unlike managed policies, which are standalone entities, inline policies are embedded directly within the resources they are intended to control. This allows for more granular control and management of permissions at a more specific level. Inline policies are often used when certain permissions need to be applied only to a specific user, group, or role, rather than being shared across <span class="No-Break">multiple entities.</span></p>
			<p class="list-inset">Before <a id="_idIndexMarker827"/>reviewing <a id="_idIndexMarker828"/>and creating the new IAM role, it’s important to ensure the addition of the specified trust relationship to control who can assume the role, enhancing security and compliance. This setup prevents unauthorized access and ensures that only designated entities can access certain <span class="No-Break">AWS resources:</span></p>
			<pre class="source-code">
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "codebuild.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}</pre>			<p class="list-inset">To complete the process, simply click the <strong class="bold">Create</strong> button. Now, we’re all set to create the AWS <span class="No-Break">CodePipeline instance.</span></p>
			<ol>
				<li value="8">Following<a id="_idIndexMarker829"/> a similar<a id="_idIndexMarker830"/> approach as done for Azure DevOps, refer to the <em class="italic">Kubernetes deployment with Azure DevOps</em> section in this chapter; it’s time to automate the application deployment to AWS EKS using <span class="No-Break">AWS CodePipeline.</span><p class="list-inset">To set up the CodePipeline correctly, navigate to the AWS console, go to <strong class="bold">Services</strong> | <strong class="bold">CodePipeline</strong> | <strong class="bold">Create pipeline</strong>, and configure the pipeline settings with the following values, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.21</em></span><span class="No-Break">:</span></p><ul><li><strong class="bold">Pipeline </strong><span class="No-Break"><strong class="bold">name</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">weather-app-pipeline</strong></span></li><li><strong class="bold">Pipeline </strong><span class="No-Break"><strong class="bold">type</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="bold">V2</strong></span></li><li><strong class="bold">Execution </strong><span class="No-Break"><strong class="bold">mode</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="bold">Queued</strong></span></li><li><strong class="bold">Service role</strong>: <strong class="bold">New </strong><span class="No-Break"><strong class="bold">service role</strong></span></li></ul><p class="list-inset">Then, click the <span class="No-Break"><strong class="bold">Next</strong></span><span class="No-Break"> button.</span></p></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer132">
					<img alt="Figure 9.21 – Initial configurations for the new AWS CodePipeline" src="image/B22100_09_21.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.21 – Initial configurations for the new AWS CodePipeline</p>
			<ol>
				<li value="9">In <strong class="bold">Add source</strong><strong class="bold"> stage</strong>, select <strong class="source-inline">GitHub (Version 2)</strong> as <strong class="bold">Source provider</strong>, then click on <strong class="bold">Connect to GitHub</strong> and follow the instructions to authenticate your <a id="_idIndexMarker831"/>GitHub <a id="_idIndexMarker832"/>connection. Once the connection is established, choose the GitHub repository in the <strong class="bold">Repository name</strong> field. Set the <strong class="bold">Default</strong> branch to <strong class="source-inline">main</strong>. For <strong class="bold">Output artifact format</strong>, select the <strong class="source-inline">CodePipeline</strong> default. Finally, click the <span class="No-Break"><strong class="bold">Next</strong></span><span class="No-Break"> button.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer133">
					<img alt="Figure 9.22 – Connection with the GitHub repository source" src="image/B22100_09_22.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.22 – Connection with the GitHub repository source</p>
			<ol>
				<li value="10">In <strong class="bold">Add build stage</strong>, select <strong class="bold">AWS CodeBuild</strong> as the build provider (refer to <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.23</em>). Choose <a id="_idIndexMarker833"/>the<a id="_idIndexMarker834"/> same region where EKS and ECR resources have been previously deployed, and then click on <span class="No-Break"><strong class="bold">Create project</strong></span><span class="No-Break">.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer134">
					<img alt="Figure 9.23 – The section of the Build panel related to selecting the build provider and region" src="image/B22100_09_23.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.23 – The section of the Build panel related to selecting the build provider and region</p>
			<ol>
				<li value="11">In the <strong class="bold">Create build project</strong> window, set <strong class="source-inline">weather-app-build</strong> as the project <a id="_idIndexMarker835"/>name and keep all other values as default, except for <strong class="bold">Service role</strong> where<a id="_idIndexMarker836"/> you need to select <strong class="bold">Existing service role</strong> and enter the previously created role (see <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.24</em> for more <span class="No-Break">details): </span><span class="No-Break"><strong class="source-inline">arn:aws:iam::[AWS_ACCOUNT_ID]:role/GitOpsCodeBuildRole</strong></span><span class="No-Break">.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer135">
					<img alt="Figure 9.24 – The section of the Build panel related to the selection of service roles and roles" src="image/B22100_09_24.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.24 – The section of the Build panel related to the selection of service roles and roles</p>
			<ol>
				<li value="12">In the <strong class="bold">Build</strong> panel, select <strong class="bold">Insert build commands</strong>, then click on <strong class="bold">Switch to editor</strong>, and add the content of the <strong class="source-inline">buildspec.yaml</strong> file. Then, click the <strong class="bold">Continue to CodePipeline</strong> button. Click on the <strong class="bold">Add environment variable</strong> button and add two environment variables (refer to <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.25</em></span><span class="No-Break">):</span><ul><li><span class="No-Break"><strong class="source-inline">ECR_REPOSITORY_URI</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">[AWS_ACCOUNT_ID].dkr.ecr.eu-central-1.amazonaws.com</strong></span></li><li><span class="No-Break"><strong class="source-inline">IMAGE_AND_TAG</strong></span><span class="No-Break">: </span><span class="No-Break"><strong class="source-inline">weather-app:latest</strong></span></li></ul></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer136">
					<img alt="Figure 9.25 – The section of the Build panel related to adding environment variables" src="image/B22100_09_25.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.25 – The section of the Build panel related to adding environment variables</p>
			<ol>
				<li value="13">For <strong class="bold">Build type</strong>, select <strong class="bold">Single Build</strong>. Click the <strong class="bold">Next</strong> button. At the <strong class="bold">Add deploy stage</strong> step, click on the <strong class="bold">Skip deploy stage</strong> button, and then on <strong class="bold">Next</strong>. Review<a id="_idIndexMarker837"/> the <a id="_idIndexMarker838"/>pipeline at the final stage and click the <strong class="bold">Create pipeline</strong> button. At this point, the CodePipeline will be triggered and completed successfully in one minute (see <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.26</em></span><span class="No-Break">).</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer137">
					<img alt="Figure 9.26 – weather-app-pipeline immediately after its definition" src="image/B22100_09_26.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.26 – weather-app-pipeline immediately after its definition</p>
			<ol>
				<li value="14">At the end of the pipeline execution, we can verify that the Docker image of <strong class="source-inline">weather-app</strong> has been correctly built and pushed to the ECR, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.27</em></span><span class="No-Break">.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer138">
					<img alt="Figure 9.27 – The weather-app:latest image successfully pushed to the ECR" src="image/B22100_09_27.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.27 – The weather-app:latest image successfully pushed to the ECR</p>
			<ol>
				<li value="15">To <a id="_idIndexMarker839"/>verify <a id="_idIndexMarker840"/>that the deployment has been successfully completed, execute the <span class="No-Break">following command:</span><pre class="source-code">
<strong class="bold">$ kubectl get deployments</strong></pre><p class="list-inset">Here is <span class="No-Break">the output:</span></p><pre class="source-code">NAME                  READY   UP-TO-DATE   AVAILABLE   AGE
my-city-weather-app   1/1     1            1           64m</pre></li>				<li>At this point, we can execute a <strong class="source-inline">port-forward</strong> command to display the app in the browser, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.28</em></span><span class="No-Break">.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer139">
					<img alt="Figure 9.28 – weather-app rendered in the browser after the deployment" src="image/B22100_09_28.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.28 – weather-app rendered in the browser after the deployment</p>
			<ol>
				<li value="17">Attempt <a id="_idIndexMarker841"/>to<a id="_idIndexMarker842"/> edit the data source file as described in <em class="italic">Step 11</em> of the <em class="italic">Kubernetes deployment with Azure DevOps</em> section. After pushing the changes, <strong class="source-inline">weather-pipeline</strong> will be triggered immediately, as illustrated in <span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.29</em>. Perform a new <strong class="source-inline">port-forward</strong> command to view the updated version of <span class="No-Break">the chart.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer140">
					<img alt="Figure 9.29 – The pipeline is immediately triggered after pushing the updated data.csv file" src="image/B22100_09_29.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.29 – The pipeline is immediately triggered after pushing the updated data.csv file</p>
			<p>To avoid incurring unnecessary costs, remember to delete all AWS resources created for this example after you’ve finished by executing the appropriate commands or using the AWS <span class="No-Break">Management Console.</span></p>
			<p>Congratulations! At this stage, you’ve successfully completed the deployment of the weather application on Azure using Azure DevOps and on AWS using CodePipeline. Now, let’s delve into GitOps applications in cloud environments in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-180"><a id="_idTextAnchor184"/>GitOps applications in cloud environments</h1>
			<p>The <a id="_idIndexMarker843"/>advent of GitOps has significantly revolutionized the way cloud environments are managed and deployed, by embedding the principles of version control and collaboration into the operational fabric of cloud-native applications. GitOps applications extend beyond mere deployment automation, encapsulating the entire life cycle of cloud resources and services. This includes provisioning, scaling, updating, and decommissioning, all governed through Git pull requests. The methodology fosters a transparent, auditable, and easily reversible process, enhancing both the security and compliance of cloud applications. Moreover, GitOps practices ensure that the desired state of the cloud environment is declaratively defined and maintained, promoting consistency and reliability across different stages of development and production. This systematic approach minimizes discrepancies between environments, significantly reducing <em class="italic">it works on my machine</em> issues and streamlining the path <span class="No-Break">to production.</span></p>
			<h2 id="_idParaDest-181"><a id="_idTextAnchor185"/>Cross-cloud strategies</h2>
			<p>In today’s multi-cloud landscape, organizations <a id="_idIndexMarker844"/>often leverage the unique advantages of Azure, AWS, and other cloud providers to optimize their operations and costs. Managing deployments across such diverse environments<a id="_idIndexMarker845"/> can present challenges, particularly in maintaining consistency and efficiency. GitOps offers a unified strategy for managing these deployments, facilitating cross-cloud interoperability and configuration management. The following is a list of benefits of adopting GitOps in a <span class="No-Break">cross-cloud setup:</span></p>
			<ul>
				<li><strong class="bold">Unified configuration management</strong>: By storing infrastructure definitions and configurations as code in a Git repository, teams can use the same GitOps workflows to manage deployments across Azure, AWS, and other clouds. This centralizes control and ensures consistency across <span class="No-Break">cloud environments.</span></li>
				<li><strong class="bold">Interoperability and portability</strong>: Leveraging containerization and Kubernetes, applications can be designed to run seamlessly across different clouds. GitOps practices, coupled with these technologies, simplify the process of deploying and managing these applications, irrespective of the underlying <span class="No-Break">cloud platform.</span></li>
				<li><strong class="bold">Automated synchronization</strong>: Tools such as Argo CD or Flux can be used to automatically<a id="_idIndexMarker846"/> synchronize the desired state in the Git repository with the actual state in each cloud environment. This<a id="_idIndexMarker847"/> ensures that all environments adhere to the same configurations and policies, facilitating a smooth and consistent operational workflow <span class="No-Break">across clouds.</span></li>
				<li><strong class="bold">Environment parity</strong>: GitOps enables teams to replicate environments across different clouds with high fidelity. This is particularly useful for testing, where an application deployed on Azure can be tested under similar conditions on AWS, ensuring that the application behaves consistently <span class="No-Break">across platforms.</span></li>
				<li><strong class="bold">Secrets management</strong>: Managing secrets and sensitive information can be challenging in a cross-cloud setup. GitOps workflows can integrate with cloud-specific secrets management services such as Azure Key Vault or AWS Secrets Manager, allowing secure handling of secrets while maintaining the flexibility of <span class="No-Break">cross-cloud deployments.</span></li>
			</ul>
			<p>Adopting a GitOps approach for cross-cloud strategies not only simplifies the complexity inherent in multi-cloud environments but also enhances operational efficiency, security, and compliance. By treating infrastructure and application configurations as code, teams gain the agility to adapt to changes swiftly, ensuring their deployments remain aligned with organizational goals and industry best practices. In the next section, we will introduce which GitOps strategies should be adopted for Kubernetes deployments on Azure <span class="No-Break">and AWS.</span></p>
			<h1 id="_idParaDest-182"><a id="_idTextAnchor186"/>GitOps strategies for Azure and AWS deployments for Kubernetes</h1>
			<p>In the realm of Kubernetes deployments, GitOps strategies offer a paradigm shift towards more efficient, transparent, and reliable operations. By leveraging GitOps principles, organizations can automate deployment processes, ensure consistency across environments, and significantly enhance their operational workflows. The following are insights into GitOps strategies tailored for Kubernetes deployments on Azure <span class="No-Break">and AWS.</span></p>
			<h2 id="_idParaDest-183"><a id="_idTextAnchor187"/>Azure GitOps strategies</h2>
			<p>Adopting<a id="_idIndexMarker848"/> GitOps strategies for AKS entails a detailed approach to integrating source control, CI/CD pipelines, and configuration management to enhance deployment processes. A pivotal strategy involves the deployment of IaC using tools such as ARM templates or Terraform, which are stored in Git repositories. This approach enables the declarative management of AKS configurations. <em class="italic">Chapters 10</em> and <em class="italic">11</em> will provide comprehensive examples of automating IaC with Terraform on Azure. These automations facilitate automated and repeatable deployments, thereby improving the stability and scalability <span class="No-Break">of applications.</span></p>
			<p>The use of Azure Policy in conjunction with GitOps further enforces compliance and governance across Kubernetes clusters, ensuring that deployments adhere to organizational and regulatory standards. Integrating Azure Monitor with GitOps workflows enables teams to implement observability as a core component of their operations, allowing for proactive monitoring and troubleshooting of <span class="No-Break">AKS deployments.</span></p>
			<h2 id="_idParaDest-184"><a id="_idTextAnchor188"/>AWS GitOps strategies</h2>
			<p>AWS offers <a id="_idIndexMarker849"/>a robust ecosystem for implementing GitOps with EKS. The foundation of AWS GitOps strategies lies in leveraging Amazon ECR for the Docker container registry, AWS CodeCommit for source control, and AWS CodePipeline for continuous integration and deployment. Similar to Azure, AWS advocates for the use of IaC, with AWS CloudFormation or Terraform as preferred tools, to manage EKS cluster configurations and resources in a <span class="No-Break">declarative manner.</span></p>
			<p>An effective GitOps strategy on AWS encompasses the integration of AWS CodeBuild and AWS CodeDeploy within the CI/CD pipeline, automating the build, test, and deployment phases directly from Git repositories. Moreover, the AWS App Mesh service can be integrated into GitOps workflows to manage microservices more effectively, providing end-to-end visibility and network traffic control <span class="No-Break">across applications.</span></p>
			<p>For both Azure<a id="_idIndexMarker850"/> and AWS, implementing GitOps for Kubernetes deployments revolves around four key principles: version control, automated deployments, merge/pull requests for change management, and observability. By adhering to these principles, organizations can achieve automated, predictable, and secure application deployments at scale. Utilizing GitOps not only simplifies Kubernetes cluster management but also aligns operational practices with development workflows, fostering a culture of collaboration and <span class="No-Break">continuous improvement.</span></p>
			<h1 id="_idParaDest-185"><a id="_idTextAnchor189"/>Summary</h1>
			<p>By now, we have gained a thorough understanding of how GitOps can be effectively implemented within the Azure and AWS cloud environments. The chapter covered the necessary tools and processes, such as AKS, Azure DevOps, AWS EKS, and AWS CodePipeline, to establish robust CI/CD pipelines and manage deployments seamlessly. With practical examples and expert advice, this chapter ensured that readers can apply these concepts to achieve more automated, consistent, and secure cloud-native deployments. Emphasizing the importance of a solid foundation in Git, Docker, and Kubernetes, the chapter prepared readers to embrace the full potential of GitOps in their cloud computing ventures. In the next chapter, we will explore the integration of GitOps with Terraform and Flux, focusing on infrastructure. We’ll cover the essential steps to align infrastructure as code with real-time operations, using Terraform for provisioning and Flux for CD. The discussion will also highlight best practices and common challenges in <span class="No-Break">this process.</span></p>
		</div>
	</body></html>