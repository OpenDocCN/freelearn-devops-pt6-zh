- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Handling the Kubernetes Platform for IoT and Edge Computing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes has achieved significant adoption in data center and cloud environments
    since its launch in 2014\. Kubernetes has progressed from orchestrating lightweight
    application containers to managing and scheduling a diverse set of IT workloads,
    ranging from virtualized network operations to AI/ML and GPU hardware resources.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes is quickly gaining popularity as the most popular control plane for
    scheduling and managing work in distributed systems. These activities could involve
    deploying virtual machines on real hosts, pushing containers to edge nodes, and
    even expanding the control plane to incorporate additional schedulers, such as
    serverless environments. Its extensibility makes it a universal scheduler and
    the most preferred management platform. In this chapter, we are going to explore
    various deployment approaches to how Kubernetes, the edge, and the cloud can collaborate
    to drive intelligent business decisions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reiterating the points we discussed in the last chapter, the following considerations
    must be noted while building the edge architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Autonomy and resiliency**: Because the solution necessitates autonomy, connection
    interruptions cannot be permitted.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource constraints**: Low compute capability and small device footprints.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security challenges**: Data privacy, physical device security, and the network
    security of the connected devices.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Manageability**: Manage application software across thousands of devices
    from many different suppliers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reliability**: Consistency in the building, deployment, and maintenance of
    applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automation**: With high levels of automation, provision for automated mechanisms
    to deploy and maintain multiple distributed applications over any number of physical
    or virtual computers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let''s look at four architectural approaches that meet these criteria. In this
    chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Deployment approaches for edge computing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Propositions that Kubernetes offers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment approaches for edge computing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The following approaches demonstrate how Kubernetes can be used for edge workloads,
    as well as support for the architecture that meets enterprise applications' requirements
    – low latency, resource constraints, data privacy, bandwidth scalability, and
    others.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment of the entire Kubernetes cluster at the edge
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The complete Kubernetes cluster is deployed among edge nodes in this approach.
    This solution is better suited to situations where the edge node has limited capacity
    and does not want to consume additional resources for control planes and nodes.
  prefs: []
  type: TYPE_NORMAL
- en: The simplest production-grade upstream **K8s** is **MicroK8s**, a **Cloud Native
    Computing Foundation**-certified Kubernetes distribution that is lightweight and
    focused, with options to install on Linux, Windows, and macOS.
  prefs: []
  type: TYPE_NORMAL
- en: Another example is K3s from Rancher, which is a Cloud Native Computing Foundation-certified
    Kubernetes distribution and is designed for production workloads running in resource-constrained
    environments such as IoT and edge computing deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'The minimal K3s Kubernetes cluster running on edge nodes is depicted in the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – K3s architecture ](img/Figure_4.1_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – K3s architecture
  prefs: []
  type: TYPE_NORMAL
- en: MicroK8s and K3s can be installed on public cloud virtual machines or even on
    a Raspberry Pi device. The architecture is highly optimized for unattended, remote
    installations on resource-constrained devices while preserving complete compatibility
    and compliance with Cloud Native Computing Foundation Kubernetes conformance tests.
  prefs: []
  type: TYPE_NORMAL
- en: By making it accessible and lightweight, MicroK8s and K3s are bringing Kubernetes
    to the edge computing layer.
  prefs: []
  type: TYPE_NORMAL
- en: 'A quick comparison of MicroK8s and K3s is shown in the following table:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 4.1 – Comparison of MicroK8s and K3s ](img/B18115_04_Table_4.1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 4.1 – Comparison of MicroK8s and K3s
  prefs: []
  type: TYPE_NORMAL
- en: 'Optionally, you can also use platforms such as Google Anthos or AKS to manage
    and orchestrate container workloads on multiple clusters like the one shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Google Anthos on the cloud and MicroK8s at the edge ](img/Figure_4.2_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – Google Anthos on the cloud and MicroK8s at the edge
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapters, we'll look at implementation aspects of common edge
    computing applications using MicroK8s.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment of Kubernetes nodes at the edge
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The core Kubernetes cluster is installed at a cloud provider or in your data
    center in this approach, with Kubernetes nodes deployed at the edge nodes. This
    is more appropriate for use cases where the infrastructure at the edge is constrained.
  prefs: []
  type: TYPE_NORMAL
- en: '**KubeEdge**, an open source application that extends native containerized
    application orchestration and device management to hosts at the edge, is an example
    of this approach. KubeEdge is made up of two parts: the cloud and the edge.'
  prefs: []
  type: TYPE_NORMAL
- en: It is based on Kubernetes and enables networking, application deployment, and
    metadata synchronization between the cloud and edge infrastructures. Developers
    can also use MQTT to write custom logic and enable resource-constrained device
    communication at the edge. KubeEdge is reliable and supports the most common IoT
    and edge use cases. It can be run on a compatible Linux distribution or an ARM
    device such as a Raspberry Pi.
  prefs: []
  type: TYPE_NORMAL
- en: 'The architecture of KubeEdge is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.3 – KubeEdge architecture ](img/Figure_4.3_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.3 – KubeEdge architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Here''s a quick rundown of KubeEdge''s different components:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 4.2 – KubeEdge components ](img/B18115_04_Table_4.2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 4.2 – KubeEdge components
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some of KubeEdge''s primary features:'
  prefs: []
  type: TYPE_NORMAL
- en: Users can orchestrate apps, manage devices, and monitor app and device status
    on edge nodes using KubeEdge, just like they can with a regular Kubernetes cluster
    in the cloud.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bidirectional communication, able to talk to edge nodes located in private subnets.
    Supports both metadata and data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Even when the edge is disconnected from the cloud, it can operate autonomously.
    Metadata is persistent per node; thus, no list-watching is required during node
    recovery. This allows you to get ready faster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the edge, resource use is optimized. The memory footprint has been reduced
    to around 70 MB.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For IoT and Industrial IoT, connectivity between applications and devices is
    simplified.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Native support for x86, ARMv7, and ARMv8 architectures.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Support for running third-party plugins and apps that rely on Kubernetes APIs
    on edge nodes with an autonomous Kube-API endpoint at the edge.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment of virtual Kubernetes nodes at the edge
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Virtual node agents reside in the cloud in this approach, but the abstract of
    nodes and Pods is deployed at the edge. Edge nodes carrying containers are given
    command control via virtual node agents.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although there are others, Microsoft''s Virtual Kubelet project is a nice example
    of a kubelet agent with a Kubernetes API extension. Virtual Kubelet is a Kubernetes
    agent that runs in a remote environment and registers itself as a cluster node.
    To build a node resource on the cluster, the agent uses the Kubernetes API. It
    uses the notions of taints and tolerations to schedule Pods in an external environment
    by calling its native API:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Microsoft Virtual Kubelet ](img/Figure_4.4_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.4 – Microsoft Virtual Kubelet
  prefs: []
  type: TYPE_NORMAL
- en: Virtual Kubelet works with providers such as AWS Fargate control plane, Azure
    Container Instances, and Azure IoT Edge. Following is a list of current providers
    (as of this writing).
  prefs: []
  type: TYPE_NORMAL
- en: Current list of Virtual Kubelet providers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we''ll take a look at some of the Virtual Kubelet providers:'
  prefs: []
  type: TYPE_NORMAL
- en: '**AWS Fargate**: Your Kubernetes cluster is connected to an AWS Fargate cluster
    using the AWS Fargate virtual-kubelet provider. The Fargate cluster appears as
    a virtual node with the CPU and memory resources you choose'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pods scheduled on the virtual node execute on Fargate in the same way as they
    would on a regular Kubernetes node.
  prefs: []
  type: TYPE_NORMAL
- en: '**Admiralty Multi-Cluster Scheduler**: Admiralty is a Kubernetes controller
    system that schedules workloads intelligently among clusters. It''s easy to use
    and integrates with other applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alibaba Cloud Elastic Container Instance** (**ECI**): The Alibaba ECI provider
    is an adaptor that connects your Kubernetes cluster to the ECI service, allowing
    Pods from a K8s cluster to be implemented on Alibaba''s cloud platform.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Batch**: Azure Batch provides a distributed HPC computing environment
    on Azure. Azure Batch is a service that manages the scheduling of discrete processes
    and tasks across pools of virtual machines. It''s frequently used for batch processing
    jobs such as rendering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Container Instances** (**ACI**): ACI in Azure provides a hosted environment
    for running containers. When you use ACI, you don''t have to worry about managing
    the underlying compute infrastructure because Azure does it for you. When using
    ACI to run containers, you are charged per second for each container that is running'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Virtual Kubelet's ACI provider configures an ACI instance as a node in any
    Kubernetes cluster. Pods can be scheduled on an ACI instance as if it were a conventional
    Kubernetes node when utilizing the Virtual Kubelet ACI provider
  prefs: []
  type: TYPE_NORMAL
- en: This setup enables you to benefit from both Kubernetes' capabilities and ACI's
    management value and cost savings.
  prefs: []
  type: TYPE_NORMAL
- en: '**Elotl Kip**: Kip is a Virtual Kubelet provider that enables a Kubernetes
    cluster to launch Pods on their own cloud instances in a transparent manner. The
    kip Pod runs on a cluster and creates a virtual Kubernetes node within it'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kip starts a right-sized cloud instance for the Pod's workload and sends the
    Pod to the instance when a Pod is scheduled on the Virtual Kubelet. The cloud
    instance is terminated once the Pod has finished operating. These cloud instances
    are referred to as *cells*
  prefs: []
  type: TYPE_NORMAL
- en: When workloads run on Kip, your cluster size naturally scales with the cluster
    workload, Pods are strongly isolated from each other, and the user is freed from
    managing worker nodes and strategically packing Pods onto nodes. This results
    in lower cloud costs, improved security, and simpler operational overhead.
  prefs: []
  type: TYPE_NORMAL
- en: '**Kubernetes Container Runtime Interface** (**CRI**): The CRI provider implementation
    should be regarded as a bare-bones minimal implementation for testing the Virtual
    Kubelet project''s core against real Pods and containers; in other words, it is
    more extensive than MockProvider'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This provider implementation is also built in such a way that it may be used
    to prototype new architectural features on local Linux infrastructure. If the
    CRI provider can be demonstrated to run effectively within a Linux guest, it may
    be assumed that the abstraction will work for other providers as well.
  prefs: []
  type: TYPE_NORMAL
- en: '**Huawei Cloud Container Instance** (**CCI**): The Huawei CCI virtual kubelet
    provider sets up a CCI project as a node in any Kubernetes cluster, including
    **Huawei Cloud Container Engine** (**CCE**). As a private cluster, CCE provides
    native Kubernetes applications and tools, allowing you to quickly build up a container
    runtime environment. The virtual kubelet provider''s scheduled Pod will run in
    CCI, taking advantage of CCI''s high performance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**HashiCorp Nomad**: By exposing the Nomad cluster as a node in Kubernetes,
    the HashiCorp Nomad provider for Virtual Kubelet connects your Kubernetes cluster
    with the Nomad cluster. Pods scheduled on the virtual Nomad node registered on
    Kubernetes will run as jobs on Nomad clients, just like they would on a Kubernetes
    node, if you use the provider.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Liqo**: Liqo is an on-prem or managed platform that enables dynamic and decentralized
    resource sharing among Kubernetes clusters. Liqo makes it possible to launch Pods
    on a distant cluster without modifying Kubernetes or the apps'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'With Liqo, you can extend a Kubernetes cluster''s control plane across cluster
    boundaries, making multi-clusters native and transparent: collapse a complete
    remote cluster to a virtual local node, allowing task offloading and resource
    management in accordance with standard Kubernetes practices.'
  prefs: []
  type: TYPE_NORMAL
- en: '**OpenStack Zun**: Your Kubernetes cluster is connected to an OpenStack cloud
    through the OpenStack Zun virtual kubelet provider. Because each Pod is provided
    with dedicated Neutron ports in your tenant subnets, your OpenStack Pods have
    access to OpenStack tenant networks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tencent Games tensile-kube**: This allows Kubernetes clusters to collaborate.
    Tensile-kube is based on Virtual Kubelet and offers the following features:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cluster resources are discovered automatically.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Pods are notified of changes in real time, reducing the expense of frequent
    lists.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: All kubectl logs and kubectl exec operations are supported.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: When utilizing a multi-scheduler, schedule Pods globally to avoid unscheduled
    Pods owing to resource fragmentation.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: If Pods can't be scheduled in lower clusters, use a descheduler to reschedule
    them.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Supports PV/PVC and service abstractions.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment of Kubernetes devices at the edge
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Kubernetes device plugin framework is used to expose leaf devices as resources
    in a Kubernetes cluster in this approach.
  prefs: []
  type: TYPE_NORMAL
- en: 'This technique is demonstrated by **Microsoft Akri**, which exposes a variety
    of sensors, controllers, and MCU class leaf devices as resources in a Kubernetes
    cluster. The Akri project brings the Kubernetes device plugin concept to the edge,
    where a variety of leaf devices use different communication protocols and have
    sporadic availability:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Akri architecture ](img/Figure_4.5_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.5 – Akri architecture
  prefs: []
  type: TYPE_NORMAL
- en: ONVIF, Udev, and OPC UA discovery handlers are now supported by Akri. More protocol
    support is being developed.
  prefs: []
  type: TYPE_NORMAL
- en: As seen previously, a variety of deployment approaches indicate how Kubernetes
    may be utilized for edge workloads, as well as support for the architecture that
    fulfills enterprise application needs such as low latency, resource constraints,
    data privacy, and bandwidth scalability, among others.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at how Kubernetes is suitable for running
    edge workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Propositions that Kubernetes offers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In terms of resource and workload control, edge-based infrastructure poses
    various challenges. There would be thousands of edge nodes and distant edge nodes
    to control in a short amount of time. Organizations'' edge architecture is designed
    to provide more centralized autonomy from the cloud, security standards, and relatively
    low latency. Take a peek at what Kubernetes for edge has to offer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Table 4.3 – Propositions that Kubernetes offers ](img/B18115_04_Table_4.3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Table 4.3 – Propositions that Kubernetes offers
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes is a critical component of businesses that are evolving into digital-first
    enterprises. Kubernetes is currently being deployed in 59% of data centers to
    increase resource efficiency and offer agility to the software development cycle,
    according to reports. In a distributed cloud environment, Kubernetes can manage
    and orchestrate containerized applications as well as legacy virtual machines.
    Kubernetes can also be used to execute AI/ML and GPU workloads, in addition to
    pure applications.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes is certainly the go-to platform for edge computing, at least for
    those edge contexts that require dynamic orchestration for apps and centralized
    administration of workloads, according to the Linux Foundation's *The State of
    the Edge Report*. Kubernetes extends the benefits of cloud-native computing software
    development to the edge, allowing for flexible and automated management of applications
    that span a disaggregated cloud environment.
  prefs: []
  type: TYPE_NORMAL
- en: By deploying and testing Kubernetes at the edge, enterprises and telecom operators
    can achieve a high level of flexibility, observability, and dynamic orchestration.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As companies embrace digital transformation, Industry 4.0, industrial automation,
    smart manufacturing, and all the advanced use cases that these initiatives provide,
    the relevance of Kubernetes, edge, and cloud collaborating to drive intelligent
    business decisions is becoming clear. We've looked at a different approach that
    shows how Kubernetes may be used for running edge workloads. In the next chapters,
    we'll go over the deployment of a whole Kubernetes cluster at the edge approach
    in depth. Other approaches are beyond the scope of this book.
  prefs: []
  type: TYPE_NORMAL
- en: In the following chapters, we'll go over implementation aspects of common edge
    computing applications using MicroK8s in detail, such as running your applications
    on a multi-node Raspberry Pi cluster; configuring load balancing; installing/configuring
    different CNI plugins for network connectivity; configuring logging, monitoring,
    and alerting options; and building/deploying ML models and serverless applications.
  prefs: []
  type: TYPE_NORMAL
- en: Also, we will look into setting up storage replication for your stateful applications,
    implementing a service mesh for cross-cutting concerns, high-availability clusters
    to withstand a component failure and continue to serve workloads without interruption,
    the configuration of containers with workload isolation, and running secured containers
    with isolation from the host system.
  prefs: []
  type: TYPE_NORMAL
- en: 'Part 3: Running Applications on MicroK8s'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This part focuses on the implementation aspects that are common for any IoT/edge
    computing applications, such as running your applications on a multi-node Raspberry
    Pi cluster, installing/configuring different CNI plugins for network connectivity,
    configuring load balancing, configuring logging, monitoring, alerting options,
    building, and deploying machine learning models, and serverless applications.
  prefs: []
  type: TYPE_NORMAL
- en: 'This part of the book comprises the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B18115_05.xhtml#_idTextAnchor070), *Creating and Implementing
    Updates on Multi-Node Raspberry Pi Kubernetes Clusters*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B18115_06.xhtml#_idTextAnchor085), *Configuring Connectivity
    for Containers*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B18115_07.xhtml#_idTextAnchor107), *Setting Up MetalLB and Ingress
    for Load Balancing*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B18115_08.xhtml#_idTextAnchor121), *Monitoring the Health of
    Infrastructure and Applications*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B18115_09.xhtml#_idTextAnchor136), *Using Kubeflow to Run AI/MLOps
    Workloads*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 10*](B18115_10.xhtml#_idTextAnchor157), *Going Serverless with Knative
    and OpenFaaS Frameworks*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
