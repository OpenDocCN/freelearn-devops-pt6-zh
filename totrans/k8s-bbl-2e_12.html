<html><head></head><body>
  <div class="Basic-Text-Frame" id="_idContainer230">
    <h1 class="chapterNumber">12</h1>
    <h1 class="chapterTitle" id="_idParaDest-423">StatefulSet – Deploying Stateful Applications</h1>
    <p class="normal">In the previous chapter, we explained how to use a Kubernetes cluster to run <em class="italic">stateless</em> workloads and applications and how to use Deployment objects for this purpose. Running stateless workloads in the cloud is generally easier to handle, as any container replica can handle the request without taking any dependencies on the results of previous operations by the end user. In other words, every container replica would handle the request in an identical way; all you need to care about is proper load balancing.</p>
    <p class="normal">However, the main complexity is in managing the <em class="italic">state</em> of applications. By <em class="italic">state,</em> we mean any stored <em class="italic">data</em> that the application or component needs to serve the requests, and it can be modified by these requests. The most common example of a stateful component in applications is a database – for example, it can be a <strong class="keyWord">relational MySQL database</strong> or a <strong class="keyWord">NoSQL MongoDB database</strong>. In Kubernetes, you can use a dedicated object to run <em class="italic">stateful</em> workloads and applications: StatefulSet. When managing StatefulSet objects, you will usually need to work with Persistent Volumes (PVs), which have been covered in <em class="chapterRef">Chapter 9</em>, <em class="italic">Persistent Storage in Kubernetes</em>. This chapter will provide you with knowledge about the role of StatefulSet in Kubernetes and how to create and manage StatefulSet objects to release new versions of your stateful applications.</p>
    <p class="normal">In this chapter, we will cover the following topics:</p>
    <ul>
      <li class="bulletList">Introducing the StatefulSet object</li>
      <li class="bulletList">Managing StatefulSet</li>
      <li class="bulletList">Releasing a new version of an app deployed as a StatefulSet</li>
      <li class="bulletList">StatefulSet best practices</li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-424">Technical requirements</h1>
    <p class="normal">For this chapter, you will need the following:</p>
    <ul>
      <li class="bulletList">A deployed Kubernetes cluster is needed. You can use either a local or a cloud-based cluster, but to fully understand the concepts, we recommend using a <strong class="keyWord">multi-node</strong>, cloud-based Kubernetes cluster. The cluster must support the creation of PersistentVolumeClaims. Any cloud-based cluster, or local cluster, for example, <code class="inlineCode">minikube</code> with a <code class="inlineCode">k8s.io/minikube-hostpath</code> provisioner, will be sufficient.</li>
      <li class="bulletList">A Kubernetes CLI (<code class="inlineCode">kubectl</code>) must be installed on your local machine and configured to manage your Kubernetes cluster.</li>
    </ul>
    <p class="normal">Kubernetes cluster deployment (local and cloud-based) and <code class="inlineCode">kubectl</code> installation have been covered in <em class="chapterRef">Chapter 3</em>, <em class="italic">Installing Your First Kubernetes Cluster</em>.</p>
    <p class="normal">You can download the latest code samples for this chapter from the official GitHub repository at <a href="https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter12"><span class="url">https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter12</span></a>.</p>
    <h1 class="heading-1" id="_idParaDest-425">Introducing the StatefulSet object</h1>
    <p class="normal">You may wonder why running <a id="_idIndexMarker1088"/>stateful workloads in the distributed cloud is generally considered <strong class="keyWord">harder</strong> than running stateless ones. In classic three-tier applications, all the states would be stored in a database (<em class="italic">data tier</em> or <em class="italic">persistence layer</em>) and there would be nothing special about it. For SQL servers, you would usually add a failover setup with data replication, and if you require superior performance, you would scale <em class="italic">vertically</em> by simply purchasing better hardware for hosting. Then, at some point, you might think about clustered SQL solutions, introducing <em class="italic">data sharding</em> (horizontal data partitions). But still, from the perspective of a web server running your application, the database would just be a single connection string to read and write the data. The database would be responsible for persisting a <em class="italic">mutable state</em>.</p>
    <div class="note">
      <p class="normal">Remember that every application <em class="italic">as a whole</em> is, in some way, stateful unless it only serves static content or just transforms user input. However, this does not mean that <em class="italic">every</em> component in the application is stateful. A web server that runs the application logic can be a <em class="italic">stateless</em> component, but the database where this application stores user input and sessions will be a <em class="italic">stateful</em> component.</p>
    </div>
    <p class="normal">We will first explain how you approach managing state in containers and what we consider an application or system state.</p>
    <h2 class="heading-2" id="_idParaDest-426">Managing state in containers</h2>
    <p class="normal">Now, imagine <a id="_idIndexMarker1089"/>how this could work if you deployed your SQL server (single instance) in a<a id="_idIndexMarker1090"/> container. The first thing you would notice is that after restarting the container, you would lose the data stored in the database – each time it is restarted, you get a fresh instance of the SQL server. Containers are <em class="italic">ephemeral</em>. This doesn’t sound too useful for our use case. Fortunately, containers come with the option to mount data volumes. A volume can be, for example, a <em class="italic">host’s directory or an external disk volume</em>, which will be <em class="italic">mounted</em> to a specific path in the container’s filesystem. Whatever you store in this path will be kept in the volume even after the container is terminated or restarted. In a similar way, you can use NFS share or an external disk instance as a volume. Now, if you configure your SQL server to put its data files in the path where the volume is mounted, you achieve data persistence even if the container restarts. The container itself is still ephemeral, but the data (state) is <em class="italic">not</em>.</p>
    <p class="normal">This is a high-level overview of how the state can be persisted for plain containers, without involving Kubernetes. But before we move on to Kubernetes, we need to clarify what we actually regard as<a id="_idIndexMarker1091"/> a <strong class="keyWord">state</strong>.</p>
    <p class="normal">Assume that you have a web server that serves just simple <em class="italic">static</em> content (which means it is always the same, as a simple HTML web page). There is still some data that has persisted, for example, the HTML files. However, this is <em class="italic">not</em> a state: user requests cannot modify this data, so <em class="italic">previous</em> requests from the user will not influence the result of the <em class="italic">current</em> request. In the same way, configuration files for your web server are not their state or log files written on the disk (well, that is arguable, but from the end user’s perspective, it is not).</p>
    <p class="normal">Now, if you have a web server that keeps user sessions and stores information about whether the user is logged in, then this is indeed the state. Depending on this information, the web server will return different web pages (responses) based on whether the user is logged in. Let’s say that this web server runs in a container – there is a catch when it comes to whether it is <em class="italic">the</em> stateful component in your application. If the web server process stores user sessions as a file in the container (warning: this is probably quite a bad design), then the web server container is a <em class="italic">stateful</em> component. But if it stores user sessions in a database or a Redis cache running in separate containers, then<a id="_idIndexMarker1092"/> the web server is <em class="italic">stateless</em>, and the database or Redis <a id="_idIndexMarker1093"/>container becomes the stateful component.</p>
    <p class="normal">This is briefly how it looks from a single container perspective. We need now to zoom out a bit and take a look at state management in <strong class="keyWord">Kubernetes Pods</strong>.</p>
    <h2 class="heading-2" id="_idParaDest-427">Managing state in Kubernetes Pods</h2>
    <p class="normal">In <a id="_idIndexMarker1094"/>Kubernetes, the concept <a id="_idIndexMarker1095"/>of container volumes is extended by <strong class="keyWord">PersistentVolumes</strong> (<strong class="keyWord">PVs</strong>), <strong class="keyWord">PersistentVolumeClaims</strong> (<strong class="keyWord">PVCs</strong>), and <strong class="keyWord">StorageClasses</strong> (<strong class="keyWord">SCs</strong>), which are dedicated, storage-related objects. PVC<a id="_idIndexMarker1096"/> aims to <em class="italic">decouple</em> Pods from the actual storage. PVC is a Kubernetes object that models a request for the <a id="_idIndexMarker1097"/>storage of a specific type, class, or size – think of<a id="_idIndexMarker1098"/> saying <em class="italic">I would like 10 GB of read/write-once SSD storage</em>. To fulfill such a request, a PV object is required, which is a piece of real storage that has been provisioned by the cluster’s automation process – think of this as a directory on the host system or storage driver-managed disk. PV types are implemented as plugins, similar to volumes in Docker or Podman. Now, the whole process of provisioning PV can be <em class="italic">dynamic</em> – it requires the creation of an SC object and for this to be used when defining PVCs. When creating a new SC, you provide a <em class="italic">provisioner</em> (or plugin details) with specific parameters, and each PVC using the given SC will automatically create a PV using the selected provisioner. The provisioners may, for example, create cloud-managed disks to provide the backing storage. On top of that, containers of a given Pod can share data using the same PV and mount it to their filesystem.</p>
    <p class="normal">This is just a brief overview of what Kubernetes provides for state storage. We have covered this in more detail in <em class="chapterRef">Chapter 9</em>, <em class="italic">Persistent Storage in Kubernetes</em>.</p>
    <p class="normal">On top of the management of state in a single Pod and its containers, there is the management of state in <em class="italic">multiple replicas</em> of a Pod. Let’s think about what would happen if we used a Deployment object to run multiple Pods with MySQL Server. First, you would need to ensure that the state persisted on a volume in a container – for this, you can use PVs in Kubernetes. But then you actually get multiple, separate MySQL servers, which is not very useful if you would like to have high availability and fault tolerance. If you expose such a deployment using a service, it will also be useless because each time, you may hit a different MySQL Pod and get different data. </p>
    <p class="normal">So, you arrive either at designing a <em class="italic">multi-node failover setup</em> with replication between the master and replicas, or a complex <em class="italic">cluster with data sharding</em>. In any case, your individual MySQL Server Pod replicas need to have a <em class="italic">unique identity</em> and, preferably, <em class="italic">predictable network names</em> so that the Nodes<a id="_idIndexMarker1099"/> and clients <a id="_idIndexMarker1100"/>can communicate.</p>
    <div class="packt_tip">
      <p class="normal">When designing your cloud-native application for the Kubernetes cluster, always analyze all the pros and cons of storing the state of the application as stateful components <em class="italic">running in Kubernetes</em>.</p>
    </div>
    <p class="normal">This is where StatefulSet comes in. Let’s take a closer look at this Kubernetes object.</p>
    <h2 class="heading-2" id="_idParaDest-428">StatefulSet and how it differs from a Deployment object</h2>
    <p class="normal">Kubernetes StatefulSet<a id="_idIndexMarker1101"/> is a similar concept to a Deployment object. It also provides a way of managing and scaling a set of Pods, but it provides guarantees about the <em class="italic">ordering and uniqueness</em> (unique identity) of the Pods. In the same way as Deployment, it uses a Pod template to define what each replica should look like. You can scale it up and down and perform rollouts of new versions. But now, in StatefulSet, the individual Pod replicas are <em class="italic">not interchangeable</em>. The unique, persistent identity for each Pod is maintained during any rescheduling or rollouts – this includes the <strong class="keyWord">Pod name</strong> and its <strong class="keyWord">cluster DNS names</strong>. This unique, persistent identity can be used to identify <a id="_idIndexMarker1102"/>PVs assigned<a id="_idIndexMarker1103"/> to each Pod, even if Pods are replaced following a failure. For this, StatefulSet provides another type of template in its specification named <code class="inlineCode">volumeClaimTemplates</code>. This template can be used for the dynamic creation of the PVCs of a given SC. By doing this, the whole process of storage provisioning is fully dynamic – you just need to create a StatefulSet. The underlying storage objects are managed by the StatefulSet controller.</p>
    <div class="packt_tip">
      <p class="normal">Cluster DNS names of individual Pods in StatefulSet remain the same, but their cluster IP addresses are not guaranteed to stay the same. This means that if you need to connect to individual Pods in the StatefulSet, you should use cluster DNS names.</p>
    </div>
    <p class="normal">Basically, you can use StatefulSet for applications that require the following:</p>
    <ul>
      <li class="bulletList">Persistent storage managed by the Kubernetes cluster (this is the main use case, but not the only one)</li>
      <li class="bulletList">Stable and unique network identifiers (usually DNS names) for each Pod replica</li>
      <li class="bulletList">Ordered deployment and scaling</li>
      <li class="bulletList">Ordered, rolling updates</li>
    </ul>
    <p class="normal">In the following diagram, you <a id="_idIndexMarker1104"/>can see that StatefulSets can be seen as a more predictable version of a Deployment object, with the possibility to use persistent storage provided by PVCs.</p>
    <figure class="mediaobject"><img alt="" src="image/B22019_12_01.png"/></figure>
    <p class="packt_figref">Figure 12.1: StatefulSet high-level view</p>
    <p class="normal">To summarize, the key differences between StatefulSet<a id="_idIndexMarker1105"/> and Deployment<a id="_idIndexMarker1106"/> are as follows:</p>
    <ul>
      <li class="bulletList">StatefulSet ensures a <em class="italic">deterministic</em> (sticky) name for Pods, which consists of <code class="inlineCode">&lt;statefulSetName&gt;-&lt;ordinal&gt;</code>. For Deployments, you would have a <em class="italic">random</em> name consisting of <code class="inlineCode">&lt;deploymentName&gt;-&lt;podTemplateHash&gt;-&lt;randomHash&gt;</code>.</li>
      <li class="bulletList">For StatefulSet objects, the Pods are started and terminated in a <em class="italic">specific</em> and <em class="italic">predictable</em> order that ensures consistency, stability, and coordination while scaling the ReplicaSet. Let us take the preceding example diagram of MySQL StatefulSet; the Pods will be created in sequential order (mysql-0, mysql-1, and mysql-2). When you scale down the StatefulSet, the Pods will be terminated in the reverse order – mysql-2, mysql-1, and mysql-0 at the end.</li>
      <li class="bulletList">In terms of storage, Kubernetes creates PVCs based on <code class="inlineCode">volumeClaimTemplates</code> of the StatefulSet specification for each Pod in the StatefulSet and always attaches this to the Pod with <em class="italic">the same</em> name. For Deployment, if you choose to use <code class="inlineCode">persistentVolumeClaim</code> in the Pod template, Kubernetes will create a single PVC and attach the same to all the Pods in the deployment. This may be useful in certain scenarios but is not a common use case.</li>
      <li class="bulletList">You need to create a <code class="inlineCode">headless</code> Service object that is responsible for managing the <em class="italic">deterministic network identity</em> (cluster DNS names) for Pods. The headless Service allows us to return <em class="italic">all</em> Pods’ IP addresses behind the service as DNS A records instead of a single DNS A record with a <code class="inlineCode">ClusterIP</code> Service. A headless Service is only required if you are not using a regular service. The specification of StatefulSet requires having the Service name provided in <code class="inlineCode">.spec.serviceName</code>. Refer to <em class="italic">Understanding headless services</em> in <em class="chapterRef">Chapter 8</em>, <em class="italic">Exposing Your Pods with Services</em>.</li>
    </ul>
    <p class="normal">Before we explore the StatefulSet, we need to understand some of the limitations of the StatefulSet objects, as explained in the following section.</p>
    <h2 class="heading-2" id="_idParaDest-429">Exploring the limitations of StatefulSet</h2>
    <p class="normal">Here’s a<a id="_idIndexMarker1107"/> breakdown of some <a id="_idIndexMarker1108"/>specific things to keep in mind when using StatefulSets:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Storage setup</strong>: StatefulSets don’t automatically create storage for your pods. You’ll need to either use a built-in tool (like PersistentVolume Provisioner) or manually set up the storage beforehand.</li>
      <li class="bulletList"><strong class="keyWord">Leftover storage</strong>: When you scale down or remove a StatefulSet, the storage used by its pods sticks around. This is because your data is important and shouldn’t accidentally be deleted. You’ll need to clean up the storage yourself if needed. Otherwise, the leftover storage could become a concern because over time, all this unused storage can accumulate, leading to wasted resources and increased storage costs.</li>
      <li class="bulletList"><strong class="keyWord">Pod address</strong>: You’ll need to set up a separate service (called a Headless Service) to give the Pod unique and stable network names.</li>
      <li class="bulletList"><strong class="keyWord">Stopping StatefulSets</strong>: There’s no guarantee that pods will shut down in a specific order when you delete a StatefulSet. To ensure a clean shutdown, it’s best to scale the StatefulSet down to zero Pods before removing it completely.</li>
      <li class="bulletList"><strong class="keyWord">Updating StatefulSets</strong>: Using the default update method with StatefulSets can sometimes lead to problems that require you to fix things manually. Be aware<a id="_idIndexMarker1109"/> of this and consider alternative update <a id="_idIndexMarker1110"/>strategies if needed.</li>
    </ul>
    <p class="normal">Before you start exercises with StatefulSet, read important information about the StatefulSets in the next section.</p>
    <h2 class="heading-2" id="_idParaDest-430">Data management in Statefulset</h2>
    <p class="normal">Kubernetes <a id="_idIndexMarker1111"/>offers StatefulSets as a powerful tool for managing<a id="_idIndexMarker1112"/> stateful applications. However, successfully deploying and maintaining stateful applications requires user involvement beyond simply defining the StatefulSet itself. Here’s a breakdown of key areas requiring your attention:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Data cloning and synchronization</strong>: Unlike stateless applications, stateful applications rely on persistent data. While StatefulSets manage Pod ordering and identity, they don’t handle data replication between Pods. You’ll need to implement this functionality yourself. Common approaches include using init containers to copy data from a predefined source during Pod creation, leveraging built-in replication features within your application (like MySQL replication), or utilizing external scripts to manage data synchronization.</li>
      <li class="bulletList"><strong class="keyWord">Remote storage accessibility</strong>: StatefulSets ensure Pods can be rescheduled across available nodes in the cluster. To maintain data persistence during rescheduling, the storage provisioned by<a id="_idIndexMarker1113"/> the PV needs to be accessible from all worker nodes. This means choosing a storage class that replicates data across nodes or using network-attached storage solutions accessible from all machines.</li>
      <li class="bulletList"><strong class="keyWord">External backups</strong>: StatefulSets are designed for managing Pod life cycles and data persistence within the cluster. However, they don’t handle external backups. To ensure disaster recovery in case of catastrophic events, implementing a separate external backup solution is crucial. This could involve backing up your<a id="_idIndexMarker1114"/> PVs to a cloud storage service or a dedicated backup server <a id="_idIndexMarker1115"/>outside the Kubernetes cluster.</li>
    </ul>
    <p class="normal">There are best practices and recommended approaches for handling the data in StatefulSets. The following section will explain some of the replication management techniques for StatefulSets.</p>
    <h2 class="heading-2" id="_idParaDest-431">Replication management</h2>
    <p class="normal">As the name suggests, Stateful<a id="_idIndexMarker1116"/> applications <a id="_idIndexMarker1117"/>handling data often require data initialization or synchronization. You might need to implement these using methods like the following:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">init containers</strong>: Copy data from a source (like a config map) to the persistent storage before starting the application.</li>
      <li class="bulletList"><strong class="keyWord">Application-level replication</strong>: Leverage built-in replication features within your application to handle data updates across Pods.</li>
      <li class="bulletList"><strong class="keyWord">External scripts</strong>: Use external scripts or tools to manage data migration during the update process.</li>
    </ul>
    <p class="normal">Now, let’s take a look at a concrete example of StatefulSet that deploys MySQL Pods with the backing of persistent storage.</p>
    <h1 class="heading-1" id="_idParaDest-432">Managing StatefulSet</h1>
    <p class="normal">To demonstrate how<a id="_idIndexMarker1118"/> StatefulSet objects work, we will modify our MySQL deployment and adapt it to be a StatefulSet. A significant part of the StatefulSet specification is the same as for Deployments. As we would like to demonstrate how the automatic management of PVCs works in StatefulSet objects, we will use <code class="inlineCode">volumeClaimTemplates</code> in the specification to create PVCs and PVs, which the Pods will consume. Each Pod will internally mount its assigned PV under the <code class="inlineCode">/var/lib/mysql</code> path in the container filesystem, which is the default location of MySQL data files. In this way, we can demonstrate how the <em class="italic">state</em> persists, even if we forcefully restart Pods.</p>
    <div class="note">
      <p class="normal">The example that we are going to use in this chapter is for demonstration purposes only and is meant to be as simple as possible. If you are interested in <em class="italic">complex</em> examples, such as deploying and managing distributed databases in StatefulSets, please take a look at the official Kubernetes blog post about deploying the Cassandra database at <a href="https://kubernetes.io/docs/tutorials/stateful-application/cassandra/"><span class="url">https://kubernetes.io/docs/tutorials/stateful-application/cassandra/</span></a>. Usually, the main source of complexity in such cases is handling the joining and removal of Pod replicas when scaling the StatefulSet.</p>
    </div>
    <p class="normal">We will now go through all the YAML manifests required to create our StatefulSet and apply them to the cluster.</p>
    <h2 class="heading-2" id="_idParaDest-433">Creating a StatefulSet</h2>
    <p class="normal">We have discussed the concepts of <a id="_idIndexMarker1119"/>StatefulSet, and now it’s time to learn how to manage them. First, let’s take a look at the StatefulSet YAML manifest file named <code class="inlineCode">mysql-statefulset.yaml</code>:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># mysql-statefulset.yaml</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">StatefulSet</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">mysql-stateful</span>
  <span class="hljs-attr">labels:</span>
    <span class="hljs-attr">app:</span> <span class="hljs-string">mysql</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">mysql</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">serviceName:</span> <span class="hljs-string">mysql-headless</span>
  <span class="hljs-attr">replicas:</span> <span class="hljs-number">3</span>
  <span class="hljs-attr">selector:</span>
    <span class="hljs-attr">matchLabels:</span>
      <span class="hljs-attr">app:</span> <span class="hljs-string">mysql</span>
      <span class="hljs-attr">environment:</span> <span class="hljs-string">test</span>
<span class="hljs-comment"># (to be continued in the next paragraph)</span>
</code></pre>
    <p class="normal">The first part of the <a id="_idIndexMarker1120"/>preceding file is very similar to the Deployment object specification, where you need to provide the number of <code class="inlineCode">replicas</code> and a <code class="inlineCode">selector</code> for Pods. There is one new parameter, <code class="inlineCode">serviceName</code>, which we will explain shortly.</p>
    <p class="normal">The next part of the file concerns the specification of the Pod template that is used by the StatefulSet:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># (continued)</span>
  <span class="hljs-attr">template:</span>
    <span class="hljs-attr">metadata:</span>
      <span class="hljs-attr">labels:</span>
        <span class="hljs-attr">app:</span> <span class="hljs-string">mysql</span>
        <span class="hljs-attr">environment:</span> <span class="hljs-string">test</span>
    <span class="hljs-attr">spec:</span>
      <span class="hljs-attr">containers:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mysql</span>
          <span class="hljs-attr">image:</span> <span class="hljs-string">mysql:8.2.0</span>
          <span class="hljs-attr">ports:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">containerPort:</span> <span class="hljs-number">3306</span>
          <span class="hljs-attr">volumeMounts:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mysql-data</span>
              <span class="hljs-attr">mountPath:</span> <span class="hljs-string">/var/lib/mysql</span>
          <span class="hljs-attr">env:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">MYSQL_ROOT_PASSWORD</span>
              <span class="hljs-attr">valueFrom:</span>
                <span class="hljs-attr">secretKeyRef:</span>
                  <span class="hljs-attr">name:</span> <span class="hljs-string">mysql-secret</span>
                  <span class="hljs-attr">key:</span> <span class="hljs-string">MYSQL_ROOT_PASSWORD</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">MYSQL_USER</span>
              <span class="hljs-attr">valueFrom:</span>
                <span class="hljs-attr">secretKeyRef:</span>
                  <span class="hljs-attr">name:</span> <span class="hljs-string">mysql-secret</span>
                  <span class="hljs-attr">key:</span> <span class="hljs-string">MYSQL_USER</span>
            <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">MYSQL_PASSWORD</span>
              <span class="hljs-attr">valueFrom:</span>
                <span class="hljs-attr">secretKeyRef:</span>
                  <span class="hljs-attr">name:</span> <span class="hljs-string">mysql-secret</span>
                  <span class="hljs-attr">key:</span> <span class="hljs-string">MYSQL_PASSWORD</span>
<span class="hljs-comment"># (to be continued in the next paragraph)</span>
</code></pre>
    <p class="normal">If you look closely, you can observe that the structure is the same as for Deployments. Notice the environment variables we are providing via the Secret object, which needs to be created before creating the StatefulSet. Also, the last part of the file contains <code class="inlineCode">volumeClaimTemplates</code>, which is <a id="_idIndexMarker1121"/>used to define templates for PVC used by the Pod:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># (continued)</span>
  <span class="hljs-attr">volumeClaimTemplates:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">metadata:</span>
        <span class="hljs-attr">name:</span> <span class="hljs-string">mysql-data</span>
      <span class="hljs-attr">spec:</span>
        <span class="hljs-attr">accessModes:</span>
          <span class="hljs-bullet">-</span> <span class="hljs-string">"ReadWriteOnce"</span>
        <span class="hljs-attr">resources:</span>
          <span class="hljs-attr">requests:</span>
            <span class="hljs-attr">storage:</span> <span class="hljs-string">1Gi</span>
</code></pre>
    <p class="normal">As you can see, in general, the structure of the StatefulSet spec is similar to a Deployment, although it has a few extra parameters for configuring PVCs and associated Service objects. The specification has five main components:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">replicas</code>: Defines the number of Pod replicas that should run using the given <code class="inlineCode">template</code> and the matching label <code class="inlineCode">selector</code>. Pods may be created or deleted to maintain the required number.</li>
      <li class="bulletList"><code class="inlineCode">serviceName</code>: The name of the service that governs the StatefulSet and provides the network identity for the Pods. This Service must be created before the StatefulSet is created. We will create the <code class="inlineCode">mysql-headless</code> Service in the next step.</li>
      <li class="bulletList"><code class="inlineCode">selector</code>: A <strong class="keyWord">label selector</strong>, which <a id="_idIndexMarker1122"/>defines how to identify Pods that the StatefulSet owns. This can include <em class="italic">set-based</em> and <em class="italic">equality-based</em> selectors.</li>
      <li class="bulletList"><code class="inlineCode">template</code>: Defines the template for Pod creation. Labels used in <code class="inlineCode">metadata</code> must match the <code class="inlineCode">selector</code>. Pod names are not random and follow the <code class="inlineCode">&lt;statefulSetName&gt;-&lt;ordinal&gt;</code> convention. You can optionally use <code class="inlineCode">.spec.ordinals</code> to control the starting number for the unique identification number assigned to each pod in your StatefulSet.</li>
      <li class="bulletList"><code class="inlineCode">volumeClaimTemplates</code>: Defines the template for PVC that will be created for each of the Pods. Each Pod in the StatefulSet object will get its own PVC that is assigned to a given Pod name persistently. In our case, it is a 1 GB volume with the <code class="inlineCode">ReadWriteOnce</code> access mode. This access mode allows the volume to be mounted for reads and writes by a <em class="italic">single</em> Node only. We did not specify <code class="inlineCode">storageClassName</code>, so the PVCs will be provisioned using the default SC in the cluster. PVC names are not random and follow the <code class="inlineCode">&lt;volumeClaimTemplateName&gt;-&lt;statefulSetName&gt;-&lt;ordinal&gt;</code> convention.</li>
    </ul>
    <div class="packt_tip">
      <p class="normal">The default SC in your cluster is marked with the <code class="inlineCode">storageclass.kubernetes.io/is-default-class</code> annotation. Whether you have a default SC, and how it is defined, depends on your cluster deployment. For example, in the Azure Kubernetes Service cluster, it will be an SC named <code class="inlineCode">default</code> that uses the <code class="inlineCode">kubernetes.io/azure-disk</code> provisioner. In <code class="inlineCode">minikube</code>, it will be an SC named <code class="inlineCode">standard</code> that uses the <code class="inlineCode">k8s.io/minikube-hostpath</code> provisioner.</p>
    </div>
    <p class="normal">The specification also <a id="_idIndexMarker1123"/>contains other fields that are related to rolling out new revisions of StatefulSet – we will explain these in more detail in the next section.</p>
    <p class="normal">Next, let’s have a look at our <em class="italic">headless</em> Service named <code class="inlineCode">mysql-headless</code>. Create a <code class="inlineCode">mysql-headless-service.yaml</code> file with the following content:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-comment"># mysql-headless-service.yaml</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">mysql-headless</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">mysql</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">selector:</span>
    <span class="hljs-attr">app:</span> <span class="hljs-string">mysql</span>
    <span class="hljs-attr">environment:</span> <span class="hljs-string">test</span>
  <span class="hljs-attr">clusterIP:</span> <span class="hljs-string">None</span>
  <span class="hljs-attr">ports:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">port:</span> <span class="hljs-number">3306</span>
</code></pre>
    <p class="normal">The specification is very similar to the normal Service that we created previously for the Deployment; the only difference is that it has the value <code class="inlineCode">None</code> for the <code class="inlineCode">clusterIP</code> field. This will result in the creation of a headless Service, <code class="inlineCode">mysql-headless</code>. A headless Service allows us to return <em class="italic">all</em> Pods’ IP addresses behind the Service as DNS <code class="inlineCode">A records</code> instead of a single DNS <code class="inlineCode">A record</code> with a <code class="inlineCode">clusterIP</code> Service. We will demonstrate what this means in practice in the next steps.</p>
    <p class="normal">With all the YAML<a id="_idIndexMarker1124"/> manifest files, we can start deploying our example StatefulSet! Perform the following steps:</p>
    <ol>
      <li class="numberedList" value="1">Create a namespace called <code class="inlineCode">mysql</code> (using <code class="inlineCode">mysql-ns.yaml</code>):
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply –f mysql-ns.yaml
namespace/mysql created
</code></pre>
      </li>
      <li class="numberedList">Create a Secret to store MySQL environment variables:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl create secret generic mysql-secret \
  --from-literal=MYSQL_ROOT_PASSWORD=<span class="hljs-con-string">'mysqlroot'</span> \
  --from-literal=MYSQL_USER=<span class="hljs-con-string">'mysqluser'</span> \
  --from-literal=MYSQL_PASSWORD=<span class="hljs-con-string">'mysqlpassword'</span> \
  -n mysql
secret/mysql-secret created
</code></pre>
      </li>
    </ol>
    <div class="note-one">
      <p class="normal">Please note that it is also possible to create the same secret using YAML and base64 encoded (e.g., <code class="inlineCode">echo -n 'mysqlroot' | base64</code>) values inside (refer to <code class="inlineCode">mysql-secret.yaml</code> in the repository to see the sample YAML file); we are using this imperative method to demonstrate the secret with actual values.</p>
    </div>
    <ol>
      <li class="numberedList" value="3">Create a headless Service, <code class="inlineCode">mysql-headless</code>, using the following command:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f mysql-headless-service.yaml
service/mysql-headless created
</code></pre>
      </li>
      <li class="numberedList">Create a StatefulSet object, <code class="inlineCode">mysql-stateful</code>, using the following command:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f mysql-statefulset.yaml
statefulset.apps/mysql-stateful created
</code></pre>
      </li>
      <li class="numberedList">Now, you can use the <code class="inlineCode">kubectl describe</code> command to observe the creation of the StatefulSet object (alternatively, you can use <code class="inlineCode">sts</code> as an abbreviation for StatefulSet when using kubectl commands):
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl describe statefulset mysql-stateful -n mysql
<span class="hljs-con-meta">$ </span> kubectl get sts -n mysql
NAME             READY   AGE
mysql-stateful   3/3     2m3s
</code></pre>
      </li>
      <li class="numberedList">Use the <code class="inlineCode">kubectl get pods</code> command to see that the three desired Pod replicas have been created. Note that this can take a bit of time as the Pods have to get the PVs provisioned based on their PVCs:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get pod -n mysql
NAME               READY   STATUS    RESTARTS   AGE
mysql-stateful-0   1/1     Running   0          2m32s
mysql-stateful-1   1/1     Running   0          2m29s
mysql-stateful-2   1/1     Running   0          2m25s
</code></pre>
      </li>
    </ol>
    <div class="note-one">
      <p class="normal">Please note the ordered, deterministic Pod naming – this is the key to providing a unique identity to the Pods in the StatefulSet object.</p>
    </div>
    <ol>
      <li class="numberedList" value="7">If you <a id="_idIndexMarker1125"/>describe one of the Pods, you will see more details about the associated PV and PVC:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl -n mysql describe pod mysql-stateful-0
Name:             mysql-stateful-0
Namespace:        mysql
Priority:         0
Service Account:  default
...&lt;removed for brevity&gt;...
Volumes:
  mysql-data:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  mysql-data-mysql-stateful-0
    ReadOnly:   false
...&lt;removed for brevity&gt;...
</code></pre>
      </li>
    </ol>
    <p class="normal-one">For the second Pod, you will see a similar output to the following, but with a different PVC:</p>
    <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl -n mysql describe pod mysql-stateful-1
Name:             mysql-stateful-1
Namespace:        mysql
Priority:         0
...&lt;removed for brevity&gt;...
Volumes:
  mysql-data:
    Type:       PersistentVolumeClaim (a reference to a PersistentVolumeClaim in the same namespace)
    ClaimName:  mysql-data-mysql-stateful-1
    ReadOnly:   false
...&lt;removed for brevity&gt;...
</code></pre>
    <p class="normal-one">As you can see, the PVC used by this <code class="inlineCode">mysql-stateful-0</code> Pod is named <code class="inlineCode">mysql-data-mysql-stateful-0 </code>and the PVC used by this <code class="inlineCode">mysql-stateful-1</code> Pod is named <code class="inlineCode">mysql-data-mysql-stateful-1</code>. Right after the Pod was scheduled on its target Node, the PVs are provisioned via the respective StorageClass and bound to the individual PVCs. After that, the actual container, which internally mounts this PV, has been created.</p>
    <ol>
      <li class="numberedList" value="8">Using <a id="_idIndexMarker1126"/>the <code class="inlineCode">kubectl get</code> command, we can reveal more details about the PVC:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span> kubectl get pvc -n mysql
NAME                          STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
mysql-data-mysql-stateful-0   Bound    pvc-453dbfee-6076-48b9-8878-e7ac6f79d271   1Gi        RWO            standard       &lt;unset&gt;                 8m38s
mysql-data-mysql-stateful-1   Bound    pvc-36494153-3829-42aa-be6d-4dc63163ea38   1Gi        RWO            standard       &lt;unset&gt;                 8m35s
mysql-data-mysql-stateful-2   Bound    pvc-6730af33-f0b6-445d-841b-4fbad5732cde   1Gi        RWO            standard       &lt;unset&gt;                 8m31s
</code></pre>
      </li>
      <li class="numberedList">And finally, let’s take a look at the PV that was provisioned:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                               STORAGECLASS   VOLUMEATTRIBUTESCLASS   REASON   AGE
pvc-36494153-3829-42aa-be6d-4dc63163ea38   1Gi        RWO            Delete           Bound    mysql/mysql-data-mysql-stateful-1   standard       &lt;unset&gt;                          11m
pvc-453dbfee-6076-48b9-8878-e7ac6f79d271   1Gi        RWO            Delete           Bound    mysql/mysql-data-mysql-stateful-0   standard       &lt;unset&gt;                          11m
pvc-6730af33-f0b6-445d-841b-4fbad5732cde   1Gi        RWO            Delete           Bound    mysql/mysql-data-mysql-stateful-2   standard       &lt;unset&gt;                          11m
</code></pre>
      </li>
    </ol>
    <div class="note-one">
      <p class="normal">Please note that, in our example, we are demonstrating this using the minikube <code class="inlineCode">hostPath</code> type. If your Kubernetes cluster uses a different storage backend, you will see different outputs.</p>
    </div>
    <p class="normal-one">We have successfully created the StatefulSet object; now it is time to verify whether it <a id="_idIndexMarker1127"/>works as expected in a basic scenario. To do this, let us use an updated <code class="inlineCode">k8sutils</code> container image with the default MySQL client package installed. (Check <code class="inlineCode">Chapter12/Containerfile</code> to see the details of the <code class="inlineCode">k8sutils</code> image.) Create <code class="inlineCode">k8sutils.yaml</code> as follows:</p>
    <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-comment"># k8sutils.yaml</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Pod</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">k8sutils</span>
  <span class="hljs-comment"># namespace: default</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">containers:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">k8sutils</span>
      <span class="hljs-attr">image:</span> <span class="hljs-string">quay.io/iamgini/k8sutils:debian12-1.1</span>
      <span class="hljs-attr">command:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-string">sleep</span>
        <span class="hljs-bullet">-</span> <span class="hljs-string">"infinity"</span>
      <span class="hljs-comment"># imagePullPolicy: IfNotPresent</span>
  <span class="hljs-attr">restartPolicy:</span> <span class="hljs-string">Always</span>
</code></pre>
    <p class="normal-one">Create the <code class="inlineCode">k8sutils</code> Pod as follows:</p>
    <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f k8sutils.yaml -n mysql
pod/k8sutils created
</code></pre>
    <div class="note-one">
      <p class="normal">Please note that we used <code class="inlineCode">-n mysql</code> while applying the YAML so that the resource will be created inside the <code class="inlineCode">mysql</code> namespace.</p>
    </div>
    <p class="normal">Follow these steps to verify the content of different Pods in the StatefulSet:</p>
    <ol>
      <li class="numberedList" value="1">Jump into the <code class="inlineCode">k8sutil</code> Pod to execute our test commands:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> -it -n mysql k8sutils -- /bin/bash
root@k8sutils:/#
</code></pre>
      </li>
      <li class="numberedList">Access the <a id="_idIndexMarker1128"/>MySQL Stateful application using the default headless service we created earlier (remember the password you created using the Secret object earlier):
        <pre class="programlisting con-one"><code class="hljs-con">root@k8sutils:/# mysql -u root -p -h mysql-headless.mysql.svc.cluster.local
Enter password: &lt;mysqlroot&gt;
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MySQL connection id is 8
Server version: 8.2.0 MySQL Community Server - GPL
Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.
Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
MySQL [(none)]&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| sys                |
+--------------------+
4 rows in set (0.003 sec)
MySQL [(none)]&gt;
</code></pre>
      </li>
    </ol>
    <p class="normal">The basic MySQL connection is working, and we are able to access the MySQL server running as a StatefulSet application. We will now take a quick look at how the <em class="italic">headless</em> Service behaves.</p>
    <h2 class="heading-2" id="_idParaDest-434">Using the headless Service and stable network identities</h2>
    <p class="normal">Previously, we learned about headless service<a id="_idIndexMarker1129"/> in Kubernetes and how we can use it for accessing StatefulSet applications. (Refer to <em class="italic">Understanding headless services</em> section in <em class="chapterRef">Chapter 8</em>, <em class="italic">Exposing Your Pods with Services</em>). In this section, let us go<a id="_idIndexMarker1130"/> deep and explore the headless service mechanism in the backend of StatefulSet.</p>
    <p class="normal">Let’s do an experiment that demonstrates how the <code class="inlineCode">headless</code> Service is used to provide stable and predictable network identities for our Pods:</p>
    <ol>
      <li class="numberedList" value="1">Log in to the same k8sutils Pod that we used in the previous test.</li>
      <li class="numberedList">Perform DNS check for the headless Service, <code class="inlineCode">mysql-headless</code>:
        <pre class="programlisting con-one"><code class="hljs-con">root@k8sutils:/# nslookup mysql-headless
Server:         10.96.0.10
Address:        10.96.0.10#53
Name:   mysql-headless.mysql.svc.cluster.local
Address: 10.244.0.14
Name:   mysql-headless.mysql.svc.cluster.local
Address: 10.244.0.15
Name:   mysql-headless.mysql.svc.cluster.local
Address: 10.244.0.16
</code></pre>
      </li>
    </ol>
    <p class="normal-one">We have received three <code class="inlineCode">A records</code> that point directly to Pod IP addresses. Additionally, they have <code class="inlineCode">CNAME records</code> in the form of <code class="inlineCode">&lt;podName&gt;-&lt;ordinal-number&gt;.&lt;headless-serviceName&gt;.&lt;namespace&gt;.svc.cluster.local</code>. So, the difference with default Service is that a Service that has <code class="inlineCode">ClusterIP</code> will get load balancing to a <em class="italic">virtual IP</em> level (which, on Linux, is usually handled at a kernel level by <code class="inlineCode">iptables</code> rules configured by <code class="inlineCode">kube-proxy</code>), whereas in the case of the headless Service, the responsibility for load balancing or choosing the target Pod is on the <em class="italic">client</em> making the request.</p>
    <ol>
      <li class="numberedList" value="3">Having <em class="italic">predictable</em> FQDNs for Pods in the StatefulSet gives us the option to send the requests directly to individual Pods, without guessing their IP addresses or names. Let’s try accessing the MySQL server served by the <code class="inlineCode">mysql-stateful-0</code> using its short DNS name provided by the headless Service:
        <pre class="programlisting con-one"><code class="hljs-con">root@k8sutils:/# mysql -u root -p -h mysql-stateful-0.mysql-headless
Enter password: &lt;mysqlroot&gt;
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MySQL connection id is 8
Server version: 8.2.0 MySQL Community Server - GPL
Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.
Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
MySQL [(none)]&gt;
</code></pre>
      </li>
    </ol>
    <p class="normal-one">As expected, you have connected directly to the Pod and have been served by the proper Pod.</p>
    <ol>
      <li class="numberedList" value="4">Let us create a database inside the MySQL database server as follows:
        <pre class="programlisting con-one"><code class="hljs-con">MySQL [(none)]&gt; create database ststest;
Query OK, 1 row affected (0.002 sec)
MySQL [(none)]&gt; exit;
Bye
</code></pre>
      </li>
      <li class="numberedList">Now, we will <a id="_idIndexMarker1131"/>show that this DNS name remains unchanged even if a Pod is restarted. The IP of the Pod will change, but the DNS name will not. What is more, the PV that is mounted will also <a id="_idIndexMarker1132"/>stay the same, but we will investigate this in the next paragraphs. In another shell window, outside of the container, execute the following command to force a restart of the <code class="inlineCode">mysql-stateful-0</code> Pod:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl delete po -n mysql mysql-stateful-0
</code></pre>
      </li>
    </ol>
    <p class="normal-one">Check the Pods and you will see that <code class="inlineCode">mysql-stateful-0</code> has been recreated and mounted with the same <code class="inlineCode">mysql-data-mysql-stateful-0</code> PVC:</p>
    <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get po -n mysql
NAME               READY   STATUS    RESTARTS   AGE
k8sutils           1/1     Running   0          35m
mysql-stateful-0   1/1     Running   0          6s
mysql-stateful-1   1/1     Running   0          52m
mysql-stateful-2   1/1     Running   0          51m
</code></pre>
    <ol>
      <li class="numberedList" value="6">In the <code class="inlineCode">k8sutils</code> shell, execute the MySQL client command to check the database server content:
        <pre class="programlisting con-one"><code class="hljs-con">root@k8sutils:/# mysql -u root -p -h mysql-stateful-0.mysql-headless
Enter password: &lt;mysqlroot&gt;
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MySQL connection id is 8
Server version: 8.2.0 MySQL Community Server - GPL
Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.
Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
MySQL [(none)]&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
| ststest            |
| sys                |
+--------------------+
5 rows in set (0.003 sec)
</code></pre>
      </li>
    </ol>
    <p class="normal-one">You can see that <a id="_idIndexMarker1133"/>the database <code class="inlineCode">ststest</code> we created before the Pod deletion is still there, which means the data is persistent or stateful. Also, notice the IP address of the Pod changed <a id="_idIndexMarker1134"/>but the DNS remained the same.</p>
    <p class="normal">This explains how the headless Services can be leveraged to get a stable and predictable network identity that will not change when a Pod is restarted or recreated. You may wonder what the actual use of this is and why it is important for StatefulSet objects. There are a couple of possible use cases:</p>
    <ul>
      <li class="bulletList">Deploying clustered databases, such as <code class="inlineCode">etcd</code> or MongoDB, requires specifying the network addresses of other Nodes in the database cluster. This is especially necessary if there are no <em class="italic">automatic discovery</em> capabilities provided by the database. In such cases, stable DNS names provided by headless Services help to run such clusters on Kubernetes as StatefulSets. There is still the problem of changing the configuration when Pod replicas are added or removed from the StatefulSet during scaling. In some cases, this is solved by the <em class="italic">sidecar container pattern</em>, which monitors the Kubernetes API to dynamically change the database configuration.</li>
      <li class="bulletList">If you decide to<a id="_idIndexMarker1135"/> implement your own storage solution running as StatefulSet with advanced data sharding, you will most likely need mappings of logical shards to physical Pod replicas in the cluster. Then, the stable DNS names can be used as part of this mapping. They will guarantee that queries for each logical shard are performed against a proper Pod, irrespective of whether it was rescheduled to another <a id="_idIndexMarker1136"/>Node or restarted.</li>
    </ul>
    <p class="normal">Finally, let’s take a look at the state persistence for Pods running in StatefulSet.</p>
    <h2 class="heading-2" id="_idParaDest-435">State persistence</h2>
    <p class="normal">As we demonstrated earlier, the <a id="_idIndexMarker1137"/>data is persistent inside the PV and will bound back to the newly created Pod with the same ordinal number.</p>
    <p class="normal">In the following example, we are deleting all of the Pods in the StatefulSet:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl delete po -n mysql mysql-stateful-0 mysql-stateful-1 mysql-stateful-2
pod "mysql-stateful-0" deleted
pod "mysql-stateful-1" deleted
pod "mysql-stateful-2" deleted
</code></pre>
    <p class="normal">Kubernetes will recreate all of the Pods in the same order as follows:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get pod -n mysql
NAME               READY   STATUS    RESTARTS   AGE
k8sutils           1/1     Running   0          47m
mysql-stateful-0   1/1     Running   0          44s
mysql-stateful-1   1/1     Running   0          43s
mysql-stateful-2   1/1     Running   0          41s
</code></pre>
    <p class="normal">We can also verify the PVs mounted to ensure the Pod to PVC binding was successful:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl describe pod -n mysql -l app=mysql |egrep <span class="hljs-con-string">'ClaimName|Name:'</span>
Name:             mysql-stateful-0
    ClaimName:  mysql-data-mysql-stateful-0
    ConfigMapName:           kube-root-ca.crt
Name:             mysql-stateful-1
    ClaimName:  mysql-data-mysql-stateful-1
    ConfigMapName:           kube-root-ca.crt
Name:             mysql-stateful-2
    ClaimName:  mysql-data-mysql-stateful-2
    ConfigMapName:           kube-root-ca.crt
</code></pre>
    <p class="normal">As you have learned, the PV will not be removed by the StatefulSet controller as part of Pod or StatefulSet deletion. It is your responsibility to clean up the data by removing the PVs manually if you <a id="_idIndexMarker1138"/>are removing the StatefulSet objects completely.</p>
    <p class="normal">Next, we will take a look at scaling the StatefulSet object.</p>
    <h2 class="heading-2" id="_idParaDest-436">Scaling StatefulSet</h2>
    <p class="normal">In the case of <a id="_idIndexMarker1139"/>StatefulSets, you can do similar <em class="italic">scaling</em> operations as for Deployment objects by changing the number of <code class="inlineCode">replicas</code> in the specification or using the <code class="inlineCode">kubectl scale</code> imperative command. The new Pods will automatically be discovered as new Endpoints for the Service when you scale up, or automatically removed from the Endpoints list when you scale down.</p>
    <p class="normal">However, there are a few differences when compared to Deployment objects:</p>
    <ul>
      <li class="bulletList">When you deploy a StatefulSet object of <code class="inlineCode">N</code> replicas, the Pods during deployment are created sequentially, in order from <code class="inlineCode">0</code> to <code class="inlineCode">N</code>-<code class="inlineCode">1</code>. In our example, during the creation of a StatefulSet object of three replicas, the first <code class="inlineCode">mysql-stateful-0 </code>Pod is created, followed by <code class="inlineCode">n mysql-stateful-1</code>, and finally <code class="inlineCode">mysql-stateful-2</code>.</li>
      <li class="bulletList">When you scale <em class="italic">up</em> the StatefulSet, the new Pods are also created sequentially and in an ordered fashion.</li>
      <li class="bulletList">When you scale <em class="italic">down</em> the StatefulSet, the Pods are terminated sequentially, in <em class="italic">reverse order</em>, from <code class="inlineCode">N</code><em class="italic">-</em><code class="inlineCode">1</code> to <code class="inlineCode">0</code>. In our example, while scaling down the StatefulSet object to zero replicas, the <code class="inlineCode">mysql-stateful-2</code> Pod is terminated, followed by <code class="inlineCode">mysql-stateful-1</code>, and finally <code class="inlineCode">mysql-stateful-0</code>.</li>
      <li class="bulletList">During the scaling up of the StatefulSet object, before the next Pod is created in the sequence, all its predecessors must be <em class="italic">running</em> and <em class="italic">ready</em>.</li>
      <li class="bulletList">During the scaling <em class="italic">down</em> of the StatefulSet object, before the next Pod is terminated in the reverse sequence, all its predecessors must be completely <em class="italic">terminated</em> and <em class="italic">deleted</em>.</li>
      <li class="bulletList">Also, in general, before <em class="italic">any</em> scaling operation is applied to a Pod in a StatefulSet object, all its predecessors must be running and ready. This means that if, during scaling down from four replicas to one replica, the <code class="inlineCode">mysql-stateful-0</code> Pod were to suddenly fail, then no further scaling operation would be performed on the <code class="inlineCode">mysql-stateful-1</code>, <code class="inlineCode">mysql-stateful-2</code>, and <code class="inlineCode">mysql-stateful-3</code> Pods. Scaling would resume when the <code class="inlineCode">mysql-stateful-0</code> Pod becomes ready again.</li>
    </ul>
    <div class="packt_tip-one">
      <p class="normal">This sequential behavior of scaling operations can be relaxed by changing the <code class="inlineCode">.spec.podManagementPolicy</code> field in the specification. The default value is <code class="inlineCode">OrderedReady</code>. If you change it to <code class="inlineCode">Parallel</code>, the scaling operations will be performed on Pods in parallel, similar to what you know from Deployment objects. Note that this only affects scaling operations. The way of updating the StatefulSet object with <code class="inlineCode">updateStrategy</code> of the <code class="inlineCode">RollingUpdate</code> type does not change.</p>
    </div>
    <p class="normal">Equipped with this <a id="_idIndexMarker1140"/>knowledge, let’s <em class="italic">scale up</em> our StatefulSet imperatively to demonstrate it quickly:</p>
    <ol>
      <li class="numberedList" value="1">Scale out the StatefulSet using the following command:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl scale statefulset -n mysql mysql-stateful --replicas 4
statefulset.apps/mysql-stateful scaled
</code></pre>
      </li>
      <li class="numberedList">If you now check the Pods using the <code class="inlineCode">kubectl get pods </code>command, you will see the sequential, ordered creation of new Pods:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get pod -n mysql
NAME               READY   STATUS    RESTARTS   AGE
k8sutils           1/1     Running   0          56m
mysql-stateful-0   1/1     Running   0          9m13s
mysql-stateful-1   1/1     Running   0          9m12s
mysql-stateful-2   1/1     Running   0          9m10s
mysql-stateful-3   1/1     Running   0          4s
</code></pre>
      </li>
    </ol>
    <p class="normal-one">Similarly, if you check the output of the <code class="inlineCode">kubectl describe</code> command for the StatefulSet object, you will see the following in the events:</p>
    <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl describe sts -n mysql mysql-stateful
Name:               mysql-stateful
Namespace:          mysql
...&lt;removed for brevity&gt;...
Events:
  Type    Reason                   Age                 From                    Message
  ----    ------                   ----                ----                    -------
  Normal  SuccessfulCreate         23m (x2 over 75m)   statefulset-controller  create Pod mysql-stateful-0 in StatefulSet mysql-stateful successful
  Normal  RecreatingTerminatedPod  11m (x13 over 23m)  statefulset-controller  StatefulSet mysql/mysql-stateful is recreating terminated Pod mysql-stateful-0
  Normal  SuccessfulDelete         11m (x13 over 23m)  statefulset-controller  delete Pod mysql-stateful-0 in StatefulSet mysql-stateful successful
  Normal  SuccessfulCreate         2m28s               statefulset-controller  create Claim mysql-data-mysql-stateful-3 Pod mysql-stateful-3 in StatefulSet mysql-stateful success
  Normal  SuccessfulCreate         2m28s               statefulset-controller  create Pod mysql-stateful-3 in StatefulSet mysql-stateful successful
Let us scale down our StatefulSet object imperatively and check the Pods as follows:
<span class="hljs-con-meta">$ </span>kubectl scale statefulset -n mysql mysql-stateful --replicas 2
statefulset.apps/mysql-stateful scaled
</code></pre>
    <p class="normal-one">You can see that the <a id="_idIndexMarker1141"/>last two Pods – <code class="inlineCode">mysql-stateful-3</code> and <code class="inlineCode">mysql-stateful-2</code> – are deleted in an orderly way. Now, let us check the Pods in the <code class="inlineCode">statefulset</code> as follows:</p>
    <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span> kubectl get pod -n mysql
NAME               READY   STATUS    RESTARTS   AGE
k8sutils           1/1     Running   0          61m
mysql-stateful-0   1/1     Running   0          15m
mysql-stateful-1   1/1     Running   0          15m
</code></pre>
    <ol>
      <li class="numberedList" value="3">Check the PVCs now and you will see the PVCs are still there. This is an expected <a id="_idIndexMarker1142"/>situation for StatefulSet, as we learned earlier:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get pvc -n mysql
NAME                          STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   VOLUMEATTRIBUTESCLASS   AGE
mysql-data-mysql-stateful-0   Bound    pvc-453dbfee-6076-48b9-8878-e7ac6f79d271   1Gi        RWO            standard       &lt;unset&gt;                 79m
mysql-data-mysql-stateful-1   Bound    pvc-36494153-3829-42aa-be6d-4dc63163ea38   1Gi        RWO            standard       &lt;unset&gt;                 79m
mysql-data-mysql-stateful-2   Bound    pvc-6730af33-f0b6-445d-841b-4fbad5732cde   1Gi        RWO            standard       &lt;unset&gt;                 79m
mysql-data-mysql-stateful-3   Bound    pvc-6ec1ee2a-5be3-4bf9-84e5-4f5aee566c11   1Gi        RWO            standard       &lt;unset&gt;                 7m4s
</code></pre>
      </li>
    </ol>
    <div class="note-one">
      <p class="normal">When managing StatefulSets with <strong class="keyWord">Horizontal Pod Autoscaler</strong> (<strong class="keyWord">HPA</strong>) or similar horizontal scaling tools, refrain from specifying a value for <code class="inlineCode">.spec.replicas</code> in your manifest. Instead, leave it unset. The Kubernetes control plane will dynamically adjust the number of replicas as per resource requirements, facilitating efficient scaling of your application without the need for manual intervention.</p>
    </div>
    <p class="normal">Congratulations! We have learned how to deploy and scale StatefulSet objects. Next, we will demonstrate how you can delete a StatefulSet object.</p>
    <h2 class="heading-2" id="_idParaDest-437">Deleting a StatefulSet</h2>
    <p class="normal">To delete a<a id="_idIndexMarker1143"/> StatefulSet object, there are two possibilities:</p>
    <ul>
      <li class="bulletList">Delete the StatefulSet together with Pods that it owns</li>
      <li class="bulletList">Delete the StatefulSet and leave the Pods unaffected</li>
    </ul>
    <p class="normal">In both cases, the PVCs and PVs that were created for the Pods using <code class="inlineCode">volumeClaimTemplates</code> will <em class="italic">not</em> be deleted by default. This ensures that state data is not lost accidentally unless you explicitly clean up the PVCs and PVs.</p>
    <p class="normal">But with the latest Kubernetes versions (from v1.27 onwards), you can use the <code class="inlineCode">.spec.persistentVolumeClaimRetentionPolicy</code> field to control the deletion of PVCs as part of the StatefulSet life cycle:</p>
    <pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">StatefulSet</span>
<span class="hljs-string">...</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">persistentVolumeClaimRetentionPolicy:</span>
    <span class="hljs-attr">whenDeleted:</span> <span class="hljs-string">Retain</span>
    <span class="hljs-attr">whenScaled:</span> <span class="hljs-string">Delete</span>
<span class="hljs-string">...</span>
</code></pre>
    <p class="normal">Refer to the <a id="_idIndexMarker1144"/>documentation to learn more about <code class="inlineCode">persistentVolumeClaimRetentionPolicy</code> (<span class="url">https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#persistentvolumeclaim-retention</span>).</p>
    <p class="normal">To delete the StatefulSet object together with Pods, you can use the regular <code class="inlineCode">kubectl delete</code> command:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl delete sts -n mysql mysql-stateful
statefulset.apps "mysql-stateful" deleted
</code></pre>
    <p class="normal">You will see that the Pods will be terminated first, followed by the StatefulSet object. Please note that this operation is different from <em class="italic">scaling down</em> the StatefulSet object to zero replicas and then deleting it. If you delete the StatefulSet object with existing Pods, there are no guarantees regarding the order of termination of the individual Pods. In most cases, they will be terminated at once.</p>
    <p class="normal">Optionally, if you would like to delete just the StatefulSet object, you need to use the <code class="inlineCode">--cascade=orphan</code> option for <code class="inlineCode">kubectl delete</code>:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl delete sts -n mysql mysql-stateful --cascade=orphan
</code></pre>
    <p class="normal">After this command, if you inspect what Pods are in the cluster, you will still see all the Pods that were owned by the <code class="inlineCode">mysql-stateful</code> StatefulSet.</p>
    <p class="normal">Lastly, if you would like to clean up PVCs and PVs after deleting the StatefulSet object, you need to perform this step manually. Use the following command to delete the PVC’s created as part of the StatefulSet:</p>
    <pre class="programlisting con"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl delete -n mysql pvc mysql-data-mysql-stateful-0 mysql-data-mysql-stateful-1 mysql-data-mysql-stateful-2 mysql-data-mysql-stateful-3
persistentvolumeclaim "mysql-data-mysql-stateful-0" deleted
persistentvolumeclaim "mysql-data-mysql-stateful-1" deleted
persistentvolumeclaim "mysql-data-mysql-stateful-2" deleted
persistentvolumeclaim "mysql-data-mysql-stateful-3" deleted
</code></pre>
    <p class="normal">This <a id="_idIndexMarker1145"/>command will delete PVCs and associated PVs.</p>
    <div class="note">
      <p class="normal">IMPORTANT NOTE</p>
      <p class="normal">Please note that if you want to perform verifications of state persistence after exercising the new version rollout in the next section, you should not yet delete the PVCs. Otherwise, you will lose the MySQL files stored in the PVs.</p>
    </div>
    <p class="normal">With this section, we have completed our learning on basic operations with the StatefulSet objects in Kubernetes. Next, let’s take a look at releasing new versions of apps deployed as StatefulSets and how StatefulSet revisions are managed.</p>
    <h1 class="heading-1" id="_idParaDest-438">Releasing a new version of an app deployed as a StatefulSet</h1>
    <p class="normal">We have just covered the <em class="italic">scaling</em> of StatefulSets in the previous section by the <code class="inlineCode">kubectl scale</code> command (or by making changes to the <code class="inlineCode">.spec.replicas</code> number in the specification). Everything you have learned about sequential and ordered changes to the Pods plays an important role in rolling out a new revision of a StatefulSet object when using the <code class="inlineCode">RollingUpdate</code> strategy. There are many similarities between StatefulSets and Deployment objects. We covered the details of Deployment updates in <em class="chapterRef">Chapter 11</em>, <em class="italic">Using Kubernetes Deployments for Stateless Workloads</em>. Making changes to the StatefulSet Pod <em class="italic">template</em> (<code class="inlineCode">.spec.template</code>) in the specification will also cause the rollout of a new revision for StatefulSet.</p>
    <p class="normal">StatefulSets support two types of <em class="italic">update strategies</em> that you define using the <code class="inlineCode">.spec.updateStrategy.type</code> field in the specification:</p>
    <ul>
      <li class="bulletList"><code class="inlineCode">RollingUpdate</code>: The default strategy, which allows you to roll out a new version of your application in a controlled way. This is slightly different from the <code class="inlineCode">RollingUpdate</code> strategy<a id="_idIndexMarker1146"/> known from Deployment objects. For StatefulSet, this strategy will terminate and recreate Pods in a sequential and ordered fashion and make sure that the Pod is recreated and in a ready state before proceeding to the next one.</li>
      <li class="bulletList"><code class="inlineCode">OnDelete</code>: This strategy<a id="_idIndexMarker1147"/> implements the legacy behavior of StatefulSet updates prior to Kubernetes 1.7. However, it is still useful! In this type of strategy, StatefulSet will <em class="italic">not</em> automatically update the Pod replicas by recreating them. You need to manually delete a Pod replica to get the new Pod template applied. This is useful in scenarios when you need to perform additional manual actions or verifications before proceeding to the next Pod replica. For example, if you are running a <em class="italic">Cassandra cluster</em> or an <em class="italic">etcd cluster</em> in a StatefulSet, you may want to verify whether the new Pod has correctly joined the existing cluster following the removal of the previous version of the Pod. Of course, it is possible to perform similar checks using the Pod template life cycle <code class="inlineCode">postStart</code> and <code class="inlineCode">preStop</code> hooks while using the <code class="inlineCode">RollingUpdate</code> strategy, but this requires more sophisticated error handling in the hooks.</li>
    </ul>
    <p class="normal">Let’s now take a closer look at the <code class="inlineCode">RollingUpdate</code> strategy, which is the most important and commonly used update strategy for StatefulSets. The key thing about this is that the strategy respects all the StatefulSet guarantees, which we explained in the previous section regarding scaling. The rollout is done in reverse order; for example, the first Pod, <code class="inlineCode">mysql-stateful-2</code>, is recreated with the new Pod template, followed by <code class="inlineCode">mysql-stateful-1</code>, and finally <code class="inlineCode">mysql-stateful-0</code>.</p>
    <p class="normal">If the process of rollout fails (not necessarily the Pod that was currently recreated), the StatefulSet controller is going to restore any failed Pod to its <em class="italic">current version</em>. This means that the Pods that have already received a <em class="italic">successful</em> update to the current version will remain at the current version, whereas the Pods that have not yet received the update will remain at the previous version. In this way, the StatefulSet attempts to always keep applications healthy and consistent. However, this can also lead to <em class="italic">broken</em> rollouts of StatefulSets. If one of the Pod replicas <em class="italic">never</em> becomes running and ready, then the StatefulSet will stop the rollout and wait for <em class="italic">manual</em> intervention. Applying the template again to the previous revision of StatefulSet is not enough – this operation will not proceed as the StatefulSet will wait for the failed Pod to become ready. The only resolution is manual deletion of the failed Pod and then having the StatefulSet apply the previous revision of the Pod template.</p>
    <p class="normal">Lastly, the <code class="inlineCode">RollingUpdate</code> strategy also provides the option to execute <em class="italic">staged</em> rollouts using the <code class="inlineCode">.spec.updateStrategy.rollingUpdate.partition</code> field. This field defines a number for which all the Pod replicas that have a <em class="italic">lesser</em> <em class="italic">ordinal</em> number will not be updated, and, even if they are deleted, they will be recreated at the previous version. So, in our example, if the <code class="inlineCode">partition</code> were to be set to <code class="inlineCode">1</code>, this means that during the rollout, only <code class="inlineCode">mysql-stateful-1</code> and <code class="inlineCode">mysql-stateful-2</code> would be updated, whereas <code class="inlineCode">mysql-stateful-0</code> would remain unchanged and run on the previous version. By controlling the <code class="inlineCode">partition</code> field, you can easily roll out a single <em class="italic">canary</em> replica and perform <em class="italic">phased</em> rollouts. Please note that the default value is <code class="inlineCode">0</code>, which means that all Pod replicas will be updated.</p>
    <p class="normal">Now, we will release a new version of our mysqlserver using the <code class="inlineCode">RollingUpdate</code> strategy.</p>
    <h2 class="heading-2" id="_idParaDest-439">Updating StatefulSet</h2>
    <p class="normal">We will now demonstrate <a id="_idIndexMarker1148"/>how to do a rollout of a new image version for a Pod container using the StatefulSet YAML manifest file that we created previously:</p>
    <ol>
      <li class="numberedList" value="1">Make a copy of the previous YAML manifest file:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span><span class="hljs-con-built_in">cp</span> mysql-statefulset.yaml mysql-statefulset-rolling-update.yaml
</code></pre>
      </li>
      <li class="numberedList">Ensure that you have the <code class="inlineCode">RollingUpdate</code> strategy type and <code class="inlineCode">partition</code> set to <code class="inlineCode">0</code>. Also note that if you have attempted to create the StatefulSet object with a different strategy first, you will not be able to modify it without deleting the StatefulSet beforehand:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-comment"># mysql-statefulset-rolling-update.yaml</span>
<span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">StatefulSet</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">mysql-stateful</span>
  <span class="hljs-attr">labels:</span>
    <span class="hljs-attr">app:</span> <span class="hljs-string">mysql</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">mysql</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">serviceName:</span> <span class="hljs-string">mysql-headless</span>
  <span class="code-highlight"><strong class="hljs-attr-slc">podManagementPolicy:</strong><strong class="hljs-slc"> </strong><strong class="hljs-string-slc">OrderedReady</strong></span>
  <span class="hljs-attr">updateStrategy:</span>
    <span class="hljs-attr">type:</span> <span class="hljs-string">RollingUpdate</span>
    <span class="hljs-attr">rollingUpdate:</span>
      <span class="code-highlight"><strong class="hljs-attr-slc">partition:</strong><strong class="hljs-slc"> </strong><strong class="hljs-number-slc">0</strong></span>
  <span class="hljs-attr">replicas:</span> <span class="hljs-number">3</span>
<span class="hljs-string">...&lt;removed</span> <span class="hljs-string">for</span> <span class="hljs-string">brevity&gt;...</span>
<span class="hljs-string">(Refer</span> <span class="hljs-string">to</span> <span class="hljs-string">the</span> <span class="hljs-string">GitHub</span> <span class="hljs-string">repo</span> <span class="hljs-string">for</span> <span class="hljs-string">full</span> <span class="hljs-string">YAML)</span> 
</code></pre>
      </li>
    </ol>
    <p class="normal-one">These values are the default ones, but it is worth specifying them explicitly to understand what is really happening.</p>
    <ol>
      <li class="numberedList" value="3">Apply the<a id="_idIndexMarker1149"/> manifest file to the cluster to create the <code class="inlineCode">mysql-stateful</code> StatefulSet with new configurations:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f mysql-statefulset-rolling-update.yaml
statefulset.apps/mysql-stateful created
</code></pre>
      </li>
    </ol>
    <p class="normal-one">Wait until the Pods are running before you continue the rolling update task. Let’s verify the pods created by StatefulSet using the <code class="inlineCode">kubectl get pods</code> command as follows:</p>
    <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl get pods -n mysql
NAME               READY   STATUS    RESTARTS      AGE
k8sutils           1/1     Running   1 (21h ago)   23h
mysql-stateful-0   1/1     Running   0             65s
mysql-stateful-1   1/1     Running   0             62s
mysql-stateful-2   1/1     Running   0             58s
</code></pre>
    <ol>
      <li class="numberedList" value="4">When the<a id="_idIndexMarker1150"/> StatefulSet is ready in the cluster, let’s create a new database inside the StatefulSet via the k8sutils Pod as follows:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> -it -n mysql k8sutils -- /bin/bash
root@k8sutils:/# mysql -u root -p -h mysql-stateful-0.mysql-headless
Enter password: &lt;mysqlroot&gt;
Welcome to the MariaDB monitor.  Commands end with ; or \g.
...&lt;removed for brevity&gt;...
MySQL [(none)]&gt; create database stsrolling;
Query OK, 1 row affected (0.027 sec)
MySQL [(none)]&gt; exit;
</code></pre>
      </li>
    </ol>
    <p class="normal-one">Now, we have a new StatefulSet with <code class="inlineCode">updateStrategy</code> and a new database created inside.</p>
    <p class="normal">Next, we can roll out a new version of the MySQL container image for our StatefulSet object. To do that, perform the following steps:</p>
    <ol>
      <li class="numberedList" value="1">Modify the container image used in the StatefulSet Pod template to <code class="inlineCode">mysql:8.3.0</code>:
        <pre class="programlisting code-one"><code class="hljs-code"><span class="hljs-comment"># mysql-statefulset-rolling-update.yaml</span>
<span class="hljs-string">...&lt;removed</span> <span class="hljs-string">for</span> <span class="hljs-string">brevity&gt;...</span>
    <span class="hljs-attr">spec:</span>
      <span class="hljs-attr">containers:</span>
        <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">mysql</span>
          <span class="hljs-attr">image:</span> <span class="hljs-string">mysql:8.3.0</span>
<span class="hljs-string">...&lt;removed</span> <span class="hljs-string">for</span> <span class="hljs-string">brevity&gt;...</span>
</code></pre>
      </li>
      <li class="numberedList">Apply the changes to the cluster using the following command:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f mysql-statefulset-rolling-update.yaml
statefulset.apps/mysql-stateful configured
</code></pre>
      </li>
      <li class="numberedList">Immediately <a id="_idIndexMarker1151"/>after that, use the <code class="inlineCode">kubectl rollout status</code> command to see the progress in real time. This process will be a bit longer than in the case of Deployment objects because the rollout is performed in a sequential and ordered fashion:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl rollout status statefulset -n mysql
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for partitioned roll out to finish: 1 out of 3 new pods have been updated...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for partitioned roll out to finish: 2 out of 3 new pods have been updated...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
partitioned roll out complete: 3 new pods have been updated...
</code></pre>
      </li>
      <li class="numberedList">Similarly, using the <code class="inlineCode">kubectl describe</code> command, you can see events for the StatefulSet <a id="_idIndexMarker1152"/>that demonstrate precisely what the order of Pod replica recreation was:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl describe sts -n mysql mysql-stateful
Name:               mysql-stateful
Namespace:          mysql
...&lt;removed for brevity&gt;...
Events:
  Type     Reason                   Age                From                    Message
  ----     ------                   ----               ----                    -------
...&lt;removed for brevity&gt;...
  Normal   SuccessfulDelete         72s (x7 over 73s)  statefulset-controller  delete Pod mysql-stateful-2 in StatefulSet mysql-stateful successful
  Normal   RecreatingTerminatedPod  72s (x7 over 72s)  statefulset-controller  StatefulSet mysql/mysql-stateful is recreating terminated Pod mysql-stateful-2
  Warning  FailedDelete             72s                statefulset-controller  delete Pod mysql-stateful-2 in StatefulSet mysql-stateful failed error: pods "mysql-stateful-2" not found
  Normal   SuccessfulDelete         70s (x2 over 71s)  statefulset-controller  delete Pod mysql-stateful-1 in StatefulSet mysql-stateful successful
  Normal   RecreatingTerminatedPod  70s                statefulset-controller  StatefulSet mysql/mysql-stateful is recreating terminated Pod mysql-stateful-1
</code></pre>
      </li>
    </ol>
    <p class="normal-one">As expected, the rollout was done in <em class="italic">reverse</em> order. The first Pod to recreate was <code class="inlineCode">mysql-stateful-2</code> followed by <code class="inlineCode">mysql-stateful-1</code>, and finally <code class="inlineCode">mysql-stateful-0</code>. Also, because we have used the default <code class="inlineCode">partition</code> value of <code class="inlineCode">0</code>, all the Pods were updated. This is because all ordinal numbers of Pod replicas are greater than or equal to <code class="inlineCode">0</code>.</p>
    <ol>
      <li class="numberedList" value="5">Now, we can<a id="_idIndexMarker1153"/> verify that the Pods were recreated with the new image. Execute the following command to verify the first Pod replica in the StatefulSet object:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl describe pod -n mysql mysql-stateful-0|grep Image
    Image:          mysql:8.3.0
    Image ID:       docker.io/library/mysql@sha256:9de9d54fecee6253130e65154b930978b1fcc336bcc86dfd06e89b72a2588ebe
</code></pre>
      </li>
      <li class="numberedList">And finally, you can verify that the <em class="italic">state</em> persisted because the existing PVCs were used for the new Pods. Please note that this will only work properly if you haven’t deleted the PVCs for the StatefulSet manually in the previous section:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> -it -n mysql k8sutils -- /bin/bash
root@k8sutils:/# mysql -u root -p -h mysql-stateful-0.mysql-headless
Enter password: <span class="code-highlight"><strong class="hljs-slc">&lt;mysqlroot&gt;</strong></span>
...&lt;removed for brevity&gt;...
Server version: <span class="code-highlight"><strong class="hljs-slc">8.3.0 MySQL Community Server - GPL</strong></span>
Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.
Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.
MySQL [(none)]&gt; show databases;
+--------------------+
| Database           |
+--------------------+
| information_schema |
| mysql              |
| performance_schema |
<span class="code-highlight"><strong class="hljs-slc">| stsrolling         |</strong></span>
| sys                |
+--------------------+
5 rows in set (0.004 sec)
MySQL [(none)]&gt;
</code></pre>
      </li>
    </ol>
    <p class="normal-one">As you can see in the preceding output, the rollout of a new version of MySQL was completed successfully and the state has persisted even though the Pods were<a id="_idIndexMarker1154"/> recreated; you can see the <code class="inlineCode">stsrolling</code> database, which you created before the rolling update.</p>
    <div class="packt_tip-one">
      <p class="normal">You can change the StatefulSet container image <em class="italic">imperatively</em> using the kubectl -n mysql set image sts <code class="inlineCode">mysql-stateful mysql=mysql:8.3.0</code> command. This approach is only recommended for non-production and testing scenarios. In general, StatefulSets are much easier to manage declaratively than imperatively.</p>
    </div>
    <p class="normal">Now, let us learn how you can use the <code class="inlineCode">partition</code> field to do a <em class="italic">phased</em> rollout with a <em class="italic">canary</em>. Assume that we would like to update the mysql image version to <code class="inlineCode">8.4.0</code>. You would like to make sure that the change is working properly in your environment using a canary deployment, which is a single (or some) Pod replica updated to the new image (or another image) version. Please refer to the following steps:</p>
    <ol>
      <li class="numberedList" value="1">Modify the <code class="inlineCode">mysql-statefulset-rolling-update.yaml</code> manifest file so that the <code class="inlineCode">partition</code> number is equal to current <code class="inlineCode">replicas</code>, in our case, <code class="inlineCode">3</code>:
        <pre class="programlisting con-one"><code class="hljs-con">...&lt;removed for brevity&gt;...
spec:
  serviceName: mysql-headless
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      <span class="code-highlight"><strong class="hljs-slc">partition: 3</strong></span>
...&lt;removed for brevity&gt;...
Also, update the image to 8.4.0 as follows:
...
    spec:
      containers:
        - name: mysql
          <span class="code-highlight"><strong class="hljs-slc">image: mysql:8.4.0</strong></span>
...&lt;removed for brevity&gt;...
</code></pre>
      </li>
    </ol>
    <p class="normal-one">When the <code class="inlineCode">partition</code> number is the same as the number of <code class="inlineCode">replicas</code>, we can apply the YAML manifest to the cluster and no changes to the Pods will be introduced yet. This is <a id="_idIndexMarker1155"/>called <strong class="keyWord">staging a rollout</strong>.</p>
    <ol>
      <li class="numberedList" value="2">Apply the manifest file to the cluster:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f mysql-statefulset-rolling-update.yaml
statefulset.apps/mysql-stateful configured
</code></pre>
      </li>
      <li class="numberedList">Now, let’s <a id="_idIndexMarker1156"/>create a <em class="italic">canary</em> for our new version. Decrease the <code class="inlineCode">partition</code> number by one to <code class="inlineCode">2</code> in the manifest file. This means that all Pod replicas with an ordinal number of less than <code class="inlineCode">2</code> will not be updated – in our case, that means updating the <code class="inlineCode">mysql-stateful-2</code> Pod only. All others will remain unchanged:
        <pre class="programlisting con-one"><code class="hljs-con">...
spec:
  serviceName: mysql-headless
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 2
  replicas: 3
...
</code></pre>
      </li>
      <li class="numberedList">Apply the manifest file to the cluster again:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f mysql-statefulset-rolling-update.yaml
statefulset.apps/mysql-stateful configured
</code></pre>
      </li>
      <li class="numberedList">Use the <code class="inlineCode">kubectl rollout status</code> command to follow the process. As expected, only one Pod will be recreated:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl rollout status statefulset -n mysql
Waiting for partitioned roll out to finish: 0 out of 1 new pods have been updated...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
partitioned roll out complete: 1 new pods have been updated...
</code></pre>
      </li>
      <li class="numberedList">If you describe <a id="_idIndexMarker1157"/>the MySQL <code class="inlineCode">mysql-stateful-0</code> and MySQL <code class="inlineCode">mysql-stateful-2</code> Pods, you can see that the first one is using the old version of the image, whereas the second is using the new one:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl describe pod -n mysql mysql-stateful-0|grep Image
    Image:          mysql:8.3.0
    Image ID:       docker-pullable://mysql@sha256:9de9d54fecee6253130e65154b930978b1fcc336bcc86dfd06e89b72a2588ebe
<span class="hljs-con-meta">$ </span>kubectl describe pod -n mysql mysql-stateful-2|grep Image
    Image:          mysql:8.4.0
    Image ID:       docker-pullable://mysql@sha256:4a4e5e2a19aab7a67870588952e8f401e17a330466ecfc55c9acf51196da5bd0
</code></pre>
      </li>
      <li class="numberedList">At this point, you can perform verifications and smoke tests on your canary. Log in to the k8sutils Pod and ensure the new Pod is running well with the new image (e.g., 8.4.0). The canary looks good, so we can continue with a <em class="italic">phased</em> rollout of our new version:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl <span class="hljs-con-built_in">exec</span> -it -n mysql k8sutils -- /bin/bash
root@k8sutils:/# mysql -u root -p -h mysql-stateful-2.mysql-headless
Enter password: &lt;mysqlroot&gt;
Welcome to the MariaDB monitor.  Commands end with ; or \g.
Your MySQL connection id is 11
Server version: 8.4.0 MySQL Community Server - GPL
...
</code></pre>
      </li>
      <li class="numberedList">For a phased<a id="_idIndexMarker1158"/> rollout, you may use any <em class="italic">lower</em> <code class="inlineCode">partition</code> number in the manifest. You can do a few small, phased rollouts or just proceed with a full rollout. Let’s do a full rollout by decreasing <code class="inlineCode">partition</code> to <code class="inlineCode">0</code>:
        <pre class="programlisting con-one"><code class="hljs-con">...
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0
...
</code></pre>
      </li>
      <li class="numberedList">Apply the manifest file to the cluster again:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl apply -f mysql-statefulset-rolling-update.yaml
statefulset.apps/mysql-stateful configured
</code></pre>
      </li>
      <li class="numberedList">Observe the next phase of the rollout using the <code class="inlineCode">kubectl rollout status</code> command:
        <pre class="programlisting con-one"><code class="hljs-con"><span class="hljs-con-meta">$ </span>kubectl rollout status statefulset -n mysql
Waiting for partitioned roll out to finish: 1 out of 3 new pods have been updated...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for partitioned roll out to finish: 2 out of 3 new pods have been updated...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
Waiting for 1 pods to be ready...
partitioned roll out complete: 3 new pods have been updated...
</code></pre>
      </li>
    </ol>
    <p class="normal">As you can see, the<a id="_idIndexMarker1159"/> phased rollout to the <code class="inlineCode">mysql:8.4.0</code> image version was completed successfully.</p>
    <div class="packt_tip">
      <p class="normal">It is possible to do phased rollouts <em class="italic">imperatively</em>. To do that, you need to control the <code class="inlineCode">partition</code> number using the <code class="inlineCode">kubectl patch</code> command, for example, <code class="inlineCode">kubectl patch sts mysql-stateful -p '{"spec":{"updateStrategy":{"type":"RollingUpdate","rollingUpdate":{"partition":3}}}}' -n mysql</code>. However, this is much less readable and more error-prone than <em class="italic">declarative</em> changes.</p>
    </div>
    <p class="normal">We will now take a look at how you can do rollbacks of StatefulSets in the next section.</p>
    <h2 class="heading-2" id="_idParaDest-440">Rolling back StatefulSet</h2>
    <p class="normal">In the <a id="_idIndexMarker1160"/>previous <em class="chapterRef">Chapter 11</em>, <em class="italic">Using Kubernetes Deployments for Stateless Workloads</em>, we have described how you can do <em class="italic">imperative</em> rollbacks to Deployments. For StatefulSets, you can do exactly the same operations. To do that, you need to use the <code class="inlineCode">kubectl rollout undo</code> commands. However, especially for StatefulSets, we recommend using a <em class="italic">declarative</em> model for introducing changes to your Kubernetes cluster. In this model, you usually commit each change to the source code repository. Performing rollback is very simple and involves just reverting the commit and applying the configuration again. Usually, the process of applying changes (both deployment and updates) can be performed as part of the CI/CD pipeline for the source code repository, instead of manually applying the changes by an operator. This is the easiest way to manage StatefulSets, and is generally recommended in Infrastructure-as-Code and Configuration-as-Code paradigms.</p>
    <div class="note">
      <p class="normal">When performing rollbacks to StatefulSets, you must be fully aware of the consequences of operations such as <em class="italic">downgrading</em> to an earlier version of the container image while persisting the state. For example, if your rollout to a new version has introduced <em class="italic">data schema changes</em> to the state, then you will not be able to safely roll back to an earlier version unless you ensure that the <em class="italic">downward migration</em> of state data is implemented!</p>
    </div>
    <p class="normal">In our example, if you <a id="_idIndexMarker1161"/>would like to roll back to the mysql:8.3.0 image version for our StatefulSet, you would either modify the YAML manifest file manually or revert the commit in your source code repository if you use one. Then, all you would need to do is execute the <code class="inlineCode">kubectl apply</code> command to the cluster.</p>
    <p class="normal">Now, in the last section of this chapter, we will provide you with a set of best practices for managing StatefulSets in Kubernetes.</p>
    <h1 class="heading-1" id="_idParaDest-441">StatefulSet best practices</h1>
    <p class="normal">This section<a id="_idIndexMarker1162"/> summarizes the known best practices when working with StatefulSet objects in Kubernetes. The list is by no means complete but is a good starting point for your journey with Kubernetes StatefulSet.</p>
    <h2 class="heading-2" id="_idParaDest-442">Use declarative object management for StatefulSets</h2>
    <p class="normal">It is a good practice in the DevOps world to stick to declarative models for introducing updates to your infrastructure and applications. Using the declarative way of updates is the core concept for paradigms such as Infrastructure-as-Code and Configuration-as-Code. In Kubernetes, you can easily perform declarative updates using the <code class="inlineCode">kubectl apply</code> command, which can be used on a single file or even a whole directory of YAML manifest files.</p>
    <div class="packt_tip">
      <p class="normal">To delete objects, it is still better to use imperative commands. It is more predictable and less prone to errors. The declarative deletion of resources in the cluster is useful mostly in CI/CD scenarios, where the whole process is entirely automated.</p>
    </div>
    <p class="normal">The same principle also applies to StatefulSets. Performing a rollout or rollback when your YAML manifest files are versioned and kept in a source control repository is easy and predictable. Using the <code class="inlineCode">kubectl rollout undo</code> method and <code class="inlineCode">kubectl set image deployment</code> commands is generally not practiced in production environments. Using these commands gets much more complicated when more than one person is working on operations in the cluster.</p>
    <h2 class="heading-2" id="_idParaDest-443">Do not use the TerminationGracePeriodSeconds Pod with a 0 value for StatefulSets</h2>
    <p class="normal">The specification of <a id="_idIndexMarker1163"/>Pod allows you to set <code class="inlineCode">TerminationGracePeriodSeconds</code>, which informs <code class="inlineCode">kubelet</code> how much time it should allow for a Pod to gracefully terminate when it attempts to terminate it. If you set <code class="inlineCode">TerminationGracePeriodSeconds</code> to <code class="inlineCode">0</code>, this will effectively make Pods terminate <em class="italic">immediately</em>, which is strongly discouraged for StatefulSets. StatefulSets often need graceful cleanup or <code class="inlineCode">preStop</code> life cycle hooks to run before the container is removed. Otherwise, there is a risk that the state of StatefulSet will become inconsistent. Refer to the Container hooks documentation (<span class="url">https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks</span>) to learn more.</p>
    <h2 class="heading-2" id="_idParaDest-444">Scale down StatefulSets before deleting</h2>
    <p class="normal">When you delete a StatefulSet and you intend to reuse the PVCs later, you need to ensure that the StatefulSet terminates gracefully, in an ordered manner, so that any subsequent redeployment will not fail because of an inconsistent state in PVCs. If you perform the <code class="inlineCode">kubectl delete</code> operation on your StatefulSet, all the Pods will be terminated <em class="italic">at once</em>. This is often not desired, and you should first scale down the StatefulSet gracefully to zero replicas and then delete the StatefulSet itself.</p>
    <h2 class="heading-2" id="_idParaDest-445">Ensure state compatibility during StatefulSet rollbacks</h2>
    <p class="normal">If you ever intend to use StatefulSet rollbacks, you need to be aware of the consequences of operations such as downgrading to an earlier version of the container image while persisting the state. For example, if your rollout to a new version has introduced data schema changes in the state, then you will not be able to safely roll back to an earlier version unless you ensure that the downward migration of state data is implemented. Otherwise, your rollback will just recreate Pods with the older versions of the container image, and they will fail to start properly because of incompatible state data.</p>
    <h2 class="heading-2" id="_idParaDest-446">Do not create Pods that match an existing StatefulSet label selector</h2>
    <p class="normal">It is possible to create Pods with labels that match the label selector of some existing StatefulSet. This can be done using bare Pods or another Deployment or ReplicaSet. This leads to conflicts, which Kubernetes does not prevent, and makes the existing StatefulSet <em class="italic">believe</em> that it has created the other Pods. The results may be unpredictable and, in general, you need to pay attention to how you organize your labeling of resources in the cluster. It is advised to use semantic labeling. You can learn more about this approach in the official documentation: <a href="https://kubernetes.io/docs/concepts/configuration/overview/#using-labels"><span class="url">https://kubernetes.io/docs/concepts/configuration/overview/#using-labels</span></a>.</p>
    <h2 class="heading-2" id="_idParaDest-447">Use Remote Storage for the PV</h2>
    <p class="normal">When using <a id="_idIndexMarker1164"/>StatefulSets, it’s important to ensure that you’re utilizing remote storage. This means storing your application’s data on a separate storage system, typically <strong class="keyWord">Network-Attached Storage</strong> (<strong class="keyWord">NAS</strong>), <strong class="keyWord">Storage Area Network</strong> (<strong class="keyWord">SAN</strong>), or a cloud <a id="_idIndexMarker1165"/>storage service. By storing data remotely, you<a id="_idIndexMarker1166"/> ensure that it’s accessible from any instance of your application (or any nodes in the cluster), even if the instance is replaced or moved. This provides data persistence and resilience, helping to prevent data loss in case of failures or updates to your StatefulSet.</p>
    <h2 class="heading-2" id="_idParaDest-448">Define liveness and readiness probes</h2>
    <p class="normal">For stateful applications, a healthy Pod needs to not only be running but also be able to access and process its persistent state. Liveness probes help ensure this functionality. If a liveness probe fails consistently, it indicates a deeper issue with the Pod’s ability to handle its state. Restarting the Pod in this case can potentially trigger recovery mechanisms or allow the StatefulSet controller to orchestrate a failover to another healthy Pod with the same state.</p>
    <p class="normal">StatefulSets often manage services that rely on specific data or configurations to be available before serving traffic. Readiness probes can be tailored to check if the Pod’s state is ready and operational. By preventing traffic from reaching unready Pods, you ensure a smooth user experience and avoid potential data inconsistencies.</p>
    <h2 class="heading-2" id="_idParaDest-449">Monitor your StatefulSets</h2>
    <p class="normal">Keeping an eye <a id="_idIndexMarker1167"/>on your StatefulSets’ health and performance is crucial. Utilize monitoring tools to track key metrics like Pod restarts, resource utilization, and application errors. This allows you to proactively identify and address potential issues before they impact your application’s functionality.</p>
    <h1 class="heading-1" id="_idParaDest-450">Summary</h1>
    <p class="normal">This chapter demonstrated how to work with <em class="italic">stateful</em> workloads and applications on Kubernetes using StatefulSets. We first learned what the approaches to persisting states in containers and Kubernetes Pods are, and, based on that, we described how a StatefulSet object can be used to persist the state. Next, we created an example StatefulSet, together with a <em class="italic">headless</em> Service. Based on that, you learned how PVCs and PVs are used in StatefulSets to ensure that the state is persisted between Pod restarts. Next, we learned how you can scale the StatefulSet and how to introduce updates using <em class="italic">canary</em> and <em class="italic">phased</em> rollouts. And finally, we provided a set of known best practices when working with StatefulSets.</p>
    <p class="normal">In the next chapter, you will learn more about managing special workloads where you need to maintain exactly one Pod per Node in Kubernetes. We will introduce a new Kubernetes object: DaemonSet.</p>
    <h1 class="heading-1" id="_idParaDest-451">Further reading</h1>
    <ul>
      <li class="bulletList">StatefulSets: <span class="url">https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/</span></li>
      <li class="bulletList">Headless Services: <span class="url">https://kubernetes.io/docs/concepts/services-networking/service/#headless-services</span></li>
      <li class="bulletList">Container hooks: <a href="https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks"><span class="url">https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#container-hooks</span></a></li>
    </ul>
    <h1 class="heading-1" id="_idParaDest-452">Join our community on Discord</h1>
    <p class="normal">Join our community’s Discord space for discussions with the authors and other readers:</p>
    <p class="normal"><a href="https://packt.link/cloudanddevops"><span class="url">https://packt.link/cloudanddevops</span></a></p>
    <p class="normal"><img alt="" src="image/QR_Code119001106479081656.png"/></p>
  </div>
</body></html>