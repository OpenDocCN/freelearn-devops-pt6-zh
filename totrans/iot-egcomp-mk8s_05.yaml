- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating and Implementing Updates on a Multi-Node Raspberry Pi Kubernetes Clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Companies are embracing digital transformation, Industry 4.0, industrial automation,
    smart manufacturing, and all the advanced use cases that these initiatives provide,
    as we saw in the previous chapter. As a result, the importance of Kubernetes,
    edge, and cloud collaboration to drive intelligent business decisions is becoming
    clear. Kubernetes is steadily becoming the go-to platform for edge computing and
    extends the benefits of cloud-native technologies to the edge, allowing for the
    flexible and automated management of applications that span a disaggregated cloud
    environment. In this and the following chapters, we will be looking at implementation
    aspects of common edge computing applications using the MicroK8s Kubernetes platform.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reiterating the points that we discussed in the previous chapter, **Canonical
    MicroK8s** ([https://microk8s.io/](https://microk8s.io/)) is a powerful, **Cloud
    Native Computing Foundation** (**CNCF**)-certified Kubernetes distribution. Here
    are some of the key reasons why it has become a powerful enterprise computing
    platform:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Delivered as a snap package**: These are application packages for desktop,
    cloud, and even **Internet of Things** (**IoT**) devices that are simple to install,
    secured with auto-updates, and can be deployed on any Linux distributions that
    support snaps.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Strict confinement**: This ensures complete isolation from the underlying
    **operating system** (**OS**) as well as a highly secure Kubernetes environment
    fit for production.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Production-grade add-ons**: Add-ons such as Istio, Knative, CoreDNS, Prometheus,
    Jaeger, Linkerd, Cilium, and Helm are available. They are straightforward to set
    up, requiring only a few lines of commands. For better **artificial intelligence**
    (**AI**) and **machine learning** (**ML**) capabilities, Kubeflow is also available
    as an add-on to MicroK8s.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automatic, autonomous, and self-healing high availability (HA)**: For clusters
    of three or more Nodes, MicroK8s automatically activates HA. With no administrative
    intervention, MicroK8s provides resilient and self-healing HA.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In this chapter, we''re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a MicroK8s multi-node cluster using a Raspberry Pi
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a sample containerized application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing rolling updates to the application with a new software version
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scaling the application deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guidelines on multi-node cluster configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container life cycle management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying and sharing HA applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a MicroK8s multi-node cluster using a Raspberry Pi
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we delve into the steps on how to create a MicroK8s multi-node cluster,
    let''s recap the key concepts of Kubernetes that we covered earlier, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'A **Kubernetes cluster** (like the one shown in *Figure 5.1*) would have the
    following two types of resources:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a. A **control plane** that controls the cluster
  prefs: []
  type: TYPE_NORMAL
- en: b. **Nodes**—the worker Nodes that run applications
  prefs: []
  type: TYPE_NORMAL
- en: All actions in the cluster are coordinated by the control plane, including scheduling
    applications, maintaining the intended state of applications, scaling applications,
    and rolling out new updates, among other things. Each node can be a **virtual
    machine** (**VM**) or a physical computer that serves as a worker machine in a
    cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A **Kubernetes control plane** is a collection of three processes: an **application
    programming interface (API) server**, a **controller manager**, and a **scheduler**.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Each individual non-control plane node on the cluster has a **kubelet** process
    that takes care of the communication with the Kubernetes control plane, the **kube-proxy**
    process for all network communications, and a **container runtime** such as Docker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The control plane issues a command to start the application containers when
    any applications need to be deployed on Kubernetes. Containers are scheduled to
    run on the cluster's Nodes by the control plane.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Nodes communicate with the control plane using the Kubernetes API, which
    the control plane exposes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'A typical Kubernetes architecture, system, and abstractions are shown in the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Kubernetes system and abstractions ](img/Figure_5.1_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – Kubernetes system and abstractions
  prefs: []
  type: TYPE_NORMAL
- en: Now that we are clear on the Kubernetes architecture, system, and abstractions,
    we will delve into the steps of creating a Kubernetes Raspberry Pi multi-node
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: What we are trying to achieve
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We''ll list down the steps that we''re seeking to accomplish in this section.
    Prepare Raspberry Pi 4 boards for MicroK8s installation by doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring MicroK8s on each of the boards
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Adding Nodes to the cluster
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Joining multiple deployments to form a two-node cluster (one control plane node/one
    worker node)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The Raspberry Pi cluster that we will build in this step is depicted in the
    following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – What we are trying to achieve ](img/Figure_5.2_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – What we are trying to achieve
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know what we want to do, let's look at the requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before you begin, here are the prerequisites for building a Raspberry Pi Kubernetes
    cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: A microSD card (4 **gigabytes** (**GB**) minimum; 8 GB recommended)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A computer with a microSD card drive
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Raspberry Pi 2, 3, or 4 (one or more)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **micro-Universal Serial Bus** (**micro-USB**) power cable (USB-C for the
    Pi 4)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Wi-Fi network or an Ethernet cable with an internet connection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (Optional) A monitor with a **High-Definition Multimedia Interface** (**HDMI**)
    interface
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (Optional) An HDMI cable for the Pi 2 and 3 and a micro-HDMI cable for the Pi
    4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (Optional) A USB keyboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we've established the requirements, we'll go on to the step-by-step
    instructions on how to complete the process.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1a**: **Installing OS image onto SD card**'
  prefs: []
  type: TYPE_NORMAL
- en: 'The first step is to install an OS image onto the microSD card. To do that,
    we will be using the **Raspberry Pi Imager tool**, as shown in the following screenshot,
    to install an OS image to a microSD card that can then be used with Raspberry
    Pi:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – Raspberry Pi Imager ](img/Figure_5.3_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – Raspberry Pi Imager
  prefs: []
  type: TYPE_NORMAL
- en: Download and install **Raspberry Pi Imager** from the Raspberry Pi website on
    a computer equipped with a **Secure Digital** (**SD**) card reader. Run Raspberry
    Pi Imager with the microSD card you'll be using and open the **CHOOSE OS** menu.
  prefs: []
  type: TYPE_NORMAL
- en: 'Choose **Other general purpose OS** from the options listed, as illustrated
    in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Raspberry Pi Imager OS options ](img/Figure_5.4_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Raspberry Pi Imager OS options
  prefs: []
  type: TYPE_NORMAL
- en: 'Choose any of the **Ubuntu Server** 64-bit versions that work with Raspberry
    Pi 2, 3, 3+, and 4 from the options listed, as illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – Choosing any Ubuntu Server version that works with Raspberry
    Pi Imager 2/3/4 ](img/Figure_5.5_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – Choosing any Ubuntu Server version that works with Raspberry Pi
    Imager 2/3/4
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: MicroK8s is only available for 64-bit Ubuntu images.
  prefs: []
  type: TYPE_NORMAL
- en: Open the **SD Card** menu after selecting an image. Choose the microSD card
    that you've inserted. Click **WRITE** to start the operation and Raspberry Pi
    Imager will wipe your microSD card data. You will be prompted to confirm this
    procedure.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process is illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – Raspberry Pi Imager write operation ](img/Figure_5.6_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – Raspberry Pi Imager write operation
  prefs: []
  type: TYPE_NORMAL
- en: 'Post confirmation, Raspberry Pi Imager will start flashing OS images to the
    microSD card. It will take a while to finish. The message that displays once finished
    is illustrated in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7 – Raspberry Pi Imager: write operation completed ](img/Figure_5.7_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.7 – Raspberry Pi Imager: write operation completed'
  prefs: []
  type: TYPE_NORMAL
- en: Once finished, continue with the configuration of Wi-Fi access, remote access,
    control groups, and hostname settings.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring Wi-Fi access settings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Open a file manager—as shown in the following screenshot—while the SD card
    is still inserted in your laptop, and look for the `system-boot` partition on
    the card. It holds the initial configuration files that are loaded during the
    first boot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8 – Configuring Wi-Fi access settings ](img/Figure_5.8_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.8 – Configuring Wi-Fi access settings
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the `network-config` file to include your Wi-Fi credentials. Here is
    an example of Wi-Fi configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: We've finished configuring Wi-Fi access and are ready to go on to the next step.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1b**: **Configuring remote access settings**'
  prefs: []
  type: TYPE_NORMAL
- en: By default, the `system-boot` partition on the card and create an empty file
    named `ssh` without a file extension. During the boot process, it will automatically
    prepare and set up SSH on your Raspberry Pi if it detects this file.
  prefs: []
  type: TYPE_NORMAL
- en: We've finished configuring remote access and are ready to go on to the next
    step of configuring control groups.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1c**: **Configuring control group settings**'
  prefs: []
  type: TYPE_NORMAL
- en: By default, control groups are disabled. Control groups (abbreviated as **cgroups**)
    are a Linux kernel feature that limits, accounts for, and isolates the resource
    usage (**central processing unit** (**CPU**), memory, disk **input/output** (**I/O**),
    network, and so on) of a collection of processes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the configuration file located at `/boot/firmware/cmdline.txt` on the
    card and add the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'A full line would look like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Save the file, extract the card from your laptop, and insert it into the Raspberry
    Pi. Before powering the Pi, connect an HDMI screen and a USB keyboard. Power on
    the Pi, and you will be able to see the boot process on the screen. It typically
    takes less than 2 minutes to complete the booting process.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the boot is finished, connect to your Raspberry Pi using any SSH client
    (for example, `putty`), and continue the following configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9 – PuTTY SSH client ](img/Figure_5.10_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.9 – PuTTY SSH client
  prefs: []
  type: TYPE_NORMAL
- en: 'Type in the IP address of the Raspberry Pi and click **Open** to connect. On
    the first connect, you will be asked to confirm the connection: click **Accept**
    to confirm.'
  prefs: []
  type: TYPE_NORMAL
- en: On the login page, type `ubuntu` as both the username and the password. Ubuntu
    will ask you to change your password to something else. After that, use the `ssh`
    command and the new password to reconnect.
  prefs: []
  type: TYPE_NORMAL
- en: '*Success! You are now connected to Ubuntu Server running on your Raspberry
    Pi.*'
  prefs: []
  type: TYPE_NORMAL
- en: We've finished configuring most of the settings and are ready to go on to the
    next step of hostname configuration.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1d**: **Configuring hostname**'
  prefs: []
  type: TYPE_NORMAL
- en: For Ubuntu OS, by default, the hostname would be `ubuntu`, but since we need
    different hostnames to be identified in the cluster, we would need to change this
    based on our needs. For the cluster we are creating, I'm going to name one of
    the Nodes `controlplane` and the others `WorkerXX`.
  prefs: []
  type: TYPE_NORMAL
- en: Follow the next steps to change the hostname.
  prefs: []
  type: TYPE_NORMAL
- en: 'From the `putty` shell, enter the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Modify the hostname and exit the `nano` editor using *Ctrl* + *X*.
  prefs: []
  type: TYPE_NORMAL
- en: Type `sudo reboot` for changes to take effect.
  prefs: []
  type: TYPE_NORMAL
- en: '*Congratulations! You have now completed all the configurations for your Raspberry
    Pi*.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Steps 1a* to *1d* must be repeated for all the Raspberry Pis in the cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Post successful boot, ensure your packages are updated to the latest version,
    and run the following commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: We've finished configuring all the settings for all the Raspberry Pis on the
    cluster and are ready to go on to the next step of installation and configuration
    of MicroK8s.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and configuring MicroK8s
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'SSH into your control plane node and install the MicroK8s snap, like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output confirms that the MicroK8s snap has
    been installed successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.10 – MicroK8s snap installation successful ](img/Figure_5.11_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.10 – MicroK8s snap installation successful
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have installed the MicroK8s snap, type the `microk8s status` command
    to verify its running state, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.11 – Verifying whether MicroK8s is running ](img/Figure_5.12_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.11 – Verifying whether MicroK8s is running
  prefs: []
  type: TYPE_NORMAL
- en: 'As indicated in the preceding command execution output, join the user in the
    MicroK8s group and gain access to a `.kube` caching directory using the following
    set of commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Retype the `microk8s status` command to verify whether it''s running. The following
    command execution output confirms that MicroK8s is running successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.12 – MicroK8s is running ](img/Figure_5.13_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.12 – MicroK8s is running
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that we have installed MicroK8s, the next step is to create a `kubectl`
    alias with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output confirms that an alias has been added
    successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.13 – kubectl alias successfully added ](img/Figure_5.14_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.13 – kubectl alias successfully added
  prefs: []
  type: TYPE_NORMAL
- en: 'If the installation has been successful, you should then see the following
    output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.14 – Verifying whether the node is in a Ready state ](img/Figure_5.15_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.14 – Verifying whether the node is in a Ready state
  prefs: []
  type: TYPE_NORMAL
- en: Repeat the MicroK8s installation process on the other Nodes as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the command execution output of the MicroK8s installation on the worker
    node:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15 – MicroK8s snap installation on worker1 node successful ](img/Figure_5.16_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.15 – MicroK8s snap installation on worker1 node successful
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command execution output confirms that MicroK8s is running successfully
    on the worker node as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.16 – Verifying whether MicroK8s is running ](img/Figure_5.17_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.16 – Verifying whether MicroK8s is running
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that MicroK8s is running, the next step is to check whether the `kubectl
    get Nodes` command displays the node in a `Ready` state, as indicated in the following
    command execution output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.17 – Verifying whether the node is in a Ready state ](img/Figure_5.18_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.17 – Verifying whether the node is in a Ready state
  prefs: []
  type: TYPE_NORMAL
- en: 'We have completed the installation of MicroK8s on all boards. The next step
    is to add a worker node to the control plane node. Open the `putty` shell to the
    control plane node and run the following command to generate a connection string:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output validates that the command was successfully
    executed and provides instructions for the connection string:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.18 – Generating connection string for adding Nodes ](img/Figure_5.19_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.18 – Generating connection string for adding Nodes
  prefs: []
  type: TYPE_NORMAL
- en: As indicated by the preceding command execution output, a connection string
    is generated in the form of `<control plane_ip>:<port>/<token>`.
  prefs: []
  type: TYPE_NORMAL
- en: Adding the worker node
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We now have the connection string to join with the control plane node. Open
    the `putty` shell to the worker node and run the `join` command to add it to the
    cluster, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The command was successfully executed, and the node has joined the cluster,
    as shown in the following output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.19 – Adding worker1 node to the cluster ](img/Figure_5.20_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.19 – Adding worker1 node to the cluster
  prefs: []
  type: TYPE_NORMAL
- en: As indicated by the preceding command execution output, you should be able to
    see the new node in a few seconds on the control plane.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the following command to verify whether the new node has been added to
    the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output shows that `controlplane` and `worker1`
    are part of the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.20 – Cluster is ready; controlplane and worker1 are part of the
    cluster ](img/Figure_5.21_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.20 – Cluster is ready; controlplane and worker1 are part of the cluster
  prefs: []
  type: TYPE_NORMAL
- en: 'The completed cluster should resemble the one as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.21 – Our cluster is ready ](img/Figure_5.22_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.21 – Our cluster is ready
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'If you want to remove a node from the cluster, run the following command on
    the control plane: `sudo microk8s remove-node <node name>`. Alternatively, you
    can leave the cluster from the worker node by running `sudo microk8s.leave`.'
  prefs: []
  type: TYPE_NORMAL
- en: At this point, you have a fully functional multi-node Kubernetes cluster. To
    summarize, we have installed MicroK8s on the Raspberry Pi boards and joined multiple
    deployments to form the cluster. We've seen how to add Nodes to the cluster as
    well. In the next section, we are going to deploy a sample application on the
    MicroK8s cluster we just created.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying a sample containerized application
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will be deploying the following nginx deployment from the
    Kubernetes examples repository on our multi-node MicroK8s cluster setup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command will deploy the previous sample application deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output indicates that there is no error in
    the deployment, and in the next step, we can verify this using the `describe`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.22 – Sample application deployment ](img/Figure_5.23_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.22 – Sample application deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command execution output displays information about the deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.23 – Describing sample application deployment ](img/Figure_5.24_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.23 – Describing sample application deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'Check the pods'' status to verify whether the application has been deployed
    and running, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output indicates that pods have been created
    and that their status is `Running`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.24 – Checking whether pods are in a Running status ](img/Figure_5.25_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.24 – Checking whether pods are in a Running status
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s also check where the pods are running using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output indicates that pods are equally distributed
    between the Nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.25 – Checking whether pods are equally distributed  ](img/Figure_5.26_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.25 – Checking whether pods are equally distributed
  prefs: []
  type: TYPE_NORMAL
- en: 'Great! We have just deployed our sample application deployment on the Raspberry
    Pi multi-node cluster. Here is what Kubernetes has done for us:'
  prefs: []
  type: TYPE_NORMAL
- en: Looked for a suitable node on which to run an instance of the application (we
    have two available Nodes) and scheduled the application to run on that node based
    on `podAntiAffinity` rules.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`podAntiAffinity` rules limit the pod deployments on which Nodes the pod can
    be scheduled based on labels from other pods currently operating on the node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configured the cluster to reschedule the instance on a new node when needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pod topology spread constraints can also be used to regulate how pods are distributed
    among failure domains such as regions, zones, Nodes, and other user-defined topology
    domains in your cluster. This can aid in achieving HA and resource-use efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, we built a Kubernetes Raspberry Pi cluster and used it to deploy
    a sample application. In the next step, we'll perform rolling updates to the application
    we've just deployed.
  prefs: []
  type: TYPE_NORMAL
- en: Performing rolling updates to the application with a new software version
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The rolling updates feature of Kubernetes allows Deployments to be updated with
    zero downtime. It handles the upgrading of pods' instances with new ones in an
    incremental manner, and new pods would be scheduled on Nodes that have resources
    available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some key features of rolling updates are listed here:'
  prefs: []
  type: TYPE_NORMAL
- en: Transferring an application from one environment to another (via container image
    updates).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rollback to a prior version of the application.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With minimal downtime, **continuous integration** and **continuous delivery**
    (**CI/CD**) of applications are achievable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are going to reuse the same example of the nginx sample deployment that we
    used earlier. We can update the same deployment by applying the following new
    YAML file.
  prefs: []
  type: TYPE_NORMAL
- en: 'This YAML file specifies that the deployment should be updated to use the `nginx
    1.16.1` container image instead of `nginx.1.14.2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command will deploy the preceding updated application deployment
    that uses the `nginx 1.16.1` image instead of the `nginx 1.14.2` image:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'The following output after the execution of the previous command confirms that
    there is no error in the deployment, and in the next steps, we can verify the
    recreation of pods with new names and delete the old pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.26 – Update to sample application deployment ](img/Figure_5.27_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.26 – Update to sample application deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command execution output indicates that pods have been recreated
    and that their status is `Running`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.27 – New pods of updated deployment ](img/Figure_5.28_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.27 – New pods of updated deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how a rolling update works (refer to *Figure 5.29*):'
  prefs: []
  type: TYPE_NORMAL
- en: Using the revised configuration, it creates a new deployment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Increases/decreases the number of replicas on the new and old controllers until
    the correct number is attained.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, the original deployment and associated pods will be deleted.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Here is a diagram of rolling updates'' functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.28 – Rolling updates to the sample application ](img/Figure_5.29_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.28 – Rolling updates to the sample application
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two additional options when utilizing the `RollingUpdate` approach
    to fine-tune the update process, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`maxSurge`: During an update, the maximum number of pods that can be created
    is greater than the desired number of pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`maxUnavailable`: The number of pods that may become unavailable during the
    upgrade procedure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We've set `maxSurge` to `0` and `maxUnavailable` to `1` in the sample application
    deployment, indicating that the maximum number of new pods that can be generated
    at a time is 0 and the maximum number of old pods that can be destroyed at a time
    is `1`. This strategy indicates that as new pods are created, old pods will be
    destroyed one by one.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on your goal, there are various sorts of deployment tactics you might
    want to use. For example, you may need to deploy modifications to a specific environment
    for more testing, or to a group of users/customers, or you may wish to do user
    testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Various Kubernetes deployment strategies are outlined here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Recreate**: In this very simple deployment strategy, all old pods are killed
    at the same time and replaced with new ones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Blue/green deployments**: In a blue/green deployment strategy, the old (green)
    and new (blue) versions of the application are deployed at the same time. When
    both are launched, consumers may only access the green deployment; the blue deployment
    is available to your **quality assurance** (**QA**) team for test automation on
    a different service or via direct port forwarding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Canary deployments**: Canary deployments are like blue/green deployments,
    except they are more controlled and use a *progressive delivery* phased-in technique.
    Canary encompasses a variety of methods, including dark launches and A/B testing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dark deployments or A/B deployments**: Another variation on a canary deployment
    is a dark deployment. The distinction between dark and canary deployments is that
    dark deployments deal with features on the frontend rather than the backend, as
    canaries do.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To summarize, we've launched a sample application as well as performed rolling
    updates on the one we've already deployed. We will concentrate on how to scale
    the application in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling the application deployment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Changing the number of replicas in a Deployment allows scaling the deployments.
    When a Deployment is scaled out, new pods will be created and scheduled to Nodes
    with available resources. The number of pods will be scaled up to the new target
    state. Autoscaling pods is also supported by Kubernetes. It is also possible to
    scale to zero, which will terminate all pods in a given Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Running many instances of an application needs a method for distributing traffic
    among them. A built-in load balancer in a `Services` object distributes network
    traffic across all pods in an exposed Deployment. Endpoints will be used to continuously
    monitor the operating pods, ensuring that traffic is only directed to those that
    are available.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll use a new YAML file to increase the number of pods in the Deployment
    in the following example. The replicas are set to `4` in this YAML file, indicating
    that the Deployment should include four pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command will deploy the preceding updated application deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command output shows that the command was successfully run and
    that the Deployment has been configured:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.29 – Scaling sample application deployment ](img/Figure_5.30_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.29 – Scaling sample application deployment
  prefs: []
  type: TYPE_NORMAL
- en: 'The following command execution output confirms that there is no error in the
    deployment, and in the next steps, we can verify that the Deployment has four
    pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command output shows that the command was successfully run and
    the deployment has created new pods and scheduled to Nodes with available resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.30 – New pods have been created post scaling ](img/Figure_5.31_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.30 – New pods have been created post scaling
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a diagram of scaling functionality:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.31 – Application deployment scaling ](img/Figure_5.32_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.31 – Application deployment scaling
  prefs: []
  type: TYPE_NORMAL
- en: 'Another option is to use the command line (without editing the YAML file).
    Let''s say we want to increase the number of nginx deployments to five. To do
    so, run the `kubectl scale` command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Those pods can also be scaled down in the same way they were scaled up. You
    can alter `replicas:` in the YAML file.
  prefs: []
  type: TYPE_NORMAL
- en: 'And with the `kubectl` command, you could scale down from `5` to `4`, like
    so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'To view how the pods are distributed across the Nodes, use the following command
    to check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'The following command execution output indicates that there are two pods running
    on the control plane node and two of them are running on `worker1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.32 – Pod distribution across Nodes ](img/Figure_5.33_B18115.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.32 – Pod distribution across Nodes
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we have demonstrated how to get MicroK8s functionality on a
    Raspberry Pi and have joined multiple Pis to form a production-grade Kubernetes
    cluster. MicroK8s is being presently employed in a range of contexts, ranging
    from a single-node installation on a developer's desktop to the support of compute-intensive
    AI and ML workloads.
  prefs: []
  type: TYPE_NORMAL
- en: MicroK8s is well suited for the edge, IoT, and appliances because of its minimal-resource
    footprint and support for both **Advanced RISC Machine** (**ARM**) and Intel architectures.
    On Raspberry Pis, MicroK8s is a common choice. We will be looking at implementation
    aspects of common edge computing applications in the upcoming chapters. In the
    next section, we will touch upon some best practices for implementing Kubernetes
    for your production-grade Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Guidelines on multi-node cluster configuration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will go through some best practices for creating a scalable,
    secure, and highly optimized Kubernetes cluster model.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster-level configuration/settings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can define levels of abstraction, such as pods and services, with Kubernetes
    so that you don''t have to worry about where your applications are running or
    whether they have enough resources to run efficiently. However, you must monitor
    your applications, the containers that run them, and even Kubernetes itself to
    maintain optimal performance. In this section, we will cover some best practices
    to follow for setting up and operating your Kubernetes clusters. These are outlined
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Use the latest version**: Kubernetes offers new features, bug patches, and
    platform upgrades with its regular version updates. You should always utilize
    the most recent Kubernetes version on your cluster as a rule of thumb.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When multiple teams are attempting to use the same cluster resources at the
    same time, namespaces can be used to achieve team-level isolation. Using Namespaces
    effectively allows you to construct numerous logical cluster divisions, enabling
    you to allocate different virtual resources to different teams.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use smaller container images whenever possible to speed up your builds. Due
    to a smaller attack surface, smaller images are likewise less vulnerable to attack
    vectors.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `kube-bench` is one of the tools that examine whether Kubernetes is deployed
    securely using the checks provided in the *CIS Kubernetes Benchmark*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alpha and beta Kubernetes features are still in development and may contain
    flaws or problems that lead to security flaws. Always weigh the benefits of an
    alpha or beta feature against the danger posed to your security posture. When
    in doubt, turn off any features that you don't utilize.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use an OpenID Connect authentication mechanism for your Kubernetes cluster and
    other development tools using **single sign-on** (**SSO**), such as Google Identity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Review retention and archival strategy for logs—ideally, 30-45 days of historical
    logs should be retained.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Logs should be collected from all Nodes, control planes, and auditing:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a. Nodes (kubelet, container runtime)
  prefs: []
  type: TYPE_NORMAL
- en: b. Control plane (API server, scheduler, controller manager)
  prefs: []
  type: TYPE_NORMAL
- en: c. Kubernetes auditing (all requests to the API server)
  prefs: []
  type: TYPE_NORMAL
- en: Use a log aggregation tool such as the **Amazon Web Services** (**AWS**) CloudWatch,
    **Elasticsearch, Fluentd, and Kibana** (**EFK**) stack, Datadog, Sumo Logic, Sysdig,
    **Google Cloud Platform** (**GCP**) Stackdriver, or Azure Monitor.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Control plane components should be monitored to assist in any discovery of issues/threats
    within the cluster and reduce latency. It's better to use automatic monitoring
    tools rather than manually managing alerts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To summarize, we have covered some of the best practices that need to be followed
    for setting up and operating your Kubernetes clusters. In the next section, we
    will look at best practices related to container life cycle management.
  prefs: []
  type: TYPE_NORMAL
- en: Container life cycle management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes and the Kubernetes architecture effectively automate the life cycle
    management of application containers, but they can be difficult to set up and
    administer. In this section, we will check on best practices and how to implement
    them in your clusters quickly and easily:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Containers with no limits might cause resource conflict with other containers
    and inefficient computational resource consumption. Use `ResourceQuota` and `LimitRange`
    for restricting resource utilization:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a. You can use `ResourceQuotas` to set a limit on the total amount of resources
    consumed by all containers in a Namespace. Other Kubernetes objects, such as the
    number of pods in the current namespace, can also have quotas imposed.
  prefs: []
  type: TYPE_NORMAL
- en: b. If you're concerned that someone might use your cluster to produce a large
    number of ConfigMaps, you can use `LimitRange` to prevent this.
  prefs: []
  type: TYPE_NORMAL
- en: Use Kubernetes *pod security policies* for enforcing security configurations—for
    example, to access the host filesystem.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While there are some circumstances where privileged containers are required,
    allowing your containers to do so is, in general, a security concern. If there
    are no specific use cases, disable privileged containers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Go for rootless containers. If a user succeeds to break out of a container-based
    application running as root, they may be able to use the same root user to get
    access to the host.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To avoid escalating privileges using `setuid` or `setgid` binaries, run your
    container with privilege escalation disabled.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Enable **network policies** so that it establishes firewalls between the pods
    on your cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use tools such as **Open Policy Agent** (**OPA**) to apply policies, such as
    using only approved base images that can be deployed in your cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To recap, we've gone through some best practices for automating container life
    cycle management. We'll look at the guidelines for deploying and sharing HA applications
    with Kubernetes in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying and sharing HA applications
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you may be aware, deploying a basic application in Kubernetes is a piece
    of cake. Trying to make your application as available and fault-tolerant as feasible,
    on the other hand, implies a slew of challenges. In this section, we list some
    of the guidelines for deploying and sharing HA applications in Kubernetes, as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: All containers should have `readiness probes` set up. The kubelet agent assumes
    that the application is ready to receive traffic as soon as the container starts
    if you don't set the readiness probe.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Liveness and readiness* probes shouldn''t point to the same endpoint because
    when the application indicates that it is not ready or live, the kubelet agent
    detaches and deletes the container from the service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running many or more than one instance of your pods ensures that eliminating
    a single pod will not result in downtime. Also, consider using a Deployment, DaemonSet,
    ReplicaSet, or StatefulSet to deploy your pod instead of running pods individually.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Anti-affinity rules* should be applied to your Deployments so that pods are
    distributed over all Nodes in your cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can set a *pod disruption budget* to safeguard Deployments against unforeseen
    events that could bring down many pods at the same time. If the final state for
    that Deployment results in fewer than five pods, Kubernetes will prevent the drain
    event.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the resources property of `containerSpec` to specify resource constraints
    that limit how much CPU and memory your containers can consume. These settings
    are taken into consideration by the scheduler to determine which node is most
    suited for the current pod.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All resources should have technical, business, and security labels defined.
    They should be applied to all resources in your cluster, including pods, services,
    Ingress manifests, and endpoints.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers should not store any state in their local filesystem. Any persistent
    data should instead be saved in a central location outside of the pods—for instance,
    in a clustered PersistentVolume, or—even better—in a storage system outside of
    your cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ConfigMaps should be used to manage all configurations outside of the application
    code. ConfigMaps should only be used to save non-sensitive settings. For sensitive
    information, use a secret resource (such as credentials). Instead of being passed
    in as environment variables, secret resources should be mounted as volumes in
    containers. To summarize, we have looked at best practices for creating a scalable,
    secure, and highly optimized Kubernetes cluster model.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to set up a MicroK8s Raspberry Pi multi-node
    cluster, deployed a sample application, and executed rolling updates on the deployed
    application. We also discovered ways to scale the deployed application. We also
    found that, while Kubernetes allows us to define levels of abstraction such as
    pods and services to help with application deployments, we must monitor the applications,
    containers, clusters, and Kubernetes itself to ensure optimal performance. In
    this context, we learned about several recommended practices for building a scalable,
    secure, and highly optimized Kubernetes cluster model.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at how to configure container network connectivity
    for your Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
