- en: '5'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GitOps at Scale and Multitenancy
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter delves into advanced **GitOps** applications, focusing on scaling
    and **multitenancy** within Kubernetes environments. It’s tailored for those with
    a foundational understanding of tools such as **Argo CD** and who are looking
    to expand their knowledge in more complex scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll start by discussing strategies to build scalable cluster infrastructures
    using GitOps. This includes designing Kubernetes clusters that can adapt to increasing
    demands, all managed through GitOps methodologies. A significant part of this
    discussion involves deploying applications across multiple clusters efficiently,
    focusing on scalability and customization.
  prefs: []
  type: TYPE_NORMAL
- en: A critical aspect we’ll address is enforcing multitenancy in shared Kubernetes
    environments. We’ll explore how to achieve this using GitOps tools such as Argo
    CD, adhering to their operational philosophies. Complementary to this, we’ll introduce
    tools such as **vCluster** that simplify multitenancy enforcement while maintaining
    GitOps principles.
  prefs: []
  type: TYPE_NORMAL
- en: The emphasis throughout this chapter is on concepts over tools. While tools
    may evolve, the underlying principles remain constant, providing a stable foundation
    for understanding these technologies.
  prefs: []
  type: TYPE_NORMAL
- en: We’ll also cover the implementation of a lightweight **internal developer platform**
    (**IDP**) to facilitate the **deployment** of third-party tools through **Kubernetes
    Service Catalog** (**KSC**). This approach simplifies application management within
    Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Real-world insights form a significant part of this chapter, drawing from experiences
    and lessons learned in diverse project environments. This practical perspective
    is invaluable for understanding the real-world application of these strategies.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter, which is aimed at **intermediate learners**, won’t delve into
    the setup or basic operations of Argo CD. Instead, it will focus on their application
    in complex, real-world scenarios, demonstrating the practical use of the most
    suitable tools for each case. The goal is to equip you with a comprehensive understanding
    of scaling and managing multitenancy in Kubernetes using GitOps, enriched with
    real-world applications and insights, by staying focused on the approaches and
    not the tools.
  prefs: []
  type: TYPE_NORMAL
- en: The chapter is tough, but I hope you’ll have learned a lot by the time you finish
    it. I’ve tried to share all the insights from projects in a compact way with you.
    This chapter can be logically divided into two sections. The first section covers
    approaches to using GitOps at scale and the necessary setup via KSC. The second
    section, starting on page 45, focuses on multitenancy with GitOps to get the most
    out of the setup.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will cover the following main topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the App of Apps approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding multi-cluster management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding effective Git repository strategies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building a service catalog for Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring native multitenancy with Argo CD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exploring multitenancy with vCluster and Argo CD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Due to the limited space available, many examples have been shortened or are
    incomplete. Therefore, we have a repository with complete examples. This follows
    the `chapter05`/`section` pattern – that is, `chapter05`/`chapter-5-building-a-service-catalog-for-kubernetes`.
    For all the code examples discussed, along with additional resources, please refer
    to the `Chapter05` folder in the book’s GitHub repository at [https://github.com/PacktPublishing/Implementing-GitOps-with-Kubernetes](https://github.com/PacktPublishing/Implementing-GitOps-with-Kubernetes).
  prefs: []
  type: TYPE_NORMAL
- en: Traditional CI/CD versus GitOps CD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The main difference between traditional CI/CD and Argo CD is in how deployments
    are handled
  prefs: []
  type: TYPE_NORMAL
- en: ':'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Traditional CI/CD versus GitOps CD](img/B22100_05_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.1 – Traditional CI/CD versus GitOps CD
  prefs: []
  type: TYPE_NORMAL
- en: Traditional CI/CD follows a workflow where changes are automatically integrated,
    tested, and deployed, while Argo CD uses a synchronization mechanism to ensure
    the actual state matches the desired state in the Git repository. Argo CD relies
    on a CI step, meaning any change must go through a CI process before Argo CD can
    detect and act on it. This ensures that only verified changes are deployed. Unlike
    CI/CD, which might require manual interventions that can lead to discrepancies,
    Argo CD continuously monitors and synchronizes the system state with the Git repository,
    reducing the risk of drifts and maintaining consistency.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we’ll look at the difference between platform engineering
    and IDPs.
  prefs: []
  type: TYPE_NORMAL
- en: Platform engineering versus IDPs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In my opinion, a distinction between **internal developer platforms** (**IDPs**)
    and **internal developer portals** (**IDPOs**) is becoming increasingly relevant
    and is already a topic of much debate. To clarify the different approaches, here’s
    how I differentiate these terms:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Platform engineering**: This is the traditional approach where a dedicated
    team owns, operates, and continuously improves the Kubernetes platform itself.
    Their focus is on the underlying infrastructure, ensuring its stability, scalability,
    and security. Developers working on applications typically consume this platform
    and concentrate solely on their software or third-party tools that aren’t offered
    by the platform team. This is a common approach in many projects today.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Internal developer platform (IDP)**: This approach introduces an IDP solution,
    such as backstage.io from Spotify. The IDP team is responsible for providing and
    maintaining the IDP itself, which includes extensive documentation, building blocks,
    and templates for developers and acts like a portal (IDPO) for developers. Developers
    can then leverage these resources to self-deploy their applications within a defined
    Kubernetes environment. This allows developers to have some influence on the content
    and functionality of the IDP through contributions or requests. The engineering
    focus of the platform team shifts from core Kubernetes operations to managing
    and evolving the IDP. However, developers are still responsible for the day-to-day
    operations of their deployed Kubernetes environments, including updates and troubleshooting.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s explore the App of Apps approach.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the App of Apps approach
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In managing multiple applications, there are primarily two established strategies:
    the **App of Apps** approach and **ApplicationSets**. This section will address
    several key questions:'
  prefs: []
  type: TYPE_NORMAL
- en: What challenges does the App of Apps approach overcome?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In which situations is the App of Apps approach most beneficial?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How does the App of Apps approach enhance GitOps practices?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An *application* in this context refers to the Git repository and folder where
    manifests, which are essential definitions that allow your app to run in Kubernetes,
    are stored. Argo CD is versatile as it supports raw **YAML** manifests, custom
    configuration management, and popular tools such as **Kustomize**, **Helm**, and
    **Jsonnet**.
  prefs: []
  type: TYPE_NORMAL
- en: But what about scenarios where we must deploy multiple applications? How should
    we manage these manifests? Each application being deployed requires an application
    definition. However, when these applications are a collection of related entities,
    it would be beneficial if Argo CD could recognize this relationship. To address
    this need, the Argo community developed the App of Apps approach. Essentially,
    this approach allows a root Argo CD *application* to be defined, which, in turn,
    defines and synchronizes multiple child applications. This method streamlines
    the management process, especially in complex deployments, by leveraging a hierarchical
    folder structure.
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 5**.2* illustrates an instance of the App of Apps approach. In this
    example, a single Argo CD *application* corresponds to just one specific web application:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – The App of Apps approach](img/B22100_05_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.2 – The App of Apps approach
  prefs: []
  type: TYPE_NORMAL
- en: 'Examining the application manifest reveals key details:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, `path` is set to directly point to the specific application. Next, let’s
    explore the App of Apps approach shown in *Figure 5**.3* for a more comprehensive
    understanding:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – App of Apps](img/B22100_05_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.3 – App of Apps
  prefs: []
  type: TYPE_NORMAL
- en: 'Rather than directing toward a singular application manifest, as it did previously,
    the root app now references a specific folder within a Git repository. This folder
    contains all the individual application manifests that define and facilitate the
    creation and deployment of each application. By adopting this approach, it’s possible
    to declare all your applications within a unified YAML manifest. The following
    example demonstrates this pattern for enhanced comprehension:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'In the provided definition, the `path` attribute instructs Argo CD to target
    a specific directory – in this case, named `simple-webapps` – located within the
    repository. This directory contains Kubernetes manifests that define the applications,
    as well as supporting various formats such as Helm, Kustomize, or plain YAML files.
    In the provided configuration, there are two notable attributes worth highlighting:
    `selfHeal: true` and `directory.recurse: true`. The `selfHeal` feature ensures
    automatic updates of the child applications in response to any changes detected,
    maintaining consistent deployment states. Additionally, the `recurse` setting
    enables the iteration through the `webapps` folders, facilitating the deployment
    of all applications contained within.'
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the App of Apps approach enables you to administer your *application*
    resources by simply updating your manifests in the Git repository – adding or
    removing application resources as needed. This approach reduces reliance on direct
    interactions with Argo CD *applications* through the web UI or **CLI**.
  prefs: []
  type: TYPE_NORMAL
- en: Use cases of App of Apps combined with examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The App of Apps approach in Argo CD is highly advantageous for managing multiple
    applications as a single entity while ensuring their isolation during deployment.
    This is particularly useful in scenarios such as cluster bootstrapping and managing
    Argo CD applications without relying on the CLI or UI. Let’s explore these use
    cases with relevant examples:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Cluster bootstrapping**: Imagine that you have a standard set of applications
    that need to be installed in every new Kubernetes cluster. Rather than deploying
    each application individually, you can group them into a single “root” application.
    This simplifies the process, allowing you to deploy the entire set of applications
    simultaneously, enhancing efficiency and consistency across different deployments.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example for developers and service providers**: Let’s say you’re developing
    or providing services that involve deploying a custom yet similar stack for each
    deployment, such as the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Frontend
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Backend for frontend
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Database
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The App of Apps approach allows you to encapsulate these components into a single
    deployment entity, streamlining the process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Managing Argo CD applications without the CLI or GUI**: You can modify an
    existing root application using Git operations, such as adding new folders to
    the paths it monitors. This capability lets Argo CD automatically deploy new applications
    or update existing ones without needing to interact through the CLI or web UI,
    aligning with GitOps principles of version control and auditability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Example for platform engineers**: As a platform engineer, let’s say you’re
    providing a similar stack on Kubernetes for each customer, such as the following:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Ingress-Controller**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cert-Manager**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**External-DNS**'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The App of Apps approach is beneficial here as it allows you to manage these
    components effectively, ensuring that each customer’s environment is consistently
    configured with the necessary tools.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In both use cases, the App of Apps approach facilitates a more streamlined,
    efficient, and consistent deployment process, whether you’re dealing with different
    client requirements as a service provider or ensuring uniformity across various
    Kubernetes clusters as a platform engineer.
  prefs: []
  type: TYPE_NORMAL
- en: The ApplicationSets approach
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you’ll discover the process of creating, updating, managing,
    and removing numerous Argo CD *applications* through the use of an *ApplicationSet*
    [*1*] controller.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will delve into the concept of an *ApplicationSet* and address key questions
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: What exactly constitutes an *ApplicationSet*?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the functionalities and advantages of an *ApplicationSet*?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Why is a generator necessary, and what varieties exist?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the Argo CD framework, an *ApplicationSet* [*2*] significantly enhances the
    GitOps strategy for **continuous deployment** (**CD**) within Kubernetes. This
    tool adeptly handles the complexity involved in managing a variety of Kubernetes
    manifests, such as deployments, services, secrets, and configuration files, all
    within a Git repository. Unlike the Argo CD *application* resource, which is limited
    to deploying resources from a single git repository to one cluster or namespace,
    the ApplicationSet extends this functionality. It utilizes templated automation
    to concurrently create, modify, and oversee multiple Argo CD applications, thereby
    broadening its operational scope to encompass several clusters and namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: The ApplicationSet controller, which is installed in the same namespace as Argo
    CD, plays a crucial role. It generates a multitude of Argo CD applications from
    the ApplicationSet’s **custom resource** (**CR**). This arrangement ensures that
    your Argo CD applications are in sync with your specified resources, effectively
    transforming the ApplicationSet into one or more Argo CD applications, thus enhancing
    overall deployment efficiency and scalability.
  prefs: []
  type: TYPE_NORMAL
- en: '*Generate* refers to the process employed by the controller using various **generators**,
    but what exactly are these generators? Generators in the ApplicationSet resource
    play a crucial role by creating parameters that are incorporated into the template
    fields, ultimately generating Argo CD Applications. For a practical example of
    this process, refer to this chapter’s introduction. The functionality of generators
    is determined by their data sources. For instance, the List generator derives
    parameters from a predefined list, the Cluster generator utilizes the Argo CD
    cluster list, and the Git generator gets sources from files or directories in
    a Git repository.'
  prefs: []
  type: TYPE_NORMAL
- en: There are numerous generators for different use cases and roles within ApplicationSets.
    For instance, there’s the Cluster generator, which is ideal for **platform engineers**
    to scale their platforms, and the Pull Request generator, which allows developers
    to deploy features for QA through GitOps. Additionally, the **Matrix generator**
    allows you to combine up to two generators to meet more specific requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'We’ll be utilizing the Cluster generator to implement GitOps at scale. Moving
    beyond theory, let’s dive into its practical application. We’ll start with a single
    cluster, tagging it with a label such as *env=prod*. This can be done in the Argo
    CD UI by navigating to **Settings** | **Clusters** | **Select In-Cluster** |**Edit**
    | **Add Labels**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.4 – Adding labels](img/B22100_05_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.4 – Adding labels
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, create an `ApplicationSet` manifest, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Here, we’re employing the Cluster generator, which is designed to deploy our
    `simple-webapp` across various Kubernetes clusters. By using the `env=prod` selector,
    the *ApplicationController* will create several applications corresponding to
    the count of your clusters. Each application’s name will be modified to include
    the cluster name – for example, `in-cluster-simple-webapp`.
  prefs: []
  type: TYPE_NORMAL
- en: 'To apply `ApplicationSet`, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To view `ApplicationSet`, run the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'You can also view a templated application like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'When you check the Argo CD UI, you won’t find the ApplicationSet directly,
    but you will see the templated application, named `in-cluster-simple-webapp`.
    This application is managed by the application controller in the following manner:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.5 – The application templated through an ApplicationSet, managed
    by the application controller, and informed over the Cluster generator](img/B22100_05_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.5 – The application templated through an ApplicationSet, managed by
    the application controller, and informed over the Cluster generator
  prefs: []
  type: TYPE_NORMAL
- en: The templated application is visible through the `ApplicationSet` manifest,
    where the application controller uses the Cluster generator to set the necessary
    parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Which approach should be used?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In most projects I’ve been involved in, teams prefer using individual applications
    and ApplicationSets over the App of Apps approach. From a platform engineer’s
    [*3*] perspective, for creating scalable infrastructure with GitOps, the ApplicationSets
    approach seems to be the most logical choice.
  prefs: []
  type: TYPE_NORMAL
- en: 'The App of Apps pattern in Argo CD is suitable for the following aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Bootstrapping multiple applications**: Efficiently deploy numerous applications
    simultaneously.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing applications as a single unit**: Simplify the management of multiple
    applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhancing the deployment workflow**: Streamline the process of deploying
    and updating applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ApplicationSets can be particularly beneficial in the following scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Creating flexible deployment strategies for diverse environments**: Deploy
    to multiple Kubernetes clusters, to different namespaces in different clusters,
    or to different namespaces on a single cluster (developer, DevOps, and platform
    engineer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing Applications in Monorepos**: Deploy from different Git repositories,
    SCM providers, or folders (developer, DevOps, platform engineer).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enabling self-service for multi-tenant clusters**: ApplicationSets can facilitate
    a self-service model, particularly with the Pull Request generator. This allows
    developers to deploy applications in multi-tenant clusters with greater autonomy,
    without needing cluster-level permissions (collaboration between developers and
    platform engineers).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deploying cluster add-ons across multiple clusters**: Using the Cluster generator,
    you can target add-ons to specific clusters managed within Argo CD, which is useful
    for large-scale, multi-cluster environments (platform engineers, **Site Reliability
    Engineers** (**SREs**) and DevSecOps engineering).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contrasting this with the App of Apps approach, which is more suited for managing
    a collection of related applications within a single repository or cluster, ApplicationSets
    offer more flexibility and scalability, especially in environments with diverse
    deployment needs. They allow for more granular and distributed control, aligning
    with complex infrastructure requirements and multi-cluster strategies.
  prefs: []
  type: TYPE_NORMAL
- en: Later, we will adopt an ApplicationSet to develop a scalable model for an IDP,
    referred to as KSC. This platform aims to efficiently manage a large number of
    Kubernetes clusters while ensuring up-to-date security measures are maintained.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we’ll take a deep dive to understand what multi-cluster management means
    in the context of GitOps with Argo CD and what possibilities it opens.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding multi-cluster management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we’ll delve into our experiences with two different approaches
    to managing multi-cluster environments within the GitOps framework. Our focus
    is not on the tools themselves, but rather on the overarching strategy of orchestrating
    and managing these clusters as though they were a singular platform. Through this
    exploration, we aim to impart a deeper understanding of these methodologies, emphasizing
    that the key lies in effective orchestration rather than a comparison of specific
    tools. We’ll discuss two distinct concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**One cockpit to rule them all**: This concept emphasizes centralized management
    and orchestration of multiple clusters as a unified platform'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**One cockpit – diverse fleet management**: This concept focuses on managing
    a diverse range of Argo CD clusters from a single control point while considering
    security aspects of inter-cluster communication'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In terms of tool selection, our experience suggests that Argo CD, with its support
    for clusters, ApplicationSets, and generators, is better suited for scaling with
    GitOps in multi-cluster environments compared to Flux, which lacks a dedicated
    multi-cluster management concept. This differentiation becomes clearer in contexts
    where management extends beyond dedicated clusters to scenarios such as **vCluster**
    approaches within a host cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some additional considerations for multi-cluster management in a GitOps
    framework:'
  prefs: []
  type: TYPE_NORMAL
- en: '**High availability and disaster recovery**: This includes deploying across
    multiple regions or even using multiple providers to ensure robustness and resilience'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Existing expertise**: The level of knowledge in Kubernetes, the cloud, or
    GitOps within the organization plays a critical role'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Budget constraints**: The costs involved in multi-cluster management should
    not exceed a predetermined amount'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Compliance and regulatory requirements**: Ensuring adherence to industry
    standards and legal regulations in different regions or sectors'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network infrastructure and latency**: Optimizing for network performance
    and reducing latency, something that’s especially important in geographically
    dispersed clusters'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cloud or service provider implementation**: For example, AKS works with Flux
    CD for its GitOps implementation, while OpenShift uses Argo CD for GitOps deployments'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overall, the choice between Argo CD and Flux CD hinges on their respective capabilities
    in orchestrating and managing multi-cluster environments and specific use case
    requirements.
  prefs: []
  type: TYPE_NORMAL
- en: One cockpit to rule them all
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this approach, there is a single Argo CD instance that’s shared by both
    developers and platform engineers (*Figure 5**.6*). This shared instance allows
    platform engineers to offer centralized management functions and comprehensive
    control over various Kubernetes clusters. They manage and monitor all deployments,
    ensuring developers have access to the required resources while upholding company
    policies and security standards. This method promotes collaboration and provides
    a unified view of all clusters, effectively reducing complexity in large, distributed
    organizations:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.6 – One cockpit to rule them all – with a common Argo CD instance](img/B22100_05_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5.6 – One cockpit to rule them all – with a common Argo CD instance
  prefs: []
  type: TYPE_NORMAL
- en: 'In the *one cockpit to rule them all* approach for GitOps with Argo CD, the
    following are some crucial considerations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Developer access**: Determining developer access to the Argo CD UI involves
    establishing **role-based access control** (**RBAC**) associated with groups,
    projects, and roles, potentially including Dex and OIDC provider integration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Project access control**: Limiting team access to specific projects to prevent
    unauthorized deployments across clusters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resources allocation**: Are savings being made in the right areas? This question
    prompts a critical evaluation of resource allocation, questioning whether cost
    savings are effectively targeted in areas that maximize efficiency and overall
    value.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Version updates**: Coordinating updates for Argo CD across teams on a shared
    instance used by multiple teams is crucial. This coordination ensures version
    compatibility and prevents issues related to API deprecations, maintaining a stable
    and functional GitOps environment for all teams.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with multiple teams on this approach brings a multitude of questions
    and considerations that need to be addressed, emphasizing the complexity and planning
    required for effective implementation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some points based on our experience with this approach:'
  prefs: []
  type: TYPE_NORMAL
- en: Shared Argo CD usage often led to increased system load, occasionally causing
    outages
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Integration of features such as Argo CD’s PR-Generator added complexity
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It necessitated robust multitenancy frameworks and tools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Argo CD, as the sole point of control, introduced a heightened risk of system
    failure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The increase in teams significantly raised the requirements for communication
    and system maintenance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While there were savings in hardware resources, these were counterbalanced by
    greater demands on human resources for management and coordination
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We employ this approach for shared clusters to facilitate cold starts, save
    money and resources, provide a learning platform, and offer shared services such
    as documentation and runners. A shared cluster is more relevant for incubating
    projects, and when a project is mature or needs to head for production, it should
    be moved onto its own cluster.
  prefs: []
  type: TYPE_NORMAL
- en: One cockpit – multiple fleet and commander concept
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this concept, one Argo CD instance will be used by the platform team to
    deploy and manage the whole infrastructure that’s needed by developer teams. The
    platform team also deploys dedicated Argo CD instances with a **dedicated UI**
    for every team. The focus is the same, but it’s more so about the orchestration
    process and managing those clusters as if they were a single platform. The developer
    will get their dedicated Argo CD instance:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.7: One cockpit – diverse fleet management with dedicated Argo CD
    instances per cluster](img/B22100_05_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.7: One cockpit – diverse fleet management with dedicated Argo CD instances
    per cluster'
  prefs: []
  type: TYPE_NORMAL
- en: 'In contrast to the *one cockpit to rule them all* approach, this approach involves
    the following aspects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Dedicated Argo CD instances**: Each cluster is managed by its own Argo CD
    instance, enhancing individual cluster autonomy and reducing risks associated
    with a single point of failure.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Autonomous project management**: Each team manages projects within their
    designated clusters, allowing for greater control and customization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource allocation**: Instead of leveraging a shared Argo CD instance, each
    cluster operates its own stack. While this may offer focused resource management
    within individual Argo CD instances per cluster, it potentially leads to higher
    overall resource consumption.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Version control autonomy**: Each team controls the version updates of their
    Argo CD instance, ensuring smooth operation and compatibility within their cluster
    environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are some insights from our experience with the *one cockpit – diverse
    fleet* *management* approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Increased autonomy**: Dedicated resources and UI access grant more **freedom**,
    **flexibility**, and **responsibility**. This setup allows for self-service and
    extended control for developers, enabling them to focus on development.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Ease of onboarding**: This model simplifies GitOps adoption, making it suitable
    for both newcomers and experienced teams. Onboarding new colleagues requires less
    time with this approach.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource consumption**: While offering clear team separation, this approach
    can lead to greater resource usage.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Enhanced security**: The compromise of one Argo CD instance doesn’t impact
    others, increasing overall security.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Platform team focus**: Platform teams concentrate on scaling and engineering
    services for a scalable, self-service approach. Less time is needed for interactions
    with development teams and for creating and hardening multitenancy aspects related
    to the shared Argo CD instance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resilience and isolation**: This approach enhances resilience and isolation
    for each project or development team. It eliminates issues with noisy neighbors,
    and upgrades to Kubernetes or infrastructure by other teams or projects do not
    affect individual teams, ensuring smoother operations and reduced disruptions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This approach is adopted for handling **critical workloads**, ensuring strict
    tenant separation, enhancing developers’ self-service capabilities, and bolstering
    security in compliance with stringent requirements for security, governance, and
    compliance. In the realm of GitOps, which is central to continuously delivering
    software into clusters, this approach becomes even more crucial when scaling,
    particularly from a security perspective in DevOps practices.
  prefs: []
  type: TYPE_NORMAL
- en: In managing multi-cluster environments at scale with GitOps, the emphasis extends
    beyond just overseeing dedicated Kubernetes clusters. It involves leveraging Argo
    CD to address varied needs and deploy diverse workloads, including both customer
    applications and infrastructure components, while maintaining security compliance
    across different clusters. This approach aims to bridge the gap between developers
    and platform engineers, fostering scalability and boosting productivity in both
    domains.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is another gap with GitOps that relates to the best way to set
    up a staging concept. This will be explained in more detail in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding effective Git repository strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Understanding how to effectively promote applications between stages in a GitOps
    framework, especially at scale, is a crucial challenge for both developers and
    platform engineers. Deploying an application to various environments involves
    navigating complexities beyond a single deployment scenario. With Argo CD, the
    process becomes more manageable, allowing deployment across multiple clusters
    without needing multiple CD pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section delves into various approaches for managing environments: environment
    branches, environment per Git, and folders for environments. Each has its pros
    and cons, and the choice largely depends on the specific needs of the project
    and the team’s expertise. Companies such as **Codefresh** [*4*] have developed
    solutions to facilitate stage propagation with Argo CD. However, this book focuses
    more on understanding these approaches rather than specific tools, guiding you
    to choose the most suitable strategy for your environment.'
  prefs: []
  type: TYPE_NORMAL
- en: Environment branches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The environment-per-branch [*4*] approach in GitOps, which involves using branches
    to represent different environments such as staging or production, is often considered
    an anti-pattern. This approach can complicate pull requests and merges between
    branches, create configuration drifts, and increase maintenance challenges with
    a large number of environments. It also contrasts with the Kubernetes ecosystem
    and is generally better suited for legacy applications. In GitOps, it’s recommended
    to separate application source code and environment configuration into different
    repositories, avoiding the branch-per-environment model. For deployment promotions,
    Git merges can be problematic due to conflicts and unintended changes, making
    promotion management more complex than it appears.
  prefs: []
  type: TYPE_NORMAL
- en: Advantages of the environment-per-branch approach include familiarity for many
    developers and the theoretical simplicity of promoting releases through git merges.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the disadvantages are significant if you’re working with GitOps and
    Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Complex merges**: Promotion through Git merges can lead to conflicts and
    unintended changes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Configuration drift**: Different branches might lead to environment-specific
    code, causing configuration drift'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Maintenance challenges**: Managing a large number of branches can become
    unwieldy'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dependent changes**: Difficulties arise in managing changes that have dependencies
    as not all commits can be cleanly cherry-picked'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let’s explore a straightforward deployment manifest as an illustrative
    example.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.8: How to propagate between stages](img/B22100_05_08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.8: How to propagate between stages'
  prefs: []
  type: TYPE_NORMAL
- en: This basic example illustrates the need to incorporate propagation logic in
    deployment manifests, ensuring that specific values, such as the number of replicas,
    are appropriately scaled for each stage according to its unique requirements.
    Using tools such as Helm or Kustomize with GitOps can present challenges as Helm
    uses different `values.yaml` files for stages, and Kustomize relies on overlays.
    Additionally, GitOps, based on the Kubernetes ecosystem, brings its own complexities
    that must be managed.
  prefs: []
  type: TYPE_NORMAL
- en: While this approach might suit legacy applications, it’s less ideal for modern
    Kubernetes environments. Branches can still be used for features and PRs for testing
    changes. However, you still need pipelines or workflows to commit the changes
    into Git. There is an option for writing back to Git outside of Argo CD. Tools
    like Argo CD and its PR-Generator can help manage these processes, but note that
    the PR generator is used to manifest Git content into the cluster, not the other
    way around.
  prefs: []
  type: TYPE_NORMAL
- en: Environment per Git
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The `main` but through pull requests and review workflows. For heightened security
    needs, organizations can use two git repositories: one for all production-related
    configurations and environments, and another for non-production elements, balancing
    security with a manageable number of repositories.'
  prefs: []
  type: TYPE_NORMAL
- en: Throughout my career, I’ve only encountered one team that adopted this approach
    specifically to prevent junior developers from accidentally accessing and exposing
    sensitive data.
  prefs: []
  type: TYPE_NORMAL
- en: Folders for environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adopting the **environment-per-folder** approach in GitOps and Kubernetes involves
    organizing different environment configurations within separate folders of a single
    Git repository. Each folder represents a specific environment such as **development**,
    **staging**, or **production**. This structure allows for clear separation and
    management of configurations for each environment, facilitating easier updates
    and maintenance. It streamlines the deployment process in Kubernetes, aligning
    with the principles of GitOps by keeping all environment configurations in a unified
    repository, ensuring consistency and traceability of changes.
  prefs: []
  type: TYPE_NORMAL
- en: To effectively create a folder structure for Kubernetes, start by understanding
    your business needs, such as developing highly available portals for different
    countries and their specific version requirements. Then, integrate business-related
    values, such as a company logo, into all environments. Also, consider dynamic
    customer-related values, such as customer status levels such as *silver*, *gold*,
    or *platinum*. This approach ensures that your Kubernetes settings, such as the
    minimum replica count, are aligned with both general and specific business requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the same example we did previously for the environment-per-folder
    approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.9: How to propagate between stages with folders for environments](img/B22100_05_09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.9: How to propagate between stages with folders for environments'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will showcase the ease of change propagation across environments using **Kustomize**.
    The first step involves setting up a specific folder structure to facilitate this
    process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.10: Example stages with folders for environments](img/B22100_05_10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.10: Example stages with folders for environments'
  prefs: []
  type: TYPE_NORMAL
- en: 'Exploring the file structure, the base directory contains configurations that
    are shared across all environments and typically undergoes infrequent changes.
    For simultaneous modifications across multiple environments, the `base` folder
    is the ideal location to manage these changes as it provides a centralized point
    for updates affecting various deployment settings:'
  prefs: []
  type: TYPE_NORMAL
- en: ./base/deployment.yaml
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'In this simple example, you can see that we cover all the points, such as the
    specific version, business-related values, and more from the previous description:'
  prefs: []
  type: TYPE_NORMAL
- en: './base/kustomization.yaml:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The `base` folder, also known as mixins or components, contains configurations
    common to different environments. Its contents are defined based on what you consider
    to be shared characteristics across your environments, a decision guided by your
    application’s specific needs. In our example, this folder includes configurations
    for the QA, staging, and production environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we’ll modify the base deployment by applying QA-specific configurations
    using a `patch.yaml` file. This approach allows us to customize the base setup
    for the QA environment without altering the common deployment settings:'
  prefs: []
  type: TYPE_NORMAL
- en: './overlays/qa/kustomization.yaml:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code shows how to overwrite the color in the base with a patch
    and thus allow a stage that’s specific for `qa` configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: './overlays/qa/patch.yaml:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The `kustomize` tool in Kubernetes allows you to customize your YAML configurations
    without having to modify the original files. It enables you to manage configuration
    variations in a more structured and scalable way by using patches, overlays, and
    other techniques to generate final configuration manifests.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can easily check the patching changes by executing the `kustomize` CLI
    tool from inside the `..chapter05/chapter-5-effective-git-repository-strategies/folders-for-environments`
    folder with the following command, which will show that the base overlay has been
    patched:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: In this stage, we will conduct tests on a specific version that incorporates
    business-related values. This version is intended to eventually become the new
    release for our “gold” customers in the future.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block shows how to reference the base, link it to the correct
    patch, and set a corresponding name prefix for all generated resources:'
  prefs: []
  type: TYPE_NORMAL
- en: './overlays/stage/kustomization.yaml:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: This process follows a similar patching method to what’s used for QA.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block shows how to overwrite the color in the base with
    a patch and thus allow a stage that’s specific for stage configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: './overlays/stage/patch.yaml:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The folder-based approach in GitOps offers a streamlined overview of all stages,
    eliminating the need to switch and compare across different branches. This simpler
    example, however, only scratches the surface. In practice, you would manage a
    variety of files and environment-specific configurations. The structure’s adaptability
    also allows for expansion into region-specific environments such as `qa-europe`
    or `qa-asia`, enabling customization based on unique regional requirements and
    business objectives.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following scenarios showcase how mighty this approach is:'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: This process is an external workflow to Argo CD that greatly simplifies deployment
    management by enabling easy comparison and propagation between stages.
  prefs: []
  type: TYPE_NORMAL
- en: '`diff` command in Linux compares two files or directories, showing the differences
    in their content in a line-by-line format.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can see the difference between the QA and staging environments by running
    `diff` `qa/patch.yaml stage/patch.yaml`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Use case 2**: Promote the application version from QA to staging:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The `cp` command in Linux is used to copy files and directories from one location
    to another.
  prefs: []
  type: TYPE_NORMAL
- en: First, copy the new version file with `cp` `qa/version.yaml staging-us/version.yaml`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Then, commit and push the changes to Git.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`base`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, again, commit and push the changes to Git.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At this point, you can remove additional config from QA, staging, and production
    because the config already exists in `base`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the final time, commit and push the changes to Git.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This approach greatly simplifies managing deployments by allowing you to easily
    compare stages. You can quickly compare differences by selecting files or folders,
    eliminating the need for complex Git operations such as **cherry-picking**. Changes
    between stages, such as moving from QA to staging, are efficiently handled by
    copying and pasting files. The flexibility of this method extends to different
    regions, countries, Kubernetes distributions, and tools, limited only by your
    own requirements. It offers a customizable and adaptable solution for a variety
    of deployment scenarios and can be automated with any workflow mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: What makes this approach particularly effective for Kubernetes and especially
    for scaling GitOps operations?
  prefs: []
  type: TYPE_NORMAL
- en: The suitability of this approach for Kubernetes and GitOps at scale is inherent
    in Kubernetes itself. Designed to be declarative and configuration-centric, Kubernetes
    seamlessly integrates with the structured, folder-based approach. This method
    supports GitOps’ focus on version control and traceability, which is crucial for
    managing configurations effectively in large-scale Kubernetes environments. The
    approach’s simplicity and organizational clarity make it an ideal match for the
    scalable and systematic deployment needs of Kubernetes and GitOps frameworks.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling with ApplicationSet generators
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We’ve already delved into the distinction between the App of Apps [*5*] approach
    and *ApplicationSets* in GitOps at scale with Kubernetes. Now, we will explore
    how to use *ApplicationSets* with generators to develop a streamlined developer
    platform, known as the KSC in this book. Specifically, we will demonstrate deploying
    an ingress controller across different clusters using *ApplicationSet*, each tailored
    with cluster-specific values. Our focus will be on using `kube-prometheus-stack`,
    which employs an **umbrella chart** with **subcharts**, such as Grafana.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here’s a brief overview of using an umbrella `ingress-nginx` `Chart.yaml` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: In the case of the `ingress-nginx` umbrella chart, using the same name for both
    the `ingress-nginx.controller.resources` – for specific overrides. This distinction
    is crucial for those unfamiliar with umbrella charts as many teams struggle with
    values not being applied as expected due to this naming overlap.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s understand why and which part allows us to build scalable deployments
    with Argo CD by looking at the following extract with `nginx-ingress-applicationset.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: You can find the complete example in this book’s GitHub repository via the name
    provided.
  prefs: []
  type: TYPE_NORMAL
- en: 'The concept of the generator, as previously explained, remains the same. The
    change lies in how the ApplicationController sources the umbrella chart (see **1**
    in *Figure. 5.11*), retrieves custom values for the specific target cluster (see
    **2** in *Figure. 5.11*), then uses Helm to template these values and deploys
    them to the target cluster (see **3** in *Figure. 5.11*). The following figure
    will further clarify the underlying processes, enhancing understanding of the
    operations taking place behind the scenes:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.11: Example stages with folders for environments](img/B22100_05_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.11: Example stages with folders for environments'
  prefs: []
  type: TYPE_NORMAL
- en: This ApplicationSet, utilized by the application controller, employs generator
    clusters to modify the Helm charts, including both umbrella and subcharts. This
    methodology facilitates the implementation of GitOps at scale. Argo CD, a widely
    used tool in the market, plays a crucial role in enabling this approach, supporting
    the dynamic and scalable management of application deployments.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will see how to build KSG, which allows you to deploy
    different services from this catalog distributed across the clusters with a scaling
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: Building a service catalog for Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will develop a service catalog for Kubernetes as a lightweight
    IDP. This platform will streamline providing necessary infrastructure through
    Kubernetes deployments. The lightweight IDP is designed to scale Kubernetes cluster
    flexibly via GitOps as projects grow, ensuring rapid time to market. Additionally,
    it will facilitate the extension of services such as **security**, **FinOps**,
    and **service-mesh** as needed, while ensuring that clusters are up to date and
    simplifying their management, regardless of the number of clusters involved. This
    approach underscores the synergy between Kubernetes, GitOps, and scalable infrastructure
    management.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before proceeding, it’s important to establish your labeling or tagging strategy,
    especially if you prefer not to deploy the entire stack to every cluster. Additionally,
    providing the opportunity to create and expand a service catalog can be beneficial.
    In such cases, it might be advisable to deploy a basic Kubernetes cluster tailored
    for various specific purposes. One potential approach could be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Labels** | **Stack will** **be Deployed** | **Notes** |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| `env: dev`, `staging`, `prod` | `none`, `plain cluster` | No stack will be
    deployed. Dev should only be used for testing purposes. It is not stable. |'
  prefs: []
  type: TYPE_TB
- en: '| `core-basic: enabled` | `argocd`, `external-dns`, and `ingress-nginx` | Should
    be deployed with security-basic if you want to issue certificates over cert-manager.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `security-basic: enabled` | `cert-manager`, `acme-issuer`, `falco`, `kyverno`,
    `sealed-secrets`, `external-secrets`, and `rbac` | Should be deployed on every
    cluster to keep the cluster secure. |'
  prefs: []
  type: TYPE_TB
- en: '| `monitoring-basic: enabled` | `grafana`, `victoria metrics`, `msteams-proxy`,
    `mailhog`, `stunnel`, `prometheus-node-exporter`, `prometheus-alertmanager`, `falco-exporter`,
    and `cluster-alerting` | Will deploy a monitoring stack without the logging stack.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `monitoring-medium: enabled` | `loki`, `promtail`, and `minio-loki-tenant`
    | This stack requires storage and should be deployed with `storage-basic: enabled`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `storage-basic: enabled` | `minio-operator` and `nfs-subdir-provisioner`
    | This stack is needed for the `monitoring-medium` stack. You can also deploy
    the stack without the `monitoring-medium` stack to use object storage or NFS for
    other purposes. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5.1: One potential approach of using labeling to manage different tech
    stacks'
  prefs: []
  type: TYPE_NORMAL
- en: For instance, using an operator or a CI/CD pipeline based on your workflow,
    you can efficiently map and transfer labels from your Kubernetes cluster to your
    Argo CD cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Building the service catalog
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To avoid exceeding the scope, we will focus on a handful of services when building
    the service catalog, and we’ll be using the following folder structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.12: Example of possible services in the catalog](img/B22100_05_12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.12: Example of possible services in the catalog'
  prefs: []
  type: TYPE_NORMAL
- en: Here, `applicationsets` is a directory dedicated to deploying various services
    across multiple Kubernetes clusters using labels. Inside, the `cluster` directory
    contains multiple clusters, each iterated within the *ApplicationSet* and enhanced
    with parameters from the Cluster generator. Other directories, such as `dns`,
    `networking`, and others, group services logically. They comprise Helm umbrella
    charts along with subcharts for specific services, such as `external-dns` or `ingress-nginx`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now review the well-known `nginx-ingress-applicationset.yaml` file,
    which has been updated to include the labels approach:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, `ApplicationController` deploys exclusively to clusters matching the `env
    = dev | prod` and `core-basic = enabled` labels. Structurally akin to other ApplicationSets
    for services shown in *Figure 5**.11*, there is a unique aspect in cert-manager
    from the security folder, incorporating an additional label, `security-basic:
    enabled`, in its `ApplicationSet`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code block shows how to implement it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Now, Argo CD’s application controller only deploys `cert-manager` to clusters
    tagged with the specific additional label.
  prefs: []
  type: TYPE_NORMAL
- en: 'Labels are powerful tools that allow you to manage different stacks for on-premises
    and public cloud environments through a single central Argo CD unit. This versatility
    allows for seamless management across multiple environments. Integrating this
    with the varied perspectives of different roles, labels facilitate the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Platform engineers can employ this method to deliver scalable Cluster-as-a-Service
    while incorporating SRE principles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DevSecOps engineers can implement policies across all clusters, ensuring governance
    and compliance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Developers can utilize this approach to deploy scalable applications across
    various customer clusters with customized values
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This unified approach streamlines operations and ensures consistency across
    diverse environments and roles.
  prefs: []
  type: TYPE_NORMAL
- en: 'Should you possess extra manifests tailored to your specific requirements where
    the service needs to be extended – for example, if Argo CD requires an optional
    ingress during deployment to a target cluster for external access over ingress,
    and not direct via the Kubernetes API – you can introduce an additional `templates`
    folder under `system.argocd`. In this folder, you can include a manifest similar
    to the following extract from `templates.ingress.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This approach enables you to override the values in the umbrella chart and,
    if necessary, deploy an additional ingress, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'If your organization uses common certificates from a root CA required by all
    external DNS, you could utilize `kustomize` to establish a folder structure. For
    instance, you could create `kustomize.dns.external-dns-secrets` with your `root-ca.yaml`
    file. Then, you could integrate this into your `external-dns` ApplicationSet using
    just a few lines, like so:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: With that, we have successfully created a catalog that will broaden the scope
    of our services, policies, and application portfolio.
  prefs: []
  type: TYPE_NORMAL
- en: A crucial point is focusing on the overarching approach to achieving GitOps
    at scale, rather than fixating on specific tools such as Argo CD. Tools may come
    and go, such as Flux or successors to Argo CD, but what remains vital is an adaptable
    strategy. This is akin to development practices evolving across different frameworks
    and languages while maintaining their foundational methods. By carefully organizing
    folders for various environments and merging this structure with an *ApplicationSet*,
    an efficient and scalable GitOps solution is formed. Such a strategy not only
    streamlines management but also significantly reduces the maintenance required
    for any given environment. KSC describes the power of joining CNCF/OSS projects
    together to create a secured, self-managed serving platform for developers, platform
    engineers, and SREs.
  prefs: []
  type: TYPE_NORMAL
- en: Bonus – maintenance with GitOps at scale and KSC
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s say that you’re managing hundreds of Kubernetes clusters, each with different
    stacks, and in every cluster, a core service is deployed. This results in approximately
    2,000 applications being distributed across the clusters. The key requirement
    is to keep everything up-to-date and secure. You’ve scaled up brilliantly and
    kept your applications in sync. Suddenly, on the same day, two critical **Common
    Vulnerabilities and Exposures** (**CVEs**) for the Ingress-NGINX image you’re
    using are exposed, along with a bug fix for Cert-Manager and an extra configuration
    for External-DNS to enhance its resilience. All your clusters are affected. How
    do you maintain all clusters at once, considering everything is managed through
    Helm charts? Here’s how:'
  prefs: []
  type: TYPE_NORMAL
- en: You could manually check all the Helm chart versions, look at the deltas, then
    upgrade the versions and deploy them across all clusters using Argo CD. However,
    CVEs and changes don’t always get published at a specific time; they’re released
    when a vulnerability is discovered.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have a pipeline or a job in your Kubernetes cluster that runs against your
    service catalog at set intervals to check for newer versions of a Helm chart.
    If a new version is found, it creates a pull request, displays all the changed
    values, and automatically merges if all criteria are met or after a review.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The second option sounds much better, and there is a script you can run in a
    pipeline that does precisely this. Alternatively, you can use a GitHub Action
    for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is what a pull request looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Afterward, the GitOps approach takes over, rolling out the changes across all
    clusters. This way, you minimize maintenance by centrally managing changes and
    deploying them via GitOps, regardless of the number of clusters involved.
  prefs: []
  type: TYPE_NORMAL
- en: The following section is about how to implement a multi-tenancy concept using
    only the board resources that Argo CD provides.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring native multitenancy with Argo CD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This chapter is not about setting up the most secure, optimal multitenancy environment
    with Argo CD. That’s because *best* is based on your specific SRE motivations,
    security team constraints, governance, the compliance policies of your company,
    your industry, and the skill level of your team. Additionally, tools change frequently,
    often multiple times a year, with minor releases introducing new features. Therefore,
    our focus here is on the approach to creating multitenancy with Argo CD while
    considering the aspects you should pay attention to, what you can address now,
    and future considerations.
  prefs: []
  type: TYPE_NORMAL
- en: But why opt for a multitenancy setup with Argo CD instead of using a dedicated
    cluster for each project?
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: Reducing the count of clusters makes it easy to maintain aspects such as upgrading
    Kubernetes versions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To maximize resource utilization and efficiency, multitenancy is essential.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In non-dynamic, ticket-based cold start environments, especially when not every
    Kubernetes cluster operates in the cloud, multitenancy becomes a necessity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By implementing FinOps practices, each machine’s cost is closely monitored and
    optimized. Multitenancy helps reduce overall costs by maximizing the utilization
    of resources across multiple teams or projects, ensuring efficient spending and
    minimizing waste.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, you will learn how to implement a multitenancy setup using
    Argo CD as the central management tool for workloads from different teams.
  prefs: []
  type: TYPE_NORMAL
- en: The setting for this setup is a Kubernetes platform in a company-owned data
    center, constrained by resources such as storage. A core Argo CD instance, provided
    by the platform team, is employed for the GitOps approach. This core instance
    delivers platform context (such as **ExternalDNS**, **Cert Manager**, and more)
    declaratively. Developer teams maintain their own Git repositories, with access
    to the Kubernetes cluster facilitated through **Active Directory** (**AD**) groups.
  prefs: []
  type: TYPE_NORMAL
- en: The challenge lies in deploying over the same core Argo CD instance without
    allowing teams to misuse it and break out of their isolated environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are the requirements to enable secure multi-client operation:'
  prefs: []
  type: TYPE_NORMAL
- en: Teams should work autonomously
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each team can only access its designated namespace
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Teams must not negatively impact others, for instance, through improper resource
    provisioning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A declarative GitOps approach is maintained
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GitOps at scale is managed declaratively for new projects and teams
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Additionally, there needs to be a clear understanding of where the platform
    team’s responsibilities begin and end. For this, you can consider the following
    approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The platform team provides the platform and context but stops at the initial
    repository setup:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pros**: No need to manage credentials such as **personal access tokens**
    (**PATs**) or **SSH keys**.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cons**: **Disaster recovery** is more challenging; developers must reinitialize
    access to the repo after, for instance, rotating a cluster'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The platform team provides the platform, context, and the initial repository:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pros**: Disaster recovery is simplified. A stateless cluster can be discarded
    or migrated, and the GitOps approach will restore everything correctly.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Cons**: Managing credentials for different team repos becomes necessary.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: By understanding and implementing these strategies, you can effectively manage
    a multitenancy environment in a resource-limited, Kubernetes-based infrastructure
    using Argo CD. The implementation of those strategies is based on the GitOps experience
    of the development and platform teams.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the second approach from the view of the platform team and create
    a folder in our Git repository to be aggregated by Argo CD, with a specific folder
    structure. But first, let’s look at *Figure 5**.13*. Here, you can see that the
    different teams have access to a specific namespace, which is regulated by **RBAC**,
    **quotas**, and **network policies** and managed over a common Argo CD instance
    with projects and applications. The Argo CD instance is also used by the platform
    team to provide a new namespace as a service for new projects of the developer
    teams:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.13: Multitenancy with GitOps and Argo CD](img/B22100_05_13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.13: Multitenancy with GitOps and Argo CD'
  prefs: []
  type: TYPE_NORMAL
- en: 'The folder structure that will be created for every team looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.14: Multitenancy with GitOps and Argo CD](img/B22100_05_14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.14: Multitenancy with GitOps and Argo CD'
  prefs: []
  type: TYPE_NORMAL
- en: A project on Argo CD represents the team’s dos and don’ts. You can define the
    relevant set of rules by setting a project per development team. With this, the
    platform team gives just enough of a playground for the developers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s take a look at `argocd-project-devteam-a.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: In this context, `AppProject` is structured simply, encompassing elements such
    as `sourceRepos`, `destinations`, `roles`, `clusterResourcesBlackList`, or `WhiteList`,
    and `namespaceResourceBlacklist` or `WhiteList`.
  prefs: []
  type: TYPE_NORMAL
- en: The operational flow involves determining the origins of resources, the clusters
    they can be deployed to, and the namespaces within a project where deployment
    is permitted. It defines which resources and namespace resources can be created
    within the cluster by the project, with options to either allow or explicitly
    disallow (`!`) actions.
  prefs: []
  type: TYPE_NORMAL
- en: Global projects can be set up to distribute configurations to other projects.
    This means you can implement cluster-wide restrictions that are inherited by other
    *AppProjects*, eliminating the need to replicate the entire configuration block
    for each project.
  prefs: []
  type: TYPE_NORMAL
- en: Project roles can be used to grant or deny access to specific resources within
    the project. Global roles (`argo-rbac-cm`) and team or project roles are also
    used here. However, if a user’s Kubernetes RBAC permissions are more extensive
    than those defined by the project, the project settings won’t limit their ability
    to access or modify resources. Therefore, it’s essential to constrain user rights
    at the RBAC cluster level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Here, you have explicitly forbidden deployment to `kube-system` while allowing
    deployments to the `devteam-a` namespace. However, this also inadvertently permits
    deployments to other namespaces, such as `devteam-b`, because they don’t match
    the deny pattern. This scenario underscores the importance of a deep understanding
    of Kubernetes and the relevant tools for implementing a multitenancy approach
    with GitOps at scale.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s examine how you would set up an application in this environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The resources are collected by the Argo CD core instance and deployed via the
    GitOps approach. At this point, the platform team takes care of applications and
    doesn’t allow the developer to deploy their own applications (see the limitations).
    You should be careful because restriction to create resources is not the same
    as manipulating resources. So, you might have to configure additional policies
    and **WebHook** validations, depending on your environment, corporate governance,
    and security guidelines.
  prefs: []
  type: TYPE_NORMAL
- en: '`devteam-a` has a folder named `applicationset` in their repository. The folder
    represents the start of Argo CD. The developers can determine the order and deploy
    their application over `kustomize`, Helm, or a direct Kubernetes manifest file.
    In this configuration, developers are unable to create custom resources such as
    applications, ApplicationSets, and AppProjects.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This approach to multitenancy with GitOps presents certain limitations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Limited team access to the Argo CD UI/CLI**: Teams typically can’t create
    and manage applications through Argo CD’s UI or CLI. If you wish to provide such
    access, you will need to use a Dex server, create policies in the **RBAC ConfigMap**,
    map groups to roles, or utilize project roles.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Restricted access to monitoring stacks**: Teams may not have access to a
    monitoring stack. Implementing multitenancy at this level is also necessary.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Potential conflicts with CRD versions**: If two teams opt to deploy different
    versions of CRDs for the same service, these conflicts must be mitigated. One
    way to do this is by blocking such actions and handling them through pull requests.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Challenges with declarative management**: The concept of declarative management
    can conflict with multitenancy principles. This is because Argo CD requires that
    custom resources, such as applications, be in the same namespace as Argo CD itself.
    A beta feature currently in development may allow applications to be deployed
    in different namespaces.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When opting for multitenancy with GitOps, you can conserve hardware resources.
    However, it’s important to consider that the engineering resources required to
    maintain and enforce multitenancy setups might increase. GitOps can simplify management
    and enforcement, but it also comes with its own set of constraints, depending
    on the tools used and the underlying Kubernetes version and core approach.
  prefs: []
  type: TYPE_NORMAL
- en: This is why *AppProject* is not enough for multi-tenancy. To get the full GitOps
    experience for development teams, Argo CD by itself needs some enforcement. Due
    to the limits described here, some tools can be used to reduce them. We’ll cover
    this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Exploring multitenancy with vCluster and Argo CD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we explored how multitenancy is implemented natively
    with Argo CD, along with its current limitations at the time of writing. While
    these limitations may be addressed in the future, there’s no certainty.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we’ll expand the multitenancy approach by introducing a tool
    called vCluster. This tool addresses most of the limitations discussed earlier
    by enabling scaling through GitOps in a declarative manner, facilitated by Argo
    CD. This method shifts from a Namespaces-as-a-Service model to a more comprehensive
    **Virtual-Kubernetes-as-a-Service** (**VKaaS**) or **Kubernetes-as-a-Service**
    (**KaaS**) approach.
  prefs: []
  type: TYPE_NORMAL
- en: vCluster, an open source solution for creating and managing virtual Kubernetes
    clusters, presents a novel approach to Kubernetes cluster management. It functions
    by establishing a host cluster, on top of which vClusters – akin to seed clusters
    – operate within namespaces. This setup allows multiple clusters to be deployed.
    Necessary Kubernetes components and an additional **syncer** operate as pods within
    the namespace, offering a unique virtual cluster with its dedicated API. These
    virtual clusters, although running within a single namespace of a host cluster,
    provide the illusion of being independent, full-fledged clusters. This is particularly
    useful in scenarios where namespace limitations are a concern, and specific configurations
    incompatible with the host cluster’s multitenancy setup are needed.
  prefs: []
  type: TYPE_NORMAL
- en: The focus here is not just on the tool itself, but on how it enables us to meet
    the requirements outlined in the previous section. We will maintain the same requirements
    and explore how vCluster can overcome the previously discussed limitations.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our context, a **tenant** (*Figure 5**.15*) refers to a project managed
    by vCluster on dedicated nodes, each with its own Argo CD instance. Thus, in our
    framework, every project is a tenant, and every tenant corresponds to a namespace,
    aligning with vCluster’s namespace-based approach within the shared cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.15: Example of how a tenant can be grouped by services](img/B22100_05_15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.15: Example of how a tenant can be grouped by services'
  prefs: []
  type: TYPE_NORMAL
- en: After this setup process, as illustrated in *Figure 5**.16*, your system will
    feature a configuration where shared and isolated workloads exist simultaneously
    on the host cluster. The degree of this simultaneous existence hinges on how you
    apply taints and tolerations, along with other strategies, to guide Kubernetes’
    deployment decisions. This ability is key to distributing shared workloads throughout
    the cluster effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'The method we’re about to delve into shows how to distinguish between the workloads
    of customer seed clusters, which operate on dedicated node pools, and those of
    the default node pool and host cluster. It’s important to note that these host
    cluster workloads are vital for either Kubernetes or your platform team’s operations,
    such as deploying the seed clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.16: Multitenancy setup with vCluster](img/B22100_05_16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.16: Multitenancy setup with vCluster'
  prefs: []
  type: TYPE_NORMAL
- en: 'We will split the workflow into four steps. However, only the first two steps
    are necessary to build a multitenancy setup with vCluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 1 –** **deploy vCluster**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: For this part, KSC is extended by optimization/vCluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following code is an extract from the application and can be found on GitHub
    in the `vcluster-application.yaml` file, which focuses on the essentials. It is
    important to understand that several repos are referenced as sources, and a Helm
    release is created and overwritten with specific values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: Additionally, we’ll deploy specific Kubernetes resources, such as `networkpolicy-deny-ingress.yaml`
    and `rbac.yaml`, to effectively manage access control at the namespace level.
    These resources are crucial for ensuring proper security and access protocols
    within the multitenancy environment.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 2 – connect Argo CD running on the host cluster to** **the vCluster**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'This step involves setting up a multitenancy environment using vCluster and
    Argo CD. The focus is on establishing a connection between Argo CD, which operates
    on the host cluster, and the vCluster running on the host cluster. This process
    begins with connecting to the vCluster. You can achieve this with a single command.
    For a port forwarding connection, the following command can be used:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'When utilizing an ingress for SSL passthrough, you can establish a connection
    using the following command:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Remember to configure certain vCluster and ingress-controller-specific parameters
    to enable SSL passthrough.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once this is set up, connecting Argo CD on the host system to the vCluster
    is a straightforward process and can be achieved with a single command line:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, we have effectively addressed the challenge of multitenancy.
    Teams are now equipped to connect to the virtual cluster using the familiar `vcluster
    connect` command. This capability is crucial in fostering self-sufficiency among
    teams.
  prefs: []
  type: TYPE_NORMAL
- en: '**Step 3 – point** **to KSC**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Here, the focus shifts to integrating the virtual Kubernetes environment with
    a service catalog. This step involves creating an application that points to a
    repository containing a suite of applications specifically designed for the virtual
    cluster. This is like the application example provided earlier. By establishing
    a **virtual KSC** (**vKSC**), you can delineate the difference between various
    environments and adopt your approach with labels to deploy in a manner akin to
    how you manage dedicated Kubernetes clusters.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To implement this, you can follow the step-by-step guide available on my blog
    [*7*]. This guide provides detailed instructions and insights into building a
    vKSC. This resource is particularly useful for understanding how to effectively
    manage and deploy applications in a multi-tenant setup using vCluster, ensuring
    a smooth and scalable operation within your Kubernetes environment.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Step 4 – deploy Argo CD into vCluster while running Argo CD on the** **host
    cluster**:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: While setting up a multitenancy environment with vCluster, we have already established
    a folder structure that represents our vKSC. This structure is crucial for organizing
    various services and applications within the vCluster. After integrating Argo
    CD into this service catalog, similarly to other services in the KSC, we must
    now use Argo CD running on the host cluster to deploy Argo CD across all clusters
    using GitOps. This approach allows for an automated and consistent deployment
    process. It helps in avoiding code redundancy and enables individual patching
    of manifests for each cluster. This setup ensures efficient management and deployment
    in a multi-tenant Kubernetes environment by uniformly deploying Argo CD across
    all clusters.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Bonus – simplified connection to multiple vClusters – a handy bash script
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Managing multiple vClusters can often become a cumbersome and noisy process,
    particularly when it involves connecting to each cluster individually. To address
    this challenge and streamline the workflow, I have developed a straightforward
    bash script. This script simplifies the process significantly. It operates based
    on the context of the host cluster and utilizes a consistent naming pattern, such
    as a namespace named `vcluster-demo` and an ingress formatted like `vcluster-team-a.example.com`.
    With this script, you can efficiently iterate over and establish connections to
    all vClusters, thereby saving considerable time and effort in managing your multi-cluster
    environment
  prefs: []
  type: TYPE_NORMAL
- en: Limitations solved in multitenancy with GitOps – a review
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The implementation of multitenancy using vCluster and Argo CD, as outlined
    in the earlier steps, addresses several key limitations:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Limited team access to Argo CD UI/CLI**: This can be resolved by implementing
    *Steps 3* and *4*. Each team receives an Argo CD instance, complete with UI and
    CLI access, enhancing autonomy and operational efficiency.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Restricted access to monitoring stacks**: This can be solved by deploying
    an additional monitoring stack within vCluster. This step ensures that teams have
    the necessary monitoring tools at their disposal for effective cluster management.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Potential conflicts with CRD versions**: This is no longer an issue because
    each virtual Kubernetes cluster maintains a key-value store with distinct CRDs.
    This separation effectively eliminates conflicts arising from CRD version discrepancies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Challenges with declarative management**: This is addressed through the platform
    team’s ability to provision virtual clusters over Argo CD, enabling teams to manage
    their dedicated vClusters effectively. From a developer’s perspective, following
    the implementation of *Steps 3* and *4* (refer to the Exploring multitenancy with
    vCluster and Argo CD section) ensures a smooth declarative management process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: However, it’s important to note the inherent trade-offs in this approach. While
    this concept appears resource-efficient, especially compared to the dedicated
    approach of one cluster per project/team, vCluster does consume additional resources
    compared to the native approach. Most resources from the virtual cluster can be
    synced into the host cluster, and **loft.sh**, the creator behind vCluster, is
    working on expanding this bidirectional synchronization. There’s also a vCluster
    Pro enterprise version offering further enhancements such as custom syncs between
    the host and vCluster, hibernating vClusters, creating templates, and more. Nevertheless,
    the focus here is not strictly on the tool but on the approach – how to effectively
    implement a multitenancy strategy using GitOps at scale.
  prefs: []
  type: TYPE_NORMAL
- en: As this chapter draws to a close, the following section summarizes the key points.
  prefs: []
  type: TYPE_NORMAL
- en: Wrapping up – insights and lessons from multitenancy experiences
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we wrap up this chapter, it’s insightful to revisit the key themes and lessons
    that have emerged. Beginning with the *App of Apps approach*, we set the stage
    for understanding the complexities of managing applications in a Kubernetes environment.
    This approach emphasized the importance of a structured and scalable method to
    handle application deployment and orchestration.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on to *multi-cluster management*, we explored the intricacies of managing
    numerous Kubernetes clusters, a critical aspect for organizations operating at
    scale. This exploration was complemented by the section on effective Git repository
    strategies, where the focus was on optimizing the management of repositories to
    enhance operational efficiency in a GitOps-centric environment.
  prefs: []
  type: TYPE_NORMAL
- en: The journey further unfolded with *ApplicationSet generators* and *building
    a service catalog for Kubernetes*. These sections delved into the techniques and
    tools necessary for effectively scaling applications and services across multiple
    Kubernetes clusters, underscoring Kubernetes’ inherent scalability and flexibility.
  prefs: []
  type: TYPE_NORMAL
- en: The *Native multitenancy with Argo CD* and *Multitenancy with vCluster and Argo
    CD* sections provided a thorough understanding of different methodologies and
    tools for achieving efficient multitenancy. They highlighted how multitenancy
    can be implemented and managed using Argo CD and vCluster, offering insights into
    creating isolated, efficient multi-tenant environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout this exploration, several key lessons and insights emerged:'
  prefs: []
  type: TYPE_NORMAL
- en: The strategy often outweighs the choice of tools, reinforcing the importance
    of approach over specific technologies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing multitenancy natively can save hardware resources but may increase
    the demand for engineering resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The use of patterns such as App of Apps and ApplicationSets can greatly aid
    in building scalable deployment strategies for different roles and use cases
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing multiple clusters with Argo CD is simplified, especially when combined
    with the effective use of labels and a GitOps approach
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labels, when used with ApplicationSets and Cluster generators, can facilitate
    selective and flexible deployment strategies across clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While native multitenancy approaches appear resource-efficient, they can introduce
    complexities and necessitate more engineering resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools such as vCluster offer a more isolated approach to multitenancy while
    maintaining declarative management and utilizing GitOps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The balance between conserving hardware resources and the increase in engineering
    and developer onboarding efforts needs to be carefully managed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GitOps at scale empowers platform engineering teams and developers, allowing
    them to focus on application development rather than operational burdens
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In concluding this chapter, it becomes evident that understanding the underlying
    approach opens a myriad of possibilities for creating diverse and impactful real-world
    solutions and products.
  prefs: []
  type: TYPE_NORMAL
- en: 'These include products:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Platform as a Service (PaaS) products**: As a platform engineering team,
    understanding these concepts enables the creation of a PaaS product. This platform
    offers a suite of tools and services that are essential for streamlined application
    development and deployment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Software as a Service (SaaS) solutions development for diverse clients**:
    By leveraging GitOps and Argo CD, developers can create customizable SaaS solutions
    that are easy to deploy across different Kubernetes clusters in various regions
    and versions. This approach ensures automated, consistent deployment, allowing
    developers to efficiently cater to the unique requirements of a diverse client
    base.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Deployment solutions for SRE teams**: SRE teams can leverage this knowledge
    to improve their deployment strategies, ensuring high availability and efficiency
    in their operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Governance and compliance tools for security teams**: Security teams can
    use these strategies to implement robust governance and compliance measures across
    all clusters. By utilizing labels effectively, they can establish comprehensive
    service packages that ensure adherence to security standards and regulatory requirements.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These applications demonstrate the versatility and real-world impact of the
    strategies discussed in this chapter, highlighting how a deep understanding of
    GitOps and multitenancy can lead to the creation of diverse, scalable, and secure
    technological solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In conclusion, this chapter has not only illuminated various strategies and
    tools for achieving multitenancy and scaling in Kubernetes but also highlighted
    the crucial role of understanding these concepts deeply. The journey through GitOps
    at scale and multitenancy reveals that while there are multiple approaches to
    achieving efficiency in Kubernetes, each comes with its trade-offs. The ultimate
    choice should be aligned with the organization’s specific needs and the goals
    of its development teams.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will introduce different architectures that have already
    been partially utilized in this chapter to illustrate concepts such as *One cockpit
    rule them all* approach for multi-cluster management, as well as discuss their
    advantages, disadvantages, use cases, and insights gathered from various projects.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[*1*] [https://docs.akuity.io/tutorials/cluster-addons-with-applicationsets/](https://docs.akuity.io/tutorials/cluster-addons-with-applicationsets/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*2*] [https://argocd-applicationset.readthedocs.io/en/stable/Generators/](https://argocd-applicationset.readthedocs.io/en/stable/Generators/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*3*] [https://codefresh.io/blog/argo-cd-best-practices/](https://codefresh.io/blog/argo-cd-best-practices/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*4*] [https://codefresh.io/docs/docs/pipelines/deployment-environments/](https://codefresh.io/docs/docs/pipelines/deployment-environments/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*5*] [https://codefresh.io/blog/codefresh-gitops-app-of-apps/](https://codefresh.io/blog/codefresh-gitops-app-of-apps/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*6*] [https://www.vcluster.com/docs/using-vclusters/access](https://www.vcluster.com/docs/using-vclusters/access)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*7*] [https://medium.com/devops-dev/multi-tenancy-with-vcluster-794de061fff1](https://medium.com/devops-dev/multi-tenancy-with-vcluster-794de061fff1)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
