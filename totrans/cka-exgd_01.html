<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer015">
<h1 class="chapter-number" id="_idParaDest-16"><a id="_idTextAnchor015"/>1</h1>
<h1 id="_idParaDest-17"><a id="_idTextAnchor016"/>Kubernetes Overview</h1>
<p>This chapter is an introduction to the Kubernetes architecture and Kubernetes core concepts. It dives into common Kubernetes tools and gets hands-on with them, showing the big picture of the different distributions and ecosystems in Kubernetes. In this chapter, we’re going to cover the following main topics: </p>
<ul>
<li>CKA exam overview</li>
<li>Cluster architecture and components</li>
<li>Kubernetes core concepts </li>
<li>Kubernetes in-market distribution and ecosystems </li>
</ul>
<h1 id="_idParaDest-18"><a id="_idTextAnchor017"/>CKA exam overview</h1>
<p><strong class="bold">Certified Kubernetes Administrator</strong> (<strong class="bold">CKA</strong>) certification <a id="_idIndexMarker000"/>is a <a id="_idIndexMarker001"/>hands-on exam with a set of common Kubernetes working scenarios. You need to achieve it within a limited time frame. We highly recommend you work through this book within your environment and make sure that you understand and practice all the steps until you train your intuition and can perform all the tasks quickly without thinking twice. Time management is the key to success in this exam. </p>
<p>At the time of writing this book, the CKA exam is based on Kubernetes 1.22. Please check out the official example page to make sure you’re up to date on any changes in the exam curriculum: <a href="https://www.cncf.io/certification/cka/">https://www.cncf.io/certification/cka/</a>. To learn more about the changes in Kubernetes, please check out the community release notes: <a href="https://github.com/kubernetes/kubernetes/releases">https://github.com/kubernetes/kubernetes/releases</a>. </p>
<p>The content of this book is well aligned with the CKA exam curriculum: </p>
<ul>
<li><em class="italic">Part 1</em> – <em class="italic">Chapters 1</em> to <em class="italic">3</em> cover <em class="italic">Kubernetes Cluster Architecture, Installation, and Configurations</em>, which makes up about 25% of the exam. </li>
<li><em class="italic">Part 2</em> – <a href="B18201_04.xhtml#_idTextAnchor080"><em class="italic">Chapter 4</em></a> covers <em class="italic">Workloads and Scheduling</em>, which makes up about 15% of the exam, <a href="B18201_05.xhtml#_idTextAnchor149"><em class="italic">Chapter 5</em></a> covers <em class="italic">Storage Services and Networking</em>, which makes up about 10% of the exam, <em class="italic">chapters 6</em> and <em class="italic">7</em> cover <em class="italic">Services and Networking</em>, which makes up about 20% of the exam.</li>
<li><em class="italic">Part 3</em> – <em class="italic">Chapters 8</em> to <em class="italic">10</em> cover <em class="italic">Troubleshooting</em>, which makes up about 30% of the exam. </li>
</ul>
<p>The goal of the exam curriculum is to help you prepare for the CKA exam and help you get a thorough understanding of each area, which will help you become skilled Kubernetes administrators later on in your career. While going through this book, please feel free to jump to the area that you need to know the most about if you’re already familiar with some other topics. </p>
<p>Note that some Kubernetes<a id="_idIndexMarker002"/> security content before November 2020 has gradually moved to the <strong class="bold">Certified Kubernetes Security Specialist</strong> (<strong class="bold">CKS</strong>) exam. As a well-rounded Kubernetes administrator, it’s essential to have a deep understanding of Kubernetes security. In fact, it is somewhat difficult to separate Kubernetes security as a different topic; however, knowledge of topics such as security<a id="_idIndexMarker003"/> context and <strong class="bold">role-based access control</strong> (<strong class="bold">RBAC</strong>) is still required for you to perform certain tasks to be successful in the exam. Therefore, this book will still cover some key security concepts to lay the groundwork if you want to pursue the CKS certification later on. To get to know more about different<a id="_idIndexMarker004"/> Kubernetes certifications, check out the FAQs from the Linux Foundation website by navigating to <a href="https://docs.linuxfoundation.org/tc-docs/certification/faq-cka-ckad-cks">https://docs.linuxfoundation.org/tc-docs/certification/faq-cka-ckad-cks</a>.</p>
<h2 id="_idParaDest-19"><a id="_idTextAnchor018"/>What to expect in your CKA exam </h2>
<p>Prior to your exam, you <a id="_idIndexMarker005"/>have to make sure the computer you’re going to use during the exam meets the system requirements defined by the exam provider. A webcam and microphone are mandatory to turn on during the exam. You’re only allowed to use a single instance of a Chromium-based browser for the exam. You can find a list of Chromium-based browsers here: <a href="https://en.wikipedia.org/wiki/Chromium_(web_browser)">https://en.wikipedia.org/wiki/Chromium_(web_browser)</a>.</p>
<p>Please make sure your hardware meets the minimum requirements by running the compatibility check tool, which you can find here: <a href="https://www.examslocal.com/ScheduleExam/Home/CompatibilityCheck">https://www.examslocal.com/ScheduleExam/Home/CompatibilityCheck</a>. The detailed system requirements are defined here: <a href="https://docs.linuxfoundation.org/tc-docs/certification/faq-cka-ckad-cks#what-are-the-system-requirements-to-take-the-exam">https://docs.linuxfoundation.org/tc-docs/certification/faq-cka-ckad-cks#what-are-the-system-requirements-to-take-the-exam</a>.</p>
<p class="callout-heading">Important note</p>
<p class="callout">As this exam is an online remote-proctored exam, you can also check out what the exam is like here: <a href="https://psi.wistia.com/medias/5kidxdd0ry">https://psi.wistia.com/medias/5kidxdd0ry</a>.</p>
<p>During your exam, you’re allowed to check the official Kubernetes documentation including articles and documents under <a href="https://kubernetes.io">https://kubernetes.io</a> and <a href="https://github.com/kubernetes">https://github.com/kubernetes</a> on the same browser instance as the exam screen. The CKA exam consists of a set of around 20 scenario-based tasks to be achieved with a Linux-based shell and a set of predefined Kubernetes clusters. Those scenario-based tasks are described as a problem to be resolved with additional information. Candidates are bound to come up with the solutions based on the provided information and perform the solution promptly. A CKA exam session is about 2 hours, and after that, the exam will be <a id="_idIndexMarker006"/>marked as delivered. You can take the exam with multiple monitors if you wish to, although check out the exam policy beforehand to make sure you have met all the requirements from the organizer: <a href="https://docs.linuxfoundation.org/tc-docs/certification/faq-cka-ckad-cks#how-is-the-exam-proctored">https://docs.linuxfoundation.org/tc-docs/certification/faq-cka-ckad-cks#how-is-the-exam-proctored</a>.</p>
<p>We highly recommend you walk through the sample <a id="_idIndexMarker007"/>scenarios provided by <strong class="bold">killer.sh</strong>, an official exam simulator, and bookmark the official documents that will be useful for you. Go to the <strong class="bold">killer.sh</strong> training website at <a href="https://killer.sh/course/">https://killer.sh/course/</a> to test out a simulated exam environment and test out the scenarios. </p>
<p>For more CKA exam instructions and tricks, please check out <a href="https://docs.linuxfoundation.org/tc-docs/certification/tips-cka-and-ckad">https://docs.linuxfoundation.org/tc-docs/certification/tips-cka-and-ckad</a>.</p>
<p>You need a score of at least 66% to pass the exam, and the results will be emailed to you within 24 to 36 hours of finishing the exam. Accordingly, you will receive the certification in PDF form with a validity of 3 years, and a badge shortly after that. In case of any questions, you could email <strong class="source-inline">certificationsupport@cncf.io</strong> for further help.</p>
<h2 id="_idParaDest-20"><a id="_idTextAnchor019"/>CKA exam tips and tricks </h2>
<p>Two key factors to<a id="_idIndexMarker008"/> help you succeed in the CKA exam or any other Kubernetes certifications are as follows: </p>
<ul>
<li>Excellent time management </li>
<li>Practice, as we know that practice makes perfect </li>
</ul>
<p>Before getting to the exam part, you have to be familiar with Kubernetes; don’t dwell only on the certification when you’re preparing for this exam. A deep understanding of the Kubernetes cluster architecture and ecosystem will help set a solid foundation on the way to learning any exam-related content. </p>
<h3>Gaining some basic understanding of the Linux shell </h3>
<p>Looking at the exam<a id="_idIndexMarker009"/> itself, a basic understanding of the Linux shell will assist you in achieving the goal quicker. The following commands will help you while you’re going through the exercises in this book: </p>
<ul>
<li><strong class="source-inline">sudo</strong> to avoid permission issues as much as possible, and <strong class="source-inline">sudo su</strong> to get root permission</li>
<li><strong class="source-inline">curl</strong> </li>
<li><strong class="source-inline">| grep</strong> in the command filtering result </li>
<li><strong class="source-inline">vi/vim/nano</strong> or other Linux text editor </li>
<li><strong class="source-inline">cat</strong> </li>
<li><strong class="source-inline">cp/mv/mkdir/touch</strong></li>
<li><strong class="source-inline">cp/scp</strong></li>
<li>A good understanding of the <strong class="source-inline">json</strong> path is a plus, and using <strong class="source-inline">jq</strong> for JSON parsing would be a good complement to locating the information that you want to get out of the command. </li>
</ul>
<p>As we’re going through all the exam topics in this book, we’ll cover most of these commands in the exercises. Make sure you understand and can confidently perform all the exercises independently with no rush. </p>
<h3>Setting up a kubectl alias to save time </h3>
<p>A lot of commands<a id="_idIndexMarker010"/> will be used repeatedly while you’re working on various scenarios of the exam, so a friendly shortcut for <strong class="source-inline">kubectl</strong> is essential, as it will be used in nearly all of your commands: </p>
<p class="source-code">alias k=kubectl </p>
<p class="source-code">alias kg='kubectl get'</p>
<p class="source-code">alias kgpo='kubectl get pod'</p>
<p>There’s a <strong class="source-inline">kubectl-aliases</strong> repository on GitHub that you can refer to (<a href="https://github.com/ahmetb/kubectl-aliases">https://github.com/ahmetb/kubectl-aliases</a>). This was created by a contributor who showed some really good examples of <strong class="source-inline">kubectl</strong> aliases. </p>
<p>If you don’t want to remember too much, you can try to understand the naming convention for shortcuts in Kubernetes. These would be things such as <strong class="source-inline">svc</strong> being short for services such that <strong class="source-inline">kubectl get services</strong> can become <strong class="source-inline">kubectl get svc</strong>, or <strong class="source-inline">kubectl get nodes</strong> can become <strong class="source-inline">k get no</strong>, for example. I have created a <strong class="source-inline">melonkube playbook</strong> repository, which covers all the shortcuts for Kubernetes objects (<a href="https://github.com/cloudmelon/melonkube/blob/master/00%20-%20Shortcuts.md">https://github.com/cloudmelon/melonkube/blob/master/00%20-%20Shortcuts.md</a>). </p>
<p>You can refer to that to<a id="_idIndexMarker011"/> find what works best for you. However, please keep it simple as your mind may be get worked up during the actual exam for some reason. Practice and more practice will get you there sooner. </p>
<h3>Setting kubectl autocomplete </h3>
<p>You could set <a id="_idIndexMarker012"/>autocompletion in your shell; this will usually work in the Linux shell in your exam. You can achieve this with the following: </p>
<p class="source-code">source &lt;(kubectl completion bash) # setup autocomplete in bash into the current shell, bash-completion package should be installed first.</p>
<p class="source-code">echo "source &lt;(kubectl completion bash)" &gt;&gt; ~/.bashrc # add autocomplete permanently to your bash shell.</p>
<p>Working in conjunction with the shortcut, you can do the following:</p>
<p class="source-code">alias k=kubectl</p>
<p class="source-code">complete -F __start_kubectl k</p>
<p>Although sometimes it may take more time to look for the right commands from <strong class="source-inline">bash autocompletion</strong>, I would say focusing on building a good understanding of the technology with practice <a id="_idIndexMarker013"/>will help you skill up faster. </p>
<h3>Bookmarking unfamiliar yet important documentation in your browser</h3>
<p>Get yourself <a id="_idIndexMarker014"/>familiar with Kubernetes official documentation to know where to find the information you need. The goal of CKA is <em class="italic">not</em> about memorizing but hands-on skills; knowing how to find the right path and resolving the challenge is the key. You could bookmark the documentation in the following domains: </p>
<ul>
<li>Kubernetes official documentation: <a href="https://kubernetes.io/docs/">https://kubernetes.io/docs/</a></li>
<li>Kubernetes blog: <a href="https://kubernetes.io/blog/">https://kubernetes.io/blog/</a></li>
<li>Kubernetes GitHub repository: <a href="https://github.com/kubernetes/">https://github.com/kubernetes/</a></li>
</ul>
<p>The first page that I usually recommend people to bookmark is the <strong class="source-inline">kubectl</strong> cheat sheet: <a href="https://kubernetes.io/docs/reference/kubectl/cheatsheet/">https://kubernetes.io/docs/reference/kubectl/cheatsheet/</a>. Another good bookmark is the <a id="_idIndexMarker015"/>official documentation search: <a href="https://kubernetes.io/search/?q=kubecon">https://kubernetes.io/search/?q=kubecon</a>.</p>
<h3>Be careful with the security context</h3>
<p>The context is <a id="_idIndexMarker016"/>the most important indicator to let you know which Kubernetes cluster you’re currently working on. We’ll touch on the security context in more detail later in the book. I suggest you perform a context check before working on any new questions as you might get confused at times. Note that if you’re not operating on the target Kubernetes cluster of that question, you will <em class="italic">not</em> get scored. </p>
<p>You can use the following command to check out the context:</p>
<p class="source-code">kubectl config current-context</p>
<p>If you want to go to a specific Kubernetes cluster, you can use the following command: </p>
<p class="source-code">kubectl config use-context my-current-cluster-name</p>
<p>You can also check out a list of Kubernetes clusters you’ve worked on with the following command in the actual exam: </p>
<p class="source-code">kubectl config get-contexts  </p>
<h3>Managing your time wisely </h3>
<p>Time management is the<a id="_idIndexMarker017"/> key to success in the CKA exam, and it is important to manage your time wisely by switching the task order. In general, all exam tasks are leveled from easy to difficult. When you reach the last few questions, you may find some tasks are quite time-consuming, but not the most difficult. You can skip to other questions that you’re confident about and then come back to these later. That’s why it’s important to be aware of the Kubernetes cluster that you’re currently working on. </p>
<h3>Final thoughts</h3>
<p>If you have walked through all the exercises in this book and want to gain a deeper understanding <a id="_idIndexMarker018"/>of Kubernetes, I recommend checking out another book that I co-authored back in 2020, called <em class="italic">The Kubernetes Workshop</em>, also published by Packt, which provides lots of Kubernetes exercises to help you skill up on the technology.</p>
<h1 id="_idParaDest-21">Cluster architect<a id="_idTextAnchor020"/>ure and components</h1>
<p>Kubernetes is <a id="_idIndexMarker019"/>a portable, highly extensible, open source orchestration that facilitates managing containerized workloads and services and orchestrates your containers to achieve the desired status across different worker nodes. It is worth mentioning that official documentation states that Kubernetes means <em class="italic">pilot</em> in Greek where its name originates from, which is appropriate for its function. </p>
<p>It supports a variety of workloads, such as stateless, stateful, and data-processing workloads. Theoretically, any application that can be containerized can be up and running on Kubernetes.</p>
<p>A Kubernetes cluster consists of a set of worker nodes; those worker machines run the actual workloads that are the containerized applications. A Kubernetes cluster can have from 1 up to 5,000 nodes (as of writing this chapter, we’re on the Kubernetes 1.23 version). </p>
<p>We usually spin up one node for quick testing, whereas, in production environments, a cluster has multiple worker nodes for high availability and fault torrent. </p>
<p>Kubernetes adopts a master/worker architecture, which is a mechanism where one process acts as the master component to control one or more other components called slaves, or in our case, worker nodes. A general Kubernetes cluster architecture would look like the <a id="_idIndexMarker020"/>following: </p>
<div>
<div class="IMG---Figure" id="_idContainer008">
<img alt="Figure 1.1 – Kubernetes cluster architecture " height="791" src="image/Figure_1.1_B18201.jpg" width="1650"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 1.1 – Kubernetes cluster architecture</p>
<p>The Kubernetes master node, or the control plane, is in charge of responding to the cluster events, and it contains the following components:</p>
<ul>
<li><strong class="bold">API server</strong>: This is<a id="_idIndexMarker021"/> the core of the Kubernetes control plane. The main implementation of the API server, also known as <strong class="source-inline">kube-apiserver</strong>, is to expose the Kubernetes REST API. You can see it as a communication manager between different Kubernetes components across the Kubernetes cluster.</li>
<li><strong class="bold">etcd</strong>: This is a distributed<a id="_idIndexMarker022"/> key-value store that stores information regarding the cluster information and all states of objects running on the Kubernetes cluster, such as Kubernetes cluster nodes, Pods, config maps, secrets, service accounts, roles, and bindings.</li>
<li><strong class="bold">Kubernetes scheduler</strong>: A Kubernetes <a id="_idIndexMarker023"/>scheduler is a part of the control plane. It is responsible for scheduling Pods to the nodes. <strong class="source-inline">kube-scheduler</strong> is the default scheduler for Kubernetes. You can imagine it as a postal officer who sends the Pod’s information to each node and when it arrives at the target node, the <strong class="source-inline">kubelet</strong> agent on that node will provide the actual containerized workloads with the received specification. </li>
<li><strong class="bold">Controllers</strong>: Controllers<a id="_idIndexMarker024"/> are responsible for running Kubernetes toward the desired states. A set of built-in controllers runs inside <strong class="source-inline">kube-controller-manager</strong> in Kubernetes. Examples of those controllers are replication controllers, endpoint controllers, and namespace controllers. </li>
</ul>
<p>Besides the control plane, every<a id="_idIndexMarker025"/> worker node in a Kubernetes cluster running the actual workloads has the following components:</p>
<ul>
<li><strong class="bold">kubelet</strong>: A kubelet is an<a id="_idIndexMarker026"/> agent that runs on each worker node. It accepts pod specifications sent from the API server or locally (for static pod) and provisions the containerized workloads such as the Pod, StatefulSet, and ReplicaSet on the respective nodes.</li>
<li><strong class="bold">Container runtime</strong>: This is <a id="_idIndexMarker027"/>the software virtualization layer that helps run containers within the Pods on each node. Docker, CRI-O, and containerd are examples of common container runtimes working with Kubernetes.</li>
<li><strong class="bold">kube-proxy</strong>: This runs on <a id="_idIndexMarker028"/>each worker node and implements the network rules and traffic forwarding when a service object is deployed in the Kubernetes cluster.</li>
</ul>
<p>Knowing about those components and how they work will help you understand the core Kubernetes core concepts. </p>
<h1 id="_idParaDest-22"><a id="_idTextAnchor021"/>Kubernetes core concepts</h1>
<p>Before diving into <a id="_idIndexMarker029"/>the meat and potatoes of Kubernetes, we’ll explain some key concepts in this section to help you start the journey with Kubernetes. </p>
<h2 id="_idParaDest-23"><a id="_idTextAnchor022"/>Containerized workloads </h2>
<p>A containerized <a id="_idIndexMarker030"/>workload means applications <a id="_idIndexMarker031"/>running on Kubernetes. Going back to the raw definition of containerization, a container provides an isolated environment for your application, with higher density and better utilization of the underlying infrastructure compared to the applications deployed on the physical <a id="_idIndexMarker032"/>server or <strong class="bold">virtual machines</strong> (<strong class="bold">VMs</strong>): </p>
<div>
<div class="IMG---Figure" id="_idContainer009">
<img alt="Figure 1.2 – Virtual machine versus containers " height="522" src="image/Figure_1.2_B18201.jpg" width="1357"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 1.2 – Virtual machine versus containers</p>
<p>The preceding diagram shows the difference between VMs and containers. When compared to VMs, containers are more efficient and easier to manage.</p>
<h2 id="_idParaDest-24"><a id="_idTextAnchor023"/>Container images </h2>
<p>A container <a id="_idIndexMarker033"/>isolates the application with all its <a id="_idIndexMarker034"/>dependencies, libraries, binaries, and configuration files. The package of the application, together with its dependencies, libraries, binaries, and configurations, is what we call a <strong class="bold">container image</strong>. Once a container image is built, the content of the image is immutable. All<a id="_idIndexMarker035"/><a id="_idIndexMarker036"/> the code changes and dependencies updates will need to build a new image. </p>
<h2 id="_idParaDest-25"><a id="_idTextAnchor024"/>Container registry</h2>
<p>To store the container<a id="_idIndexMarker037"/> image, we need <a id="_idIndexMarker038"/>a container registry. The <strong class="bold">container registry</strong> is located on your local machine, on-premises, or sometimes in the cloud. You need to authenticate to the container registry to access its content to ensure security. Most public registries, such as DockerHub and <a href="http://quay.io">quay.io</a>, allow a wide range of non-gated container image distributions across the board: </p>
<div>
<div class="IMG---Figure" id="_idContainer010">
<img alt="Figure 1.3 – Container images " height="398" src="image/Figure_1.3_B18201.jpg" width="1204"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 1.3 – Container images</p>
<p>The upside of this entire mechanism is that it allows the developers to focus on coding and configuring, which is the core value of their job, without worrying about the underlying infrastructure or managing dependencies and libraries to be installed on the host node, as shown in the preceding diagram.</p>
<h2 id="_idParaDest-26"><a id="_idTextAnchor025"/>Container runtimes</h2>
<p>The container <a id="_idIndexMarker039"/>runtime is in charge of running<a id="_idIndexMarker040"/> containers, which is also known as <a id="_idIndexMarker041"/>the <strong class="bold">container engine</strong>. This is a software virtualization layer that runs containers on a host operating system. A container runtime such as Docker can pull container images from a container registry and manage the container life cycle using CLI commands, in this case, Docker CLI commands, as the following diagram describes: </p>
<div>
<div class="IMG---Figure" id="_idContainer011">
<img alt="Figure 1.4 – Managing Docker containers " height="565" src="image/Figure_1.4_B18201.jpg" width="1384"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 1.4 – Managing Docker containers</p>
<p>Besides Docker, Kubernetes supports multiple container runtimes, such as containerd and CRI-O. In the context of Kubernetes, the container runtime helps get containers up and running within the Pods on each worker node. We’ll cover how to set up the container <a id="_idIndexMarker042"/>runtime in the next chapter as part of preparation work prior to provisioning a Kubernetes cluster. </p>
<p class="callout-heading">Important note</p>
<p class="callout">Kubernetes runs the containerized workloads by provisioning Pods run on worker nodes. A node could be a physical or a virtual machine, on-premises, or in the cloud.</p>
<h1 id="_idParaDest-27"><a id="_idTextAnchor026"/>Kubernetes basic workflow</h1>
<p>We saw earlier a <a id="_idIndexMarker043"/>typical workflow showing how Kubernetes works with Kubernetes components, and how they collaborate with each other, in the <em class="italic">Cluster architecture and components</em> section. When you’re using <strong class="source-inline">kubectl</strong> commands, a YAML specification, or another way to invoke an API call, the API server creates a Pod definition and the scheduler identifies the available node to place the new Pod on. The scheduler does two things: <em class="italic">filtering</em> and <em class="italic">scoring</em>. The filtering step finds a set of available candidate nodes to place the Pod, and the scoring step ranks the most fitting Pod placement. </p>
<p>The API server then passes that information to the kubelet agent on the target worker node. The kubelet then creates the Pod on the node and instructs the container runtime engine to deploy the application image. Once it’s done, the kubelet communicates the status back to the API server, which then updates the data in the <strong class="source-inline">etcd</strong> store, and the user will be notified that the Pod has been created.</p>
<p>This mechanism is repeated every time we perform a task and talk to the Kubernetes cluster, either by using <strong class="source-inline">kubectl</strong> commands, deploying a YAML definition file, or using other ways to trigger a REST API call through the API server. </p>
<p>The following<a id="_idIndexMarker044"/> diagram shows the process that we just described: </p>
<div>
<div class="IMG---Figure" id="_idContainer012">
<img alt="Figure 1.5 – Kubernetes cluster basic workflow  " height="815" src="image/Figure_1.5_B18201.jpg" width="1605"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 1.5 – Kubernetes cluster basic workflow </p>
<p>Knowing the basic Kubernetes workflow will help you understand how Kubernetes cluster components collaborate with each other and lay the foundation for learning about the <a id="_idIndexMarker045"/>Kubernetes plugin model and API objects. </p>
<h2 id="_idParaDest-28"><a id="_idTextAnchor027"/>Kubernetes plugin model</h2>
<p>One of the most important<a id="_idIndexMarker046"/> reasons for Kubernetes to dominate the market and become the new normal of the cloud-native ecosystem is that it is flexible, highly configurable, and has a highly extensible architecture. Kubernetes is highly<a id="_idIndexMarker047"/> configurable and extensible on the following layers: </p>
<ul>
<li><strong class="bold">Container runtime</strong>: The<a id="_idIndexMarker048"/> container <a id="_idIndexMarker049"/>runtime is the lowest software virtualization layer running containers. This layer supports a variety of runtimes in the market<a id="_idIndexMarker050"/> thanks to the <strong class="bold">Container Runtime Interface</strong> (<strong class="bold">CRI</strong>) plugin. The CRI contains a set of protocol buffers, specifications, a gRPC API, libraries, and tools. We’ll cover how to cooperate with different runtimes when provisioning the Kubernetes cluster in <a href="B18201_02.xhtml#_idTextAnchor035"><em class="italic">Chapter 2</em></a>, <em class="italic">Installing and Configuring Kubernetes Clusters</em>. </li>
<li><strong class="bold">Networking</strong>: The networking<a id="_idIndexMarker051"/> layer <a id="_idIndexMarker052"/>of Kubernetes is defined by kubenet <a id="_idIndexMarker053"/>or the <strong class="bold">Container Network Interface</strong> (<strong class="bold">CNI</strong>), which is responsible for configuring network interfaces for Linux containers, in our case, mostly Kubernetes Pods. The CNI is actually a <strong class="bold">Cloud Native Computing Foundation</strong> (<strong class="bold">CNCF</strong>) project that includes CNI specifications, plugins, and <a id="_idIndexMarker054"/>libraries. We’ll cover more details about Kubernetes networking in <a href="B18201_07.xhtml#_idTextAnchor235"><em class="italic">Chapter 7</em></a>, <em class="italic">Demystifying Kubernetes Networking</em>. </li>
<li><strong class="bold">Storage</strong>: The <a id="_idIndexMarker055"/>storage <a id="_idIndexMarker056"/>layer of Kubernetes was one of the most challenging parts at a time prior<a id="_idIndexMarker057"/> to <strong class="bold">Container Storage Interface</strong> (<strong class="bold">CSI</strong>) being introduced as a standard interface for exposing block and file storage systems. The storage volumes are managed by storage drivers tailored by storage vendors, this part previously being part of Kubernetes source code. The CSI compatible volume drivers are served for users to attach or mount the CSI volumes to the Pods running in the Kubernetes <a id="_idIndexMarker058"/>cluster. We’ll cover storage management in Kubernetes in <a href="B18201_05.xhtml#_idTextAnchor149"><em class="italic">Chapter 5</em></a>, <em class="italic">Demystifying Kubernetes Storage</em>. </li>
</ul>
<p>They can be easily laid out as shown in the following diagram: </p>
<div>
<div class="IMG---Figure" id="_idContainer013">
<img alt="Figure 1.6 – Kubernetes plugin model " height="747" src="image/Figure_1.6_B18201.jpg" width="991"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 1.6 – Kubernetes plugin model</p>
<p>A good<a id="_idIndexMarker059"/> understanding of the Kubernetes plugin model will help you not only in your daily work as a Kubernetes administrator but also to lay the foundation to help you quickly learn about Kubernetes ecosystems and cloud-native community standards. </p>
<h1 id="_idParaDest-29"><a id="_idTextAnchor028"/>Kubernetes API primitives </h1>
<p>All operations <a id="_idIndexMarker060"/>and communications between components and external user commands are REST API calls that the API server handles. Everything in Kubernetes is considered an API object. </p>
<p>In Kubernetes, when you run a <strong class="source-inline">kubectl</strong> command, the <strong class="source-inline">kubectl</strong> utility is in fact reaching kube-apiserver. <strong class="source-inline">kube-apiserver</strong> first authenticates and validates requests and then updates information in <strong class="source-inline">etcd</strong> and retrieves the requested information. </p>
<p>When it comes down to each worker node, the kubelet agent on each node takes Podspecs that are primarily provided by the API server, provisions the containerized workloads, and ensures (as described in those Podspecs) that the Pods are running and healthy. A Podspec is the body of the YAML definition file, which is translated to a JSON object that describes the specification for the workloads. Kubernetes form an API call going through the API server. And it is then taken into consideration by the control plane. </p>
<p>Kubernetes API primitives, also known as Kubernetes objects, are the fundamental building blocks of any containerized workload up and running in the Kubernetes cluster. </p>
<p>The following are the main Kubernetes objects we’re going to use in our daily life while working with Kubernetes clusters: </p>
<ul>
<li><strong class="bold">Pods</strong>: The smallest <a id="_idIndexMarker061"/>deployable unit in Kubernetes is a<a id="_idIndexMarker062"/> Pod. The worker node hosts the Pods, which contain the actual application workload. The applications are packaged and deployed in the containers. A single Pod contains one or more containers. </li>
<li><strong class="bold">ReplicaSet</strong>: ReplicaSet helps<a id="_idIndexMarker063"/> Pods achieve higher availability when users define a certain number of replicas at a time with a ReplicaSet. The role of the ReplicaSet is to make sure the cluster will always have an exact number of replicas up and running in the Kubernetes cluster. If any of them were to fail, new ones will be deployed. </li>
<li><strong class="bold">DaemonSet</strong>: DaemonSet is <a id="_idIndexMarker064"/>like ReplicaSet but it makes sure at least one copy of your Pod is evenly presented on each node in the Kubernetes cluster. If a new node is added to the cluster, a replica of that Pod is automatically assigned to that node. Similarly, when a node is removed, the Pod is automatically removed.</li>
<li><strong class="bold">StatefulSet</strong>: StatefulSet is <a id="_idIndexMarker065"/>used to manage stateful applications. Users can use StatefulSet when a storage volume is needed to provide persistence for the workload. </li>
<li><strong class="bold">Job</strong>: A job can be <a id="_idIndexMarker066"/>used to reliably execute a workload automatically. When it completes, typically, a job will create one or more Pods. After the job is finished, the containers will exit and the Pods will enter the <strong class="source-inline">Completed</strong> status. An example of using jobs is when we want to run a workload with a particular purpose and make sure it runs once and succeeds.</li>
<li><strong class="bold">CronJob</strong>: CronJobs <a id="_idIndexMarker067"/>are based on the capability of a job by adding value to allow users to execute jobs on a schedule. Users can use a <strong class="source-inline">cron</strong> expression to define a particular<a id="_idIndexMarker068"/> schedule per requirement. </li>
<li><strong class="bold">Deployment</strong>: A Deployment is a <a id="_idIndexMarker069"/>convenient way where you can define the desired state Deployment, such as deploying a ReplicaSet with a certain number of replicas, and it is easy to roll out and roll back to the previous versions. </li>
</ul>
<p>We’ll cover <a id="_idIndexMarker070"/>more<a id="_idIndexMarker071"/> details about how to work with those Kubernetes objects in <a href="B18201_04.xhtml#_idTextAnchor080"><em class="italic">Chapter 4</em></a>, <em class="italic">Application Scheduling and Lifecycle Management</em>. Stay tuned!</p>
<h1 id="_idParaDest-30"><a id="_idTextAnchor029"/>Sharing a cluster with namespaces</h1>
<p>Understanding<a id="_idIndexMarker072"/> the<a id="_idIndexMarker073"/> basic Kubernetes objects will give you a glimpse of how Kubernetes works on a workload level, and we’ll cover more details and other related objects as we go. Those objects running on the Kubernetes cluster will work just fine when we’re doing the development or test ourselves or a quick onboarding exercise, although we’ll need to think about the separation of the workloads when it comes to the production environment for those enterprise-grade organizations. That’s where the namespace comes in. </p>
<p>A namespace is a logical separation of all the namespaced objects deployed in a single Kubernetes cluster. Examples of namespaced objects are Deployments, Services, Secrets, and more. Some other Kubernetes objects are cluster-wide, such as StorageClasses, Nodes, and PersistentVolumes. The name of a resource has to be unique within a namespace, but it’s labeled by a namespace name and an object name across all namespaces.</p>
<p>Namespaces are intended to separate cluster resources between multiple users, which creates the possibility of sharing a cluster for multiple projects within an organization. We call this<a id="_idIndexMarker074"/> model the <strong class="bold">Kubernetes multi-tenant model</strong>. The multi-tenant model is an effective way to help different projects and teams share the cluster and get the most use out of the same cluster. The multi-tenant model helps minimize resource wasting. It comes in <a id="_idIndexMarker075"/>handy<a id="_idIndexMarker076"/> in particular when working with Kubernetes in the cloud as there is always a reservation of resources by the cloud vendors. Despite all the upsides, the multi-tenant model is also bringing extra challenges to resource management and security aspects. We’ll cover resource management in <a href="B18201_04.xhtml#_idTextAnchor080"><em class="italic">Chapter 4</em></a>, <em class="italic">Application Scheduling and Lifecycle Management</em>. </p>
<p>For better physical isolation, we recommend that organizations use multiple Kubernetes clusters. It will bring a physical boundary for different projects and teams, although the resources reserved by the Kubernetes system are also replicated across clusters. Beyond that, working across diﬀerent Kubernetes clusters is also challenging, as it involves setting up an eﬀective mechanism by switching the security context, as well as dealing with the complexity of the networking aspects. We’ll cover Kubernetes security in <a href="B18201_06.xhtml#_idTextAnchor192"><em class="italic">Chapter 6</em></a>, <em class="italic">Securing Kubernetes</em>, and Kubernetes networking in <a href="B18201_07.xhtml#_idTextAnchor235"><em class="italic">Chapter 7</em></a>, <em class="italic">Demystifying Kubernetes Networking</em>. The following is a diagram showing a Kubernetes multi-tenancy and multi-cluster comparison: </p>
<div>
<div class="IMG---Figure" id="_idContainer014">
<img alt="Figure 1.7 – Kubernetes multi-tenancy versus multi-cluster " height="802" src="image/Figure_1.7_B18201.jpg" width="1317"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 1.7 – Kubernetes multi-tenancy versus multi-cluster</p>
<h1 id="_idParaDest-31"><a id="_idTextAnchor030"/>Kubernetes in-market distribution and ecosystems</h1>
<p>Kubernetes is<a id="_idIndexMarker077"/> supported <a id="_idIndexMarker078"/>by a fast-growing and vibrant open source community. There are more than 60 known Kubernetes platforms and distributions on the market. On the high level, there are managed Kubernetes and standard Kubernetes distributions from the upstream community. We’re covering a high-level wrap-up for Kubernetes and its ecosystem in this section. </p>
<h2 id="_idParaDest-32"><a id="_idTextAnchor031"/>Upstream vanilla Kubernetes</h2>
<p>Upstream<a id="_idIndexMarker079"/> vanilla<a id="_idIndexMarker080"/> Kubernetes is commonly used when the organization wants to manage the Kubernetes cluster and their own on-premises infrastructure or their cloud-based VM. The source code of Kubernetes distribution comes from the upstream Kubernetes community project. It’s open for contribution, so feel free to<a id="_idIndexMarker081"/> join <a id="_idIndexMarker082"/>any <strong class="bold">Special Interest Group</strong> (<strong class="bold">SIG</strong>) groups; here’s the full list of community groups : <a href="https://github.com/kubernetes/community/blob/master/sig-list.md">https://github.com/kubernetes/community/blob/master/sig-list.md</a>.</p>
<p>If you have any ideas <a id="_idIndexMarker083"/>to share or want to learn from the <a id="_idIndexMarker084"/>community: <a href="https://kubernetes.io/docs/contribute/generate-ref-docs/contribute-upstream/">https://kubernetes.io/docs/contribute/generate-ref-docs/contribute-upstream/</a>.</p>
<h2 id="_idParaDest-33"><a id="_idTextAnchor032"/>Managed Kubernetes</h2>
<p>Cloud vendor-managed <a id="_idIndexMarker085"/>Kubernetes distribution often falls into this category. Managed Kubernetes distribution is usually based on the vanilla Kubernetes cluster, and different vendors build their features on top of that and make it more adaptive to their infrastructure. A managed Kubernetes distribution usually has a control plane managed by the vendor, and users only need to manage the worker nodes and focus<a id="_idIndexMarker086"/> their <a id="_idIndexMarker087"/>energy on <a id="_idIndexMarker088"/>delivering <a id="_idIndexMarker089"/>value <a id="_idIndexMarker090"/>based <a id="_idIndexMarker091"/>on their core expertise. </p>
<p><strong class="bold">Microsoft Azure</strong> provides <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>), <strong class="bold">Amazon Web Service</strong> (<strong class="bold">AWS</strong>) has <strong class="bold">Elastic Kubernetes Service</strong> (<strong class="bold">EKS</strong>), and <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) is proud of its <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>). </p>
<p>Other popular Kubernetes distributions include VMware’s Tanzu, RedHat OpenShift, Canonical’s Charmed Kubernetes, and Kubernetes from Ranger Lab. </p>
<h2 id="_idParaDest-34"><a id="_idTextAnchor033"/>Kubernetes ecosystems</h2>
<p>The Kubernetes <a id="_idIndexMarker092"/>ecosystem is not limited to provisioning and management tools; it has a wide variety of tools for security, networking, observability, and more. It covers all the important aspects of working with Kubernetes. The Kubernetes ecosystem is an important part of the cloud-native landscape. Thanks to Kubernetes being highly portable and platform-agnostic, we can literally take Kubernetes anywhere. It is easy to integrate with a security-sensitive disconnected scenario or integrated with the hybrid scenario as organizations are moving to the cloud. Those tools in the ecosystem are complementary to each other to boost Kubernetes’ tremendous growth as a cloud-native technology and make a positive impact in the community and on the different sizes of businesses. Check out the cloud-native <a id="_idIndexMarker093"/>landscape at <a href="https://landscape.cncf.io">https://landscape.cncf.io</a>.</p>
<p>Learning about Kubernetes and its ecosystem will help you better understand how to work with Kubernetes for your organization and how to help your organization get the best out of <a id="_idIndexMarker094"/>Kubernetes. </p>
<h1 id="_idParaDest-35"><a id="_idTextAnchor034"/>Summary</h1>
<p>This chapter introduced you to some of the core concepts of Kubernetes, and we took a glimpse at the big picture of all the popular Kubernetes distributions on the market. An exciting journey is about to start! </p>
<p>In the next chapter, we’ll dive into the details of the installation and configuration of a Kubernetes cluster. Stay tuned! </p>
</div>
</div></body></html>