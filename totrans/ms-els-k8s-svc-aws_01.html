<html><head></head><body>
		<div id="_idContainer016">
			<h1 id="_idParaDest-15" class="chapter-number"><a id="_idTextAnchor014"/>1</h1>
			<h1 id="_idParaDest-16"><a id="_idTextAnchor015"/>The Fundamentals of Kubernetes and Containers</h1>
			<p>As more organizations adopt agile development and modern (cloud-native) application architectures, the need for a platform that can deploy, scale, and provide reliable container services has become critical for many medium-sized and large companies. Kubernetes has become the de facto platform for hosting container workloads but can be complex to install, configure, <span class="No-Break">and manage.</span></p>
			<p><strong class="bold">Elastic Kubernetes Service</strong> (<strong class="bold">EKS</strong>) is a <a id="_idIndexMarker000"/>managed service that enables users of the AWS platform to focus on using a Kubernetes cluster rather than spending time on installation <span class="No-Break">and maintenance.</span></p>
			<p>In this chapter, we will review the basic building blocks of Kubernetes. Specifically, however, we will be covering the <span class="No-Break">following topics:</span></p>
			<ul>
				<li>A brief history of Docker, containerd, <span class="No-Break">and runc</span></li>
				<li>A deeper dive <span class="No-Break">into containers</span></li>
				<li>What is <span class="No-Break">container orchestration?</span></li>
				<li>What <span class="No-Break">is Kubernetes?</span></li>
				<li>Understanding Kubernetes <span class="No-Break">deployment architectures</span></li>
			</ul>
			<p>For a deeper understanding of the chapter, it is recommended that you have some familiarity with Linux commands <span class="No-Break">and architectures.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">The content in this book is intended for IT professionals that have experience building and/or running Kubernetes on-premises or on other cloud platforms. We recognize that not everyone with the prerequisite experience is aware of the background of Kubernetes so this first chapter is included (but optional) to provide a consistent view of where Kubernetes has come from and the supporting technology it leverages. If you think you already have a clear understanding of the topics discussed in this chapter, feel free to skip this one and move on to the <span class="No-Break">next chapter.</span></p>
			<h1 id="_idParaDest-17"><a id="_idTextAnchor016"/>A brief history of Docker, containerd, and runc</h1>
			<p>The IT industry <a id="_idIndexMarker001"/>has gone through a number of changes: from large, dedicated mainframes and UNIX systems in the 1970s-80s, to the virtualization movement with Solaris Zones, VMware, and the development<a id="_idIndexMarker002"/> of <strong class="bold">cgroups</strong> and <strong class="bold">namespaces</strong> in<a id="_idIndexMarker003"/> the Linux kernel in the early 2000s. In 2008, LXC was released. It provided a way to manage cgroups and namespaces in a consistent way to allow virtualization natively in the Linux kernel. The host system has no concept of a <em class="italic">container</em> so LXC orchestrates the underlying technology to create an isolated set of processes, that is, <span class="No-Break">the container.</span></p>
			<p><strong class="bold">Docker</strong>, launched in 2013, was initially built on top of LXC and introduced a whole ecosystem around container management including a packaging format (the <strong class="bold">Dockerfile</strong>), which<a id="_idIndexMarker004"/> leverages a union filesystem to allow developers to build lightweight container images, and a runtime environment that manages Docker containers, container storage and CPU, RAM limits, and so on, while managing and transferring <a id="_idIndexMarker005"/>images (the <strong class="bold">Docker daemon</strong>) and provides an <strong class="bold">Application Programming Interface</strong> (<strong class="bold">API</strong>) that can<a id="_idIndexMarker006"/> be consumed by the Docker CLI. Docker also provides a set of registries (<strong class="bold">Docker Hub</strong>) that <a id="_idIndexMarker007"/>allows operating systems, middleware, and application vendors to build and distribute their code <span class="No-Break">in containers.</span></p>
			<p>In 2016, Docker <a id="_idIndexMarker008"/>extracted these runtime capabilities into a separate engine called <strong class="bold">containerd</strong> and donated it to<a id="_idIndexMarker009"/> the <strong class="bold">Cloud Native Compute Foundation</strong> (<strong class="bold">CNCF</strong>), allowing other container ecosystems such as Kubernetes to deploy and manage containers. Kubernetes initially used Docker as its container runtime, but in Kubernetes 1.15, the <strong class="bold">Container Runtime Interface</strong> (<strong class="bold">CRI</strong>) was <a id="_idIndexMarker010"/>introduced, which allows Kubernetes to use different runtimes such <span class="No-Break">as containerd.</span></p>
			<p>The <strong class="bold">Open Container Initiative</strong> (<strong class="bold">OCI</strong>) was<a id="_idIndexMarker011"/> founded by Docker and the container industry to help provide a lower-level interface to manage containers. One of the first standards they developed was the OCI Runtime Specification, which adopted the Docker image format as the basis for all of its image specifications. The <strong class="bold">runc</strong> tool <a id="_idIndexMarker012"/>was developed by the OCI to implement its Runtime Specification and has been adopted by most runtime engines, such as containerd, as <a id="_idIndexMarker013"/>a low-level interface to manage containers <span class="No-Break">and images.</span></p>
			<p>The following diagram illustrates how all the concepts we have discussed in this section <span class="No-Break">fit together:</span></p>
			<div>
				<div id="_idContainer011" class="IMG---Figure">
					<img src="image/B18129_01_01.jpg" alt="Figure 1.1 – Container runtimes"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.1 – Container runtimes</p>
			<p>In this section, we <a id="_idIndexMarker014"/>discussed the history of containers and the various technologies used to create and manage them. In the next section, we will dive deeper into what a container actually <span class="No-Break">consists of.</span></p>
			<h1 id="_idParaDest-18"><a id="_idTextAnchor017"/>A deeper dive into containers</h1>
			<p>The <a id="_idIndexMarker015"/>container is a purely logical construction and consists of a set of technologies <em class="italic">glued</em> together by the container runtime. This section will provide a more detailed view of the technologies used in a Linux kernel to create and manage containers. The two foundational Linux services are<a id="_idIndexMarker016"/> namespaces and <span class="No-Break">control groups:</span></p>
			<ul>
				<li><strong class="bold">Namespaces (in the context of Linux)</strong>: A namespace is a feature of the Linux kernel used to partition kernel resources, allowing processes running within the namespace to be isolated from other processes. Each namespace will have its <a id="_idIndexMarker017"/>own <strong class="bold">process IDs</strong> (<strong class="bold">PIDs</strong>), hostname, network access, and <span class="No-Break">so on.</span></li>
				<li><strong class="bold">Control groups</strong>: A<a id="_idIndexMarker018"/> control group (cgroup) is used to limit the usage by a process or set of processes of resources such as CPU, RAM, disk I/O, or network I/O. Originally developed by Google, this technology has been incorporated into the <span class="No-Break">Linux kernel.</span></li>
			</ul>
			<p>The combination of namespaces and control groups in Linux allows a container to be defined as a set of isolated processes (namespace) with resource <span class="No-Break">limits (cgroups):</span></p>
			<div>
				<div id="_idContainer012" class="IMG---Figure">
					<img src="image/B18129_01_02.jpg" alt="Figure 1.2 – The container as a combination of cgroup and namespace"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.2 – The container as a combination of cgroup and namespace</p>
			<p>The way the container runtime image is created is important as it has a direct bearing on how that container <a id="_idIndexMarker019"/>works and is secured. A <strong class="bold">union filesystem</strong> (<strong class="bold">UFS</strong>) is a special filesystem used in container images and will be <span class="No-Break">discussed next.</span></p>
			<h2 id="_idParaDest-19"><a id="_idTextAnchor018"/>Getting to know union filesystems</h2>
			<p>A UFS <a id="_idIndexMarker020"/>is a type of filesystem that can merge/overlay multiple directories/files into a single view. It also gives the appearance of a single writable filesystem, but is read-only and does allow the modification of the original content. The most common example of this <a id="_idIndexMarker021"/>is <strong class="bold">OverlayFS</strong>, which is included in the Linux kernel and used by default <span class="No-Break">by Docker.</span></p>
			<p>A UFS is a very efficient way to merge content for a container image. Each set of discreet content is considered a layer, and layers can be reused between container images. Docker, for example, will use the Dockerfile to create a layered file based on a base image. An example is shown in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer013" class="IMG---Figure">
					<img src="image/B18129_01_03.jpg" alt="Figure 1.3 – Sample Docker image"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.3 – Sample Docker image</p>
			<p>In <span class="No-Break"><em class="italic">Figure 1</em></span><em class="italic">.3</em>, the <strong class="source-inline">FROM</strong> command creates an initial layer from the <strong class="source-inline">ubuntu 18.04</strong> image. The output from the two <strong class="source-inline">RUN</strong> commands creates discreet layers while the final step is for Docker to add a thin read/write layer where all changes to the running container are written. The <strong class="source-inline">MAINTAINER</strong> and <strong class="source-inline">CMD</strong> commands don’t <span class="No-Break">generate layers.</span></p>
			<p>Docker is the most prevalent container runtime environment and can be used on Windows, macOS, and Linux so it provides an easy way to learn how to build and run containers (although please note that the Windows and Linux operating systems are fundamentally different so, at present, you can’t run Windows containers on Linux). While the Docker binaries have been removed from the current version of Kubernetes, the concepts and techniques in the next section will help you understand how containers work at a <span class="No-Break">fundamental level.</span></p>
			<h2 id="_idParaDest-20"><a id="_idTextAnchor019"/>How to use Docker</h2>
			<p>The<a id="_idIndexMarker022"/> simplest way to get started with containers is to use Docker on your development machine. As the OCI has developed standardization for Docker images, images created locally can be used anywhere. If you have already installed Docker, the following command will run a simple container with the official <strong class="source-inline">hello-world</strong> sample image and show <span class="No-Break">its output:</span></p>
			<pre class="console">
$ docker run hello-world
Unable to find image 'hello-world:latest' locally
latest: Pulling from library/hello-world
2db29710123e: Pull complete
...
Status: Downloaded newer image for hello-world:latest
Hello from Docker!</pre>
			<p>This preceding message shows that your installation appears to be working correctly. You can see that the <strong class="source-inline">hello-world</strong> image is “pulled” from a repository. This defaults to the public Docker Hub repositories at <a href="https://hub.docker.com/">https://hub.docker.com/</a>. We will discuss repositories, and in particular, AWS <strong class="bold">Elastic Container Registry</strong> (<strong class="bold">ECR</strong>) in <a href="B18129_11.xhtml#_idTextAnchor162"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, <em class="italic">Building Applications and Pushing Them to </em><span class="No-Break"><em class="italic">Amazon ECR</em></span><span class="No-Break">.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">If you would like to know how to install and run with Docker, you can refer to the <em class="italic">Get Started</em> guide in the Docker official <span class="No-Break">documentation: </span><a href="https://docs.docker.com/get-started/"><span class="No-Break">https://docs.docker.com/get-started/</span></a><span class="No-Break">.</span></p>
			<p>Meanwhile, you can use the following command to list containers on <span class="No-Break">your host:</span></p>
			<pre class="console">
$ docker ps -a
CONTAINER ID   IMAGE  COMMAND      CREATED       STATUS  PORTS     NAMES
39bad0810900   hello-world
"/hello"                  10 minutes ago   Exited (0) 10 minutes ago             distracted_tereshkova
...</pre>
			<p>Although<a id="_idIndexMarker023"/> the preceding commands are simple, they demonstrate how easy it is to build and run containers. When you use the Docker CLI (client), it will interact with the runtime engine, which is the Docker daemon. When the daemon receives the request from the CLI, the Docker daemon proceeds with the corresponding action. In the <strong class="source-inline">docker run</strong> example, this means creating a container from the <strong class="source-inline">hello-world</strong> image. If the image is stored on your machine, it will use that; otherwise, it will try and <em class="italic">pull</em> the image from a public Docker repository such as <span class="No-Break"><em class="italic">Docker Hub</em></span><span class="No-Break">.</span></p>
			<p>As discussed in the previous section, Docker now leverages containerd and runc. You can use the <strong class="source-inline">docker info</strong> command to view the versions of <span class="No-Break">these components:</span></p>
			<pre class="console">
$ docker info
…
  buildx: Docker Buildx (Docker Inc., v0.8.1)
  compose: Docker Compose (Docker Inc., v2.3.3)
  scan: Docker Scan (Docker Inc., v0.17.0)
……
containerd version: 2a1d4dbdb2a1030dc5b01e96fb110a9d9f150ecc
 runc version: v1.0.3-0-gf46b6ba
 init version: de40ad0
...</pre>
			<p>In this section, we looked at the underlying technology used in Linux to support containers. In the following sections, we will look at container orchestration and Kubernetes in <span class="No-Break">more detail.</span></p>
			<h1 id="_idParaDest-21"><a id="_idTextAnchor020"/>What is container orchestration?</h1>
			<p>Docker works <a id="_idIndexMarker024"/>well on a single machine, but what if you need to deploy thousands of containers across many different machines? This is what container orchestration aims to do: to schedule, deploy, and manage hundreds or thousands of <a id="_idIndexMarker025"/>containers across your environment. There are several platforms that attempt to <span class="No-Break">do this:</span></p>
			<ul>
				<li><strong class="bold">Docker Swarm</strong>: A<a id="_idIndexMarker026"/> cluster management and orchestration solution from <span class="No-Break">Docker (</span><span class="No-Break">https://docs.docker.com/engine/swarm/</span><span class="No-Break">).</span></li>
				<li><strong class="bold">Kubernetes </strong>(<strong class="bold">K8s</strong>): An <a id="_idIndexMarker027"/>open source container orchestration system, originally designed by Google and now maintained by CNCF. Thanks to active contributions from the open source community, Kubernetes has a strong ecosystem for a series of solutions regarding deployment, scheduling, scaling, monitoring, and so <span class="No-Break">on (</span><span class="No-Break">https://kubernetes.io/</span><span class="No-Break">).</span></li>
				<li><strong class="bold">Amazon Elastic Container Service </strong>(<strong class="bold">ECS</strong>): A highly secure, reliable, and scalable container<a id="_idIndexMarker028"/> orchestration solution provided by AWS. With a similar concept as many other orchestration systems, ECS also makes it easy to run, stop, and manage containers and is integrated with other AWS services such as CloudFormation, IAM, and ELB, among others (see more <span class="No-Break">at </span><span class="No-Break">https://ecs.aws/</span><span class="No-Break">).</span></li>
			</ul>
			<p>The control/data plane, a common architecture for container orchestrators, is shown in the <span class="No-Break">following diagram:</span></p>
			<div>
				<div id="_idContainer014" class="IMG---Figure">
					<img src="image/B18129_01_04.jpg" alt="Figure 1.4 – An overview of container orchestration"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.4 – An overview of container orchestration</p>
			<p>Container orchestration<a id="_idIndexMarker029"/> usually consists of the <em class="italic">brain</em> or scheduler/orchestrator that decides where to put the containers (control plane), while the <em class="italic">worker</em> runs the actual containers (data plane). The orchestrator offers a number of <span class="No-Break">additional features:</span></p>
			<ul>
				<li>Maintains the desired state for the entire <span class="No-Break">cluster system</span></li>
				<li>Provisions and <span class="No-Break">schedules containers</span></li>
				<li>Reschedules containers when a worker <span class="No-Break">becomes unavailable</span></li>
				<li>Recovery <span class="No-Break">from failure</span></li>
				<li>Scales containers in or out based on workload metrics, time, or some <span class="No-Break">external event</span></li>
			</ul>
			<p>We’ve spoken about container orchestration at the conceptual level, now let’s take a look at Kubernetes to make this <span class="No-Break">concept </span><span class="No-Break"><em class="italic">real</em></span><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-22"><a id="_idTextAnchor021"/>What is Kubernetes?</h1>
			<p>Kubernetes<a id="_idIndexMarker030"/> is an open source container orchestrator originally developed by Google but now seen as the de facto container platform for many organizations. Kubernetes is deployed as clusters containing a control plane that provides an API that exposes the Kubernetes operations, a scheduler that schedules containers (Pods are discussed next) across the worker nodes, a datastore to store all cluster data and state (<strong class="bold">etcd</strong>), and a controller that manages jobs, failures, <span class="No-Break">and restarts.</span></p>
			<div>
				<div id="_idContainer015" class="IMG---Figure">
					<img src="image/B18129_01_05.jpg" alt="Figure 1.5 – An overview of Kubernetes"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 1.5 – An overview of Kubernetes</p>
			<p>The <a id="_idIndexMarker031"/>cluster is also composed of many worker nodes that make up the data plane. Each node runs<a id="_idIndexMarker032"/> the <strong class="bold">kubelet</strong> agent, which makes sure that containers are running on a specific node, and <strong class="bold">kube-proxy</strong>, which manages <a id="_idIndexMarker033"/>the networking for <span class="No-Break">the node.</span></p>
			<p>One of the major advantages of Kubernetes is that all the resources are defined as objects that can be created, read, updated, and deleted. The next section will review the major K8s objects, or “<strong class="bold">kinds</strong>” as they are called, that you will typically be <span class="No-Break">working with.</span></p>
			<h2 id="_idParaDest-23"><a id="_idTextAnchor022"/>Key Kubernetes API resources</h2>
			<p>Containerized <a id="_idIndexMarker034"/>applications will be deployed and launched on a worker node(s) using the API. The API provides an abstract object called a <strong class="bold">Pod</strong>, which<a id="_idIndexMarker035"/> is defined as one or more containers sharing the same Linux namespace, cgroups, network, and storage resources. Let’s look at a simple example of <span class="No-Break">a Pod:</span></p>
			<pre class="source-code">
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80</pre>
			<p>In this example, <strong class="source-inline">kind</strong> defines the API object, a single <strong class="source-inline">Pod</strong>, and <strong class="source-inline">metadata</strong> contains the name of the Pod, in this case, <strong class="source-inline">nginx</strong>. The <strong class="source-inline">spec</strong> section contains one container, which will use the <strong class="source-inline">nginx 1.14.2</strong> image and expose a <span class="No-Break">port (</span><span class="No-Break"><strong class="source-inline">80</strong></span><span class="No-Break">).</span></p>
			<p>In most <a id="_idIndexMarker036"/>cases, you want to deploy multiple Pods across multiple nodes and maintain that number of Pods even if you have node failures. To do this, you use a Deployment, which will keep your Pods running. A Deployment is a Kubernetes <strong class="source-inline">kind</strong> that allows you to define the number of replicas or Pods you want, along with the Pod specification we saw previously. Let’s look at an example that builds on the <strong class="source-inline">nginx</strong> Pod we <span class="No-Break">discussed previously:</span></p>
			<pre class="source-code">
ApiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80</pre>
			<p>Finally, you<a id="_idIndexMarker037"/> want to expose your Pods outside the clusters! This is because, by default, Pods and Deployments are only accessible from inside the cluster’s other Pods. There are various services, but let’s discuss the <strong class="source-inline">NodePort</strong> service here, which exposes a dynamic port on all nodes in the cluster. </p>
			<p>To do this, you will use the <strong class="source-inline">kind</strong> of <strong class="source-inline">Service</strong>, an example of which is <span class="No-Break">shown here:</span></p>
			<pre class="source-code">
kind: Service
apiVersion: v1
metadata:
  name: nginx-service
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
  port: 80
  nodePort: 30163</pre>
			<p>In the <a id="_idIndexMarker038"/>preceding example, <strong class="source-inline">Service</strong> exposes port <strong class="source-inline">30163</strong> on any host in the cluster and maps it back to any Pod that has <strong class="source-inline">label</strong> <strong class="source-inline">app=nginx</strong> (set in the Deployment), even if a host is not running on that Pod. It translates the <strong class="source-inline">port</strong> value to port <strong class="source-inline">80</strong>, which is what the <strong class="source-inline">nginx</strong> Pod is <span class="No-Break">listening on.</span></p>
			<p>In this section, we’ve looked at the basic Kubernetes architecture and some basic API objects. In the final section, we will review some standard <span class="No-Break">deployment architectures.</span></p>
			<h1 id="_idParaDest-24"><a id="_idTextAnchor023"/>Understanding Kubernetes deployment architectures</h1>
			<p>There are <a id="_idIndexMarker039"/>a multitude of ways to deploy Kubernetes, depending on whether you are developing on your laptop/workstation, deploying to non-production or productions, or whether you are building it yourself or using a managed service such <span class="No-Break">as EKS.</span></p>
			<p>The following sections will discuss how Kubernetes can be deployed for different development environments such as locally on your laptop for testing or for <span class="No-Break">production workloads.</span></p>
			<h2 id="_idParaDest-25"><a id="_idTextAnchor024"/>Developer deployment</h2>
			<p>For local <a id="_idIndexMarker040"/>development, you<a id="_idIndexMarker041"/> may want to use a simple deployment such as minikube or Kind. These deploy a full control plane on a virtual machine (minikube) or Docker container (Kind) and allow you to deploy API resources on your local machine, which acts as both the control plane and data plane. The advantages of this approach are that everything is run on your development machine, you can easily build and test your app, and your Deployment manifests . However, you only have one worker node, which means that complex, multi-node application scenarios are <span class="No-Break">not possible.</span></p>
			<h2 id="_idParaDest-26"><a id="_idTextAnchor025"/>Non-production deployments</h2>
			<p>In most cases, non-production deployments <a id="_idIndexMarker042"/>have a non-resilient control plane. This typically means<a id="_idIndexMarker043"/> having a single master node hosting the control plane components (API server, etcd, and so on) and multiple worker nodes. This helps test multi-node application architectures but without the overhead of a complex <span class="No-Break">control plane.</span></p>
			<p>The one exception is integration and/or operational non-production environments where you want to test cluster or application operations in the case of a control plane failure. In this case, you may want to have at least two <span class="No-Break">master nodes.</span></p>
			<h2 id="_idParaDest-27"><a id="_idTextAnchor026"/>Self-built production environments</h2>
			<p>In <a id="_idIndexMarker044"/>production<a id="_idIndexMarker045"/> environments, you will need a resilient control plane, typically following the <em class="italic">rule of 3,</em> where you deploy 3, 6, or 9 control nodes to ensure an odd number of nodes are used to gain a majority during a failure event. The control plane components are mainly stateless, while configuration is stored in etcd. A load balancer can be deployed across the API controllers to provide resilience for K8s API requests; however, a key design decision is how to provide a resilient <span class="No-Break"><strong class="bold">etcd</strong></span><span class="No-Break"> layer.</span></p>
			<p>In the first model, <em class="italic">stacked</em> etcd, etcd is deployed directly on the master nodes making the etcd and Kubernetes topologies tightly coupled (<span class="No-Break">see </span><span class="No-Break">https://d33wubrfki0l68.cloudfront.net/d1411cded83856552f37911eb4522d9887ca4e83/b94b2/images/kubeadm/kubeadm-ha-topology-stacked-etcd.svg</span><span class="No-Break">).</span></p>
			<p>This means if one node fails, both the API layer and data persistence (etcd) layers are affected. A solution to this problem is to use an external etcd cluster hosted on separate machines than the other Kubernetes components, effectively decoupling them (<span class="No-Break">see </span><span class="No-Break">https://d33wubrfki0l68.cloudfront.net/ad49fffce42d5a35ae0d0cc1186b97209d86b99c/5a6ae/images/kubeadm/kubeadm-ha-topology-external-etcd.svg</span><span class="No-Break">).</span></p>
			<p>In the case of the external etcd model, failure in either the API or etcd clusters will not impact the other. It does mean, however, that you will have twice as many machines (virtual or physical) to manage <span class="No-Break">and maintain.</span></p>
			<h2 id="_idParaDest-28"><a id="_idTextAnchor027"/>Managed service environments</h2>
			<p>AWS EKS is<a id="_idIndexMarker046"/> a managed <a id="_idIndexMarker047"/>service where AWS provides the control plane and you connect worker nodes to it using either self-managed or AWS-managed node groups (see <a href="B18129_08.xhtml#_idTextAnchor123"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, <em class="italic">Managing Worker Nodes on EKS</em>). You simply create a cluster and AWS will provision and manage at least two API servers (in two distinct Availability Zones) and a separate etcd autoscaling group spread over three <span class="No-Break">Availability Zones.</span></p>
			<p>The cluster supports a service level of 99.95% uptime and AWS will fix any issues with your control plane. This model means that you don’t have any flexibility in the control plane architecture but, at the same time, you won’t be required to manage it. EKS can be used for test, non-production, and production workloads, but remember there is a cost associated with each cluster (this will be discussed in <a href="B18129_02.xhtml#_idTextAnchor030"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Introducing </em><span class="No-Break"><em class="italic">Amazon EKS</em></span><span class="No-Break">).</span></p>
			<p>Now you’ve learned about several architectures that can be implemented when building a Kubernetes cluster from development to production. In this book, you don’t have to know how to build an entire Kubernetes cluster by yourself, as we will be <span class="No-Break">using EKS.</span></p>
			<h1 id="_idParaDest-29"><a id="_idTextAnchor028"/>Summary</h1>
			<p>In this chapter, we explored the basic concepts of containers and Kubernetes. We discussed the core technical concepts used by Docker, containerd, and runc on Linux systems, as well as scaling deployments using a container orchestration system such <span class="No-Break">as Kubernetes.</span></p>
			<p>We also looked at what Kubernetes is, reviewed several components and API resources, and discussed different deployment architectures for development <span class="No-Break">and production.</span></p>
			<p>In the next chapter, let’s talk about the managed Kubernetes service, <strong class="bold">Amazon Elastic Kubernetes Service</strong> (<strong class="bold">Amazon EKS</strong>), in more detail and learn what its key <span class="No-Break">benefits are.</span></p>
			<h1 id="_idParaDest-30"><a id="_idTextAnchor029"/>Further reading</h1>
			<ul>
				<li><em class="italic">Understanding the </em><span class="No-Break"><em class="italic">EKS SLA</em></span></li>
			</ul>
			<p><span class="No-Break">https://aws.amazon.com/eks/sla/</span></p>
			<ul>
				<li><em class="italic">Understanding the </em><span class="No-Break"><em class="italic">Kubernetes API</em></span></li>
			</ul>
			<p><span class="No-Break">https://kubernetes.io/docs/concepts/overview/kubernetes-api/</span></p>
			<ul>
				<li><em class="italic">Getting started </em><span class="No-Break"><em class="italic">with minikube</em></span></li>
			</ul>
			<p><span class="No-Break">https://minikube.sigs.k8s.io/docs/start/</span></p>
			<ul>
				<li><em class="italic">Getting started </em><span class="No-Break"><em class="italic">with Kind</em></span></li>
			</ul>
			<p><span class="No-Break">https://kind.sigs.k8s.io/docs/user/quick-start/</span></p>
			<ul>
				<li><em class="italic">EKS control plane </em><span class="No-Break"><em class="italic">best practice</em></span></li>
			</ul>
			<p><span class="No-Break">https://aws.github.io/aws-eks-best-practices/reliability/docs/controlplane/</span></p>
			<ul>
				<li><em class="italic">Open Container </em><span class="No-Break"><em class="italic">Initiative document</em></span></li>
			</ul>
			<p><span class="No-Break">https://opencontainers.org/</span></p>
		</div>
		<div>
			<div id="_idContainer017" class="IMG---Figure">
			</div>
		</div>
	</body></html>