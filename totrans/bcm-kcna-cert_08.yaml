- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Following Kubernetes Best Practices
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 遵循Kubernetes最佳实践
- en: We have finally reached the last chapter of the Kubernetes part! Congrats on
    making it here—you’re now more than halfway through becoming **Kubernetes and
    Cloud Native Associate** (**KCNA**) certified!
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们终于到达了Kubernetes部分的最后一章！恭喜你来到这里——你现在已经完成了成为**Kubernetes和云原生助理**（**KCNA**）认证的一半以上！
- en: In this chapter, we are going to discuss some of the best practices for operating
    Kubernetes and some of the security gaps and ways to address those.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将讨论一些操作Kubernetes的最佳实践以及一些安全漏洞和解决方法。
- en: We’ll learn about Kubernetes networking and **network policies** for traffic
    control; restricting access with **role-based access control** (**RBAC**); using
    **Helm** as a K8s package manager, and more. As before, we’ll need the minikube
    setup from the previous chapters to perform a few hands-on exercises.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将学习Kubernetes网络和**网络策略**用于流量控制；使用**基于角色的访问控制**（**RBAC**）来限制访问；使用**Helm**作为K8s的包管理器，等等。和之前一样，我们需要上一章的minikube设置来进行一些实践练习。
- en: 'The topics of this chapter include the following:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的主题包括以下内容：
- en: Kubernetes networking essentials
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes网络基础
- en: RBAC
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RBAC
- en: Helm—the package manager for K8s
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Helm——K8s的包管理器
- en: Kubernetes best practices
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes最佳实践
- en: Let’s get started!
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Kubernetes networking essentials
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes网络基础
- en: Without exaggeration, K8s networking is probably the hardest part to understand,
    and even for very experienced engineers and operators, it might be tough. As you
    hopefully remember from [*Chapter 4*](B18970_04.xhtml#_idTextAnchor048), Kubernetes
    implements the **Container Networking Interface** (**CNI**), which allows us to
    use different overlay network plugins for container networking. Yet there are
    so many CNI providers out there (**Flannel**, **Calico**, **Cilium**, **Weave**,
    and **Canal**, to name a few) that it is easy to get confused. Those providers
    rely on different technologies such as **Border Gateway Protocol** (**BGP**) or
    **Virtual Extensible LAN** (**VXLAN**) to deliver different levels of overlay
    network performance and offer different features.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 毫不夸张地说，K8s网络可能是最难理解的部分，即使是经验非常丰富的工程师和运维人员，也可能会感到困难。希望你还记得在[*第4章*](B18970_04.xhtml#_idTextAnchor048)中提到，Kubernetes实现了**容器网络接口**（**CNI**），这使我们可以使用不同的覆盖网络插件进行容器网络配置。然而，市面上有很多CNI提供商（例如**Flannel**、**Calico**、**Cilium**、**Weave**和**Canal**等），因此很容易感到困惑。这些提供商依赖于不同的技术，如**边界网关协议**（**BGP**）或**虚拟扩展局域网**（**VXLAN**），以提供不同级别的覆盖网络性能，并提供不同的功能。
- en: But don’t worry – for the scope of KCNA, you are not required to know many details.
    For now, we will cover Kubernetes networking essentials.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 但不用担心——在KCNA的范围内，你不需要了解太多细节。目前，我们将介绍Kubernetes网络基础知识。
- en: 'Have a look at the following diagram:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 请查看下图：
- en: '![Figure 8.1 – Kubernetes networking model](img/B18970_08_01.jpg)'
  id: totrans-15
  prefs: []
  type: TYPE_IMG
  zh: '![图8.1 – Kubernetes网络模型](img/B18970_08_01.jpg)'
- en: Figure 8.1 – Kubernetes networking model
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – Kubernetes网络模型
- en: 'As *Figure 8**.1* suggests, there are three types of communication happening
    in a Kubernetes cluster:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 如*图8.1*所示，Kubernetes集群中有三种类型的通信：
- en: '`localhost` because they are collocated together as one unit.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`localhost`，因为它们作为一个单元共同部署。'
- en: '**Pod to pod**—Communication on the level of the overlay network (sometimes
    called the **pod network**) spanning all nodes in the cluster. The overlay network
    makes it possible for a pod on one node to talk with other pods on any nodes in
    a cluster. This kind of communication is often called **East-West** traffic.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Pod到Pod**——在覆盖网络层级上的通信（有时称为**Pod网络**），跨越集群中所有节点。覆盖网络使得一个节点上的pod能够与集群中任何其他节点上的pod进行通信。这种通信通常称为**东西流量**。'
- en: '`NodePort` or a `LoadBalancer` type to expose a pod or a group of pods with
    the same application outside of the cluster. Communication with the outside world
    is also known as **North-South** traffic.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用`NodePort`或`LoadBalancer`类型将一个pod或一组具有相同应用程序的pods暴露到集群外部。与外部世界的通信也称为**南北流量**。
- en: In practice, when a pod needs to communicate with other pods, this will also
    involve Kubernetes’ service discovery mechanism. Since every new pod started in
    Kubernetes automatically gets an IP address in the flat overlay network, it is
    almost impossible to refer to IP addresses in any configuration as addresses change
    all the time. Instead, we will use the `ClusterIP` Service, which automatically
    tracks all changes to the list of endpoints when a new pod comes up or an old
    pod is terminated (refer to [*Chapter 6*](B18970_06.xhtml#_idTextAnchor068) for
    a detailed explanation). Kubernetes also allows the use of **IP Address Management**
    (**IPAM**) plugins to control how pod IP addresses are allocated. By default,
    a single IP pool is used for all pods in a cluster. Using IPAM plugins, it is
    possible to subdivide the overlay network IP pool into smaller blocks and allocate
    pod IP addresses based on annotations or the worker node where a pod is started.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，当一个 Pod 需要与其他 Pod 通信时，这还会涉及 Kubernetes 的服务发现机制。由于 Kubernetes 中每个新启动的 Pod
    会自动获得一个在平面覆盖网络中的 IP 地址，因此几乎不可能在任何配置中引用 IP 地址，因为地址会不断变化。相反，我们将使用 `ClusterIP` 服务，它会在新
    Pod 启动或旧 Pod 终止时自动跟踪所有端点列表的变化（详见 [*第六章*](B18970_06.xhtml#_idTextAnchor068)）。Kubernetes
    还允许使用 **IP 地址管理**（**IPAM**）插件来控制 Pod IP 地址的分配。默认情况下，集群中的所有 Pod 使用单一的 IP 池。使用 IPAM
    插件，可以将覆盖网络 IP 池细分为更小的块，并根据注释或 Pod 启动所在的工作节点来分配 Pod IP 地址。
- en: Moving on, it is important to understand that all pods in the cluster pod network
    can talk to each other *without any restriction* *by default*.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，重要的是要理解，集群中的所有 Pod 网络中的 Pod *默认情况下* 可以相互通信，*没有任何限制*。
- en: Note
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Kubernetes namespaces do not provide network isolation. Pods in namespace `A`
    can reach pods in namespace `B` by their IP address in the pod network and the
    other way around unless restricted by a `NetworkPolicy` resource.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 命名空间不提供网络隔离。命名空间 `A` 中的 Pod 可以通过其在 Pod 网络中的 IP 地址访问命名空间 `B` 中的 Pod，反之亦然，除非通过
    `NetworkPolicy` 资源加以限制。
- en: '`NetworkPolicy` is a resource allowing us to control network traffic flow in
    Kubernetes in an application-centric way. `NetworkPolicy` allows us to define
    how a pod can communicate with other pods (selected via label selectors), pods
    in other namespaces (selected via namespace selector), or IP block ranges.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '`NetworkPolicy` 是一种资源，允许我们以应用程序为中心的方式控制 Kubernetes 中的网络流量。`NetworkPolicy` 允许我们定义
    Pod 如何与其他 Pod（通过标签选择器选择）、其他命名空间中的 Pod（通过命名空间选择器选择）或 IP 地址块范围内的 Pod 通信。'
- en: 'Network policies are essentially a pod-level firewall in Kubernetes that allows
    us to specify which traffic is allowed to and from pods that match selectors.
    A simple example might be when you have one application per Kubernetes namespace
    consisting of many microservices. You might want to disallow communication of
    pods between the namespaces in such a scenario for better isolation. Another example
    scenario: you might want to restrict access to a database running in Kubernetes
    to only pods that need to access it because allowing every pod in the cluster
    to reach the database imposes a security risk.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 网络策略本质上是 Kubernetes 中的一种 Pod 级别防火墙，它允许我们指定哪些流量可以进出与选择器匹配的 Pod。一个简单的例子是，当你有一个每个
    Kubernetes 命名空间下包含多个微服务的应用程序时。你可能想要在这种情况下禁止命名空间之间的 Pod 通信，以便更好地实现隔离。另一个例子是：你可能希望限制对运行在
    Kubernetes 中的数据库的访问，只允许需要访问它的 Pod，因为允许集群中的每个 Pod 访问数据库会带来安全风险。
- en: But why, exactly, do we need to apply network policies in Kubernetes?
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，为什么我们在 Kubernetes 中需要应用网络策略呢？
- en: As applications shifted from monolithic to microservice architectures, this
    added a lot of network-based communication. Monolithic applications have most
    communication happening *within themselves*, as being one big executable program,
    while microservices rely on message buses and web protocols to exchange data,
    which causes an increased amount of **East-West** network traffic that should
    also be secured.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 随着应用程序从单体架构转向微服务架构，这增加了大量基于网络的通信。单体应用程序的绝大部分通信发生在 *内部*，因为它是一个大的可执行程序，而微服务依赖于消息总线和
    Web 协议交换数据，这导致了大量的 **东西向** 网络流量，这些流量也应当得到安全保护。
- en: Under the hood, network policies are implemented by the CNI provider, and to
    use network policies, the provider should support those. For example, `NetworkPolicy`
    definition in our minikube Kubernetes, it will not have any effect on the traffic
    in the cluster. Nevertheless, feel free to check the *Further reading* section
    if you’d like to learn more about K8s networking and network policies.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在底层，网络策略由 CNI 提供商实现，为了使用网络策略，提供商应支持这些策略。例如，在我们的 minikube Kubernetes 中，`NetworkPolicy`
    定义不会对集群中的流量产生任何影响。不过，如果你想深入了解 K8s 网络和网络策略，请查看*进一步阅读*部分。
- en: Coming up next, we will explore RBAC and see how it helps in securing a Kubernetes
    cluster.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将深入探讨 RBAC，看看它如何帮助保障 Kubernetes 集群的安全。
- en: RBAC
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: RBAC
- en: You’ve probably noticed that in our minikube cluster, we have unlimited access
    and control over all resources and namespaces. While this is fine for learning
    purposes, when it comes to running and operating production systems, you’ll most
    likely need to restrict the access. This is where Kubernetes RBAC becomes very
    helpful.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能已经注意到，在我们的 minikube 集群中，我们对所有资源和命名空间都有无限制的访问和控制。虽然这对于学习目的来说是可以的，但在运行和操作生产系统时，你很可能需要限制访问权限。这时，Kubernetes
    RBAC 就变得非常有用。
- en: Kubernetes RBAC
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes RBAC
- en: This is the main security mechanism in Kubernetes to ensure that users only
    have access to resources according to their assigned roles.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 Kubernetes 中的主要安全机制，确保用户仅根据其分配的角色访问资源。
- en: 'A few examples of what can be done with K8s RBAC:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 K8s RBAC 可以做的一些示例：
- en: Restricting access to a specific namespace (for example, production namespace
    or namespace for a certain application) for a limited group of people (such as
    with an administrator role)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制对特定命名空间（例如生产命名空间或某个应用的命名空间）的访问，仅限于一小部分人群（例如具有管理员角色的人员）
- en: Restricting access to be read-only for certain resources
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制对某些资源的只读访问
- en: Restricting access to a certain group of resources (such as **Pod**, **Service**,
    **Deployment**, **Secret**, or anything else)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制对特定资源组的访问（例如，**Pod**、**Service**、**Deployment**、**Secret** 或任何其他资源）
- en: Restricting access to an application that interacts with the Kubernetes API
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 限制对与 Kubernetes API 交互的应用的访问
- en: Kubernetes RBAC is a very powerful mechanism, and it allows us to implement
    the **least privilege** principle, which is considered the best practice for access
    management.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes RBAC 是一个非常强大的机制，它允许我们实施**最小权限**原则，这被认为是访问管理的最佳实践。
- en: Least privilege principle
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 最小权限原则
- en: This is when each user or account receives only the minimum privileges required
    to fulfill their job or process.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是指每个用户或账户仅获得完成其工作或流程所需的最小权限。
- en: As for the scope of the KCNA exam, this is pretty much all you need to know
    about restricting access in Kubernetes. The intention of this book, however, is
    to take you one step further and closer to the real-world scenarios of operating
    a Kubernetes cluster, so we’ll dig a little deeper.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 至于 KCNA 考试的范围，这几乎涵盖了你需要了解的关于 Kubernetes 中访问限制的所有内容。不过，本书的目的是将你带得更进一步，更接近操作 Kubernetes
    集群的真实场景，因此我们将深入探讨。
- en: 'Let’s see what happens when you execute `kubectl apply` or `kubectl create`
    with some resource specification:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看当你执行 `kubectl apply` 或 `kubectl create` 并提供一些资源规范时会发生什么：
- en: '`kubectl` will read the Kubernetes configuration from the file at the `KUBECONFIG`
    environment variable.'
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubectl` 会从 `KUBECONFIG` 环境变量中指定的文件读取 Kubernetes 配置。'
- en: '`kubectl` will discover available Kubernetes APIs.'
  id: totrans-46
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubectl` 会发现可用的 Kubernetes API。'
- en: '`kubectl` will validate the specification provided (for example, for malformed
    YAML).'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kubectl` 会验证提供的规范（例如，检查 YAML 格式是否正确）。'
- en: Send the request to `kube-apiserver` with the spec in the payload.
  id: totrans-48
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将请求与载荷中的规范一起发送到 `kube-apiserver`。
- en: '`kube-apiserver` receives the request and verifies the authenticity of the
    request (for example, *who* made the request).'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`kube-apiserver` 接收请求并验证请求的真实性（例如，*是谁*发起的请求）。'
- en: If the user that did the request is authenticated on the previous step, an authorization
    check is performed (for example, is this user allowed to create/apply the changes
    requested?).
  id: totrans-50
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果在上一步请求的用户已通过身份验证，则会执行授权检查（例如，是否允许该用户创建/应用所请求的更改？）。
- en: 'This is the point where RBAC kicks in and helps the API server decide if the
    request should be permitted or not. In Kubernetes, several RBAC concepts are used
    to define access rules:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 这是 RBAC 发挥作用的地方，它帮助 API 服务器决定是否允许该请求。在 Kubernetes 中，使用多个 RBAC 概念来定义访问规则：
- en: '`ALLOW` permission and no `DENY` rule, and what is not explicitly allowed by
    a role will be *denied*. Role is a namespaced resource and requires a namespace
    to be specified when created.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ALLOW`权限和没有`DENY`规则，角色没有明确允许的内容将会被*拒绝*。角色是一个命名空间资源，创建时需要指定命名空间。'
- en: '**ClusterRole**—Same as *Role*, but a non-namespaced resource. For cluster-wide
    permissions such as granting access to all resources in all namespaces at once
    or granting access to cluster-scoped resources such as *nodes*.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ClusterRole**—与*Role*相同，但它是一个非命名空间资源。用于集群范围的权限，如一次性授予对所有命名空间内所有资源的访问权限，或授予对集群范围内资源（如*节点*）的访问权限。'
- en: '**ServiceAccount**—A resource to give identity to an application running inside
    the *Pod*. It is essentially the same as a normal *User* but used specifically
    for non-human identities that need to interact with the Kubernetes API. Every
    pod in Kubernetes always has an association with a service account.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ServiceAccount**—一种为运行在*Pod*内的应用程序提供身份的资源。它本质上与普通的*User*相同，但专门用于需要与Kubernetes
    API交互的非人工身份。Kubernetes中的每个Pod都总是与一个服务账户关联。'
- en: '**RoleBinding**—This is an entity to apply and grant the permissions defined
    in a Role or in a *ClusterRole* to a *User*, a *Group* of users, or a *ServiceAccount*
    within a specific namespace.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RoleBinding**—这是一个实体，用于在特定命名空间内将Role或*ClusterRole*中定义的权限应用并授予*User*、*Group*（用户组）或*ServiceAccount*。'
- en: '**ClusterRoleBinding**—Like *RoleBinding* but works only for *ClusterRole*
    to apply the rules to all namespaces at once.'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ClusterRoleBinding**—与*RoleBinding*类似，但仅适用于*ClusterRole*，可以将规则应用于所有命名空间。'
- en: '*Figure 8**.2* demonstrates the *RoleBinding* of a *Role A* and a *ClusterRole
    B* to a *Group D* of users and a *ServiceAccount C* within *Namespace E*. The
    rules are additive, meaning that everything that is allowed by merging of *ClusterRole
    B* and *Role A* rules will be allowed:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 8.2* 演示了将*Role A*和*ClusterRole B*通过*RoleBinding*应用于*Namespace E*中的*Group
    D*用户和*ServiceAccount C*。规则是累加的，意味着将*ClusterRole B*和*Role A*规则合并后，允许的所有操作都将被允许：'
- en: '![Figure 8.2 – Application of Role and ClusterRole rules via RoleBinding](img/B18970_08_02.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.2 – 通过RoleBinding应用Role和ClusterRole规则](img/B18970_08_02.png)'
- en: Figure 8.2 – Application of Role and ClusterRole rules via RoleBinding
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – 通过RoleBinding应用Role和ClusterRole规则
- en: While Kubernetes RBAC might seem complex at first, the moment you start applying
    it in practice, it gets much easier and clear. You’ll see that RBAC mechanisms
    are very flexible and granular and allow us to cover all possible scenarios, including
    a case when an application inside the pod needs to access a Kubernetes API.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然Kubernetes RBAC初看可能比较复杂，但一旦你开始实践应用它，它会变得更加简单和清晰。你会发现RBAC机制非常灵活和精细，可以覆盖所有可能的场景，包括当Pod内的应用程序需要访问Kubernetes
    API时的情况。
- en: 'Let’s check the following simple `pod-reader` Role definition:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看以下简单的`pod-reader`角色定义：
- en: '[PRE0]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'It can be used to grant read-only access to pod resources in the `kcna` namespace
    using `RoleBinding`, such as in the following code snippet:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 它可以通过`RoleBinding`授予在`kcna`命名空间内的Pod资源的只读访问权限，如以下代码片段所示：
- en: '[PRE1]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Go ahead and create first a `Role` and then a `RoleBinding` resource in our
    minikube playground:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 继续在我们的minikube游乐场中首先创建一个`Role`，然后创建一个`RoleBinding`资源：
- en: '[PRE2]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: The `RoleBinding` was referencing user `jack` as the only subject, but a single
    `RoleBinding` can also be used to reference any number of users, groups, and service
    accounts.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '`RoleBinding`引用了用户`jack`作为唯一主体，但单个`RoleBinding`也可以用来引用任意数量的用户、组和服务账户。'
- en: 'Now, when it comes to testing permissions, Kubernetes has a very neat feature
    that allows us to check permissions without the actual user credentials (which
    can be an x509 client certificate). The respective `kubectl auth can-I` command
    allows us to verify what is allowed and what is not for a certain user, group,
    or service account. Try the following:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在测试权限时，Kubernetes有一个非常整洁的功能，允许我们在没有实际用户凭据（如x509客户端证书）的情况下检查权限。相应的`kubectl
    auth can-I`命令使我们能够验证特定用户、组或服务账户的允许和不允许的操作。尝试以下操作：
- en: '[PRE3]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'But hey, didn’t we allow it to `get` in our preceding `pod-reader` role definition
    for a user named `jack`? We did, but only in the `kcna` namespace! Let’s try again
    by specifying the namespace:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，嘿，我们不是在之前的`pod-reader`角色定义中允许了用户`jack`进行`get`操作吗？是的，但是仅限于`kcna`命名空间！让我们通过指定命名空间再试一次：
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Looks much better now. How about the creation or deletion of pods? Let’s try
    the following:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 看起来好多了。那么Pod的创建或删除呢？让我们尝试以下操作：
- en: '[PRE5]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'As expected, this is not allowed, just as nothing else is allowed to be done
    with other resources than pods in the `kcna` namespace according to the role and
    binding we’ve created. You’ve probably noticed that the *verbs* in the role definition
    are very precise—we’ve specified `get`, `watch`, and `list`, and they are not
    the same:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 正如预期的那样，这是不允许的，就像我们为 `kcna` 命名空间中其他资源（除了 pod）创建的角色和绑定所限制的一样。你可能已经注意到角色定义中的*动词*非常精确——我们指定了
    `get`、`watch` 和 `list`，它们并不相同：
- en: '`watch` is a verb that allows us to see updates to resources in real time'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`watch` 是一个动词，允许我们实时查看资源的更新。'
- en: '`list` allows us to only list resources, but not to get further details about
    a particular object'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`list` 只允许我们列出资源，但无法获取特定对象的更多细节'
- en: '`get` allows us to retrieve information about a resource, but you need to know
    the name of the resource (to find this out, you’ll need the `list` verb)'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`get` 允许我们检索资源的信息，但你需要知道资源的名称（要找出这个信息，你需要使用 `list` 动词）'
- en: And of course, there are write permission verbs such as `create`, `update`,
    `patch`, and `delete`, which can be a part of a role definition spec.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，也有写权限的动词，如 `create`、`update`、`patch` 和 `delete`，它们可以作为角色定义规范的一部分。
- en: If you’d like to learn more about RBAC, feel free to explore on your own and
    check the materials in the *Further reading* section at the end of the chapter.
    Moving forward, we’re going to learn about the Kubernetes package manager in the
    next section.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于 RBAC 的信息，可以自行探索并查看章节末尾的*进一步阅读*部分的资料。接下来，我们将学习 Kubernetes 包管理器的内容。
- en: Helm – the package manager for K8s
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Helm —— Kubernetes 的包管理器
- en: A package manager for Kubernetes—that might sound confusing at first. We are
    building images with system packages and pushing those to the image registry with
    Docker or another tool. Why do we need a package manager?
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的包管理器——这可能听起来有些困惑。我们使用系统包构建镜像，并通过 Docker 或其他工具将其推送到镜像仓库。那么，我们为什么还需要包管理器呢？
- en: Note
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: This section is not a prerequisite for passing the KCNA exam; however, it is
    strongly recommended reading as it might help you to avoid mistakes when using
    Kubernetes in real-world, practical setups.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 本节内容并不是 KCNA 考试的必备知识；然而，强烈推荐阅读它，因为它可能帮助你在实际使用 Kubernetes 时避免一些错误。
- en: Imagine the following scenario—you are operating a few Kubernetes clusters for
    a small enterprise. Those Kubernetes clusters are similar in size and configuration
    and run exactly the same applications, but for different environments such as
    *development*, *testing*, and *production*. The dev team was pushing for microservices
    architecture, and now there are about 50 microservices that run on Kubernetes
    working together as a part of bigger applications.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 想象一下以下场景——你正在为一家小企业管理几个 Kubernetes 集群。这些 Kubernetes 集群在规模和配置上类似，并且运行完全相同的应用程序，但分别用于不同的环境，如*开发*、*测试*和*生产*。开发团队推动微服务架构，现在大约有
    50 个微服务在 Kubernetes 上运行，作为更大应用的一部分协同工作。
- en: The naive way to manage the Kubernetes specifications for all those would be
    the creation of individual spec files for each microservice and each environment.
    The number of YAML files to maintain might easily grow to over 100, and they will
    likely include a bunch of duplicated code and settings that are even harder to
    manage in the long run. There must be a better way, and using a package manager
    such as Helm is one possible solution.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 管理这些 Kubernetes 规范的天真方法是为每个微服务和每个环境创建单独的规范文件。要维护的 YAML 文件数量可能轻易超过 100 个，并且它们可能会包含大量重复的代码和设置，长期来看更难以管理。肯定有更好的方法，使用像
    Helm 这样的包管理器就是其中一种可能的解决方案。
- en: Let’s clarify that in more detail. Helm is not for building container images
    and packaging application executables inside. Helm is used for the standardized
    management of Kubernetes specifications that represent the payload we want to
    run in Kubernetes clusters.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地澄清一下。Helm 不是用于构建容器镜像并将应用程序可执行文件打包其中的工具。Helm 用于对 Kubernetes 规范进行标准化管理，这些规范代表了我们希望在
    Kubernetes 集群中运行的负载。
- en: Helm
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: Helm
- en: This is a tool for automating the creation, packaging, deployment, and configuration
    of Kubernetes applications. It helps to define, install, and update applications
    on Kubernetes.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个用于自动化创建、打包、部署和配置 Kubernetes 应用程序的工具。它有助于在 Kubernetes 上定义、安装和更新应用程序。
- en: Coming back to the previous example with 50 microservices and 3 environments,
    instead of writing duplicated spec files, with Helm you can create reusable templates
    once and simply apply configuration values that are different based on the environment
    where the application should be deployed.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 回到之前的50个微服务和3个环境的例子，使用Helm，你可以创建一次可重用的模板，避免编写重复的规格文件，并且可以根据应用程序应该部署的环境，简单地应用不同的配置值。
- en: Next, you realize that 20 out of those 50 microservices you run rely on individual
    **Redis** instances, and instead of duplicating the same Redis deployment specification
    with different names 20 times, you create a single one that is templated, reusable,
    and can be simply added as a requirement for other applications that need it.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你会意识到你运行的50个微服务中有20个依赖于独立的**Redis**实例，为了避免重复20次编写相同的Redis部署规格并使用不同的名称，你创建了一个模板化、可重用的单一规格，并可以简单地作为需求添加到其他需要它的应用程序中。
- en: 'In order to understand Helm a little better, let’s talk about its three main
    concepts:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解Helm，我们来谈谈它的三个主要概念：
- en: '**Helm chart**—This is a package that contains all K8s resource definitions
    (specs) required to run an application in Kubernetes. Think of it as the Kubernetes
    equivalent of a Linux **DEB** package, an **RPM** package, or a **Homebrew** formula.'
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Helm chart**——这是一个包含运行Kubernetes应用程序所需的所有K8s资源定义（规格）的包。可以把它看作Kubernetes的等效物，就像Linux的**DEB**包、**RPM**包或**Homebrew**配方一样。'
- en: '**Helm repository**—This is a place where *charts* are collected and shared;
    it could be thought of as a Kubernetes equivalent to the **Python Package Index**
    (**PyPI**) or the **Comprehensive Perl Archive Network** (**CPAN**) for Perl.
    Charts can be downloaded from and uploaded to the *repository*.'
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Helm仓库**——这是收集和共享*charts*的地方；它可以被视为Kubernetes的等效物，就像**Python包索引**（**PyPI**）或**Perl综合档案网络**（**CPAN**）对于Perl一样。*Charts*可以从*仓库*中下载，也可以上传到*仓库*。'
- en: '**Helm release**—This is an instance of a *chart* running in a Kubernetes cluster.
    One *chart* can be installed many times into the same cluster, and on each installation,
    a new release is created. For the previous example with Redis, we can have 1 Redis
    *chart* that we can install 20 times on the same cluster where each installation
    will have its own *release* and *release name*.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Helm发布**——这是在Kubernetes集群中运行的*chart*实例。一个*chart*可以多次安装到同一个集群中，每次安装时都会创建一个新的发布。对于之前提到的Redis示例，我们可以有一个Redis
    *chart*，在同一个集群中安装20次，每次安装都会有自己的*发布*和*发布名称*。'
- en: In a nutshell, Helm installs charts onto Kubernetes, creating a new release
    on each installation. Using Helm repositories, it is very easy to find and reuse
    ready charts for common software to be run on Kubernetes. It is also easy to install
    multiple charts together that need to work as one application by specifying dependencies
    between the charts.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 总而言之，Helm将charts安装到Kubernetes中，每次安装时都会创建一个新的发布。通过Helm仓库，非常容易找到并重用适用于Kubernetes运行的常见软件的现成charts。通过指定charts之间的依赖关系，也可以轻松地将多个charts一起安装，作为一个应用程序共同工作。
- en: 'Helm comes with a CLI tool that is also called `helm`. Using the `helm` CLI
    tool, we can search chart repositories, package charts, install, update, and delete
    releases, and do pretty much anything else that Helm allows. Helm uses the same
    Kubernetes config file that `kubectl` is using and interacts directly with the
    Kubernetes API, as shown in *Figure 8**.3*:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Helm附带了一个CLI工具，也叫做`helm`。使用`helm` CLI工具，我们可以搜索chart仓库、打包charts、安装、更新和删除发布，并且几乎可以做Helm允许的所有操作。Helm使用与`kubectl`相同的Kubernetes配置文件，并直接与Kubernetes
    API交互，如*图8.3*所示：
- en: '![Figure 8.3 – Helm v3 architecture](img/B18970_08_03.jpg)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![图8.3 – Helm v3架构](img/B18970_08_03.jpg)'
- en: Figure 8.3 – Helm v3 architecture
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.3 – Helm v3架构
- en: Helm also makes updates and rollbacks of applications easier. If something goes
    wrong with the changes introduced by the release, one simple command—`helm rollback`
    —can help to go back to the previous release version in a matter of seconds or
    minutes. Rollbacks with Helm are similar to the Kubernetes Deployment rollbacks
    that we have tried before in [*Chapter 6*](B18970_06.xhtml#_idTextAnchor068),
    but the difference is that Helm can roll back any chart spec changes. For example,
    you have modified a Secret spec file that is a part of a Helm chart and triggered
    `helm upgrade` to roll out the changes. A few moments later, you realize that
    the change broke the chart application, and you need to get back to the previous
    version quickly. You execute `helm rollback` with an optional release revision
    and release name and get back to the working revision.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: Helm 还使得应用程序的更新和回滚变得更加简单。如果发布的变更出现问题，一个简单的命令——`helm rollback`——可以在几秒钟或几分钟内将你带回到之前的发布版本。使用
    Helm 回滚与我们之前在[*第 6 章*](B18970_06.xhtml#_idTextAnchor068)中尝试过的 Kubernetes 部署回滚类似，但不同之处在于
    Helm 可以回滚任何图表规格的更改。例如，你修改了一个属于 Helm 图表的 Secret 规格文件，并触发了 `helm upgrade` 来推出这些更改。几分钟后，你发现这些更改破坏了图表应用程序，需要快速恢复到先前的版本。你可以执行
    `helm rollback` 命令，指定可选的发布修订版和发布名称，迅速恢复到工作版本。
- en: At this time, we are not going to dive deeper into Helm and do any hands-on
    assignments because, again, Helm is not a part of the KCNA exam. The goal of this
    section is to give you a quick introduction to Helm—a tool that significantly
    simplifies the management of applications on Kubernetes. Helm is a graduated `if`/`else`/`with`/`range`,
    and so on).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 在此，我们不会深入探讨 Helm 或进行任何动手实验，因为 Helm 并不属于 KCNA 考试的一部分。本节的目标是为你快速介绍 Helm——一个大大简化
    Kubernetes 上应用管理的工具。Helm 是一个包含 `if`/`else`/`with`/`range` 等功能的工具。
- en: You can also consider other tools such as **Kustomize** and **YTT** that serve
    the same purpose yet follow a different approach. Neither is a part of KCNA, but
    as usual, the *Further reading* section will include resources about those if
    you’d like to go the extra mile.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以考虑其他工具，如**Kustomize**和**YTT**，它们实现了相同的目标，但采用了不同的方法。这些工具都不属于 KCNA 考试的一部分，但和往常一样，*进一步阅读*部分将包括这些工具的相关资源，如果你愿意深入了解。
- en: Kubernetes best practices
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 最佳实践
- en: While KCNA is not a security-focused certification, you are expected to know
    a few basics and best practices about Kubernetes and Cloud Native, and now is
    the time to talk about those.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 KCNA 认证并不是一个安全性聚焦的认证，但你需要了解一些关于 Kubernetes 和 Cloud Native 的基本知识和最佳实践，现在是时候讨论这些内容了。
- en: 'Kubernetes’ documentation suggests the **4Cs of Cloud Native security**: *Cloud*,
    *Clusters*, *Containers*, and *Code*—an approach with four layers for in-depth
    defense:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的文档建议了**Cloud Native 安全的 4Cs**：*Cloud*、*Clusters*、*Containers* 和
    *Code*——这是一个具有四层深入防御的方法：
- en: '![Figure 8.4 – 4Cs of Cloud Native security](img/B18970_08_04.jpg)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4 – Cloud Native 安全的 4Cs](img/B18970_08_04.jpg)'
- en: Figure 8.4 – 4Cs of Cloud Native security
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – Cloud Native 安全的 4Cs
- en: In this approach, the inner circle security builds upon the next outermost layers.
    This way, the *Code* layer is protected by the bases of the *Container*, *Cluster*,
    and *Cloud* layers, and you cannot safeguard against poor security standards and
    practices in the base layers by addressing the security on the level of *Code*,
    just as you cannot disregard the need to secure the innermost circle even when
    you have very strong security in the outer layers. Let’s see why in more detail
    and what each layer of the 4Cs means.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种方法中，内圈安全性建立在外层的基础上。这样，*Code* 层受到 *Container*、*Cluster* 和 *Cloud* 层的保护，你无法仅通过在
    *Code* 层进行安全防护来解决基础层存在的不良安全标准和实践问题，就像即使外层有很强的安全性，你也不能忽视保护最内层的需要。让我们更详细地了解一下，看看
    4Cs 中的每一层代表了什么。
- en: Starting with the base, the cloud or other infrastructure (such as a corporate
    database or co-located servers) acts as a trusted base for the Kubernetes cluster.
    If the *Cloud* layer is vulnerable or misconfigured, there is no guarantee that
    the components built on top are secure.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 从基础层开始，云或其他基础设施（例如企业数据库或共置服务器）作为 Kubernetes 集群的可信基础。如果 *Cloud* 层存在漏洞或配置错误，那么构建在其上的组件就无法保证安全。
- en: At the beginning of the book, we discussed what the *shared responsibility model*
    means in the cloud, where both the cloud provider and the users must take action
    in order to keep workloads safe and secure. Therefore, always refer to and follow
    the security documentation from your cloud provider.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在书的开始部分，我们讨论了云中的*共享责任模型*的含义，其中云提供商和用户都必须采取措施，以确保工作负载的安全。因此，始终参考并遵循云提供商的安全文档。
- en: When it comes to the *Cluster* layer, there are multiple best practices for
    Kubernetes— specifically, things such as *etcd* encryption, RBAC configuration,
    limiting access to nodes, restricting API server access, keeping the Kubernetes
    version up to date, and more. But don’t worry—you are not required to memorize
    any of those to pass the KCNA exam.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 说到*集群*层，Kubernetes 有许多最佳实践——具体来说，包括*etcd*加密、RBAC配置、限制对节点的访问、限制API服务器访问、保持Kubernetes版本更新等。但不用担心——你不需要记住这些内容就能通过
    KCNA 考试。
- en: Next is the *Container* layer. As you might remember from [*Chapter 4*](B18970_04.xhtml#_idTextAnchor048),
    there are *Namespaced*, *Sandboxed*, and *Virtualized* containers, and they all
    have their pros and cons, *Virtualized* being the most secure yet *heavy*, and
    *Namespaced* the most lightweight, but sharing the same host kernel and thus providing
    lower levels of security. Which one to run depends on the workload and other requirements
    you might have. Also, avoid running applications in containers as the `root` user.
    Doing so means there is a high chance of the whole node with all other containers
    being compromised if that `root` container is compromised.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是*容器*层。如你在[*第4章*](B18970_04.xhtml#_idTextAnchor048)中可能记得的那样，容器有*命名空间*、*沙箱*和*虚拟化*三种类型，它们各有优缺点，*虚拟化*最安全但*笨重*，*命名空间*最轻量，但共享同一宿主机内核，因此安全性较低。运行哪种容器取决于工作负载及其他要求。此外，避免在容器中以`root`用户身份运行应用程序。如果`root`容器被攻破，那么整个节点和所有其他容器都可能面临被攻破的高风险。
- en: And reaching the middle, at the core is the *Code* layer. You should not run
    sources that you don’t trust—for example, if you don’t know the origin of the
    code or exactly what it does. We also discussed that aspect in detail in [*Chapter
    4*](B18970_04.xhtml#_idTextAnchor048). Container images that you’ve found somewhere
    might package malicious code inside, and running those in your environment can
    open a backdoor for an attacker. At a minimum, build and test the code you execute
    yourself and automate vulnerability scanning as a part of the container image
    build process.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 到达中间层时，核心是*代码*层。你不应运行你不信任的源代码——例如，如果你不知道代码的来源或具体功能。我们在[*第4章*](B18970_04.xhtml#_idTextAnchor048)中也详细讨论了这个方面。你在某处找到的容器镜像可能会封装恶意代码，运行这些代码会在你的环境中为攻击者打开一个后门。至少，你应该自己构建和测试运行的代码，并将漏洞扫描自动化，作为容器镜像构建过程的一部分。
- en: Should you be running Kubernetes clusters over unsecured or public networks,
    consider implementing a service mesh to encrypt all pod traffic. Otherwise, by
    default, Kubernetes’ overlay network transports all data unencrypted, although
    a few CNI providers support **Transport Layer Security** (**TLS**) too. Consider
    using network policies to isolate and further protect your workloads. The right
    way to do it is to *deny* all communication between pods by default and put tailored
    *allow* rules for each application and microservice in place. And yes, you can
    have both a service mesh and network policies in one cluster, and their usage
    is not exclusive.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在不安全或公共网络上运行 Kubernetes 集群，考虑实施服务网格来加密所有 pod 流量。否则，Kubernetes 默认的覆盖网络会以未加密的方式传输所有数据，尽管一些
    CNI 提供商也支持**传输层安全协议**（**TLS**）。考虑使用网络策略来隔离并进一步保护你的工作负载。正确的做法是默认*拒绝*所有 pod 之间的通信，并为每个应用程序和微服务制定定制的*允许*规则。是的，你可以在一个集群中同时使用服务网格和网络策略，它们的使用并不互相排斥。
- en: 'Finally, a few basic good practices when dealing with Kubernetes. Some might
    be a repetition of what we have learned, but better repeat twice than learn the
    *hard way* *later on*:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，在处理 Kubernetes 时，有一些基本的良好实践。它们可能是我们所学内容的重复，但“温故而知新”总比*事后吃苦*要好：
- en: '**Use controllers** **to create**'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用控制器** **创建**'
- en: Simple pod specification does not provide fault tolerance and any additional
    functions such as rolling updates. Use `Deployment`, `StatefulSet`, `DaemonSet`,
    or `Job` controllers to create pods.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 简单的 pod 规格不提供容错性及任何额外功能，如滚动更新。使用`Deployment`、`StatefulSet`、`DaemonSet`或`Job`控制器来创建
    pod。
- en: '**Use namespaces to** **organize workloads**'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用命名空间** **组织工作负载**'
- en: Deploying everything into one, default namespace will quickly make it a mess.
    Create multiple namespaces for better workload organization and ease of operation.
    Namespaces are also great for RBAC configuration and restricting traffic with
    network policies.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有内容都部署到一个默认的命名空间中很快会变得一团糟。创建多个命名空间以更好地组织工作负载，并简化操作。命名空间对于 RBAC 配置以及通过网络策略限制流量也非常有用。
- en: '**Use resource requests** **and limits**'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用资源请求** **和限制**'
- en: These are required for Kubernetes to make the best scheduling decisions and
    protect clusters against misbehaving applications utilizing all resources and
    causing nodes to crash.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是 Kubernetes 做出最佳调度决策和保护集群免受恶意应用程序占用所有资源导致节点崩溃所必需的。
- en: '**Use readiness and** **liveness probes**'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用就绪和** **存活探针**'
- en: These ensure that requests reach pods only when they *are ready* to process
    those. If we don’t define `readinessProbe` and the application takes too long
    to start, then all requests forwarded to that pod will fail or time out first.
    `livenessProbe` is just as important because it will make the container restart
    in case its process is caught in a deadlock or stuck.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可以确保请求仅在 Pod *准备好* 处理时到达。如果我们没有定义 `readinessProbe` 且应用程序启动过慢，那么所有转发到该 Pod
    的请求都会失败或超时。`livenessProbe` 同样重要，因为它可以在容器的进程陷入死锁或卡住时重新启动容器。
- en: '**Use small container images** **when possible**'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**尽可能使用小的容器镜像**'
- en: Avoid installing optional packages into container images you’re building and
    try to get rid of all unnecessary packages. Large images take longer to download
    (and thus more time for the pod to start first) and consume more disk space. Specialized,
    minimal images such as **Alpine** can only be 5-10 MB in size.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 避免在构建的容器镜像中安装可选的包，并尽量去除所有不必要的包。大镜像下载时间较长（因此，Pod 启动时也会花费更多时间），并且占用更多磁盘空间。像**Alpine**这样的专用精简镜像大小仅为
    5-10 MB。
- en: '**Use labels** **and annotations**'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用标签** **和注解**'
- en: Add metadata to Kubernetes resources to organize your cluster workloads. This
    is helpful for operations and for tracking how different applications interact
    with each other. The K8s documentation recommends including `name`, `instance`,
    `version`, `component`, `part-of`, and other labels. Where labels are used to
    identify resources, annotations are used to store additional information about
    K8s resources (`last-updated`, `managed-by`, and so on).
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 向 Kubernetes 资源添加元数据，以便组织集群中的工作负载。这对操作和追踪不同应用程序之间的交互非常有帮助。K8s 文档建议包括 `name`、`instance`、`version`、`component`、`part-of`
    和其他标签。标签用于标识资源，而注解则用于存储关于 K8s 资源的额外信息（如 `last-updated`、`managed-by` 等）。
- en: '**Use multiple nodes and** **topology awareness**'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用多个节点和** **拓扑感知**'
- en: Use an uneven number of control plane nodes (such as 3 or 5) to avoid *split-brain*
    situations and use multiple worker nodes spread across multiple failure domains
    (such as **availability zones** or **AZs**) where possible. Apply pod topology
    spread constraints or anti-affinity rules to ensure that all replicas of microservices
    are not running on the same node.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 使用奇数个控制平面节点（如 3 或 5）来避免 *脑裂* 情况，并尽可能使用分布在多个故障域（如**可用区**或**AZs**）的多个工作节点。应用 Pod
    拓扑分布约束或反亲和性规则，以确保微服务的所有副本不会都运行在同一个节点上。
- en: The list can be extended with many further points, but this should be enough
    to let you continue in the right direction with Kubernetes. Monitoring and observability
    topics will be discussed additionally in the upcoming chapters.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这个列表可以扩展为更多的内容，但这些应该足够让你在使用 Kubernetes 时朝着正确的方向前进。监控和可观测性的话题将在后续章节中进一步讨论。
- en: Summary
  id: totrans-130
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: With that, we’ve reached the end of the Kubernetes part – well done!
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，我们就完成了 Kubernetes 部分的内容——做得好！
- en: Remember – the more hands-on you get, the faster you’ll learn and understand
    Kubernetes and its concepts. If some points still feel a bit blurry, that is fine.
    You can always go back and read some parts again and check the *Further reading*
    sections at the end of each cha[pter. Refer to the official Kube](https://kubernetes.io/docs/home/)rnetes
    documentation at [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/)
    if you have any questions.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 记住——你动手实践越多，学习和理解 Kubernetes 及其概念的速度就越快。如果某些点仍然有些模糊，那也没关系。你可以随时回去重新阅读一些部分，并查看每章结尾的
    *进一步阅读* 部分。如果有任何问题，请参考官方的 [Kubernetes 文档](https://kubernetes.io/docs/home/)。
- en: This chapter discussed which three types of network communication happen in
    a Kubernetes cluster and that by default, there is nothing restricting communication
    between two pods in the cluster. Therefore, it is a good idea to use network policies
    in order to only allow required communication and deny the rest for security reasons.
    Not all CNI providers support network policies, therefore make sure to check that
    when planning a Kubernetes installation.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 本章讨论了 Kubernetes 集群中发生的三种类型的网络通信，并且默认情况下，集群中的两个 Pod 之间没有任何限制通信。因此，使用网络策略来只允许必要的通信并拒绝其余通信是一个好主意，出于安全原因。并非所有
    CNI 提供商都支持网络策略，因此在规划 Kubernetes 安装时，确保检查这一点。
- en: Every new pod in the cluster automatically gets an IP address in the overlay
    network, and Kubernetes also takes care of cleaning it up when a pod is terminated.
    However, using pod IP addresses in any configuration is not practical, and we
    should use Kubernetes Services for both **East-West** and **North-South** communication.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 集群中的每个新 Pod 都会自动获得覆盖网络中的 IP 地址，Kubernetes 也会在 Pod 被终止时自动清理该 IP 地址。然而，在任何配置中使用
    Pod 的 IP 地址并不实际，我们应该使用 Kubernetes 服务来处理 **东-西** 和 **南-北** 的通信。
- en: Next, we learned about the RBAC features of Kubernetes and how they allow restricting
    access to the API. It is strongly recommended to implement RBAC rules for any
    cluster that is accessed by more than one person or if an application running
    in Kubernetes talks with the K8s API.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们学习了 Kubernetes 的 RBAC 功能，以及它们如何限制对 API 的访问。强烈建议为任何由多个人访问的集群，或者在 Kubernetes
    中运行的应用程序与 K8s API 交互时，实施 RBAC 规则。
- en: Managing a large number of microservices and environments might be challenging,
    and a package manager tool can become very handy. Helm is a powerful tool for
    packaging, configuring, and deploying Kubernetes applications. We’ve seen that
    Helm introduces additional concepts of charts, repositories, and releases.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 管理大量微服务和环境可能是一个挑战，一个包管理工具会非常有用。Helm 是一个强大的工具，用于打包、配置和部署 Kubernetes 应用程序。我们已经看到，Helm
    引入了额外的概念，如 chart、仓库和发布。
- en: 'When it comes to security, Kubernetes suggests a 4Cs layered approach: *Cloud*,
    *Clusters*, *Containers*, and *Code*. Each layer requires its own practices and
    actions to be taken, and only together do they make infrastructure and workloads
    secure. Depending on the security requirements and the K8s cluster setup, it might
    be necessary to use virtualized containers instead of namespaced containers and
    have a service mesh integrated to encrypt pod traffic.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 关于安全性，Kubernetes 提出了 4Cs 分层方法：*云*，*集群*，*容器*，和*代码*。每一层都需要采取相应的实践和措施，只有这些层一起工作，才能确保基础设施和工作负载的安全。根据安全要求和
    K8s 集群的设置，可能需要使用虚拟化容器而不是命名空间容器，并集成服务网格以加密 Pod 流量。
- en: Finally, we collected seven basic Kubernetes practices based on materials from
    this and previous chapters that should help to get you moving in the right direction.
    In the upcoming chapter, we will continue exploring the world of Cloud Native
    and learn about Cloud Native architectures.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们总结了七个基本的 Kubernetes 实践，基于本章和前几章的材料，这些实践应有助于你朝着正确的方向前进。在接下来的章节中，我们将继续探索云原生世界，并学习关于云原生架构的内容。
- en: Questions
  id: totrans-139
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'As we conclude, here is a list of questions for you to test your knowledge
    regarding this chapter’s material. You will find the answers in the *Assessments*
    section of the *Appendix*:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们总结时，以下是一些问题，供你测试自己对本章内容的理解。你可以在*附录*的*评估*部分找到答案：
- en: Which of the following is another name for pod-to-pod network traffic?
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个是 Pod 之间网络流量的另一种说法？
- en: East-South
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 东-西
- en: North-East
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 东-北
- en: East-West
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 东-西
- en: North-South
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 南-北
- en: What can be applied to restrict pod-to-pod traffic?
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以应用什么来限制 Pod 之间的流量？
- en: '`PodPolicy`'
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`PodPolicy`'
- en: '`PodSecurityPolicy`'
  id: totrans-148
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`PodSecurityPolicy`'
- en: '`TrafficPolicy`'
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`TrafficPolicy`'
- en: '`NetworkPolicy`'
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`NetworkPolicy`'
- en: Which layers are part of the 4Cs of Cloud Native security?
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪些层是云原生安全性 4Cs 的组成部分？
- en: Cloud, Collocations, Clusters, Code
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 云，联合，集群，代码
- en: Cloud, Clusters, Containers, Code
  id: totrans-153
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 云，集群，容器，代码
- en: Cloud, Collocations, Containers, Code
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 云，联合，容器，代码
- en: Code, Controllers, Clusters, Cloud
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码，控制器，集群，云
- en: Pod A is running in Namespace A and pod B is running in Namespace B. Can they
    communicate via their IP addresses?
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pod A 在命名空间 A 中运行，Pod B 在命名空间 B 中运行。它们可以通过各自的 IP 地址通信吗？
- en: No, because different namespaces are isolated with a firewall
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不是，因为不同的命名空间通过防火墙隔离
- en: Yes, but only if they are running on the same worker node
  id: totrans-158
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是的，但只有在它们运行在同一个工作节点上时
- en: Yes, if not restricted with `NetworkPolicy`
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 是的，如果没有通过 `NetworkPolicy` 限制
- en: No, because different namespaces have different IP **Classless Inter-Domain
    Routing** (**CIDR**) blocks
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不，因为不同的命名空间有不同的 IP **无类域间路由**（**CIDR**）块
- en: How do two containers in the same pod communicate?
  id: totrans-161
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同一 Pod 中的两个容器如何通信？
- en: Via a network policy
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过网络策略
- en: Via `localhost`
  id: totrans-163
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 `localhost`
- en: Via the `NodeIP` Service
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 `NodeIP` 服务
- en: Via the `ClusterIP` Service
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过 `ClusterIP` 服务
- en: Which of the following service types is typically used for internal pod-to-pod
    communication?
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪种服务类型通常用于内部 Pod 到 Pod 的通信？
- en: '`InternalIP`'
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`InternalIP`'
- en: '`LoadBalancer`'
  id: totrans-168
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`LoadBalancer`'
- en: '`ClusterIP`'
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ClusterIP`'
- en: '`NodePort`'
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`NodePort`'
- en: What can be used to encrypt pod-to-pod communication in a cluster?
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以用什么来加密集群中 Pod 之间的通信？
- en: '`NetworkPolicy`'
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`NetworkPolicy`'
- en: Service mesh
  id: totrans-173
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务网格
- en: '`EncryptionPolicy`'
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`EncryptionPolicy`'
- en: Security Service
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安全服务
- en: Which of the following container types provides maximum isolation?
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪种容器类型提供最大的隔离？
- en: Virtualized
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 虚拟化
- en: Namespaced
  id: totrans-178
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Namespaced
- en: Isolated
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 隔离
- en: Sandboxed
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 沙盒化
- en: What can be used to restrict access to the Kubernetes API?
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 可以用什么来限制对 Kubernetes API 的访问？
- en: Service mesh
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务网格
- en: Helm
  id: totrans-183
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Helm
- en: Network policies
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络策略
- en: RBAC
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: RBAC
- en: Why is it important to build your own container images?
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么构建自己的容器镜像很重要？
- en: Newly built images are often smaller in size
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新构建的镜像通常体积更小
- en: Due to copyrights and license restrictions
  id: totrans-188
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 由于版权和许可限制
- en: Newly built images always include the newest packages
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 新构建的镜像总是包含最新的软件包
- en: Images found on the internet might include malware
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络上的镜像可能包含恶意软件
- en: Which of the following can be used to provide fault tolerance for pods (pick
    multiple)?
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪项可以用来为 Pods 提供容错能力（可以选择多个）？
- en: Service
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务
- en: Deployment
  id: totrans-193
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署
- en: Ingress
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ingress
- en: StatefulSet
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: StatefulSet
- en: Why it is better to have three and not four control plane nodes?
  id: totrans-196
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么最好使用三个控制平面节点，而不是四个？
- en: Because four nodes consume too many resources; three is enough
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为四个节点消耗太多资源，三个节点就足够了
- en: An uneven number of nodes helps prevent split-brain situations
  id: totrans-198
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 不等数目的节点有助于防止脑裂情况
- en: More nodes make the overlay pod network slower
  id: totrans-199
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更多节点会使覆盖的 Pod 网络变慢
- en: More nodes introduce more operational burden for version upgrades
  id: totrans-200
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更多节点会带来更多的运维负担，尤其是在版本升级时
- en: Why is it not recommended to use pod IP addresses in `ConfigMap` configurations?
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为什么不建议在 `ConfigMap` 配置中使用 Pod 的 IP 地址？
- en: Because pods are ephemeral
  id: totrans-202
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为 Pods 是短暂的
- en: Because the pod IP is not reachable from the internet
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为 Pod 的 IP 无法从互联网访问
- en: Because pods are using an old IPv4 protocol
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为 Pods 使用的是旧版 IPv4 协议
- en: Because it is hard to remember IP addresses
  id: totrans-205
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 因为很难记住 IP 地址
- en: What could be the reasons why a request forwarded to a running pod ends up in
    a timeout error (pick multiple)?
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将请求转发到正在运行的 Pod 可能会导致超时错误的原因是什么（可以选择多个）？
- en: The Kubernetes API overloaded, affecting all pods
  id: totrans-207
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes API 过载，影响所有 Pods
- en: Network policy rules add additional network latency
  id: totrans-208
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 网络策略规则增加额外的网络延迟
- en: A process in a pod is stuck and no `livenessProbe` is set
  id: totrans-209
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pod 中的进程卡住且没有设置 `livenessProbe`
- en: A process in a pod is still starting and no `readinessProbe` is set
  id: totrans-210
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pod 中的进程仍在启动中，且没有设置 `readinessProbe`
- en: Which RBAC entity is used to give an identity to an application?
  id: totrans-211
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个 RBAC 实体用于给应用程序分配身份？
- en: '`Role`'
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Role`'
- en: '`ServiceAccount`'
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ServiceAccount`'
- en: '`RoleBinding`'
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`RoleBinding`'
- en: '`ServiceIdentity`'
  id: totrans-215
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ServiceIdentity`'
- en: Further reading
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多本章覆盖的主题，请查看以下资源：
- en: 'Network policies: [https://kubernetes.io/docs/concepts/services-networking/network-policies/](https://kubernetes.io/docs/concepts/services-networking/network-policies/)'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '网络策略: [https://kubernetes.io/docs/concepts/services-networking/network-policies/](https://kubernetes.io/docs/concepts/services-networking/network-policies/)'
- en: 'Network policies with miniKube Kubernetes: [https://minikube.sigs.k8s.io/docs/handbook/network_policy/](https://minikube.sigs.k8s.io/docs/handbook/network_policy/)'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '使用 miniKube Kubernetes 的网络策略: [https://minikube.sigs.k8s.io/docs/handbook/network_policy/](https://minikube.sigs.k8s.io/docs/handbook/network_policy/)'
- en: 'RBAC: [https://kubernetes.io/docs/reference/access-authn-authz/rbac/](https://kubernetes.io/docs/reference/access-authn-authz/rbac/)'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'RBAC: [https://kubernetes.io/docs/reference/access-authn-authz/rbac/](https://kubernetes.io/docs/reference/access-authn-authz/rbac/)'
- en: 'Helm quickstart guide: [https://helm.sh/docs/intro/quickstart/](https://helm.sh/docs/intro/quickstart/)'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Helm 快速入门指南: [https://helm.sh/docs/intro/quickstart/](https://helm.sh/docs/intro/quickstart/)'
- en: 'Kustomize: [https://kustomize.io/](https://kustomize.io/)'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kustomize: [https://kustomize.io/](https://kustomize.io/)'
- en: 'YTT: [https://carvel.dev/ytt/](https://carvel.dev/ytt/)'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'YTT: [https://carvel.dev/ytt/](https://carvel.dev/ytt/)'
- en: '4Cs of Cloud Native security: [https://kubernetes.io/docs/concepts/security/overview/](https://kubernetes.io/docs/concepts/security/overview/)'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云原生安全的4Cs：[https://kubernetes.io/docs/concepts/security/overview/](https://kubernetes.io/docs/concepts/security/overview/)
- en: 'Recommended Kubernetes labels: [https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/](https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/)'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 推荐的Kubernetes标签：[https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/](https://kubernetes.io/docs/concepts/overview/working-with-objects/common-labels/)
- en: 'Kubernetes in a production environment: [https://kubernetes.io/docs/setup/production-environment/](https://kubernetes.io/docs/setup/production-environment/)'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 在生产环境中： [https://kubernetes.io/docs/setup/production-environment/](https://kubernetes.io/docs/setup/production-environment/)
- en: 'Part 4: Exploring Cloud Native'
  id: totrans-227
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第4部分：探索云原生
- en: This part will explain in more detail what is behind cloud native, what makes
    an application cloud native, and which concepts should apply to cloud native applications,
    as well as how to deliver and operate such applications in modern environments.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分将更详细地解释云原生背后的概念，什么使得应用成为云原生应用，哪些概念应该应用于云原生应用，以及如何在现代环境中交付和运营这些应用。
- en: 'This part contains the following chapters:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 9*](B18970_09.xhtml#_idTextAnchor095), *Understanding Cloud Native
    Architectures*'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B18970_09.xhtml#_idTextAnchor095)，*理解云原生架构*'
- en: '*Chapter 10*, *Implementing Telemetry and Observability in the Cloud*'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*第10章*，*在云中实现遥测与可观察性*'
- en: '[*Chapter 11*](B18970_11.xhtml#_idTextAnchor112), *Automating Cloud Native
    Application Delivery*'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第11章*](B18970_11.xhtml#_idTextAnchor112)，*自动化云原生应用交付*'
