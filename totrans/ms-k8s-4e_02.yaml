- en: '2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '2'
- en: Creating Kubernetes Clusters
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 创建Kubernetes集群
- en: In the previous chapter, we learned what Kubernetes is all about, how it is
    designed, what concepts it supports, its architecture, and the various container
    runtimes it supports.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们了解了Kubernetes的基本概念，它的设计、支持的概念、架构以及支持的各种容器运行时。
- en: 'Creating a Kubernetes cluster from scratch is a non-trivial task. There are
    many options and tools to select from. There are many factors to consider. In
    this chapter, we will roll our sleeves up and build some Kubernetes clusters using
    Minikube, KinD, and k3d. We will discuss and evaluate other tools such as Kubeadm
    and Kubespray. We will also look into deployment environments such as local, cloud,
    and bare metal. The topics we will cover are as follows:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 从零开始创建Kubernetes集群是一项复杂的任务。需要选择多种选项和工具，考虑的因素也很多。在本章中，我们将动手构建一些Kubernetes集群，使用Minikube、KinD和k3d。我们还将讨论并评估其他工具，如Kubeadm和Kubespray。我们还会研究本地、云端和裸金属等部署环境。我们将涵盖的主题如下：
- en: Getting ready for your first cluster
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为你的第一个集群做准备
- en: Creating a single-node cluster with Minikube
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Minikube创建一个单节点集群
- en: Creating a multi-node cluster with KinD
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用KinD创建一个多节点集群
- en: Creating a multi-node cluster using k3d
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用k3d创建一个多节点集群
- en: Creating clusters in the cloud
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在云端创建集群
- en: Creating bare-metal clusters from scratch
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从零开始创建裸金属集群
- en: Reviewing other options for creating Kubernetes clusters
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 审视其他创建Kubernetes集群的选项
- en: At the end of this chapter, you will have a solid understanding of the various
    options to create Kubernetes clusters and knowledge of the best-of-breed tools
    to support the creation of Kubernetes clusters, and you will also build several
    clusters, both single-node and multi-node.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章结束时，你将对创建Kubernetes集群的各种选项有一个全面的理解，并掌握支持Kubernetes集群创建的最佳工具，同时你还将构建多个集群，包括单节点和多节点集群。
- en: Getting ready for your first cluster
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 为你的第一个集群做准备
- en: Before we start creating clusters, we should install a couple of tools such
    as the Docker client and kubectl. These days, the most convenient way to install
    Docker and kubectl on Mac and Windows is via Rancher Desktop. If you already have
    them installed, feel free to skip this section.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始创建集群之前，我们应该安装一些工具，如Docker客户端和kubectl。如今，最方便的在Mac和Windows上安装Docker和kubectl的方法是通过Rancher
    Desktop。如果你已经安装了这些工具，可以跳过本节。
- en: Installing Rancher Desktop
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装Rancher Desktop
- en: 'Rancher Desktop is a cross-platform desktop application that lets you run Docker
    on your local machine. It will install additional tools such as:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Rancher Desktop是一个跨平台的桌面应用程序，让你可以在本地计算机上运行Docker。它将安装额外的工具，如：
- en: Helm
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Helm
- en: Kubectl
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubectl
- en: Nerdctl
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nerdctl
- en: Moby (open source Docker)
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Moby（开源Docker）
- en: Docker Compose
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Docker Compose
- en: Installation on macOS
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: macOS上的安装
- en: 'The most streamlined way to install Rancher Desktop on macOS is via Homebrew:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在macOS上安装Rancher Desktop最简便的方法是通过Homebrew：
- en: '[PRE0]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Installation on Windows
  id: totrans-24
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Windows上的安装
- en: 'The most streamlined way to install Rancher Desktop on Windows is via Chocolatey:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上安装Rancher Desktop最简便的方法是通过Chocolatey：
- en: '[PRE1]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Additional installation methods
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 其他安装方法
- en: 'For alternative methods to install Docker Desktop, follow the instructions
    here:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 有关其他安装Docker Desktop的方法，请按照此处的说明进行操作：
- en: '[https://docs.rancherdesktop.io/getting-started/installation/](https://docs.rancherdesktop.io/getting-started/installation/)'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://docs.rancherdesktop.io/getting-started/installation/](https://docs.rancherdesktop.io/getting-started/installation/)'
- en: 'Let’s verify `docker` was installed correctly. Type the following commands
    and make sure you don’t see any errors (the output doesn’t have to be identical
    if you installed a different version than mine):'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们验证一下`docker`是否已正确安装。输入以下命令，并确保没有错误（如果你安装了与我不同的版本，输出不必完全相同）：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'And, while we’re at it, let’s verify kubectl has been installed correctly too:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 同时，让我们验证一下kubectl是否已正确安装：
- en: '[PRE3]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The `Server` section may be empty if no active Kubernetes server is up and running.
    When you see this output, you can rest assured that kubectl is ready to go.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 如果没有激活的Kubernetes服务器在运行，`Server`部分可能会为空。当你看到这个输出时，可以放心地确认kubectl已经准备好使用。
- en: Meet kubectl
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 认识kubectl
- en: Before we start creating clusters, let’s talk about kubectl. It is the official
    Kubernetes CLI, and it interacts with your Kubernetes cluster’s API server via
    its API. It is configured by default using the `~/.kube/config` file, which is
    a YAML file that contains metadata, connection info, and authentication tokens
    or certificates for one or more clusters. Kubectl provides commands to view your
    configuration and switch between clusters if it contains more than one. You can
    also point kubectl at a different config file by setting the `KUBECONFIG` environment
    variable or passing the `--kubeconfig` command-line flag.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始创建集群之前，先来聊聊 kubectl。它是官方的 Kubernetes CLI，能够通过其 API 与 Kubernetes 集群的 API
    服务器进行交互。默认情况下，它使用 `~/.kube/config` 文件进行配置，这是一个 YAML 文件，包含元数据、连接信息以及一个或多个集群的身份验证令牌或证书。Kubectl
    提供了查看配置和在多个集群之间切换的命令。如果配置文件包含多个集群，你也可以通过设置 `KUBECONFIG` 环境变量或传递 `--kubeconfig`
    命令行标志，指定 kubectl 使用不同的配置文件。
- en: 'The code below uses a `kubectl` command to check the pods in the `kube-system`
    namespace of the current active cluster:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的代码使用 `kubectl` 命令检查当前活动集群的 `kube-system` 命名空间中的 pods：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Kubectl is great, but it is not the only game in town. Let’s look at some alternative
    tools.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Kubectl 很棒，但它并不是唯一的选择。我们来看看一些替代工具。
- en: Kubectl alternatives – K9S, KUI, and Lens
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubectl 替代品 – K9S、KUI 和 Lens
- en: Kubectl is a no-nonsense command-line tool. It is very powerful, but it may
    be difficult or less convenient for some people to visually parse its output or
    remember all the flags and options. There are many tools the community developed
    that can replace (or more like complement) kubectl. The best ones, in my opinion,
    are K9S, KUI, and Lens.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: Kubectl 是一个直截了当的命令行工具。它非常强大，但对于一些人来说，它的输出可能难以视觉解析，或者记不住所有的标志和选项。社区开发了许多可以替代（或者更像是补充）kubectl
    的工具。在我看来，最好的几个是 K9S、KUI 和 Lens。
- en: K9S
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: K9S
- en: K9S is a terminal-based UI for managing Kubernetes clusters. It has a lot of
    shortcuts and aggregated views that will require multiple kubectl commands to
    accomplish.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: K9S 是一个基于终端的 UI，用于管理 Kubernetes 集群。它拥有许多快捷键和聚合视图，这些视图通常需要执行多个 kubectl 命令才能完成。
- en: 'Here is what the K9S window looks like:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是 K9S 窗口的样子：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B18998_02_01.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图  自动生成的描述 中等置信度](img/B18998_02_01.png)'
- en: 'Figure 2.1: K9S window'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1：K9S 窗口
- en: 'Check it out here: [https://k9scli.io](https://k9scli.io)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里查看：[https://k9scli.io](https://k9scli.io)
- en: KUI
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: KUI
- en: KUI is a framework for adding graphics to **CLIs** (**command-line interfaces**).
    This is a very interesting concept. KUI is focused on Kubernetes of course. It
    lets you run Kubectl commands and returns the results as graphics. KUI also collects
    a lot of relevant information and presents it in a concise way with tabs and detail
    panes to explore even deeper.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: KUI 是一个为 **CLI**（**命令行界面**）添加图形界面的框架。这是一个非常有趣的概念。KUI 当然专注于 Kubernetes。它让你运行
    Kubectl 命令，并将结果以图形方式呈现。KUI 还收集了大量相关信息，并通过标签和详细面板以简洁的方式呈现，便于更深入探索。
- en: KUI is based on Electron, but it is fast.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: KUI 基于 Electron，但它非常快速。
- en: 'Here is what the KUI window looks like:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是 KUI 窗口的样子：
- en: '![Graphical user interface  Description automatically generated](img/B18998_02_02.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面 自动生成的描述](img/B18998_02_02.png)'
- en: 'Figure 2.2: KUI window'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2：KUI 窗口
- en: 'Check it out here: [https://kui.tools](https://kui.tools)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里查看：[https://kui.tools](https://kui.tools)
- en: Lens
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Lens
- en: Lens is a very polished application. It also presents a graphical view of clusters
    and allows you to perform a lot of operations from the UI and drop to a terminal
    interface when necessary. I especially appreciate the ability to work easily with
    multiple clusters that Lens provides.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: Lens 是一个非常精致的应用程序。它同样提供了集群的图形化视图，并允许你在 UI 中执行大量操作，必要时还可以切换到终端界面。我尤其欣赏 Lens 提供的轻松操作多个集群的能力。
- en: 'Here is what the Lens window looks like:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是 Lens 窗口的样子：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B18998_02_03.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图  自动生成的描述 中等置信度](img/B18998_02_03.png)'
- en: 'Figure 2.3: Lens window'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3：Lens 窗口
- en: 'Check it out here: [https://k8slens.dev](https://k8slens.dev)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里查看：[https://k8slens.dev](https://k8slens.dev)
- en: All these tools are running locally. I highly recommend that you start playing
    with kubectl and then give these tools a test drive. One of them may just be your
    speed.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些工具都是本地运行的。我强烈建议你先尝试使用 kubectl，然后再试试这些工具。也许其中某一个正适合你的使用方式。
- en: In this section, we covered the installation of Rancher Desktop, introduced
    kubectl, and looked at some alternatives. We are now ready to create our first
    Kubernetes cluster.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了 Rancher Desktop 的安装，介绍了 kubectl，并查看了一些替代方案。现在我们准备创建我们的第一个 Kubernetes
    集群。
- en: Creating a single-node cluster with Minikube
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Minikube 创建单节点集群
- en: In this section, we will create a local single-node cluster using Minikube.
    Local clusters are most useful for developers that want quick edit-test-deploy-debug
    cycles on their machine before committing their changes. Local clusters are also
    very useful for DevOps and operators that want to play with Kubernetes locally
    without concerns about breaking a shared environment or creating expensive resources
    in the cloud and forgetting to clean them up. While Kubernetes is typically deployed
    on Linux in production, many developers work on Windows PCs or Macs. That said,
    there aren’t too many differences if you do want to install Minikube on Linux.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 Minikube 创建一个本地单节点集群。本地集群对于开发人员非常有用，尤其是那些希望在提交更改之前，在自己的机器上进行快速的编辑-测试-部署-调试循环的开发人员。本地集群对于
    DevOps 和操作员也很有用，尤其是那些希望在不担心破坏共享环境或在云中创建昂贵资源并忘记清理的情况下，进行本地 Kubernetes 测试的人员。虽然
    Kubernetes 通常在生产环境中部署在 Linux 上，但许多开发人员使用的是 Windows PC 或 Mac。因此，如果您希望在 Linux 上安装
    Minikube，差异不大。
- en: '![A picture containing text, clipart  Description automatically generated](img/B18998_02_04.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![一张包含文字的图片，带有剪贴画 描述自动生成](img/B18998_02_04.png)'
- en: 'Figure 2.4: minikube'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.4：minikube
- en: Quick introduction to Minikube
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Minikube 简介
- en: 'Minikube is the most mature local Kubernetes cluster. It runs the latest stable
    Kubernetes release. It supports Windows, macOS, and Linux. Minikube provides a
    lot of advanced options and capabilities:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Minikube 是最成熟的本地 Kubernetes 集群。它运行最新的稳定 Kubernetes 版本，支持 Windows、macOS 和 Linux。Minikube
    提供了许多高级选项和功能：
- en: LoadBalancer service type - via minikube tunnel
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LoadBalancer 服务类型 - 通过 minikube tunnel
- en: NodePort service type - via minikube service
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NodePort 服务类型 - 通过 minikube service
- en: Multiple clusters
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多个集群
- en: Filesystem mounts
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文件系统挂载
- en: GPU support - for machine learning
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPU 支持 - 用于机器学习
- en: RBAC
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: RBAC
- en: Persistent Volumes
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久化卷
- en: Ingress
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ingress
- en: Dashboard - via minikube dashboard
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 仪表盘 - 通过 minikube dashboard
- en: Custom container runtimes - via the `start --container-runtime` flag
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自定义容器运行时 - 通过 `start --container-runtime` 标志
- en: Configuring API server and kubelet options via command-line flags
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过命令行标志配置 API 服务器和 kubelet 选项
- en: Addons
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 插件
- en: Installing Minikube
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Minikube
- en: 'The ultimate guide is here: [https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 终极指南在这里：[https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)
- en: But, to save you a trip, here are the latest instructions at the time of writing.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，为了节省您的时间，以下是写作时的最新安装说明。
- en: Installing Minikube on Windows
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 Windows 上安装 Minikube
- en: 'On Windows, I prefer to install software via the Chocolatey package manager.
    If you don’t have it yet, you can get it here: [https://chocolatey.org/](https://chocolatey.org/)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，我喜欢通过 Chocolatey 包管理器安装软件。如果您还没有安装它，可以在这里获取：[https://chocolatey.org/](https://chocolatey.org/)
- en: If you don’t want to use Chocolatey, check the ultimate guide above for alternative
    methods.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您不想使用 Chocolatey，请查看上面的终极指南，获取其他方法。
- en: 'With Chocolatey installed, the installation is pretty simple:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 安装 Chocolatey 后，安装过程相当简单：
- en: '[PRE5]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: On Windows, you can work in different command-line environments. The most common
    ones are PowerShell and **WSL** (**Windows System for Linux**). Either one works.
    You may need to run them in Administrator mode for certain operations.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，您可以在不同的命令行环境中工作。最常见的环境是 PowerShell 和 **WSL**（**Windows Subsystem
    for Linux**）。这两种环境都可以使用。某些操作可能需要以管理员模式运行。
- en: 'As far as console windows go, I recommend the official Windows Terminal these
    days. You can install it with one command:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 至于控制台窗口，近年来我推荐使用官方的 Windows Terminal。您可以通过一条命令安装它：
- en: '[PRE6]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: If you prefer other console windows such as ConEMU or Cmdr, this is totally
    fine.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您更喜欢使用其他控制台窗口，如 ConEMU 或 Cmdr，也是完全可以的。
- en: I’ll use shortcuts to make life easy. If you want to follow along and copy the
    aliases into your profile, you can use the following for PowerShell and WSL.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 我会使用快捷方式让操作更简单。如果您希望跟着操作并将别名复制到您的配置文件中，您可以在 PowerShell 和 WSL 中使用以下内容。
- en: 'For PowerShell, add the following to your `$profile`:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 PowerShell，请将以下内容添加到您的 `$profile`：
- en: '[PRE7]'
  id: totrans-95
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'For WSL, add the following to `.bashrc`:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 WSL，请将以下内容添加到 `.bashrc`：
- en: '[PRE8]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let’s verify that minikube was installed correctly:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们验证 Minikube 是否正确安装：
- en: '[PRE9]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Let’s create a cluster with `mk start`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用 `mk start` 创建一个集群：
- en: '[PRE10]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: As you can see, the process is pretty complicated even for the default setup,
    and required multiple retries (automatically). You can customize the cluster creation
    process with a multitude of command-line flags. Type `mk start -h` to see what’s
    available.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，即使是默认设置的过程也相当复杂，需要多次重试（自动进行）。你可以通过多种命令行标志来自定义集群创建过程。输入`mk start -h`查看可用的选项。
- en: 'Let’s check the status of our cluster:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查集群的状态：
- en: '[PRE11]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: All is well!
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一切顺利！
- en: 'Now let’s stop the cluster and later restart it:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们停止集群，然后稍后重新启动它：
- en: '[PRE12]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Restarting with the time command to measure how long it takes:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`time`命令重启并测量所需时间：
- en: '[PRE13]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: It took a little over a minute.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这花了稍微超过一分钟。
- en: 'Let’s review what Minikube did behind the curtains for you. You’ll need to
    do a lot of it when creating a cluster from scratch:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下Minikube为你背后做了哪些工作。当你从零开始创建集群时，你将需要做很多这些操作。
- en: Started a Hyper-V VM
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动了一个Hyper-V虚拟机
- en: Created certificates for the local machine and the VM
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为本地机器和虚拟机创建了证书
- en: Downloaded images
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载了镜像
- en: Set up networking between the local machine and the VM
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置本地机器与虚拟机之间的网络连接
- en: Ran the local Kubernetes cluster on the VM
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在虚拟机上运行本地Kubernetes集群
- en: Configured the cluster
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置了集群
- en: Started all the Kubernetes control plane components
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动了所有Kubernetes控制平面组件
- en: Configured the kubelet
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置了kubelet
- en: Enabled addons (for storage)
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启用了附加组件（用于存储）
- en: Configured kubectl to talk to the cluster
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置了kubectl与集群通信
- en: Installing Minikube on macOS
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在macOS上安装Minikube
- en: 'On Mac, I recommend installing minikube using Homebrew:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在Mac上，我建议使用Homebrew安装minikube：
- en: '[PRE14]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'You can add aliases to your `.bashrc` file (similar to the WSL aliases on Windows):'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将别名添加到你的`.bashrc`文件中（类似于Windows上的WSL别名）：
- en: '[PRE15]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now you can use `k` and `mk` and type less.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以使用`k`和`mk`，这样可以减少输入。
- en: 'Type `mk version` to verify Minikube is correctly installed and functioning:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 输入`mk version`来验证Minikube是否正确安装并正常运行：
- en: '[PRE16]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Type `k version` to verify kubectl is correctly installed and functioning:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 输入`k version`来验证kubectl是否正确安装并正常运行：
- en: '[PRE17]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Note that the client version is 1.23\. Don’t worry about the error message.
    There is no cluster running, so kubectl can’t connect to anything. That’s expected.
    The error message will disappear when we create the cluster.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意客户端版本是1.23。不要担心错误信息。没有集群在运行，所以kubectl无法连接任何东西。这是预期中的情况。当我们创建集群时，错误信息将消失。
- en: You can explore the available commands and flags for both Minikube and kubectl
    by just typing the commands with no arguments.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过不带参数地输入命令，探索Minikube和kubectl的可用命令和标志。
- en: To create the cluster on macOS, just run `mk start`.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在macOS上创建集群，只需运行`mk start`。
- en: Troubleshooting the Minikube installation
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 故障排除Minikube安装
- en: 'If something goes wrong during the process, try to follow the error messages.
    You can add the `--alsologtostderr` flag to get detailed error info to the console.
    Everything minikube does is organized neatly under `~/.minikube`. Here is the
    directory structure:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在过程中出现问题，请尝试根据错误信息进行操作。你可以添加`--alsologtostderr`标志，将详细的错误信息输出到控制台。Minikube执行的所有操作都井井有条地组织在`~/.minikube`目录下。这里是目录结构：
- en: '[PRE18]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: If you don’t have the tree utility, you can install it.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有tree工具，可以安装它。
- en: 'On Windows: `$ choco install -y tree`'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows上：`$ choco install -y tree`
- en: 'On Mac: `brew install tree`'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 在Mac上：`brew install tree`
- en: Checking out the cluster
  id: totrans-141
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 查看集群
- en: Now that we have a cluster up and running, let’s peek inside.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经有了一个正在运行的集群，让我们来看一下集群内部。
- en: 'First, let’s `ssh` into the VM:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们`ssh`进入虚拟机：
- en: '[PRE19]'
  id: totrans-144
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Great! That works. The weird symbols are ASCII art for “minikube.” Now, let’s
    start using kubectl because it is the Swiss Army knife of Kubernetes and will
    be useful for all clusters.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 很好！它能正常工作。那些奇怪的符号是“minikube”的ASCII艺术。现在，让我们开始使用kubectl，因为它是Kubernetes的瑞士军刀，将对所有集群都非常有用。
- en: 'Disconnect from the VM via *ctrl*+*D* or by typing:'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 通过*ctrl*+*D*或输入以下命令断开与虚拟机的连接：
- en: '[PRE20]'
  id: totrans-147
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'We will cover many of the kubectl commands in our journey. First, let’s check
    the cluster status using `cluster-info`:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的旅程中，我们将涵盖许多kubectl命令。首先，使用`cluster-info`检查集群状态：
- en: '[PRE21]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'You can see that the control plane is running properly. To see a much more
    detailed view of all the objects in the cluster as JSON, type: `k cluster-info
    dump`. The output can be a little daunting let’s use more specific commands to
    explore the cluster.'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到控制平面正在正常运行。要查看集群中所有对象的更详细的JSON格式视图，输入：`k cluster-info dump`。输出可能会让人觉得有些让人望而生畏，我们可以使用更具体的命令来探索集群。
- en: 'Let’s check out the nodes in the cluster using `get nodes`:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用`get nodes`检查集群中的节点：
- en: '[PRE22]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'So, we have one node called minikube. To get a lot more information about it,
    type:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们有一个名为minikube的节点。要获取更多关于它的信息，输入：
- en: '[PRE23]'
  id: totrans-154
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: The output is verbose; I’ll let you try it yourself.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 输出非常详细；我会让你自己试一下。
- en: 'Before we start putting our cluster to work, let’s check the addons minikube
    installed by default:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始让集群工作之前，先检查一下 Minikube 默认安装的附加组件：
- en: '[PRE24]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: As you can see, minikube comes loaded with a lot of addons, but only enables
    a couple of storage addons out of the box.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，Minikube 配载了许多附加组件，但默认仅启用了几个存储相关的附加组件。
- en: Doing work
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 开始工作
- en: Before we start, if you have a VPN running, you may need to shut it down when
    pulling images.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，如果你正在运行 VPN，拉取镜像时可能需要关闭它。
- en: 'We have a nice empty cluster up and running (well, not completely empty, as
    the DNS service and dashboard run as pods in the kube-system namespace). It’s
    time to deploy some pods:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经有了一个干净的空集群（当然并非完全空，因为 DNS 服务和仪表板作为 Pod 运行在 kube-system 命名空间中）。现在是时候部署一些
    Pod 了：
- en: '[PRE25]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let’s check out the pod that was created. The `-w` flag means watch. Whenever
    the status changes, a new line will be displayed:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下已经创建的 Pod。`-w` 标志表示监视。每当状态变化时，都会显示新的一行：
- en: '[PRE26]'
  id: totrans-164
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'To expose our pod as a service, type the following:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 要将我们的 Pod 暴露为服务，请输入以下命令：
- en: '[PRE27]'
  id: totrans-166
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Exposing the service as type `NodePort` means that it is exposed to the host
    on some port. But it is not the `8080` port we ran the pod on. Ports get mapped
    in the cluster. To access the service, we need the cluster IP and exposed port:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 将服务暴露为 `NodePort` 类型意味着它通过某个端口暴露给主机。但这不是我们在 Pod 上运行的 `8080` 端口。端口会在集群中进行映射。要访问该服务，我们需要集群
    IP 和暴露的端口：
- en: '[PRE28]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Now we can access the echo service, which returns a lot of information:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以访问回显服务，它返回了大量信息：
- en: '[PRE29]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Congratulations! You just created a local Kubernetes cluster, deployed a service,
    and exposed it to the world.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜！你刚刚创建了一个本地 Kubernetes 集群，部署了一个服务，并将其暴露给全世界。
- en: Examining the cluster with the dashboard
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用仪表板检查集群
- en: Kubernetes has a very nice web interface, which is deployed, of course, as a
    service in a pod. The dashboard is well designed and provides a high-level overview
    of your cluster as well as drilling down into individual resources, viewing logs,
    editing resource files, and more. It is the perfect weapon when you want to check
    out your cluster manually and don’t have local tools like KUI or Lens. Minikube
    provides it as an addon.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 有一个非常好用的 Web 界面，当然它是作为服务部署在一个 Pod 中的。仪表板设计精良，提供了集群的高层次概览，并能深入查看单个资源、查看日志、编辑资源文件等。当你想手动查看集群，并且没有像
    KUI 或 Lens 这样的本地工具时，它是完美的利器。Minikube 将它作为附加组件提供。
- en: 'Let’s enable it:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们启用它：
- en: '[PRE30]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'To launch it, type:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 要启动它，输入：
- en: '[PRE31]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Minikube will open a browser window with the dashboard UI.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: Minikube 会打开一个浏览器窗口，显示仪表板 UI。
- en: Here is the **Workloads** view, which displays **Deployments**, **Replica Sets**,
    and **Pods**.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这是**工作负载**视图，显示了**部署（Deployments）**、**副本集（Replica Sets）**和**Pod**。
- en: '![Graphical user interface, chart, bubble chart  Description automatically
    generated](img/B18998_02_05.png)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，图表，气泡图 描述自动生成](img/B18998_02_05.png)'
- en: 'Figure 2.5: Workloads dashboard'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.5：工作负载仪表板
- en: It can also display daemon sets, stateful sets, and jobs, but we don’t have
    any in this cluster.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 它还可以显示守护进程集、状态集和任务，但我们在这个集群中没有这些。
- en: 'To delete the cluster we created, type:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除我们创建的集群，请输入：
- en: '[PRE32]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: In this section, we created a local single-node Kubernetes cluster on Windows,
    explored it a little bit using kubectl, deployed a service, and played with the
    web UI. In the next section, we’ll move to a multi-node cluster.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们在 Windows 上创建了一个本地单节点 Kubernetes 集群，使用 kubectl 探索了一下，部署了一个服务，并尝试了网页 UI。在下一节中，我们将转向多节点集群。
- en: Creating a multi-node cluster with KinD
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 KinD 创建多节点集群
- en: In this section, we’ll create a multi-node cluster using KinD. We will also
    repeat the deployment of the echo server we deployed on Minikube and observe the
    differences. Spoiler alert - everything will be faster and easier!
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将使用 KinD 创建一个多节点集群。我们还将重复在 Minikube 上部署的回显服务器，并观察其中的差异。剧透警告——一切都会更快且更容易！
- en: Quick introduction to KinD
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: KinD 简介
- en: '**KinD** stands for **Kubernetes in Docker**. It is a tool for creating ephemeral
    clusters (no persistent storage). It was built primarily for running the Kubernetes
    conformance tests. It supports Kubernetes 1.11+. Under the covers, it uses `kubeadm`
    to bootstrap Docker containers as nodes in the cluster. KinD is a combination
    of a library and a CLI. You can use the library in your code for testing or other
    purposes. KinD can create highly-available clusters with multiple control plane
    nodes. Finally, KinD is a CNCF conformant Kubernetes installer. It had better
    be if it’s used for the conformance tests of Kubernetes itself.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '**KinD** 代表 **Kubernetes in Docker**。它是一个用于创建临时集群（没有持久化存储）的工具。它最初是为运行 Kubernetes
    兼容性测试而构建的。它支持 Kubernetes 1.11+。在后台，它使用 `kubeadm` 来启动 Docker 容器作为集群中的节点。KinD 是一个库和命令行工具的结合体。你可以在代码中使用该库进行测试或其他用途。KinD
    可以创建具有多个控制平面节点的高可用集群。最后，KinD 是一个符合 CNCF 标准的 Kubernetes 安装工具。如果它被用于 Kubernetes
    本身的兼容性测试，它必须符合这个标准。'
- en: 'KinD is super fast to start, but it has some limitations too:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: KinD 启动非常迅速，但它也有一些限制：
- en: No persistent storage
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 没有持久化存储
- en: No support for alternative runtimes yet, only Docker
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 目前尚不支持其他运行时，仅支持 Docker
- en: Let’s install KinD and get going.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们安装 KinD 并开始吧。
- en: Installing KinD
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 KinD
- en: 'You must have Docker installed as KinD is literally running as a Docker container.
    If you have Go installed, you can install the KinD CLI via:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 必须安装 Docker，因为 KinD 实际上是作为 Docker 容器运行的。如果你安装了 Go，可以通过以下方式安装 KinD CLI：
- en: '[PRE33]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Otherwise, on macOS type:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 否则，在 macOS 上输入：
- en: '[PRE34]'
  id: totrans-198
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'On Windows type:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows 上，输入：
- en: '[PRE35]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: Dealing with Docker contexts
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理 Docker 上下文
- en: 'You may have multiple Docker engines on your system and the Docker context
    determines which one is used. You may get an error like:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 您的系统上可能有多个 Docker 引擎，而 Docker 上下文决定了使用哪个。您可能会遇到如下错误：
- en: '[PRE36]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'In this case, check your Docker contexts:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，检查你的 Docker 上下文：
- en: '[PRE37]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'The context marked with `*` is the current context. If you use Rancher Desktop,
    then you should set the context to `rancher-desktop`:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 用 `*` 标记的上下文是当前上下文。如果你使用 Rancher Desktop，则应将上下文设置为 `rancher-desktop`：
- en: '[PRE38]'
  id: totrans-207
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: Creating a cluster with KinD
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 KinD 创建集群
- en: Creating a cluster is super easy.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 创建集群非常简单。
- en: '[PRE39]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: It takes less than 30 seconds to create a single-node cluster.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 创建一个单节点集群需要不到 30 秒。
- en: 'Now, we can access the cluster using kubectl:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以使用 kubectl 访问集群：
- en: '[PRE40]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: KinD adds its kube context to the default `~/.kube/config` file by default.
    When creating a lot of temporary clusters, it is sometimes better to store the
    KinD contexts in separate files and avoid cluttering `~/.kube/config`. This is
    easily done by passing the `--kubeconfig` flag with a file path.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，KinD 会将其 kube 上下文添加到默认的 `~/.kube/config` 文件中。当创建大量临时集群时，有时最好将 KinD 上下文存储在单独的文件中，避免让
    `~/.kube/config` 文件变得混乱。这可以通过传递 `--kubeconfig` 标志并指定文件路径轻松完成。
- en: 'So, KinD creates a single-node cluster by default:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，KinD 默认创建一个单节点集群：
- en: '[PRE41]'
  id: totrans-216
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Let’s delete it and create a multi-node cluster:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们删除它并创建一个多节点集群：
- en: '[PRE42]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'To create a multi-node cluster, we need to provide a configuration file with
    the specification of our nodes. Here is a configuration file that will create
    a cluster called `multi-node-cluster` with one control plane node and two worker
    nodes:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个多节点集群，我们需要提供一个包含节点规格的配置文件。以下是一个配置文件，它将创建一个名为 `multi-node-cluster` 的集群，包含一个控制平面节点和两个工作节点：
- en: '[PRE43]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Let’s save the configuration file as `kind-multi-node-config.yaml` and create
    the cluster storing the kubeconfig with its own file `$TMPDIR/kind-multi-node-config`:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将配置文件保存为 `kind-multi-node-config.yaml` 并创建集群，将 kubeconfig 存储在自己的文件 `$TMPDIR/kind-multi-node-config`
    中：
- en: '[PRE44]'
  id: totrans-222
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'Yeah, it works! And we got a local 3-node cluster in less than a minute:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 对了，成功了！我们在不到一分钟的时间内得到了一个本地的 3 节点集群：
- en: '[PRE45]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: 'KinD is also kind enough (see what I did there) to let us create **HA** (**highly
    available**) clusters with multiple control plane nodes for redundancy. If you
    want a highly available cluster with three control plane nodes and two worker
    nodes, your cluster config file will be very similar:'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: KinD 还很贴心（看到了吗）地允许我们创建具有多个控制平面节点的 **HA**（**高可用**）集群以实现冗余。如果你想要一个具有三个控制平面节点和两个工作节点的高可用集群，你的集群配置文件会非常类似：
- en: '[PRE46]'
  id: totrans-226
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'Let’s save the configuration file as `kind-ha-multi-node-config.yaml` and create
    a new HA cluster:'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将配置文件保存为 `kind-ha-multi-node-config.yaml` 并创建一个新的 HA 集群：
- en: '[PRE47]'
  id: totrans-228
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: Hmmm... there is something new here. Now KinD creates an external load balancer
    as well as joining more control plane nodes before joining the worker nodes. The
    load balancer is necessary to distribute requests across all the control plane
    nodes.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 嗯……这里有些新变化。现在，KinD 创建了一个外部负载均衡器，并且在加入工作节点之前，会先加入更多的控制平面节点。负载均衡器对于在所有控制平面节点之间分发请求是必要的。
- en: 'Note that the external load balancer doesn’t show as a node using kubectl:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，使用 kubectl 时，外部负载均衡器不会显示为节点：
- en: '[PRE48]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'But, KinD has its own `get nodes` command, where you can see the load balancer:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，KinD 有自己的 `get nodes` 命令，在这里你可以看到负载均衡器：
- en: '[PRE49]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Our KinD cluster is up and running; let’s put it to work.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 KinD 集群已启动并运行；让我们开始使用它。
- en: Doing work with KinD
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 KinD 进行工作
- en: 'Let’s deploy our echo service on the KinD cluster. It starts the same:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在 KinD 集群上部署我们的回声服务。它的启动方式相同：
- en: '[PRE50]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'Checking our services, we can see the echo service front and center:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 检查我们的服务时，我们可以看到回声服务处于最前面：
- en: '[PRE51]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: But, there is no external IP to the service. With minikube, we got the IP of
    the minikube node itself via `$(minikube ip)` and we could use it in combination
    with the node port to access the service. That is not an option with KinD clusters.
    Let’s see how to use a proxy to access the echo service.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 但是，服务没有外部 IP。使用 minikube 时，我们可以通过 `$(minikube ip)` 获取 minikube 节点本身的 IP，并可以结合节点端口来访问服务。但在
    KinD 集群中没有这个选项。让我们看看如何使用代理来访问回声服务。
- en: Accessing Kubernetes services locally through a proxy
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过代理本地访问 Kubernetes 服务
- en: We will go into a lot of detail about networking, services, and how to expose
    them outside the cluster later in the book.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本书后续部分详细讨论网络、服务以及如何将它们暴露到集群外部。
- en: 'Here, we will just show you how to get it done and keep you in suspense for
    now. First, we need to run the `kubectl proxy` command that exposes the API server,
    pods, and services on localhost:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将只展示如何完成操作，并且暂时保持悬念。首先，我们需要运行 `kubectl proxy` 命令来暴露 API 服务器、Pod 和服务到本地主机：
- en: '[PRE52]'
  id: totrans-244
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'Then, we can access the echo service through a specially crafted proxy URL
    that includes the exposed port (`8080`) and NOT the node port:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们可以通过一个专门设计的代理 URL 来访问回声服务，URL 中包含暴露的端口（`8080`），而不是节点端口：
- en: '[PRE53]'
  id: totrans-246
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: 'I used httpie in the command above. You can use curl too. To install httpie,
    follow the instructions here: [https://httpie.org/doc#installation](https://httpie.org/doc#installation).'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 我在上面的命令中使用了 httpie。你也可以使用 curl。要安装 httpie，请按照这里的说明操作：[https://httpie.org/doc#installation](https://httpie.org/doc#installation)。
- en: We will deep dive into exactly what’s going on in *Chapter 10*, *Exploring Kubernetes
    Networking*. For now, it is enough to demonstrate how kubectl proxy allows us
    to access our KinD services.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在*第10章*、*探索 Kubernetes 网络*中深入探讨发生了什么。目前，只需演示如何通过 kubectl proxy 访问我们的 KinD
    服务就足够了。
- en: Let’s check out my favorite local cluster solution – k3d.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看我最喜欢的本地集群解决方案——k3d。
- en: Creating a multi-node cluster with k3d
  id: totrans-250
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 k3d 创建多节点集群
- en: In this section, we’ll create a multi-node cluster using k3d from Rancher. We
    will not repeat the deployment of the echo server because it’s identical to the
    KinD cluster including accessing it through a proxy. Spoiler alert – creating
    clusters with k3d is even faster and more user-friendly than KinD!
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将使用 Rancher 的 k3d 创建一个多节点集群。我们不会重复回声服务的部署，因为它与 KinD 集群相同，包括通过代理访问它。剧透警告——使用
    k3d 创建集群比 KinD 更快且更具用户友好性！
- en: Quick introduction to k3s and k3d
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: k3s 和 k3d 快速介绍
- en: 'Rancher created k3s, which is a lightweight Kubernetes distribution. Rancher
    says that k3s is 5 less than k8s if that makes any sense. The basic idea is to
    remove features and capabilities that most people don’t need such as:'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: Rancher 创建了 k3s，这是一个轻量级的 Kubernetes 发行版。Rancher 表示 k3s 比 k8s 少了 5（如果有任何意义的话）。基本的想法是移除大多数人不需要的功能和能力，例如：
- en: Non-default features
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 非默认功能
- en: Legacy features
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传统功能
- en: Alpha features
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alpha 功能
- en: In-tree storage drivers
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内建存储驱动程序
- en: In-tree cloud providers
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内建云提供商
- en: K3s removed Docker completely and uses containerd instead. You can still bring
    Docker back if you depend on it. Another major change is that k3s stores its state
    in an SQLite DB instead of etcd. For networking and DNS, k3s uses Flannel and
    CoreDNS.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: K3s 完全去除了 Docker，改用了 containerd。如果你依赖 Docker，仍然可以将它恢复。另一个重大变化是，k3s 将其状态存储在 SQLite
    数据库中，而不是 etcd。对于网络和 DNS，k3s 使用 Flannel 和 CoreDNS。
- en: K3s also added a simplified installer that takes care of SSL and certificate
    provisioning.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: K3s 还添加了一个简化的安装程序，负责 SSL 和证书的配置。
- en: The end result is astonishing – a single binary (less than 40MB) that needs
    only 512MB of memory.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 最终结果令人惊讶——一个单一的二进制文件（小于 40MB），只需要 512MB 的内存。
- en: Unlike Minikube and KinD, k3s is actually designed for production. The primary
    use case is for edge computing, IoT, and CI systems. It is optimized for ARM devices.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: OK. That’s k3s, but what’s k3d? K3d takes all the goodness that is k3s and packages
    it in Docker (similar to KinD) and adds a friendly CLI to manage it.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: Let’s install k3d and see for ourselves.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Installing k3d
  id: totrans-265
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Installing k3d on macOS is as simple as:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-267
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'And on Windows, it is just:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-269
  prefs: []
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'On Windows, optionally add this alias to your WSL `.bashrc` file:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-271
  prefs: []
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Let’s see what we have:'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-273
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: As you see, k3d reports its version, which shows all is well. Now, we can create
    a cluster with k3d.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: Creating the cluster with k3d
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Are you ready to be amazed? Creating a single-node cluster with k3d takes less
    than 20 seconds!
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-277
  prefs: []
  type: TYPE_PRE
  zh: '[PRE58]'
- en: Without a load balancer, it takes less than 8 seconds!
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: What about multi-node clusters? We saw that KinD was much slower, especially
    when creating a HA cluster with multiple control plane nodes and an external load
    balancer.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s delete the single-node cluster first:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-281
  prefs: []
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Now, let’s create a cluster with 3 worker nodes. That takes a little over 30
    seconds:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  id: totrans-283
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'Let’s verify the cluster works as expected:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  id: totrans-285
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Here are the nodes. Note that there is just one control plane node called `k3d-k3s-default-server-0`:'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  id: totrans-287
  prefs: []
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'You can stop and start clusters, create multiple clusters, and list existing
    clusters using the k3d CLI. Here are all the commands. Feel free to explore further:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  id: totrans-289
  prefs: []
  type: TYPE_PRE
  zh: '[PRE63]'
- en: You can repeat the steps for deploying, exposing, and accessing the echo service
    on your own. It works just like KinD.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: OK. We created clusters using minikube, KinD and k3d. Let’s compare them, so
    you can decide which one works for you.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: Comparing Minikube, KinD, and k3d
  id: totrans-292
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Minikube is an official local Kubernetes release. It’s very mature and very
    full-featured. That said, it requires a VM and is both slow to install and to
    start. It also can get into trouble with networking at arbitrary times, and sometimes
    the only remedy is deleting the cluster and rebooting. Also, minikube supports
    a single node only. I suggest using Minikube only if it supports some features
    that you need that are not available in either KinD or k3d. See [https://minikube.sigs.k8s.io/](https://minikube.sigs.k8s.io/)
    for more info.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: KinD is much faster than Minikube and is used for Kubernetes conformance tests,
    so by definition, it is a conformant Kubernetes distribution. It is the only local
    cluster solution that provides an HA cluster with multiple control plane nodes.
    It is also designed to be used as a library, which I don’t find a big attraction
    because it is very easy to automate CLIs from code. The main downside of KinD
    for local development is that it is ephemeral. I recommend using KinD if you contribute
    to Kubernetes itself and want to test against it. See [https://kind.sigs.k8s.io/](https://kind.sigs.k8s.io/).
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: K3d is the clear winner for me. Lightning fast, and supports multiple clusters
    and multiple worker nodes per cluster. Easy to stop and start clusters without
    losing state. See [https://k3d.io/](https://k3d.io/).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 对我来说，K3d 是明显的赢家。速度非常快，支持多个集群以及每个集群中的多个工作节点。轻松停止和启动集群而不会丢失状态。查看 [https://k3d.io/](https://k3d.io/)。
- en: Honorable mention – Rancher Desktop Kubernetes cluster
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 荣誉提名 – Rancher Desktop Kubernetes 集群
- en: I use Rancher Desktop as my Docker Engine provider, but it also comes with a
    built-in Kubernetes cluster. You don’t get to customize it and you can’t have
    multiple clusters or even multiple nodes in the same cluster. But, if all you
    need is a local single-node Kubernetes cluster to play with, then the `rancher-desktop`
    cluster is there for you.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 我使用 Rancher Desktop 作为我的 Docker 引擎提供商，但它还内置了一个 Kubernetes 集群。你无法自定义它，不能有多个集群，甚至同一个集群中也不能有多个节点。但如果你只需要一个本地的单节点
    Kubernetes 集群来进行试验，那么`rancher-desktop`集群就适合你。
- en: 'To use this cluster, type:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用此集群，请输入：
- en: '[PRE64]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE64]'
- en: You can decide how many resources you allocate to its node, which is important
    if you try to deploy a lot of workloads on it because you get just the one node.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以决定为其节点分配多少资源，这在尝试在其上部署大量工作负载时非常重要，因为你只有一个节点。
- en: '![Graphical user interface, application  Description automatically generated](img/B18998_02_06.png)'
  id: totrans-301
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，应用程序描述自动生成](img/B18998_02_06.png)'
- en: 'Figure 2.6: Rancher Desktop – Kubernetes settings'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6：Rancher Desktop – Kubernetes 设置
- en: In this section, we covered creating Kubernetes clusters locally using Minikube,
    KinD, and K3d. In the next section, we will look at creating clusters in the cloud.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们介绍了如何使用 Minikube、KinD 和 K3d 在本地创建 Kubernetes 集群。在下一节中，我们将探讨如何在云端创建集群。
- en: Creating clusters in the cloud (GCP, AWS, Azure, and Digital Ocean)
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在云中创建集群（GCP、AWS、Azure 和 Digital Ocean）
- en: Creating clusters locally is fun. It’s also important during development and
    when trying to troubleshoot problems locally. But, in the end, Kubernetes is designed
    for cloud-native applications (applications that run in the cloud). Kubernetes
    doesn’t want to be aware of individual cloud environments because that doesn’t
    scale. Instead, Kubernetes has the concept of a cloud-provider interface. Every
    cloud provider can implement this interface and then host Kubernetes.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 本地创建集群很有趣。它在开发过程中和尝试本地排查问题时也非常重要。但是，最终，Kubernetes 是为云原生应用程序（在云中运行的应用程序）设计的。Kubernetes
    不希望知道单个云环境，因为这不具备可扩展性。因此，Kubernetes 有一个云提供商接口的概念。每个云提供商都可以实现此接口，然后托管 Kubernetes。
- en: The cloud-provider interface
  id: totrans-306
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 云提供商接口
- en: 'The cloud-provider interface is a collection of Go data types and interfaces.
    It is defined in a file called `cloud.go`, available at: [https://github.com/kubernetes/cloud-provider/blob/master/cloud.go](https://github.com/kubernetes/cloud-provider/blob/master/cloud.go).'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 云提供商接口是一个由 Go 数据类型和接口组成的集合。它定义在一个名为`cloud.go`的文件中，可以在以下位置找到：[https://github.com/kubernetes/cloud-provider/blob/master/cloud.go](https://github.com/kubernetes/cloud-provider/blob/master/cloud.go)。
- en: 'Here is the main interface:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 这是主要界面：
- en: '[PRE65]'
  id: totrans-309
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: This is very clear. Kubernetes operates in terms of instances, zones, clusters,
    and routes, and also requires access to a load balancer and provider name. The
    main interface is primarily a gateway. Most methods of the `Interface` interface
    above return yet other interfaces.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 这非常清晰。Kubernetes 是基于实例、区域、集群和路由来运作的，还需要访问负载均衡器和提供商名称。主要接口主要是一个网关。上面`Interface`接口的大多数方法返回的是其他接口。
- en: 'For example, the `Clusters()` method returns the `Cluster` interface, which
    is very simple:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，`Clusters()`方法返回`Cluster`接口，使用起来非常简单：
- en: '[PRE66]'
  id: totrans-312
  prefs: []
  type: TYPE_PRE
  zh: '[PRE66]'
- en: The `ListClusters()` method returns cluster names. The `Master()` method returns
    the IP address or DNS name of the control plane of the cluster.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '`ListClusters()` 方法返回集群名称。`Master()` 方法返回集群控制平面的 IP 地址或 DNS 名称。'
- en: The other interfaces are not much more complicated. The entire file is 313 lines
    long (at the time of writing) including lots of comments. The take-home point
    is that it is not too complicated to implement a Kubernetes provider if your cloud
    utilizes those basic concepts.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 其他接口也没有更复杂。整个文件有 313 行（截至编写时），包括大量注释。关键点是，如果你的云环境利用了这些基本概念，实现 Kubernetes 提供商并不太复杂。
- en: Creating Kubernetes clusters in the cloud
  id: totrans-315
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在云中创建 Kubernetes 集群
- en: Before we look at the cloud providers and their support for managed and non-managed
    Kubernetes, let’s consider how you should create and maintain clusters. If you
    commit to a single cloud provider, and you are happy with using their tooling,
    then you are set. All cloud providers let you create and configure Kubernetes
    clusters using either a Web UI, a CLI, or an API. However, if you prefer a more
    general approach and want to utilize GitOps to manage your clusters, you should
    look into Infrastructure as Code solutions such as Terraform and Pulumi.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们查看云服务提供商及其对托管和非托管 Kubernetes 的支持之前，让我们先考虑一下你应该如何创建和维护集群。如果你决定使用一个云服务提供商，并且对使用他们的工具感到满意，那么你就准备好了。所有云服务提供商都允许你通过
    Web UI、CLI 或 API 来创建和配置 Kubernetes 集群。然而，如果你更倾向于采用更通用的方法，并希望利用 GitOps 来管理集群，那么你应该研究如
    Terraform 和 Pulumi 等基础设施即代码的解决方案。
- en: 'If you prefer to roll out non-managed Kubernetes clusters in the cloud, then
    kOps is a strong candidate. See: [https://kops.sigs.k8s.io](https://kops.sigs.k8s.io).'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你倾向于在云端部署非托管的 Kubernetes 集群，那么 kOps 是一个强有力的候选方案。请参见：[https://kops.sigs.k8s.io](https://kops.sigs.k8s.io)。
- en: Later, in *Chapter 17*, *Running Kubernetes in Production*, we will discuss
    in detail the topic of multi-cluster provisioning and management. There are many
    technologies, open source projects, and commercial products in this space.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 在稍后的*第17章*，*在生产环境中运行 Kubernetes*，我们将详细讨论多集群配置和管理的话题。这个领域有许多技术、开源项目和商业产品。
- en: For now, let’s look at the various cloud providers.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来看一下各种云服务提供商。
- en: GCP
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GCP
- en: The **Google Cloud Platform** (**GCP**) supports Kubernetes out of the box.
    The so-called **Google Kubernetes Engine** (**GKE**) is a container management
    solution built on Kubernetes. You don’t need to install Kubernetes on GCP, and
    you can use the Google Cloud API to create Kubernetes clusters and provision them.
    The fact that Kubernetes is a built-in part of the GCP means it will always be
    well integrated and well tested, and you don’t have to worry about changes in
    the underlying platform breaking the cloud-provider interface.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: '**谷歌云平台**（**GCP**）原生支持 Kubernetes。所谓的 **Google Kubernetes Engine**（**GKE**）是一个基于
    Kubernetes 的容器管理解决方案。你无需在 GCP 上安装 Kubernetes，可以使用 Google Cloud API 来创建和配置 Kubernetes
    集群。Kubernetes 是 GCP 的内建部分，这意味着它将始终与 GCP 深度集成，并经过充分测试，你不必担心底层平台的变化会破坏云服务提供商的接口。'
- en: If you prefer to manage Kubernetes yourself, then you can just deploy it directly
    on GCP instances (or use kOps alpha support for GCP), but I would generally advise
    against it as GKE does a lot of work for you and it’s integrated deeply with GCP
    compute, networking, and core services.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你更倾向于自行管理 Kubernetes，那么你可以直接在 GCP 实例上部署它（或使用 kOps 的 GCP alpha 支持），但我一般不建议这么做，因为
    GKE 为你做了很多工作，并且它与 GCP 的计算、网络和核心服务深度集成。
- en: All in all, if you plan to base your system on Kubernetes and you don’t have
    any existing code on other cloud platforms, then GCP is a solid choice. It leads
    the pack in terms of maturity, polish, and depth of integration to GCP services,
    and is usually the first to update to newer versions of Kubernetes.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，如果你计划基于 Kubernetes 构建系统，并且没有在其他云平台上已有现有代码，那么 GCP 是一个可靠的选择。它在成熟度、精致度和与 GCP
    服务的深度集成方面处于领先地位，并且通常是第一个更新到 Kubernetes 新版本的云平台。
- en: I spent a lot of time with Kubernetes on GKE, managing tens of clusters, upgrading
    them, and deploying workloads. GKE is production-grade Kubernetes for sure.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 我在 GKE 上花了很多时间，管理了几十个集群，升级它们并部署工作负载。GKE 毫无疑问是一个生产级的 Kubernetes 解决方案。
- en: GKE Autopilot
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: GKE 自动驾驶
- en: GKE also has the Autopilot project, which takes care of managing worker nodes
    and node pools for you, so you focus on deploying and configuring workloads.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: GKE 还有一个名为 Autopilot 的项目，它为你管理工作节点和节点池，让你可以专注于部署和配置工作负载。
- en: 'See: [https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview](https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview).'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 请参见：[https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview](https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview)。
- en: AWS
  id: totrans-328
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: AWS
- en: '**AWS** has its own container management service called ECS, which is not based
    on Kubernetes. It also has a managed Kubernetes service called EKS. You can run
    Kubernetes yourself on AWS EC2 instances. Let’s talk about how to roll your own
    Kubernetes first and then we’ll discuss EKS.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: '**AWS** 有自己的容器管理服务，称为 ECS，它不是基于 Kubernetes 的。它也有一个托管的 Kubernetes 服务，称为 EKS。你可以在
    AWS EC2 实例上自行运行 Kubernetes。我们先来谈谈如何自建 Kubernetes，然后再讨论 EKS。'
- en: Kubernetes on EC2
  id: totrans-330
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在 EC2 上运行 Kubernetes
- en: AWS was a supported cloud provider from the get-go. There is a lot of documentation
    on how to set it up. While you could provision some EC2 instances yourself and
    use kubeadm to create a cluster, I recommend using the kOps (Kubernetes Operations)
    project mentioned earlier. kOps initially supported only AWS and is generally
    considered the most battle-tested and feature-rich tool for self-provisioning
    Kubernetes clusters on AWS (without using EKS).
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 从一开始就是一个支持的云服务提供商。有大量的文档说明如何进行设置。尽管您可以自己配置一些 EC2 实例并使用 kubeadm 创建集群，但我建议使用之前提到的
    kOps（Kubernetes 操作）项目。kOps 最初只支持 AWS，通常被认为是最经受考验且功能最丰富的工具，用于在 AWS 上自我配置 Kubernetes
    集群（不使用 EKS）。
- en: 'It supports the following features:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 它支持以下功能：
- en: Automated Kubernetes cluster CRUD for the cloud (AWS)
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动化的 Kubernetes 集群 CRUD 操作（适用于 AWS）
- en: HA Kubernetes clusters
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高可用 Kubernetes 集群
- en: Uses a state-sync model for dry-run and automatic idempotency
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用状态同步模型进行干运行和自动幂等性
- en: Custom support for kubectl addons
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对 kubectl 插件的自定义支持
- en: kOps can generate Terraform configuration
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: kOps 可以生成 Terraform 配置
- en: Based on a simple meta-model defined in a directory tree
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基于在目录树中定义的简单元模型
- en: Easy command-line syntax
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的命令行语法
- en: Community support
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 社区支持
- en: 'To create a cluster, you need to do some IAM and DNS configuration, set up
    an S3 bucket to store the cluster configuration, and then run a single command:'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 要创建一个集群，您需要进行一些 IAM 和 DNS 配置，设置一个 S3 桶来存储集群配置，然后运行一个命令：
- en: '[PRE67]'
  id: totrans-342
  prefs: []
  type: TYPE_PRE
  zh: '[PRE67]'
- en: 'The complete instructions are here: [https://kops.sigs.k8s.io/getting_started/aws/](https://kops.sigs.k8s.io/getting_started/aws/).'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的说明在这里：[https://kops.sigs.k8s.io/getting_started/aws/](https://kops.sigs.k8s.io/getting_started/aws/)。
- en: 'At the end of 2017, AWS joined the CNCF and made two big announcements regarding
    Kubernetes: its own Kubernetes-based container orchestration solution (EKS) and
    a container-on-demand solution (Fargate).'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 2017 年底，AWS 加入了 CNCF，并发布了关于 Kubernetes 的两项重要公告：其基于 Kubernetes 的容器编排解决方案（EKS）和按需容器解决方案（Fargate）。
- en: Amazon EKS
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Amazon EKS
- en: '**Amazon Elastic Kubernetes Service** (**EKS**) is a fully managed and highly
    available Kubernetes solution. It has three control plane nodes running in three
    AZs. EKS also takes care of upgrades and patching. The great thing about EKS is
    that it runs a stock Kubernetes. This means you can use all the standard plugins
    and tools developed by the community. It also opens the door to convenient cluster
    federation with other cloud providers and/or your own on-premise Kubernetes clusters.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '**Amazon 弹性 Kubernetes 服务** (**EKS**) 是一个完全托管且高可用的 Kubernetes 解决方案。它有三个控制平面节点，分别运行在三个
    AZ（可用区）。EKS 还会处理升级和补丁管理。EKS 的一个优点是它运行的是标准 Kubernetes。这意味着您可以使用社区开发的所有标准插件和工具。它还为与其他云服务提供商和/或您自己的本地
    Kubernetes 集群进行便捷的集群联合打开了大门。'
- en: EKS provides deep integration with AWS infrastructure like IAM authentication,
    which is integrated with Kubernetes **Role-Based Access Control** (**RBAC**).
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: EKS 提供与 AWS 基础设施的深度集成，例如与 Kubernetes **基于角色的访问控制** (**RBAC**) 集成的 IAM 身份验证。
- en: You can also use PrivateLink if you want to access your Kubernetes masters directly
    from your own Amazon VPC. With PrivateLink, your Kubernetes control plane and
    the Amazon EKS service endpoint appear as an elastic network interface with private
    IP addresses in your Amazon VPC.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望直接从自己的 Amazon VPC 访问 Kubernetes 主节点，还可以使用 PrivateLink。通过 PrivateLink，您的
    Kubernetes 控制平面和 Amazon EKS 服务终端将作为具有私有 IP 地址的弹性网络接口显示在您的 Amazon VPC 中。
- en: Another important piece of the puzzle is a special CNI plugin that lets your
    Kubernetes components talk to each other using AWS networking.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关键部分是一个特殊的 CNI 插件，允许您的 Kubernetes 组件使用 AWS 网络进行相互通信。
- en: EKS keeps getting better and Amazon demonstrated that it is committed to keeping
    it up to date and improving it. If you are an AWS shop and getting into Kubernetes,
    I recommend starting with EKS as opposed to building your own cluster.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: EKS 不断改进，亚马逊展示了其致力于保持更新和不断优化的承诺。如果您是 AWS 用户并开始使用 Kubernetes，我建议从 EKS 开始，而不是自行构建集群。
- en: The eksctl tool is a great CLI for creating and managing EKS clusters and node
    groups for testing and development. I successfully created, deleted, and added
    nodes to several Kubernetes clusters on AWS using eksctl. Check out [https://eksctl.io/](https://eksctl.io/).
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: eksctl 工具是一个出色的 CLI，用于创建和管理 EKS 集群以及节点组，以便进行测试和开发。我使用 eksctl 成功创建、删除并向多个 AWS
    上的 Kubernetes 集群添加节点。查看 [https://eksctl.io/](https://eksctl.io/)。
- en: Fargate
  id: totrans-352
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Fargate
- en: '**Fargate** lets you run containers directly without worrying about provisioning
    hardware. It eliminates a huge part of the operational complexity at the cost
    of losing some control. When using Fargate, you package your application into
    a container, specify CPU and memory requirements, define networking and IAM policies,
    and you’re off to the races. Fargate can run on top of ECS and EKS. It is a very
    interesting member of the serverless camp although it’s not specific to Kubernetes
    like GKE’s Autopilot.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '**Fargate** 让你可以直接运行容器，无需担心硬件配置。它通过牺牲一些控制权，消除了大量的操作复杂性。在使用 Fargate 时，你将应用程序打包成容器，指定
    CPU 和内存需求，定义网络和 IAM 策略，然后即可开始。Fargate 可以在 ECS 和 EKS 上运行。它是无服务器阵营中一个非常有趣的成员，尽管它不像
    GKE 的 Autopilot 那样专门为 Kubernetes 定制。'
- en: Azure
  id: totrans-354
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Azure
- en: '**Azure** used to have its own container management service based on Mesos-based
    DC/OS or Docker Swarm to manage your containers. But you can also use Kubernetes,
    of course. You could also provision the cluster yourself (for example, using Azure’s
    desired state configuration) and then create the Kubernetes cluster using kubeadm.
    kOps has alpha support for Azure, and the Kubespray project is a good option too.'
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: '**Azure** 曾经有一个基于 Mesos 的 DC/OS 或 Docker Swarm 的容器管理服务来管理你的容器。但你当然也可以使用 Kubernetes。你还可以自己配置集群（例如，使用
    Azure 的所需状态配置），然后通过 kubeadm 创建 Kubernetes 集群。kOps 对 Azure 提供了 alpha 级支持，Kubespray
    项目也是一个不错的选择。'
- en: However, in the second half of 2017 Azure jumped on the Kubernetes bandwagon
    too and introduced **AKS** (**Azure Kubernetes Service**). It is similar to Amazon
    EKS, although it’s a little further ahead in its implementation.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在 2017 年下半年，Azure 也加入了 Kubernetes 队列，并推出了 **AKS**（**Azure Kubernetes 服务**）。它与
    Amazon EKS 类似，尽管其实现略微领先。
- en: AKS provides a Web UI, CLI, and REST API to manage your Kubernetes clusters.
    Once, an AKS cluster is configured, you can use kubectl and any other Kubernetes
    tooling directly.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: AKS 提供 Web UI、CLI 和 REST API 来管理你的 Kubernetes 集群。一旦 AKS 集群配置完成，你可以直接使用 kubectl
    及任何其他 Kubernetes 工具。
- en: 'Here are some of the benefits of using AKS:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是使用 AKS 的一些好处：
- en: Automated Kubernetes version upgrades and patching
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动 Kubernetes 版本升级和补丁
- en: Easy cluster scaling
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 简单的集群扩展
- en: Self-healing hosted control plane (masters)
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自愈的托管控制平面（主控节点）
- en: Cost savings – pay only for running agent pool nodes
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 成本节省 – 仅为运行代理池节点付费
- en: AKS also offers integration with **Azure Container Instances** (**ACI**), which
    is similar to AWS Fargate and GKE AutoPilot. This means that not only the control
    plane of your Kubernetes cluster is managed, but also the worker nodes.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: AKS 还提供与 **Azure 容器实例**（**ACI**）的集成，类似于 AWS Fargate 和 GKE AutoPilot。这意味着不仅是你的
    Kubernetes 集群的控制平面是托管的，连同工作节点也是。
- en: Digital Ocean
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Digital Ocean
- en: Digital Ocean is not a cloud provider on the order of the big three (GCP, AWS,
    Azure), but it does provide a managed Kubernetes solution and it has data centers
    across the world (US, Canada, Europe, Asia). It is also much cheaper compared
    to the alternatives, and cost is a major deciding factor when choosing a cloud
    provider. With Digital Ocean, the control plane doesn’t cost anything. Besides
    lower prices Digital Ocean’s claim to fame is simplicity.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: Digital Ocean 并不是像 GCP、AWS、Azure 那样的大型云服务提供商，但它确实提供了托管的 Kubernetes 解决方案，并且在全球（美国、加拿大、欧洲、亚洲）都有数据中心。与其他选择相比，它也便宜得多，而成本通常是选择云服务提供商时的决定性因素。使用
    Digital Ocean 时，控制平面不收费。除了更低的价格，Digital Ocean 还以简单性著称。
- en: '**DOKS** (**Digital Ocean Kubernetes Service**) gives you a managed Kubernetes
    control plane (which can be highly available) and integration with Digital Ocean’s
    droplets (for nodes and node pools), load balancers, and block storage volumes.
    This covers all the basic needs. Your clusters are of course CNCF conformant.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '**DOKS**（**数字海洋 Kubernetes 服务**）为你提供了一个托管的 Kubernetes 控制平面（可以实现高可用性）并与 Digital
    Ocean 的 Droplets（用于节点和节点池）、负载均衡器和块存储卷进行集成。这满足了所有基本需求。你的集群当然符合 CNCF 标准。'
- en: Digital Ocean will take care of system upgrades, security patches, and the installed
    packages on the control plane as well as the worker nodes.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: Digital Ocean 将负责控制平面以及工作节点上的系统升级、安全补丁和已安装的包。
- en: Other cloud providers
  id: totrans-368
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 其他云服务提供商
- en: GCP, AWS, and Azure are leading the pack, but there are quite a few other companies
    that offer managed Kubernetes services. In general, I recommend using these providers
    if you already have significant business connections or integrations.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: GCP、AWS 和 Azure 是行业领先者，但也有很多其他公司提供托管的 Kubernetes 服务。一般来说，如果你已经与这些云服务提供商有显著的业务联系或集成，我推荐使用它们。
- en: Once upon a time in China
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从前，在中国
- en: 'If you operate in China with its special constraints and limitations, you should
    probably use a Chinese cloud platform. There are three big ones: Alibaba, Tencent,
    and Huawei.'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: 'The Chinese **Alibaba** cloud is an up-and-comer on the cloud platform scene.
    It mimics AWS pretty closely, although its English documentation leaves a lot
    to be desired. The Alibaba cloud supports Kubernetes in several ways via its **ACK**
    (**Alibaba Container service for Kubernetes**) and allows you to:'
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: Run your own dedicated Kubernetes cluster (you must create 3 master nodes and
    upgrade and maintain them)
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the managed Kubernetes cluster (you’re just responsible for the worker nodes)
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the serverless Kubernetes cluster via **ECI** (**Elastic Container Instances**),
    which is similar to Fargate and ACI
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ACK is a CNCF-certified Kubernetes distribution. If you need to deploy cloud-native
    applications in China, then ACK looks like a solid option.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: See [https://www.alibabacloud.com/product/kubernetes](https://www.alibabacloud.com/product/kubernetes).
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: Tencent is another large Chinese company with its own cloud platform and Kubernetes
    support. **TKE** (**Tencent Kubernetes Engine**) seems less mature than ACK. See
    [https://intl.cloud.tencent.com/products/tke](https://intl.cloud.tencent.com/products/tke).
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the Huawei cloud platform offers **CCE** (**Cloud Container Engine**),
    which is built on Kubernetes. It supports VMs, bare metal, and GPU accelerated
    instances. See [https://www.huaweicloud.com/intl/en-us/product/cce.html](https://www.huaweicloud.com/intl/en-us/product/cce.html).
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: IBM Kubernetes service
  id: totrans-380
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: IBM is investing heavily in Kubernetes. It acquired Red Hat at the end of 2018\.
    Red Hat was of course a major player in the Kubernetes world, building its OpenShift
    Kubernetes-based platform and contributing RBAC to Kubernetes. IBM has its own
    cloud platform and it offers a managed Kubernetes cluster. You can try it out
    for free with $200 credit and there is also a free tier.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: IBM is also involved in the development of Istio and Knative, so you can expect
    IKS to have deep integration with those technologies.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: IKS offers integration with a lot of IBM services.
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: See [https://www.ibm.com/cloud/kubernetes-service](https://www.ibm.com/cloud/kubernetes-service).
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: Oracle Container Service
  id: totrans-385
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Oracle also has a cloud platform and of course, it offers a managed Kubernetes
    service too, with high availability, bare-metal instances, and multi-AZ support.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: OKE supports ARM and GPU instances and also offers a few control plane options.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: See [https://www.oracle.com/cloud/cloud-native/container-engine-kubernetes/](https://www.oracle.com/cloud/cloud-native/container-engine-kubernetes/).
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered the cloud-provider interface and looked at the recommended
    ways to create Kubernetes clusters on various cloud providers. The scene is still
    young and the tools evolve quickly. I believe convergence will happen soon. Kubeadm
    has matured and is the underlying foundation of many other tools to bootstrap
    and create Kubernetes clusters on and off the cloud. Let’s consider now what it
    takes to create bare-metal clusters where you have to provision the hardware and
    low-level networking and storage too.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: Creating a bare-metal cluster from scratch
  id: totrans-390
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we looked at running Kubernetes on cloud providers.
    This is the dominant deployment story for Kubernetes. But there are strong use
    cases for running Kubernetes on bare metal, such as Kubernetes on the edge. We
    don’t focus here on hosted versus on-premise. This is yet another dimension. If
    you already manage a lot of servers on-premise, you are in the best position to
    decide.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: Use cases for bare metal
  id: totrans-392
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bare-metal clusters are a bear to deal with, especially if you manage them yourself.
    There are companies that provide commercial support for bare-metal Kubernetes
    clusters, such as Platform 9, but the offerings are not mature yet. A solid open-source
    option is Kubespray, which can deploy industrial-strength Kubernetes clusters
    on bare metal, AWS, GCE, Azure, and OpenStack.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some use cases where it makes sense:'
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
- en: '**Price**: If you already manage large-scale bare-metal clusters, it may be
    much cheaper to run Kubernetes clusters on your physical infrastructure'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Low network latency**: If you must have low latency between your nodes, then
    the VM overhead might be too much'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regulatory requirements**: If you must comply with regulations, you may not
    be allowed to use cloud providers'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**You want total control over hardware**: Cloud providers give you many options,
    but you may have special needs'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When should you consider creating a bare-metal cluster?
  id: totrans-399
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The complexities of creating a cluster from scratch are significant. A Kubernetes
    cluster is not a trivial beast. There is a lot of documentation on the web on
    how to set up bare-metal clusters, but as the whole ecosystem moves forward, many
    of these guides get out of date quickly.
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: You should consider going down this route if you have the operational capability
    to troubleshoot problems at every level of the stack. Most of the problems will
    probably be networking-related, but filesystems and storage drivers can bite you
    too, as well as general incompatibilities and version mismatches between components
    such as Kubernetes itself, Docker (or other runtimes, if you use them), images,
    your OS, your OS kernel, and the various addons and tools you use. If you opt
    for using VMs on top of bare metal, then you add another layer of complexity.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the process
  id: totrans-402
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is a lot to do. Here is a list of some of the concerns you’ll have to
    address:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
- en: Implementing your own cloud-provider interface or sidestepping it
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a networking model and how to implement it (CNI plugin, direct compile)
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择网络模型及其实现方式（CNI 插件、直接编译）
- en: Whether or not to use network policies
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否使用网络策略
- en: Selecting images for system components
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择系统组件的镜像
- en: The security model and SSL certificates
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安全模型和 SSL 证书
- en: Admin credentials
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理员凭证
- en: Templates for components such as API Server, replication controller, and scheduler
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 组件模板，如 API 服务器、复制控制器和调度器
- en: 'Cluster services: DNS, logging, monitoring, and GUI'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 集群服务：DNS、日志、监控和 GUI
- en: 'I recommend the following guide from the Kubernetes site to get a deeper understanding
    of what it takes to create a HA cluster from scratch using kubeadm:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 我推荐 Kubernetes 网站上的以下指南，以深入了解使用 kubeadm 从零开始创建高可用集群的过程：
- en: '[https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/)'
  id: totrans-413
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/)'
- en: Using the Cluster API for managing bare-metal clusters
  id: totrans-414
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Cluster API 管理裸金属集群
- en: 'The Cluster API (AKA CAPI) is a Kubernetes sub-project for managing Kubernetes
    clusters at scale. It uses kubeadm for provisioning. It can provision and manage
    Kubernetes clusters in any environment using providers. At work, we use it to
    manage multiple clusters in the cloud. But, it has multiple providers for bare-metal
    clusters:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
  zh: Cluster API（也叫 CAPI）是一个 Kubernetes 子项目，用于大规模管理 Kubernetes 集群。它使用 kubeadm 进行配置。它可以在任何环境中使用提供程序来配置和管理
    Kubernetes 集群。在工作中，我们使用它来管理云中的多个集群。但它也有多个提供程序支持裸金属集群：
- en: MAAS
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MAAS
- en: Equinix metal
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Equinix metal
- en: Metal3
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Metal3
- en: Cidero
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cidero
- en: See [https://cluster-api.sigs.k8s.io](https://cluster-api.sigs.k8s.io).
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: 请参见 [https://cluster-api.sigs.k8s.io](https://cluster-api.sigs.k8s.io)。
- en: Using virtual private cloud infrastructure
  id: totrans-421
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用虚拟私有云基础设施
- en: If your use case falls under the bare-metal use cases but you don’t have the
    necessary skilled manpower or the inclination to deal with the infrastructure
    challenges of bare metal, you have the option to use a private cloud such as OpenStack.
    If you want to aim a little higher in the abstraction ladder, then Mirantis offers
    a cloud platform built on top of OpenStack and Kubernetes.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的使用场景属于裸金属用例，但您没有必要的技术人员或不愿意处理裸金属的基础设施挑战，您可以选择使用 OpenStack 等私有云。如果您希望在抽象层次上更进一步，那么
    Mirantis 提供了一个建立在 OpenStack 和 Kubernetes 之上的云平台。
- en: Let’s review a few more tools for building Kubernetes clusters on bare metal.
    Some of these tools support OpenStack as well.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回顾一下在裸金属上构建 Kubernetes 集群的一些工具。这些工具中的一些也支持 OpenStack。
- en: Building your own cluster with Kubespray
  id: totrans-424
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Kubespray 构建自己的集群
- en: 'Kubespray is a project for deploying production-ready highly available Kubernetes
    clusters. It uses Ansible and can deploy Kubernetes on a large number of targets
    such as:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: Kubespray 是一个用于部署生产就绪的高可用性 Kubernetes 集群的项目。它使用 Ansible 并可以在大量目标上部署 Kubernetes，例如：
- en: AWS
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: AWS
- en: GCE
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GCE
- en: Azure
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azure
- en: OpenStack
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: OpenStack
- en: vSphere
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: vSphere
- en: Equinix metal
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Equinix metal
- en: Oracle Cloud Infrastructure (Experimental)
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oracle Cloud Infrastructure（实验性）
- en: It is also used to deploy Kubernetes clusters on plain bare-metal machines.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 它也用于在普通裸金属机器上部署 Kubernetes 集群。
- en: It is highly customizable and supports multiple operating systems for the nodes,
    multiple CNI plugins for networking, and multiple container runtimes.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 它高度可定制，支持多种操作系统节点、多个 CNI 插件用于网络连接，以及多个容器运行时。
- en: If you want to test it locally, it can deploy to a multi-node vagrant setup
    too. If you’re an Ansible fan, Kubespray may be a great choice for you.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想在本地测试，它也可以部署到多节点的 Vagrant 设置中。如果您是 Ansible 的粉丝，Kubespray 可能是一个不错的选择。
- en: See [https://kubespray.io](https://kubespray.io).
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 请参见 [https://kubespray.io](https://kubespray.io)。
- en: Building your cluster with Rancher RKE
  id: totrans-437
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Rancher RKE 构建集群
- en: '**Rancher Kubernetes Engine** (**RKE**) is a friendly Kubernetes installer
    that can install Kubernetes on bare metal as well as virtualized servers. RKE
    aims to address the complexity of installing Kubernetes. It is open source and
    has great documentation. Check it out here: [http://rancher.com/docs/rke/v0.1.x/en/](http://rancher.com/docs/rke/v0.1.x/en/).'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: '**Rancher Kubernetes Engine**（**RKE**）是一个友好的 Kubernetes 安装器，可以在裸金属和虚拟化服务器上安装
    Kubernetes。RKE 旨在解决安装 Kubernetes 的复杂性。它是开源的，并且有很好的文档。您可以在这里查看：[http://rancher.com/docs/rke/v0.1.x/en/](http://rancher.com/docs/rke/v0.1.x/en/)。'
- en: Running managed Kubernetes on bare metal or VMs
  id: totrans-439
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在裸金属或虚拟机上运行托管 Kubernetes
- en: The cloud providers didn’t want to confine themselves to their own cloud only.
    They all offer multi-cloud and hybrid solutions where you can control Kubernetes
    clusters on multiple clouds as well as use their managed control plane on VMs
    anywhere.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
- en: GKE Anthos
  id: totrans-441
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Anthos is a comprehensive managed platform that facilitates the deployment of
    applications, encompassing both traditional and cloud-native environments. It
    empowers you to construct and oversee global fleets of applications while ensuring
    operational consistency across them.
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
- en: EKS Anywhere
  id: totrans-443
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon EKS Anywhere presents a fresh deployment alternative for Amazon EKS that
    enables you to establish and manage Kubernetes clusters on your infrastructure
    with AWS support. It grants you the flexibility to run Amazon EKS Anywhere on
    your own on-premises infrastructure, utilizing VMware vSphere, as well as bare
    metal environments.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
- en: AKS Arc
  id: totrans-445
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure Arc encompasses a collection of technologies that extend Azure’s security
    and cloud-native services to hybrid and multi-cloud environments. It empowers
    you to safeguard and manage your infrastructure and applications across various
    locations while providing familiar tools and services to accelerate the development
    of cloud-native apps. These applications can then be deployed on any Kubernetes
    platform.
  id: totrans-446
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered creating bare-metal Kubernetes clusters, which gives
    you total control, but is highly complicated, and requires a tremendous amount
    of effort and knowledge. Luckily, there are multiple tools, projects, and frameworks
    to assist you.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-448
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we got into some hands-on cluster creation. We created single-node
    and multi-node clusters using tools like Minikube, KinD, and k3d. Then we looked
    at the various options to create Kubernetes clusters on cloud providers. Finally,
    we touched on the complexities of creating Kubernetes clusters on bare metal.
    The current state of affairs is very dynamic. The basic components are changing
    rapidly, the tooling is getting better, and there are different options for each
    environment. Kubeadm is now the cornerstone of most installation options, which
    is great for consistency and consolidation of effort. It’s still not completely
    trivial to stand up a Kubernetes cluster on your own, but with some effort and
    attention to detail, you can get it done quickly.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: I highly recommend considering the Cluster API as the go-to solution for provisioning
    and managing clusters in any environment – managed, private cloud, VMs, and bare
    metal. We will discuss the Cluster API in depth in *Chapter 17*, *Running Kubernetes
    in Production*.
  id: totrans-450
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore the important topics of scalability and
    high availability. Once your cluster is up and running, you need to make sure
    it stays that way even as the volume of requests increases. This requires ongoing
    attention and building the ability to recover from failures as well adjusting
    to changes in traffic.
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: Join us on Discord!
  id: totrans-452
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Read this book alongside other users, cloud experts, authors, and like-minded
    professionals.
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
- en: Ask questions, provide solutions to other readers, chat with the authors via.
    Ask Me Anything sessions and much more.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: Scan the QR code or visit the link to join the community now.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code844810820358034203.png)'
  id: totrans-457
  prefs: []
  type: TYPE_IMG
