- en: '2'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating Kubernetes Clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we learned what Kubernetes is all about, how it is
    designed, what concepts it supports, its architecture, and the various container
    runtimes it supports.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a Kubernetes cluster from scratch is a non-trivial task. There are
    many options and tools to select from. There are many factors to consider. In
    this chapter, we will roll our sleeves up and build some Kubernetes clusters using
    Minikube, KinD, and k3d. We will discuss and evaluate other tools such as Kubeadm
    and Kubespray. We will also look into deployment environments such as local, cloud,
    and bare metal. The topics we will cover are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready for your first cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a single-node cluster with Minikube
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a multi-node cluster with KinD
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a multi-node cluster using k3d
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating clusters in the cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating bare-metal clusters from scratch
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reviewing other options for creating Kubernetes clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At the end of this chapter, you will have a solid understanding of the various
    options to create Kubernetes clusters and knowledge of the best-of-breed tools
    to support the creation of Kubernetes clusters, and you will also build several
    clusters, both single-node and multi-node.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready for your first cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before we start creating clusters, we should install a couple of tools such
    as the Docker client and kubectl. These days, the most convenient way to install
    Docker and kubectl on Mac and Windows is via Rancher Desktop. If you already have
    them installed, feel free to skip this section.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Rancher Desktop
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Rancher Desktop is a cross-platform desktop application that lets you run Docker
    on your local machine. It will install additional tools such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Helm
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubectl
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nerdctl
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moby (open source Docker)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Compose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installation on macOS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The most streamlined way to install Rancher Desktop on macOS is via Homebrew:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Installation on Windows
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The most streamlined way to install Rancher Desktop on Windows is via Chocolatey:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Additional installation methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'For alternative methods to install Docker Desktop, follow the instructions
    here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://docs.rancherdesktop.io/getting-started/installation/](https://docs.rancherdesktop.io/getting-started/installation/)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s verify `docker` was installed correctly. Type the following commands
    and make sure you don’t see any errors (the output doesn’t have to be identical
    if you installed a different version than mine):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'And, while we’re at it, let’s verify kubectl has been installed correctly too:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: The `Server` section may be empty if no active Kubernetes server is up and running.
    When you see this output, you can rest assured that kubectl is ready to go.
  prefs: []
  type: TYPE_NORMAL
- en: Meet kubectl
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we start creating clusters, let’s talk about kubectl. It is the official
    Kubernetes CLI, and it interacts with your Kubernetes cluster’s API server via
    its API. It is configured by default using the `~/.kube/config` file, which is
    a YAML file that contains metadata, connection info, and authentication tokens
    or certificates for one or more clusters. Kubectl provides commands to view your
    configuration and switch between clusters if it contains more than one. You can
    also point kubectl at a different config file by setting the `KUBECONFIG` environment
    variable or passing the `--kubeconfig` command-line flag.
  prefs: []
  type: TYPE_NORMAL
- en: 'The code below uses a `kubectl` command to check the pods in the `kube-system`
    namespace of the current active cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Kubectl is great, but it is not the only game in town. Let’s look at some alternative
    tools.
  prefs: []
  type: TYPE_NORMAL
- en: Kubectl alternatives – K9S, KUI, and Lens
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubectl is a no-nonsense command-line tool. It is very powerful, but it may
    be difficult or less convenient for some people to visually parse its output or
    remember all the flags and options. There are many tools the community developed
    that can replace (or more like complement) kubectl. The best ones, in my opinion,
    are K9S, KUI, and Lens.
  prefs: []
  type: TYPE_NORMAL
- en: K9S
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: K9S is a terminal-based UI for managing Kubernetes clusters. It has a lot of
    shortcuts and aggregated views that will require multiple kubectl commands to
    accomplish.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what the K9S window looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B18998_02_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.1: K9S window'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check it out here: [https://k9scli.io](https://k9scli.io)'
  prefs: []
  type: TYPE_NORMAL
- en: KUI
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: KUI is a framework for adding graphics to **CLIs** (**command-line interfaces**).
    This is a very interesting concept. KUI is focused on Kubernetes of course. It
    lets you run Kubectl commands and returns the results as graphics. KUI also collects
    a lot of relevant information and presents it in a concise way with tabs and detail
    panes to explore even deeper.
  prefs: []
  type: TYPE_NORMAL
- en: KUI is based on Electron, but it is fast.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what the KUI window looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface  Description automatically generated](img/B18998_02_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.2: KUI window'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check it out here: [https://kui.tools](https://kui.tools)'
  prefs: []
  type: TYPE_NORMAL
- en: Lens
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Lens is a very polished application. It also presents a graphical view of clusters
    and allows you to perform a lot of operations from the UI and drop to a terminal
    interface when necessary. I especially appreciate the ability to work easily with
    multiple clusters that Lens provides.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is what the Lens window looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B18998_02_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.3: Lens window'
  prefs: []
  type: TYPE_NORMAL
- en: 'Check it out here: [https://k8slens.dev](https://k8slens.dev)'
  prefs: []
  type: TYPE_NORMAL
- en: All these tools are running locally. I highly recommend that you start playing
    with kubectl and then give these tools a test drive. One of them may just be your
    speed.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered the installation of Rancher Desktop, introduced
    kubectl, and looked at some alternatives. We are now ready to create our first
    Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a single-node cluster with Minikube
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will create a local single-node cluster using Minikube.
    Local clusters are most useful for developers that want quick edit-test-deploy-debug
    cycles on their machine before committing their changes. Local clusters are also
    very useful for DevOps and operators that want to play with Kubernetes locally
    without concerns about breaking a shared environment or creating expensive resources
    in the cloud and forgetting to clean them up. While Kubernetes is typically deployed
    on Linux in production, many developers work on Windows PCs or Macs. That said,
    there aren’t too many differences if you do want to install Minikube on Linux.
  prefs: []
  type: TYPE_NORMAL
- en: '![A picture containing text, clipart  Description automatically generated](img/B18998_02_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.4: minikube'
  prefs: []
  type: TYPE_NORMAL
- en: Quick introduction to Minikube
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Minikube is the most mature local Kubernetes cluster. It runs the latest stable
    Kubernetes release. It supports Windows, macOS, and Linux. Minikube provides a
    lot of advanced options and capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: LoadBalancer service type - via minikube tunnel
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NodePort service type - via minikube service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiple clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Filesystem mounts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GPU support - for machine learning
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: RBAC
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Persistent Volumes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ingress
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dashboard - via minikube dashboard
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom container runtimes - via the `start --container-runtime` flag
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Configuring API server and kubelet options via command-line flags
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Addons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Installing Minikube
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The ultimate guide is here: [https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/)'
  prefs: []
  type: TYPE_NORMAL
- en: But, to save you a trip, here are the latest instructions at the time of writing.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Minikube on Windows
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'On Windows, I prefer to install software via the Chocolatey package manager.
    If you don’t have it yet, you can get it here: [https://chocolatey.org/](https://chocolatey.org/)'
  prefs: []
  type: TYPE_NORMAL
- en: If you don’t want to use Chocolatey, check the ultimate guide above for alternative
    methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'With Chocolatey installed, the installation is pretty simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: On Windows, you can work in different command-line environments. The most common
    ones are PowerShell and **WSL** (**Windows System for Linux**). Either one works.
    You may need to run them in Administrator mode for certain operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'As far as console windows go, I recommend the official Windows Terminal these
    days. You can install it with one command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: If you prefer other console windows such as ConEMU or Cmdr, this is totally
    fine.
  prefs: []
  type: TYPE_NORMAL
- en: I’ll use shortcuts to make life easy. If you want to follow along and copy the
    aliases into your profile, you can use the following for PowerShell and WSL.
  prefs: []
  type: TYPE_NORMAL
- en: 'For PowerShell, add the following to your `$profile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'For WSL, add the following to `.bashrc`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s verify that minikube was installed correctly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s create a cluster with `mk start`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the process is pretty complicated even for the default setup,
    and required multiple retries (automatically). You can customize the cluster creation
    process with a multitude of command-line flags. Type `mk start -h` to see what’s
    available.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check the status of our cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: All is well!
  prefs: []
  type: TYPE_NORMAL
- en: 'Now let’s stop the cluster and later restart it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Restarting with the time command to measure how long it takes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: It took a little over a minute.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s review what Minikube did behind the curtains for you. You’ll need to
    do a lot of it when creating a cluster from scratch:'
  prefs: []
  type: TYPE_NORMAL
- en: Started a Hyper-V VM
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Created certificates for the local machine and the VM
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Downloaded images
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set up networking between the local machine and the VM
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ran the local Kubernetes cluster on the VM
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configured the cluster
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Started all the Kubernetes control plane components
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configured the kubelet
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enabled addons (for storage)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Configured kubectl to talk to the cluster
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Installing Minikube on macOS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'On Mac, I recommend installing minikube using Homebrew:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'You can add aliases to your `.bashrc` file (similar to the WSL aliases on Windows):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now you can use `k` and `mk` and type less.
  prefs: []
  type: TYPE_NORMAL
- en: 'Type `mk version` to verify Minikube is correctly installed and functioning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Type `k version` to verify kubectl is correctly installed and functioning:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Note that the client version is 1.23\. Don’t worry about the error message.
    There is no cluster running, so kubectl can’t connect to anything. That’s expected.
    The error message will disappear when we create the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: You can explore the available commands and flags for both Minikube and kubectl
    by just typing the commands with no arguments.
  prefs: []
  type: TYPE_NORMAL
- en: To create the cluster on macOS, just run `mk start`.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting the Minikube installation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If something goes wrong during the process, try to follow the error messages.
    You can add the `--alsologtostderr` flag to get detailed error info to the console.
    Everything minikube does is organized neatly under `~/.minikube`. Here is the
    directory structure:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: If you don’t have the tree utility, you can install it.
  prefs: []
  type: TYPE_NORMAL
- en: 'On Windows: `$ choco install -y tree`'
  prefs: []
  type: TYPE_NORMAL
- en: 'On Mac: `brew install tree`'
  prefs: []
  type: TYPE_NORMAL
- en: Checking out the cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we have a cluster up and running, let’s peek inside.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s `ssh` into the VM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Great! That works. The weird symbols are ASCII art for “minikube.” Now, let’s
    start using kubectl because it is the Swiss Army knife of Kubernetes and will
    be useful for all clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Disconnect from the VM via *ctrl*+*D* or by typing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We will cover many of the kubectl commands in our journey. First, let’s check
    the cluster status using `cluster-info`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that the control plane is running properly. To see a much more
    detailed view of all the objects in the cluster as JSON, type: `k cluster-info
    dump`. The output can be a little daunting let’s use more specific commands to
    explore the cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check out the nodes in the cluster using `get nodes`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'So, we have one node called minikube. To get a lot more information about it,
    type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: The output is verbose; I’ll let you try it yourself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before we start putting our cluster to work, let’s check the addons minikube
    installed by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, minikube comes loaded with a lot of addons, but only enables
    a couple of storage addons out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: Doing work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we start, if you have a VPN running, you may need to shut it down when
    pulling images.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have a nice empty cluster up and running (well, not completely empty, as
    the DNS service and dashboard run as pods in the kube-system namespace). It’s
    time to deploy some pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s check out the pod that was created. The `-w` flag means watch. Whenever
    the status changes, a new line will be displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'To expose our pod as a service, type the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Exposing the service as type `NodePort` means that it is exposed to the host
    on some port. But it is not the `8080` port we ran the pod on. Ports get mapped
    in the cluster. To access the service, we need the cluster IP and exposed port:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we can access the echo service, which returns a lot of information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations! You just created a local Kubernetes cluster, deployed a service,
    and exposed it to the world.
  prefs: []
  type: TYPE_NORMAL
- en: Examining the cluster with the dashboard
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes has a very nice web interface, which is deployed, of course, as a
    service in a pod. The dashboard is well designed and provides a high-level overview
    of your cluster as well as drilling down into individual resources, viewing logs,
    editing resource files, and more. It is the perfect weapon when you want to check
    out your cluster manually and don’t have local tools like KUI or Lens. Minikube
    provides it as an addon.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s enable it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'To launch it, type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Minikube will open a browser window with the dashboard UI.
  prefs: []
  type: TYPE_NORMAL
- en: Here is the **Workloads** view, which displays **Deployments**, **Replica Sets**,
    and **Pods**.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, chart, bubble chart  Description automatically
    generated](img/B18998_02_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.5: Workloads dashboard'
  prefs: []
  type: TYPE_NORMAL
- en: It can also display daemon sets, stateful sets, and jobs, but we don’t have
    any in this cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'To delete the cluster we created, type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: In this section, we created a local single-node Kubernetes cluster on Windows,
    explored it a little bit using kubectl, deployed a service, and played with the
    web UI. In the next section, we’ll move to a multi-node cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a multi-node cluster with KinD
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll create a multi-node cluster using KinD. We will also
    repeat the deployment of the echo server we deployed on Minikube and observe the
    differences. Spoiler alert - everything will be faster and easier!
  prefs: []
  type: TYPE_NORMAL
- en: Quick introduction to KinD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**KinD** stands for **Kubernetes in Docker**. It is a tool for creating ephemeral
    clusters (no persistent storage). It was built primarily for running the Kubernetes
    conformance tests. It supports Kubernetes 1.11+. Under the covers, it uses `kubeadm`
    to bootstrap Docker containers as nodes in the cluster. KinD is a combination
    of a library and a CLI. You can use the library in your code for testing or other
    purposes. KinD can create highly-available clusters with multiple control plane
    nodes. Finally, KinD is a CNCF conformant Kubernetes installer. It had better
    be if it’s used for the conformance tests of Kubernetes itself.'
  prefs: []
  type: TYPE_NORMAL
- en: 'KinD is super fast to start, but it has some limitations too:'
  prefs: []
  type: TYPE_NORMAL
- en: No persistent storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No support for alternative runtimes yet, only Docker
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s install KinD and get going.
  prefs: []
  type: TYPE_NORMAL
- en: Installing KinD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You must have Docker installed as KinD is literally running as a Docker container.
    If you have Go installed, you can install the KinD CLI via:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Otherwise, on macOS type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'On Windows type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Dealing with Docker contexts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You may have multiple Docker engines on your system and the Docker context
    determines which one is used. You may get an error like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'In this case, check your Docker contexts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The context marked with `*` is the current context. If you use Rancher Desktop,
    then you should set the context to `rancher-desktop`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: Creating a cluster with KinD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating a cluster is super easy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: It takes less than 30 seconds to create a single-node cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we can access the cluster using kubectl:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: KinD adds its kube context to the default `~/.kube/config` file by default.
    When creating a lot of temporary clusters, it is sometimes better to store the
    KinD contexts in separate files and avoid cluttering `~/.kube/config`. This is
    easily done by passing the `--kubeconfig` flag with a file path.
  prefs: []
  type: TYPE_NORMAL
- en: 'So, KinD creates a single-node cluster by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s delete it and create a multi-node cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'To create a multi-node cluster, we need to provide a configuration file with
    the specification of our nodes. Here is a configuration file that will create
    a cluster called `multi-node-cluster` with one control plane node and two worker
    nodes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s save the configuration file as `kind-multi-node-config.yaml` and create
    the cluster storing the kubeconfig with its own file `$TMPDIR/kind-multi-node-config`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'Yeah, it works! And we got a local 3-node cluster in less than a minute:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: 'KinD is also kind enough (see what I did there) to let us create **HA** (**highly
    available**) clusters with multiple control plane nodes for redundancy. If you
    want a highly available cluster with three control plane nodes and two worker
    nodes, your cluster config file will be very similar:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s save the configuration file as `kind-ha-multi-node-config.yaml` and create
    a new HA cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: Hmmm... there is something new here. Now KinD creates an external load balancer
    as well as joining more control plane nodes before joining the worker nodes. The
    load balancer is necessary to distribute requests across all the control plane
    nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the external load balancer doesn’t show as a node using kubectl:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: 'But, KinD has its own `get nodes` command, where you can see the load balancer:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Our KinD cluster is up and running; let’s put it to work.
  prefs: []
  type: TYPE_NORMAL
- en: Doing work with KinD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s deploy our echo service on the KinD cluster. It starts the same:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'Checking our services, we can see the echo service front and center:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: But, there is no external IP to the service. With minikube, we got the IP of
    the minikube node itself via `$(minikube ip)` and we could use it in combination
    with the node port to access the service. That is not an option with KinD clusters.
    Let’s see how to use a proxy to access the echo service.
  prefs: []
  type: TYPE_NORMAL
- en: Accessing Kubernetes services locally through a proxy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We will go into a lot of detail about networking, services, and how to expose
    them outside the cluster later in the book.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we will just show you how to get it done and keep you in suspense for
    now. First, we need to run the `kubectl proxy` command that exposes the API server,
    pods, and services on localhost:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can access the echo service through a specially crafted proxy URL
    that includes the exposed port (`8080`) and NOT the node port:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'I used httpie in the command above. You can use curl too. To install httpie,
    follow the instructions here: [https://httpie.org/doc#installation](https://httpie.org/doc#installation).'
  prefs: []
  type: TYPE_NORMAL
- en: We will deep dive into exactly what’s going on in *Chapter 10*, *Exploring Kubernetes
    Networking*. For now, it is enough to demonstrate how kubectl proxy allows us
    to access our KinD services.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s check out my favorite local cluster solution – k3d.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a multi-node cluster with k3d
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we’ll create a multi-node cluster using k3d from Rancher. We
    will not repeat the deployment of the echo server because it’s identical to the
    KinD cluster including accessing it through a proxy. Spoiler alert – creating
    clusters with k3d is even faster and more user-friendly than KinD!
  prefs: []
  type: TYPE_NORMAL
- en: Quick introduction to k3s and k3d
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Rancher created k3s, which is a lightweight Kubernetes distribution. Rancher
    says that k3s is 5 less than k8s if that makes any sense. The basic idea is to
    remove features and capabilities that most people don’t need such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Non-default features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Legacy features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alpha features
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In-tree storage drivers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In-tree cloud providers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: K3s removed Docker completely and uses containerd instead. You can still bring
    Docker back if you depend on it. Another major change is that k3s stores its state
    in an SQLite DB instead of etcd. For networking and DNS, k3s uses Flannel and
    CoreDNS.
  prefs: []
  type: TYPE_NORMAL
- en: K3s also added a simplified installer that takes care of SSL and certificate
    provisioning.
  prefs: []
  type: TYPE_NORMAL
- en: The end result is astonishing – a single binary (less than 40MB) that needs
    only 512MB of memory.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike Minikube and KinD, k3s is actually designed for production. The primary
    use case is for edge computing, IoT, and CI systems. It is optimized for ARM devices.
  prefs: []
  type: TYPE_NORMAL
- en: OK. That’s k3s, but what’s k3d? K3d takes all the goodness that is k3s and packages
    it in Docker (similar to KinD) and adds a friendly CLI to manage it.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s install k3d and see for ourselves.
  prefs: []
  type: TYPE_NORMAL
- en: Installing k3d
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Installing k3d on macOS is as simple as:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'And on Windows, it is just:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'On Windows, optionally add this alias to your WSL `.bashrc` file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s see what we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: As you see, k3d reports its version, which shows all is well. Now, we can create
    a cluster with k3d.
  prefs: []
  type: TYPE_NORMAL
- en: Creating the cluster with k3d
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Are you ready to be amazed? Creating a single-node cluster with k3d takes less
    than 20 seconds!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: Without a load balancer, it takes less than 8 seconds!
  prefs: []
  type: TYPE_NORMAL
- en: What about multi-node clusters? We saw that KinD was much slower, especially
    when creating a HA cluster with multiple control plane nodes and an external load
    balancer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s delete the single-node cluster first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s create a cluster with 3 worker nodes. That takes a little over 30
    seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s verify the cluster works as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'Here are the nodes. Note that there is just one control plane node called `k3d-k3s-default-server-0`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'You can stop and start clusters, create multiple clusters, and list existing
    clusters using the k3d CLI. Here are all the commands. Feel free to explore further:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: You can repeat the steps for deploying, exposing, and accessing the echo service
    on your own. It works just like KinD.
  prefs: []
  type: TYPE_NORMAL
- en: OK. We created clusters using minikube, KinD and k3d. Let’s compare them, so
    you can decide which one works for you.
  prefs: []
  type: TYPE_NORMAL
- en: Comparing Minikube, KinD, and k3d
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Minikube is an official local Kubernetes release. It’s very mature and very
    full-featured. That said, it requires a VM and is both slow to install and to
    start. It also can get into trouble with networking at arbitrary times, and sometimes
    the only remedy is deleting the cluster and rebooting. Also, minikube supports
    a single node only. I suggest using Minikube only if it supports some features
    that you need that are not available in either KinD or k3d. See [https://minikube.sigs.k8s.io/](https://minikube.sigs.k8s.io/)
    for more info.
  prefs: []
  type: TYPE_NORMAL
- en: KinD is much faster than Minikube and is used for Kubernetes conformance tests,
    so by definition, it is a conformant Kubernetes distribution. It is the only local
    cluster solution that provides an HA cluster with multiple control plane nodes.
    It is also designed to be used as a library, which I don’t find a big attraction
    because it is very easy to automate CLIs from code. The main downside of KinD
    for local development is that it is ephemeral. I recommend using KinD if you contribute
    to Kubernetes itself and want to test against it. See [https://kind.sigs.k8s.io/](https://kind.sigs.k8s.io/).
  prefs: []
  type: TYPE_NORMAL
- en: K3d is the clear winner for me. Lightning fast, and supports multiple clusters
    and multiple worker nodes per cluster. Easy to stop and start clusters without
    losing state. See [https://k3d.io/](https://k3d.io/).
  prefs: []
  type: TYPE_NORMAL
- en: Honorable mention – Rancher Desktop Kubernetes cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: I use Rancher Desktop as my Docker Engine provider, but it also comes with a
    built-in Kubernetes cluster. You don’t get to customize it and you can’t have
    multiple clusters or even multiple nodes in the same cluster. But, if all you
    need is a local single-node Kubernetes cluster to play with, then the `rancher-desktop`
    cluster is there for you.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use this cluster, type:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: You can decide how many resources you allocate to its node, which is important
    if you try to deploy a lot of workloads on it because you get just the one node.
  prefs: []
  type: TYPE_NORMAL
- en: '![Graphical user interface, application  Description automatically generated](img/B18998_02_06.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2.6: Rancher Desktop – Kubernetes settings'
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered creating Kubernetes clusters locally using Minikube,
    KinD, and K3d. In the next section, we will look at creating clusters in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Creating clusters in the cloud (GCP, AWS, Azure, and Digital Ocean)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Creating clusters locally is fun. It’s also important during development and
    when trying to troubleshoot problems locally. But, in the end, Kubernetes is designed
    for cloud-native applications (applications that run in the cloud). Kubernetes
    doesn’t want to be aware of individual cloud environments because that doesn’t
    scale. Instead, Kubernetes has the concept of a cloud-provider interface. Every
    cloud provider can implement this interface and then host Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: The cloud-provider interface
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The cloud-provider interface is a collection of Go data types and interfaces.
    It is defined in a file called `cloud.go`, available at: [https://github.com/kubernetes/cloud-provider/blob/master/cloud.go](https://github.com/kubernetes/cloud-provider/blob/master/cloud.go).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the main interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: This is very clear. Kubernetes operates in terms of instances, zones, clusters,
    and routes, and also requires access to a load balancer and provider name. The
    main interface is primarily a gateway. Most methods of the `Interface` interface
    above return yet other interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, the `Clusters()` method returns the `Cluster` interface, which
    is very simple:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: The `ListClusters()` method returns cluster names. The `Master()` method returns
    the IP address or DNS name of the control plane of the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The other interfaces are not much more complicated. The entire file is 313 lines
    long (at the time of writing) including lots of comments. The take-home point
    is that it is not too complicated to implement a Kubernetes provider if your cloud
    utilizes those basic concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Creating Kubernetes clusters in the cloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before we look at the cloud providers and their support for managed and non-managed
    Kubernetes, let’s consider how you should create and maintain clusters. If you
    commit to a single cloud provider, and you are happy with using their tooling,
    then you are set. All cloud providers let you create and configure Kubernetes
    clusters using either a Web UI, a CLI, or an API. However, if you prefer a more
    general approach and want to utilize GitOps to manage your clusters, you should
    look into Infrastructure as Code solutions such as Terraform and Pulumi.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you prefer to roll out non-managed Kubernetes clusters in the cloud, then
    kOps is a strong candidate. See: [https://kops.sigs.k8s.io](https://kops.sigs.k8s.io).'
  prefs: []
  type: TYPE_NORMAL
- en: Later, in *Chapter 17*, *Running Kubernetes in Production*, we will discuss
    in detail the topic of multi-cluster provisioning and management. There are many
    technologies, open source projects, and commercial products in this space.
  prefs: []
  type: TYPE_NORMAL
- en: For now, let’s look at the various cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: GCP
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Google Cloud Platform** (**GCP**) supports Kubernetes out of the box.
    The so-called **Google Kubernetes Engine** (**GKE**) is a container management
    solution built on Kubernetes. You don’t need to install Kubernetes on GCP, and
    you can use the Google Cloud API to create Kubernetes clusters and provision them.
    The fact that Kubernetes is a built-in part of the GCP means it will always be
    well integrated and well tested, and you don’t have to worry about changes in
    the underlying platform breaking the cloud-provider interface.
  prefs: []
  type: TYPE_NORMAL
- en: If you prefer to manage Kubernetes yourself, then you can just deploy it directly
    on GCP instances (or use kOps alpha support for GCP), but I would generally advise
    against it as GKE does a lot of work for you and it’s integrated deeply with GCP
    compute, networking, and core services.
  prefs: []
  type: TYPE_NORMAL
- en: All in all, if you plan to base your system on Kubernetes and you don’t have
    any existing code on other cloud platforms, then GCP is a solid choice. It leads
    the pack in terms of maturity, polish, and depth of integration to GCP services,
    and is usually the first to update to newer versions of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: I spent a lot of time with Kubernetes on GKE, managing tens of clusters, upgrading
    them, and deploying workloads. GKE is production-grade Kubernetes for sure.
  prefs: []
  type: TYPE_NORMAL
- en: GKE Autopilot
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GKE also has the Autopilot project, which takes care of managing worker nodes
    and node pools for you, so you focus on deploying and configuring workloads.
  prefs: []
  type: TYPE_NORMAL
- en: 'See: [https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview](https://cloud.google.com/kubernetes-engine/docs/concepts/autopilot-overview).'
  prefs: []
  type: TYPE_NORMAL
- en: AWS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**AWS** has its own container management service called ECS, which is not based
    on Kubernetes. It also has a managed Kubernetes service called EKS. You can run
    Kubernetes yourself on AWS EC2 instances. Let’s talk about how to roll your own
    Kubernetes first and then we’ll discuss EKS.'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes on EC2
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: AWS was a supported cloud provider from the get-go. There is a lot of documentation
    on how to set it up. While you could provision some EC2 instances yourself and
    use kubeadm to create a cluster, I recommend using the kOps (Kubernetes Operations)
    project mentioned earlier. kOps initially supported only AWS and is generally
    considered the most battle-tested and feature-rich tool for self-provisioning
    Kubernetes clusters on AWS (without using EKS).
  prefs: []
  type: TYPE_NORMAL
- en: 'It supports the following features:'
  prefs: []
  type: TYPE_NORMAL
- en: Automated Kubernetes cluster CRUD for the cloud (AWS)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HA Kubernetes clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uses a state-sync model for dry-run and automatic idempotency
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Custom support for kubectl addons
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: kOps can generate Terraform configuration
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Based on a simple meta-model defined in a directory tree
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy command-line syntax
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Community support
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To create a cluster, you need to do some IAM and DNS configuration, set up
    an S3 bucket to store the cluster configuration, and then run a single command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'The complete instructions are here: [https://kops.sigs.k8s.io/getting_started/aws/](https://kops.sigs.k8s.io/getting_started/aws/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'At the end of 2017, AWS joined the CNCF and made two big announcements regarding
    Kubernetes: its own Kubernetes-based container orchestration solution (EKS) and
    a container-on-demand solution (Fargate).'
  prefs: []
  type: TYPE_NORMAL
- en: Amazon EKS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Amazon Elastic Kubernetes Service** (**EKS**) is a fully managed and highly
    available Kubernetes solution. It has three control plane nodes running in three
    AZs. EKS also takes care of upgrades and patching. The great thing about EKS is
    that it runs a stock Kubernetes. This means you can use all the standard plugins
    and tools developed by the community. It also opens the door to convenient cluster
    federation with other cloud providers and/or your own on-premise Kubernetes clusters.'
  prefs: []
  type: TYPE_NORMAL
- en: EKS provides deep integration with AWS infrastructure like IAM authentication,
    which is integrated with Kubernetes **Role-Based Access Control** (**RBAC**).
  prefs: []
  type: TYPE_NORMAL
- en: You can also use PrivateLink if you want to access your Kubernetes masters directly
    from your own Amazon VPC. With PrivateLink, your Kubernetes control plane and
    the Amazon EKS service endpoint appear as an elastic network interface with private
    IP addresses in your Amazon VPC.
  prefs: []
  type: TYPE_NORMAL
- en: Another important piece of the puzzle is a special CNI plugin that lets your
    Kubernetes components talk to each other using AWS networking.
  prefs: []
  type: TYPE_NORMAL
- en: EKS keeps getting better and Amazon demonstrated that it is committed to keeping
    it up to date and improving it. If you are an AWS shop and getting into Kubernetes,
    I recommend starting with EKS as opposed to building your own cluster.
  prefs: []
  type: TYPE_NORMAL
- en: The eksctl tool is a great CLI for creating and managing EKS clusters and node
    groups for testing and development. I successfully created, deleted, and added
    nodes to several Kubernetes clusters on AWS using eksctl. Check out [https://eksctl.io/](https://eksctl.io/).
  prefs: []
  type: TYPE_NORMAL
- en: Fargate
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Fargate** lets you run containers directly without worrying about provisioning
    hardware. It eliminates a huge part of the operational complexity at the cost
    of losing some control. When using Fargate, you package your application into
    a container, specify CPU and memory requirements, define networking and IAM policies,
    and you’re off to the races. Fargate can run on top of ECS and EKS. It is a very
    interesting member of the serverless camp although it’s not specific to Kubernetes
    like GKE’s Autopilot.'
  prefs: []
  type: TYPE_NORMAL
- en: Azure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Azure** used to have its own container management service based on Mesos-based
    DC/OS or Docker Swarm to manage your containers. But you can also use Kubernetes,
    of course. You could also provision the cluster yourself (for example, using Azure’s
    desired state configuration) and then create the Kubernetes cluster using kubeadm.
    kOps has alpha support for Azure, and the Kubespray project is a good option too.'
  prefs: []
  type: TYPE_NORMAL
- en: However, in the second half of 2017 Azure jumped on the Kubernetes bandwagon
    too and introduced **AKS** (**Azure Kubernetes Service**). It is similar to Amazon
    EKS, although it’s a little further ahead in its implementation.
  prefs: []
  type: TYPE_NORMAL
- en: AKS provides a Web UI, CLI, and REST API to manage your Kubernetes clusters.
    Once, an AKS cluster is configured, you can use kubectl and any other Kubernetes
    tooling directly.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of the benefits of using AKS:'
  prefs: []
  type: TYPE_NORMAL
- en: Automated Kubernetes version upgrades and patching
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Easy cluster scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Self-healing hosted control plane (masters)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cost savings – pay only for running agent pool nodes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AKS also offers integration with **Azure Container Instances** (**ACI**), which
    is similar to AWS Fargate and GKE AutoPilot. This means that not only the control
    plane of your Kubernetes cluster is managed, but also the worker nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Digital Ocean
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Digital Ocean is not a cloud provider on the order of the big three (GCP, AWS,
    Azure), but it does provide a managed Kubernetes solution and it has data centers
    across the world (US, Canada, Europe, Asia). It is also much cheaper compared
    to the alternatives, and cost is a major deciding factor when choosing a cloud
    provider. With Digital Ocean, the control plane doesn’t cost anything. Besides
    lower prices Digital Ocean’s claim to fame is simplicity.
  prefs: []
  type: TYPE_NORMAL
- en: '**DOKS** (**Digital Ocean Kubernetes Service**) gives you a managed Kubernetes
    control plane (which can be highly available) and integration with Digital Ocean’s
    droplets (for nodes and node pools), load balancers, and block storage volumes.
    This covers all the basic needs. Your clusters are of course CNCF conformant.'
  prefs: []
  type: TYPE_NORMAL
- en: Digital Ocean will take care of system upgrades, security patches, and the installed
    packages on the control plane as well as the worker nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Other cloud providers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: GCP, AWS, and Azure are leading the pack, but there are quite a few other companies
    that offer managed Kubernetes services. In general, I recommend using these providers
    if you already have significant business connections or integrations.
  prefs: []
  type: TYPE_NORMAL
- en: Once upon a time in China
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'If you operate in China with its special constraints and limitations, you should
    probably use a Chinese cloud platform. There are three big ones: Alibaba, Tencent,
    and Huawei.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Chinese **Alibaba** cloud is an up-and-comer on the cloud platform scene.
    It mimics AWS pretty closely, although its English documentation leaves a lot
    to be desired. The Alibaba cloud supports Kubernetes in several ways via its **ACK**
    (**Alibaba Container service for Kubernetes**) and allows you to:'
  prefs: []
  type: TYPE_NORMAL
- en: Run your own dedicated Kubernetes cluster (you must create 3 master nodes and
    upgrade and maintain them)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the managed Kubernetes cluster (you’re just responsible for the worker nodes)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the serverless Kubernetes cluster via **ECI** (**Elastic Container Instances**),
    which is similar to Fargate and ACI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ACK is a CNCF-certified Kubernetes distribution. If you need to deploy cloud-native
    applications in China, then ACK looks like a solid option.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://www.alibabacloud.com/product/kubernetes](https://www.alibabacloud.com/product/kubernetes).
  prefs: []
  type: TYPE_NORMAL
- en: Tencent is another large Chinese company with its own cloud platform and Kubernetes
    support. **TKE** (**Tencent Kubernetes Engine**) seems less mature than ACK. See
    [https://intl.cloud.tencent.com/products/tke](https://intl.cloud.tencent.com/products/tke).
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the Huawei cloud platform offers **CCE** (**Cloud Container Engine**),
    which is built on Kubernetes. It supports VMs, bare metal, and GPU accelerated
    instances. See [https://www.huaweicloud.com/intl/en-us/product/cce.html](https://www.huaweicloud.com/intl/en-us/product/cce.html).
  prefs: []
  type: TYPE_NORMAL
- en: IBM Kubernetes service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: IBM is investing heavily in Kubernetes. It acquired Red Hat at the end of 2018\.
    Red Hat was of course a major player in the Kubernetes world, building its OpenShift
    Kubernetes-based platform and contributing RBAC to Kubernetes. IBM has its own
    cloud platform and it offers a managed Kubernetes cluster. You can try it out
    for free with $200 credit and there is also a free tier.
  prefs: []
  type: TYPE_NORMAL
- en: IBM is also involved in the development of Istio and Knative, so you can expect
    IKS to have deep integration with those technologies.
  prefs: []
  type: TYPE_NORMAL
- en: IKS offers integration with a lot of IBM services.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://www.ibm.com/cloud/kubernetes-service](https://www.ibm.com/cloud/kubernetes-service).
  prefs: []
  type: TYPE_NORMAL
- en: Oracle Container Service
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Oracle also has a cloud platform and of course, it offers a managed Kubernetes
    service too, with high availability, bare-metal instances, and multi-AZ support.
  prefs: []
  type: TYPE_NORMAL
- en: OKE supports ARM and GPU instances and also offers a few control plane options.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://www.oracle.com/cloud/cloud-native/container-engine-kubernetes/](https://www.oracle.com/cloud/cloud-native/container-engine-kubernetes/).
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered the cloud-provider interface and looked at the recommended
    ways to create Kubernetes clusters on various cloud providers. The scene is still
    young and the tools evolve quickly. I believe convergence will happen soon. Kubeadm
    has matured and is the underlying foundation of many other tools to bootstrap
    and create Kubernetes clusters on and off the cloud. Let’s consider now what it
    takes to create bare-metal clusters where you have to provision the hardware and
    low-level networking and storage too.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a bare-metal cluster from scratch
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous section, we looked at running Kubernetes on cloud providers.
    This is the dominant deployment story for Kubernetes. But there are strong use
    cases for running Kubernetes on bare metal, such as Kubernetes on the edge. We
    don’t focus here on hosted versus on-premise. This is yet another dimension. If
    you already manage a lot of servers on-premise, you are in the best position to
    decide.
  prefs: []
  type: TYPE_NORMAL
- en: Use cases for bare metal
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Bare-metal clusters are a bear to deal with, especially if you manage them yourself.
    There are companies that provide commercial support for bare-metal Kubernetes
    clusters, such as Platform 9, but the offerings are not mature yet. A solid open-source
    option is Kubespray, which can deploy industrial-strength Kubernetes clusters
    on bare metal, AWS, GCE, Azure, and OpenStack.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some use cases where it makes sense:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Price**: If you already manage large-scale bare-metal clusters, it may be
    much cheaper to run Kubernetes clusters on your physical infrastructure'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Low network latency**: If you must have low latency between your nodes, then
    the VM overhead might be too much'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regulatory requirements**: If you must comply with regulations, you may not
    be allowed to use cloud providers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**You want total control over hardware**: Cloud providers give you many options,
    but you may have special needs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When should you consider creating a bare-metal cluster?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The complexities of creating a cluster from scratch are significant. A Kubernetes
    cluster is not a trivial beast. There is a lot of documentation on the web on
    how to set up bare-metal clusters, but as the whole ecosystem moves forward, many
    of these guides get out of date quickly.
  prefs: []
  type: TYPE_NORMAL
- en: You should consider going down this route if you have the operational capability
    to troubleshoot problems at every level of the stack. Most of the problems will
    probably be networking-related, but filesystems and storage drivers can bite you
    too, as well as general incompatibilities and version mismatches between components
    such as Kubernetes itself, Docker (or other runtimes, if you use them), images,
    your OS, your OS kernel, and the various addons and tools you use. If you opt
    for using VMs on top of bare metal, then you add another layer of complexity.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There is a lot to do. Here is a list of some of the concerns you’ll have to
    address:'
  prefs: []
  type: TYPE_NORMAL
- en: Implementing your own cloud-provider interface or sidestepping it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choosing a networking model and how to implement it (CNI plugin, direct compile)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whether or not to use network policies
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Selecting images for system components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The security model and SSL certificates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Admin credentials
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Templates for components such as API Server, replication controller, and scheduler
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cluster services: DNS, logging, monitoring, and GUI'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'I recommend the following guide from the Kubernetes site to get a deeper understanding
    of what it takes to create a HA cluster from scratch using kubeadm:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/high-availability/)'
  prefs: []
  type: TYPE_NORMAL
- en: Using the Cluster API for managing bare-metal clusters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The Cluster API (AKA CAPI) is a Kubernetes sub-project for managing Kubernetes
    clusters at scale. It uses kubeadm for provisioning. It can provision and manage
    Kubernetes clusters in any environment using providers. At work, we use it to
    manage multiple clusters in the cloud. But, it has multiple providers for bare-metal
    clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: MAAS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Equinix metal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metal3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cidero
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See [https://cluster-api.sigs.k8s.io](https://cluster-api.sigs.k8s.io).
  prefs: []
  type: TYPE_NORMAL
- en: Using virtual private cloud infrastructure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If your use case falls under the bare-metal use cases but you don’t have the
    necessary skilled manpower or the inclination to deal with the infrastructure
    challenges of bare metal, you have the option to use a private cloud such as OpenStack.
    If you want to aim a little higher in the abstraction ladder, then Mirantis offers
    a cloud platform built on top of OpenStack and Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s review a few more tools for building Kubernetes clusters on bare metal.
    Some of these tools support OpenStack as well.
  prefs: []
  type: TYPE_NORMAL
- en: Building your own cluster with Kubespray
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Kubespray is a project for deploying production-ready highly available Kubernetes
    clusters. It uses Ansible and can deploy Kubernetes on a large number of targets
    such as:'
  prefs: []
  type: TYPE_NORMAL
- en: AWS
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCE
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: OpenStack
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: vSphere
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Equinix metal
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oracle Cloud Infrastructure (Experimental)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is also used to deploy Kubernetes clusters on plain bare-metal machines.
  prefs: []
  type: TYPE_NORMAL
- en: It is highly customizable and supports multiple operating systems for the nodes,
    multiple CNI plugins for networking, and multiple container runtimes.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to test it locally, it can deploy to a multi-node vagrant setup
    too. If you’re an Ansible fan, Kubespray may be a great choice for you.
  prefs: []
  type: TYPE_NORMAL
- en: See [https://kubespray.io](https://kubespray.io).
  prefs: []
  type: TYPE_NORMAL
- en: Building your cluster with Rancher RKE
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Rancher Kubernetes Engine** (**RKE**) is a friendly Kubernetes installer
    that can install Kubernetes on bare metal as well as virtualized servers. RKE
    aims to address the complexity of installing Kubernetes. It is open source and
    has great documentation. Check it out here: [http://rancher.com/docs/rke/v0.1.x/en/](http://rancher.com/docs/rke/v0.1.x/en/).'
  prefs: []
  type: TYPE_NORMAL
- en: Running managed Kubernetes on bare metal or VMs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The cloud providers didn’t want to confine themselves to their own cloud only.
    They all offer multi-cloud and hybrid solutions where you can control Kubernetes
    clusters on multiple clouds as well as use their managed control plane on VMs
    anywhere.
  prefs: []
  type: TYPE_NORMAL
- en: GKE Anthos
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Anthos is a comprehensive managed platform that facilitates the deployment of
    applications, encompassing both traditional and cloud-native environments. It
    empowers you to construct and oversee global fleets of applications while ensuring
    operational consistency across them.
  prefs: []
  type: TYPE_NORMAL
- en: EKS Anywhere
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Amazon EKS Anywhere presents a fresh deployment alternative for Amazon EKS that
    enables you to establish and manage Kubernetes clusters on your infrastructure
    with AWS support. It grants you the flexibility to run Amazon EKS Anywhere on
    your own on-premises infrastructure, utilizing VMware vSphere, as well as bare
    metal environments.
  prefs: []
  type: TYPE_NORMAL
- en: AKS Arc
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Azure Arc encompasses a collection of technologies that extend Azure’s security
    and cloud-native services to hybrid and multi-cloud environments. It empowers
    you to safeguard and manage your infrastructure and applications across various
    locations while providing familiar tools and services to accelerate the development
    of cloud-native apps. These applications can then be deployed on any Kubernetes
    platform.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we covered creating bare-metal Kubernetes clusters, which gives
    you total control, but is highly complicated, and requires a tremendous amount
    of effort and knowledge. Luckily, there are multiple tools, projects, and frameworks
    to assist you.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we got into some hands-on cluster creation. We created single-node
    and multi-node clusters using tools like Minikube, KinD, and k3d. Then we looked
    at the various options to create Kubernetes clusters on cloud providers. Finally,
    we touched on the complexities of creating Kubernetes clusters on bare metal.
    The current state of affairs is very dynamic. The basic components are changing
    rapidly, the tooling is getting better, and there are different options for each
    environment. Kubeadm is now the cornerstone of most installation options, which
    is great for consistency and consolidation of effort. It’s still not completely
    trivial to stand up a Kubernetes cluster on your own, but with some effort and
    attention to detail, you can get it done quickly.
  prefs: []
  type: TYPE_NORMAL
- en: I highly recommend considering the Cluster API as the go-to solution for provisioning
    and managing clusters in any environment – managed, private cloud, VMs, and bare
    metal. We will discuss the Cluster API in depth in *Chapter 17*, *Running Kubernetes
    in Production*.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will explore the important topics of scalability and
    high availability. Once your cluster is up and running, you need to make sure
    it stays that way even as the volume of requests increases. This requires ongoing
    attention and building the ability to recover from failures as well adjusting
    to changes in traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Join us on Discord!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Read this book alongside other users, cloud experts, authors, and like-minded
    professionals.
  prefs: []
  type: TYPE_NORMAL
- en: Ask questions, provide solutions to other readers, chat with the authors via.
    Ask Me Anything sessions and much more.
  prefs: []
  type: TYPE_NORMAL
- en: Scan the QR code or visit the link to join the community now.
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code844810820358034203.png)'
  prefs: []
  type: TYPE_IMG
