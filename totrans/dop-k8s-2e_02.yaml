- en: DevOps with Containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'We''re now familiar with a wide variety of DevOps tools that can help us to
    automate tasks and manage configuration throughout the delivery journey of an
    application. Challenges still lie ahead, however, as applications have now become
    more diverse than ever. In this chapter, we''ll add another skill to our tool
    belt: the container. In particular, we''ll talk about the **Docker container**.
    In doing this, we''ll seek to understand the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Key concepts related to containers
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running Docker applications
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building Docker applications with Dockerfile
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orchestrating multiple containers with Docker compose
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the key features of containers is isolation. In this section, we'll establish
    a proper understanding of this powerful tool by looking at how a container achieves
    isolation and why this matters in the software development life cycle.
  prefs: []
  type: TYPE_NORMAL
- en: Resource isolation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When an application launches, it consumes CPU time, occupies memory space, links
    to its dependent libraries, writes to the disk, transmits packets, and may access
    other devices as well. Everything it uses up is a kind of resource, which is shared
    by all the programs on the same host. To increase the efficiency of resource utilization,
    we may try to put as many applications as possible on a single machine. However,
    the complexity involved in making every application work in a box effectively
    increases exponentially, even if we just want to run two applications, let alone
    work with tons of applications and machines. Because of this, the idea to separate
    the resources of a physical computing unit into isolated pieces soon became a
    paradigm in the industry.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may have heard of terms such as **Virtual Machines** (**VMs**), BSD jails,
    Solaris containers, Linux containers, Docker, and others. All of these promise
    us similar isolation concepts but use fundamentally distinct mechanisms, so the
    actual level of isolation differs. For example, the implementation of a VM involves
    full virtualization of the hardware layer with a hypervisor. If you want to run
    an application on a VM, you have to start from a full operating system. In other
    words, the resources are isolated between guest operating systems running on the
    same hypervisor. In contrast, Linux and Docker containers are built on top of
    Linux primitives, which means they can only run in an operating system with those
    capabilities. BSD jails and Solaris containers work in a similar fashion, but
    on other operating systems. The following diagram illustrates the isolation relationship
    of the Linux container and VMs. The container isolates an application on the operating
    system layer, while VM-based separation is achieved by the underlying hypervisor
    or host operating system:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e66656ae-d26e-4df1-a84d-b5f82716b601.png)'
  prefs: []
  type: TYPE_IMG
- en: Linux containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Linux container is made up of several building blocks, the two most important
    of which are **namespaces** and **control groups** (**cgroups**). Both of these
    are Linux kernel features. Namespaces provide logical partitions of certain kinds
    of system resources, such as the mounting point (`mnt`), the process ID (`PID`),
    and the network (`net`). To further understand the concept of isolation, let's
    look at some simple examples on the `pid` namespace. The following examples are
    from Ubuntu 18.04.1 and util-linux 2.31.1.
  prefs: []
  type: TYPE_NORMAL
- en: 'When we type `ps axf` in our Terminal, we''ll see a long list of running processes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`ps` is a utility that is used to report current processes on the system. `ps
    axf` provides a list of all processes in a forest.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s now enter a new `pid` namespace with `unshare`, which is able to disassociate
    a process resource part by part into a new namespace. We''ll then check the processes
    again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'You''ll find that the `pid` of the shell process at the new namespace becomes `1` and
    all other processes have disappeared. This means you''ve successfully created
    a `pid` container. Let''s switch to another session outside the namespace and
    list the processes again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: You can still see the other processes and your shell process within the new
    namespace. With the `pid` namespace's isolation, processes inhabiting different
    namespaces can't see each other. However, if one process uses a considerable amount
    of system resources, such as the memory, it could cause the system to run out
    of that resource and become unstable. In other words, an isolated process could
    still disrupt other processes or even crash the whole system if we don't impose
    resource usage restrictions on it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the `PID` namespaces and how an **Out-Of-Memory**
    (**OOM**) event can affect other processes outside a child namespace. The numbered
    blocks are the processes in the system, and the numbers are their PIDs. Blocks
    with two numbers are processes created with the child namespace, where the second
    number represents their PIDs in the child namespace. In the upper part of the
    diagram, there''s still free memory available in the system. Later on, however,
    in the lower part of the diagram, the processes in the child namespace exhaust
    the remaining memory in the system. Due to the lack of free memory, the host kernel
    then starts the OOM killer to release memory, the victims of which are likely
    to be processes outside the child namespace. In the example here, processes **8**
    and **13** in the system are killed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/f06dbc4f-0da3-43f6-a512-9f76754d83b6.png)'
  prefs: []
  type: TYPE_IMG
- en: 'In light of this, `cgroups` is utilized here to limit resource usage. Like
    namespaces, this can impose constraints on different kinds of system resources.
    Let''s continue from our `pid` namespace, generate some loadon the CPU with `yes
    > /dev/null`, and then monitor it with `top`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Our CPU load reaches 100%, as expected. Let''s now limit it with the `cgroup`
    CPU. `cgroups` are organized as folders under `/sys/fs/cgroup/`. First, we need
    to switch to the host session:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Each folder represents the resources it controls. It''s pretty easy to create
    a `cgroup` and control processes with it: just create a folder under the resource
    type with any name and append the process IDs you''d like to control to `tasks`.
    Here, we want to throttle the CPU usage of our `yes` process, so create a new folder
    under `cpu` and find out the `PID` of the `yes` process:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'We''ve just added `yes` into the newly created `box` CPU group, but the policy
    remains unset, and the process still runs without any restrictions. Set a limit
    by writing the desired number into the corresponding file and check the CPU usage
    again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The CPU usage is dramatically reduced, meaning that our CPU throttle works.
  prefs: []
  type: TYPE_NORMAL
- en: The previous two examples elucidate how a Linux container isolates system resources.
    By putting more confinements in an application, we can build a fully isolated
    box, including filesystems and networks, without encapsulating an operating system
    within it.
  prefs: []
  type: TYPE_NORMAL
- en: Containerized delivery
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The usual way to run applications consists of the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Provision machines and the corresponding infrastructure resources
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install an operating system
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Install system programs and application dependencies
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Deploy the application
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Maintain the running states of the application
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The entire process is tedious and complicated, which is why we usually don't
    want to do it manually. The **configuration management tool**, introduced in [Chapter
    1](43698ec3-b595-4aa0-811a-111010763585.xhtml), *Introduction to DevOps*, is used
    to eliminate most of the effort otherwise required in the delivery process. Its
    modular and code-based configuration design works well until application stacks
    grow complex and diverse. Maintaining a large configuration base is hard, especially
    if it's a legacy configuration that contains various hacks. Although changing
    configuration codes with the configuration management tool has a direct impact
    on the production environment, the configuration code often gets less attention
    than application code. Whenever we want to update an installed package, we would
    have to work in entangled and fragile dependencies between the system and application
    packages. It's not uncommon that some applications break inadvertently after upgrading
    an unrelated package. Moreover, upgrading the configuration management tool itself
    is also a challenging task.
  prefs: []
  type: TYPE_NORMAL
- en: In order to overcome this problem, immutable deployments with pre-baked VM images
    were introduced. This means that whenever we carry out any updates on the system
    or application packages, we would build a full VM image against the change and
    deploy it accordingly. This reduces some of the complexity, because we can test
    changes prior to roll-outs and we're able to customize runtimes for applications
    that can't share the same environments. Nevertheless, carrying out immutable deployment
    with VM images is costly. The overhead of booting, distributing, and running a
    bloated VM image is significantly larger than deploying packages.
  prefs: []
  type: TYPE_NORMAL
- en: The container, here, is a jigsaw piece that snugly fits the deployment needs.
    A manifestation of a container can be managed within VCS and built into a blob
    image, and the image can be deployed immutably as well. This enables developers
    to abstract from actual resources and infrastructure engineers to avoid dependency
    hell. Besides, since we only need to pack up the application itself and its dependent
    libraries, its image size would be significantly smaller than a VM's. Consequently,
    distributing a container image is more economical than distributing a VM image.
    Additionally, we already know that running a process inside a container is basically
    identical to running it on its Linux host and, as such, almost no overhead will
    be produced. To summarize, a container is lightweight, self-contained, and almost
    immutable. This provides clear borders to distinguish responsibilities between
    applications and infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the fact that Linux containers share the same kernel, there are still
    potential security risks for the kernel from containers running on top of it.
    An emerging trend to address this concern is making running VMs as easy and efficient
    as operating system containers, such as **unikernel**-based solutions or the **Kata
    container**. Another approach is inserting a mediator layer between applications
    and the host kernel, such as **gVisor**.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are many mature container engines such as **Docker** ([https://www.docker.com](https://www.docker.com))
    or **rkt** ([https://coreos.com/rkt](https://coreos.com/rkt)) that have already
    implemented features for production usage, so you don't need to build your own
    container from scratch. As well as this, the **Open Container Initiative** ([https://www.opencontainers.org](https://www.opencontainers.org)),
    an organization formed by container industry leaders, has standardized container
    specifications. Any implementation of standards, regardless of the underlying
    platform, should have similar properties, as the OCI aims to provide a seamless
    experience of using containers across a variety of operating systems. In fact,
    the core of Docker is **containerd**, which is an OCI-compatible runtime and can
    be used without Docker. In this book, we'll use the Docker (community edition)
    container engine to fabricate our containerized applications.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Docker for Ubuntu
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Docker requires a 64-bit version of Bionic 18.04 LTS, Artful 17.10, Xenial 16.04
    LTS, or Trusty 14.04 LTS. You can install Docker with `apt-get install docker.io`,
    but its updates are usually slower than the Docker official repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the installation steps from Docker ([https://docs.docker.com/install/linux/docker-ce/ubuntu/](https://docs.docker.com/install/linux/docker-ce/ubuntu/#install-using-the-repository)):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make sure you have the packages to allow `apt` repositories; if not, you can get
    them with the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Add Docker''s `gpg` key and verify whether its fingerprint matches `9DC8 5822
    9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Set up the repository of the `amd64` arch:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Update the package index and install Docker CE:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: Installing Docker for CentOS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A 64-bit version of CentOS 7 is required to run Docker. You can get the Docker
    package from CentOS''s repository via `sudo yum install docker`, but this might
    be an older version. Again, the installation steps from Docker''s official guide
    ([https://docs.docker.com/install/linux/docker-ce/centos/](https://docs.docker.com/install/linux/docker-ce/centos/#install-using-the-repository))
    are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the utility to enable `yum` to use the extra repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Set up Docker''s repository:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Install Docker CE and start it. If key verification is prompted, make sure
    it matches `060A 61C5 1B55 8A7F 742B 77AA C52F EB6B 621E 9F35`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Installing Docker for macOS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Docker wraps a micro Linux with the hypervisor framework to build a native
    application on macOS, which means we don''t need third-party virtualization tools
    to use Docker on a Mac. To benefit from the hypervisor framework, you must upgrade
    your macOS to version 10.10.3 or more:'
  prefs: []
  type: TYPE_NORMAL
- en: Download the Docker package and install it: [https://download.docker.com/mac/stable/Docker.dmg](https://download.docker.com/mac/stable/Docker.dmg).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Docker for Windows requires no third-party tools either. Check for the installation
    guide at the following link: [https://docs.docker.com/docker-for-windows/install](https://docs.docker.com/docker-for-windows/install).'
  prefs: []
  type: TYPE_NORMAL
- en: 'You''re now in Docker. Try creating and running your very first Docker container.
    Run the command with `sudo` if you''re on Linux:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'You''ll see that you''re under a `root` directory instead of your current one.
    Let''s check the process list again:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: It's isolated, as expected. You're now all ready to work with the container.
  prefs: []
  type: TYPE_NORMAL
- en: Alpine is a Linux distribution. Since it's really small in size, many people
    use it as their base image to build their application container. Do note, however,
    that it still has a few differences from mainstream Linux distributions. For example,
    Alpine uses `musl libc`, while most distributions use `glibc`.
  prefs: []
  type: TYPE_NORMAL
- en: The life cycle of a container
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using containers isn't as intuitive as most of the tools that we're used to
    working with, so we'll need to change the way we work. In this section, we'll
    go through how to use Docker so that we're able to benefit from containers.
  prefs: []
  type: TYPE_NORMAL
- en: The basics of Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When `docker run alpine ls` is executed, Docker carries out the following steps
    behind the scenes:'
  prefs: []
  type: TYPE_NORMAL
- en: It finds the `alpine` image locally. If this is not found, Docker will try to
    locate and pull it from the public Docker registry to the local image storage.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It extracts the image and creates a container accordingly.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: It executes the entry point defined in the image with commands, which are the
    arguments after the image name. In this example, the argument is `ls`. By default,
    the entry point is `/bin/sh -c` on Linux-based Docker.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: When the entry point process is finished, the container then exits.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: An image is an immutable bundle of code, libraries, configurations, and everything
    else we want to put in it. A container is an instance of an image, which is executed
    during runtime. You can use the `docker inspect IMAGE` and `docker inspect CONTAINER`
    commands to see the difference between an image and a container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Anything launched with `docker run` would take the foreground; the `-d` option (`--detach`)
    enables us to run a container in the detached mode. Sometimes, we may need to
    enter an active container to check the image or update something inside it. To
    do this, we could use the `-i` and `-t` options (`--interactive` and `--tty`).
    If we want to interact with a detached container, we can use the `exec` and `attach`
    command: the `exec` command allows us to run a process in a running container,
    while `attach` works as its name suggests. The following example demonstrates
    how to use these commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Your Terminal should now be flooded with `meow~`. Switch to another Terminal
    and run `docker ps`, a command to get the status of containers, to find out the
    name and the ID of the container. Here, both the name and the ID are generated
    by Docker, and you can access a container with either of them:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: As a matter of convenience, the name can be assigned upon `create` or `run` with
    the `--name` flag.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we access the container and inspect its processes, we''ll see two shells:
    one is meowing and the other is where we are. Kill the first shell with `kill
    -s 2 1` inside the container and we''ll see the whole container stopped as the
    entry point is exited. Finally, we''ll list the stopped containers with `docker
    ps -a` and clean them up with `docker rm CONTAINER_NAME` or `docker rm CONTAINER_ID`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Since Docker 1.13, the `docker system prune` command has been introduced, which
    helps us clean up stopped containers and occupied resources with ease.
  prefs: []
  type: TYPE_NORMAL
- en: The `PID 1` process is very special in UNIX-like operating systems. Regardless
    of what kind of process it is, it should reclaim its exited children and not take
    the `SIGKILL` signal. That's why the previous example uses `SIGINT` (2) instead
    of `SIGKILL`. Besides, most of the entry processes in a container don't handle
    terminated children, which may cause lots of un-reaped zombie processes in the
    system. If there's a need to run Docker containers in production without Kubernetes,
    use the `--init` flag upon `docker run`. This injects a `PID 1` process, which
    handles its terminated children correctly, into the container to run.
  prefs: []
  type: TYPE_NORMAL
- en: Layers, images, containers, and volumes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We know that an image is immutable and a container is ephemeral, and we know
    how to run an image as a container. Nevertheless, we are still missing some information with
    regard to packing an image.
  prefs: []
  type: TYPE_NORMAL
- en: An image is a read-only stack that consists of one or more layers, and a layer
    is a collection of files and directories in the filesystem. To improve disk space
    utilization, layers aren't locked to just one image but are shared among images,
    which means that Docker simply stores one copy of a base image locally, regardless
    of how many images are derived from it. You can utilize the `docker history [image]`
    command to understand how an image is built. For example, you will see that Alpine
    has only one layer if you check it with `docker history alpine`.
  prefs: []
  type: TYPE_NORMAL
- en: Whenever a container is created, it adds a thin, writable layer on top of the
    base image. Docker adopts the **Copy-On-Write** (**COW**) strategy on the thin
    layer. This means that a container reads the layers of the base image where the
    target files are stored and copies the file to its own writable layer if the file
    is modified. This approach prevents containers that are created from the same
    image from intervening with each other. The `docker diff [CONTAINER]` command
    shows the difference between the container and its base image in terms of their
    filesystem states. For example, if `/etc/hosts` in the base image is modified,
    Docker copies the file to the writable layer, and it'll be the only file in the
    output of `docker diff`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram illustrates the hierarchical structure of Docker images:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/fabdc429-ba54-4123-9bf4-3ab0d77e337b.png)'
  prefs: []
  type: TYPE_IMG
- en: It's important to note that data in the writable layer is deleted along with
    its container. To persist data, you commit the container layer as a new image with
    the `docker commit [CONTAINER]` command or mount data volumes into a container.
  prefs: []
  type: TYPE_NORMAL
- en: 'A data volume allows a container to carry out reading and writing operations,
    bypassing Docker''s filesystem. It can either be on a host''s directory or in
    other storage, such as Ceph or GlusterFS. Therefore, any disk I/O against the
    volume can operate at native speeds depending on the underlying storage. Since
    the data is persistent outside a container, it can be reused and shared by multiple
    containers. Mounting a volume is done by specifying the `-v` (`--volume`) flag
    with `docker run` or `docker create`. The following example mounts a volume under
    `/chest` in the container and leaves a file there. Afterwards, we use `docker
    inspect` to locate the data volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'The default `tty` path of the micro Linux provided by Docker CE on macOS can
    be found in the following location:'
  prefs: []
  type: TYPE_NORMAL
- en: '`~/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/tty`.'
  prefs: []
  type: TYPE_NORMAL
- en: You can attach to it with `screen`.
  prefs: []
  type: TYPE_NORMAL
- en: 'One use case of data volumes is sharing data between containers. To do this,
    we first create a container and mount volumes on it, and then reference the volume
    with the `--volumes-from` flag when launching other containers. The following
    examples create a container with a data volume, `/share-vol`. Container A can
    put a file into it, and container B can read it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'In addition, data volumes can be mounted under a given `host` path, and of
    course the data inside is persistent:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: Distributing images
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A registry is a service that stores, manages, and distributes images. Public
    services, such as Docker Hub ([https://hub.docker.com](https://hub.docker.com))
    and Quay ([https://quay.io](https://quay.io)), collect all kinds of pre-built
    images of popular tools, such as Ubuntu, `nginx`, and custom images from other
    developers. The Alpine Linux tool we've used many times already is actually pulled
    from Docker Hub ([https://hub.docker.com/_/alpine](https://hub.docker.com/_/alpine)).
    You can upload your own tool onto these services and share them with everyone
    else as well.
  prefs: []
  type: TYPE_NORMAL
- en: If you need a private registry, but for some reason you don't want to subscribe
    to the paid plans of registry service providers, you can always set up one on
    your own with the Docker Registry ([https://hub.docker.com/_/registry](https://hub.docker.com/_/registry)).
    Other popular registry service providers include Harbor ([https://goharbor.io/](https://goharbor.io/))
    and Portus ([http://port.us.org/](http://port.us.org/)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Before provisioning a container, Docker will try to locate the specified image
    in a rule indicated in the image name. An image name consists of three sections, `[registry/]name[:tag]`,
    and it''s resolved with the following rules:'
  prefs: []
  type: TYPE_NORMAL
- en: If the `registry` field is left out, Docker searches for the name on Docker
    Hub
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the `registry` field is a registry server, Docker searches the name for it
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You can have more than one slash in a name
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The tag defaults to `latest` if it's omitted
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'For example, an image name such as `gcr.io/google-containers/guestbook:v3`
    instructs Docker to download `v3` of `google-containers/guestbook` from `gcr.io`.
    Likewise, if you want to push an image to a registry, tag your image in the same
    manner and push it with `docker push [IMAGE]`. To list the images you currently
    own locally, use `docker images`. You can remove an image with `docker rmi [IMAGE]`.
    The following example shows how to work between different registries: downloading
    an `nginx` image from Docker Hub, tagging it to a private registry path, and pushing
    it accordingly. The private registry is hosted locally with `docker run -p 5000:5000
    registry`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we use the registry mentioned previously with the most basic setup. A
    more detailed guide about the deployment can be found at the following link: [https://docs.docker.com/registry/deploying/](https://docs.docker.com/registry/deploying/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Notice that although the default tag is `latest`, you have to tag and `push`
    it explicitly:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Most registry services ask for authentications if you're going to push images. `docker
    login` is designed for this purpose. For some older versions of Docker, you may sometimes receive
    an `image not found` error when attempting to pull an image, even though the image
    path is valid. This is likely to mean that you're unauthorized with the registry
    that keeps the image.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to images distributed via the registry service, there are options
    to dump images as a TAR archive and import them back into the local repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '`docker commit [CONTAINER]`: Commits the changes of the container layer into
    a new image'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker save --output [filename] IMAGE1 IMAGE2 ...`: Saves one or more images
    to a TAR archive'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker load -i [filename]`: Loads a TAR image into the local repository'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker export --output [filename] [CONTAINER]`: Exports a container''s filesystem
    as a TAR archive'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`docker import --output [filename] IMAGE1 IMAGE2`: Imports an exported TAR
    archive'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The `commit`, `save`, and `export` commands look pretty much the same. The main
    difference is that a saved image preserves files in between layers even if they
    are to be deleted eventually. On the other hand, an exported image squashes all
    intermediate layers into one final layer. Another difference is that a saved image
    keeps metadata such as layer histories, but this isn't available with an exported
    image. As a result, the exported image is usually smaller in size.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram depicts the relationship of states between a container
    and the images. The captions on the arrows are the corresponding Docker sub-commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7a5cfc93-ca67-4258-9142-e2d84b831e71.png)'
  prefs: []
  type: TYPE_IMG
- en: The container technology is tightly bound to operating system features, which
    means an image built for one platform can't run on another platform without recompiling
    a new image on the target platform. To make this simpler, Docker introduced the
    Image Manifest, which supports multi-arch builds. We won't discuss multi-arch
    builds in this book further, but you can find more information at the following
    link: [https://docs.docker.com/edge/engine/reference/commandline/manifest/](https://docs.docker.com/edge/engine/reference/commandline/manifest/).
  prefs: []
  type: TYPE_NORMAL
- en: Connecting containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Docker provides three kinds of networks to manage communications between containers
    and the hosts, namely `bridge`, `host`, and `none`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'By default, every container is connected to the bridge network upon creation.
    In this mode, every container is allocated a virtual interface as well as a private
    IP address, and the traffic going through the interface is bridged to the host''s
    `docker0` interface. Containers within the same bridge network can also connect
    to each other via their IP address. Let''s run one container that''s feeding a
    short message over port `5000`, and observe its configuration. The `--expose`
    flag opens the given ports to the world outside the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, the `greeter` container is allocated to the IP address `172.17.0.2`.
    Now, run another container, connecting to it with this IP address:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: The `docker network inspect bridge` command provides configuration details,
    such as attached containers, subnet segments, and gateway information.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can group some containers into one user-defined bridge network. This is
    the recommended way to connect multiple containers on a single host. The user-defined
    bridge network slightly differs from the default one, the major difference being
    that you can access a container from other containers with its name, rather than
    its IP address. Creating a network is done using the `docker network create [NW-NAME]` command,
    and we can attach containers to it by adding the `--network [NW-NAME]` flag at
    the time of creation. The network name of a container is its name by default,
    but it can be given another alias name with the `--network-alias` flag as well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'The `host` network works as its name suggests; every connected container shares
    the host''s network, but it loses the isolation property at the same time. The
    `none` network is a logically air-gapped box. Regardless of ingress or egress,
    traffic is isolated inside as there''s no network interface attached to the container.
    Here, we attach a container that listens on port `5000` to the `host` network
    and communicates with it locally:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: If you are using Docker CE for macOS, the host is the micro Linux on top of
    the hypervisor framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'The interaction between the host and the three network modes is shown in the
    following diagram. Containers in the `host` and `bridge` networks are attached
    with proper network interfaces and communicate with containers within the same
    network, as well as the outside world, but the `none` network is kept away from
    the host interfaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/b60d1e99-879c-46b7-8fde-5c8a47af6900.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Other than sharing the host network, the `-p(--publish) [host]:[container]` flag,
    when creating a container, also allows you to map a host port to a container.
    We don''t need attaching a `--expose` flag together with the `--publish` flag,
    as you''ll need to open a container''s port in any case. The following command
    launches a simple HTTP server at port `80`. You can view it with a browser as
    well:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: Working with a Dockerfile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When assembling an image, whether using `docker commit` or `export`, optimizing
    the outcome in a managed way is a challenge, let alone integrating it with a CI/CD
    pipeline. A `Dockerfile` represents the building task in the form of code, which
    significantly reduces the difficulty of building tasks for us. In this section,
    we'll describe how to map Docker commands into a `Dockerfile` and take a step
    towards optimizing it.
  prefs: []
  type: TYPE_NORMAL
- en: Writing your first Dockerfile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'A `Dockerfile` consists of a series of text instructions to guide the Docker
    daemon to form an image, and a `Dockerfile` must start with the `FROM` directive.
    For example, we may have an image built from the following one-liner:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'This roughly equates to the following `Dockerfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Obviously, building with a `Dockerfile` is much more concise and precise.
  prefs: []
  type: TYPE_NORMAL
- en: The `docker build [OPTIONS] [CONTEXT]` command is the only command associated
    with building tasks. A context can be a local path, URL, or `stdin`, which denotes
    the location of the `Dockerfile`. Once a build is triggered, the `Dockerfile`,
    alongside everything under the context, will be sent to the Docker daemon beforehand
    and then the daemon will start to execute instructions in the `Dockerfile` sequentially.
    Every execution of the instructions results in a new cache layer, and the ensuing
    instruction is executed at the new cache layer in the cascade. Since the context
    will be sent somewhere that isn't guaranteed to be a local path, and sending too
    many irrelevant files takes time, it's a good practice to put the `Dockerfile`,
    code, necessary files, and a `.dockerignore` file in an `empty` folder to make
    sure the resultant image contains only the desired files.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `.dockerignore` file is a list indicating which files under the same directory
    can be ignored at build time. It typically looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'Generally, `docker build` will try to locate a file named `Dockerfile` under
    the context to start a build. Sometimes, however, we may want to give it another
    name, which we can do using the `-f` (`--file`) flag. Another useful flag, `-t` (`--tag`),
    is able to give an image one or more repository tags after an image is built.
    Let''s say we want to build a `Dockerfile` named `builder.dck` under `./deploy`
    and label it with the current date and the latest tag. The command to do this
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The syntax of a Dockerfile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The building blocks of a `Dockerfile` are a dozen directives. Most of these
    are made up of functions of the `docker run/create` flags. Let''s take a look
    at the most essential ones:'
  prefs: []
  type: TYPE_NORMAL
- en: '`FROM <IMAGE>[:TAG|[@DIGEST]`: This is to tell the Docker daemon which image
    the current `Dockerfile` is based on. It''s also the one and only instruction
    that has to be in a `Dockerfile`; you can have a `Dockerfile` that contains only
    this line. Like all of the other image-relevant commands, the tag defaults to
    the latest if unspecified.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`RUN`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The `RUN` instruction runs one line of a command at the current cache layer
    and commits the outcome. The main discrepancy between the two forms is with regards
    to how the command is executed. The first form is called **shell form**. This
    actually executes commands in the form of `/bin/sh -c <commands>`. The other form
    is **exec form**.This treats the command with `exec` directly.
  prefs: []
  type: TYPE_NORMAL
- en: Using the shell form is similar to writing shell scripts, hence concatenating
    multiple commands by shell operators and line continuation, condition tests, or
    variable substitutions is completely valid. Bear in mind, however, that commands
    aren't processed by `bash` but by `sh`.
  prefs: []
  type: TYPE_NORMAL
- en: The `exec` form is parsed as a JSON array, which means that you have to wrap
    texts with double quotes and escape the reserved characters. Besides, as the command
    is not processed by any shell, the shell variables in the array will not be evaluated.
    On the other hand, if the shell doesn't exist in the base image, you can still
    use the `exec` form to invoke executables.
  prefs: []
  type: TYPE_NORMAL
- en: '`CMD`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: The `CMD` it to set default commands for the built image, but it doesn't run
    the command at build time. If arguments are supplied upon executing `docker run`,
    the `CMD` configurations here are overridden. The syntax rules of `CMD` are almost
    identical to `RUN`; the previous two forms are the `exec` form, and the third
    one is the shell form, which prepends `/bin/sh -c` to the parameters as well.
    There's another `ENTRYPOINT` directive that would interact with `CMD`;the parameter
    of `ENTRYPOINT` would prepend to the three forms of `CMD` when a container starts.
    There can be many `CMD` directives in a `Dockerfile`, but only the last one will
    take effect.
  prefs: []
  type: TYPE_NORMAL
- en: '`ENTRYPOINT`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'These two forms are, respectively, the `exec` form and the shell form, and
    the syntax rules are the same as `RUN`. The entry point is the default executable
    for an image. This means that when a container spins up, it runs the executable
    configured by `ENTRYPOINT`. When `ENTRYPOINT` is combined with the `CMD` and `docker
    run` arguments, writing it in a different form would lead to very different behavior.
    Here are the rules regarding their combinations:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the `ENTRYPOINT` is in shell form, then the `CMD` and `docker run` arguments
    would be ignored. The runtime command would be as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'If the `ENTRYPOINT` is in `exec` form and the `docker run` arguments are specified,
    then the `CMD` commands are overridden. The runtime command would be as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'If the `ENTRYPOINT` is in `exec` form and only `CMD` is configured, the runtime
    command would become the following for the three forms:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '`ENV`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'The `ENV` instruction sets environment variables for the consequent instructions
    and the built image. The first form sets the key to the string after the first
    space, including special characters, except the line continuation character. The
    second form allows us to set multiple variables in a line, separated with spaces.
    If there are spaces in a value, either enclose them with double quotes or escape
    the space character. Moreover, the key defined with `ENV` also takes effect on
    variables in the same document. See the following examples to observe the behavior
    of `ENV`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'The output during the `docker build` would be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '`ARG key[=<default value>]`: The `ARG` instruction can pass our arguments as
    environment variables into the building container via the `--build-arg` flag of `docker
    build`. For instance, building the following file using `docker build --build-arg
    FLAGS=--static` would result in `RUN ./build/dev/run --static` on the last line:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'Unlike `ENV`, only one argument can be assigned per line. If we are using `ARG`
    together with `ENV`, then the value of `ARG`, no matter where it is (either by `--build-arg`
    or the default value), would be overwritten by the value of `ENV`. Due to the
    frequent use of the proxy environment variables, these are all supported as arguments
    by default, including `HTTP_PROXY`, `http_proxy`, `HTTPS_PROXY`, `https_proxy`,
    `FTP_PROXY`, `ftp_proxy`, `NO_PROXY`, and `no_proxy`. This means we can pass these
    building arguments without defining them in the `Dockerfile` beforehand. One thing
    worth noting is that the value of `ARG` would remain in both the shell history
    on the building machine and the Docker history of the image, which means it''s
    wise not to pass sensitive data via `ARG`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`LABEL key1=value1 key2=value2 ...`: The use of `LABEL` resembles that of `ENV`,
    but a label is only stored in the metadata section of an image and is used by
    other host programs instead of programs in a container. For example, if we attach
    the maintainer of our image in the form `LABEL maintainer=johndoe@example.com`,
    we can filter the annotated image with the `-f(--filter)` flag in this query: `docker
    images --filter label=maintainer=johndoe@example.com`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`EXPOSE <port> [<port> ...]`: This instruction is identical to the `--expose`
    flag used with `docker run/create`, exposing ports in the container created by
    the resulting image.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`USER <name|uid>[:<group|gid>]`: The `USER` instruction switches the user to
    run the subsequent instructions, including the ones in `CMD` or `ENTRYPOINT`.
    However, it can''t work properly if the user doesn''t exist in the image. If you
    want to run instructions using a user that doesn''t exist, you have to run `adduser`
    before using the `USER` directive.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`WORKDIR <path>`: This instruction sets the working directory to a certain
    path. Environment variables set with `ENV` take effect on the path. The path would
    be created automatically if it doesn''t already exist. It works like `cd` in a
    `Dockerfile`, as it takes both relative and absolute paths and can be used multiple
    times. If an absolute path is followed by a relative path, the result would be
    relative to the previous path:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '`COPY`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: 'This directive copies the source to a file or a directory in the building container. The
    source as well as the destination could be files or directories. The source must
    be within the context path and not excluded by `.dockerignore`, as only those
    will be sent to the Docker daemon. The second form is for cases in which the path
    contains spaces. The `--chown` flag enables us to set the file owner on the fly
    without running additional `chown` steps inside containers. It also accepts numeric
    user IDs and group IDs:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ADD`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '`ADD` is quite similar to `COPY` in terms of its functionality: it moves files
    into an image. The major differences are that `ADD` supports downloading files
    from a remote address and extracting compressed files from the container in one
    line. As such, `<src>` can also be a URL or compressed file. If `<src>` is a URL,
    `ADD` will download it and copy it into the image; if `<src>` is inferred as a
    compressed file, it''ll be extracted into the `<dest>` path:'
  prefs: []
  type: TYPE_NORMAL
- en: '`VOLUME`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The `VOLUME` instruction creates data volumes at the given mount points. Once
    it''s been declared during build time, any change in the data volume at consequent
    directives would not persist. Besides, mounting host directories in a `Dockerfile`
    or `docker build` isn''t doable because of portability concerns: there''s no guarantee
    that the specified path would exist in the host. The effect of both syntax forms
    is identical; they only differ with regard to syntax parsing. The second form
    is a JSON array, so characters such as `\` should be escaped.'
  prefs: []
  type: TYPE_NORMAL
- en: '`ONBUILD [Other directives]`: `ONBUILD` allows you to postpone some instructions
    to later builds that happen in the derived image. For example, suppose we have
    the following two Dockerfiles:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'The instruction then would be evaluated in the following order when running `docker
    build`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Organizing a Dockerfile
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even though writing a `Dockerfile` is pretty much the same as composing a build
    script, there are some more factors that we should consider to build efficient,
    secure, and stable images. Moreover, a `Dockerfile` itself is also a document.
    Keeping it readable makes it easier to manage.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say we have an application stack that consists of application code,
    a database, and a cache. The initial `Dockerfile` of our stack could be the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: 'The first suggestion is to make sure a container is dedicated to one thing
    and one thing only. This gives our system better transparency since it helps us
    clarify the boundaries between components in the system. Also, packing unnecessary
    packages is discouraged, as it increases the image size, which could slow down
    the time it takes to build, distribute, and launch the image. We''ll remove the
    installation and configuration of both `mysql` and `redis` in our `Dockerfile`
    in the beginning. Next, the code is moved into the container with `ADD .`, which
    means that we''re very likely to move the whole code repository into the container.
    Usually, there''re lots of files that aren''t directly relevant to the application,
    including VCS files, CI server configurations, or even build caches, and we probably
    wouldn''t like to pack them into an image. For this reason, it is suggested to
    use `.dockerignore` to filter out these files as well. Lastly, using `COPY` is
    preferred over `ADD` in general, unless we want to extract a file in one step.
    This is because it is easier to predict the outcome when we use `COPY`. Now our
    `Dockerfile` is simpler, as shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: 'While building an image, the Docker engine will try to reuse the cache layer
    as much as possible, which notably reduces the build time. In our `Dockerfile`,
    we have to go through all the updating and dependency installation processes if
    any package to be installed needs updating. To benefit from building caches, we''ll
    re-order the directives based on a rule of thumb: run less frequent instructions
    first.'
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, as we've described before, any changes made to the container filesystem
    result in a new image layer. To be more specific, `ADD`, `RUN`, and `COPY` create
    layers. Even though we deleted certain files in the consequent layer, these files
    still occupy image layers as they're still being kept at intermediate layers.
    Therefore, our next step is to minimize the image layers by simply compacting
    multiple `RUN` instructions and cleaning the unused files at the end of the `RUN`.
    Moreover, to keep the readability of the `Dockerfile`, we tend to format the compacted
    `RUN` with the line continuation character, `\`. Although `ADD` can fetch a file
    from a remote location to the image, it's still not a good idea to do this as
    this would still occupy a layer in order to store the downloaded file. Downloading
    files with `RUN` and `wget/curl` is more common.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition to working with the building mechanisms of Docker, we''d also like
    to write a maintainable `Dockerfile` to make it clearer, more predictable, and
    more stable. Here are some suggestions:'
  prefs: []
  type: TYPE_NORMAL
- en: Use `WORKDIR` instead of the inline `cd`, and use the absolute path for `WORKDIR`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Explicitly expose the required ports
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specify a tag for the base image
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Separate and sort packages line by line
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the `exec` form to launch an application
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first four suggestions are pretty straightforward, aimed at eliminating
    ambiguity. The last one refers to how an application is terminated. When a stop
    request from the Docker daemon is sent to a running container, the main process
    (`PID 1`) will receive a stop signal (`SIGTERM`). If the process is not stopped
    after a certain period of time, the Docker daemon will send another signal (`SIGKILL`)
    to kill the container. The `exec` form and shell form differ here. In the shell
    form, the `PID 1` process is `/bin/sh -c`, not the application. Furthermore, different
    shells don't handle signals in the same way. Some forward the stop signal to the
    child processes, while some do not. The shell at Alpine Linux doesn't forward
    them. As a result, to stop and clean up our application properly, using the `exec`
    form is encouraged.
  prefs: []
  type: TYPE_NORMAL
- en: 'Combining those principles, we have the following `Dockerfile`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: There are other practices that we can follow to make our `Dockerfile` better,
    including starting from a dedicated and smaller base image rather than general-purpose
    distributions, using users other than `root` for better security, and removing
    unnecessary files in the `RUN` in which they are joined.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-stage builds
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The principles we've discussed so far are all about how to make builds fast
    and how to make the final image smaller while keeping the maintainability of the
    `Dockerfile`. Instead of striving to optimize a `Dockerfile`, writing one to build
    the artifacts we need and then moving them to another image with runtime dependencies only
    makes it much easier to sort the different logic out. In the building stage, we
    can forget about minimizing the layers so that the build cache can be reused efficiently;
    when it comes to the release image, we can follow the previously recommended techniques
    to make our image clean and small. Before Docker CE 17.05, we had to write two
    Dockerfiles to implement this build pattern. Now, Docker has built-in support
    to define different stages in a single `Dockerfile`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a `golang` build as an example: this requires lots of dependencies and
    a compiler, but the artifact can merely be a single binary. Let''s look at the
    following example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: The delimiter for the different stages is the `FROM` directive, and we can name
    the stages with the `AS` keyword after the image name. At the `builder` stage,
    Docker starts a `golang` base image, and then builds the target binary as usual.
    Afterwards, during the second build, it copies the binary from the `builder` container
    with `--from=[stage name|image name]` to a `scratch` image—a reserved name for
    an entirely empty image. As there's only one binary file and one layer in the
    resultant image, its size is dramatically smaller than the `builder` one.
  prefs: []
  type: TYPE_NORMAL
- en: 'The number of stages isn''t limited to two, and the source of the `COPY` directive
    can either be a previously defined stage or a built image. The `ARG` directive
    works against `FROM`, which is also the only exception that can be written before
    a `FROM` directive, as they belong to different stages. In order to use it, the `ARG` directive
    to be consumed in `FROM` should be declared before `FROM`, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Multi-container orchestration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we pack more and more applications into isolated boxes, we'll soon realize
    that we need a tool that is able to help us tackle many containers simultaneously.
    In this section, we'll move a step up from spinning up just one single container
    to orchestrating multiple containers in a band.
  prefs: []
  type: TYPE_NORMAL
- en: Piling up containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Modern systems are usually built as stacks made up of multiple components that
    are distributed over networks, such as application servers, caches, databases,
    and message queues. Each individual component is also a self-contained system
    with many sub-components. What's more, the rising trend of microservices introduces
    additional degrees of complexity into these entangled relationships between systems.
    Because of this, even though container technology gives us a certain degree of
    relief regarding deployment tasks, coordinating components in a system is still
    difficult.
  prefs: []
  type: TYPE_NORMAL
- en: Let's say we have a simple application called `kiosk`, which connects to a `redis`
    to manage how many tickets we currently have. Once a ticket is sold, it publishes
    an event through a `redis` channel. The **recorder** subscribes the `redis` channel
    and writes a timestamp log into a MySQL database upon receiving any event.
  prefs: []
  type: TYPE_NORMAL
- en: 'For the `kiosk` and the `recorder`, you can find the code as well as their
    Dockerfiles here: [https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter2](https://github.com/PacktPublishing/DevOps-with-Kubernetes-Second-Edition/tree/master/chapter2). The
    architecture is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0adc75ae-67ca-499e-bf09-be8ca35c7489.png)'
  prefs: []
  type: TYPE_IMG
- en: 'We know how to start those containers separately and connect them with each
    other. Based on what we''ve discussed before, we would first create a bridge network
    and run the containers inside:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: Because our `kiosk` and `recorder` are much lighter than the database, our applications
    are very likely to start up earlier than the database's. In this case, our `kiosk`
    might fail if any incoming connection requests changes to the databases or to
    Redis. In other words, we have to consider the startup order in our startup scripts.
    We also have to deal with problems such as how to deal with random components
    crashing, how to manage variables, how to scale out certain components, and how
    to manage the states of every moving part.
  prefs: []
  type: TYPE_NORMAL
- en: An overview of Docker compose
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Docker compose is a tool that enables us to run multiple containers with ease.
    It''s a built-in tool in the Docker CE distribution. All it does is read `docker-compose.yml`
    (or `.yaml`) to run the defined containers. A `docker-compose` file is a YAML-based
    template, and it typically looks like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'Launching it is pretty simple: save the template to `docker-compose.yml` and
    use the `docker-compose up` command to start it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: Let's take a look at what `docker-compose` did when the `up` command was executed.
  prefs: []
  type: TYPE_NORMAL
- en: Docker compose is basically a medley of Docker functions for multiple containers.
    For example, the counterpart of `docker build` is `docker-compose build`; the
    former builds a Docker image and the latter builds Docker images listed in `docker-compose.yml`.
    Remember, however, that the `docker-compose run` command doesn't correspond to `docker
    run`; it's actually used to run a specific container from the configuration in `docker-compose.yml`.
    In fact, the closest command to `docker run` is `docker-compose up`.
  prefs: []
  type: TYPE_NORMAL
- en: The `docker-compose.yml` file consists of different configurations of volumes,
    networks, and services. There should be a version definition to indicate which
    version of the `docker-compose` format should be used. With this understanding
    of the template structure, what the previous `hello-world` example does is quite
    clear; it creates a service called `hello-world` that uses the `hello-world:latest` image.
  prefs: []
  type: TYPE_NORMAL
- en: Since there's no network defined, `docker-compose` will create a new network
    with a default driver and connect services to that network, as shown at the start
    of the output of the example.
  prefs: []
  type: TYPE_NORMAL
- en: The network name of a container will be the name of the service. You may notice
    that the name displayed in the console differs slightly from its original one
    in `docker-compose.yml`. This is because Docker compose tries to avoid name conflicts
    between containers. As a result, Docker compose runs the container with the name
    it generated and makes a network alias with the service name. In this example,
    both `hello-world` and `user_hello-world_1` are resolvable to other containers
    within the same network.
  prefs: []
  type: TYPE_NORMAL
- en: Docker compose is the easiest option to run multiple containers on a single
    machine, but it's not designed to orchestrate containers across networks. Other
    major container orchestration engines such as **Kubernetes**, **Docker Swarm**,
    **Mesos** (with **Marathon** or **Aurora**), or **Nomad** are better choices to
    run containers across multiple nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Composing containers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As Docker compose is the same as Docker in many aspects, it''s more efficient
    to understand how to write `docker-compose.yml` with examples than start from
    `docker-compose` syntax. Let''s now go back to the `kiosk-example` we looked at
    earlier and start with a `version` definition and four `services`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The `docker run` arguments for `kiosk-example` are pretty simple. They include
    a publishing port and an environment variable. On the Docker compose side, we
    fill the source image, the publishing port, and environment variables accordingly.
    Because Docker compose is able to handle `docker build`, it can build images if
    those images can''t be found locally. We want to use this to decrease the effort
    of image management:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 'Converting the Docker run of the `recorder-example` and `redis` in the same
    manner, we have a template that looks as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'For the MySQL part, MySQL requires a data volume to keep its data as well as
    its configurations. In addition to the `lmysql` section, we add `volumes` at the
    level of `services` and an empty map called `mysql-vol` to claim a data volume:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: One of the benefits of this is that we can manage the launching order between
    the components with `depends_on`. What this does is maintain the order; it can't
    detect whether the components that it will use are ready. This means our application
    could still connect and write to the database before the database is ready. All
    in all, as our program is a part of a distributed system with many moving parts,
    it's a good idea to make it resilient to the changes of its dependencies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Combining all of the preceding configurations, including `depends_on`, we have
    the final template, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 'This file is put in the `root` folder of a project. The corresponding file
    tree is shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, run `docker-compose up` to check everything is fine. We can check
    every component is linked nicely using `kiosk`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: Writing a template for Docker compose is as simple as this. We're now able to
    run an application in the stack with ease.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Starting from the very primitive elements of Linux containers and Docker tool
    stacks, we went through every aspect of containerizing an application, including
    packing and running a Docker container, writing a `Dockerfile` for code-based
    immutable deployment, and manipulating multiple containers with Docker compose.
    However, the abilities we gained in this chapter only allow us to run and connect
    containers within the same host, which limits our ability to build larger applications.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 3](a5cf080a-372a-406e-bb48-019af313c676.xhtml), *Getting Started
    with Kubernetes*, we'll meet Kubernetes, unleashing the power of containers beyond
    the limits of scale.
  prefs: []
  type: TYPE_NORMAL
