- en: '11'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Using Kubernetes Deployments for Stateless Workloads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The previous chapter introduced two important Kubernetes objects: **ReplicationController**
    and **ReplicaSet**. At this point, you already know that they serve similar purposes
    in terms of maintaining identical, healthy replicas (copies) of Pods. In fact,
    ReplicaSet is a successor of ReplicationController and, in the most recent versions
    of Kubernetes, ReplicaSet should be used in favor of ReplicationController.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, it is time to introduce the **Deployment** object, which provides easy
    scalability, rolling updates, and versioned rollbacks for your stateless Kubernetes
    applications and services. Deployment objects are built on top of ReplicaSets
    and they provide a declarative way of managing them – just describe the desired
    state in the Deployment manifest and Kubernetes will take care of orchestrating
    the underlying ReplicaSets in a controlled, predictable manner. Alongside StatefulSet,
    which will be covered in the next chapter, it is the most important workload management
    object in Kubernetes. This will be the bread and butter of your development and
    operations on Kubernetes! The goal of this chapter is to make sure that you have
    all the tools and knowledge you need to deploy your stateless application components
    using Deployment objects, as well as to safely release new versions of your components
    using rolling updates of Deployments.
  prefs: []
  type: TYPE_NORMAL
- en: 'This chapter will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the Deployment object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How Kubernetes Deployments seamlessly handle revisions and version rollouts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployment object best practices
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A Kubernetes cluster that has been deployed. You can use either a local or cloud-based
    cluster, but to fully understand the concepts shown in this chapter, we recommend
    using a multi-node, cloud-based Kubernetes cluster if available.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kubernetes CLI (`kubectl`) must be installed on your local machine and configured
    to manage your Kubernetes cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes cluster deployment (local and cloud-based) and `kubectl` installation
    were covered in *Chapter 3*, *Installing Your First Kubernetes Cluster*.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the latest code samples for this chapter from the official
    GitHub repository: [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter11](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter11).'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the Deployment object
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes gives you out-of-the-box flexibility when it comes to running different
    types of workloads, depending on your use cases. By knowing which workload type
    fits your application needs, you can make more informed decisions, optimize resource
    usage, and ensure better performance and reliability in your cloud-based applications.
    This foundational knowledge helps you unlock the full potential of Kubernetes’
    flexibility, allowing you to deploy and scale applications with confidence. Let’s
    have a brief look at the supported workloads to understand where the Deployment
    object fits, as well as its purpose.
  prefs: []
  type: TYPE_NORMAL
- en: The following diagram demonstrates the different types of application workloads
    in Kubernetes, which we will explain in the following sections.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22019_11_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.1: Application workload types in Kubernetes'
  prefs: []
  type: TYPE_NORMAL
- en: 'When implementing cloud-based applications, you will generally need the following
    types of workloads:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Stateless**: In the world of containers, stateless applications are those
    that don’t hold onto data (state) within the container itself. Imagine two Nginx
    containers serving the same purpose: one stores user data in a file inside the
    container, while the other uses a separate container like MongoDB for data persistence.
    Although they both achieve the same goal, the first Nginx container becomes stateful
    because it relies on internal storage. The second Nginx container, utilizing an
    external database, remains stateless. This stateless approach makes applications
    simpler to manage and scale in Kubernetes, as they can be easily restarted or
    replaced without worrying about data loss. Typically, Deployment objects in Kubernetes
    are used to manage these stateless workloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Stateful**: In the case of containers and Pods, we call them stateful if
    they store any modifiable data inside themselves. A good example of such a Pod
    is a MySQL or MongoDB Pod that reads and writes the data to a PersistentVolume.
    Stateful workloads are much harder to manage – you need to carefully manage sticky
    sessions or data partitions during rollouts, rollbacks, and when scaling. As a
    rule of thumb, try to keep stateful workloads outside your Kubernetes cluster
    if possible, such as by using cloud-based **Software-as-a-Service** (**SaaS**)
    database offerings. In Kubernetes, StatefulSet objects are used to manage stateful
    workloads. *Chapter 12*, *StatefulSet – Deploying Stateful Applications*, provides
    more details about these types of objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Job or CronJob**: This type of workload performs job or task processing,
    either scheduled or on demand. Depending on the type of application, batch workloads
    may require thousands of containers and a lot of nodes – this can be anything
    that happens *in the background*. Containers that are used for batch processing
    should also be stateless to make it easier to resume interrupted jobs. In Kubernetes,
    Job and CronJob objects are used to manage batch workloads. *Chapter 4*, *Running
    Your Containers in Kubernetes*, provides more details about these types of objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**DaemonSet**: There are cases where we want to run workloads on every Kubernetes
    node to support the Kubernetes functionality. It can be a monitoring application,
    logging application, storage management agent (for PersistentVolumes), etc. For
    such workloads, we can use a special deployment type called a DaemonSet, which
    will guarantee that a copy of the workload will be running on every node in the
    cluster. *Chapter 13*, *DaemonSet – Maintaining Pod Singletons on Nodes*, provides
    more details about these types of objects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With this concept regarding the different types of workloads in Kubernetes,
    we can dive deeper into managing stateless workloads using Deployment objects.
    In short, they provide declarative and controlled updates for Pods and ReplicaSets.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can declaratively perform operations such as the following by using Deployment
    objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rollout of a New ReplicaSet**: Deployments excel at managing controlled rollouts.
    You can define a new ReplicaSet with the desired Pod template within a Deployment
    object. Kubernetes then orchestrates a gradual rollout by scaling up the new ReplicaSet
    while scaling down the old one, minimizing downtime and ensuring a smooth transition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Controlled Rollout with Pod Template Change**: Deployments allow you to update
    the Pod template within the Deployment definition. When you deploy the updated
    Deployment, Kubernetes performs a rolling update, scaling up the new ReplicaSet
    with the modified template and scaling down the old one. This enables you to introduce
    changes to your application’s Pods in a controlled manner.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rollback to a Previous Version**: Deployments keep track of their revision
    history. If you encounter any issues with the new version, you can easily roll
    back to a previous stable Deployment version. This allows you to revert changes
    quickly and minimize disruption.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scaling ReplicaSets**: Scaling a Deployment directly scales the associated
    ReplicaSet. You can specify the desired number of replicas for the Deployment,
    and Kubernetes automatically scales the underlying ReplicaSet to meet that requirement.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pausing and Resuming Rollouts**: Deployments offer the ability to pause the
    rollout of a new ReplicaSet if you need to address any issues or perform additional
    configuration. Similarly, you can resume the rollout once the issue is resolved.
    This provides flexibility during the deployment process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this way, Deployment objects provide an end-to-end pipeline for managing
    your stateless components running in Kubernetes clusters. Usually, you will combine
    them with Service objects, as presented in *Chapter 8*, *Exposing Your Pods with
    Services*, to achieve high fault tolerance, health monitoring, and intelligent
    load balancing for traffic coming into your application.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s have a closer look at the anatomy of the Deployment object specification
    and how to create a simple example deployment in our Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Deployment object
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Do not worry about the Deployment skeleton as you can use any supported tools
    for creating the Deployment YAMLs. It is possible to create a Deployment skeleton
    with `kubectl create deployment` commands as follows, which will basically display
    the YAML with the values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'You can redirect the output to a file and use it as the base for your deployment
    configurations:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'First, let’s take a look at the structure of an example Deployment YAML manifest
    file, `nginx-deployment.yaml`, that maintains three replicas of an `nginx` Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the structure of the Deployment spec is almost identical to
    ReplicaSet, although it has a few extra parameters for configuring the strategy
    for rolling out new versions. The preceding YAML specification has four main components:'
  prefs: []
  type: TYPE_NORMAL
- en: '`replicas`: Defines the number of Pod replicas that should run using the given
    `template` and matching label `selector`. Pods may be created or deleted to maintain
    the required number. This property is used by the underlying ReplicaSet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`selector`: A label selector, which defines how to identify Pods that the underlying
    ReplicaSet owns. This can include set-based and equality-based selectors. In the
    case of Deployments, the underlying ReplicaSet will also use a generated `pod-template-hash`
    label to ensure that there are no conflicts between different child ReplicaSets
    when you’re rolling out a new version. Additionally, this generally prevents accidental
    acquisitions of bare Pods, which could easily happen with simple ReplicaSets.
    Nevertheless, Kubernetes does not prevent you from defining overlapping Pod selectors
    between different Deployments or even other types of controllers. However, if
    this happens, they may conflict and behave unexpectedly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`template`: Defines the template for Pod creation. Labels used in `metadata`
    must match our `selector`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`strategy`: Defines the details of the strategy that will be used to replace
    existing Pods with new ones. You will learn more about such strategies in the
    following sections. In this example, we showed the default `RollingUpdate` strategy.
    In short, this strategy works by slowly replacing the Pods of the previous version,
    one by one, by using the Pods of the new version. This ensures zero downtime and,
    together with Service objects and readiness probes, provides traffic load balancing
    to Pods that can serve the incoming traffic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Deployment spec provides a high degree of reconfigurability to suit your
    needs. We recommend referring to the official documentation for all the details:
    https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.31/#deployment-v1-apps
    (refer to the appropriate version of your Kubernetes cluster, e.g., v1.31)'
  prefs: []
  type: TYPE_NORMAL
- en: 'To better understand the relationship of Deployment, its underlying child ReplicaSet,
    and Pods, look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.1 – Kubernetes Deployment'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B22019_11_02.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.2: Kubernetes Deployment'
  prefs: []
  type: TYPE_NORMAL
- en: 'Once you have defined and created a Deployment, it is not possible to change
    its `selector`. This is desired because, otherwise, you could easily end up with
    orphaned ReplicaSets. There are two important actions that you can perform on
    existing Deployment objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Modify template**: Usually, you would like to change the Pod definition to
    a new image version of your application. This will cause a rollout to begin, according
    to the rollout `strategy`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Modify replica number**: Just changing the number will cause ReplicaSet to
    gracefully scale up or down.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now, let’s declaratively apply our example Deployment YAML manifest file, `nginx-deployment.yaml`,
    to the cluster using the `kubectl apply` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Using the `--record` flag is useful for tracking the changes that are made to
    the objects, as well as to inspect which commands caused these changes. You will
    then see an additional automatic annotation, `kubernetes.io/change-cause`, which
    contains information about the command. But the `--record` flag has been deprecated,
    and will be removed in the future. So, if you have a dependency on this annotation,
    it is a best practice to include the annotation manually as part of the Deployment
    update.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you wish, add an annotation to the Deployment manually using the `kubectl
    annotate` command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Immediately after the Deployment object has been created, use the `kubectl
    rollout` command to track the status of your Deployment in real time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This is a useful command that can give us a lot of insight into what is happening
    with an ongoing Deployment rollout. You can also use the usual `kubectl get` or
    `kubectl describe` commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the Deployment has been successfully created and all three Pods
    are now in the ready state.
  prefs: []
  type: TYPE_NORMAL
- en: Instead of typing `deployment`, you can use the `deploy` abbreviation when using
    `kubectl` commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may also be interested in seeing the underlying ReplicaSets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Please take note of the generated hash, `5b8dc6b8cd`, in the name of our ReplicaSet,
    which is also the value of the `pod-template-hash` label, which we mentioned earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, you can see the Pods in the cluster that were created by the Deployment
    object using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations – you have created and inspected your first Kubernetes Deployment!
    Next, we will take a look at how Service objects are used to expose your Deployment
    to external traffic coming into the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing Deployment Pods using Service objects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Service objects were covered in detail in *Chapter 8*, *Exposing Your Pods with
    Services*, so, in this section, we will provide a brief recap about the role of
    Services and how they are usually used with Deployments.
  prefs: []
  type: TYPE_NORMAL
- en: The following diagram can be used as a base reference for the different networks
    in a Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22019_11_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.3: Different networks in Kubernetes'
  prefs: []
  type: TYPE_NORMAL
- en: Services are Kubernetes objects that allow you to expose your Pods, either to
    other Pods in the cluster or to end users. They are the crucial building blocks
    for highly available and fault-tolerant Kubernetes applications since they provide
    a load balancing layer that actively routes incoming traffic to ready and healthy
    Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deployment objects, on the other hand, provide Pod replication, automatic restarts
    when failures occur, easy scaling, controlled version rollouts, and rollbacks.
    But there is a catch: Pods that are created by ReplicaSets or Deployments have
    a finite life cycle. At some point, you can expect them to be terminated; then,
    new Pod replicas with new IP addresses will be created in their place. So, what
    if you have a Deployment running web server Pods that need to communicate with
    Pods that have been created as a part of another Deployment such as backend Pods?
    Web server Pods cannot assume anything about the IP addresses or the DNS names
    of backend Pods, as they may change over time. This issue can be resolved with
    Service objects, which provide reliable networking for a set of Pods.'
  prefs: []
  type: TYPE_NORMAL
- en: In short, Services target a set of Pods, and this is determined by label selectors.
    These label selectors work on the same principle that you have learned about for
    ReplicaSets and Deployments. The most common scenario is exposing a Service for
    an existing Deployment by using the same label selector.
  prefs: []
  type: TYPE_NORMAL
- en: The Service is responsible for providing a reliable DNS name and IP address,
    as well as for monitoring selector results and updating the associated endpoint
    object with the current IP addresses of the matching Pods. For internal cluster
    communication, this is usually achieved using simple `ClusterIP` Services, whereas
    to expose them to external traffic, you can use the `NodePort` Service or, more
    commonly in cloud deployments, the `LoadBalancer` Service.
  prefs: []
  type: TYPE_NORMAL
- en: 'To visualize how Service objects interact with Deployment objects in Kubernetes,
    look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 11.2 – Client Pod performing requests to the Kubernetes Deployment,
    exposed by the ClusterIP Service'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B22019_11_04.png)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 11.4: Client Pod performing requests to the Kubernetes Deployment, exposed
    by the ClusterIP Service'
  prefs: []
  type: TYPE_NORMAL
- en: This diagram visualizes how any client Pod in the cluster can transparently
    communicate with the `nginx` Pods that are created by our Deployment object and
    exposed using the `ClusterIP` Service. ClusterIPs are essentially virtual IP addresses
    that are managed by the `kube-proxy` service that is running on each Node. `kube-proxy`
    is responsible for all the clever routing logic in the cluster and ensures that
    the routing is entirely transparent to the client Pods – they do not need to know
    if they are communicating with the same Node, a different Node, or even an external
    component. In the backend, `kube-proxy` watches the updates in the Service object
    and maintains all necessary routing rules required on each Node to ensure the
    proper traffic. `kube-proxy` generally uses `iptables` or **IP Virtual Server**
    (**IPVS**) to manage the traffic routing.
  prefs: []
  type: TYPE_NORMAL
- en: The role of the Service object is to define a set of ready Pods that should
    be *hidden* behind a stable ClusterIP. Usually, the internal clients will not
    be calling the Service pods using the ClusterIP, but they will use a DNS short
    name, which is the same as the Service name – for example, `nginx-service-example`.
    This will be resolved to the ClusterIP by the cluster’s internal DNS service.
    Alternatively, they may use a DNS **Fully Qualified Domain Name** (**FQDN**) in
    the form of `<serviceName>.<namespaceName>.svc.<clusterDomain>`; for example,
    `nginx-service-example.default.svc.cluster.local`.
  prefs: []
  type: TYPE_NORMAL
- en: For `LoadBalancer` or `NodePort` Services that expose Pods to external traffic,
    the principle is similar to internally; they also provide a ClusterIP for internal
    communication. The difference is that they also configure more components so that
    external traffic can be routed to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you’re equipped with the necessary knowledge about Service objects
    and their interactions with Deployment objects, let’s put what we’ve learned into
    practice!
  prefs: []
  type: TYPE_NORMAL
- en: Refer to *Chapter 8*, *Exposing Your Pods with Services*, to learn more about
    Services and the different types of Services available in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Service declaratively
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we are going to expose our `nginx-deployment-example` Deployment
    using the `nginx-service-example` Service object, which is of the `LoadBalancer`
    type, by performing the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create an `nginx-service.yaml` manifest file with the following content:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The label selector of the Service is the same as the one we used for our Deployment
    object. The specification of the Service instructs us to expose our Deployment
    on port `80` of the cloud load balancer, and then route the traffic from target
    port `80` to the underlying Pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on how your Kubernetes cluster is deployed, you may not be able to
    use the `LoadBalancer` type. In that case, you may need to use the `NodePort`
    type for this exercise or stick to the simple `ClusterIP` type and skip the part
    about external access. For local development deployments such as `minikube`, you
    will need to use the `minikube service` command to access your Service. You can
    find more details in the documentation: [https://minikube.sigs.k8s.io/docs/commands/service/](https://minikube.sigs.k8s.io/docs/commands/service/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `nginx-service-example` Service and use the `kubectl get` or `kubectl
    describe` command to gather information about the status of our new Service and
    associated load balancer:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let us try to access the Service from another Pod, as we did in *Chapter
    8*, *Exposing Your Pods with Services*. Let us create a `k8sutils` Pod as follows
    and test the Service access:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This shows how Services are used to expose Deployment Pods to external traffic.
    Now, we will quickly show you how to achieve a similar result using imperative
    commands to create a Service for our Deployment object.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Service imperatively
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A similar effect can be achieved using the imperative `kubectl expose` command
    `– a` Service will be created for our Deployment object named `nginx-deployment-example`.
    Use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us explain the preceding code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: This will create a Service with the same name as the Deployment object – that
    is, `nginx-deployment-example`. If you would like to use a different name, as
    shown in the declarative example, you can use the `--name=nginx-service-example`
    parameter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Additionally, port `80`, which will be used by the Service, will be the same
    as the one that was defined for the Pods. If you want to change this, you can
    use the `--port=<number>` and `--target-port=<number>` parameters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Check `kubectl expose deployment --help` to see the options available for exposing
    the Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that this imperative command is recommended for use in development
    or debugging scenarios only. For production environments, you should leverage
    declarative *Infrastructure-as-Code* and *Configuration-as-Code* approaches as
    much as possible.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, let us learn how to use readiness, liveness, and startup
    probes with the Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Role of readiness, liveness, and startup probes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In *Chapter 8*, *Exposing Your Pods with Services*, we learned that there are
    three types of probes that you can configure for each container running in a Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: Readiness probe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liveness probe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Startup probe
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All these probes are incredibly useful when you’re configuring your Deployments
    – always try to predict possible life cycle scenarios for the processes running
    in your containers and configure the probes accordingly for your Deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that, by default, no probes are configured on containers running
    in Pods. Kubernetes will serve traffic to Pod containers behind the Service, but
    only if the containers have successfully started, and restart them if they have
    crashed using the default `always-restart` policy. This means that it is your
    responsibility to figure out what type of probes and what settings you need for
    your particular case. You will also need to understand the possible consequences
    and caveats of incorrectly configured probes – for example, if your liveness probe
    is too restrictive and has timeouts that are too small, it may wrongfully restart
    your containers and decrease the availability of your application.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s demonstrate how you can configure a **readiness probe** on your Deployment
    and how it works in real time.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are interested in the configuration details for other types of probes,
    refer to *Chapter 8*, *Exposing Your Pods with Services*, and also to the official
    documentation: [https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/).'
  prefs: []
  type: TYPE_NORMAL
- en: The `nginx` Deployment that we use is very simple and does not need any dedicated
    readiness probe. Instead, we will arrange the container’s setup so that we can
    have the container’s readiness probe fail or succeed on demand. The idea is to
    create an empty file called `/usr/share/nginx/html/ready` during container setup,
    which will be served on the `/ready` endpoint by `nginx` (just like any other
    file) and configure a readiness probe of the `httpGet` type to query the `/ready`
    endpoint for a successful HTTP status code. Now, by deleting or recreating the
    `ready` file using the `kubectl exec` command, we can easily simulate failures
    in our Pods that cause the readiness probe to fail or succeed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Follow these steps to configure and test the readiness probe:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Delete the existing Deployment using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a new Deployment YAML as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we have the `spec.template` section as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'There are multiple parts changing in the Deployment manifest, all of which
    have been highlighted. First, we have overridden the default container entry point
    command using `command` and passed additional arguments. `command` is set to `/bin/sh`
    to execute a custom shell command. The additional arguments are constructed in
    the following way:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-c` is an argument for `/bin/sh` that instructs it that what follows is a
    command to be executed in the shell.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`touch /usr/share/nginx/html/ready` is the first command that’s used in the
    container shell. This will create an empty `ready` file that can be served by
    `nginx` on the `/ready` endpoint.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`echo "You have been served by Pod with IP address: $(hostname -i)" > /usr/share/nginx/html/index.html`
    is the second command that sets the content of `index.html` to information about
    the internal cluster Pod’s IP address. `hostname -i` is the command that’s used
    to get the container IP address. This value will be different for each Pod running
    in our Deployment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`nginx -g "daemon off;"`: Finally, we execute the default `entrypoint` command
    for the `nginx:1.25.4` image. This will start the `nginx` web server as the main
    process in the container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Usually, you would perform such customization using a new container image, which
    inherits from a generic container image (e.g., `nginx` image) as a base and dedicated
    application script. The method shown here is being used for demonstration purposes
    and shows how flexible the Kubernetes runtime is. Refer to the sample `Chapter11/Containerfile`
    in the GitHub repository for creating custom container images.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second set of changes we made in the YAML manifest for the Deployment was
    for the definition of `readinessProbe`, which is configured as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The probe is of the `httpGet` type and executes an HTTP GET request to the `/ready`
    HTTP endpoint on port `80` of the container.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`initialDelaySeconds`: This is set to `5` seconds and configures the probe
    to start querying after 5 seconds from container start.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`periodSeconds`: This is set to `2` seconds and configures the probe to query
    in 2-second intervals.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`timeoutSeconds`: This is set to `10` seconds and configures the number of
    seconds, after which the HTTP GET request times out.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`successThreshold`: This is set to `1` and configures the minimum number of
    consecutive success queries of the probe before it is considered to be successful
    once it has failed.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`failureThreshold`: This is set to `2` and configures the minimum number of
    consecutive failed queries of the probe before it is considered to have failed.
    Setting it to a value that’s greater than `1` ensures that the probe is not providing
    false positives.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To create the Deployment, follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply the new YAML manifest file to the cluster using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Verify that the `nginx-service-example` Service is displaying with backend
    Pod IP addresses. You can see that the Service has three endpoints that map to
    our Deployment Pods, all of which are ready to serve traffic:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Test the nginx web server access using the `k8sutils` Pod that we created earlier
    in this chapter. You will notice that the responses iterate over different Pod
    IP addresses. This is because our Deployment has been configured to have three
    Pod replicas. Each time you perform a request, you may hit a different Pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s simulate a readiness failure for the first Pod. In our case, this
    is `nginx-deployment-readiness-69dd4cfdd9-4pkwr`, which has an IP address of `10.244.1.7`.
    To do this, we need to simply delete the `ready` file inside the container using
    the `kubectl exec` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The readiness probe will now start to fail, but not immediately! We have set
    it up so that it needs to fail at least two times, and each check is performed
    in 2-second intervals. Later, you will notice that you are only served by two
    other Pods that are still ready.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, if you describe the `nginx-service-example` Service, you will see that
    it only has two endpoints available, as expected:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'In the events for the Pod, you can also see that it is considered not ready:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'We can push this even further. Delete the ready files in the other two Pods
    to make the whole Service fail:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: Now, when you check the Service from the `k8sutils` Pod, you will see that the
    request is pending and that, eventually, it will fail with a timeout. We are now
    in a pretty bad state – we have a total readiness failure for all the Pod replicas
    in our Deployment!
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Finally, let’s make one of our Pods ready again by recreating the file. You
    can refresh the web page so that the request is pending and, at the same time,
    execute the necessary command to create the `ready` file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Congratulations – you have successfully configured and tested the readiness
    probe for your Deployment Pods! This should give you a good insight into how the
    probes work and how you can use them with Services that expose your Deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will take a brief look at how you can scale your Deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling a Deployment object
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The beauty of Deployments is that you can almost instantly scale them up or
    down, depending on your needs. When the Deployment is exposed behind a Service,
    the new Pods will be automatically discovered as new endpoints when you scale
    up or automatically removed from the endpoints list when you scale down. The steps
    for this are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s scale up our Deployment declaratively. Open the `nginx-deployment-readinessprobe.yaml`
    manifest file and modify the number of replicas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply these changes to the cluster using the `kubectl apply` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, if you check the Pods using the `kubectl get pods` command, you will immediately
    see that new Pods are being created. Similarly, if you check the output of the
    `kubectl describe` command for the Deployment, you will see the following in the
    events:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can achieve the same result using the `imperative` command, which is only
    recommended for development scenarios:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'To scale down our Deployment declaratively, simply modify the `nginx-deployment-readinessprobe.yaml`
    manifest file and change the number of replicas:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the changes to the cluster using the `kubectl apply` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You can achieve the same result using imperative commands. For example, you
    can execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you describe the Deployment, you will see that this scaling down is reflected
    in the events:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: Deployment events are very useful if you want to know the exact timeline of
    scaling and the other operations that can be performed with the Deployment object.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to autoscale your deployments using `HorizontalPodAutoscaler`.
    This will be covered in *Chapter 20*, *Autoscaling Kubernetes Pods and Nodes*.
  prefs: []
  type: TYPE_NORMAL
- en: Next, you will learn how to delete a Deployment from your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting a Deployment object
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To delete a Deployment object, you can do two things:'
  prefs: []
  type: TYPE_NORMAL
- en: Delete the Deployment object along with the Pods that it owns. This can be done
    by first scaling down automatically.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delete the Deployment object and leave the other Pods unaffected.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To delete the Deployment object and its Pods, you can use the regular `kubectl
    delete` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: You will see that the Pods get terminated and that the Deployment object is
    then deleted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, if you would like to delete just the Deployment object, you need to use
    the `--cascade=orphan` option for `kubectl delete`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: After executing this command, if you inspect what Pods are in the cluster, you
    will still see all the Pods that were owned by the `nginx-deployment-example`
    Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: In the following section, we will explore how to manage different revisions
    and roll out using the Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: How Kubernetes Deployments seamlessly handle revisions and version rollouts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have only covered making one possible modification to a living Deployment
    – we have scaled up and down by changing the `replicas` parameter in the specification.
    However, this is not all we can do! It is possible to modify the Deployment’s
    Pod template (`.spec.template`) in the specification and, in this way, trigger
    a rollout. This rollout may be caused by a simple change, such as changing the
    labels of the Pods, but it may be also a more complex operation when the container
    images in the Pod definition are changed to a different version. This is the most
    common scenario as it enables you, as a Kubernetes cluster operator, to perform
    a controlled, predictable rollout of a new version of your image and effectively
    create a new revision of your Deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Your Deployment uses a rollout strategy, which can be specified in a YAML manifest
    using `.spec.strategy.type`. Kubernetes supports two strategies out of the box:'
  prefs: []
  type: TYPE_NORMAL
- en: '`RollingUpdate`: This is the default strategy and allows you to roll out a
    new version of your application in a controlled way. This type of strategy uses
    two ReplicaSets internally. When you perform a change in the Deployment spec that
    causes a rollout, Kubernetes will create a new ReplicaSet with a new Pod template
    scaled to zero Pods initially. The old, existing ReplicaSet will remain unchanged
    at this point. Next, the old ReplicaSet will be scaled down gradually, whereas
    the new ReplicaSet will be scaled up gradually at the same time. The number of
    Pods that may be unavailable (readiness probe failing) is controlled using the
    `.spec.strategy.rollingUpdate.maxUnavailable` parameter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The maximum number of extra Pods that can be scheduled above the desired number
    of Pods in the Deployment is controlled by the `.spec.strategy.rollingUpdate.maxSurge`
    parameter. Additionally, this type of strategy offers automatic revision history,
    which can be used for quick rollbacks in case of any failures.
  prefs: []
  type: TYPE_NORMAL
- en: '`Recreate`: This is a simple strategy that’s useful for development scenarios
    where all the old Pods have been terminated and replaced with new ones. This instantly
    deletes any existing underlying ReplicaSet and replaces it with a new one. You
    should not use this strategy for production workloads unless you have a specific
    use case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Consider the Deployment strategies as basic building blocks for more advanced
    Deployment scenarios. For example, if you are interested in blue/green Deployments,
    you can easily achieve this in Kubernetes by using a combination of Deployments
    and Services while manipulating label selectors. You can find out more about this
    in the official Kubernetes blog post: [https://kubernetes.io/blog/2018/04/30/zero-downtime-deployment-kubernetes-jenkins/](https://kubernetes.io/blog/2018/04/30/zero-downtime-deployment-kubernetes-jenkins/).'
  prefs: []
  type: TYPE_NORMAL
- en: Now, we will perform a rollout using the `RollingUpdate` strategy. The `Recreate`
    strategy, which is much simpler, can be exercised similarly.
  prefs: []
  type: TYPE_NORMAL
- en: Updating a Deployment object
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will explore the `RollingUpdate` strategy with a practical example in this
    section. First, let’s recreate the Deployment that we used previously for our
    readiness probe demonstration:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make a copy of the previous YAML manifest file:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Ensure that you have a strategy of the `RollingUpdate` type, called `readinessProbe`,
    set up and an image version of `nginx:1.17`. This should already be set up in
    the `nginx-deployment-readinessprobe.yaml` manifest file if you completed the
    previous sections:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In this example, we are using `maxUnavailable` set to `1`, which means that
    we allow only one Pod out of three, which is the target number, to be unavailable
    (not ready). This means that, at any time, there must be at least two Pods ready
    to serve traffic.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Similarly, setting `maxSurge` to `1` means that we allow one extra Pod to be
    created above the target number of three Pods during the rollout. This effectively
    means that we can have up to four Pods (ready or not) present in the cluster during
    the rollout. Please note that it is also possible to set up these parameters as
    percentage values (such as `25%`), which is very useful in autoscaling scenarios.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Additionally, `minReadySeconds` (which is set to `10`) provides an additional
    time span for which the Pod has to be ready before it can be *announced* as successful
    during the rollout.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Apply the manifest file to the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'With the Deployment ready in the cluster, we can start rolling out a new version
    of our application. We will change the image in the Pod template for our Deployment
    to a newer version and observe what happens during the rollout. To do this, follow
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the container image that was used in the Deployment to `nginx:1.18`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the changes to the cluster using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Immediately after that, use the `kubectl rollout status` command to see the
    progress in real time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The rollout will take a bit of time because we have configured `minReadySeconds`
    on the Deployment specification and `initialDelaySeconds` on the Pod container
    readiness probe.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Similarly, using the `kubectl describe` command, you can see the events for
    the Deployment that inform us of how the ReplicaSets were scaled up and down:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s take a look at the ReplicaSets in the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will see something interesting here: the old ReplicaSet remains in the
    cluster but has been scaled down to zero Pods! The reason for this is that we’re
    keeping the Deployment revision history – each revision has a matching ReplicaSet
    that can be used if we need to roll back. The number of revisions that are kept
    for each Deployment is controlled by the `.spec.revisionHistoryLimit` parameter
    – by default, it is set to `10`. Revision history is important, especially if
    you are making imperative changes to your Deployments. If you are using the declarative
    model and always committing your changes to a source code repository, then the
    revision history may be less relevant.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Lastly, we can check if the Pods were indeed updated to a new image version.
    Use the following command and verify one of the Pods in the output:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This shows that we have indeed performed a rollout of the new `nginx` container
    image version!
  prefs: []
  type: TYPE_NORMAL
- en: You can change the Deployment container image *imperatively* using the `kubectl
    set image deployment nginx-deployment-example nginx=nginx:1.18` command. This
    approach is only recommended for non-production scenarios, and it works well with
    *imperative* rollbacks.
  prefs: []
  type: TYPE_NORMAL
- en: Next, you will learn how to roll back a Deployment object.
  prefs: []
  type: TYPE_NORMAL
- en: Rolling back a Deployment object
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you are using a declarative model to introduce changes to your Kubernetes
    cluster and are committing each change to your source code repository, performing
    a rollback is very simple and involves just reverting the commit and applying
    the configuration again. Usually, the process of applying changes is performed
    as part of the CI/CD pipeline for the source code repository, instead of the changes
    being manually applied by an operator (such as an application team or administrators).
    This is the easiest way to manage Deployments, and this is generally recommended
    in the Infrastructure-as-Code and Configuration-as-Code paradigms.
  prefs: []
  type: TYPE_NORMAL
- en: A powerful example of using a declarative model in practice is **Flux** ([https://fluxcd.io/](https://fluxcd.io/)).
    While originally incubated by the **Cloud Native Computing Foundation** (**CNCF**),
    Flux has since graduated and become a full-fledged project within the CNCF landscape.
    Flux is the core of the GitOps approach, a methodology for implementing continuous
    deployment for cloud-native applications. It prioritizes a developer-centric experience
    by leveraging familiar tools like Git and continuous deployment pipelines, streamlining
    infrastructure management for developers.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, Kubernetes still provides an imperative way to roll back a Deployment
    using revision history. Imperative rollbacks can also be performed on Deployments
    that have been updated declaratively. Now, we will demonstrate how to use `kubectl`
    for rollbacks. Follow the next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s imperatively roll out another version of our Deployment. This
    time, we will update the `nginx` image to version `1.19`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Please note, `nginx=nginx:1.19` means we are setting the `nginx:1.19` image
    for the container called `nginx` in the `nginx-deployment-rollingupdate` Deployment.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Using `kubectl rollout status`, wait for the end of the Deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, let’s suppose that the new version of the application image, `1.19`, is
    causing problems and that your team decided to roll back to the previous version
    of the image, which was working fine.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Use the following `kubectl rollout history` command to see all the revisions
    that are available for the Deployment:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As you can see, we have three revisions. The first revision is our initial creation
    of the Deployment. The second revision is the declarative update of the Deployment
    to the `nginx:1.18` image. Finally, the third revision is our last imperative
    update to the Deployment that caused the `nginx:1.19` image to be rolled out.
    `CHANGE-CAUSE` is empty here because we haven’t used the `--record` flag, as the
    `--record` flag has been deprecated and will be removed in the future version.
    If you have a requirement to update `CHANGE-CAUSE`, you need to manually update
    the Deployment annotation, as we learned earlier in this chapter.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The revisions that were created as declarative changes do not contain too much
    information in `CHANGE-CAUSE`. To find out more about the second revision, you
    can use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s perform a rollback to this revision. Because it is the previous
    revision, you can simply execute the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This would be equivalent to executing a rollback to a specific revision number:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Again, as in the case of a normal rollout, you can use the following command
    to follow the rollback:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will notice that version 2 is missing, and a new version of the deployment
    has been created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Please note that you can also perform rollbacks on currently ongoing rollouts.
    This can be done in both ways; that is, declaratively and imperatively.
  prefs: []
  type: TYPE_NORMAL
- en: If you need to pause and resume the ongoing rollout of a Deployment, use the
    `kubectl rollout pause deployment nginx-deployment-example` and `kubectl rollout
    resume deployment nginx-deployment-example` commands.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations – you have successfully rolled back your Deployment. In the
    next section, we will provide you with a set of best practices for managing Deployment
    objects in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Canary deployment strategy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Canary deployments offer a valuable strategy for minimizing risk during application
    rollouts. They take inspiration from the practice of sending canaries (birds)
    into coal mines to detect dangerous gases. Similarly, canary deployments introduce
    a new version of an application to a limited subset of users before exposing it
    to the entire production environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'This controlled rollout allows for real-world testing of the new version while
    minimizing potential disruptions. Here’s how it works: imagine you’re deploying
    an update to your e-commerce website. Traditionally, the entire website would
    be switched to the new version simultaneously. With a canary deployment, however,
    it is possible to create two deployments: a stable deployment running the current
    version serving the majority of users, and a canary deployment with the new version
    serving a small percentage of users. Traffic routing mechanisms like ingress controllers
    or service annotations then direct a specific portion of traffic (e.g., 10%) to
    the canary deployment.'
  prefs: []
  type: TYPE_NORMAL
- en: By closely monitoring the canary Deployment’s performance through metrics like
    error rates, response times, and user feedback, you can assess the new version’s
    stability. If everything runs smoothly, you can gradually increase the percentage
    of traffic directed to the canary deployment until it serves all users. Conversely,
    if issues arise, you can easily roll back the canary deployment and maintain the
    stable version, preventing a wider impact on your user base.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this YAML example demonstrating a canary deployment for a frontend
    application: We have the stable app Deployment configuration with `image: frontend-app:1.0`
    as follows.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Now we have a canary deployment configuration for the same application with
    `image: frontend-app:2.0`, as follows.'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'And we need a Service to route the traffic to both versions of the Deployment.
    Please note, we only used `app: myapp` and `tier: frontend` labels as selectors
    so that the Service will use both `stable` and `Canary` Pods to serve the traffic:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: By adjusting the replicas in each Deployment, you control the percentage of
    users directed to each version.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, it is also possible to create different Service objects for stable
    and canary versions and use a mechanism like ingress controllers or service annotations
    to route a specific percentage of traffic (e.g., 10%) to the canary deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The important part is monitoring the canary deployment and ensuring the new
    version is working as per expectation. Based on the result, you can either promote
    the canary as the stable Deployment or delete the canary and update the new application
    image (e.g., `image: frontend-app:2.0`) in the stable Deployment.'
  prefs: []
  type: TYPE_NORMAL
- en: Refer to the documentation ([https://kubernetes.io/docs/concepts/workloads/management/#canary-deployments](https://kubernetes.io/docs/concepts/workloads/management/#canary-deployments))
    to learn more about canary deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s move on to the next section on the best practices of working with
    Deployment objects.
  prefs: []
  type: TYPE_NORMAL
- en: Deployment object best practices
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will summarize the best practices when working with Deployment
    objects in Kubernetes. This list is by no means complete, but it is a good starting
    point for your journey with Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Use declarative object management for Deployments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the DevOps and containerized application world, it is a good practice to
    stick to declarative models when introducing updates to your infrastructure and
    applications. This is at the core of the *Infrastructure-as-Code* and *Configuration-as-Code*
    paradigms. In Kubernetes, you can easily perform declarative updates using the
    `kubectl apply` command, which can be used on a single file or even a whole directory
    of YAML manifest files.
  prefs: []
  type: TYPE_NORMAL
- en: To delete objects, it is still better to use imperative commands. It is more
    predictable and less prone to errors. Declaratively deleting resources in your
    cluster is mostly useful in CI/CD and GitOps scenarios, where the whole process
    is entirely automated.
  prefs: []
  type: TYPE_NORMAL
- en: The same principle also applies to Deployment objects. Performing a rollout
    or rollback when your YAML manifest files are versioned and kept in a source control
    repository is easy and predictable. Using the `kubectl rollout undo` and `kubectl
    set image deployment` commands is generally not recommended in production environments.
    Using these commands gets much more complicated when more than one person is working
    on operations in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Do not use the Recreate strategy for production workloads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the `Recreate` strategy may be tempting as it provides instantaneous updates
    for your Deployments. However, at the same time, this will mean downtime for your
    end users. This is because all the existing Pods for the old revision of the Deployment
    will be terminated at once and replaced with the new Pods. There may be a significant
    delay before the new Pods become ready, and this means downtime. This downtime
    can be easily avoided by using the `RollingUpdate` strategy in production scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: The `Recreate` deployment strategy in Kubernetes is best suited for specific
    scenarios where downtime is acceptable and offers some advantages over other strategies.
    For example, when deploying significant application changes or introducing entirely
    new versions, the `Recreate` strategy allows for a clean slate and ensures the
    new version runs independently from the previous one.
  prefs: []
  type: TYPE_NORMAL
- en: Do not create Pods that match an existing Deployment label selector
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is possible to create Pods with labels that match the label selector of
    some existing Deployment. This can be done using bare Pods or another Deployment
    or ReplicaSet. This leads to conflicts, which Kubernetes does not prevent, and
    makes the existing deployment *believe* that it has created the other Pods. The
    results may be unpredictable and, in general, you need to pay attention to how
    you label the resources in your cluster. We advise you to use semantic labeling
    here, which you can learn more about in the official documentation: [https://kubernetes.io/docs/concepts/configuration/overview/#using-labels](https://kubernetes.io/docs/concepts/configuration/overview/#using-labels).'
  prefs: []
  type: TYPE_NORMAL
- en: Carefully set up your container probes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The liveness, readiness, and startup probes of your Pod containers can provide
    a lot of benefits but, at the same time, if they have been misconfigured, they
    can cause outages, including cascading failures. You should always be sure that
    you understand the consequences of each probe going into a failed state and how
    it affects other Kubernetes resources, such as Service objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few established best practices for readiness probes that you should
    consider:'
  prefs: []
  type: TYPE_NORMAL
- en: Use this probe whenever your containers may not be ready to serve traffic as
    soon as the container is started.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that you check things such as cache warm-ups or your database migration
    status during readiness probe evaluation. You may also consider starting the actual
    process of a warm-up if it has not been started yet, but use this approach with
    caution – a readiness probe will be executed constantly throughout the life cycle
    of a Pod, which means you shouldn’t perform any costly operations for every request.
    Alternatively, you may want to use a startup probe for this purpose.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For microservice applications that expose HTTP endpoints, consider configuring
    the `httpGet` readiness probe. This will ensure that every basis is covered when
    a container is successfully running but the HTTP server has not been fully initialized.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is a good idea to use a separate, dedicated HTTP endpoint for readiness checks
    in your application. For example, a common convention is using `/health`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are checking the state of your dependencies (external database, logging
    services, etc.) in this type of probe, be careful with shared dependencies, such
    as databases. In this case, you should consider using a probe timeout, which is
    greater than the maximum allowed timeout for the external dependency – otherwise,
    you may get cascading failures and lower availability instead of occasionally
    increased latency.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Similar to readiness probes, there are a few guidelines on how and when you
    should use liveness probes:'
  prefs: []
  type: TYPE_NORMAL
- en: Liveness probes should be used with caution. Incorrectly configuring these probes
    can result in cascading failures in your services and container restart loops.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not use liveness probes unless you have a good reason to do so. A good reason
    may be, for example, if there’s a known issue with a deadlock in your application
    that has an unknown root cause.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Execute simple and fast checks that determine the status of the process, not
    its dependencies. In other words, you do not want to check the status of your
    external dependencies in the liveness probe, since this can lead to cascading
    failures due to an avalanche of container restarts and overloading a small subset
    of Service Pods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the process running in your container can crash or exit whenever it encounters
    an unrecoverable error, you probably do not need a liveness probe at all.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use conservative settings for `initialDelaySeconds` to avoid any premature container
    restarts and falling into a restart loop.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are the most important points concerning probes for Pods. Now, let’s discuss
    how you should tag your container images.
  prefs: []
  type: TYPE_NORMAL
- en: Use meaningful and semantic image tags
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Managing Deployment rollbacks and inspecting the history of rollouts requires
    that we use good tagging for the container images. If you rely on the `latest`
    tag, performing a rollback will not be possible because this tag points to a different
    version of the image as time goes on. It is a good practice to use semantic versioning
    for your container images. Additionally, you may consider tagging the images with
    a source code hash, such as a Git commit hash, to ensure that you can easily track
    what is running in your Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Migrate from older versions of Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you are working on workloads that were developed on older versions of Kubernetes,
    you may notice that, starting with Kubernetes 1.16, you can’t apply the Deployment
    to the cluster because of the following error:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: 'The reason for this is that in version 1.16, the Deployment object was removed
    from the `extensions/v1beta1` API group, according to the API versioning policy.
    You should use the `apps/v1` API group instead, which Deployment has been part
    of since 1.9\. This also shows an important rule to follow when you work with
    Kubernetes: always follow the API versioning policy and try to upgrade your resources
    to the latest API groups when you migrate to a new version of Kubernetes. This
    will save you unpleasant surprises when the resource is eventually deprecated
    in older API groups.'
  prefs: []
  type: TYPE_NORMAL
- en: Include resource management in the Deployment
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Define resource requests (minimum guaranteed resources) and limits (maximum
    allowed resources) for containers within your Deployment. This helps the Kubernetes
    scheduler allocate resources efficiently and prevent resource starvation. Also,
    don’t overestimate or underestimate resource needs. Analyze application behavior
    to determine appropriate resource requests and limits to avoid under-utilization
    or performance bottlenecks.
  prefs: []
  type: TYPE_NORMAL
- en: Scaling and replica management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use **HorizontalPodAutoscaler** (**HPA**) to automatically scale your Deployment
    replicas up or down based on predefined metrics like CPU or memory usage.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image illustrates how HPA handles the desired count of replicas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22019_11_05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.5: HPA handling the Deployment based on metrics information'
  prefs: []
  type: TYPE_NORMAL
- en: Also, it is a best practice to set the initial replica count (number of Pod
    instances) for your Deployment considering factors like expected workload and
    resource availability.
  prefs: []
  type: TYPE_NORMAL
- en: Security considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Implement Deployment policies that will not allow running containers with unnecessary
    privileges (e.g., root user). This reduces the attack surface and potential security
    vulnerabilities. Also, remember to store sensitive information like passwords
    or configuration details in Secrets and ConfigMaps instead of embedding them directly
    in Deployments. Refer to *Chapter 18*, *Security in Kubernetes*, to explore different
    security aspects of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to work with **stateless** workloads and applications
    on Kubernetes using Deployment objects. First, you created an example Deployment
    and exposed its Pods using a Service object of the `LoadBalancer` type for external
    traffic. Next, you learned how to scale and manage Deployment objects in the cluster.
    The management operations we covered included rolling out a new revision of a
    Deployment and rolling back to an earlier revision in case of a failure. Lastly,
    we equipped you with a set of known best practices when working with Deployment
    objects.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next chapter will extend this knowledge with details about managing **stateful**
    workloads and applications. While doing so, we will introduce a new Kubernetes
    object: StatefulSet.'
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes Deployments: [https://kubernetes.io/docs/concepts/workloads/controllers/deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'StatefulSets: [https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Canary deployments: [https://kubernetes.io/docs/concepts/workloads/management/#canary-deployments](https://kubernetes.io/docs/concepts/workloads/management/#canary-deployments
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code119001106479081656.png)'
  prefs: []
  type: TYPE_IMG
