- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Using Kubernetes Deployments for Stateless Workloads
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 部署无状态工作负载
- en: 'The previous chapter introduced two important Kubernetes objects: **ReplicationController**
    and **ReplicaSet**. At this point, you already know that they serve similar purposes
    in terms of maintaining identical, healthy replicas (copies) of Pods. In fact,
    ReplicaSet is a successor of ReplicationController and, in the most recent versions
    of Kubernetes, ReplicaSet should be used in favor of ReplicationController.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 前一章介绍了两个重要的 Kubernetes 对象：**ReplicationController** 和 **ReplicaSet**。到此为止，你已经知道它们在保持
    Pod 的相同健康副本（拷贝）方面起着类似的作用。实际上，ReplicaSet 是 ReplicationController 的继任者，在 Kubernetes
    的最新版本中，应该使用 ReplicaSet 来代替 ReplicationController。
- en: Now, it is time to introduce the **Deployment** object, which provides easy
    scalability, rolling updates, and versioned rollbacks for your stateless Kubernetes
    applications and services. Deployment objects are built on top of ReplicaSets
    and they provide a declarative way of managing them – just describe the desired
    state in the Deployment manifest and Kubernetes will take care of orchestrating
    the underlying ReplicaSets in a controlled, predictable manner. Alongside StatefulSet,
    which will be covered in the next chapter, it is the most important workload management
    object in Kubernetes. This will be the bread and butter of your development and
    operations on Kubernetes! The goal of this chapter is to make sure that you have
    all the tools and knowledge you need to deploy your stateless application components
    using Deployment objects, as well as to safely release new versions of your components
    using rolling updates of Deployments.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候介绍 **Deployment** 对象了，它为你的无状态 Kubernetes 应用程序和服务提供了轻松的可扩展性、滚动更新和版本回滚。部署对象建立在
    ReplicaSets 之上，并且提供了一种声明式的管理方式——只需在部署清单中描述所需的状态，Kubernetes 将负责以受控、可预测的方式协调底层的
    ReplicaSets。与 StatefulSet 一起，它是 Kubernetes 中最重要的工作负载管理对象，本章将涵盖 StatefulSet。Deployment
    将是你在 Kubernetes 上开发和运维的核心！本章的目标是确保你掌握所有工具和知识，使用 Deployment 对象部署无状态应用组件，并通过 Deployment
    的滚动更新安全地发布新版本的组件。
- en: 'This chapter will cover the following topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下内容：
- en: Introducing the Deployment object
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍部署对象
- en: How Kubernetes Deployments seamlessly handle revisions and version rollouts
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 部署如何无缝处理修订和版本发布
- en: Deployment object best practices
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署对象的最佳实践
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'For this chapter, you will need the following:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要以下内容：
- en: A Kubernetes cluster that has been deployed. You can use either a local or cloud-based
    cluster, but to fully understand the concepts shown in this chapter, we recommend
    using a multi-node, cloud-based Kubernetes cluster if available.
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个已部署的 Kubernetes 集群。你可以使用本地集群或云集群，但为了更好地理解本章展示的概念，如果有条件，建议使用多节点的云基础 Kubernetes
    集群。
- en: The Kubernetes CLI (`kubectl`) must be installed on your local machine and configured
    to manage your Kubernetes cluster.
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 必须在本地计算机上安装 Kubernetes 命令行工具（`kubectl`），并将其配置为管理你的 Kubernetes 集群。
- en: Kubernetes cluster deployment (local and cloud-based) and `kubectl` installation
    were covered in *Chapter 3*, *Installing Your First Kubernetes Cluster*.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群的部署（本地和云端）以及 `kubectl` 安装已在 *第 3 章*，*安装你的第一个 Kubernetes 集群* 中涵盖。
- en: 'You can download the latest code samples for this chapter from the official
    GitHub repository: [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter11](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter11).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从官方 GitHub 仓库下载本章的最新代码示例：[https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter11](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter11)。
- en: Introducing the Deployment object
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍部署对象
- en: Kubernetes gives you out-of-the-box flexibility when it comes to running different
    types of workloads, depending on your use cases. By knowing which workload type
    fits your application needs, you can make more informed decisions, optimize resource
    usage, and ensure better performance and reliability in your cloud-based applications.
    This foundational knowledge helps you unlock the full potential of Kubernetes’
    flexibility, allowing you to deploy and scale applications with confidence. Let’s
    have a brief look at the supported workloads to understand where the Deployment
    object fits, as well as its purpose.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes在运行不同类型的工作负载方面为您提供了开箱即用的灵活性，具体取决于您的使用案例。通过了解哪种工作负载类型适合您的应用需求，您可以做出更明智的决策，优化资源使用，并确保在云端应用程序中获得更好的性能和可靠性。这一基础知识帮助您充分发挥Kubernetes的灵活性，使您能够自信地部署和扩展应用程序。让我们简要看看支持的工作负载类型，以了解Deployment对象的适用场景及其目的。
- en: The following diagram demonstrates the different types of application workloads
    in Kubernetes, which we will explain in the following sections.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了Kubernetes中不同类型的应用程序工作负载，我们将在接下来的章节中进行解释。
- en: '![](img/B22019_11_01.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_11_01.png)'
- en: 'Figure 11.1: Application workload types in Kubernetes'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.1：Kubernetes中的应用程序工作负载类型
- en: 'When implementing cloud-based applications, you will generally need the following
    types of workloads:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在实施基于云的应用程序时，您通常需要以下类型的工作负载：
- en: '**Stateless**: In the world of containers, stateless applications are those
    that don’t hold onto data (state) within the container itself. Imagine two Nginx
    containers serving the same purpose: one stores user data in a file inside the
    container, while the other uses a separate container like MongoDB for data persistence.
    Although they both achieve the same goal, the first Nginx container becomes stateful
    because it relies on internal storage. The second Nginx container, utilizing an
    external database, remains stateless. This stateless approach makes applications
    simpler to manage and scale in Kubernetes, as they can be easily restarted or
    replaced without worrying about data loss. Typically, Deployment objects in Kubernetes
    are used to manage these stateless workloads.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无状态**：在容器的世界里，无状态应用程序是指那些不在容器内部保存数据（状态）的应用程序。设想两个Nginx容器执行相同的任务：一个将用户数据存储在容器内的文件中，而另一个使用像MongoDB这样的独立容器进行数据持久化。尽管它们实现了相同的目标，第一个Nginx容器因为依赖内部存储而变成了有状态。第二个Nginx容器则使用外部数据库，保持无状态。这种无状态的方式使得在Kubernetes中管理和扩展应用程序更加简单，因为它们可以轻松重启或替换，而无需担心数据丢失。在Kubernetes中，通常使用Deployment对象来管理这些无状态工作负载。'
- en: '**Stateful**: In the case of containers and Pods, we call them stateful if
    they store any modifiable data inside themselves. A good example of such a Pod
    is a MySQL or MongoDB Pod that reads and writes the data to a PersistentVolume.
    Stateful workloads are much harder to manage – you need to carefully manage sticky
    sessions or data partitions during rollouts, rollbacks, and when scaling. As a
    rule of thumb, try to keep stateful workloads outside your Kubernetes cluster
    if possible, such as by using cloud-based **Software-as-a-Service** (**SaaS**)
    database offerings. In Kubernetes, StatefulSet objects are used to manage stateful
    workloads. *Chapter 12*, *StatefulSet – Deploying Stateful Applications*, provides
    more details about these types of objects.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**有状态**：在容器和Pod的情况下，如果它们内部存储任何可修改的数据，我们称之为有状态。一个典型的有状态Pod示例是MySQL或MongoDB Pod，它将数据读写到持久化存储卷（PersistentVolume）。有状态工作负载的管理难度较大——在发布、回滚和扩展时，您需要仔细管理粘性会话或数据分区。一般来说，如果可能的话，尽量将有状态工作负载保持在Kubernetes集群之外，例如使用基于云的**软件即服务**（**SaaS**）数据库服务。在Kubernetes中，StatefulSet对象用于管理有状态工作负载。*第12章*，*StatefulSet
    – 部署有状态应用程序*，提供了有关这些对象的更多详细信息。'
- en: '**Job or CronJob**: This type of workload performs job or task processing,
    either scheduled or on demand. Depending on the type of application, batch workloads
    may require thousands of containers and a lot of nodes – this can be anything
    that happens *in the background*. Containers that are used for batch processing
    should also be stateless to make it easier to resume interrupted jobs. In Kubernetes,
    Job and CronJob objects are used to manage batch workloads. *Chapter 4*, *Running
    Your Containers in Kubernetes*, provides more details about these types of objects.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Job或CronJob**：这种类型的工作负载执行作业或任务处理，可以是定时任务或按需执行。根据应用程序的类型，批处理工作负载可能需要成千上万个容器和大量节点——这可以是任何发生在*后台*的事情。用于批处理的容器也应该是无状态的，以便更容易恢复中断的作业。在Kubernetes中，Job和CronJob对象用于管理批处理工作负载。*第4章*，*在Kubernetes中运行容器*，提供了有关这些类型对象的更多详细信息。'
- en: '**DaemonSet**: There are cases where we want to run workloads on every Kubernetes
    node to support the Kubernetes functionality. It can be a monitoring application,
    logging application, storage management agent (for PersistentVolumes), etc. For
    such workloads, we can use a special deployment type called a DaemonSet, which
    will guarantee that a copy of the workload will be running on every node in the
    cluster. *Chapter 13*, *DaemonSet – Maintaining Pod Singletons on Nodes*, provides
    more details about these types of objects.'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**DaemonSet**：在某些情况下，我们希望在每个Kubernetes节点上运行工作负载，以支持Kubernetes的功能。这可以是监控应用程序、日志应用程序、存储管理代理（用于PersistentVolumes）等。对于这些工作负载，我们可以使用一种特殊的部署类型，称为DaemonSet，它保证在集群中的每个节点上都运行该工作负载的一个副本。*第13章*，*DaemonSet
    - 在节点上维护Pod单例*，提供了有关这些类型对象的更多详细信息。'
- en: With this concept regarding the different types of workloads in Kubernetes,
    we can dive deeper into managing stateless workloads using Deployment objects.
    In short, they provide declarative and controlled updates for Pods and ReplicaSets.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 通过了解Kubernetes中不同类型工作负载的概念，我们可以更深入地探讨如何使用Deployment对象管理无状态工作负载。简而言之，它们为Pods和ReplicaSets提供声明式和可控的更新。
- en: 'You can declaratively perform operations such as the following by using Deployment
    objects:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过使用Deployment对象声明性地执行以下操作：
- en: '**Rollout of a New ReplicaSet**: Deployments excel at managing controlled rollouts.
    You can define a new ReplicaSet with the desired Pod template within a Deployment
    object. Kubernetes then orchestrates a gradual rollout by scaling up the new ReplicaSet
    while scaling down the old one, minimizing downtime and ensuring a smooth transition.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**新ReplicaSet的发布**：部署擅长管理受控发布。你可以在Deployment对象中定义一个具有所需Pod模板的新ReplicaSet。Kubernetes随后通过逐步扩展新的ReplicaSet并缩减旧的ReplicaSet来进行发布，最小化停机时间，确保平稳过渡。'
- en: '**Controlled Rollout with Pod Template Change**: Deployments allow you to update
    the Pod template within the Deployment definition. When you deploy the updated
    Deployment, Kubernetes performs a rolling update, scaling up the new ReplicaSet
    with the modified template and scaling down the old one. This enables you to introduce
    changes to your application’s Pods in a controlled manner.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**通过Pod模板变更进行受控发布**：部署允许你在Deployment定义中更新Pod模板。当你部署更新后的Deployment时，Kubernetes会执行滚动更新，使用修改后的模板扩展新的ReplicaSet，同时缩减旧的ReplicaSet。这使你能够以受控的方式对应用程序的Pods进行变更。'
- en: '**Rollback to a Previous Version**: Deployments keep track of their revision
    history. If you encounter any issues with the new version, you can easily roll
    back to a previous stable Deployment version. This allows you to revert changes
    quickly and minimize disruption.'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**回滚到之前的版本**：部署会跟踪其修订历史。如果你在新版本中遇到任何问题，可以轻松回滚到先前的稳定部署版本。这使你能够快速恢复更改，最小化中断。'
- en: '**Scaling ReplicaSets**: Scaling a Deployment directly scales the associated
    ReplicaSet. You can specify the desired number of replicas for the Deployment,
    and Kubernetes automatically scales the underlying ReplicaSet to meet that requirement.'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩展ReplicaSets**：直接扩展Deployment将会扩展相关的ReplicaSet。你可以指定Deployment所需的副本数量，Kubernetes会自动扩展底层的ReplicaSet以满足该需求。'
- en: '**Pausing and Resuming Rollouts**: Deployments offer the ability to pause the
    rollout of a new ReplicaSet if you need to address any issues or perform additional
    configuration. Similarly, you can resume the rollout once the issue is resolved.
    This provides flexibility during the deployment process.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**暂停和恢复发布**：部署提供了暂停新ReplicaSet发布的功能，如果你需要解决任何问题或进行额外配置，可以暂停发布。同样，问题解决后，可以恢复发布。这为部署过程提供了灵活性。'
- en: In this way, Deployment objects provide an end-to-end pipeline for managing
    your stateless components running in Kubernetes clusters. Usually, you will combine
    them with Service objects, as presented in *Chapter 8*, *Exposing Your Pods with
    Services*, to achieve high fault tolerance, health monitoring, and intelligent
    load balancing for traffic coming into your application.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，Deployment 对象提供了一个端到端的管道，用于管理运行在 Kubernetes 集群中的无状态组件。通常，你会将它们与 Service
    对象结合使用，正如 *第 8 章* 中所展示的 *通过服务暴露你的 Pods*，以实现高容错性、健康监控和智能负载均衡，从而处理进入应用的流量。
- en: Now, let’s have a closer look at the anatomy of the Deployment object specification
    and how to create a simple example deployment in our Kubernetes cluster.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们更仔细地看看 Deployment 对象规范的结构，以及如何在我们的 Kubernetes 集群中创建一个简单的示例 Deployment。
- en: Creating a Deployment object
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建一个 Deployment 对象
- en: 'Do not worry about the Deployment skeleton as you can use any supported tools
    for creating the Deployment YAMLs. It is possible to create a Deployment skeleton
    with `kubectl create deployment` commands as follows, which will basically display
    the YAML with the values:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 不用担心 Deployment 骨架，因为你可以使用任何支持的工具来创建 Deployment YAML。你可以通过以下 `kubectl create
    deployment` 命令来创建 Deployment 骨架，该命令基本上会显示包含这些值的 YAML：
- en: '[PRE0]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can redirect the output to a file and use it as the base for your deployment
    configurations:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将输出重定向到一个文件，并将其用作你的部署配置的基础：
- en: '[PRE1]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'First, let’s take a look at the structure of an example Deployment YAML manifest
    file, `nginx-deployment.yaml`, that maintains three replicas of an `nginx` Pod:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们看一下一个示例 Deployment YAML 清单文件 `nginx-deployment.yaml` 的结构，它保持三个 `nginx`
    Pod 副本：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'As you can see, the structure of the Deployment spec is almost identical to
    ReplicaSet, although it has a few extra parameters for configuring the strategy
    for rolling out new versions. The preceding YAML specification has four main components:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，Deployment 规范的结构与 ReplicaSet 几乎相同，尽管它有一些额外的参数来配置发布新版本的策略。上述的 YAML 规范有四个主要组件：
- en: '`replicas`: Defines the number of Pod replicas that should run using the given
    `template` and matching label `selector`. Pods may be created or deleted to maintain
    the required number. This property is used by the underlying ReplicaSet.'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`replicas`：定义应该使用给定的 `template` 和匹配的标签 `selector` 运行的 Pod 副本数量。Pods 可以被创建或删除，以保持所需的数量。此属性由底层的
    ReplicaSet 使用。'
- en: '`selector`: A label selector, which defines how to identify Pods that the underlying
    ReplicaSet owns. This can include set-based and equality-based selectors. In the
    case of Deployments, the underlying ReplicaSet will also use a generated `pod-template-hash`
    label to ensure that there are no conflicts between different child ReplicaSets
    when you’re rolling out a new version. Additionally, this generally prevents accidental
    acquisitions of bare Pods, which could easily happen with simple ReplicaSets.
    Nevertheless, Kubernetes does not prevent you from defining overlapping Pod selectors
    between different Deployments or even other types of controllers. However, if
    this happens, they may conflict and behave unexpectedly.'
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`selector`：标签选择器，用于定义如何识别底层 ReplicaSet 所拥有的 Pods。可以包括基于集合的选择器和基于相等性的选择器。在 Deployments
    的情况下，底层的 ReplicaSet 还会使用生成的 `pod-template-hash` 标签来确保在滚动发布新版本时，不同子 ReplicaSets
    之间没有冲突。此外，这通常可以防止无意间获取裸 Pods，这在简单的 ReplicaSets 中很容易发生。然而，Kubernetes 不会阻止你在不同的
    Deployments 或甚至其他类型的控制器之间定义重叠的 Pod 选择器。但如果发生这种情况，它们可能会发生冲突并表现出异常行为。'
- en: '`template`: Defines the template for Pod creation. Labels used in `metadata`
    must match our `selector`.'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`template`：定义 Pod 创建的模板。`metadata` 中使用的标签必须与我们的 `selector` 匹配。'
- en: '`strategy`: Defines the details of the strategy that will be used to replace
    existing Pods with new ones. You will learn more about such strategies in the
    following sections. In this example, we showed the default `RollingUpdate` strategy.
    In short, this strategy works by slowly replacing the Pods of the previous version,
    one by one, by using the Pods of the new version. This ensures zero downtime and,
    together with Service objects and readiness probes, provides traffic load balancing
    to Pods that can serve the incoming traffic.'
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`strategy`：定义用于用新 Pods 替换现有 Pods 的策略细节。你将在接下来的章节中了解更多关于此类策略的内容。在这个例子中，我们展示了默认的
    `RollingUpdate` 策略。简而言之，这个策略通过慢慢地用新版本的 Pods 替换旧版本的 Pods，从而确保零停机时间，并与 Service 对象和就绪探针一起，为能够处理传入流量的
    Pods 提供流量负载均衡。'
- en: 'The Deployment spec provides a high degree of reconfigurability to suit your
    needs. We recommend referring to the official documentation for all the details:
    https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.31/#deployment-v1-apps
    (refer to the appropriate version of your Kubernetes cluster, e.g., v1.31)'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment 规格提供了高度的可重配置性，以满足您的需求。我们建议参考官方文档以获取所有详细信息：[Kubernetes 官方文档](https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.31/#deployment-v1-apps)（请根据您的
    Kubernetes 集群版本选择合适的版本，例如 v1.31）。
- en: 'To better understand the relationship of Deployment, its underlying child ReplicaSet,
    and Pods, look at the following diagram:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地理解 Deployment、其底层的子 ReplicaSet 以及 Pods 之间的关系，请查看以下图表：
- en: '![Figure 11.1 – Kubernetes Deployment'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.1 – Kubernetes Deployment'
- en: '](img/B22019_11_02.png)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B22019_11_02.png)'
- en: 'Figure 11.2: Kubernetes Deployment'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2：Kubernetes Deployment
- en: 'Once you have defined and created a Deployment, it is not possible to change
    its `selector`. This is desired because, otherwise, you could easily end up with
    orphaned ReplicaSets. There are two important actions that you can perform on
    existing Deployment objects:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦定义并创建了 Deployment，就无法更改其 `selector`。这是因为如果可以更改 `selector`，您很容易会遇到孤立的 ReplicaSets。您可以对现有
    Deployment 对象执行两种重要操作：
- en: '**Modify template**: Usually, you would like to change the Pod definition to
    a new image version of your application. This will cause a rollout to begin, according
    to the rollout `strategy`.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修改模板**：通常，您可能希望将 Pod 定义更改为应用程序的新镜像版本。这将根据发布 `策略` 开始进行发布。'
- en: '**Modify replica number**: Just changing the number will cause ReplicaSet to
    gracefully scale up or down.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**修改副本数**：仅更改副本数将导致 ReplicaSet 平稳地进行扩展或缩减。'
- en: 'Now, let’s declaratively apply our example Deployment YAML manifest file, `nginx-deployment.yaml`,
    to the cluster using the `kubectl apply` command:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们声明性地应用我们的示例 Deployment YAML 清单文件 `nginx-deployment.yaml` 到集群中，使用 `kubectl
    apply` 命令：
- en: '[PRE3]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Using the `--record` flag is useful for tracking the changes that are made to
    the objects, as well as to inspect which commands caused these changes. You will
    then see an additional automatic annotation, `kubernetes.io/change-cause`, which
    contains information about the command. But the `--record` flag has been deprecated,
    and will be removed in the future. So, if you have a dependency on this annotation,
    it is a best practice to include the annotation manually as part of the Deployment
    update.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `--record` 标志对于跟踪对对象所做的更改非常有用，还可以检查哪些命令导致了这些更改。然后，您将看到一个额外的自动注释 `kubernetes.io/change-cause`，该注释包含有关命令的信息。但是，`--record`
    标志已被弃用，并将在未来移除。因此，如果您依赖该注释，最佳实践是手动将该注释作为 Deployment 更新的一部分进行添加。
- en: 'If you wish, add an annotation to the Deployment manually using the `kubectl
    annotate` command, as follows:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，可以使用 `kubectl annotate` 命令手动向 Deployment 添加注释，如下所示：
- en: '[PRE4]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Immediately after the Deployment object has been created, use the `kubectl
    rollout` command to track the status of your Deployment in real time:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Deployment 对象创建之后，立即使用 `kubectl rollout` 命令来实时跟踪 Deployment 的状态：
- en: '[PRE5]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This is a useful command that can give us a lot of insight into what is happening
    with an ongoing Deployment rollout. You can also use the usual `kubectl get` or
    `kubectl describe` commands:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个有用的命令，可以帮助我们深入了解正在进行的 Deployment 发布的情况。您还可以使用常见的 `kubectl get` 或 `kubectl
    describe` 命令：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: As you can see, the Deployment has been successfully created and all three Pods
    are now in the ready state.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，Deployment 已成功创建，所有三个 Pods 当前处于就绪状态。
- en: Instead of typing `deployment`, you can use the `deploy` abbreviation when using
    `kubectl` commands.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在输入 `deployment` 时，您可以使用 `deploy` 缩写来代替，在使用 `kubectl` 命令时。
- en: 'You may also be interested in seeing the underlying ReplicaSets:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还会对查看底层的 ReplicaSets 感兴趣：
- en: '[PRE7]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Please take note of the generated hash, `5b8dc6b8cd`, in the name of our ReplicaSet,
    which is also the value of the `pod-template-hash` label, which we mentioned earlier.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们的 ReplicaSet 名称中生成的哈希值 `5b8dc6b8cd`，这也是 `pod-template-hash` 标签的值，如前所述。
- en: 'Lastly, you can see the Pods in the cluster that were created by the Deployment
    object using the following command:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，您可以使用以下命令查看由 Deployment 对象创建的集群中的 Pods：
- en: '[PRE8]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Congratulations – you have created and inspected your first Kubernetes Deployment!
    Next, we will take a look at how Service objects are used to expose your Deployment
    to external traffic coming into the cluster.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜—您已经创建并检查了第一个 Kubernetes Deployment！接下来，我们将看看如何使用 Service 对象将 Deployment 暴露给集群外部的流量。
- en: Exposing Deployment Pods using Service objects
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Service 对象暴露 Deployment Pods
- en: Service objects were covered in detail in *Chapter 8*, *Exposing Your Pods with
    Services*, so, in this section, we will provide a brief recap about the role of
    Services and how they are usually used with Deployments.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: Service 对象已在*第 8 章*，*通过服务暴露你的 Pods* 中详细介绍，因此在本节中，我们将简要回顾 Service 的作用以及它们通常如何与
    Deployments 一起使用。
- en: The following diagram can be used as a base reference for the different networks
    in a Kubernetes cluster.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示可作为 Kubernetes 集群中不同网络的基础参考。
- en: '![](img/B22019_11_03.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_11_03.png)'
- en: 'Figure 11.3: Different networks in Kubernetes'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3：Kubernetes 中的不同网络
- en: Services are Kubernetes objects that allow you to expose your Pods, either to
    other Pods in the cluster or to end users. They are the crucial building blocks
    for highly available and fault-tolerant Kubernetes applications since they provide
    a load balancing layer that actively routes incoming traffic to ready and healthy
    Pods.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 服务是 Kubernetes 对象，允许你将 Pods 暴露给集群中的其他 Pods 或终端用户。它们是高可用和容错的 Kubernetes 应用程序的关键构建块，因为它们提供了一个负载均衡层，主动将传入流量路由到就绪和健康的
    Pods。
- en: 'Deployment objects, on the other hand, provide Pod replication, automatic restarts
    when failures occur, easy scaling, controlled version rollouts, and rollbacks.
    But there is a catch: Pods that are created by ReplicaSets or Deployments have
    a finite life cycle. At some point, you can expect them to be terminated; then,
    new Pod replicas with new IP addresses will be created in their place. So, what
    if you have a Deployment running web server Pods that need to communicate with
    Pods that have been created as a part of another Deployment such as backend Pods?
    Web server Pods cannot assume anything about the IP addresses or the DNS names
    of backend Pods, as they may change over time. This issue can be resolved with
    Service objects, which provide reliable networking for a set of Pods.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Deployment 对象提供 Pod 复制、故障发生时的自动重启、轻松扩展、受控版本发布和回滚。但有一个问题：由 ReplicaSets 或
    Deployments 创建的 Pods 有一个有限的生命周期。到某个时刻，你可以预计它们会被终止；然后，将在它们的位置创建具有新 IP 地址的新 Pod
    副本。那么，如果你有一个运行 Web 服务器 Pods 的 Deployment，并且这些 Pods 需要与作为另一个 Deployment 一部分创建的
    Pods（例如后端 Pods）进行通信怎么办？Web 服务器 Pods 不能假设后端 Pods 的 IP 地址或 DNS 名称，因为它们可能会随着时间的推移而变化。这个问题可以通过
    Service 对象来解决，后者为一组 Pods 提供可靠的网络连接。
- en: In short, Services target a set of Pods, and this is determined by label selectors.
    These label selectors work on the same principle that you have learned about for
    ReplicaSets and Deployments. The most common scenario is exposing a Service for
    an existing Deployment by using the same label selector.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，服务针对一组 Pods，这由标签选择器决定。这些标签选择器的工作原理与您在 ReplicaSets 和 Deployments 中学到的相同。最常见的场景是通过使用相同的标签选择器为现有的
    Deployment 暴露一个 Service。
- en: The Service is responsible for providing a reliable DNS name and IP address,
    as well as for monitoring selector results and updating the associated endpoint
    object with the current IP addresses of the matching Pods. For internal cluster
    communication, this is usually achieved using simple `ClusterIP` Services, whereas
    to expose them to external traffic, you can use the `NodePort` Service or, more
    commonly in cloud deployments, the `LoadBalancer` Service.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: Service 负责提供可靠的 DNS 名称和 IP 地址，并监控选择器的结果，更新与之关联的端点对象，包含匹配 Pods 的当前 IP 地址。对于集群内部的通信，通常使用简单的
    `ClusterIP` 服务，而要将其暴露给外部流量，你可以使用 `NodePort` 服务，或者在云部署中更常见的是使用 `LoadBalancer` 服务。
- en: 'To visualize how Service objects interact with Deployment objects in Kubernetes,
    look at the following diagram:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 要可视化 Service 对象与 Kubernetes 中的 Deployment 对象如何交互，请查看以下图示：
- en: '![Figure 11.2 – Client Pod performing requests to the Kubernetes Deployment,
    exposed by the ClusterIP Service'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.2 – 客户端 Pod 执行请求到通过 ClusterIP 服务暴露的 Kubernetes 部署'
- en: '](img/B22019_11_04.png)'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B22019_11_04.png)'
- en: 'Figure 11.4: Client Pod performing requests to the Kubernetes Deployment, exposed
    by the ClusterIP Service'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4：客户端 Pod 执行请求到通过 ClusterIP 服务暴露的 Kubernetes 部署
- en: This diagram visualizes how any client Pod in the cluster can transparently
    communicate with the `nginx` Pods that are created by our Deployment object and
    exposed using the `ClusterIP` Service. ClusterIPs are essentially virtual IP addresses
    that are managed by the `kube-proxy` service that is running on each Node. `kube-proxy`
    is responsible for all the clever routing logic in the cluster and ensures that
    the routing is entirely transparent to the client Pods – they do not need to know
    if they are communicating with the same Node, a different Node, or even an external
    component. In the backend, `kube-proxy` watches the updates in the Service object
    and maintains all necessary routing rules required on each Node to ensure the
    proper traffic. `kube-proxy` generally uses `iptables` or **IP Virtual Server**
    (**IPVS**) to manage the traffic routing.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 此图示展示了集群中任何客户端 Pod 如何透明地与通过我们的 Deployment 对象创建并通过 `ClusterIP` 服务暴露的 `nginx`
    Pods 进行通信。ClusterIP 本质上是由每个节点上运行的 `kube-proxy` 服务管理的虚拟 IP 地址。`kube-proxy` 负责集群中的所有巧妙路由逻辑，确保路由对客户端
    Pods 完全透明——它们无需知道自己是在与同一节点、不同节点，甚至是外部组件进行通信。在后台，`kube-proxy` 监视服务对象的更新，并维护每个节点上所需的所有路由规则，以确保正确的流量。`kube-proxy`
    通常使用 `iptables` 或 **IP 虚拟服务器** (**IPVS**) 来管理流量路由。
- en: The role of the Service object is to define a set of ready Pods that should
    be *hidden* behind a stable ClusterIP. Usually, the internal clients will not
    be calling the Service pods using the ClusterIP, but they will use a DNS short
    name, which is the same as the Service name – for example, `nginx-service-example`.
    This will be resolved to the ClusterIP by the cluster’s internal DNS service.
    Alternatively, they may use a DNS **Fully Qualified Domain Name** (**FQDN**) in
    the form of `<serviceName>.<namespaceName>.svc.<clusterDomain>`; for example,
    `nginx-service-example.default.svc.cluster.local`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 服务对象的作用是定义一组应当被 *隐藏* 在稳定 ClusterIP 后的准备就绪的 Pods。通常，内部客户端不会使用 ClusterIP 调用服务
    Pods，而是使用与服务名称相同的 DNS 短名称——例如，`nginx-service-example`。这将通过集群的内部 DNS 服务解析为 ClusterIP。或者，它们也可以使用
    DNS **完全限定域名** (**FQDN**) 形式的 `<serviceName>.<namespaceName>.svc.<clusterDomain>`；例如，`nginx-service-example.default.svc.cluster.local`。
- en: For `LoadBalancer` or `NodePort` Services that expose Pods to external traffic,
    the principle is similar to internally; they also provide a ClusterIP for internal
    communication. The difference is that they also configure more components so that
    external traffic can be routed to the cluster.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 对于暴露 Pods 给外部流量的 `LoadBalancer` 或 `NodePort` 服务，其原理与内部服务类似；它们也提供用于内部通信的 ClusterIP。不同之处在于，它们还配置了更多组件，以便外部流量能够被路由到集群。
- en: Now that you’re equipped with the necessary knowledge about Service objects
    and their interactions with Deployment objects, let’s put what we’ve learned into
    practice!
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已掌握了有关服务对象及其与 Deployment 对象交互的必要知识，让我们把所学的知识付诸实践！
- en: Refer to *Chapter 8*, *Exposing Your Pods with Services*, to learn more about
    Services and the different types of Services available in Kubernetes.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅 *第8章*，*通过服务暴露您的 Pods*，了解更多关于服务以及 Kubernetes 中不同类型的服务的信息。
- en: Creating a Service declaratively
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 声明式创建服务
- en: 'In this section, we are going to expose our `nginx-deployment-example` Deployment
    using the `nginx-service-example` Service object, which is of the `LoadBalancer`
    type, by performing the following steps:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将通过执行以下步骤，使用 `LoadBalancer` 类型的 `nginx-service-example` 服务对象暴露我们的 `nginx-deployment-example`
    Deployment。
- en: 'Create an `nginx-service.yaml` manifest file with the following content:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `nginx-service.yaml` 清单文件，内容如下：
- en: '[PRE9]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The label selector of the Service is the same as the one we used for our Deployment
    object. The specification of the Service instructs us to expose our Deployment
    on port `80` of the cloud load balancer, and then route the traffic from target
    port `80` to the underlying Pods.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 服务的标签选择器与我们为 Deployment 对象使用的标签选择器相同。服务的规格指示我们将 Deployment 暴露在云负载均衡器的 `80` 端口上，然后将来自目标端口
    `80` 的流量路由到底层的 Pods。
- en: 'Depending on how your Kubernetes cluster is deployed, you may not be able to
    use the `LoadBalancer` type. In that case, you may need to use the `NodePort`
    type for this exercise or stick to the simple `ClusterIP` type and skip the part
    about external access. For local development deployments such as `minikube`, you
    will need to use the `minikube service` command to access your Service. You can
    find more details in the documentation: [https://minikube.sigs.k8s.io/docs/commands/service/](https://minikube.sigs.k8s.io/docs/commands/service/).'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的Kubernetes集群部署方式，你可能无法使用`LoadBalancer`类型。在这种情况下，你可能需要为本次练习使用`NodePort`类型，或者坚持使用简单的`ClusterIP`类型，并跳过有关外部访问的部分。对于本地开发部署，如`minikube`，你将需要使用`minikube
    service`命令来访问你的服务。你可以在文档中找到更多细节：[https://minikube.sigs.k8s.io/docs/commands/service/](https://minikube.sigs.k8s.io/docs/commands/service/)。
- en: 'Create the `nginx-service-example` Service and use the `kubectl get` or `kubectl
    describe` command to gather information about the status of our new Service and
    associated load balancer:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建`nginx-service-example`服务，并使用`kubectl get`或`kubectl describe`命令获取有关新服务及相关负载均衡器状态的信息：
- en: '[PRE10]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Now, let us try to access the Service from another Pod, as we did in *Chapter
    8*, *Exposing Your Pods with Services*. Let us create a `k8sutils` Pod as follows
    and test the Service access:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们像在*第8章*中那样，从另一个Pod访问该服务，*通过服务暴露你的Pods*。我们将按如下方式创建一个`k8sutils` Pod，并测试服务的访问：
- en: '[PRE11]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This shows how Services are used to expose Deployment Pods to external traffic.
    Now, we will quickly show you how to achieve a similar result using imperative
    commands to create a Service for our Deployment object.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这展示了如何使用服务将部署的Pods暴露给外部流量。现在，我们将快速展示如何使用命令式命令为我们的部署对象创建一个服务，从而实现类似的效果。
- en: Creating a Service imperatively
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 命令式创建服务
- en: 'A similar effect can be achieved using the imperative `kubectl expose` command
    `– a` Service will be created for our Deployment object named `nginx-deployment-example`.
    Use the following command:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 使用命令式的`kubectl expose`命令也可以实现类似的效果——一个名为`nginx-deployment-example`的服务将为我们的部署对象创建。使用以下命令：
- en: '[PRE12]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Let us explain the preceding code snippet:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释一下前面的代码片段：
- en: This will create a Service with the same name as the Deployment object – that
    is, `nginx-deployment-example`. If you would like to use a different name, as
    shown in the declarative example, you can use the `--name=nginx-service-example`
    parameter.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这将创建一个与部署对象同名的服务——即`nginx-deployment-example`。如果你希望使用不同的名称，如声明式示例所示，可以使用`--name=nginx-service-example`参数。
- en: Additionally, port `80`, which will be used by the Service, will be the same
    as the one that was defined for the Pods. If you want to change this, you can
    use the `--port=<number>` and `--target-port=<number>` parameters.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，将由服务使用的端口`80`将与Pods定义的端口相同。如果你希望更改此端口，可以使用`--port=<number>`和`--target-port=<number>`参数。
- en: Check `kubectl expose deployment --help` to see the options available for exposing
    the Deployment.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 查看`kubectl expose deployment --help`以查看暴露部署时可用的选项。
- en: Please note that this imperative command is recommended for use in development
    or debugging scenarios only. For production environments, you should leverage
    declarative *Infrastructure-as-Code* and *Configuration-as-Code* approaches as
    much as possible.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，这个命令式命令仅推荐在开发或调试场景中使用。对于生产环境，你应尽可能采用声明式的*基础设施即代码*和*配置即代码*方法。
- en: In the next section, let us learn how to use readiness, liveness, and startup
    probes with the Deployment.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，让我们学习如何在部署中使用就绪探针、存活探针和启动探针。
- en: Role of readiness, liveness, and startup probes
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 就绪探针、存活探针和启动探针的作用
- en: 'In *Chapter 8*, *Exposing Your Pods with Services*, we learned that there are
    three types of probes that you can configure for each container running in a Pod:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第8章*，*通过服务暴露你的Pods*中，我们学到了有三种类型的探针可以为每个运行在Pod中的容器配置：
- en: Readiness probe
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 就绪探针
- en: Liveness probe
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 存活探针
- en: Startup probe
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 启动探针
- en: All these probes are incredibly useful when you’re configuring your Deployments
    – always try to predict possible life cycle scenarios for the processes running
    in your containers and configure the probes accordingly for your Deployments.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些探针在你配置部署时都非常有用——总是尝试预测运行在容器中的进程可能的生命周期场景，并相应地为你的部署配置探针。
- en: Please note that, by default, no probes are configured on containers running
    in Pods. Kubernetes will serve traffic to Pod containers behind the Service, but
    only if the containers have successfully started, and restart them if they have
    crashed using the default `always-restart` policy. This means that it is your
    responsibility to figure out what type of probes and what settings you need for
    your particular case. You will also need to understand the possible consequences
    and caveats of incorrectly configured probes – for example, if your liveness probe
    is too restrictive and has timeouts that are too small, it may wrongfully restart
    your containers and decrease the availability of your application.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，默认情况下，Pod中的容器没有配置任何探针。Kubernetes会在Pod容器启动成功后通过服务提供流量，但只有在容器成功启动时才会提供流量，并且如果容器崩溃，它会使用默认的`always-restart`策略重启容器。这意味着你需要负责确定在特定情况下需要什么类型的探针和设置。你还需要理解配置错误的探针可能带来的后果和注意事项——例如，如果你的存活探针过于严格，且超时设置过短，可能会错误地重启容器，进而降低应用程序的可用性。
- en: Now, let’s demonstrate how you can configure a **readiness probe** on your Deployment
    and how it works in real time.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们演示如何在你的部署中配置**就绪探针**，以及它如何在实时中工作。
- en: 'If you are interested in the configuration details for other types of probes,
    refer to *Chapter 8*, *Exposing Your Pods with Services*, and also to the official
    documentation: [https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你对其他类型的探针的配置细节感兴趣，可以参考*第8章*、*通过服务暴露你的Pod*，以及官方文档：[https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)。
- en: The `nginx` Deployment that we use is very simple and does not need any dedicated
    readiness probe. Instead, we will arrange the container’s setup so that we can
    have the container’s readiness probe fail or succeed on demand. The idea is to
    create an empty file called `/usr/share/nginx/html/ready` during container setup,
    which will be served on the `/ready` endpoint by `nginx` (just like any other
    file) and configure a readiness probe of the `httpGet` type to query the `/ready`
    endpoint for a successful HTTP status code. Now, by deleting or recreating the
    `ready` file using the `kubectl exec` command, we can easily simulate failures
    in our Pods that cause the readiness probe to fail or succeed.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用的`nginx`部署非常简单，不需要任何专门的就绪探针。相反，我们将安排容器的设置，以便根据需要让容器的就绪探针失败或成功。具体来说，在容器设置过程中，我们将创建一个名为`/usr/share/nginx/html/ready`的空文件，`nginx`将通过`/ready`端点提供该文件（就像其他任何文件一样），并配置一个`httpGet`类型的就绪探针，用于查询`/ready`端点并获取成功的HTTP状态码。现在，通过使用`kubectl
    exec`命令删除或重新创建`ready`文件，我们可以轻松模拟导致就绪探针失败或成功的Pod故障。
- en: 'Follow these steps to configure and test the readiness probe:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤配置和测试就绪探针：
- en: 'Delete the existing Deployment using the following command:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令删除现有的部署：
- en: '[PRE13]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'Create a new Deployment YAML as follows:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按如下方式创建一个新的部署YAML：
- en: '[PRE14]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now we have the `spec.template` section as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们有如下的`spec.template`部分：
- en: '[PRE15]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'There are multiple parts changing in the Deployment manifest, all of which
    have been highlighted. First, we have overridden the default container entry point
    command using `command` and passed additional arguments. `command` is set to `/bin/sh`
    to execute a custom shell command. The additional arguments are constructed in
    the following way:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 部署清单中有多个部分发生了变化，所有这些变化都已被突出显示。首先，我们通过`command`覆盖了默认的容器入口点命令，并传递了额外的参数。`command`被设置为`/bin/sh`，用于执行自定义Shell命令。额外的参数构造方式如下：
- en: '`-c` is an argument for `/bin/sh` that instructs it that what follows is a
    command to be executed in the shell.'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-c`是`/bin/sh`的一个参数，指示它后续内容是要在Shell中执行的命令。'
- en: '`touch /usr/share/nginx/html/ready` is the first command that’s used in the
    container shell. This will create an empty `ready` file that can be served by
    `nginx` on the `/ready` endpoint.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`touch /usr/share/nginx/html/ready`是容器Shell中使用的第一个命令。这将创建一个空的`ready`文件，`nginx`将通过`/ready`端点提供该文件。'
- en: '`echo "You have been served by Pod with IP address: $(hostname -i)" > /usr/share/nginx/html/index.html`
    is the second command that sets the content of `index.html` to information about
    the internal cluster Pod’s IP address. `hostname -i` is the command that’s used
    to get the container IP address. This value will be different for each Pod running
    in our Deployment.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`echo "You have been served by Pod with IP address: $(hostname -i)" > /usr/share/nginx/html/index.html`是第二个命令，它将`index.html`的内容设置为关于内部集群Pod的IP地址信息。`hostname
    -i`是用于获取容器IP地址的命令。此值在每个运行在我们部署中的Pod中会有所不同。'
- en: '`nginx -g "daemon off;"`: Finally, we execute the default `entrypoint` command
    for the `nginx:1.25.4` image. This will start the `nginx` web server as the main
    process in the container.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`nginx -g "daemon off;"`：最后，我们执行`nginx:1.25.4`镜像的默认`entrypoint`命令。该命令将启动`nginx`
    Web服务器，并作为容器中的主进程运行。'
- en: Usually, you would perform such customization using a new container image, which
    inherits from a generic container image (e.g., `nginx` image) as a base and dedicated
    application script. The method shown here is being used for demonstration purposes
    and shows how flexible the Kubernetes runtime is. Refer to the sample `Chapter11/Containerfile`
    in the GitHub repository for creating custom container images.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，你会使用新的容器镜像进行这种自定义，该镜像继承自通用的容器镜像（例如`nginx`镜像）作为基础，并添加专用的应用程序脚本。这里展示的方法是用于演示目的，并展示了Kubernetes运行时的灵活性。有关创建自定义容器镜像的更多信息，请参考GitHub仓库中的示例`Chapter11/Containerfile`。
- en: 'The second set of changes we made in the YAML manifest for the Deployment was
    for the definition of `readinessProbe`, which is configured as follows:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在YAML清单中所做的第二组更改是针对`readinessProbe`的定义，其配置如下：
- en: The probe is of the `httpGet` type and executes an HTTP GET request to the `/ready`
    HTTP endpoint on port `80` of the container.
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探针的类型是`httpGet`，并执行一个HTTP GET请求，访问容器的`/ready` HTTP端点，端口为`80`。
- en: '`initialDelaySeconds`: This is set to `5` seconds and configures the probe
    to start querying after 5 seconds from container start.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`initialDelaySeconds`：此值设置为`5`秒，配置探针在容器启动后5秒开始查询。'
- en: '`periodSeconds`: This is set to `2` seconds and configures the probe to query
    in 2-second intervals.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`periodSeconds`：此值设置为`2`秒，配置探针以2秒为间隔进行查询。'
- en: '`timeoutSeconds`: This is set to `10` seconds and configures the number of
    seconds, after which the HTTP GET request times out.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`timeoutSeconds`：此值设置为`10`秒，配置HTTP GET请求超时的秒数。'
- en: '`successThreshold`: This is set to `1` and configures the minimum number of
    consecutive success queries of the probe before it is considered to be successful
    once it has failed.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`successThreshold`：此值设置为`1`，配置探针在失败后需要连续成功查询的最小次数，才会被认为是成功的。'
- en: '`failureThreshold`: This is set to `2` and configures the minimum number of
    consecutive failed queries of the probe before it is considered to have failed.
    Setting it to a value that’s greater than `1` ensures that the probe is not providing
    false positives.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`failureThreshold`：此值设置为`2`，配置探针在连续失败查询达到最小次数后，才会被认为失败。将其设置为大于`1`的值可以确保探针不会出现假阳性。'
- en: 'To create the Deployment, follow these steps:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 按照以下步骤创建部署：
- en: 'Apply the new YAML manifest file to the cluster using the following command:'
  id: totrans-139
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将新的YAML清单文件应用到集群中：
- en: '[PRE16]'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Verify that the `nginx-service-example` Service is displaying with backend
    Pod IP addresses. You can see that the Service has three endpoints that map to
    our Deployment Pods, all of which are ready to serve traffic:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证`nginx-service-example`服务是否显示后端Pod的IP地址。你可以看到该服务有三个端点，分别映射到我们的部署Pod，所有端点都准备好为流量提供服务：
- en: '[PRE17]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Test the nginx web server access using the `k8sutils` Pod that we created earlier
    in this chapter. You will notice that the responses iterate over different Pod
    IP addresses. This is because our Deployment has been configured to have three
    Pod replicas. Each time you perform a request, you may hit a different Pod:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用本章早些时候创建的`k8sutils` Pod测试nginx Web服务器访问。你会注意到，响应会在不同的Pod IP地址之间循环。这是因为我们的部署配置了三个Pod副本。每次你发起请求时，可能会命中不同的Pod：
- en: '[PRE18]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, let’s simulate a readiness failure for the first Pod. In our case, this
    is `nginx-deployment-readiness-69dd4cfdd9-4pkwr`, which has an IP address of `10.244.1.7`.
    To do this, we need to simply delete the `ready` file inside the container using
    the `kubectl exec` command:'
  id: totrans-145
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们模拟第一个Pod的就绪失败。在我们的案例中，Pod为`nginx-deployment-readiness-69dd4cfdd9-4pkwr`，其IP地址为`10.244.1.7`。为了做到这一点，我们只需要使用`kubectl
    exec`命令删除容器中的`ready`文件：
- en: '[PRE19]'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: The readiness probe will now start to fail, but not immediately! We have set
    it up so that it needs to fail at least two times, and each check is performed
    in 2-second intervals. Later, you will notice that you are only served by two
    other Pods that are still ready.
  id: totrans-147
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就绪探针现在开始失败，但不会立即失败！我们已经设置了它，要求至少失败两次，并且每次检查的间隔是 2 秒。稍后你会注意到，只有两个其他仍然就绪的 Pod
    为你提供服务。
- en: 'Now, if you describe the `nginx-service-example` Service, you will see that
    it only has two endpoints available, as expected:'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，如果你描述 `nginx-service-example` 服务，你会看到它只有两个可用的端点，正如预期的那样：
- en: '[PRE20]'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'In the events for the Pod, you can also see that it is considered not ready:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Pod 的事件中，你还可以看到它被认为是未就绪的：
- en: '[PRE21]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'We can push this even further. Delete the ready files in the other two Pods
    to make the whole Service fail:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以进一步推动这一过程。删除其他两个 Pod 中的就绪文件，使整个服务失败：
- en: '[PRE22]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: Now, when you check the Service from the `k8sutils` Pod, you will see that the
    request is pending and that, eventually, it will fail with a timeout. We are now
    in a pretty bad state – we have a total readiness failure for all the Pod replicas
    in our Deployment!
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，当你从 `k8sutils` Pod 检查服务时，你会看到请求处于挂起状态，最终会因为超时而失败。我们现在处于一种非常糟糕的状态——我们的部署中所有
    Pod 副本都未就绪！
- en: '[PRE23]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Finally, let’s make one of our Pods ready again by recreating the file. You
    can refresh the web page so that the request is pending and, at the same time,
    execute the necessary command to create the `ready` file:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们通过重新创建文件使其中一个 Pod 再次就绪。你可以刷新网页，让请求处于挂起状态，并同时执行必要的命令以创建 `ready` 文件：
- en: '[PRE24]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Congratulations – you have successfully configured and tested the readiness
    probe for your Deployment Pods! This should give you a good insight into how the
    probes work and how you can use them with Services that expose your Deployments.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你——你已成功配置并测试了你的部署 Pod 的就绪探针！这应该能让你深入了解探针是如何工作的，以及如何将它们与暴露你部署的服务一起使用。
- en: Next, we will take a brief look at how you can scale your Deployments.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将简要了解如何扩展你的部署。
- en: Scaling a Deployment object
  id: totrans-160
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展部署对象
- en: 'The beauty of Deployments is that you can almost instantly scale them up or
    down, depending on your needs. When the Deployment is exposed behind a Service,
    the new Pods will be automatically discovered as new endpoints when you scale
    up or automatically removed from the endpoints list when you scale down. The steps
    for this are as follows:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 部署的优点在于，你可以根据需求几乎即时地扩展或缩减它们。当部署通过服务暴露时，新 Pods 会在扩展时自动作为新端点被发现，或者在缩减时自动从端点列表中移除。操作步骤如下：
- en: 'First, let’s scale up our Deployment declaratively. Open the `nginx-deployment-readinessprobe.yaml`
    manifest file and modify the number of replicas:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，让我们声明式地扩展我们的部署。打开 `nginx-deployment-readinessprobe.yaml` 清单文件并修改副本数量：
- en: '[PRE25]'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Apply these changes to the cluster using the `kubectl apply` command:'
  id: totrans-164
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `kubectl apply` 命令将这些更改应用到集群中：
- en: '[PRE26]'
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'Now, if you check the Pods using the `kubectl get pods` command, you will immediately
    see that new Pods are being created. Similarly, if you check the output of the
    `kubectl describe` command for the Deployment, you will see the following in the
    events:'
  id: totrans-166
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，如果你使用 `kubectl get pods` 命令检查 Pod，你会立即看到正在创建新的 Pod。类似地，如果你检查 `kubectl describe`
    命令的输出，你会看到以下事件：
- en: '[PRE27]'
  id: totrans-167
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'You can achieve the same result using the `imperative` command, which is only
    recommended for development scenarios:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以使用 `imperative` 命令达到相同的效果，这仅推荐用于开发场景：
- en: '[PRE28]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'To scale down our Deployment declaratively, simply modify the `nginx-deployment-readinessprobe.yaml`
    manifest file and change the number of replicas:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要声明式地缩小我们的部署，只需修改 `nginx-deployment-readinessprobe.yaml` 清单文件并更改副本数量：
- en: '[PRE29]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Apply the changes to the cluster using the `kubectl apply` command:'
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `kubectl apply` 命令将更改应用到集群中：
- en: '[PRE30]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'You can achieve the same result using imperative commands. For example, you
    can execute the following command:'
  id: totrans-174
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你也可以通过命令式方式达到相同的效果。例如，你可以执行以下命令：
- en: '[PRE31]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'If you describe the Deployment, you will see that this scaling down is reflected
    in the events:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你描述该部署，你会看到这个缩小操作在事件中有所反映：
- en: '[PRE32]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: Deployment events are very useful if you want to know the exact timeline of
    scaling and the other operations that can be performed with the Deployment object.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 部署事件非常有用，如果你想了解扩展的确切时间线以及可以在部署对象上执行的其他操作。
- en: It is possible to autoscale your deployments using `HorizontalPodAutoscaler`.
    This will be covered in *Chapter 20*, *Autoscaling Kubernetes Pods and Nodes*.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `HorizontalPodAutoscaler` 自动扩展你的 Deployments。这将在*第 20 章*，*自动扩展 Kubernetes
    Pods 和节点*中讲解。
- en: Next, you will learn how to delete a Deployment from your cluster.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将学习如何从集群中删除一个 Deployment。
- en: Deleting a Deployment object
  id: totrans-181
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 删除 Deployment 对象
- en: 'To delete a Deployment object, you can do two things:'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除 Deployment 对象，你可以做两件事：
- en: Delete the Deployment object along with the Pods that it owns. This can be done
    by first scaling down automatically.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除 Deployment 对象以及它所拥有的 Pods。这可以通过首先自动缩减来完成。
- en: Delete the Deployment object and leave the other Pods unaffected.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除 Deployment 对象，同时保持其他 Pods 不受影响。
- en: 'To delete the Deployment object and its Pods, you can use the regular `kubectl
    delete` command:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 要删除 Deployment 对象及其 Pods，你可以使用常规的 `kubectl delete` 命令：
- en: '[PRE33]'
  id: totrans-186
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: You will see that the Pods get terminated and that the Deployment object is
    then deleted.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到 Pods 被终止，Deployment 对象也随之被删除。
- en: 'Now, if you would like to delete just the Deployment object, you need to use
    the `--cascade=orphan` option for `kubectl delete`:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果你只想删除 Deployment 对象，你需要在 `kubectl delete` 命令中使用 `--cascade=orphan` 选项：
- en: '[PRE34]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: After executing this command, if you inspect what Pods are in the cluster, you
    will still see all the Pods that were owned by the `nginx-deployment-example`
    Deployment.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此命令后，如果你检查集群中的 Pods，你仍然会看到所有由 `nginx-deployment-example` Deployment 所拥有的 Pods。
- en: In the following section, we will explore how to manage different revisions
    and roll out using the Deployment.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分，我们将探索如何使用 Deployment 管理不同的修订和发布。
- en: How Kubernetes Deployments seamlessly handle revisions and version rollouts
  id: totrans-192
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes Deployments 如何无缝处理修订和版本发布
- en: So far, we have only covered making one possible modification to a living Deployment
    – we have scaled up and down by changing the `replicas` parameter in the specification.
    However, this is not all we can do! It is possible to modify the Deployment’s
    Pod template (`.spec.template`) in the specification and, in this way, trigger
    a rollout. This rollout may be caused by a simple change, such as changing the
    labels of the Pods, but it may be also a more complex operation when the container
    images in the Pod definition are changed to a different version. This is the most
    common scenario as it enables you, as a Kubernetes cluster operator, to perform
    a controlled, predictable rollout of a new version of your image and effectively
    create a new revision of your Deployment.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们只讨论了对一个活跃的 Deployment 进行的单一修改——我们通过修改规范中的 `replicas` 参数来进行扩缩容。但这并不是我们能做的所有操作！你还可以在规范中修改
    Deployment 的 Pod 模板（`.spec.template`），通过这种方式触发发布。这个发布可能是由于简单的更改，比如更改 Pods 的标签，但当
    Pod 定义中的容器镜像更换为不同版本时，这也可能是一个更复杂的操作。这是最常见的场景，因为它使你作为 Kubernetes 集群操作员，能够进行可控、可预测的新版镜像发布，并有效地创建
    Deployment 的新修订。
- en: 'Your Deployment uses a rollout strategy, which can be specified in a YAML manifest
    using `.spec.strategy.type`. Kubernetes supports two strategies out of the box:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 你的 Deployment 使用了发布策略，这可以通过 YAML 清单中的 `.spec.strategy.type` 来指定。Kubernetes 默认支持两种策略：
- en: '`RollingUpdate`: This is the default strategy and allows you to roll out a
    new version of your application in a controlled way. This type of strategy uses
    two ReplicaSets internally. When you perform a change in the Deployment spec that
    causes a rollout, Kubernetes will create a new ReplicaSet with a new Pod template
    scaled to zero Pods initially. The old, existing ReplicaSet will remain unchanged
    at this point. Next, the old ReplicaSet will be scaled down gradually, whereas
    the new ReplicaSet will be scaled up gradually at the same time. The number of
    Pods that may be unavailable (readiness probe failing) is controlled using the
    `.spec.strategy.rollingUpdate.maxUnavailable` parameter.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`RollingUpdate`：这是默认的发布策略，允许你以可控的方式发布应用程序的新版本。此策略内部使用两个 ReplicaSets。当你在 Deployment
    规范中进行导致发布的更改时，Kubernetes 会创建一个新的 ReplicaSet，并将新的 Pod 模板初始扩容为零个 Pods。此时，旧的 ReplicaSet
    将保持不变。接下来，旧的 ReplicaSet 将逐步缩减，而新的 ReplicaSet 将同时逐步扩容。通过 `.spec.strategy.rollingUpdate.maxUnavailable`
    参数，可以控制在发布过程中可能出现的不可用 Pods（就绪探针失败的 Pods）数量。'
- en: The maximum number of extra Pods that can be scheduled above the desired number
    of Pods in the Deployment is controlled by the `.spec.strategy.rollingUpdate.maxSurge`
    parameter. Additionally, this type of strategy offers automatic revision history,
    which can be used for quick rollbacks in case of any failures.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 可以调度的额外 Pod 数量（超出目标数量的 Pod）由`.spec.strategy.rollingUpdate.maxSurge`参数控制。此外，这种策略提供了自动修订历史记录，可用于在发生故障时进行快速回滚。
- en: '`Recreate`: This is a simple strategy that’s useful for development scenarios
    where all the old Pods have been terminated and replaced with new ones. This instantly
    deletes any existing underlying ReplicaSet and replaces it with a new one. You
    should not use this strategy for production workloads unless you have a specific
    use case.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Recreate`：这是一种简单的策略，适用于开发场景，其中所有旧的 Pod 都已终止，并被新的 Pod 替换。它会立即删除任何现有的底层 ReplicaSet，并用新的
    ReplicaSet 替换。除非有特定的用例，否则不应将此策略用于生产工作负载。'
- en: 'Consider the Deployment strategies as basic building blocks for more advanced
    Deployment scenarios. For example, if you are interested in blue/green Deployments,
    you can easily achieve this in Kubernetes by using a combination of Deployments
    and Services while manipulating label selectors. You can find out more about this
    in the official Kubernetes blog post: [https://kubernetes.io/blog/2018/04/30/zero-downtime-deployment-kubernetes-jenkins/](https://kubernetes.io/blog/2018/04/30/zero-downtime-deployment-kubernetes-jenkins/).'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 将部署策略视为更高级部署场景的基本构建块。例如，如果你有兴趣进行蓝绿部署，可以通过使用部署和服务的组合，并操控标签选择器，轻松在 Kubernetes
    中实现。你可以在 Kubernetes 官方博客文章中了解更多内容：[https://kubernetes.io/blog/2018/04/30/zero-downtime-deployment-kubernetes-jenkins/](https://kubernetes.io/blog/2018/04/30/zero-downtime-deployment-kubernetes-jenkins/)。
- en: Now, we will perform a rollout using the `RollingUpdate` strategy. The `Recreate`
    strategy, which is much simpler, can be exercised similarly.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将使用`RollingUpdate`策略执行一次滚动更新。`Recreate`策略更简单，类似地也可以使用。
- en: Updating a Deployment object
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更新一个部署对象
- en: 'We will explore the `RollingUpdate` strategy with a practical example in this
    section. First, let’s recreate the Deployment that we used previously for our
    readiness probe demonstration:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 本节将通过实际例子来探讨`RollingUpdate`策略。首先，让我们重新创建之前用于演示就绪探针的部署：
- en: 'Make a copy of the previous YAML manifest file:'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 复制前一个 YAML 清单文件：
- en: '[PRE35]'
  id: totrans-203
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Ensure that you have a strategy of the `RollingUpdate` type, called `readinessProbe`,
    set up and an image version of `nginx:1.17`. This should already be set up in
    the `nginx-deployment-readinessprobe.yaml` manifest file if you completed the
    previous sections:'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你已经设置了`RollingUpdate`类型的策略，名为`readinessProbe`，并使用了`nginx:1.17`的镜像版本。如果你完成了之前的章节，这些内容应该已经在`nginx-deployment-readinessprobe.yaml`清单文件中设置好了：
- en: '[PRE36]'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: In this example, we are using `maxUnavailable` set to `1`, which means that
    we allow only one Pod out of three, which is the target number, to be unavailable
    (not ready). This means that, at any time, there must be at least two Pods ready
    to serve traffic.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这个例子中，我们使用`maxUnavailable`设置为`1`，这意味着我们允许三个 Pod 中只有一个（即目标数量）不可用（未准备好）。这意味着，在任何时候，必须有至少两个
    Pod 准备好提供流量。
- en: Similarly, setting `maxSurge` to `1` means that we allow one extra Pod to be
    created above the target number of three Pods during the rollout. This effectively
    means that we can have up to four Pods (ready or not) present in the cluster during
    the rollout. Please note that it is also possible to set up these parameters as
    percentage values (such as `25%`), which is very useful in autoscaling scenarios.
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 类似地，将`maxSurge`设置为`1`意味着我们允许在滚动更新期间创建一个额外的 Pod，使其数量超过目标的三个 Pod。实际效果是，在滚动更新期间，集群中最多可以有四个
    Pod（无论是否准备好）。请注意，这些参数也可以设置为百分比值（例如`25%`），这在自动伸缩场景中非常有用。
- en: Additionally, `minReadySeconds` (which is set to `10`) provides an additional
    time span for which the Pod has to be ready before it can be *announced* as successful
    during the rollout.
  id: totrans-208
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 此外，`minReadySeconds`（设置为`10`）为 Pod 提供了额外的时间段，只有 Pod 准备好后才能在滚动更新期间被*宣布*为成功。
- en: 'Apply the manifest file to the cluster:'
  id: totrans-209
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将清单文件应用到集群中：
- en: '[PRE37]'
  id: totrans-210
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'With the Deployment ready in the cluster, we can start rolling out a new version
    of our application. We will change the image in the Pod template for our Deployment
    to a newer version and observe what happens during the rollout. To do this, follow
    the following steps:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 部署在集群中准备好后，我们可以开始发布应用程序的新版本。我们将更改部署Pod模板中的镜像为更新版本，并观察在发布过程中发生了什么。按照以下步骤操作：
- en: 'Modify the container image that was used in the Deployment to `nginx:1.18`:'
  id: totrans-212
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将部署中使用的容器镜像修改为`nginx:1.18`：
- en: '[PRE38]'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Apply the changes to the cluster using the following command:'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令将更改应用到集群中：
- en: '[PRE39]'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Immediately after that, use the `kubectl rollout status` command to see the
    progress in real time:'
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 紧接着，使用`kubectl rollout status`命令查看实时进度：
- en: '[PRE40]'
  id: totrans-217
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: The rollout will take a bit of time because we have configured `minReadySeconds`
    on the Deployment specification and `initialDelaySeconds` on the Pod container
    readiness probe.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署过程需要一些时间，因为我们在部署规格中配置了`minReadySeconds`，并在Pod容器就绪探针中配置了`initialDelaySeconds`。
- en: 'Similarly, using the `kubectl describe` command, you can see the events for
    the Deployment that inform us of how the ReplicaSets were scaled up and down:'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同样，使用`kubectl describe`命令，你可以查看有关部署的事件，这些事件会告诉我们ReplicaSets是如何被扩展和缩减的：
- en: '[PRE41]'
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Now, let’s take a look at the ReplicaSets in the cluster:'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们查看集群中的ReplicaSets：
- en: '[PRE42]'
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'You will see something interesting here: the old ReplicaSet remains in the
    cluster but has been scaled down to zero Pods! The reason for this is that we’re
    keeping the Deployment revision history – each revision has a matching ReplicaSet
    that can be used if we need to roll back. The number of revisions that are kept
    for each Deployment is controlled by the `.spec.revisionHistoryLimit` parameter
    – by default, it is set to `10`. Revision history is important, especially if
    you are making imperative changes to your Deployments. If you are using the declarative
    model and always committing your changes to a source code repository, then the
    revision history may be less relevant.'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在这里看到一些有趣的事情：旧的ReplicaSet仍然存在于集群中，但已被缩减为零个Pod！其原因是我们保留了部署的修订历史——每个修订都有一个匹配的ReplicaSet，可以在需要回滚时使用。每个部署保留的修订历史的数量由`.spec.revisionHistoryLimit`参数控制——默认情况下，设置为`10`。修订历史非常重要，尤其是当你对部署进行命令式更改时。如果你使用声明式模型，并且总是将更改提交到源代码仓库，那么修订历史可能不那么重要。
- en: 'Lastly, we can check if the Pods were indeed updated to a new image version.
    Use the following command and verify one of the Pods in the output:'
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们可以检查Pods是否确实已更新为新的镜像版本。使用以下命令并在输出中验证其中一个Pod：
- en: '[PRE43]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: This shows that we have indeed performed a rollout of the new `nginx` container
    image version!
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这表明我们确实已经进行了新的`nginx`容器镜像版本的部署！
- en: You can change the Deployment container image *imperatively* using the `kubectl
    set image deployment nginx-deployment-example nginx=nginx:1.18` command. This
    approach is only recommended for non-production scenarios, and it works well with
    *imperative* rollbacks.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过`kubectl set image deployment nginx-deployment-example nginx=nginx:1.18`命令以*命令式*方式更改部署容器镜像。这种方法仅建议在非生产环境中使用，并且与*命令式*回滚配合使用效果良好。
- en: Next, you will learn how to roll back a Deployment object.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，你将学习如何回滚一个部署对象。
- en: Rolling back a Deployment object
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 回滚部署对象
- en: If you are using a declarative model to introduce changes to your Kubernetes
    cluster and are committing each change to your source code repository, performing
    a rollback is very simple and involves just reverting the commit and applying
    the configuration again. Usually, the process of applying changes is performed
    as part of the CI/CD pipeline for the source code repository, instead of the changes
    being manually applied by an operator (such as an application team or administrators).
    This is the easiest way to manage Deployments, and this is generally recommended
    in the Infrastructure-as-Code and Configuration-as-Code paradigms.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你使用声明式模型向Kubernetes集群引入更改，并将每个更改提交到源代码仓库，执行回滚非常简单，只需恢复提交并重新应用配置即可。通常，应用更改的过程作为源代码仓库的CI/CD管道的一部分执行，而不是由操作员（如应用团队或管理员）手动应用更改。这是管理部署的最简单方式，通常建议在基础设施即代码（Infrastructure-as-Code）和配置即代码（Configuration-as-Code）范式中使用。
- en: A powerful example of using a declarative model in practice is **Flux** ([https://fluxcd.io/](https://fluxcd.io/)).
    While originally incubated by the **Cloud Native Computing Foundation** (**CNCF**),
    Flux has since graduated and become a full-fledged project within the CNCF landscape.
    Flux is the core of the GitOps approach, a methodology for implementing continuous
    deployment for cloud-native applications. It prioritizes a developer-centric experience
    by leveraging familiar tools like Git and continuous deployment pipelines, streamlining
    infrastructure management for developers.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 一个使用声明式模型的强大示例是 **Flux** ([https://fluxcd.io/](https://fluxcd.io/))。Flux 最初由
    **Cloud Native Computing Foundation** (**CNCF**) 孵化，后来已毕业并成为 CNCF 生态系统中的一个成熟项目。Flux
    是 GitOps 方法的核心，GitOps 是实现云原生应用持续部署的一种方法论。它通过利用 Git 和持续部署管道等熟悉的工具，优先考虑开发者中心的体验，从而简化了基础设施管理。
- en: 'However, Kubernetes still provides an imperative way to roll back a Deployment
    using revision history. Imperative rollbacks can also be performed on Deployments
    that have been updated declaratively. Now, we will demonstrate how to use `kubectl`
    for rollbacks. Follow the next steps:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，Kubernetes 仍然提供了一种通过修订历史回滚 Deployment 的命令式方法。即使是通过声明式更新的 Deployments，也可以执行命令式回滚。现在，我们将演示如何使用
    `kubectl` 进行回滚。请按照以下步骤操作：
- en: 'First, let’s imperatively roll out another version of our Deployment. This
    time, we will update the `nginx` image to version `1.19`:'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们命令式地发布另一个版本的 Deployment。这次，我们将 `nginx` 镜像更新为版本 `1.19`：
- en: '[PRE44]'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: Please note, `nginx=nginx:1.19` means we are setting the `nginx:1.19` image
    for the container called `nginx` in the `nginx-deployment-rollingupdate` Deployment.
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 请注意，`nginx=nginx:1.19` 表示我们正在为名为 `nginx` 的容器设置 `nginx:1.19` 镜像，该容器位于 `nginx-deployment-rollingupdate`
    Deployment 中。
- en: 'Using `kubectl rollout status`, wait for the end of the Deployment:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 `kubectl rollout status`，等待 Deployment 完成：
- en: '[PRE45]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: Now, let’s suppose that the new version of the application image, `1.19`, is
    causing problems and that your team decided to roll back to the previous version
    of the image, which was working fine.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，假设新版本的应用镜像 `1.19` 造成了一些问题，你的团队决定回滚到之前的版本，这个版本运行良好。
- en: 'Use the following `kubectl rollout history` command to see all the revisions
    that are available for the Deployment:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下 `kubectl rollout history` 命令查看 Deployment 可用的所有修订：
- en: '[PRE46]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: As you can see, we have three revisions. The first revision is our initial creation
    of the Deployment. The second revision is the declarative update of the Deployment
    to the `nginx:1.18` image. Finally, the third revision is our last imperative
    update to the Deployment that caused the `nginx:1.19` image to be rolled out.
    `CHANGE-CAUSE` is empty here because we haven’t used the `--record` flag, as the
    `--record` flag has been deprecated and will be removed in the future version.
    If you have a requirement to update `CHANGE-CAUSE`, you need to manually update
    the Deployment annotation, as we learned earlier in this chapter.
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如你所见，我们有三个修订版本。第一个修订是我们最初创建的 Deployment。第二个修订是将 Deployment 声明式更新为 `nginx:1.18`
    镜像。最后，第三个修订是我们最后一次的命令式更新，将 `nginx:1.19` 镜像发布。这里 `CHANGE-CAUSE` 为空，因为我们没有使用 `--record`
    标志，`--record` 标志已被弃用，并将在未来的版本中删除。如果你有更新 `CHANGE-CAUSE` 的需求，你需要手动更新 Deployment
    注解，正如我们在本章前面学到的那样。
- en: 'The revisions that were created as declarative changes do not contain too much
    information in `CHANGE-CAUSE`. To find out more about the second revision, you
    can use the following command:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 作为声明式更改创建的修订中，`CHANGE-CAUSE` 并未包含太多信息。若要了解第二个修订版本的更多信息，你可以使用以下命令：
- en: '[PRE47]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'Now, let’s perform a rollback to this revision. Because it is the previous
    revision, you can simply execute the following command:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们回滚到这个修订版本。由于它是上一个修订，你可以简单地执行以下命令：
- en: '[PRE48]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'This would be equivalent to executing a rollback to a specific revision number:'
  id: totrans-246
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 这相当于执行回滚到特定的修订版本：
- en: '[PRE49]'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Again, as in the case of a normal rollout, you can use the following command
    to follow the rollback:'
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次，和正常的发布一样，你可以使用以下命令跟踪回滚过程：
- en: '[PRE50]'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: You will notice that version 2 is missing, and a new version of the deployment
    has been created.
  id: totrans-250
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会注意到版本 2 缺失，并且创建了一个新的部署版本。
- en: Please note that you can also perform rollbacks on currently ongoing rollouts.
    This can be done in both ways; that is, declaratively and imperatively.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，你还可以在当前正在进行的发布中执行回滚。回滚可以以声明式和命令式两种方式进行。
- en: If you need to pause and resume the ongoing rollout of a Deployment, use the
    `kubectl rollout pause deployment nginx-deployment-example` and `kubectl rollout
    resume deployment nginx-deployment-example` commands.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations – you have successfully rolled back your Deployment. In the
    next section, we will provide you with a set of best practices for managing Deployment
    objects in Kubernetes.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Canary deployment strategy
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Canary deployments offer a valuable strategy for minimizing risk during application
    rollouts. They take inspiration from the practice of sending canaries (birds)
    into coal mines to detect dangerous gases. Similarly, canary deployments introduce
    a new version of an application to a limited subset of users before exposing it
    to the entire production environment.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: 'This controlled rollout allows for real-world testing of the new version while
    minimizing potential disruptions. Here’s how it works: imagine you’re deploying
    an update to your e-commerce website. Traditionally, the entire website would
    be switched to the new version simultaneously. With a canary deployment, however,
    it is possible to create two deployments: a stable deployment running the current
    version serving the majority of users, and a canary deployment with the new version
    serving a small percentage of users. Traffic routing mechanisms like ingress controllers
    or service annotations then direct a specific portion of traffic (e.g., 10%) to
    the canary deployment.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: By closely monitoring the canary Deployment’s performance through metrics like
    error rates, response times, and user feedback, you can assess the new version’s
    stability. If everything runs smoothly, you can gradually increase the percentage
    of traffic directed to the canary deployment until it serves all users. Conversely,
    if issues arise, you can easily roll back the canary deployment and maintain the
    stable version, preventing a wider impact on your user base.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider this YAML example demonstrating a canary deployment for a frontend
    application: We have the stable app Deployment configuration with `image: frontend-app:1.0`
    as follows.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-259
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'Now we have a canary deployment configuration for the same application with
    `image: frontend-app:2.0`, as follows.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-261
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'And we need a Service to route the traffic to both versions of the Deployment.
    Please note, we only used `app: myapp` and `tier: frontend` labels as selectors
    so that the Service will use both `stable` and `Canary` Pods to serve the traffic:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: By adjusting the replicas in each Deployment, you control the percentage of
    users directed to each version.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Alternatively, it is also possible to create different Service objects for stable
    and canary versions and use a mechanism like ingress controllers or service annotations
    to route a specific percentage of traffic (e.g., 10%) to the canary deployment.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: 'The important part is monitoring the canary deployment and ensuring the new
    version is working as per expectation. Based on the result, you can either promote
    the canary as the stable Deployment or delete the canary and update the new application
    image (e.g., `image: frontend-app:2.0`) in the stable Deployment.'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Refer to the documentation ([https://kubernetes.io/docs/concepts/workloads/management/#canary-deployments](https://kubernetes.io/docs/concepts/workloads/management/#canary-deployments))
    to learn more about canary deployments.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s move on to the next section on the best practices of working with
    Deployment objects.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Deployment object best practices
  id: totrans-269
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This section will summarize the best practices when working with Deployment
    objects in Kubernetes. This list is by no means complete, but it is a good starting
    point for your journey with Kubernetes.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: Use declarative object management for Deployments
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the DevOps and containerized application world, it is a good practice to
    stick to declarative models when introducing updates to your infrastructure and
    applications. This is at the core of the *Infrastructure-as-Code* and *Configuration-as-Code*
    paradigms. In Kubernetes, you can easily perform declarative updates using the
    `kubectl apply` command, which can be used on a single file or even a whole directory
    of YAML manifest files.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: To delete objects, it is still better to use imperative commands. It is more
    predictable and less prone to errors. Declaratively deleting resources in your
    cluster is mostly useful in CI/CD and GitOps scenarios, where the whole process
    is entirely automated.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: The same principle also applies to Deployment objects. Performing a rollout
    or rollback when your YAML manifest files are versioned and kept in a source control
    repository is easy and predictable. Using the `kubectl rollout undo` and `kubectl
    set image deployment` commands is generally not recommended in production environments.
    Using these commands gets much more complicated when more than one person is working
    on operations in the cluster.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: Do not use the Recreate strategy for production workloads
  id: totrans-275
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using the `Recreate` strategy may be tempting as it provides instantaneous updates
    for your Deployments. However, at the same time, this will mean downtime for your
    end users. This is because all the existing Pods for the old revision of the Deployment
    will be terminated at once and replaced with the new Pods. There may be a significant
    delay before the new Pods become ready, and this means downtime. This downtime
    can be easily avoided by using the `RollingUpdate` strategy in production scenarios.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: The `Recreate` deployment strategy in Kubernetes is best suited for specific
    scenarios where downtime is acceptable and offers some advantages over other strategies.
    For example, when deploying significant application changes or introducing entirely
    new versions, the `Recreate` strategy allows for a clean slate and ensures the
    new version runs independently from the previous one.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: Do not create Pods that match an existing Deployment label selector
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is possible to create Pods with labels that match the label selector of
    some existing Deployment. This can be done using bare Pods or another Deployment
    or ReplicaSet. This leads to conflicts, which Kubernetes does not prevent, and
    makes the existing deployment *believe* that it has created the other Pods. The
    results may be unpredictable and, in general, you need to pay attention to how
    you label the resources in your cluster. We advise you to use semantic labeling
    here, which you can learn more about in the official documentation: [https://kubernetes.io/docs/concepts/configuration/overview/#using-labels](https://kubernetes.io/docs/concepts/configuration/overview/#using-labels).'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Carefully set up your container probes
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The liveness, readiness, and startup probes of your Pod containers can provide
    a lot of benefits but, at the same time, if they have been misconfigured, they
    can cause outages, including cascading failures. You should always be sure that
    you understand the consequences of each probe going into a failed state and how
    it affects other Kubernetes resources, such as Service objects.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'There are a few established best practices for readiness probes that you should
    consider:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Use this probe whenever your containers may not be ready to serve traffic as
    soon as the container is started.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensure that you check things such as cache warm-ups or your database migration
    status during readiness probe evaluation. You may also consider starting the actual
    process of a warm-up if it has not been started yet, but use this approach with
    caution – a readiness probe will be executed constantly throughout the life cycle
    of a Pod, which means you shouldn’t perform any costly operations for every request.
    Alternatively, you may want to use a startup probe for this purpose.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For microservice applications that expose HTTP endpoints, consider configuring
    the `httpGet` readiness probe. This will ensure that every basis is covered when
    a container is successfully running but the HTTP server has not been fully initialized.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is a good idea to use a separate, dedicated HTTP endpoint for readiness checks
    in your application. For example, a common convention is using `/health`.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are checking the state of your dependencies (external database, logging
    services, etc.) in this type of probe, be careful with shared dependencies, such
    as databases. In this case, you should consider using a probe timeout, which is
    greater than the maximum allowed timeout for the external dependency – otherwise,
    you may get cascading failures and lower availability instead of occasionally
    increased latency.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Similar to readiness probes, there are a few guidelines on how and when you
    should use liveness probes:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Liveness probes should be used with caution. Incorrectly configuring these probes
    can result in cascading failures in your services and container restart loops.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not use liveness probes unless you have a good reason to do so. A good reason
    may be, for example, if there’s a known issue with a deadlock in your application
    that has an unknown root cause.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Execute simple and fast checks that determine the status of the process, not
    its dependencies. In other words, you do not want to check the status of your
    external dependencies in the liveness probe, since this can lead to cascading
    failures due to an avalanche of container restarts and overloading a small subset
    of Service Pods.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If the process running in your container can crash or exit whenever it encounters
    an unrecoverable error, you probably do not need a liveness probe at all.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use conservative settings for `initialDelaySeconds` to avoid any premature container
    restarts and falling into a restart loop.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are the most important points concerning probes for Pods. Now, let’s discuss
    how you should tag your container images.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: Use meaningful and semantic image tags
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Managing Deployment rollbacks and inspecting the history of rollouts requires
    that we use good tagging for the container images. If you rely on the `latest`
    tag, performing a rollback will not be possible because this tag points to a different
    version of the image as time goes on. It is a good practice to use semantic versioning
    for your container images. Additionally, you may consider tagging the images with
    a source code hash, such as a Git commit hash, to ensure that you can easily track
    what is running in your Kubernetes cluster.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: Migrate from older versions of Kubernetes
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'If you are working on workloads that were developed on older versions of Kubernetes,
    you may notice that, starting with Kubernetes 1.16, you can’t apply the Deployment
    to the cluster because of the following error:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-299
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'The reason for this is that in version 1.16, the Deployment object was removed
    from the `extensions/v1beta1` API group, according to the API versioning policy.
    You should use the `apps/v1` API group instead, which Deployment has been part
    of since 1.9\. This also shows an important rule to follow when you work with
    Kubernetes: always follow the API versioning policy and try to upgrade your resources
    to the latest API groups when you migrate to a new version of Kubernetes. This
    will save you unpleasant surprises when the resource is eventually deprecated
    in older API groups.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: Include resource management in the Deployment
  id: totrans-301
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Define resource requests (minimum guaranteed resources) and limits (maximum
    allowed resources) for containers within your Deployment. This helps the Kubernetes
    scheduler allocate resources efficiently and prevent resource starvation. Also,
    don’t overestimate or underestimate resource needs. Analyze application behavior
    to determine appropriate resource requests and limits to avoid under-utilization
    or performance bottlenecks.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: Scaling and replica management
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Use **HorizontalPodAutoscaler** (**HPA**) to automatically scale your Deployment
    replicas up or down based on predefined metrics like CPU or memory usage.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: 'The following image illustrates how HPA handles the desired count of replicas:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22019_11_05.png)'
  id: totrans-306
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11.5: HPA handling the Deployment based on metrics information'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: Also, it is a best practice to set the initial replica count (number of Pod
    instances) for your Deployment considering factors like expected workload and
    resource availability.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Security considerations
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Implement Deployment policies that will not allow running containers with unnecessary
    privileges (e.g., root user). This reduces the attack surface and potential security
    vulnerabilities. Also, remember to store sensitive information like passwords
    or configuration details in Secrets and ConfigMaps instead of embedding them directly
    in Deployments. Refer to *Chapter 18*, *Security in Kubernetes*, to explore different
    security aspects of Kubernetes.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-311
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you learned how to work with **stateless** workloads and applications
    on Kubernetes using Deployment objects. First, you created an example Deployment
    and exposed its Pods using a Service object of the `LoadBalancer` type for external
    traffic. Next, you learned how to scale and manage Deployment objects in the cluster.
    The management operations we covered included rolling out a new revision of a
    Deployment and rolling back to an earlier revision in case of a failure. Lastly,
    we equipped you with a set of known best practices when working with Deployment
    objects.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: 'The next chapter will extend this knowledge with details about managing **stateful**
    workloads and applications. While doing so, we will introduce a new Kubernetes
    object: StatefulSet.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-314
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes Deployments: [https://kubernetes.io/docs/concepts/workloads/controllers/deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment
    )'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'StatefulSets: [https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/
    )'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Canary deployments: [https://kubernetes.io/docs/concepts/workloads/management/#canary-deployments](https://kubernetes.io/docs/concepts/workloads/management/#canary-deployments
    )'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  id: totrans-318
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code119001106479081656.png)'
  id: totrans-321
  prefs: []
  type: TYPE_IMG
