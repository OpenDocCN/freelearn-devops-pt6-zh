<html><head></head><body>
		<div id="_idContainer077">
			<h1 class="chapter-number" id="_idParaDest-141"><a id="_idTextAnchor141"/>9</h1>
			<h1 id="_idParaDest-142"><a id="_idTextAnchor142"/>Data Consumption Layer</h1>
			<p>In today’s data-driven world, organizations are dealing with an ever-increasing volume of data, and the ability to effectively consume and analyze this data is crucial for making informed business decisions. As we delve into the realm of big data on Kubernetes, we must address the critical component of the data consumption layer. This layer serves as the bridge between the vast repositories of data and the business analysts who need to extract valuable insights and make decisions that have an impact on <span class="No-Break">the business.</span></p>
			<p>In this chapter, we will explore two powerful tools that will enable you to unlock the potential of your <a id="_idIndexMarker542"/>Kubernetes-based data architecture: <strong class="bold">Trino</strong> and <strong class="bold">Elasticsearch</strong>. Trino, a distributed SQL query engine, will empower you to directly query your <a id="_idIndexMarker543"/>data lake, eliminating the need for a traditional data warehouse. You will learn how to deploy Trino on Kubernetes, monitor its performance, and execute SQL queries against your data stored in <span class="No-Break">Amazon S3.</span></p>
			<p>Furthermore, we will introduce Elasticsearch, a highly scalable and efficient search engine widely used <a id="_idIndexMarker544"/>in real-time data pipelines, along with <strong class="bold">Kibana</strong>, its powerful data visualization tool. You will gain hands-on experience in deploying Elasticsearch on Kubernetes, indexing data for optimized storage and retrieval, and building simple yet insightful visualizations using Kibana. This combination will equip you with the ability to analyze real-time data streams and uncover valuable patterns <span class="No-Break">and trends.</span></p>
			<p>By the end of this chapter, you will have acquired the skills necessary to successfully deploy and utilize Trino and Elasticsearch on Kubernetes. You will be able to execute SQL queries directly against your data lake, monitor query execution and history, and leverage the power of Elasticsearch and Kibana for real-time data analysis <span class="No-Break">and visualization.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Getting started with SQL <span class="No-Break">query engines</span></li>
				<li>Deploying Trino <span class="No-Break">in Kubernetes</span></li>
				<li>Deploying Elasticsearch <span class="No-Break">in Kubernetes</span></li>
				<li>Running queries and connecting to <span class="No-Break">other tools</span></li>
			</ul>
			<h1 id="_idParaDest-143"><a id="_idTextAnchor143"/>Technical requirements</h1>
			<p>For this chapter, you should have an AWS EKS cluster ready for deployment and DBeaver Community locally installed (<a href="https://dbeaver.io/">https://dbeaver.io/</a>) We will continue working on the cluster we deployed in <a href="B21927_08.xhtml#_idTextAnchor134"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>. All the code for this chapter is available at <a href="https://github.com/PacktPublishing/Bigdata-on-Kubernetes">https://github.com/PacktPublishing/Bigdata-on-Kubernetes</a> in the <span class="No-Break"><strong class="source-inline">Chapter09</strong></span><span class="No-Break"> folder.</span></p>
			<h1 id="_idParaDest-144"><a id="_idTextAnchor144"/>Getting started with SQL query engines</h1>
			<p>In the world of big data, the way we store and analyze data has undergone a significant transformation. Traditional <a id="_idIndexMarker545"/>data warehouses, which were once the go-to solution for data analysis, have given way to more modern and scalable approaches, such as <a id="_idIndexMarker546"/>SQL query <a id="_idIndexMarker547"/>engines. These engines, such as <strong class="bold">Trino</strong> (formerly known as Presto), <strong class="bold">Dremio</strong>, and <strong class="bold">Apache Spark SQL</strong>, offer a high-performance, cost-effective, and <a id="_idIndexMarker548"/>flexible alternative to traditional <span class="No-Break">data warehouses.</span></p>
			<p>Next, we are going to see the main differences between data warehouses and SQL <span class="No-Break">query engines.</span></p>
			<h2 id="_idParaDest-145"><a id="_idTextAnchor145"/>The limitations of traditional data warehouses</h2>
			<p>Traditional data warehouses were designed to store and analyze structured data from relational <a id="_idIndexMarker549"/>databases. However, with the <a id="_idIndexMarker550"/>advent of big data and the proliferation of diverse data sources, such as log files, sensor data, and social media data, the limitations of data warehouses became apparent. These limitations include <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Scalability</strong>: Data <a id="_idIndexMarker551"/>warehouses often struggle to scale horizontally, making it challenging to handle large volumes of <span class="No-Break">data efficiently</span></li>
				<li><strong class="bold">Data ingestion</strong>: The <a id="_idIndexMarker552"/>process of <strong class="bold">extracting, transforming, and loading</strong> (<strong class="bold">ETL</strong>) data into a data warehouse <a id="_idIndexMarker553"/>can be complex, time-consuming, <span class="No-Break">and resource-intensive</span></li>
				<li><strong class="bold">Cost</strong>: Data <a id="_idIndexMarker554"/>warehouses can be expensive to set up and maintain, especially when dealing with large volumes <span class="No-Break">of data</span></li>
				<li><strong class="bold">Flexibility</strong>: Data <a id="_idIndexMarker555"/>warehouses are typically optimized for structured data and may not handle semi-structured or unstructured data <span class="No-Break">as efficiently</span></li>
			</ul>
			<p>SQL query engines were developed to address these limitations. Let’s see how <span class="No-Break">they work.</span></p>
			<h2 id="_idParaDest-146"><a id="_idTextAnchor146"/>The rise of SQL query engines</h2>
			<p>SQL query engines, such as Trino, provide a distributed, scalable, and cost-effective solution <a id="_idIndexMarker556"/>for querying large datasets stored in various data sources, including object storage (e.g., Amazon S3, Google Cloud Storage, and Azure Blob Storage), relational databases, and NoSQL databases. We will take a deeper dive into SQL query engines’ architecture in the <span class="No-Break">next section.</span></p>
			<p>Here are <a id="_idIndexMarker557"/>some key advantages of SQL <span class="No-Break">query engines:</span></p>
			<ul>
				<li><strong class="bold">High performance</strong>: SQL query engines are designed to leverage the power of distributed computing, allowing them to process large datasets in parallel across multiple nodes. This parallelization enables high-performance queries, even on <span class="No-Break">massive datasets.</span></li>
				<li><strong class="bold">Cost-effective</strong>: By leveraging object storage and separating storage from compute, SQL query engines can significantly reduce the cost of data storage and processing compared to traditional <span class="No-Break">data warehouses.</span></li>
				<li><strong class="bold">Scalability</strong>: SQL query engines can scale horizontally by adding more nodes to the cluster, enabling them to handle increasing volumes of <span class="No-Break">data efficiently.</span></li>
				<li><strong class="bold">Flexibility</strong>: SQL query engines can query a wide range of data sources, including structured, semi-structured, and unstructured data, making them highly flexible <a id="_idIndexMarker558"/>and adaptable to various data formats and <span class="No-Break">storage systems.</span></li>
				<li><strong class="bold">Open source</strong>: Many SQL query engines are open source projects, allowing organizations to leverage the power of community contributions and avoid <span class="No-Break">vendor lock-in.</span></li>
			</ul>
			<p>Now, let’s understand the underlying architecture of this type <span class="No-Break">of solution.</span></p>
			<h2 id="_idParaDest-147"><a id="_idTextAnchor147"/>The architecture of SQL query engines</h2>
			<p>SQL query <a id="_idIndexMarker559"/>engines such as Trino are designed to work in a distributed computing environment, where multiple nodes work together to process queries and return results. The architecture typically consists of the <span class="No-Break">following components:</span></p>
			<ul>
				<li>A <strong class="bold">coordinator node</strong>, which is responsible for parsing SQL queries, creating a distributed <a id="_idIndexMarker560"/>execution plan, and coordinating the execution of the query across the <span class="No-Break">worker nodes.</span></li>
				<li>A set of <strong class="bold">worker nodes</strong>, which are responsible for executing the tasks assigned by the <a id="_idIndexMarker561"/>coordinator node. They read data from the underlying data sources, perform computations, and exchange intermediate results with other worker nodes <span class="No-Break">as needed.</span></li>
				<li>A <strong class="bold">metadata store</strong>, which <a id="_idIndexMarker562"/>contains information about the data sources, table definitions, and other metadata required for <span class="No-Break">query execution.</span></li>
			</ul>
			<p>When a user submits a SQL query to the SQL query engine, this is <span class="No-Break">what occurs:</span></p>
			<ol>
				<li>First, the coordinator node receives the query and parses it to create a distributed <span class="No-Break"><strong class="bold">execution plan</strong></span><span class="No-Break">.</span></li>
				<li>The execution plan is divided into smaller tasks, and these tasks are assigned to the available <span class="No-Break">worker nodes.</span></li>
				<li>The worker nodes read data from the underlying data sources, perform computations, and exchange intermediate results <span class="No-Break">as needed.</span></li>
				<li>The coordinator node collects and combines the results from the worker nodes to produce the final query result, which is returned to the user of the <span class="No-Break">client application.</span></li>
			</ol>
			<p>This distributed architecture allows SQL query engines to leverage the combined computing power of multiple nodes, enabling them to process large datasets efficiently and deliver high-performance <span class="No-Break">query execution.</span></p>
			<p>In the case of Trino, it can directly connect to object storage systems such as Amazon S3, Azure Blob Storage, or Google Cloud Storage, where data is often stored in formats such as Parquet, ORC, or CSV. Trino can read and process this data directly from the object storage, without the need for intermediate data loading or transformation steps. This capability eliminates the need for a separate data ingestion process, reducing complexity and enabling faster time <span class="No-Break">to insight.</span></p>
			<p>Trino’s distributed architecture allows it to split the query execution across multiple worker nodes, each processing a portion of the data in parallel. This parallelization enables <a id="_idIndexMarker563"/>Trino to leverage the combined computing power of the cluster, resulting in high-performance query execution, even on <span class="No-Break">massive datasets.</span></p>
			<p>Furthermore, Trino’s cost-effectiveness stems from its ability to separate storage from compute. By leveraging object storage for data storage, organizations can take advantage of the low-cost and scalable nature of these storage systems, while dynamically provisioning compute resources (worker nodes) as needed for query execution. This separation of concerns allows organizations to optimize their infrastructure costs and scale resources independently based on their <span class="No-Break">specific needs.</span></p>
			<p>Now, let’s move on to a hands-on exercise and see how we can deploy Trino to Kubernetes and connect it to Amazon S3 as a <span class="No-Break">data source.</span></p>
			<h1 id="_idParaDest-148"><a id="_idTextAnchor148"/>Deploying Trino in Kubernetes</h1>
			<p>Trino <a id="_idIndexMarker564"/>deployment is very straightforward using its official <a id="_idIndexMarker565"/>Helm chart. First, we install the chart with <span class="No-Break">the following:</span></p>
			<pre class="console">
helm repo add trino <a href="https://trinodb.github.io/charts">https://trinodb.github.io/charts</a></pre>			<p>Next, we will configure the <strong class="source-inline">custom_values.yaml</strong> file. The full version of the file is available at <a href="https://github.com/PacktPublishing/Bigdata-on-Kubernetes/blob/main/Chapter09/trino/custom_values.yaml">https://github.com/PacktPublishing/Bigdata-on-Kubernetes/blob/main/Chapter09/trino/custom_values.yaml</a>. There are only a few custom configurations needed for this deployment. First, the <strong class="source-inline">server.workers</strong> parameter allows us to set the number of worker pods we want for the Trino cluster. We will set this to <strong class="source-inline">2</strong> but it is advisable to scale if you will run queries on <span class="No-Break">big data:</span></p>
			<pre class="console">
server:
  workers: 2</pre>			<p>In the <a id="_idIndexMarker566"/>block of parameters, set the <strong class="source-inline">image.tag</strong> parameter <a id="_idIndexMarker567"/>to <strong class="source-inline">432</strong> as this is the latest Trino version compatible with the chart version we are <span class="No-Break">using (0.19.0):</span></p>
			<pre class="console">
image:
  registry: ""
  repository: trinodb/trino
  tag: 432</pre>			<p>In the <strong class="source-inline">additionalCatalogs</strong> section, we must configure Trino to use the AWS Glue Data Catalog. The block should be as <span class="No-Break">shown here:</span></p>
			<pre class="console">
additionalCatalogs:
  hive: |
    connector.name=hive
    hive.metastore=glue</pre>			<p>Finally, we will set the <strong class="source-inline">service.type</strong> parameter to <strong class="source-inline">LoadBalancer</strong> to be able to access Trino from outside AWS (for testing only, not suited <span class="No-Break">for production):</span></p>
			<pre class="source-code">
service:
  type: LoadBalancer
  port: 8080</pre>			<p>And that’s it. We are ready to launch Trino <span class="No-Break">on Kubernetes.</span></p>
			<p class="callout-heading">Note</p>
			<p class="callout">We are not using any authentication method (password, OAuth, certificate, etc.). In a production environment, you should set an appropriate authentication method and keep the traffic to Trino private inside your VPC (private network), not exposing the load balancer to the internet as we are doing here. This simple configuration is just for training and <span class="No-Break">non-critical data.</span></p>
			<p>After <a id="_idIndexMarker568"/>saving the <strong class="source-inline">custom_values.yaml</strong> file, use the <a id="_idIndexMarker569"/>following command to <span class="No-Break">deploy Trino:</span></p>
			<pre class="console">
helm install trino trino/trino -f custom_values.yaml -n trino --create-namespace --version 0.19.0</pre>			<p>Now, we can check whether the deployment was successful with <span class="No-Break">the following:</span></p>
			<pre class="console">
kubectl get pods,svc -n trino</pre>			<p>This yields <span class="No-Break">this output:</span></p>
			<pre class="console">
NAME                                    READY   STATUS
pod/trino-coordinator-dbbbcf9d9-94wsn   1/1     Running
pod/trino-worker-6c58b678cc-6fgjs       1/1     Running
pod/trino-worker-6c58b678cc-hldrb       1/1     Running
NAME           TYPE          CLUSTER-IP       EXTERNAL-IP
service/trino  LoadBalancer  10.100.246.148   xxxx.us-east-1.elb.amazonaws.com</pre>			<p>The output was simplified to improve visualization. We can see one coordinator node and two workers, which is what we set. Now, copy the URL provided in the <strong class="source-inline">EXTERNAL-IP</strong> column of the output and paste it into your browser, adding <strong class="source-inline">:8080</strong> at the end. You should see a <span class="No-Break">login page.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer057">
					<img alt="Figure 9.1 – Trino login page" src="image/B21927_09_01.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.1 – Trino login page</p>
			<p>The default <a id="_idIndexMarker570"/>user is <strong class="source-inline">trino</strong>. No password is required <a id="_idIndexMarker571"/>as we did not set any in the deployment. After clicking <strong class="bold">Log In</strong>, you will see Trino’s <span class="No-Break">monitoring page.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer058">
					<img alt="Figure 9.2 – Trino’s monitoring page" src="image/B21927_09_02.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.2 – Trino’s monitoring page</p>
			<p>Next, we will use the same <strong class="source-inline">LoadBalancer</strong> URL to interact with Trino using DBeaver, an open source <span class="No-Break">SQL client.</span></p>
			<h2 id="_idParaDest-149"><a id="_idTextAnchor149"/>Connecting DBeaver with Trino</h2>
			<p>To connect <a id="_idIndexMarker572"/>with Trino, first, open DBeaver and <a id="_idIndexMarker573"/>create a new Trino connection. In the configuration section (<strong class="bold">General</strong>), insert the URL in the <strong class="bold">Host</strong> space and <strong class="source-inline">trino</strong> as the username. Leave the <span class="No-Break">password blank.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer059">
					<img alt="Figure 9.3 – DBeaver connection configuration" src="image/B21927_09_03.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.3 – DBeaver connection configuration</p>
			<p>Then, click on <strong class="bold">Test Connection …</strong>. If this is the first time you are configuring a Trino connection, DBeaver will automatically find the necessary drivers and show a new window asking you to download it. You can hit <strong class="bold">OK</strong> and go through the installation, then finish <span class="No-Break">the configuration.</span></p>
			<p>Before we try to access our data, we need to catalog some data and make it available in Glue Data Catalog, as well as setting up an IAM permission that will allow Trino to access the catalog and the underlying data. Let’s get <span class="No-Break">to it.</span></p>
			<p>Download the dataset from <a href="https://github.com/neylsoncrepalde/titanic_data_with_semicolon">https://github.com/neylsoncrepalde/titanic_data_with_semicolon</a> and store the CSV file in <a id="_idIndexMarker574"/>an S3 bucket inside a folder named <strong class="source-inline">titanic</strong>. Glue only <a id="_idIndexMarker575"/>understands tables from folders, not from <a id="_idIndexMarker576"/>isolated files. Now, we will create a <strong class="bold">Glue crawler</strong>. This crawler will look into the dataset, map its columns and column types, and register the metadata in <span class="No-Break">the catalog:</span></p>
			<ol>
				<li>In your AWS account, type <strong class="source-inline">Glue</strong> to enter the AWS Glue service, expand the <strong class="bold">Data Catalog</strong> option in the side menu, and click on <strong class="bold">Crawlers</strong> (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.4</em></span><span class="No-Break">).</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer060">
					<img alt="Figure 9.4 – AWS Glue landing page" src="image/B21927_09_04.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.4 – AWS Glue landing page</p>
			<ol>
				<li value="2">Next, click on <strong class="bold">Create crawler</strong> and start filling in the information. In the <strong class="bold">Name</strong> section, type <strong class="source-inline">bdok-titanic-crawler</strong> (you can choose any name). <span class="No-Break">Click </span><span class="No-Break"><strong class="bold">Next</strong></span><span class="No-Break">.</span></li>
				<li>On the next page, click on <strong class="bold">Add a data source</strong> and make sure <strong class="bold">S3</strong> is selected in the first field. Then, click on <strong class="bold">Browse S3</strong> to select the folder where the Titanic dataset is stored. The final path should look like this: <strong class="source-inline">s3://&lt;YOUR_BUCKET_NAME&gt;/titanic/</strong>. You can leave the other configurations as the default. Click on <strong class="bold">Add an S3 data source</strong> and <span class="No-Break">then </span><span class="No-Break"><strong class="bold">Next</strong></span><span class="No-Break">.</span></li>
				<li>In the next step, click on <strong class="bold">Create new IAM role</strong> to give the crawler permissions on AWS. Type the name <strong class="source-inline">AWSGlueServiceRole-titanic</strong>. <span class="No-Break">Click </span><span class="No-Break"><strong class="bold">Next</strong></span><span class="No-Break">.</span></li>
				<li>On the next page, click on <strong class="bold">Add database</strong>. A new window will pop up. Type <strong class="source-inline">bdok-database</strong>, click <strong class="bold">Create database</strong>, and then close this window and go back to the <strong class="bold">Glue crawler </strong><span class="No-Break"><strong class="bold">configuration</strong></span><span class="No-Break"> tab.</span></li>
				<li>Back to <a id="_idIndexMarker577"/>the crawler, hit the refresh button <a id="_idIndexMarker578"/>and select your new <strong class="bold">bdok-database</strong> database. Leave the other options as the default. <span class="No-Break">Click </span><span class="No-Break"><strong class="bold">Next</strong></span><span class="No-Break">.</span></li>
				<li>Now, in the last section, carefully review all the information and click <span class="No-Break"><strong class="bold">Create crawler</strong></span><span class="No-Break">.</span></li>
				<li>When it is ready, you will be taken to the crawler page on the AWS console. Click <strong class="bold">Run crawler</strong> to start the crawler. It should run for about 1 to 2 minutes (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.5</em></span><span class="No-Break">).</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer061">
					<img alt="Figure 9.5 – bdok-titanic-crawler" src="image/B21927_09_05.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.5 – bdok-titanic-crawler</p>
			<ol>
				<li value="9">After the crawler is finished, you can validate that the table was correctly cataloged by accessing the <strong class="bold">Data Catalog tables</strong> menu item. The <strong class="bold">titanic</strong> table should be listed with the <strong class="bold">bdok-database</strong> database (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.6</em></span><span class="No-Break">).</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer062">
					<img alt="Figure 9.6 – Glue Data Catalog tables" src="image/B21927_09_06.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.6 – Glue Data Catalog tables</p>
			<ol>
				<li value="10">Click on the <strong class="source-inline">titanic</strong> table’s name to check whether the columns were <span class="No-Break">correctly mapped.</span></li>
				<li>Now, we need <a id="_idIndexMarker579"/>to create an IAM policy that <a id="_idIndexMarker580"/>gives Kubernetes permission to access the catalog and the data stored in S3. To that, in the console, go to the <strong class="bold">IAM</strong> page and select <strong class="bold">Roles</strong>. In the search box, type <strong class="source-inline">studycluster</strong> and you will see two roles created for Kubernetes, one service role and one node instance role. We want to change permissions on the node instance role (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">).</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer063">
					<img alt="Figure 9.7 – IAM Roles page" src="image/B21927_09_07.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.7 – IAM Roles page</p>
			<ol>
				<li value="12">Click on the node instance role, then click on the <strong class="bold">Add permissions</strong> button and select <strong class="bold">Create </strong><span class="No-Break"><strong class="bold">inline policy</strong></span><span class="No-Break">.</span></li>
				<li>On the <strong class="bold">Specify permissions</strong> page, click to edit as a JSON document and paste the JSON file available in this GitHub repository: <a href="https://github.com/PacktPublishing/Bigdata-on-Kubernetes/blob/main/Chapter09/trino/iam/AthenaFullWithAllBucketsPolicy.json">https://github.com/PacktPublishing/Bigdata-on-Kubernetes/blob/main/Chapter09/trino/iam/AthenaFullWithAllBucketsPolicy.json</a> (<span class="No-Break"><em class="italic">Figure 9</em></span><em class="italic">.8</em>). This policy allows Athena and Glue permissions, as well as getting all S3 data from any bucket. Remember that this is a very open policy and should <a id="_idIndexMarker581"/>not be used in production. It is <a id="_idIndexMarker582"/>a best security practice to allow access only in the <span class="No-Break">needed buckets.</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer064">
					<img alt="Figure 9.8 – Specifying permissions" src="image/B21927_09_08.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.8 – Specifying permissions</p>
			<ol>
				<li value="14">Click <strong class="bold">Next</strong> and then save the policy as <strong class="source-inline">AthenaFullWithAllBucketsPolicy</strong> to facilitate this policy search later. Then, click on <strong class="bold">Create policy</strong>. And we are set <span class="No-Break">to go!</span></li>
			</ol>
			<p>Now, let’s get back to DBeaver and play with some queries. First, we need to find where the table is stored. Expand the Trino connection in DBeaver and you will see a database named <strong class="bold">hive</strong>. This is where data from the Glue Data Catalog is mirrored in Trino. Expand <strong class="bold">hive</strong> and you will see the <strong class="bold">bdok-database</strong> catalog there. If you expand <strong class="bold">Tables</strong>, you will see the <strong class="bold">titanic</strong> <span class="No-Break">dataset mapped.</span></p>
			<p>To test <a id="_idIndexMarker583"/>a query, right-click the <strong class="bold">hive</strong> database and <a id="_idIndexMarker584"/>select <strong class="bold">SQL Editor</strong> and then <strong class="bold">New SQL Script</strong>. Now, run <span class="No-Break">the query:</span></p>
			<pre class="console">
select * from hive."bdok-database".titanic</pre>			<p>You should see the results (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.9</em></span><span class="No-Break">):</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer065">
					<img alt="Figure 9.9 – DBeaver results from Trino" src="image/B21927_09_09.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.9 – DBeaver results from Trino</p>
			<p>And, of course, Trino can perform any calculations or aggregations we like. Let’s try a simple query to get the count and average age of all the passengers by <strong class="source-inline">pclass</strong> and <strong class="source-inline">sex</strong>. We will show the results ordered by <strong class="source-inline">sex</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">pclass</strong></span><span class="No-Break">.</span></p>
			<pre class="console">
select
    pclass,
    sex,
    COUNT(1) as people_count,
    AVG(age) as avg_age
from hive."bdok-database".titanic
group by pclass, sex
order by sex, pclass</pre>			<p>This <a id="_idIndexMarker585"/>query <a id="_idIndexMarker586"/>yields <span class="No-Break">this result:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer066">
					<img alt="Figure 9.10 – Simple query on Titanic dataset" src="image/B21927_09_10.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.10 – Simple query on Titanic dataset</p>
			<p>Now, let’s visit Trino’s monitoring page once again to see the query we just ran. Check the <strong class="bold">Finished</strong> box under <strong class="bold">Query details</strong> to see all queries; the first one shown is the query we just ran. Click on it to see <span class="No-Break">the details.</span></p>
			<p>That’s it! You <a id="_idIndexMarker587"/>have successfully deployed Trino on <a id="_idIndexMarker588"/>Kubernetes and used it to query data from a data lake on Amazon S3. In the next section, we will work <span class="No-Break">with Elasticsearch.</span></p>
			<h1 id="_idParaDest-150"><a id="_idTextAnchor150"/>Deploying Elasticsearch in Kubernetes</h1>
			<p>While Trino provides a powerful SQL interface for querying structured data in your data lake, many <a id="_idIndexMarker589"/>modern applications also need to analyze semi-structured and unstructured data, such as logs, metrics, and text, in real time. For <a id="_idIndexMarker590"/>these types of use cases, Elasticsearch (or the ELK Stack, as it came to be known, referring to Elasticsearch, Logstash, and Kibana) provides a <span class="No-Break">powerful solution.</span></p>
			<p>Elasticsearch is an open source, distributed, RESTful search and analytics engine built on top of Apache Lucene. It is designed to store, search, and analyze large volumes of data quickly and in near <span class="No-Break">real time.</span></p>
			<p>At its core, Elasticsearch is a NoSQL database that uses JSON documents to represent data. It indexes all data in every field and uses advanced data structures and indexing techniques to make searches <span class="No-Break">extremely fast.</span></p>
			<h2 id="_idParaDest-151"><a id="_idTextAnchor151"/>How Elasticsearch stores, indexes and manages data</h2>
			<p>Data is stored in Elasticsearch in individual JSON documents. These documents are grouped <a id="_idIndexMarker591"/>into types within an index. You can think of an index like a database table that has a defined mapping <span class="No-Break">or schema.</span></p>
			<p>To add data to Elasticsearch, you make an HTTP request to the appropriate index with the JSON document in the request body. Elasticsearch automatically indexes all data in the document’s fields using advanced data structures such as the inverted index from <span class="No-Break">Apache Lucene.</span></p>
			<p>This indexing <a id="_idIndexMarker592"/>process optimizes data for extremely fast queries and aggregations. Elasticsearch distributes data across shards, which can be allocated to different nodes in the cluster for redundancy <span class="No-Break">and scalability.</span></p>
			<p>When you want to query or retrieve data from Elasticsearch, you use the RESTful search API to define the query using a simple JSON request body. Results are returned in JSON format <span class="No-Break">as well.</span></p>
			<p>Elasticsearch is designed as a distributed system from the ground up. It can scale out to hundreds of servers and handle petabytes of data. Its core elements are <span class="No-Break">as follows:</span></p>
			<ul>
				<li><strong class="bold">Nodes</strong>, running <a id="_idIndexMarker593"/>instances of Elasticsearch that together form <span class="No-Break">a </span><span class="No-Break"><strong class="bold">cluster</strong></span></li>
				<li><strong class="bold">Indexes</strong>, which <a id="_idIndexMarker594"/>are collections of documents that have <span class="No-Break">similar characteristics</span></li>
				<li><strong class="bold">Shards</strong>, which are <a id="_idIndexMarker595"/>low-level partitions of an index that contain a slice of all the documents in <span class="No-Break">the index</span></li>
				<li><strong class="bold">Replicas</strong>, which are <a id="_idIndexMarker596"/>copies of a shard for redundancy and <span class="No-Break">improved performance</span></li>
			</ul>
			<p>At the core <a id="_idIndexMarker597"/>of Elasticsearch’s distributed architecture is the sharding system. Sharding refers to horizontally splitting an Elasticsearch index into multiple pieces, called shards. This allows the index data to be distributed across multiple nodes in the cluster, providing several <span class="No-Break">key benefits:</span></p>
			<ul>
				<li><strong class="bold">Horizontal scalability</strong>: By distributing shards across nodes, Elasticsearch can effectively <a id="_idIndexMarker598"/>scale out to handle more data and higher query/indexing throughput. As the dataset grows, you can simply add more nodes to the cluster and Elasticsearch will automatically migrate shards to balance <span class="No-Break">the load.</span></li>
				<li><strong class="bold">High availability</strong>: Each shard can have one or more replica shards. A replica is a full <a id="_idIndexMarker599"/>copy of the primary shard. Replicas provide redundancy and high availability – if a node hosting a primary shard fails, Elasticsearch will automatically promote a replica as the new primary to <span class="No-Break">take over.</span></li>
				<li><strong class="bold">Parallelization of operations</strong>: Since <a id="_idIndexMarker600"/>index operations such as searches and aggregations are executed in parallel on each shard, having more shards allows greater parallelization and thus <span class="No-Break">higher performance.</span></li>
			</ul>
			<p>When you create an index in Elasticsearch, you need to specify the number of primary shards the index should have. For example, if you configure an index with three primary shards, Elasticsearch will horizontally partition the index data into three shards and distribute them across nodes in <span class="No-Break">the cluster.</span></p>
			<p>Each primary shard can also have zero or more replica shards configured. A common setup is to have one replica, meaning there are two copies of each shard – the primary and one replica. The replica shards are also distributed across nodes in the cluster, with each replica on a different node than its respective primary <span class="No-Break">for redundancy.</span></p>
			<p>Elasticsearch <a id="_idIndexMarker601"/>automatically manages shard allocation across nodes using a shard allocation strategy. The default is to spread shards across as many nodes as possible to balance the load. As nodes are added or removed from the cluster, Elasticsearch will automatically migrate shards to rebalance <span class="No-Break">the cluster.</span></p>
			<p>Queries are executed in parallel on each shard, with results being merged to produce the final result set. Writes (indexing new documents) are sent to a primary shard, which is responsible for validating the data, making changes persistent, and replicating changes to associated <span class="No-Break">replica shards.</span></p>
			<p>The number of shards configured for an index is fixed at index creation time. It cannot be changed later, so proper shard planning is important. Having more shards allows greater parallelization, but too many shards can also <span class="No-Break">increase overhead.</span></p>
			<p>A good rule of thumb is to start with enough shards (3 to 5 shards) that index data can be distributed across multiple nodes. The number can be increased if the index grows very large and more parallelization is needed. However, having hundreds or thousands of shards is generally not recommended due to increased cluster <span class="No-Break">management overhead.</span></p>
			<p>Now, let’s see how to deploy Elasticsearch <span class="No-Break">on Kubernetes.</span></p>
			<h2 id="_idParaDest-152"><a id="_idTextAnchor152"/>Elasticsearch deployment</h2>
			<p>Here, we will <a id="_idIndexMarker602"/>work with <strong class="bold">Elastic Cloud on Kubernetes</strong> (<strong class="bold">ECK</strong>), an official <a id="_idIndexMarker603"/>Elastic operator that allows you to provision, manage, and orchestrate Elastic Stack applications on Kubernetes clusters. We will use the official Helm chart to install the operator. In your terminal, type <span class="No-Break">the following:</span></p>
			<pre class="console">
helm repo add elastic <a href="https://helm.elastic.co">https://helm.elastic.co</a>
helm install elastic-operator elastic/eck-operator -n elastic --create-namespace --version 2.12.1</pre>			<p>This will download the Helm chart locally and deploy the default definitions for the Elastic Stack in a new environment named <strong class="source-inline">elastic</strong>. Here, we will use the <strong class="source-inline">2.12.1</strong> version of the <span class="No-Break">Helm Chart.</span></p>
			<p>Now, we will <a id="_idIndexMarker604"/>configure the deployment for an Elasticsearch cluster. The <strong class="source-inline">elastic_cluster.yaml</strong> YAML file does <span class="No-Break">the trick.</span></p>
			<pre class="console">
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: elastic
spec:
  version: 8.13.0
  volumeClaimDeletePolicy: DeleteOnScaledownAndClusterDeletion
  nodeSets:
  - name: default
    count: 2
    podTemplate:
      spec:
        containers:
        - name: elasticsearch
          resources:
            requests:
              memory: 2Gi
              cpu: 1
            limits:
              memory: 2Gi
        initContainers:
        - name: sysctl
          securityContext:
            privileged: true
            runAsUser: 0
          command: ['sh', '-c', 'sysctl -w vm.max_map_count=262144']
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 5Gi
        storageClassName: gp2</pre>			<p>Let’s take a <a id="_idIndexMarker605"/>closer look at this code. The first block specifies the API version and the kind of Kubernetes resource we are defining. In this case, it’s an <strong class="source-inline">Elasticsearch</strong> resource from the <strong class="source-inline">elasticsearch.k8s.elastic.co/v1</strong> API group, which is provided by the ECK operator. The <strong class="source-inline">metadata</strong> block specifies the name of the cluster, in this case, <strong class="source-inline">elastic</strong>. Within the <strong class="source-inline">spec</strong> block, we set the Elasticsearch version to be used (<strong class="source-inline">8.13.0</strong>) and a <a id="_idIndexMarker606"/>policy that determines when the <strong class="bold">PersistentVolumeClaims</strong> (<strong class="bold">PVCs</strong>) associated with the Elasticsearch data volumes should be deleted. The <strong class="source-inline">DeleteOnScaledownAndClusterDeletion</strong> policy deletes the PVCs when the Elasticsearch cluster is scaled down or <span class="No-Break">deleted entirely.</span></p>
			<p>The <strong class="source-inline">nodeSets</strong> block defines <a id="_idIndexMarker607"/>the configuration for the Elasticsearch nodes. In this case, we have a single node set named <strong class="source-inline">default</strong> with a count of <strong class="source-inline">2</strong>, meaning we will have two Elasticsearch nodes in the cluster. The <strong class="source-inline">podTemplate</strong> block specifies <a id="_idIndexMarker608"/>the configuration for the Pods that will run the Elasticsearch containers. Here, we define the resource requests and limits for the Elasticsearch <a id="_idIndexMarker609"/>container, setting the memory request and limit to 2 GiB and the CPU request to <span class="No-Break">one vCPU.</span></p>
			<p>The <strong class="source-inline">initContainers</strong> block is <a id="_idIndexMarker610"/>a recommendation from the official Elastic documentation for a production environment. It defines a container that will run before the main Elasticsearch container starts. In this case, we have an <strong class="source-inline">initContainer</strong> named <strong class="source-inline">sysctl</strong> that runs with privileged security context and sets the <strong class="source-inline">vm.max_map_count</strong> kernel setting to <strong class="source-inline">262144</strong>. This setting is recommended for running Elasticsearch on Linux to allow for a higher limit on memory-mapped areas <span class="No-Break">in use.</span></p>
			<p>Finally, the <strong class="source-inline">volumeClaimTemplates</strong> block defines the PVCs that will be used to store <a id="_idIndexMarker611"/>Elasticsearch data. In this case, we have a single PVC named <strong class="source-inline">elasticsearch-data</strong> with a requested storage size of 5 GiB. <strong class="source-inline">accessModes</strong> specifies that the volume should be <strong class="source-inline">ReadWriteOnce</strong>, meaning it can be mounted as read-write by a single node. <strong class="source-inline">storageClassName</strong> is set to <strong class="source-inline">gp2</strong>, which is an AWS EBS storage class for general-purpose <span class="No-Break">SSD volumes.</span></p>
			<p>After saving this file locally, run the following command to deploy an <span class="No-Break">Elasticsearch cluster:</span></p>
			<pre class="console">
kubectl apply -f elastic_cluster.yaml -n elastic</pre>			<p>Monitor the deployment with <span class="No-Break">the following:</span></p>
			<pre class="console">
kubectl get pods -n elastic</pre>			<p>Alternatively, you can use <span class="No-Break">the following:</span></p>
			<pre class="console">
kubectl get elastic -n elastic</pre>			<p>This will give a little more information. Note that this deployment will take a few minutes to finish. You can also get some detailed information on the cluster with <span class="No-Break">the following:</span></p>
			<pre class="console">
kubectl describe elastic -n elastic</pre>			<p>In the output, <strong class="source-inline">HEALTH</strong> should be <strong class="source-inline">green</strong> and the <strong class="source-inline">PHASE</strong> column should <span class="No-Break">display </span><span class="No-Break"><strong class="source-inline">Ready</strong></span><span class="No-Break">:</span></p>
			<pre class="console">
NAME      HEALTH   NODES   VERSION   PHASE
elastic   green    2       8.13.0    Ready</pre>			<p>Now, let’s move <a id="_idIndexMarker612"/>on to Kibana. We will follow the same process. The first thing to do is to set a YAML file named <strong class="source-inline">kibana.yaml</strong> with the <span class="No-Break">deployment configuration.</span></p>
			<pre class="console">
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: kibana
spec:
  version: 8.13.0
  count: 1
  elasticsearchRef:
    name: elastic
  http:
    service:
      spec:
        type: LoadBalancer
  podTemplate:
    spec:
      containers:
      - name: kibana
        env:
          - name: NODE_OPTIONS
            value: "--max-old-space-size=2048"
        resources:
          requests:
            memory: 1Gi
            cpu: 0.5
          limits:
            memory: 2Gi
            cpu: 2</pre>			<p>This code is <a id="_idIndexMarker613"/>very similar to the previous one, but simpler. The main differences are in the <strong class="source-inline">spec</strong> block. First, the <strong class="source-inline">elasticsearchRef</strong> parameter specifies the name of the Elasticsearch cluster that Kibana should connect to. In this case, it’s referencing the Elasticsearch cluster we created before named <strong class="source-inline">elastic</strong>. The http block configures the Kubernetes Service that will expose the Kibana deployment. Specifically, we are setting the type of the Service to <strong class="source-inline">LoadBalancer</strong>, which means that a load balancer will be provisioned by the cloud provider to distribute traffic across the Kibana instances. Finally, in the <strong class="source-inline">podTemplate</strong> block, we have an <strong class="source-inline">env</strong> configuration that sets an environment variable, <strong class="source-inline">NODE_OPTIONS</strong>, with the value <strong class="source-inline">--max-old-space-size=2048</strong>, which increases the maximum heap size <span class="No-Break">for Kibana.</span></p>
			<p>Now, we are ready <span class="No-Break">to deploy:</span></p>
			<pre class="console">
kubectl apply -f kibana.yaml -n elastic</pre>			<p>We use the same commands as before to monitor whether the deployment was successful. Now, we need to access the automatically generated password for Elastic and Kibana. We can do this with the <span class="No-Break">following command:</span></p>
			<pre class="console">
kubectl get secret elastic-es-elastic-user -n elastic -o go-template='{{.data.elastic | base64decode}}'</pre>			<p>This command <a id="_idIndexMarker614"/>will print the generated password on the screen. Copy it and keep it safe. Now, run <span class="No-Break">the following:</span></p>
			<pre class="console">
kubectl get svc -n elastic</pre>			<p>To get the services list, copy the URL address for the LoadBalancer and paste it into a browser, adding <strong class="source-inline">:5601</strong> at the end and https:// at the beginning. Kibana will not accept regular HTTP protocol connections. You should see the login page as in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.11</em></span><span class="No-Break">.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer067">
					<img alt="" role="presentation" src="image/B21927_09_11.jpg"/>
				</div>
			</div>
			<p class="IMG---Figure">FIgure 9.11 – Kibana login page</p>
			<p>After inserting <a id="_idIndexMarker615"/>the username and password, you should be able to access Kibana’s first empty page (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.12</em></span><span class="No-Break">).</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer068">
					<img alt="Figure 9.12 – Kibana’s first empty page" src="image/B21927_09_12.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.12 – Kibana’s first empty page</p>
			<p>Click on <strong class="bold">Explore on my own</strong> and you <a id="_idIndexMarker616"/>will now be able to play with Elastic as much as you want (although it does not have any data just yet). To do that, we will experiment with our (well-known) Titanic dataset. On the <strong class="bold">Home</strong> page, click on the menu in the upper-left corner and then click on <strong class="bold">Stack Management</strong> (the last option). On the next page, in the left menu, click on <strong class="bold">Data Views</strong> and then click on the <strong class="bold">Upload a file</strong> button in the center (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.13</em></span><span class="No-Break">).</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer069">
					<img alt="Figure 9.13 – Upload a file option in Kibana" src="image/B21927_09_13.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.13 – Upload a file option in Kibana</p>
			<p>Now, select the <a id="_idIndexMarker617"/>Titanic dataset CSV file you already have and upload it to Kibana. You will see a page with the mapped contents from the file (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.14</em></span><span class="No-Break">).</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer070">
					<img alt="Figure 9.14 – Titanic dataset mapped contents" src="image/B21927_09_14.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.14 – Titanic dataset mapped contents</p>
			<p>Now, click on <strong class="bold">Import</strong>. On the next page, you will be prompted for an index creation. Name the <a id="_idIndexMarker618"/>index <strong class="source-inline">titanic</strong> and make sure that the <strong class="bold">Create data view</strong> option is checked. Click on <strong class="bold">Import</strong> (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.15</em></span><span class="No-Break">).</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer071">
					<img alt="Figure 9.15 – Kibana – creating an index" src="image/B21927_09_15.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.15 – Kibana – creating an index</p>
			<p>In a few seconds, you should see a success screen. Now, let’s play a little bit with this data with visualizations. Go back to the home page and, in the left menu, click on <strong class="bold">Dashboards</strong>. Then, click on <strong class="bold">Create a dashboard</strong> and then on <strong class="bold">Create visualization</strong>. This will get you to the visualization building in Kibana (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.16</em></span><span class="No-Break">).</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer072">
					<img alt="" role="presentation" src="image/B21927_09_16.jpg"/>
				</div>
			</div>
			<p class="IMG---Figure">FIgure 9.16 – Kibana visualization creation</p>
			<p>Now, let’s build <a id="_idIndexMarker619"/>some quick visualizations. On the right side of the page, select the type of visualization (let’s keep <strong class="bold">Bar vertical stacked</strong>). For <strong class="bold">Horizontal axis</strong>, drag and drop the <strong class="bold">Pclass</strong> field. For <strong class="bold">Vertical axis</strong>, drag and drop the <strong class="bold">Fare</strong> field. As it is a numeric field, Kibana will automatically suggest the median as an aggregation function. Click on it to change it to <strong class="bold">Average</strong>. For <strong class="bold">Breakdown</strong>, drag and drop the <strong class="bold">Sex</strong> field. We should end up with a nice bar graph, as shown in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.17</em></span><span class="No-Break">.</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer073">
					<img alt="Figure 9.17 – Average fare price per sex and Pclass" src="image/B21927_09_17.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.17 – Average fare price per sex and Pclass</p>
			<p>Click on <strong class="bold">Save and return</strong> to view your newly created graphic on a new dashboard. Let’s do another quick analysis. Click <strong class="bold">Create visualization</strong> again. This time, we will make a scatter plot with <strong class="bold">Age</strong> and <strong class="bold">Fare</strong> to see whether there is any correlation between those variables. Drop <strong class="bold">Age</strong> in <strong class="bold">Horizontal axis</strong> and <strong class="bold">Fare</strong> in <strong class="bold">Vertical axis</strong>. Click on <strong class="bold">Vertical axis</strong> to change the aggregation function to <strong class="bold">Average</strong>. Now, you have a nice scatter plot <a id="_idIndexMarker620"/>showing the interaction between those two variables. No significant correlation so far. Let’s add the <strong class="bold">Pclass</strong> field as the breakdown and we will get a cool visualization of the data (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.18</em></span><span class="No-Break">).</span></p>
			<p class="IMG---Figure"> </p>
			<div>
				<div class="IMG---Figure" id="_idContainer074">
					<img alt="Figure 9.18 – Scatter plot in Kibana" src="image/B21927_09_18.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.18 – Scatter plot in Kibana</p>
			<p>Now, click on <strong class="bold">Save and return</strong> to see your new visualization on the dashboard. Finally, let’s try something different. We will just show the number of Titanic survivors. Start a new visualization and, on the left menu, press the <strong class="bold">+</strong> button right next to the <strong class="bold">Records</strong> field. Kibana automatically suggests a simple <strong class="bold">Legacy metric</strong> visualization. In the top part, we will filter the field “Survived = 1” to count just the survivors. Click on <strong class="bold">Update</strong>. You should see the number <strong class="bold">342</strong> on the screen. Now, click on <strong class="bold">Count of Records</strong> in the right panel and change <strong class="bold">Name</strong> to <strong class="source-inline">Survivors</strong> (<span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.19</em></span><span class="No-Break">).</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer075">
					<img alt="Figure 9.19 – Survivors count visualization" src="image/B21927_09_19.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.19 – Survivors count visualization</p>
			<p>Then, click <strong class="bold">Save and return</strong> and rearrange the dashboard manually as you wish (a simple <a id="_idIndexMarker621"/>example is shown in <span class="No-Break"><em class="italic">Figure 9</em></span><span class="No-Break"><em class="italic">.20</em></span><span class="No-Break">).</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer076">
					<img alt="Figure 9.20 – Your first Kibana dashboard" src="image/B21927_09_20.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 9.20 – Your first Kibana dashboard</p>
			<p>And that’s it! You successfully deployed Elasticsearch and Kibana on Kubernetes, added data manually, and built a dashboard (with lots of potential). Feel free to play with Kibana, trying out other datasets <span class="No-Break">and visualizations.</span></p>
			<h1 id="_idParaDest-153"><a id="_idTextAnchor153"/>Summary</h1>
			<p>In this chapter, we explored two powerful tools, Trino and Elasticsearch, which enable effective data consumption and analysis in a Kubernetes-based big data architecture. We learned the importance of having a robust data consumption layer that bridges the gap between data repositories and business analysts, allowing them to extract valuable insights and make <span class="No-Break">informed decisions.</span></p>
			<p>We learned how to deploy Trino, a distributed SQL query engine, on Kubernetes and leverage its ability to directly query data stored in object storage systems such as Amazon S3. This eliminates the need for a traditional data warehouse and provides a cost-effective, scalable, and flexible solution for querying large datasets. We acquired hands-on experience in deploying Trino, configuring it to use the AWS Glue Data Catalog, and executing SQL queries against our <span class="No-Break">data lake.</span></p>
			<p>Additionally, we dove into Elasticsearch, a highly scalable and efficient search engine, along with Kibana, its powerful data visualization tool. We learned how to deploy Elasticsearch on Kubernetes using the ECK operator, index data for optimized storage and retrieval, and build simple yet insightful visualizations using Kibana. This combination equips us with the ability to analyze real-time data streams and uncover valuable patterns <span class="No-Break">and trends.</span></p>
			<p>The skills learned in this chapter are crucial in today’s data-driven world, where organizations need to effectively consume and analyze vast amounts of data to make informed business decisions. Trino and Elasticsearch can also be extremely helpful for business teams who are not acquainted with coding to explore data (with simple SQL queries or in a visual way) and enhance their <span class="No-Break">everyday decision-making.</span></p>
			<p>In the next chapter, we will put all the pieces we have seen so far together to build a complete data pipeline <span class="No-Break">on Kubernetes.</span></p>
		</div>
	</body></html>