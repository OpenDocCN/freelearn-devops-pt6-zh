<html><head></head><body><div id="book-content"><div id="sbo-rt-content"><div id="_idContainer117" epub:type="chapter">&#13;
			<h1 id="_idParaDest-183" class="chapter-number"><a id="_idTextAnchor183"/>14</h1>&#13;
			<h1 id="_idParaDest-184"><a id="_idTextAnchor184"/>Wrapping Up: GenAI Coding Assistants and Further Reading</h1>&#13;
			<p>In the last few years, GenAI has significantly evolved, and there are now numerous GenAI-based coding assistants that can help with creating, launching, and monitoring K8s clusters. Since the field is evolving at a rapid pace, in this chapter, we will cover some of the coding assistants, evolving trends, and good references to read for <span class="No-Break">further information.</span></p>&#13;
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>&#13;
			<ul>&#13;
				<li>GenAI-powered <span class="No-Break">coding assistants</span></li>&#13;
				<li>GenAI-powered observability <span class="No-Break">and optimization</span></li>&#13;
				<li>Amazon Q Developer walk-through with <span class="No-Break">Amazon EKS</span></li>&#13;
				<li>References for <span class="No-Break">further reading</span></li>&#13;
			</ul>&#13;
			<h1 id="_idParaDest-185"><a id="_idTextAnchor185"/>Technical requirements</h1>&#13;
			<p>In this chapter, we will be using the following services, some of which require you to set up <span class="No-Break">an account:</span></p>&#13;
			<ul>&#13;
				<li><span class="No-Break">AWS</span><span class="No-Break"> (</span><a href="https://signin.aws.amazon.com/signup?request_type=register"><span class="No-Break">https://signin.aws.amazon.com/signup?request_type=register</span></a><span class="No-Break">)</span></li>&#13;
				<li>Docker Desktop (<a href="https://www.docker.com/products/docker-desktop/">https://www.docker.com/products/docker-desktop/</a>) or <span class="No-Break"><strong class="source-inline">Finch</strong></span><span class="No-Break"> (</span><a href="https://runfinch.com/"><span class="No-Break">https://runfinch.com/</span></a><span class="No-Break">)</span></li>&#13;
			</ul>&#13;
			<h1 id="_idParaDest-186"><a id="_idTextAnchor186"/>GenAI-powered coding assistants</h1>&#13;
			<p>GenAI-powered assistants <a id="_idIndexMarker1278"/>are transforming K8s cluster creation, deployment, and management by automating config file creation, workload scaling, and monitoring. Some GenAI-based coding assistants that can help with K8s clusters are <span class="No-Break">the following:</span></p>&#13;
			<ul>&#13;
				<li><strong class="source-inline">Amazon Q Developer</strong> (<a href="https://aws.amazon.com/q/developer/">https://aws.amazon.com/q/developer/</a>): This is Amazon’s GenAI assistant, designed to help with cloud-based development, including K8s management on <a id="_idIndexMarker1279"/><strong class="bold">Amazon</strong> <strong class="bold">Elastic Kubernetes Service</strong> (<strong class="bold">EKS</strong>). It simplifies writing deployment manifests, automating <strong class="bold">infrastructure as code</strong> (<strong class="bold">IaC</strong>), and <a id="_idIndexMarker1280"/>diagnosing issues in K8s deployment. It can also assist with optimizing cluster configurations by providing recommendations for resource allocation, autoscaling settings, and networking configurations. In this chapter, we will provide a walk-through on how to use AWS Q Developer for an EKS cluster deployment. We chose Amazon Q Developer for the walk-through since we are operating in an <span class="No-Break">AWS environment.</span></li>&#13;
				<li><strong class="source-inline">GitHub Copilot</strong> (<a href="https://github.com/features/copilot">https://github.com/features/copilot</a>): This is an AI-powered coding assistant that can integrate into IDEs, such as Visual Studio Code and JetBrains. It can create K8s deployment code, such as deployment manifests, Helm charts, and CI/CD pipeline configurations. By providing inline suggestions and auto-completion, Copilot<a id="_idIndexMarker1281"/> can accelerate K8s automation and ensure adherence to <span class="No-Break">best practices.</span></li>&#13;
				<li><strong class="source-inline">Google Gemini Code Assist</strong> (<a href="https://codeassist.google/products/business">https://codeassist.google/products/business</a>): This coding assistant can work across the software development life cycle. It can help with K8s workload optimization and infrastructure management and provide insights into scaling policies, cluster health, and performance tuning. By leveraging AI, Gemini suggests ways to optimize cost efficiency and minimize downtime, especially for  <span class="No-Break">GKE clusters.</span></li>&#13;
				<li><strong class="source-inline">Microsoft Copilot in Azure</strong> (<a href="https://azure.microsoft.com/en-us/products/copilot">https://azure.microsoft.com/en-us/products/copilot</a>): This can assist developers working<a id="_idIndexMarker1282"/> with <strong class="bold">Azure Kubernetes Service</strong> (<strong class="bold">AKS</strong>). It provides recommendations for cluster scaling, node pool configurations, and security policies. Azure AI Copilot also integrates with Terraform and Bicep, allowing DevOps teams to automate K8s infrastructure <span class="No-Break">provisioning efficiently.</span></li>&#13;
				<li><strong class="source-inline">IBM watsonx Code Assistant</strong> (<a href="https://www.ibm.com/products/watsonx-code-assistant">https://www.ibm.com/products/watsonx-code-assistant</a>): This is particularly useful for teams using OpenShift and K8s in hybrid cloud environments. It automates application containerization, suggesting optimizations for container images, network policies, and security hardening. It also integrates with Red Hat OpenShift GitOps, allowing AI-driven automation of CI/CD pipelines and application <span class="No-Break">deployment strategies.</span></li>&#13;
				<li>K8sGPT (<a href="https://k8sgpt.ai/">https://k8sgpt.ai/</a>): This is an open source tool that brings AI-powered diagnostics to K8s clusters by leveraging GenAI to identify, analyze, and explain issues. It can be run locally using a CLI or deployed in a K8s cluster for continuous analysis. It supports a variety of AI backends, including OpenAI, or even local LLMs through tools such as Ollama or LangChain, giving teams flexibility based on their data privacy needs. It scans various K8s resources, such as Pods, Services, Deployments, and Nodes, and detects problems such as crash loops, configuration errors, or failed health checks. Instead of K8s error messages, K8sGPT can provide clear, human-readable explanations along with suggested remediation steps, making it especially helpful for developers and SREs troubleshooting <span class="No-Break">complex environments.</span><p class="list-inset">For example, instead of a vague <strong class="source-inline">CrashLoopBackOff</strong> error, K8sGPT might explain that a Pod is <a id="_idIndexMarker1283"/>crashing because it’s missing a required secret or has a misconfigured <span class="No-Break">environment variable.</span></p></li>&#13;
			</ul>&#13;
			<p>In this section, we explored several GenAI-powered coding assistants that aid in software deployment, generating IaC, and debugging K8s clusters. However, when working with AI-generated configurations, such as Amazon Q Developer or any other GenAI assistant, it’s essential to validate output manually and test it in a staging environment before deployment. Tools such as <strong class="source-inline">terraform plan</strong>, <strong class="source-inline">docker scan</strong>, and <strong class="source-inline">kubeval</strong> can help verify syntactic correctness and highlight configuration issues. Consider using policy-as-code frameworks, such<a id="_idIndexMarker1284"/> as <strong class="bold">Open Policy Agent</strong> (<strong class="bold">OPA</strong>), to enforce security <span class="No-Break">standards automatically.</span></p>&#13;
			<p>In the next section, we will discuss how GenAI is transforming the K8s observability and <span class="No-Break">optimization landscape.</span></p>&#13;
			<h1 id="_idParaDest-187"><a id="_idTextAnchor187"/>GenAI-powered observability and optimization</h1>&#13;
			<p>Besides generating <a id="_idIndexMarker1285"/>the K8s manifest files, GenAI is also transforming K8s operations by automating security, monitoring, and optimization. These AI-powered solutions are making K8s environments more efficient, cost-effective, and self-healing. Some good examples are <span class="No-Break">the following:</span></p>&#13;
			<ul>&#13;
				<li><strong class="bold">AI-powered K8s autoscaling</strong>: Traditional K8s autoscalers rely on CPU and memory thresholds, but AI-powered autoscalers predict workload demands and dynamically adjust resources to optimize performance and costs. Tools such as StormForge (<a href="https://stormforge.io/">https://stormforge.io/</a>) and PredictKube (<a href="https://dysnix.com/predictkube">https://dysnix.com/predictkube</a>) leverage <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) to enhance<a id="_idIndexMarker1286"/> autoscaling strategies, preventing over-provisioning while ensuring availability during <span class="No-Break">traffic spikes.</span></li>&#13;
				<li><strong class="bold">AI-assisted K8s governance and policy enforcement</strong>: AI-driven governance tools enforce compliance and security policies in K8s clusters. By integrating ML models trained in historical data and policy violations, one can go beyond static rule definitions. For<a id="_idIndexMarker1287"/> example, one can analyze historical policy violations and detect patterns, such as which resources are most affected and under what conditions. Based on learned patterns, AI can suggest new rules to tighten access beyond the static rules for policy enforcers, such <span class="No-Break">as OPA.</span></li>&#13;
				<li><strong class="bold">GenAI for K8s workflows and observability</strong>: AI-powered observability tools analyze logs, metrics, and traces to identify anomalies before they impact applications. Solutions such as New Relic AI (<a href="https://newrelic.com/platform/new-relic-ai">https://newrelic.com/platform/new-relic-ai</a>) and Dynatrace Davis AI (<a href="https://www.dynatrace.com/platform/artificial-intelligence/">https://www.dynatrace.com/platform/artificial-intelligence/</a>) can automate root cause analysis and alert prioritization, helping DevOps reduce downtime and improve troubleshooting efficiency. Prometheus with AI models enhances smart alerting by filtering out non-critical events and focusing on <span class="No-Break">actionable insights.</span></li>&#13;
				<li><strong class="bold">Envoy AI Gateway</strong> (<a href="https://aigateway.envoyproxy.io/docs/">https://aigateway.envoyproxy.io/docs/</a>): This was developed to simplify the<a id="_idIndexMarker1288"/> increasingly complex task of connecting modern applications to GenAI services. Built on Envoy Proxy, the project offers a unified layer to manage LLM/AI traffic at scale. Key goals of the project include providing seamless routing and policy control for GenAI workloads, supporting automatic failover for resilient service delivery, securing AI traffic with upstream authorization, and enabling usage limits through a flexible policy framework. At its core, Envoy AI Gateway aims to make GenAI infrastructure easier to integrate and safer to operate. To use Envoy AI Gateway’s observability capabilities, users can configure Prometheus to scrape metrics exposed by the gateway, which include AI-specific insights such as token usage, time to first token, and per-token latency. These metrics follow OpenTelemetry’s GenAI semantic conventions and are designed to give visibility into how GenAI models are performing <span class="No-Break">in production.</span></li>&#13;
				<li><strong class="bold">Generative AI for K8s IaC</strong>: AI-powered assistants accelerate K8s infrastructure deployment <a id="_idIndexMarker1289"/>by automatically generating YAML, Terraform, and Helm configurations. Tools such as Amazon Q Developer enable teams to describe their desired infrastructure in plain language and receive <span class="No-Break">optimized configurations.</span></li>&#13;
				<li><strong class="bold">AI-powered K8s cost optimization (FinOps)</strong>: Optimizing cloud costs in K8s environments is challenging due to the dynamic nature of workloads. AI-powered FinOps solutions such as Harness (<a href="https://www.harness.io/solutions/finops-excellence">https://www.harness.io/solutions/finops-excellence</a>) and Cast AI (<a href="https://cast.ai/">https://cast.ai/</a>) can analyze cluster utilization, suggest cost-saving measures, and adjust resource allocations to minimize waste. These tools help organizations optimize their K8s spending while maintaining <span class="No-Break">application performance.</span></li>&#13;
				<li><strong class="bold">GenAI-powered K8s ChatOps</strong>: AI-driven ChatOps tools enhance K8s management by enabling conversational interactions within platforms such as Slack and Microsoft Teams. Botkube AI Assistant (<a href="https://botkube.io/">https://botkube.io/</a>) allows users to query K8s clusters and execute commands via chat, while K8sGPT functions as an AI-powered K8s SRE, diagnosing and resolving cluster issues autonomously. AI-driven self-healing mechanisms can detect failures, restart Pods, and proactively fix issues without <span class="No-Break">manual intervention.</span></li>&#13;
			</ul>&#13;
			<p>In this section, we explored various AI-powered tools that can help transform K8s environments. These tools can be leveraged to automate key K8s operations such as autoscaling, security, cost<a id="_idIndexMarker1290"/> optimization, and observability. In the next section, we’ll walk through how to use a GenAI assistant to simplify the development of <span class="No-Break">K8s applications.</span></p>&#13;
			<h1 id="_idParaDest-188"><a id="_idTextAnchor188"/>Amazon Q Developer walk-through with EKS</h1>&#13;
			<p>In this section, we<a id="_idIndexMarker1291"/> will explore how GenAI-powered<a id="_idIndexMarker1292"/> assistants, such as Amazon Q Developer, can simplify the development of GenAI applications, streamline the creation and management of K8s clusters, and simplify deployments. Amazon Q Developer introduced a new <em class="italic">agentic experience</em> directly within <a id="_idIndexMarker1293"/>the <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>), offering a dynamic and interactive coding experience. Agentic experiences refer to systems that actively assist users by understanding context, offering suggestions, and helping guide task completion. Amazon Q Developer iteratively refines changes based on your feedback and leverages information from your CLI environment to assist with local file operations, querying AWS resources, writing code, and automatically <span class="No-Break">debugging issues.</span></p>&#13;
			<p class="callout-heading">Important note</p>&#13;
			<p class="callout">When using GenAI-powered assistants for coding and executing local tasks such as running commands, always review generated code and commands thoroughly. Ensure they are secure, appropriate for your environment, and won’t unintentionally affect critical resources <span class="No-Break">or data.</span></p>&#13;
			<p>Let’s <span class="No-Break">get started:</span></p>&#13;
			<p>Install <em class="italic">Amazon Q Developer for command line</em> by following the instructions <span class="No-Break">at </span><a href="https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html"><span class="No-Break">https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html</span></a><span class="No-Break">.</span></p>&#13;
			<p>Open a terminal or command-line application and initiate a conversation with Amazon Q Developer using the <span class="No-Break">following command:</span></p>&#13;
			<pre class="source-code">&#13;
$ q chat</pre>			<p>You will be directed to the <strong class="bold">AWS Builder ID</strong> login page (<a href="https://docs.aws.amazon.com/signin/latest/userguide/sign-in-aws_builder_id.html">https://docs.aws.amazon.com/signin/latest/userguide/sign-in-aws_builder_id.html</a>) to allow permission to Amazon Q Developer for <span class="No-Break">command line.</span></p>&#13;
			<p>Type the following query in the CLI. Amazon Q Developer will process your input, considering the provided context, call the <strong class="bold">Amazon Bedrock API</strong>, and respond with an output as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer111" class="IMG---Figure">&#13;
					<img src="image/B31108_14_01.jpg" alt="Figure 14.1 – Kubectl command generation using Amazon Q Developer" width="1290" height="456"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.1 – Kubectl command generation using Amazon Q Developer</p>&#13;
			<p>Now, let’s ask <a id="_idIndexMarker1294"/>the <a id="_idIndexMarker1295"/>GenAI assistant to create the IaC templates for creating a new Amazon EKS cluster along with a VPC, private and public subnets, and so on. Use the following prompt in <span class="No-Break">the CLI:</span></p>&#13;
			<pre class="source-code">&#13;
$ Generate Terraform code for an Amazon EKS cluster with:&#13;
- Cluster name "eks-genai-demo" in us-west-2 region using EKS v1.32&#13;
- Dedicated VPC (CIDR 10.0.0.0/16) with public/private subnets across 3 AZs&#13;
- 1 NAT gateway for internet access from private subnets&#13;
- Standard EKS Managed add-ons (Amazon VPC CNI, CoreDNS, kube-proxy)&#13;
- Output cluster endpoint and access information&#13;
Provide modular, well-commented code with appropriate provider configurations and use open-source terraform modules where possible.</pre>			<p>Within a <a id="_idIndexMarker1296"/>few<a id="_idIndexMarker1297"/> seconds, Amazon Q Developer will generate Terraform code to create an Amazon VPC, EKS cluster, and so on, along with Terraform provider configuration, input variables, and outputs, as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.2</em></span><span class="No-Break">:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer112" class="IMG---Figure">&#13;
					<img src="image/B31108_14_02.jpg" alt="Figure 14.2 – Terraform code generation using Amazon Q Developer" width="1209" height="1011"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.2 – Terraform code generation using Amazon Q Developer</p>&#13;
			<p>We ran this prompt and uploaded the generated files to the GitHub repository <span class="No-Break">at </span><a href="https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/tree/main/ch14/amazon-q-demo"><span class="No-Break">https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/tree/main/ch14/amazon-q-demo</span></a><span class="No-Break">.</span></p>&#13;
			<p>GenAI-powered<a id="_idIndexMarker1298"/> coding <a id="_idIndexMarker1299"/>assistants may use older versions of Terraform providers or modules, based on their training data. In the generated code, it used <strong class="source-inline">Terraform version &gt;= 1.0.0</strong>, <strong class="source-inline">AWS provider &gt;= 5.0.0</strong>, and so on. We can also give a follow-up prompt to use specific versions of these providers, as <span class="No-Break">shown here:</span></p>&#13;
			<pre class="console">&#13;
$ Update the previous EKS cluster Terraform code to use the following provider versions:&#13;
- Terraform version &gt;= 1.9&#13;
- AWS provider &gt;= 5.63&#13;
- Helm provider &gt;= 2.15&#13;
- Kubernetes provider &gt;= 2.32&#13;
Ensure all provider configurations are explicitly defined with these version constraints in the required_providers block, and the code remains compatible with these newer versions.</pre>			<p>Amazon Q Developer will reason the prompt, start reading the Terraform files from the local<a id="_idIndexMarker1300"/> filesystem, and<a id="_idIndexMarker1301"/> suggest the changes, as shown in <span class="No-Break">Figure 14</span><span class="No-Break">.3:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer113" class="IMG---Figure">&#13;
					<img src="image/B31108_14_03.jpg" alt="Figure 14.3 – Output of Amazon Q Developer" width="982" height="1046"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.3 – Output of Amazon Q Developer</p>&#13;
			<p>You can review the generated Terraform code and ask the agent to plan and deploy it to the AWS account using natural <span class="No-Break">language prompts.</span></p>&#13;
			<p>Similarly, you can use Amazon Q Developer to automatically generate complete project code from the ground up, such as for a to-do application that provides basic functionality to manage to-do tasks. Run the following prompt in an empty directory<a id="_idIndexMarker1302"/> to <a id="_idIndexMarker1303"/>generate a <span class="No-Break">to-do application:</span></p>&#13;
			<pre class="source-code">&#13;
<strong class="bold">$ Please create a simple TODO application with the following specifications:</strong>&#13;
<strong class="bold">Functionality</strong>&#13;
<strong class="bold">- Create new tasks with title and description</strong>&#13;
<strong class="bold">- Mark tasks as complete/incomplete</strong>&#13;
<strong class="bold">- Delete tasks</strong>&#13;
<strong class="bold">- View all tasks</strong>&#13;
<strong class="bold">Technical Requirements</strong>&#13;
<strong class="bold">- Create a single application</strong>&#13;
<strong class="bold">- Use in-memory storage for tasks (no need for a database)</strong>&#13;
<strong class="bold">- Follow good coding practices with appropriate comments</strong>&#13;
<strong class="bold">Docker Requirements</strong>&#13;
<strong class="bold">- Create a Dockerfile to containerize the application</strong>&#13;
<strong class="bold">- The Dockerfile should follow best practices</strong>&#13;
<strong class="bold">- Make it simple to build and run.</strong></pre>			<p>Within no time, Amazon Q Developer will start creating a hierarchal project structure, source code files, Dockerfile for containerization, documentation, and so on. We executed this prompt and provided the generated files in the GitHub repository at <a href="https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/tree/main/ch14/todo-app">https://github.com/PacktPublishing/Kubernetes-for-Generative-AI-Solutions/tree/main/ch14/todo-app</a>. It created the project structure and files shown in <span class="No-Break">Figure 14</span><span class="No-Break">.4:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer114" class="IMG---Figure">&#13;
					<img src="image/B31108_14_04.jpg" alt="Figure 14.4 – Output of Amazon Q Developer" width="374" height="322"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.4 – Output of Amazon Q Developer</p>&#13;
			<p>Review the<a id="_idIndexMarker1304"/> generated <a id="_idIndexMarker1305"/>files. To test the application locally, we can prompt Amazon Q Developer to build the container image and run it using Docker or Finch. Use the following prompt to build and run the <span class="No-Break">container image:</span></p>&#13;
			<pre class="source-code">&#13;
<strong class="bold">$ Build and run the container image locally using Docker.</strong></pre>			<p>On a different terminal, you use the following commands to verify the container image and <span class="No-Break">running container:</span></p>&#13;
			<pre class="console">&#13;
<strong class="bold">$ docker images</strong>&#13;
<strong class="bold">$ docker ps</strong></pre>			<p>Finally, we can take this a step further by asking the AI assistant to create the necessary K8s manifest files and deploy the application to a K8s cluster. Use the following prompt to create the K8s Deployment and <span class="No-Break">Service resources:</span></p>&#13;
			<pre class="console">&#13;
<strong class="bold">$ Create necessary manifest files to deploy this application to a kubernetes cluster. Run two replicas of this app and expose it via ClusterIP service.</strong></pre>			<p>Within a few seconds, Amazon Q Developer will generate K8s deployment, service, and namespace manifest files, among others, to deploy the to-do application to a K8s cluster, as shown in <span class="No-Break">Figure 14</span><span class="No-Break">.5:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer115" class="IMG---Figure">&#13;
					<img src="image/B31108_14_05.jpg" alt="Figure 14.5 – K8s manifest files created by Amazon Q Developer" width="378" height="328"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.5 – K8s manifest files created by Amazon Q Developer</p>&#13;
			<p>In this section, we have explored how AI coding assistants such as Amazon Q Developer simplify software development tasks, including generating K8s configuration files and IaC templates for creating AWS and EKS resources. We have interacted with these assistants using natural language prompts, instructing them to perform various tasks such as <a id="_idIndexMarker1306"/>building a<a id="_idIndexMarker1307"/> container image, running applications locally, and modifying the generated code to meet specific requirements. In the next section, we will provide references for further reading on <span class="No-Break">this topic.</span></p>&#13;
			<h1 id="_idParaDest-189"><a id="_idTextAnchor189"/>References for further reading</h1>&#13;
			<ul>&#13;
				<li><a href="https://kubernetes.io/docs/">https://kubernetes.io/docs/</a>: Official Kubernetes documentation, always up to date <span class="No-Break">and comprehensive</span></li>&#13;
				<li><a href="https://github.com/kubernetes/kubernetes">https://github.com/kubernetes/kubernetes</a>: The core Kubernetes GitHub repo with <span class="No-Break">source code</span></li>&#13;
				<li><a href="https://training.linuxfoundation.org/certification/">https://training.linuxfoundation.org/certification/</a>: The Linux Foundation, in partnership with<a id="_idIndexMarker1308"/> the <strong class="bold">Cloud Native Computing Foundation</strong> (<strong class="bold">CNCF</strong>), offers three key K8s certifications – <strong class="source-inline">Certified Kubernetes Administrator</strong> (CKA), <strong class="source-inline">Certified Kubernetes Application Developer</strong> (CKAD), and <strong class="source-inline">Certified Kubernetes Security </strong><span class="No-Break"><strong class="source-inline">Specialist</strong></span><span class="No-Break"> (</span><span class="No-Break"><strong class="source-inline">CKS</strong></span><span class="No-Break">)</span></li>&#13;
				<li><a href="https://kubernetes.io/blog/">https://kubernetes.io/blog/</a>: The official blog with updates, best practices, and <span class="No-Break">use cases</span></li>&#13;
				<li><a href="https://kubernetes.io/community/">https://kubernetes.io/community/</a>: Community hub for contributing, SIGs, events, and <span class="No-Break">getting involved</span></li>&#13;
				<li><a href="https://www.cncf.io/projects/kubernetes/">https://www.cncf.io/projects/kubernetes/</a>: K8s page on CNCF – project status, governance, <span class="No-Break">and landscape</span></li>&#13;
				<li><a href="https://github.com/aws-ia/terraform-aws-eks-blueprints">https://github.com/aws-ia/terraform-aws-eks-blueprints</a>: Official EKS blueprints using Terraform – modular <span class="No-Break">and production-ready</span></li>&#13;
				<li><a href="https://awslabs.github.io/data-on-eks/">https://awslabs.github.io/data-on-eks/</a>: Data on EKS is a tool to build, deploy, and scale Data &amp; ML platforms <span class="No-Break">on EKS</span></li>&#13;
				<li><a href="https://aws.github.io/aws-eks-best-practices/">https://aws.github.io/aws-eks-best-practices/</a>: Official <em class="italic">Amazon EKS Best Practices Guide</em>, covering security, networking, scaling, GitOps, <span class="No-Break">and more</span></li>&#13;
				<li><a href="https://wellarchitectedlabs.com/architecture-guides/containers/eks-best-practices/">https://wellarchitectedlabs.com/architecture-guides/containers/eks-best-practices/</a>: <em class="italic">AWS Well-Architected Labs</em> guide for EKS with practical labs and <span class="No-Break">architecture reviews</span></li>&#13;
			</ul>&#13;
			<h1 id="_idParaDest-190"><a id="_idTextAnchor190"/>Summary</h1>&#13;
			<p>In this chapter, we covered how GenAI-based coding assistants are transforming the way K8s clusters are being built, deployed, and monitored. These tools automate IaC, optimize workloads, and enhance observability. Key assistants include Amazon Q Developer, GitHub Copilot, Google Gemini Code Assist, Microsoft Azure Copilot, IBM watsonx Code Assistant, and K8sGPT. They support everything from writing deployment manifests and Terraform configurations to real-time diagnostics and optimization of <span class="No-Break">cluster performance.</span></p>&#13;
			<p>GenAI tools also boost observability, security, and cost efficiency through AI-powered autoscaling, anomaly detection, and policy enforcement. Tools such as StormForge, PredictKube, and Dynatrace Davis AI automate root cause analysis and resource scaling, while others, such as Harness and Cast AI, assist with <span class="No-Break">K8s FinOps.</span></p>&#13;
			<p>Amazon Q Developer offers CLI-based support to generate and refine Terraform templates, build Docker containers, and deploy complete applications using simple natural language prompts. It supports creating modular IaC for EKS clusters and enables fast iteration through <span class="No-Break">intelligent suggestions.</span></p>&#13;
			<p>Lastly, we provided a curated list of references for deeper learning. These include official K8s documentation, GitHub repositories, and blogs offering best practices, patterns, and community resources. It also highlights certification programs from the Linux Foundation and CNCF. Together, these resources offer valuable guidance for mastering K8s and effectively using GenAI-powered tools in production environments. We hope you enjoyed reading this book and we will look forward to getting your feedback on how we can improve in <span class="No-Break">future editions.</span></p>&#13;
			<h1 id="_idParaDest-191"><a id="_idTextAnchor191"/>Stay Sharp in Cloud and DevOps – Join 44,000+ Subscribers of CloudPro</h1>&#13;
			<p><strong class="bold">CloudPro</strong> is a weekly newsletter for cloud professionals who want to stay current on the fast-evolving world of cloud computing, DevOps, and <span class="No-Break">infrastructure engineering.</span></p>&#13;
			<p>Every issue delivers focused, high-signal content on <span class="No-Break">topics like:</span></p>&#13;
			<ul>&#13;
				<li>AWS, GCP &amp; <span class="No-Break">multi-cloud architecture</span></li>&#13;
				<li>Containers, Kubernetes &amp; <span class="No-Break">orchestration</span></li>&#13;
				<li>Infrastructure as Code (IaC) with Terraform, <span class="No-Break">Pulumi, etc.</span></li>&#13;
				<li>Platform engineering &amp; <span class="No-Break">automation workflows</span></li>&#13;
				<li>Observability, performance tuning, and reliability <span class="No-Break">best practices</span></li>&#13;
			</ul>&#13;
			<p>Whether you’re a cloud engineer, SRE, DevOps practitioner, or platform lead, CloudPro helps you stay on top of what matters, without <span class="No-Break">the noise.</span></p>&#13;
			<p>Scan the QR code to join for free and get weekly insights straight to <span class="No-Break">your inbox:</span></p>&#13;
			<div>&#13;
				<div id="_idContainer116" class="IMG---Figure">&#13;
					<img src="image/NL_Part1.jpg" alt="https://packt.link/cloudpro" width="150" height="150"/>&#13;
				</div>&#13;
			</div>&#13;
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><a href="https://packt.link/cloudpro">https://packt.link/cloudpro</a></p>&#13;
		</div>&#13;
	</div></div></body></html>