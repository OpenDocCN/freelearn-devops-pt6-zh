<html><head></head><body>
		<div id="_idContainer005">
			<h1 id="_idParaDest-5"><a id="_idTextAnchor004"/>Preface</h1>
			<p>In today’s data-driven world, the ability to process and analyze vast amounts of data has become a critical competitive advantage for businesses across industries. Big data technologies have emerged as powerful tools to handle the ever-increasing volume, velocity, and variety of data, enabling organizations to extract valuable insights and drive informed decision-making. However, managing and scaling these technologies can be a daunting task, often requiring significant infrastructure and <span class="No-Break">operational overhead.</span></p>
			<p>Enter Kubernetes, the open source container orchestration platform that has revolutionized the way we deploy and manage applications. By providing a standardized and automated approach to container management, Kubernetes has simplified the deployment and scaling of complex applications, including big data workloads. This book aims to bridge the gap between these two powerful technologies, guiding you through the process of implementing a robust and scalable big data architecture <span class="No-Break">on Kubernetes.</span></p>
			<p>Throughout the chapters, you will embark on a comprehensive journey, starting with the fundamentals of containers and Kubernetes architecture. You will learn how to build and deploy Docker images, understand the core components of Kubernetes, and gain hands-on experience in setting up local and cloud-based Kubernetes clusters. This solid foundation will prepare you for the subsequent chapters, where you will dive into the world of the modern <span class="No-Break">data stack.</span></p>
			<p>The book will introduce you to the most widely adopted tools in the big data ecosystem, such as Apache Spark for data processing, Apache Airflow for pipeline orchestration, and Apache Kafka for real-time data ingestion. You will not only learn the theoretical concepts behind these technologies but also gain practical experience in implementing them on Kubernetes. Through a series of hands-on exercises and projects, you will develop a deep understanding of how to build and deploy data pipelines, process large datasets, and orchestrate complex workflows on a <span class="No-Break">Kubernetes cluster.</span></p>
			<p>As the book progresses, you will explore advanced topics such as deploying a data consumption layer with tools such as Trino and Elasticsearch and integrating generative AI workloads using Amazon Bedrock. These topics will equip you with the knowledge and skills necessary to build and maintain a robust and scalable big data architecture on Kubernetes, ensuring efficient data processing, analysis, and analytics <span class="No-Break">application deployment.</span></p>
			<p>By the end of this book, you will have gained a comprehensive understanding of the synergy between big data and Kubernetes, enabling you to leverage the power of these technologies to drive innovation and business growth. Whether you are a data engineer, a DevOps professional, or a technology enthusiast, this book will provide you with the practical knowledge and hands-on experience needed to successfully implement and manage big data workloads <span class="No-Break">on Kubernetes.</span></p>
			<h1 id="_idParaDest-6"><a id="_idTextAnchor005"/>Who this book is for</h1>
			<p>If you are a data engineer, a cloud architect, a DevOps professional, a data or science manager, or a technology enthusiast, this book is for you. You should have a basic background in Python and SQL programming, and basic knowledge of Apache Spark, Apache Kafka, and Apache Airflow. A basic understanding of Docker and Git will also <span class="No-Break">be helpful.</span></p>
			<h1 id="_idParaDest-7"><a id="_idTextAnchor006"/>What this book covers</h1>
			<p><a href="B21927_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic">Chapter 1</em></span></a>, <em class="italic">Getting Started with Containers</em>, embarks on a journey to understand containers and Docker, the foundational technologies for modern application deployment. You’ll learn how to install Docker and run your first container image, experiencing the power of containerization firsthand. Additionally, you’ll dive into the intricacies of Dockerfiles, mastering the art of crafting concise and functional container images. Through practical examples, including the construction of a simple API and a data processing job with Python, you’ll grasp the nuances of containerizing services and jobs. By the end of this chapter, you’ll have the opportunity to solidify your newfound knowledge by building your own job and API, laying the groundwork for a portfolio of practical <span class="No-Break">container-based applications.</span></p>
			<p><a href="B21927_02.xhtml#_idTextAnchor031"><span class="No-Break"><em class="italic">Chapter 2</em></span></a>, <em class="italic">Kubernetes Architecture</em>, introduces you to the core components that make up the Kubernetes architecture. You will learn about the control plane components such as the API server, etcd, scheduler, and controller manager, as well as the worker node components such as kubelet, kube-proxy, and container runtime. The chapter will explain the roles and responsibilities of each component, and how they interact with each other to ensure the smooth operation of a Kubernetes cluster. Additionally, you will gain an understanding of the key concepts in Kubernetes, including pods, deployments, services, jobs, stateful sets, persistent volumes, ConfigMaps, and secrets. By the end of this chapter, you will have a solid foundation in the architecture and core concepts of Kubernetes, preparing you for hands-on experience in the <span class="No-Break">subsequent chapters.</span></p>
			<p><a href="B21927_03.xhtml#_idTextAnchor053"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, <em class="italic">Kubernetes – Hands On</em>, guides you through the process of deploying a local Kubernetes cluster using kind, and a cloud-based cluster on AWS using Amazon EKS. You will learn the minimal AWS account configuration required to successfully deploy an EKS cluster. After setting up the clusters, you will have the opportunity to choose between deploying your applications on the local or cloud environment. Regardless of your choice, you will retake the API and data processing jobs developed in <a href="B21927_01.xhtml#_idTextAnchor015"><span class="No-Break"><em class="italic">Chapter 1</em></span></a> and deploy them to Kubernetes. This hands-on experience will solidify your understanding of Kubernetes concepts and prepare you for more advanced topics in the <span class="No-Break">following chapters.</span></p>
			<p><a href="B21927_04.xhtml#_idTextAnchor070"><span class="No-Break"><em class="italic">Chapter 4</em></span></a>, <em class="italic">The Modern Data Stack</em>, introduces you to the most well-known data architecture designs, with a focus on the “lambda” architecture. You will learn about the tools that make up the modern data stack, which is a set of technologies used to implement a data lake(house) architecture. Among these tools are Apache Spark for data processing, Apache Airflow for data pipeline orchestration, and Apache Kafka for real-time event streaming and data ingestion. This chapter will provide a conceptual introduction to these tools and how they work together to build the core technology assets of a data <span class="No-Break">lake(house) architecture.</span></p>
			<p><a href="B21927_05.xhtml#_idTextAnchor092"><span class="No-Break"><em class="italic">Chapter 5</em></span></a>, <em class="italic">Big Data Processing with Apache Spark</em>, introduces you to Apache Spark, one of the most popular tools for big data processing. You will understand the core components of a Spark program, how it scales and handles distributed processing, and best practices for working with Spark. You will implement simple data processing tasks using both the DataFrames API and the Spark SQL API, leveraging Python to interact with Spark. The chapter will guide you through installing Spark locally for testing purposes, enabling you to gain hands-on experience with this powerful tool before deploying it on a <span class="No-Break">larger scale.</span></p>
			<p><a href="B21927_06.xhtml#_idTextAnchor112"><span class="No-Break"><em class="italic">Chapter 6</em></span></a>, <em class="italic">Apache Airflow for Building Pipelines</em>, introduces you to Apache Airflow, a widely adopted open source tool for data pipeline orchestration. You will learn how to install Airflow using Docker and Astro CLI, making the setup process straightforward. The chapter will familiarize you with Airflow’s core features and the most commonly used operators for data engineering tasks. Additionally, you will gain insights into best practices for building resilient and efficient data pipelines that leverage Airflow’s capabilities to the fullest. By the end of this chapter, you will have a solid understanding of how to orchestrate complex data workflows using Airflow, a crucial skill for any data engineer or data architect working with big data <span class="No-Break">on Kubernetes.</span></p>
			<p><a href="B21927_07.xhtml#_idTextAnchor122"><span class="No-Break"><em class="italic">Chapter 7</em></span></a>, <em class="italic">Apache Kafka for Real-Time Events and Data Ingestion</em>, introduces you to Apache Kafka, a distributed event streaming platform that is widely used for building real-time data pipelines and streaming applications. You will understand Kafka’s architecture and how it scales while being resilient, enabling it to handle high volumes of real-time data with low latency. You will learn about Kafka’s distributed topics design, which underpins its robust performance for real-time events. The chapter will guide you through running Kafka locally with Docker and implementing basic reading and writing operations on topics. Additionally, you will explore different strategies for data replication and topic distribution, ensuring you can design and implement efficient and reliable <span class="No-Break">Kafka clusters.</span></p>
			<p><a href="B21927_08.xhtml#_idTextAnchor134"><span class="No-Break"><em class="italic">Chapter 8</em></span></a>, <em class="italic">Deploying the Big Data Stack on Kubernetes</em>, guides you through the process of deploying the big data tools you learned about in the previous chapters on a Kubernetes cluster. You will start by building bash scripts to deploy the Spark operator and run <strong class="source-inline">SparkApplications</strong> on Kubernetes. Next, you will deploy Apache Airflow to Kubernetes, enabling you to orchestrate data pipelines within the cluster. Additionally, you will deploy Apache Kafka on Kubernetes using both the ephemeral cluster and JBOD techniques. The Kafka Connect cluster will also be deployed, along with connectors to migrate data from SQL databases to persistent object storage. By the end of this chapter, you will have a fully functional big data stack running on Kubernetes, ready for further exploration <span class="No-Break">and development.</span></p>
			<p><a href="B21927_09.xhtml#_idTextAnchor141"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>, <em class="italic">Data Consumption Layer</em>, guides you through the process of securely making data available for business analysts in a big data architecture deployed on Kubernetes. You will start by gaining an overview of working on a modern approach using a “data lake engine” instead of a data warehouse. In this chapter, you will become familiar with Trino for data consumption directly from a data lake through Kubernetes. You will understand how a data lake engine works, deploy it into Kubernetes, and monitor query execution and history. Additionally, for real-time data, you will get familiar with Elasticsearch and Kibana for data consumption. You will deploy these tools, and learn how to index data in them and how to build a simple data visualization <span class="No-Break">with Kibana.</span></p>
			<p><a href="B21927_10.xhtml#_idTextAnchor154"><span class="No-Break"><em class="italic">Chapter 10</em></span></a>, <em class="italic">Building a Big Data Pipeline in Kubernetes</em>, guides you through the process of deploying and orchestrating two complete data pipelines, one for batch processing and another for real-time processing, on a Kubernetes cluster. You will connect all the tools you’ve learned about throughout the book, such as Apache Spark, Apache Airflow, Apache Kafka, and Trino, to build a single, complex solution. You will deploy these tools on Kubernetes, write code for data processing and orchestration, and make the data available for querying through a SQL engine. By the end of this chapter, you will have hands-on experience in building and managing a comprehensive big data pipeline on Kubernetes, integrating various components and technologies into a cohesive and <span class="No-Break">scalable architecture.</span></p>
			<p><a href="B21927_11.xhtml#_idTextAnchor167"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, <em class="italic">Generative AI on Kubernetes</em>, guides you through the process of deploying a generative AI application on Kubernetes using Amazon Bedrock as a service suite for foundational models. You will learn how to connect your application to a knowledge base serving as a <strong class="bold">Retrieval-Augmented Generation</strong> (<strong class="bold">RAG</strong>) layer, which enhances the AI model’s capabilities by providing access to external information sources. Additionally, you will discover how to automate task execution by the AI models with agents, enabling seamless integration of generative AI into your workflows. By the end of this chapter, you will have a solid understanding of how to leverage the power of generative AI on Kubernetes, unlocking new possibilities for personalized customer experiences, intelligent assistants, and automated <span class="No-Break">business analytics.</span></p>
			<p><a href="B21927_12.xhtml#_idTextAnchor183"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>, <em class="italic">Where to Go from Here</em>, guides you through the next steps in your journey toward mastering big data and Kubernetes. You will explore crucial concepts and technologies that are essential for building robust and scalable solutions on Kubernetes. This includes monitoring strategies for both Kubernetes and your applications, implementing a service mesh for efficient communication, securing your cluster and applications, enabling automated scalability, embracing GitOps and CI/CD practices for streamlined deployment and management, and Kubernetes cost control. For each topic, you’ll receive an overview and recommendations on the technologies to explore further, empowering you to deepen your knowledge and skills in <span class="No-Break">these areas.</span></p>
			<h1 id="_idParaDest-8"><a id="_idTextAnchor007"/>To get the most out of this book</h1>
			<p>Some basics in Python programming knowledge and experience with Spark, Docker, Airflow, Kafka, and Git will help you get the most out of <span class="No-Break">this book.</span></p>
			<table class="No-Table-Style" id="table001">
				<colgroup>
					<col/>
					<col/>
				</colgroup>
				<thead>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><strong class="bold">Software/hardware covered in </strong><span class="No-Break"><strong class="bold">the book</strong></span></p>
						</td>
						<td class="No-Table-Style">
							<p><strong class="bold">Operating </strong><span class="No-Break"><strong class="bold">system requirements</strong></span></p>
						</td>
					</tr>
				</thead>
				<tbody>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Python&gt;=3.9</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Windows, macOS, <span class="No-Break">or Linux</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Docker, the latest <span class="No-Break">version available</span></p>
						</td>
						<td class="No-Table-Style">
							<p><span class="No-Break">Linux</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>Docker Desktop, the latest <span class="No-Break">version available</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Windows <span class="No-Break">or macOS</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Kubectl</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Windows, macOS, <span class="No-Break">or Linux</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Awscli</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Windows, macOS, <span class="No-Break">or Linux</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p><span class="No-Break">Eksctl</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Windows, macOS, <span class="No-Break">or Linux</span></p>
						</td>
					</tr>
					<tr class="No-Table-Style">
						<td class="No-Table-Style">
							<p>DBeaver <span class="No-Break">Community Edition</span></p>
						</td>
						<td class="No-Table-Style">
							<p>Windows, macOS, <span class="No-Break">or Linux</span></p>
						</td>
					</tr>
				</tbody>
			</table>
			<p>All guidance needed for software installation will be provided in <span class="No-Break">each chapter.</span></p>
			<p><strong class="bold">If you are using the digital version of this book, we advise you to type the code yourself or access the code from the book’s GitHub repository (a link is available in the next section). Doing so will help you avoid any potential errors related to the copying and pasting </strong><span class="No-Break"><strong class="bold">of code.</strong></span></p>
			<h1 id="_idParaDest-9"><a id="_idTextAnchor008"/>Download the example code files</h1>
			<p>You can download the example code files for this book from GitHub at <a id="_idTextAnchor009"/><a href="https://github.com/PacktPublishing/Bigdata-on-Kubernetes">https://github.com/PacktPublishing/Bigdata-on-Kubernetes</a>. If there’s an update to the code, it will be updated in the <span class="No-Break">GitHub repository.</span></p>
			<p>We also have other code bundles from our rich catalog of books and videos available at <a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>. Check <span class="No-Break">them out!</span></p>
			<h1 id="_idParaDest-10"><a id="_idTextAnchor010"/>Conventions used</h1>
			<p>There are a number of text conventions used throughout <span class="No-Break">this book.</span></p>
			<p><strong class="source-inline">Code in text</strong>: Indicates code words in text, database table names, folder names, filenames, file extensions, pathnames, dummy URLs, user input, and Twitter handles. Here is an example: “This command will pull the <strong class="source-inline">hello-world</strong> image from the Docker Hub public repository and run the application in <span class="No-Break">it. “</span></p>
			<p>A block of code is set <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
import pandas as pd
url = '<a href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'">https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'</a>
df = pd.read_csv(url, header=None)
df["newcolumn"] = df[5].apply(lambda x: x*2)
print(df.columns)
print(df.head())
print(df.shape)</pre>			<p>Any command-line input or output is written <span class="No-Break">as follows:</span></p>
			<pre class="console">
$ sudo apt install docker.io</pre>			<p>This is how the filename above the code snippet <span class="No-Break">will look:</span></p>
			<p class="SC---Heading-without-line" lang="en-US" xml:lang="en-US"><strong class="bold">Cjava.py</strong></p>
			<p><strong class="bold">Bold</strong>: Indicates a new term, an important word, or words that you see onscreen. For instance, words in menus or dialog boxes appear in <strong class="bold">bold</strong>. Here is an example: “You should ensure that the <strong class="bold">Use WSL 2 instead of Hyper-V</strong> option is selected on the <span class="No-Break"><strong class="bold">Configuration</strong></span><span class="No-Break"> page.”</span></p>
			<p class="callout-heading">Tips or important notes</p>
			<p class="callout">Appear like this.</p>
			<h1 id="_idParaDest-11"><a id="_idTextAnchor011"/>Get in touch</h1>
			<p>Feedback from our readers is <span class="No-Break">always welcome.</span></p>
			<p><strong class="bold">General feedback</strong>: If you have questions about any aspect of this book, email us at <a href="mailto:customercare@packtpub.com">customercare@packtpub.com</a> and mention the book title in the subject of <span class="No-Break">your message.</span></p>
			<p><strong class="bold">Errata</strong>: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. If you have found a mistake in this book, we would be grateful if you would report this to us. Please visit <a href="http://www.packtpub.com/support/errata">www.packtpub.com/support/errata</a> and fill in <span class="No-Break">the form.</span></p>
			<p><strong class="bold">Piracy</strong>: If you come across any illegal copies of our works in any form on the internet, we would be grateful if you would provide us with the location address or website name. Please contact us at <a href="mailto:copyright@packt.com">copyright@packt.com</a> with a link to <span class="No-Break">the material.</span></p>
			<p><strong class="bold">If you are interested in becoming an author</strong>: If there is a topic that you have expertise in and you are interested in either writing or contributing to a book, please <span class="No-Break">visit </span><a href="http://authors.packtpub.com"><span class="No-Break">authors.packtpub.com</span></a><span class="No-Break">.</span></p>
			<h1 id="_idParaDest-12"><a id="_idTextAnchor012"/>Share Your Thoughts</h1>
			<p>Once you’ve read <em class="italic">Big Data on Kubernetes</em>, we’d love to hear your thoughts! Please <a href="https://packt.link/r/1-835-46214-6">click here to go straight to the Amazon review page</a> for this book and share <span class="No-Break">your feedback.</span></p>
			<p>Your review is important to us and the tech community and will help us make sure we’re delivering excellent <span class="No-Break">quality content.</span></p>
			<h1 id="_idParaDest-13"><a id="_idTextAnchor013"/>Download a free PDF copy of this book</h1>
			<p>Thanks for purchasing <span class="No-Break">this book!</span></p>
			<p>Do you like to read on the go but are unable to carry your print <span class="No-Break">books everywhere?</span></p>
			<p>Is your eBook purchase not compatible with the device of <span class="No-Break">your choice?</span></p>
			<p>Don’t worry, now with every Packt book you get a DRM-free PDF version of that book at <span class="No-Break">no cost.</span></p>
			<p>Read anywhere, any place, on any device. Search, copy, and paste code from your favorite technical books directly into <span class="No-Break">your application.</span></p>
			<p>The perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content in your <span class="No-Break">inbox daily</span></p>
			<p>Follow these simple steps to get <span class="No-Break">the benefits:</span></p>
			<ol>
				<li>Scan the QR code or visit the <span class="No-Break">link below</span></li>
			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer004">
					<img alt="Download a free PDF copy of this book&#13;&#10;" src="image/B21927_QR_Free_PDF.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US"><a href="https://packt.link/free-ebook/978-1-83546-214-0">https://packt.link/free-ebook/978-1-83546-214-0</a></p>
			<ol>
				<li value="2">Submit your proof <span class="No-Break">of purchase</span></li>
				<li>That’s it! We’ll send your free PDF and other benefits to your <span class="No-Break">email directly</span></li>
			</ol>
		</div>
	

		<div class="Content" id="_idContainer006">
			<h1 id="_idParaDest-14" lang="en-US" xml:lang="en-US"><a id="_idTextAnchor014"/>Part 1:Docker and Kubernetes</h1>
		</div>
		<div id="_idContainer007">
			<p>In this part, you will learn about the fundamentals of containerization and Kubernetes. You will start by understanding the basics of containers and how to build and run Docker images. This will provide you with a solid foundation for working with containerized applications. Next, you will dive into the Kubernetes architecture, exploring its components, features, and core concepts such as pods, deployments, and services. With this knowledge, you will be well equipped to navigate the Kubernetes ecosystem. Finally, you will get hands-on experience by deploying local and cloud-based Kubernetes clusters and then deploying applications you built earlier onto <span class="No-Break">these clusters.</span></p>
			<p>This part contains the <span class="No-Break">following chapters:</span></p>
			<ul>
				<li><a href="B21927_01.xhtml#_idTextAnchor015"><em class="italic">Chapter 1</em></a>, Getting Started with Containers</li>
				<li><a href="B21927_02.xhtml#_idTextAnchor031"><em class="italic">Chapter 2</em></a>, Kubernetes Architecture</li>
				<li><a href="B21927_03.xhtml#_idTextAnchor053"><em class="italic">Chapter 3</em></a>, Kubernetes – Hands On</li>
			</ul>
		</div>
		<div>
			<div id="_idContainer008">
			</div>
		</div>
		<div>
			<div class="Basic-Graphics-Frame" id="_idContainer009">
			</div>
		</div>
	</body></html>