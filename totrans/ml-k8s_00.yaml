- en: '*Chapter 2*: Understanding MLOps'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第 2 章*：理解 MLOps'
- en: Most people from software engineering backgrounds know about the term **development-operations**
    (**DevOps**). To us, DevOps is about collaboration and shared responsibilities
    across different teams during the **software development life cycle** (**SDLC**).
    The teams are not limited to a few **information technology** (**IT**) teams;
    instead, it involves everyone from the organization who is a stakeholder in the
    project. No more segregation between building software (developers' responsibility)
    and running it in production (operations' responsibility). Instead, the team *owns*
    the product. DevOps is popular because it helps teams increase the velocity and
    reliability of the software being developed.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数软件工程背景的人都知道**开发运维**（**DevOps**）这个术语。对我们来说，DevOps 是关于在**软件开发生命周期**（**SDLC**）中跨不同团队之间进行协作和共享责任。这些团队不仅限于少数**信息技术**（**IT**）团队，而是涉及到项目中的所有利益相关者。不再区分软件构建（开发者的责任）和在生产环境中运行它（运维的责任）。相反，团队共同*拥有*产品。DevOps
    之所以流行，是因为它帮助团队提高了正在开发的软件的速度和可靠性。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主题：
- en: Comparing **machine learning** (**ML**) to traditional programming
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将**机器学习**（**ML**）与传统编程进行比较
- en: Exploring the benefits of DevOps
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探讨 DevOps 的好处
- en: Understanding **ML operations** (**MLOps**)
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解**ML 运维**（**MLOps**）
- en: The role of **open source software** (**OSS**) in ML projects
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开源软件**（**OSS**）在 ML 项目中的作用'
- en: Running ML projects on Kubernetes
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上运行 ML 项目
- en: Before we can apply DevOps to ML projects, we must first understand the difference
    between traditional software development and ML development processes.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们可以将 DevOps 应用于 ML 项目之前，我们必须首先了解传统软件开发和 ML 开发过程之间的区别。
- en: Comparing ML to traditional programming
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 将 ML 与传统编程进行比较
- en: As with traditional application development, an ML project is also a software
    project, but there are fundamental differences in the way they are delivered.
    Let's understand how an ML project is different from a traditional software application.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 与传统应用程序开发类似，ML 项目也是一个软件项目，但它们在交付方式上有根本性的区别。让我们了解一下 ML 项目与传统软件应用程序的不同之处。
- en: In traditional software applications, a software developer writes a program
    that holds an explicitly handcrafted set of rules. At runtime or prediction time,
    the built software applies these well-defined rules to the given data, and the
    output of the program is the result calculated based on coded rules.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在传统软件应用程序中，软件开发人员编写一个程序，其中包含一组明确定义的手工制作的规则。在运行时或预测时，构建的软件将这些明确定义的规则应用于给定的数据，程序的输出是基于编码规则计算得出的结果。
- en: 'The following diagram shows the **inputs and outputs** (**I/Os**) for a traditional
    software application:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了传统软件应用程序的**输入和输出**（**I/Os**）：
- en: '![Figure 2.1 – Traditional software development'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.1 – 传统软件开发'
- en: '](img/B18332_02_001.jpg)'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_02_001.jpg)'
- en: Figure 2.1 – Traditional software development
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.1 – 传统软件开发
- en: In an ML project, the rules or patterns are not completely known, therefore
    we cannot explicitly describe rules in code as we can in traditional programming.
    In ML, there is a process that extracts rules based on a given sample pair of
    data and its associated expected results. This process is called **model training**.
    In the model-training process, the chosen ML algorithm calculates rules based
    on the given data and the verified answer. The output of this process is the **ML
    model**. This generated model can then be used to infer answers during prediction
    time. In contrast with traditional software development, instead of using explicitly
    written rules, we use a generated ML model to get a result.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ML 项目中，规则或模式并非完全已知，因此我们无法像在传统编程中那样在代码中明确描述规则。在 ML 中，有一个过程可以根据给定的数据样本对和其关联的预期结果提取规则。这个过程称为**模型训练**。在模型训练过程中，选择的
    ML 算法根据给定的数据和验证的答案计算规则。这个过程的输出是**ML 模型**。生成的模型随后可用于在预测时推断答案。与传统软件开发不同的是，我们不使用明确编写的规则，而是使用生成的
    ML 模型来获得结果。
- en: 'The following diagram shows that the ML model is generated at training time,
    which is then used to produce answers or results during prediction time:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了在训练时生成的 ML 模型，然后在预测时用于产生答案或结果：
- en: '![Figure 2.2 – ML development'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.2 – ML 开发'
- en: '](img/B18332_02_002.jpg)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_02_002.jpg)'
- en: Figure 2.2 – ML development
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.2 – ML 开发
- en: Though traditional software development and ML are fundamentally different,
    there are some synergies in the engineering processes between the two approaches.
    Given that traditional software development is very mature in the current era,
    we can apply lessons from it to our ML projects. Primarily, of course, both traditional
    programming and ML are software. Whichever processes we apply to build software
    in the traditional world—such as versioning, packaging of software as containers,
    automated deployments, and so on—these can be applied to ML projects too. However,
    we also must accommodate added processes in ML, such as model training.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管传统软件开发和机器学习在本质上是不同的，但这两种方法的工程过程之间存在一些协同效应。考虑到传统软件开发在当今时代非常成熟，我们可以将其中的经验教训应用到我们的机器学习项目中。当然，最主要的是，传统编程和机器学习都属于软件开发。我们在传统领域中应用于构建软件的所有流程——例如版本控制、将软件打包成容器、自动化部署等——也可以应用到机器学习项目中。然而，我们也必须考虑到机器学习中额外的过程，如模型训练。
- en: So, why do we really need DevOps in ML projects? What does it bring to the table?
    Let's have a look at this in the next section.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，为什么我们在机器学习项目中真的需要 DevOps 呢？它能带来什么好处？我们将在下一节中探讨这个问题。
- en: Exploring the benefits of DevOps
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索 DevOps 的好处
- en: 'DevOps is not just about toolsets. Say you have a tool available that can run
    unit tests for you. However, if the team has no culture of writing test cases,
    the tool would not be useful. DevOps is about how we work together on tasks that
    span across different teams. So, the three primary areas to focus on in DevOps
    are these:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps 不仅仅是关于工具集。假设你有一个可以为你运行单元测试的工具。然而，如果团队没有编写测试用例的文化，那么这个工具就不会有任何用处。DevOps
    关注的是我们如何在跨团队的任务上协作。所以，DevOps 需要专注的三个主要领域是：
- en: '**People**: Teams from multiple disciplines to achieve a common goal'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**人员**：来自多个学科的团队，旨在实现共同目标'
- en: '**Processes**: The way teams work together'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**过程**：团队合作的方式'
- en: '**Technology**: The tools that facilitate collaboration across different teams'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**技术**：促进不同团队间协作的工具'
- en: DevOps is built on top of Agile development practices with the objective of
    streamlining the software development process. DevOps teams are cross-functional,
    and they have the autonomy to build software through **continuous integration/continuous
    delivery** (**CI/CD**). DevOps encourages teams to collaborate over a fast feedback
    loop to improve the efficiency and quality of the software being developed.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps 基于敏捷开发实践，旨在简化软件开发过程。DevOps 团队是跨职能的，并且拥有通过**持续集成/持续交付**（**CI/CD**）来构建软件的自主权。DevOps
    鼓励团队通过快速反馈回路进行协作，以提高开发软件的效率和质量。
- en: 'The following diagram illustrates a complete DevOps cycle for traditional software
    development projects:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了传统软件开发项目中完整的 DevOps 生命周期：
- en: '![Figure 2.3 – A mobius loop showcasing a DevOps process'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.3 – 展示 DevOps 过程的莫比乌斯环'
- en: '](img/B18332_02_003.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_02_003.jpg)'
- en: Figure 2.3 – A mobius loop showcasing a DevOps process
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.3 – 展示 DevOps 过程的莫比乌斯环
- en: 'Through DevOps, teams can have well-defined and streamlined development practices
    for building, testing, deploying, and monitoring software in production. All this
    makes it possible to quickly and reliably release software into production. Some
    of the benefits that come out of DevOps practices are presented here:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 通过 DevOps，团队可以拥有明确且简化的开发实践，用于构建、测试、部署和监控生产中的软件。所有这些都使得能够快速且可靠地将软件发布到生产环境中。以下是
    DevOps 实践带来的一些好处：
- en: '**CI/CD**: CI is a phase through which software is merged and verified as soon
    as the developer pushes it into the code repository. CD is a series of stages
    through which software is built, tested, and packaged in a deployment ready form.
    **Continuous deployment** (also known as **CD**) is a phase where the deployment-ready
    code is picked and deployed to be consumed by end users. In DevOps, all these
    processes are automated.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CI/CD**：CI 是一个阶段，软件在开发者将其推送到代码库时即进行合并和验证。CD 是一系列阶段，通过这些阶段，软件被构建、测试，并打包成准备部署的形式。**持续部署**（也称为
    **CD**）是一个阶段，在这个阶段，准备部署的代码被选中并部署，以供最终用户使用。在 DevOps 中，所有这些流程都是自动化的。'
- en: '**Infrastructure as Code** (**IaC**): IaC is an approach to automate the provisioning
    and configuring of IT infrastructure. This aspect enables the team to request
    and configure infrastructure on an on-demand and as-needed basis. Imagine that
    a data scientist in your team needs a **graphics processing unit** (**GPU**) to
    do their model training. If we follow the practice of configuring and provisioning
    IaC, the request for a GPU can be automatically fulfilled by the system. In the
    next chapters, you will see this capability in action.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基础设施即代码**（**IaC**）：IaC 是一种自动化 IT 基础设施配置和供应的方法。这一方面使得团队可以根据需求随时请求并配置基础设施。想象一下，团队中的数据科学家需要一个
    **图形处理单元**（**GPU**）来进行模型训练。如果我们遵循 IaC 的配置和供应实践，那么系统可以自动完成对 GPU 的请求。接下来的章节中，你将看到这一能力的实际应用。'
- en: '**Observability**: Observability relates to how well we understand the state
    of our running system. DevOps makes systems observable via federating logging
    from different components, monitoring the systems (such as **central processing
    unit** (**CPU**), memory, response times, and so on), and providing a way to correlate
    various parts of the system for a given call through call tracing. All these capabilities,
    collectively, provide the basis for understanding the system state and help debug
    any issues without changing the code.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**可观察性**：可观察性与我们如何理解正在运行系统的状态有关。DevOps 通过联邦日志记录来自不同组件的日志、监控系统（例如 **中央处理单元**（**CPU**）、内存、响应时间等），并通过调用追踪提供一种将系统的各个部分关联起来的方式，从而使系统可观察。所有这些能力共同为理解系统状态提供基础，帮助调试任何问题，而不需要修改代码。'
- en: '**Team collaboration**: DevOps is not just about technology. In fact, the key
    focus area for the team is to collaborate. Collaboration is how multiple individuals
    from different teams work toward a common goal. Business, development, and operations
    teams working together is the core of DevOps. For ML-based projects, the team
    will have data scientists and data engineers on top of the aforementioned roles.
    With such a diverse team, communication is critical for building collective understanding
    and ownership of the defined outcome.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**团队协作**：DevOps 不仅仅是关于技术。事实上，团队的关键关注点是协作。协作是指来自不同团队的多个个体共同朝着一个共同目标努力。业务、开发和运维团队的合作是
    DevOps 的核心。对于基于 ML 的项目，团队中除了上述角色外，还会有数据科学家和数据工程师。由于团队成员的多样性，沟通对于构建集体理解和对既定结果的共同责任感至关重要。'
- en: So, how can we bring the benefits of a DevOps approach to ML projects? The answer
    is MLOps.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，我们如何将 DevOps 方法的优势带入到 ML 项目中呢？答案就是 MLOps。
- en: Understanding MLOps
  id: totrans-39
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 MLOps
- en: '**MLOps** is an emerging domain that takes advantage of the maturity of existing
    software development processes—in other words, DevOps combined with data engineering
    and ML disciplines. MLOps can be simplified as an engineering practice of applying
    DevOps to ML projects. Let''s take a closer look at how these disciplines form
    the foundation of MLOps.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '**MLOps** 是一个新兴领域，它利用了现有软件开发流程的成熟性——换句话说，就是将 DevOps 与数据工程和 ML 学科结合起来。MLOps
    可以简化为将 DevOps 应用于 ML 项目的工程实践。让我们更详细地了解这些学科如何构成 MLOps 的基础。'
- en: ML
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML
- en: ML projects involve activities that are not present in traditional programming.
    You learned in *Figure 2.3* that the bulk of the work in ML projects is not model
    development. Rather, it is more data gathering and processing, data analysis,
    **feature engineering** (**FE**), process management, data analysis, model serving,
    and more. In fact, according to the paper *Hidden Technical Debt in Machine Learning
    Systems* by D. Sculley et al., only 5% of the work is ML model development. Because
    of this, MLOps is not only focused on the ML model development task but mostly
    on the big picture—the entire ML project life cycle.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: ML 项目涉及一些传统编程中没有的活动。你在 *图 2.3* 中学习到，ML 项目中大部分的工作并不是模型开发，而是更多的数据收集与处理、数据分析、**特征工程**（**FE**）、过程管理、数据分析、模型服务等。实际上，根据
    D. Sculley 等人的论文 *Hidden Technical Debt in Machine Learning Systems*，只有 5% 的工作是
    ML 模型开发。因此，MLOps 不仅关注 ML 模型的开发任务，更多的是聚焦于大局——整个 ML 项目生命周期。
- en: 'Just as with DevOps, MLOps focuses on people, processes, and technology. But
    there are some complexities that MLOps has to address and DevOps doesn''t have
    to. Let''s look at some of these complexities in more detail here:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 就像 DevOps 一样，MLOps 也关注人、流程和技术。但 MLOps 有一些复杂性是 DevOps 不需要处理的。我们在这里更详细地了解这些复杂性：
- en: First, unlike traditional programming, where your only input is code, in ML,
    your input is both code and data. The ML model that is produced in the model development
    stage is highly dependent on data. This means that even if you do not change your
    code, if you train an ML algorithm using a different dataset, the resulting ML
    model will be different and will perform differently. When it comes to **version
    control**, this means that you not only version the code that facilitates model
    training, but you also need to version the data. Data is difficult to version
    because of the huge amount required, unlike code. One approach to address this
    is by using Git to keep track of a dataset version using the hash of the data.
    The actual data is then stored somewhere in remote storage such as a **Simple
    Storage Service** (**S3**) bucket. An open source tool called **Data Version Control**
    (**DVC**) can do this.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 首先，与传统编程不同，你的输入不仅是代码，还包括数据。在ML中，模型开发阶段生成的ML模型高度依赖于数据。这意味着即使你没有改变代码，如果使用不同的数据集训练ML算法，生成的ML模型将不同，并且性能也会有所不同。在**版本控制**方面，这意味着不仅需要版本化促进模型训练的代码，还需要版本化数据。由于数据量巨大，数据版本控制相对较难。解决这个问题的一种方法是使用Git跟踪数据集版本，使用数据哈希存储实际数据在远程存储（如**简单存储服务**（**S3**）桶）中。一个名为**数据版本控制**（**DVC**）的开源工具可以做到这一点。
- en: Secondly, there are more personas involved and *more collaboration* required
    in ML projects. You have data scientists, ML engineers, and data engineers collaborating
    with software engineers, business analysts, and operations teams. Sometimes, these
    personas are very diverse. A data scientist may not completely understand what
    production deployment really is. On the other hand, operations people (and sometimes
    even software engineers) do not understand what an ML model is. This makes collaboration
    in ML projects more complicated than a traditional software project.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 其次，在ML项目中涉及更多人物角色，需要*更多的协作*。你有数据科学家、ML工程师和数据工程师与软件工程师、业务分析师和运营团队合作。有时，这些角色非常多样化。一个数据科学家可能完全不理解什么是真正的生产部署。另一方面，运营人员（有时甚至是软件工程师）不了解什么是ML模型。这使得在ML项目中进行协作比传统软件项目更加复杂。
- en: Third, the addition of a model development stage adds more pivot points to the
    life cycle. This complicates the whole process. Unlike traditional software development,
    you only need to develop one set of working code. In ML, a data scientist or ML
    engineer may use multiple ML algorithms and generate multiple resulting ML models,
    and because only one model will get selected to be deployed to production, those
    models are compared with each other in terms of performance against other model
    properties. MLOps accommodates this complex workflow of *testing, comparing, and
    selecting models* to be deployed to production.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第三，增加模型开发阶段为生命周期添加了更多的转折点。这使得整个过程变得更加复杂。与传统软件开发不同，你只需开发一组可工作的代码。在ML中，数据科学家或ML工程师可能会使用多个ML算法并生成多个ML模型，因为只有一个模型将被选中部署到生产环境中，这些模型将根据性能与其他模型属性进行比较。MLOps适应了这种复杂的*测试、比较和选择模型*的工作流程。
- en: Building traditional code to generate an executable binary usually takes a few
    seconds to a few minutes. However, *training an ML algorithm to produce an ML
    model can take hours or days*, sometimes even weeks when you use certain **deep
    learning** (**DL**) algorithms. This makes setting up an Agile iterative time-bound
    cadence a little complicated. An MLOps-enabled team needs to handle this delay
    in their workflow, and one way to do this is to start building the other model
    while waiting for other models to be trained completely. This is very difficult
    to achieve if the data scientists or ML engineers are training their ML algorithms
    using their own laptops. This is where the use of a scalable infrastructure comes
    in handy.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 传统编码生成可执行二进制文件通常需要几秒到几分钟。然而，*训练ML算法生成ML模型可能需要几个小时或几天*，有时甚至使用某些**深度学习**（**DL**）算法时可能需要几周。这使得建立敏捷的迭代时间限制节奏稍显复杂。MLOps团队需要处理工作流中的这种延迟，一种方法是在等待其他模型完全训练完成时开始构建另一个模型。如果数据科学家或ML工程师在他们自己的笔记本电脑上训练他们的ML算法，这是非常难以实现的。这就是可扩展基础设施的用武之地。
- en: 'Lastly, because ML models'' performances rely on the data used during training,
    if this data no longer represents the real-world situation, the model accuracy
    will degrade, resulting in poor prediction performance. This is called **model
    drift**, and this needs to be detected early. This is usually incorporated as
    part of the monitoring process of the ML project life cycle. Aside from the traditional
    metrics that you collect in production, with ML models, you also need to monitor
    model drift and outliers. Outlier detection, however, is much more difficult to
    implement, and sometimes requires you to train and build another ML model. **Outlier
    detection** is about detecting incoming data, in production, that does not look
    like the data the model was trained on: you do not want your model to provide
    irrelevant answers to these non-related questions. Another reason is that this
    could be an attack or an attempt to abuse the system. Once you have detected model
    drift or outliers, what are you going to do with this information? It could very
    well be just about raising an alert, or it could trigger some other automated
    processes.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，由于ML模型的性能依赖于训练过程中使用的数据，如果这些数据不再代表现实世界的情况，模型的准确性将会下降，从而导致预测性能变差。这被称为**模型漂移**，并且需要尽早检测。通常，这会作为ML项目生命周期监控过程的一部分进行。除了在生产中收集的传统指标外，使用ML模型时，你还需要监控模型漂移和异常值。然而，异常值检测的实现要困难得多，有时需要你训练并构建另一个ML模型。**异常值检测**是关于检测生产中进入的数据，这些数据与模型训练时使用的数据不相符：你不希望你的模型给出与这些无关问题的无关答案。另一个原因是，这可能是一次攻击或滥用系统的尝试。一旦你检测到模型漂移或异常值，你打算如何处理这些信息？这可能仅仅是触发警报，或者可能会触发其他自动化流程。
- en: Because of the complexity ML adds when compared to traditional programming,
    the need to address these complexities led to the emergence of MLOps.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 由于与传统编程相比，ML增加了复杂性，因此必须解决这些复杂性，促使了MLOps的出现。
- en: DevOps
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DevOps
- en: 'In terms of deployment, think about all the sets of code you write in an ML
    project: the code that performs the data processing, the code that facilitates
    model training and FE, the code that runs the model inference, and the code that
    performs model drift and outlier detection. All of these sets of code need to
    be built, packaged, and deployed for consumption at scale. This code, once running
    in production, needs to be monitored and maintained as well. This is where the
    CI/CD practices of DevOps help. The practice of automating software packaging,
    testing, securing, deploying, and monitoring came from DevOps.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在部署方面，想一想你在ML项目中编写的所有代码：执行数据处理的代码、促进模型训练和前端工程的代码、运行模型推理的代码以及执行模型漂移和异常值检测的代码。这些代码集需要构建、打包并部署以便大规模使用。一旦这些代码在生产环境中运行，它们还需要被监控和维护。这就是DevOps的CI/CD实践发挥作用的地方。自动化软件打包、测试、安全、部署和监控的实践源自DevOps。
- en: Data engineering
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 数据工程
- en: Every ML project involves **data engineering**, and ML projects deal with a
    lot of data a lot more than code. Therefore, it is mandatory that your infrastructure
    includes data processing capabilities and that it can integrate with existing
    data engineering pipelines in your organization.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 每个ML项目都涉及到**数据工程**，而且ML项目处理的数据远比代码要多。因此，确保你的基础设施包括数据处理能力，并且能够与组织中现有的数据工程管道集成，是强制性的。
- en: Data engineering is a huge subject—an entire book could be written about it.
    But what we want to emphasize here is that MLOps intersects with data engineering
    practices, particularly in **data ingestion**, **data cleansing**, **data transformation**,
    and **big data testing**. In fact, your ML project could be just a small ML classification
    model that is a subpart of a much bigger data engineering or data analytics project.
    MLOps adopts the best practices in data engineering and analytics.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程是一个庞大的主题—可以写一本书来讲述它。但我们在这里想强调的是，MLOps与数据工程实践交叉，特别是在**数据摄取**、**数据清洗**、**数据转换**和**大数据测试**方面。事实上，你的ML项目可能只是一个小型的ML分类模型，它是一个更大数据工程或数据分析项目的子部分。MLOps采纳了数据工程和分析中的最佳实践。
- en: 'A representation of MLOps is provided in the following diagram:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图表展示了MLOps的表示：
- en: '![Figure 2.4 – MLOps as the intersection of ML, data engineering, and DevOps'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.4 – MLOps作为ML、数据工程和DevOps的交集'
- en: '](img/B18332_02_004.jpg)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_02_004.jpg)'
- en: Figure 2.4 – MLOps as the intersection of ML, data engineering, and DevOps
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.4 – MLOps作为ML、数据工程和DevOps的交集
- en: To put it in another way, MLOps, as shown in *Figure 2.4*, is the convergence
    of **ML**, **DevOps**, and **data engineering** disciplines that focus on running
    ML in production. It is also about encapsulating ML projects in a highly scalable,
    reliable, observable infrastructure. Finally, it is also about establishing repeatable
    processes for teams to perform the tasks required to successfully deliver ML projects,
    as shown in *Figure 2.4*, while supporting collaboration with each other.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 用另一种方式来说，MLOps，如*图2.4*所示，是**ML**、**DevOps**和**数据工程**学科的融合，专注于在生产环境中运行ML。它还涉及将ML项目封装在一个高度可扩展、可靠且可观测的基础设施中。最后，它还涉及为团队建立可重复的流程，以执行成功交付ML项目所需的任务，如*图2.4*所示，同时支持团队之间的协作。
- en: With this basic understanding of MLOps, let's dig a little deeper into the ML
    project life cycle. We'll start by defining what are the general stages of an
    ML project.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 有了对MLOps的基本理解后，让我们更深入地探讨ML项目生命周期。我们将从定义ML项目的一般阶段开始。
- en: ML project life cycle
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ML项目生命周期
- en: 'As with DevOps, which provides a series of activities that could be performed
    in a DevOps cycle, you can see a series of steps that could be used to take your
    ML project from start to finish in *Figure 2.5*. These steps or stages will become
    part of your ML projects'' life cycle and provide a consistent way to take your
    ML projects into production. The ML platform that you build in this book is the
    ecosystem that allows you to implement this flow. In later chapters of this book,
    you will use this flow as the basis for the platform. A summary of the stages
    in an ML project could be depicted as follows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 与DevOps类似，DevOps提供了一系列活动，可以在DevOps周期中执行，你可以在*图2.5*中看到一系列步骤，这些步骤可用于将你的ML项目从开始到结束。这些步骤或阶段将成为ML项目生命周期的一部分，并提供一种一致的方式将ML项目投入生产。你在本书中构建的ML平台是允许你实现这个流程的生态系统。在本书的后续章节中，你将使用这个流程作为平台的基础。ML项目的各个阶段总结如下：
- en: '![Figure 2.5 – A ML project life cycle'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '![图2.5 - 一个ML项目生命周期'
- en: '](img/B18332_02_005.jpg)'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_02_005.jpg)'
- en: Figure 2.5 – A ML project life cycle
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 图2.5 - 一个ML项目生命周期
- en: 'Here is a definition of each stage of the project life cycle presented in the
    preceding diagram:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是前面图表中呈现的每个阶段的定义：
- en: '**Codify the problem and define success metrics**: In this stage, the team
    evaluates if the given business problem can be solved using ML. Notice the word
    *team* here, which would consist of data scientists and the business **subject-matter
    expert** (**SME**) at a minimum. The team will then define a success criterion
    to assess the prediction of the model.'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**编码问题并定义成功指标**：在这个阶段，团队评估给定的业务问题是否可以通过ML来解决。请注意这里的“团队”一词，团队至少包括数据科学家和业务**领域专家**（**SME**）。团队将定义一个成功标准，以评估模型的预测结果。'
- en: '**Ingest, clean, and label data**: In this stage, the team assesses if the
    data required to train the model is available. The team will play an additional
    role, that of data engineers, to help move the project during this stage and beyond.
    The team will build components to ingest data from a variety of sources, clean
    the captured data, possibly label the data, and store it. This data will form
    the basis of ML activities.'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**获取、清洗和标注数据**：在这个阶段，团队评估是否有可用的数据来训练模型。团队将扮演额外的角色——数据工程师，帮助推动项目在这一阶段及其后的进展。团队将构建组件，从各种来源获取数据，清洗获取的数据，可能会标注数据并存储它。这些数据将构成ML活动的基础。'
- en: '**FE**: FE is about transforming the raw data into features that are more relevant
    to the given problem. Consider you are building a model that predicts if any given
    passenger on the *Titanic* will survive or not. Imagine the dataset you got contains
    the ticket number of the passenger. Do you think ticket numbers have something
    to do with the survival of the passenger? A business SME may mention that ticket
    numbers may be able to provide which class the customer belongs to on the ship,
    and first-class passengers may have easier access to lifeboats on the ship.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**FE**：FE是指将原始数据转化为与给定问题更相关的特征。假设你正在构建一个模型，用来预测任何给定的*泰坦尼克号*乘客是否会生还。假设你得到的数据集包含了乘客的票号。你认为票号与乘客的生还有关系吗？一位业务领域专家（SME）可能会提到，票号可能能提供乘客所在舱位的信息，而头等舱的乘客可能更容易获得船上的救生艇。'
- en: '**Model building and tuning**: In this stage, the team starts experimenting
    with different models and different hyperparameters. The team will test the model
    against the given dataset and compare the results of each iteration. The team
    will then determine the best model for the given success metrics and store the
    model in the model registry.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型构建和调优**：在这个阶段，团队开始尝试不同的模型和不同的超参数。团队会将模型与给定的数据集进行测试，并比较每次迭代的结果。然后，团队会根据给定的成功指标确定最佳模型，并将该模型存储在模型注册表中。'
- en: '**Model validation**: In this stage, the team validates the model against a
    new set of data that is not available at the training time. This stage is critical
    as it **determines** if the model is generalized enough for the unseen data, or
    if the model only works well on the training data but not on the unseen data—in
    other words, avoiding **overfitting**. Model validation also involves identifying
    **model biases**.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型验证**：在这个阶段，团队使用一个在训练时无法获取的新数据集来验证模型。这个阶段至关重要，因为它**决定**了模型是否足够泛化以应对未见过的数据，或者模型只在训练数据上表现良好，而无法处理未见过的数据——换句话说，就是避免**过拟合**。模型验证还包括识别**模型偏差**。'
- en: '**Model deployment**: In this stage, the team picks the model from the model
    registry, packages it, and deploys it to be consumed. Traditional DevOps processes
    could be used here to make the model available as a service. In this book, we
    will focus on **model as a service** (**MaaS**), where the model is available
    as a **REpresentational State Transfer** (**REST**) service. However, in certain
    scenarios, the model could be packaged as a library for other applications to
    use it.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署**：在这个阶段，团队从模型注册表中选取模型，将其打包并部署以供使用。传统的DevOps流程可以在这里使用，将模型作为服务提供。在本书中，我们将专注于**模型即服务**（**MaaS**），即将模型作为**表现性状态转移**（**REST**）服务提供。然而，在某些情况下，模型可以作为库打包，供其他应用程序使用。'
- en: '**Monitoring and validation**: In this stage, the model will be continually
    monitored for response times, the accuracy of predictions, and whether the input
    data is like the data on which the model is trained. We have briefly touched on
    outlier detection. In practice, it works like this: imagine that you have trained
    your model for rush-hour vacancy in a public transport system, and the data the
    model is trained against is where citizens use the public transport system for
    over a year. The data will have variances for weekends, public holidays, and any
    other events. Now, imagine if, due to the COVID-19 lockdown, no one is allowed
    to use the public transport system. The real world is not the *same* as compared
    to the data our model is trained upon. Naturally, our model is not particularly
    useful for this changed world. We will need to detect this anomaly and generate
    alerts so that we can retrain our model with the new datasets if possible.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控和验证**：在这个阶段，模型将持续监控响应时间、预测的准确性，以及输入数据是否与模型训练时的数据相似。我们简要介绍了异常值检测。在实践中，它的运作方式是这样的：假设你已经为公共交通系统的高峰时段空车率训练了一个模型，且模型训练时的数据是市民使用公共交通系统超过一年的数据。数据会存在周末、公共假期和其他事件的变化。现在，假设由于COVID-19封锁，所有人都不允许使用公共交通系统。现实世界与我们模型训练时的数据**不同**。自然地，我们的模型在这种变化的世界中并不是特别有用。我们需要检测这种异常并生成警报，以便在可能的情况下，我们能够使用新的数据集重新训练模型。'
- en: You have just learned the stages of the ML project life cycle. Although the
    stages may look straightforward, in the real world, there are several good reasons
    why you need to go back to previous stages in certain cases.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚了解了机器学习项目生命周期的各个阶段。尽管这些阶段看起来很简单，但在现实世界中，确实有一些很好的理由在某些情况下需要回到之前的阶段。
- en: Fast feedback loop
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 快速反馈循环
- en: A keen observer may have noticed that a key attribute of the Agile and cross-functional
    teams that we presented in the first chapter is not available in the stages presented
    so far in this chapter. Modern DevOps is all about fast feedback loops to course-correct
    early in the project life cycle. The same concept will bring even more value to
    ML projects because ML projects are more complex than traditional software applications.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 一个敏锐的观察者可能已经注意到，在第一章中我们展示的敏捷和跨职能团队的一个关键特征，在本章目前展示的阶段中并没有出现。现代DevOps的核心就是快速反馈循环，以便在项目生命周期的早期进行调整。这个概念将为机器学习项目带来更多的价值，因为机器学习项目比传统的软件应用程序更为复杂。
- en: Let's see at which stages we can assess and evaluate the progress of the team.
    After evaluation, the team can decide to course-correct by going back to an earlier
    stage or moving on to the next stage.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看在哪些阶段可以评估和衡量团队的进展。评估后，团队可以决定通过回到早期阶段进行调整，或继续推进到下一个阶段。
- en: 'The following diagram shows the ML project life cycle with feedback checkpoints
    from various stages, denoted by green arrows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了带有各个阶段反馈检查点的机器学习项目生命周期，用绿色箭头表示：
- en: '![Figure 2.6 – A ML project life cycle with feedback checkpoints'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.6 – 带有反馈检查点的机器学习项目生命周期'
- en: '](img/B18332_02_006.jpg)'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_02_006.jpg)'
- en: Figure 2.6 – A ML project life cycle with feedback checkpoints
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.6 – 带有反馈检查点的机器学习项目生命周期
- en: 'Let''s look at this in more detail here:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在这里更详细地看看：
- en: '**Checkpoint from the ingest, clean, and label data stage**: After *Stage 1*
    is completed, you have started to process data as defined in the second stage.
    You may find that the actual data is incomplete or not correct. You can take this
    feedback to improve your understanding of data and may need to redefine the success
    criteria of the project or, in worse cases, stop the project because the required
    data is not available. In many scenarios, teams find additional data sources to
    fill the data gap identified in the second stage.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据摄取、清理和标注阶段的检查点**：在完成*第一阶段*后，你已经开始按第二阶段的定义处理数据。你可能会发现实际数据不完整或不正确。你可以根据这些反馈改进对数据的理解，并可能需要重新定义项目的成功标准，或者在最坏的情况下，由于所需的数据不可用而停止项目。在许多场景中，团队会寻找额外的数据来源来填补第二阶段中识别的数据空白。'
- en: '**Checkpoint from the model building and tuning stage**: During this stage,
    the team may find that the features available to train the model may not be enough
    to get the desired metric. At this point, the team may decide to invest more time
    in finding new features or revisit the raw data to determine if more data is needed.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型构建与调优阶段的检查点**：在这个阶段，团队可能会发现用于训练模型的特征不足以获得预期的指标。此时，团队可能会决定花更多时间寻找新特征，或者重新审视原始数据，以确定是否需要更多数据。'
- en: '**Checkpoint from the model validation stage**: During this stage, the model
    will be validated against a new dataset that the model has never seen before.
    Poor metrics at this stage may trigger the tuning of the model, or you may decide
    to go back to find more features for better model performance,'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型验证阶段的检查点**：在这个阶段，模型将针对一个模型从未见过的新数据集进行验证。此时指标较差可能会触发模型的调优，或者你也可以决定回去寻找更多特征，以提升模型的性能。'
- en: '**Checkpoint from the model monitoring and validation stage**: Once the model
    moves into production, it must be monitored continuously to validate if the model
    is still relevant to the real and changing world. You need to find out if the
    model is still relevant and, if not, how you can make the model more useful. The
    result of this may trigger any other stage in the life cycle; as you can see in
    *Figure 2.6*, you may end up retraining an existing model with new data or going
    to a different model altogether, or even rethinking if this problem *should* be
    tackled by ML. There is no definitive answer on which stage you end up at; just
    as with the real world, it is unpredictable. However, what is important is the
    capability to re-assess and re-evaluate, and to continue to deliver value to the
    business.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型监控与验证阶段的检查点**：一旦模型进入生产阶段，就必须持续监控，以验证模型是否仍然与现实世界和变化中的世界相关。你需要找出模型是否仍然有效，如果无效，如何使模型变得更有用。这个结果可能会触发生命周期中的其他任何阶段；正如在*图
    2.6*中所看到的，你可能最终会使用新数据重新训练现有模型，或者完全换用不同的模型，甚至重新思考是否应该用机器学习来解决这个问题。没有确定的答案能告诉你最终会到哪个阶段，就像现实世界一样，它是不可预测的。然而，重要的是具备重新评估和重新审视的能力，并持续为业务创造价值。'
- en: You have seen the stages of the ML project life cycle and the feedback checkpoints
    from which you decided whether to continue to the next stage or go back to previous
    stages. Now, let's look at the personas involved in each of the stages and their
    collaboration points.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了机器学习项目生命周期的各个阶段以及从这些阶段获得的反馈检查点，决定是否继续推进到下一个阶段或返回上一个阶段。现在，让我们来看看每个阶段涉及的角色以及他们的合作点。
- en: Collaborating over the project life cycle
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在项目生命周期中的协作
- en: We have defined a streamlined process for building our model. Let's try to define
    how a team of diverse roles and abilities will collaborate on this model. Recall
    from the previous chapter that building a model takes effort from different teams
    with different abilities. It is important to note that in smaller projects, the
    same person may be representing different roles at the same time. For example,
    in a small project, the same person can be both a data scientist and a data engineer.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: 'The following diagram shows an ML project life cycle with an overlay of feedback
    points and personas:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 2.7 – A ML project life cycle with feedback checkpoints and team roles'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_02_007.jpg)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2.7 – A ML project life cycle with feedback checkpoints and team roles
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: The ML project within your organization needs collaboration between data scientists
    and the business SMEs in the first stage. Imagine the team wants to predict, based
    on a picture, the probability of a certain type of skin disease.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: At this stage, a collaboration between data scientists and doctors (the SME
    for this case) is needed to define the problem and the performance metrics. Without
    this collaboration, the project would not be successful.
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the second stage—the data ingestion and cleaning stage—data engineers will
    need to work along with the business SMEs to understand which data is available
    and how to clean and label it correctly. The knowledge the SMEs will bring during
    this stage is critical as this is responsible for creating a useful dataset for
    future stages.
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the third stage, data scientists, data engineers, and SMEs will collaborate
    to work on the base data from the second stage and process it to extract useful
    features from it. The data scientists and SMEs will provide guidance on which
    data can be extracted, and the data engineer will write processing logic to do
    so.
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In the fourth and the fifth stages, most of the work will be done by data scientists
    to build and tune the model as per the given criteria. However, based on whether
    or not the model has managed to achieve the defined metric, the team may decide
    to go back to any of the previous stages for better performance.
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Once the model is built, the DevOps team experts can package, version, and deploy
    the model to the correct environment.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: 'The last stage is critical: the team uses observability capabilities to monitor
    the performance of the model in the production environment. After monitoring the
    model performance in the real world and based on the feedback, the team may again
    decide to go back to any of the previous stages to make the model more useful
    for the business.'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you have a good understanding of the challenges we have highlighted
    and how you can overcome these challenges using the ML life cycle, the next phase
    is to have a platform that supports this life cycle while providing a solution
    for each component defined in the big picture (see [*Chapter 1*](B18332_01_ePub.xhtml#_idTextAnchor015),
    *Challenges in Machine Learning*) with self-service and automation capabilities.
    What better way to start a journey while collaborating with the open source community?
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经很好地理解了我们所提到的挑战，以及如何通过机器学习生命周期克服这些挑战，接下来的阶段是要有一个支持这一生命周期的平台，同时为大图中的每个组件提供解决方案（请参见[*第1章*](B18332_01_ePub.xhtml#_idTextAnchor015)，*机器学习中的挑战*），并具备自服务和自动化能力。与开源社区合作，开始这段旅程，还有什么比这更好的方式呢？
- en: The role of OSS in ML projects
  id: totrans-102
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 开源软件在机器学习项目中的角色
- en: Now that you have a clear understanding of what problems the ML platform is
    expected to solve, let's see why open source is the best place to start. We should
    start with some definitions to set the basics, right?
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经清楚地了解了机器学习平台需要解决的问题，接下来我们来看一下为什么开源是最好的起点。我们应该从一些定义开始，以便打好基础，对吧？
- en: Free OSS is where *the users have the freedom to run, copy, distribute, study,
    change, and improve the software*.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 免费的开源软件（OSS）是指*用户有自由运行、复制、分发、研究、修改和改进软件*的地方。
- en: OSS
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 开源软件
- en: 'For more information on OSS, see the following link:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 想了解更多关于开源软件的信息，请参阅以下链接：
- en: '[https://www.gnu.org/philosophy/free-sw.html](https://www.gnu.org/philosophy/free-sw.html)'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://www.gnu.org/philosophy/free-sw.html](https://www.gnu.org/philosophy/free-sw.html)'
- en: OSS is everywhere. Linux is the most common operating system, running in data
    centers and powering the cloud around the world. Apache Spark and related open
    source technologies are the foundation for the big data revolution for a range
    of organizations. Open source-based **artificial intelligence** (**AI**) technologies
    such as TensorFlow and MLflow are at the forefront of AI advancement and are used
    by hundreds of organizations. Kubernetes, the open source container orchestration
    platform, has become the de facto standard for container platforms.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 开源无处不在。Linux是最常见的操作系统，运行在数据中心并支持全球云计算。Apache Spark和相关的开源技术是大数据革命的基础，帮助众多组织实现其目标。基于开源的**人工智能**（**AI**）技术，如TensorFlow和MLflow，处于AI发展的前沿，并被成百上千的组织所使用。开源的容器编排平台Kubernetes已经成为容器平台的事实标准。
- en: The top players in computing—such as Amazon, Apple, Facebook, Google, Microsoft,
    and Red Hat, to name a few—have contributed to and owned major open source projects,
    and fresh players are joining all the time. Businesses and governments around
    the world depend on open source to power mission-critical and highly scalable
    systems every day.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 计算领域的顶级玩家——如亚马逊、苹果、Facebook、谷歌、微软和红帽等——已经为主要开源项目做出贡献并拥有这些项目，而且新的参与者也不断加入。全球各地的企业和政府每天都依赖开源软件来支持关键任务和高可扩展的系统。
- en: One of the most successful open source projects in the cloud computing space
    is **Kubernetes**. Kubernetes was founded in mid-2014 and was followed by the
    release of its version 1.0 in mid-2015\. Since then, it has become the de facto
    standard for container orchestration.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 云计算领域最成功的开源项目之一就是**Kubernetes**。Kubernetes成立于2014年中期，2015年中期发布了它的1.0版本。自那时以来，它已成为容器编排的事实标准。
- en: Moreover, the **Cloud Native Computing Foundation** (**CNCF**) was created by
    *The Linux Foundation* with the mission of making cloud computing ubiquitous.
    CNCF does this by bringing together the world's top engineers, developers, end
    users, and vendors. They also run the world's largest open source conferences.
    The foundation was created by using **Kubernetes** as the seed project. This is
    how Kubernetes sets the standard definition of **cloud native**. As of this writing,
    the foundation has 741 member organizations and 130 certified Kubernetes distributions
    and platforms and has graduated 16 very successful open source projects. Among
    those projects is, of course, **Kubernetes** but also the **Operator Framework**,
    which you will learn more about in the next chapter.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，**云原生计算基金会**（**CNCF**）是由*Linux基金会*创建的，使命是让云计算无处不在。CNCF通过汇集世界顶级工程师、开发者、终端用户和供应商来实现这一目标。它们还举办世界上最大的开源会议。基金会的创建使用了**Kubernetes**作为种子项目。正是通过这个项目，Kubernetes设定了**云原生**的标准定义。截至本文撰写时，基金会已经有741个会员组织，130个认证的Kubernetes发行版和平台，并且已经毕业了16个非常成功的开源项目。当然，其中包括**Kubernetes**，还有**Operator
    Framework**，你将在下一章了解更多关于它的内容。
- en: Before the explosion of **big data** and **cloud computing**, ML projects were
    mostly academic. They seldom left the boundaries of colleges and universities,
    but this doesn't mean that AI, ML, and **data science** were not progressing forward.
    The academic world has actually created hundreds of open source Python libraries
    for mathematical, scientific, and statistical calculations. These libraries have
    become the foundation modern ML frameworks are built upon. The most popular ML
    frameworks at the time of writing—TensorFlow, PyTorch, scikit-learn, and Spark
    ML—are all open source. The most popular data science and ML development environments
    today—Jupyter Notebook, JupyterLab, JupyterHub, Anaconda, and many more—are also
    all open source.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在**大数据**和**云计算**爆炸式发展的之前，机器学习（ML）项目主要是学术性质的。它们很少走出高校的范围，但这并不意味着人工智能（AI）、机器学习（ML）和**数据科学**没有向前发展。学术界实际上已经创造了数百个开源的Python库，用于数学、科学和统计计算。这些库已经成为现代机器学习框架的基础。目前最流行的机器学习框架——TensorFlow、PyTorch、scikit-learn和Spark
    ML——都是开源的。如今最流行的数据科学和机器学习开发环境——Jupyter Notebook、JupyterLab、JupyterHub、Anaconda等——同样都是开源的。
- en: ML is an evolving field, and it needs the vision of larger communities that
    go beyond any single organization. The process of working in a community-based
    style enables the collaboration and creativity that is required by ML projects,
    and open source is an important part of why ML is progressing at a tremendous
    speed.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习是一个不断发展的领域，它需要超越任何单一组织的大型社区的愿景。社区合作模式的工作流程能够促进机器学习项目所需的合作与创造力，而开源正是机器学习快速发展的重要原因之一。
- en: You now have a basic understanding of how important OSS is in the AI and ML
    space. Now, let's take a closer look at why you should run ML projects on Kubernetes.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经对开源软件（OSS）在人工智能和机器学习领域的重要性有了基本了解。接下来，让我们更详细地看看为什么你应该在Kubernetes上运行机器学习项目。
- en: Running ML projects on Kubernetes
  id: totrans-115
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在Kubernetes上运行机器学习项目
- en: For building reliable and scalable ML systems, you need a rock-solid base. **Kubernetes**
    provides the foundation for building scalable and reliable distributed systems
    along with the self-service capabilities that are required by our platform. The
    capability of Kubernetes to abstract the hardware infrastructure and consume it
    as a single unit is of great benefit to our platform.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建可靠且可扩展的机器学习系统，你需要一个稳固的基础。**Kubernetes**为构建可扩展且可靠的分布式系统提供了基础，并提供了平台所需的自助服务功能。Kubernetes能够将硬件基础设施抽象为一个单一的单元进行消费，这对于我们的平台具有巨大的益处。
- en: Another key component is the ability of Kubernetes-based software to run anywhere,
    from small on-premises data centers to large hyperscalers (**Amazon Web Services**
    (**AWS**), **Google Cloud Platform** (**GCP**), Azure). This capability will give
    you the portability to run your ML platform anywhere you want. The consistency
    it brings to the consumer of your platform is brilliant as the team can experiment
    with extremely low initial costs on the cloud and then customize the platform
    for a wider audience in your enterprise.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关键因素是基于Kubernetes的软件能够在任何地方运行，从小型本地数据中心到大型超大规模云平台（**Amazon Web Services**（**AWS**）、**Google
    Cloud Platform**（**GCP**）、Azure）。这个能力将为你提供在任何你想要的地方运行机器学习平台的可移植性。它带给平台使用者的统一性非常出色，因为团队可以在云上以极低的初始成本进行实验，然后根据企业的更广泛需求定制平台。
- en: The third and final reason to opt for Kubernetes is its capability to run different
    kinds of workloads. You probably remember from the previous chapter that a successful
    ML project needs not only ML but also infrastructure automation, data life cycle
    management, stateful components, and more. Kubernetes provides a consistent base
    to run diverse types of software components to create an **end-to-end** (**E2E**)
    solution for business use cases.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 选择Kubernetes的第三个也是最后一个理由是其能够运行不同类型的工作负载。你可能还记得在前一章中提到的，成功的机器学习项目不仅需要机器学习，还需要基础设施自动化、数据生命周期管理、有状态组件等。Kubernetes提供了一个一致的基础，可以运行各种类型的软件组件，从而为业务用例创建一个**端到端**（**E2E**）的解决方案。
- en: 'The following screenshot shows the layers of an ML platform. Kubernetes provides
    the scaling and abstracting layer on which an ML platform is built. Kubernetes
    offers the freedom of abstracting the underlying infrastructure. Because of this
    flexibility, we can run on a variety of cloud providers and on-premises solutions.
    The ML platform you will build in this book allows operationalization and self-service
    in the three wider areas of an ML project—FE, model development, and DevOps:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了一个 ML 平台的各个层次。Kubernetes 提供了一个扩展和抽象层，ML 平台就是在这个层次上构建的。Kubernetes 提供了抽象底层基础设施的自由。正因如此，我们可以在各种云服务商和本地解决方案上运行。你将在本书中构建的
    ML 平台支持 ML 项目三个更广泛领域的运营化和自助服务——前端（FE）、模型开发和 DevOps：
- en: '![Figure 2.8 – An OSS-based ML platform'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 2.8 – 基于开源软件的 ML 平台'
- en: '](img/B18332_02_008.jpg)'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_02_008.jpg)'
- en: Figure 2.8 – An OSS-based ML platform
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2.8 – 基于开源软件的 ML 平台
- en: 'There you go: your ML platform will be based on OSS and will use Kubernetes
    as the hosting base. The strength of the open source Kubernetes communities will
    help you use the best technologies that will evolve as the field continues to
    mature.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样：你的 ML 平台将基于开源软件，并使用 Kubernetes 作为托管基础。开源 Kubernetes 社区的力量将帮助你使用最好的技术，而这些技术会随着领域的不断成熟而不断发展。
- en: Summary
  id: totrans-124
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have defined the term *MLOps* and suggested an ML project
    life cycle that is collaborative and provides early feedback. You have learned
    that with this project life cycle, the team can continuously deliver value to
    the business. You have also learned about some of the reasons why building a platform
    based on OSS makes sense and the benefits of community-driven software.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 本章中，我们定义了 *MLOps* 这一术语，并提出了一个协作型的 ML 项目生命周期，能够提供早期反馈。你已经了解到，通过这个项目生命周期，团队可以持续向业务提供价值。你还了解了为何基于开源软件构建平台是合理的，以及社区驱动软件的好处。
- en: This completes the part of the book about setting the context, learning why
    a platform is needed, and discovering what kinds of problems it is expected to
    solve. In the next chapter, we will examine some basic concepts of the Kubernetes
    system that is at the heart of our ML platform.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 本书的这一部分介绍了设置背景、学习为何需要平台以及探索平台预期解决的各种问题。下一章我们将探讨 Kubernetes 系统的一些基本概念，它是我们 ML
    平台的核心。
- en: Further reading
  id: totrans-127
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'For more information regarding the topics that were covered in this chapter,
    take a look at the following resources:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 有关本章所涵盖主题的更多信息，请查阅以下资源：
- en: '*DevOps: Breaking the development-operations barrier* [https://www.atlassian.com/devops](https://www.atlassian.com/devops)'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*DevOps：打破开发与运维的壁垒* [https://www.atlassian.com/devops](https://www.atlassian.com/devops)'
