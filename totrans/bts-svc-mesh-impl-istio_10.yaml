- en: '10'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deploying Istio Service Mesh for Non-Kubernetes Workloads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Istio and Kubernetes are technologies that complement each other. Kubernetes
    solves the problem of managing distributed applications packaged as containers
    isolated from each other and deployed in a consistent environment with dedicated
    resources. Although Kubernetes solves container deployment, scheduling, and management,
    it doesn’t solve traffic management between containers. Istio complements Kubernetes
    by providing traffic management capabilities, adding observability, and enforcing
    a zero-trust security model.
  prefs: []
  type: TYPE_NORMAL
- en: Istio is like a sidecar to Kubernetes; having said that, Kubernetes is a fairly
    new technology that got mainstream adoption approximately around 2017\. From 2017
    onward, most enterprises have used Kubernetes when building microservices and
    other cloud-native applications, but there are still many applications that are
    not built on Kubernetes and/or not migrated to Kubernetes; such applications are
    traditionally deployed on **virtual machines** (**VMs**). VMs are not just limited
    to traditional data centers but are also a mainstream offering from cloud providers.
    Organizations end up having this parallel universe of Kubernetes-based applications
    and VM-based applications deployed across the cloud and on-premises.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will read about how Istio helps to marry these two worlds
    of legacy and modern technologies and how can you extend Service Mesh beyond Kubernetes.
    In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Examining hybrid architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Setting up a Service Mesh for hybrid architecture
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Using the following commands, we will set up the infrastructure in Google Cloud
    that will be used for hands-on exercises:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a Kubernetes cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a VM:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Check your `kubectl` file to find the cluster name and set `context` appropriately:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Access the created server using **SSH** from the Google Cloud dashboard – you
    will find the **SSH** option in the bottom-right corner, as shown in the following
    screenshot:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.1 – Google Cloud dashboard](img/B17989_10_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.1 – Google Cloud dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'Click on **SSH**, which will open **SSH-in-browser**, as shown in the following
    figure:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 10.2 – SSH-in-browser](img/B17989_10_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.2 – SSH-in-browser
  prefs: []
  type: TYPE_NORMAL
- en: 'Find the username and then SSH from your terminal:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set up the firewall to allow traffic between the Kubernetes cluster and VM
    using the following steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Find the **Classless Inter-Domain Routing** (**CIDR**) of the cluster:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create firewall rules:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: That’s all you need for the upcoming sections. We will first explore some fundamentals
    and then go through the actual setup.
  prefs: []
  type: TYPE_NORMAL
- en: Examining hybrid architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As mentioned in the introduction of this chapter, organizations have adopted
    Kubernetes and they run microservices and various other workloads as containers,
    but not all workloads are suitable for containers. So, organizations have to live
    with following a hybrid architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.3 – Hybrid architecture](img/B17989_10_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.3 – Hybrid architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Appliances and legacy applications are usually deployed on bare metal servers.
    Monolithic applications, as well as several **commercial off-the-shelf** (**COTS**)
    applications, are deployed on VMs. Modern applications, as well as self-developed
    applications based on microservices architecture, are deployed as containers that
    are managed and orchestrated by platforms such as Kubernetes. All three deployment
    models – that is, bare metal, VMs, and containers – are spread across traditional
    data centers and various cloud providers. This intermingling of various application
    architectures and deployment patterns causes various problems:'
  prefs: []
  type: TYPE_NORMAL
- en: Management of traffic flows between the Service Mesh and VM is challenging because
    neither of them has any idea of the other’s existence
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No operational visibility of application traffic between VM applications and
    applications within the Service Mesh
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Inconsistent governance of VMs and applications within the Service Mesh because
    there is no consistent way of defining and applying security policies for VM apps
    and apps within the mesh
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following is an example of how traffic flows in an environment with a VM
    and Service Mesh:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.4 – Traffic across Service Mesh and VM is managed separately](img/B17989_10_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.4 – Traffic across Service Mesh and VM is managed separately
  prefs: []
  type: TYPE_NORMAL
- en: A VM is treated as a separate universe. Developers have to choose one of the
    deployment patterns because they can’t have system components spread across VMs
    and containers. This is okay for legacy systems but when building applications
    based on microservice architecture, it is constraining to choose between VMs and
    containers. For example, your system may need a database that might be best suited
    for VM-based deployment, whereas the rest of the application might be well suited
    for container-based deployment. Although there are many traditional solutions
    to route traffic between the Service Mesh and VM, doing so results in disparate
    networking solutions. Luckily, Istio provides options to establish a Service Mesh
    for VMs. The solution is to abstract VMs under Istio constructs so that the Service
    Mesh operator can operate the network between containers and VMs consistently.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn how to configure a Service Mesh for VMs.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a Service Mesh for hybrid architecture
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will set up the Service Mesh. But first, let’s look at the
    steps at a high level in the *Overview of the setup* section and then perform
    implementation in the *Setting up a demo app on a virtual* *machine* section.
  prefs: []
  type: TYPE_NORMAL
- en: Overview of the setup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Envoy** is a great networking software and an excellent reverse proxy; it
    is also widely adopted as a standalone reverse proxy. **Solo.io** and a few others
    have built API gateway solutions using Envoy, and **Kong Inc.** has both Kong
    Mesh and Kuma Service Mesh technologies, which make use of Envoy as sidecars for
    the data plane.'
  prefs: []
  type: TYPE_NORMAL
- en: Envoy, when deployed as a sidecar, has no idea about being a sidecar; it communicates
    to `istiod` via the xDS protocols. Istio `init` bootstraps Envoy with the right
    configuration and details about `istiod`, and sidecar injection mounts the right
    certificates, which are then used by Envoy to authenticate itself with `istiod`;
    once bootstrapped, it keeps fetching correct configurations via xDS APIs.
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the same concepts, Istio packages Envoy as a sidecar for VMs. An Istio
    operator will need to perform the steps shown in the following figure to include
    a VM into the Service Mesh:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.5 – Steps to include VM into the mesh](img/B17989_10_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.5 – Steps to include VM into the mesh
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is a brief overview of the steps we will be implementing in the
    next section:'
  prefs: []
  type: TYPE_NORMAL
- en: For the VM sidecar to access the Istio control plane, we need to expose `istiod`
    via the east-west gateway. So, we install another Ingress gateway for east-west
    traffic purposes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We expose `istiod` services via the east-west gateway. This and the previous
    step are similar to the steps required for a multi-cluster Service Mesh setup,
    as discussed in *Chapter 8*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The sidecar in the VM needs to access the Kubernetes API server but because
    the VM isn’t part of the cluster, it does not have access to **Kubernetes credentials**.
    To solve that problem, we will manually create a service account in Kubernetes
    for the VM sidecar to access the API server. We are doing it manually here, but
    it can be automated using an external credential management service such as **HashiCorp
    Vault**.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next step is the creation of the Istio `WorkloadGroup` provides specifications
    that are used by sidecars to bootstrap themselves. It can be shared by collections
    of VMs that are running similar types of workloads. In `WorkloadGroup`, you define
    labels through which the workload will be identified in Kubernetes as well as
    other nuances, such as what ports are exposed, the service account to be used,
    and various health check probes. To some extent, `WorkloadGroup` is similar to
    deployment descriptors in Kubernetes. We will look at it in more detail in the
    next section during the setup.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The operator needs to manually generate the configuration that will be used
    to configure the VM and the sidecar. This step has some challenges when it comes
    to generating configuration for auto-scalable VMs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In this step, we need to copy the configuration from previous step to the VM
    at set locations.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The Istio sidecar needs to be installed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Finally, the Istio sidecar needs to be started and some checks performed to
    ensure that it has picked up the configuration created in *step 5*.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once the Istio sidecar is started, it will intercept the outgoing traffic and
    route it according to the Service Mesh rules as long as the target service endpoints,
    which can be VMs or Kubernetes Pods, are on the same network. The Ingress gateway
    is fully aware of the VM workload and can route traffic, and the same applies
    to any traffic inside the mesh, as shown in the following figure:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.6 – VM workload treated similarly to other workloads in the mesh](img/B17989_10_06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.6 – VM workload treated similarly to other workloads in the mesh
  prefs: []
  type: TYPE_NORMAL
- en: '**Pod connectivity** assumes that the cluster network uses the same address
    space as standalone machines. For cloud-managed Kubernetes (Google GKE and Amazon
    EKS), it is the default networking mode, but for self-managed clusters, you need
    a networking subsystem such as Calico to implement a flat routable network address
    space. In the next section, we will perform the setup of Istio on VMs, so roll
    up your sleeves and make sure that you have completed the tasks described in the
    *Technical* *requirements* section.'
  prefs: []
  type: TYPE_NORMAL
- en: Setting up a demo app on a VM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will first install an application on the VM to mimic a VM workload/application
    that we can use for testing the overall setup. To do this, we need to perform
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Set up Envoy on the VM. Follow the instructions as provided by Envoy at [https://www.envoyproxy.io/docs/envoy/latest/start/install](https://www.envoyproxy.io/docs/envoy/latest/start/install)
    for the operating system you selected for creating the VM. This can be done as
    follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install `envoy`, as shown in the following code block:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Configure Envoy to run a dummy application:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using `envoy-demo.yaml` and copy the contents of `Chapter4/envoy-config-2.yaml`.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Check that the contents of `envoy-demo.yaml` match what you have copied or
    created.*   Run `envoy` with the config provided in `envoy-demo.yaml`:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Test that the application is running on the VM:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With an application running on the VM, we can now proceed with the rest of the
    setup. Please note that it is not mandatory to set up the application before installing
    Istio on the VM. You can install the demo application on the VM at any time before
    or after setting up the Istio sidecar on the VM.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Istio in the cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We are assuming that you don’t have Istio running in the cluster, but if you
    have, then you can skip this section. Use the following steps to set it up:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Configure the `IstioOperator` config file for installation, providing the cluster
    and network names. The file is also available at `Chapter10/01-Cluster1.yaml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install Istio, as shown in the following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This concludes the basic installation of Istio in the cluster. Next, we will
    configure Istio to make it ready for integration with Istio on the VM.
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the Kubernetes cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we will prepare the mesh for integration with Istio on VMs:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Install the east-west gateway to expose the `istiod` validation webhook and
    services:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Expose the `istiod` services:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create a service account by following these steps:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create a namespace to host `WorkloadGroup` and `ServiceAccount`:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Set up `WorkloadGroup` as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Use the following configuration to create a workload template; the file is
    also available at `Chapter10/01-WorkloadGroup.yaml`:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the configuration. This template will be used by Istio to create workload
    entries representing the workload running on the VM:'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Before moving to the next section, let’s inspect the contents of `WorkloadGroup.yaml`.
  prefs: []
  type: TYPE_NORMAL
- en: '`WorkloadGroup` is a way to define the characteristics of the workload hosted
    in the VM and is similar to deployments in Kubernetes. `WorkloadGroup` has the
    following configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '`metadata`: This is primarily used for defining Kubernetes labels to identify
    the workloads. We have set up an `app` label with the value of `envoydummy`, which
    we can use in the Kubernetes service description to identify the endpoints to
    be abstracted by service definitions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`template`: This defines the values that will be copied over to the `WorkloadEntry`
    configuration generated by the Istio agent. The two most important values are
    the service account name and network name. `ServiceAccount` specifies the account
    name whose token will be used to generate workload identities. The network name
    is used to group endpoints based on their network location and to understand which
    endpoints are directly reachable from each other and which ones need to be connected
    via the east-west gateway, like the ones we set up for a multi-cluster environment
    in *Chapter 8*. In this instance, we have allocated the value of `network1`, which
    is the same as what we configure in `01-cluster1.yaml` (that is `cluster1`) and
    the VM are on the same network and directly reachable to each other, so we don’t
    need any special provisions for connecting them.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`probe`: This is the configuration to be used to understand the health and
    readiness of the VM workload. Traffic is not routed to unhealthy workloads, providing
    a resilient architecture. In this instance, we are configuring to perform an HTTP
    `Get` probe with a delay of 1 second after the creation of `WorkloadEntry` and
    then at regular intervals of 5 seconds. You can also define success and failure
    thresholds, for which the default values are `1` and `3` seconds, respectively.
    We have configured that the endpoint on the VM is exposed on port `10000` on the
    `root` path and it should be used to determine the health of the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, let’s get started with setting up Istio on a VM.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up Istio on a VM
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To configure and set up Istio on a VM, we will need to perform the following
    steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generate a configuration for the Istio sidecar:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will generate the following five files in the current directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Copy all files to the VM home directory first, and then copy them to various
    folders, as shown in the following code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install the Istio VM integration runtime. Download and install the package
    from [https://storage.googleapis.com/istio-release/releases/](https://storage.googleapis.com/istio-release/releases/):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Start the Istio agent on the VM and then check the status:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This completes the installation and configuration of the Istio sidecar on the
    VM.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, verify that `WorkloadEntry` is created in the `chapter10vm` namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '`WorkloadEntry` is automatically created and is a sign that the VM has onboarded
    itself successfully into the mesh. It describes the properties of the application
    running on the VM and inherits the template from the `WorkloadGroup` configuration.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Inspect the contents of `WorkloadEntry` using the following code block:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '`WorkloadEntry` contains the following values:'
  prefs: []
  type: TYPE_NORMAL
- en: '`address`: This is the network address at which the application is running
    on the VM. This can also be DNS names. In this instance, the VM’s private IP is
    `10.152.0.21`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`labels`: These are inherited from the `WorkloadGroup` definition and are used
    to identify endpoints selected by service definitions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`locality`: In a multi-data center, this field is used to identify the location
    of the workload at the rack level. This field is used for locality/proximity-based
    load balancing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`network`: This value is inherited from the `WorkloadGroup` entry.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`serviceAccount`: This value is inherited from the `WorkloadGroup` entry.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`status`: This value specifies the health of the application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By now, we have configured the Istio agent on a VM and have verified that the
    agent can communicate with Istiod. In the next section, we will integrate the
    workload on the VM with the mesh.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating the VM workload with the mesh
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s get started with performing configurations so that the mesh can route
    traffic to workloads running on the VM:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Expose the `envoydummy` app on the VM as a Kubernetes service using the following
    code block:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The configuration is standard, and it treats the VM as a Pod that needs to
    be exposed by a service. Notice the labels, which match the metadata values in
    `WorkloadGroup` definitions. When defining the service, just assume that the VM
    is nothing other than a Kubernetes Pod as defined in the `WorkloadGroup` configuration
    file. The service description file is available at `Chapter10/01-istio-gateway.yaml`.
    Apply the configuration using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we will deploy version v1 of the `envoydummy` application in the Kubernetes
    cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Notice the `route` configuration in `01-istio-gateway.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: We are routing half of the traffic to `envoydummy.chapter10vm.svc.cluster.local`,
    which represents the application running in the VM, and the other half to `envoydummy.chapter10.svc.cluster.local`,
    which represents the application running in the Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have configured all the steps for the integration of the VM workload with
    the mesh. To test the connectivity and DNS resolution of the VM, run the following
    command from the VM:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: This shows that the VM is cognizant of endpoints exposed in the Service Mesh.
    You can do it the other way round, from the Kubernetes cluster of the `curl` Pod
    described in the `utilities` folders in the GitHub repository of this book, please
    make sure that it is part of the mesh and not just a Pod running on Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, test it from the Istio Ingress gateway:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s also take a peek into the Kiali dashboard and see what the graph
    looks like. Please install Kiali using the instructions in *Chapter 7*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 10.7 – Kiali dashboard showing the traffic distribution to VM workload](img/B17989_10_07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 10.7 – Kiali dashboard showing the traffic distribution to VM workload
  prefs: []
  type: TYPE_NORMAL
- en: From the preceding figure, you can see `WorkloadEntry` in the `chapter10vm`
    namespace represented like another Pod, just like `envoydummyv1` in the `chapter10`
    namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Now that the setup is complete, let’s summarize what we’ve learned in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: VMs are an important piece of the puzzle in modern architecture and are here
    to stay for the foreseeable future along with containers. With Istio, you can
    integrate traditional workloads running on VMs into Istio Service Mesh and leverage
    all the benefits of traffic management and security provided by Istio. Istio support
    for VMs enables the inclusion of legacy applications, as well as those applications
    that cannot run on a container due to certain constraints in the mesh.
  prefs: []
  type: TYPE_NORMAL
- en: After reading this chapter, you should be able to create a mesh for hybrid architectures.
    You can now install Istio on a VM and integrate workloads with the mesh along
    with Kubernetes-based workloads. To get yourself hardened with concepts in this
    chapter, practice creating multiple VMs with different versions of the `envoydummy`
    application and then implement traffic management via virtual services and destination
    rules.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will read about various troubleshooting strategies and
    techniques to manage Istio.
  prefs: []
  type: TYPE_NORMAL
