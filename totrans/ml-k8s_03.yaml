- en: '*Chapter 4*: The Anatomy of a Machine Learning Platform'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第4章*：机器学习平台的构成'
- en: In this and the next few chapters, you will learn and install the components
    of a **machine learning** (**ML**) platform on top of Kubernetes. An ML platform
    should be capable of providing the tooling required to run the full life cycle
    of an ML project as described in [*Chapter 2*](B18332_02_ePub.xhtml#_idTextAnchor027),
    *Understanding MLOps*. This chapter starts with defining the different components
    of an ML platform in a technology-agnostic way. In the later parts, you will see
    the group of open source software that can satisfy the requirements of each component.
    We have chosen this approach to not tie you up with a specific technology stack;
    instead, you can replace components as you deem fit for your environment.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章及接下来的几章中，你将学习并安装构建在Kubernetes上的**机器学习**（**ML**）平台的各个组件。一个ML平台应当能够提供运行ML项目全生命周期所需的工具，如[*第2章*](B18332_02_ePub.xhtml#_idTextAnchor027)《理解MLOps》中所描述的那样。本章首先从技术无关的角度定义了ML平台的不同组件。在后续部分，你将看到一组开源软件，能够满足每个组件的要求。我们选择这种方式，是为了不将你束缚于特定的技术栈；相反，你可以根据自己的环境需要替换组件。
- en: The solution that you will build in this book will be based on open source technologies
    and will be hosted on the Kubernetes platform that you built in [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040),
    *Exploring Kubernetes*.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在本书中构建的解决方案将基于开源技术，并托管在你在[*第3章*](B18332_03_ePub.xhtml#_idTextAnchor040)《探索Kubernetes》中构建的Kubernetes平台上。
- en: 'In this chapter, you will learn about the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习以下主题：
- en: Defining a self-service platform
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义自助平台
- en: Exploring the data engineering components
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索数据工程组件
- en: Exploring the ML model life cycle components
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索ML模型生命周期组件
- en: Addressing security, monitoring, and automation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决安全性、监控和自动化问题
- en: Exploring Open Data Hub
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索Open Data Hub
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter includes some hands-on setup. You will be needing a running Kubernetes
    cluster configured with the **Operator Life cycle Manager** (**OLM**). Building
    such a Kubernetes environment is covered in [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040),
    *Exploring Kubernetes*. Before attempting the technical exercises in this chapter,
    please make sure that you have a working Kubernetes cluster. You may choose to
    use a different flavor of Kubernetes than the one described in [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040),
    *Exploring Kubernetes*, as long as the cluster has the OLM installed.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包括一些实践设置。你将需要一个配置了**操作符生命周期管理器**（**OLM**）的运行中Kubernetes集群。如何构建这样的Kubernetes环境已在[*第3章*](B18332_03_ePub.xhtml#_idTextAnchor040)《探索Kubernetes》中介绍。在尝试本章的技术练习之前，请确保你有一个正在工作的Kubernetes集群。你可以选择使用与[*第3章*](B18332_03_ePub.xhtml#_idTextAnchor040)《探索Kubernetes》中描述的不同版本的Kubernetes，只要该集群安装了OLM。
- en: Defining a self-service platform
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义自助服务平台
- en: '**Self-service** is defined as the capability of a platform that allows platform
    end users to provision resources on-demand without other human intervention. Take,
    for example, a data scientist user who needs an instance of a Jupyter notebook
    server, running on a host container with eight CPUs, to perform his/her work.
    A self-service ML platform should allow the data scientist to provision, through
    an end user friendly interface, the container that will run an instance of the
    Jupyter notebook server on it. Another example of self-service provisioning would
    be a data engineer requesting a new instance of an Apache Spark cluster to be
    provisioned to run his/her data pipelines. The last example is a data scientist
    who wants to package and deploy their ML model as a REST service so that the application
    can use the model.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**自助服务**被定义为平台的一种能力，允许平台终端用户按需提供资源而无需其他人工干预。例如，数据科学家用户可能需要一个Jupyter notebook服务器实例，运行在一个具有8个CPU的主机容器上，以执行他的/她的工作。一个自助式的ML平台应当允许数据科学家通过一个终端用户友好的界面，提供容器并运行Jupyter
    notebook服务器实例。另一个自助服务的例子是，数据工程师请求提供一个新的Apache Spark集群实例，以运行他的/她的数据管道。最后一个例子是数据科学家希望将其ML模型打包并作为REST服务进行部署，以便应用程序可以使用该模型。'
- en: One benefit of a self-service platform is that it allows cross-functional teams
    to work together with minimal dependencies on other teams. This independence results
    in better team dynamics, less friction, and increased team velocity.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自助服务平台的一个好处是，它允许跨职能团队以最小的依赖关系共同工作。这种独立性带来了更好的团队动态、更少的摩擦和更高的团队速度。
- en: The self-service model, however, needs governance. Imagine every data scientist
    requesting GPUs or data engineers requesting tens of terabytes of storage! Self-service
    capability is great, but without proper governance, it could also create problems.
    To avoid such problems, the platform has to be managed by a platform team that
    can control or limit the things the end users can do. One example of this limit
    is resource quotas. Teams and/or individual users can be allocated with quotas
    and be responsible for managing their own resources within the allocated quotas.
    Luckily, Kubernetes has this capability, and our ML platform can utilize this
    capability to apply limits to the team's resources.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，自服务模型需要治理。试想，每个数据科学家都请求GPU，或者数据工程师请求数十TB的存储！自服务功能非常好，但如果没有适当的治理，也可能带来问题。为了避免此类问题，平台必须由平台团队进行管理，团队可以控制或限制最终用户的操作。资源配额就是这种限制的一个例子。团队和/或个人用户可以分配配额，并负责在分配的配额范围内管理自己的资源。幸运的是，Kubernetes具有这种能力，我们的机器学习平台可以利用此能力为团队的资源应用限制。
- en: As part of governance, the platform must have role-based access control. This
    is to ensure that only the users with the right role will have access to the resources
    they manage. For example, the platform team may be able to change the resource
    quotas, while data engineers can only spin up new Spark clusters and run data
    pipelines.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 作为治理的一部分，平台必须具备基于角色的访问控制。这是为了确保只有具有适当角色的用户才能访问他们管理的资源。例如，平台团队可以更改资源配额，而数据工程师只能启动新的Spark集群并运行数据管道。
- en: Another aspect of a self-service platform is the isolation of workloads. Many
    teams will be sharing the same platform and, while the quotas will keep the teams
    within their predefined boundaries, it is critical that there is a capability
    to isolate workloads from each other so that multiple unrelated projects running
    on the same platform do not overlap.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 自服务平台的另一个方面是工作负载的隔离。许多团队将共享同一个平台，尽管配额将使团队保持在预定义的边界内，但至关重要的是，平台必须具备隔离工作负载的能力，以确保在同一平台上运行的多个不相关的项目不会重叠。
- en: Exploring the data engineering components
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索数据工程组件
- en: In the context of this book, data engineering is the process of ingesting raw
    data from source systems and producing reliable data that could be used in scenarios
    such as analytics, business reporting, and ML. A data engineer is a person who
    builds software that collects and processes raw data to generate clean and meaningful
    datasets for data analysts and data scientists. These datasets will form the backbone
    for your organization's ML initiatives.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书的上下文中，数据工程是指从源系统中摄取原始数据，并生成可用于分析、业务报告和机器学习等场景的可靠数据的过程。数据工程师是构建软件来收集和处理原始数据，从而为数据分析师和数据科学家生成干净且有意义的数据集的人。这些数据集将成为组织机器学习计划的基础。
- en: '*Figure 4.1* shows the various stages of a typical data engineering area of
    an ML project:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.1* 展示了典型的机器学习项目中数据工程阶段的各个步骤：'
- en: '![Figure 4.1 – Data engineering stages for ML'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.1 – 机器学习中的数据工程阶段'
- en: '](img/B18332_04_001.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_001.jpg)'
- en: Figure 4.1 – Data engineering stages for ML
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 – 机器学习中的数据工程阶段
- en: Data engineering often overlaps with **feature engineering**. While a data scientist
    decides on which features are more useful for the ML use case, he or she may work
    with the data engineer to retrieve particular data points that are not available
    in the current feature set. This is the main collaboration point between data
    engineers and data scientists. The datasets created by the data engineer in the
    data engineering block become the feature set in the ML block.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程通常与**特征工程**有交集。虽然数据科学家决定哪些特征对机器学习用例更有用，但他或她可能会与数据工程师合作，以获取当前特征集中没有的数据点。这是数据工程师与数据科学家之间的主要合作点。数据工程师在数据工程阶段创建的数据集将成为机器学习阶段中的特征集。
- en: An ML platform that enables teams to perform feature engineering will have the
    following components and processes.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 一个支持团队进行特征工程的机器学习平台将包含以下组件和过程。
- en: '**Data ingestion**: Data ingestion is the process in which the team understands
    the data sources and builds and deploys software that collects data from one or
    more data sources. Data engineers understand the impact of reading data from source
    systems. For example, while reading data from a source, the performance of the
    source system may get affected. Therefore, it is important for the ML platform
    to have a workflow scheduling capability so that the data collection can be scheduled
    during a time when the source system is less active.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据摄取**：数据摄取是团队理解数据源并构建和部署收集来自一个或多个数据源的数据的软件的过程。数据工程师理解从源系统读取数据的影响。例如，在从源读取数据时，源系统的性能可能会受到影响。因此，机器学习平台必须具备工作流调度功能，以便在源系统不太活跃的时间安排数据收集。'
- en: 'An ML platform enables the team to ingest data from various sources in multiple
    ways. For example, some data sources would allow data to be pulled, while other
    data sources may be able to push data. Data may come from a relational database,
    data warehouses, data lakes, data pools, data streams, API calls, or even from
    a raw filesystem. The platform should also have the capability to understand different
    protocols, for example, a messaging system may have multiple protocols, such as
    **Advanced Message Queuing Protocol** (**AMQP**), **Message Queuing Telemetry
    Transport** (**MQTT**), and Kafka. In other words, the ML platform should have
    the capability to gather data of various shapes and sizes from different types
    of data sources in various ways. *Figure 4.2* shows various sources of data from
    where the platform should be able to ingest the data:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一个机器学习平台使团队能够以多种方式从各种来源摄取数据。例如，某些数据源允许拉取数据，而其他数据源可能允许推送数据。数据可能来自关系型数据库、数据仓库、数据湖、数据池、数据流、API
    调用，甚至是原始文件系统。平台还应具备理解不同协议的能力，例如，一个消息系统可能有多种协议，如**高级消息队列协议**（**AMQP**）、**消息队列遥测传输**（**MQTT**）和
    Kafka。换句话说，机器学习平台应该具备从不同类型的数据源以各种方式收集不同形状和大小的数据的能力。*图 4.2*展示了平台应该能够摄取的各种数据来源：
- en: '![Figure 4.2 – Data ingestion integrations'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.2 – 数据摄取集成'
- en: '](img/B18332_04_002.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_002.jpg)'
- en: Figure 4.2 – Data ingestion integrations
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.2 – 数据摄取集成
- en: '**Data transformation**: Once the data is ingested from various sources, it
    needs to be transformed from its original form into something that is more useful
    for the ML model training and other use cases. According to a Forbes survey, *80%
    of data scientists'' work is related to preparing data for the model training*;
    this is the stage that is generally considered as boring among the data science
    teams. However, if the data is not transformed into an appropriate form, it will
    lead to less useful and/or inefficient ML models. An ML platform enables teams
    to code, build, and deploy the data transformation pipelines and jobs with ease.
    The platform abstracts the complications of running and managing data transformation
    components such as Apache Spark jobs. Not only does the platform manage the execution
    of these processes, but it also manages the provisioning and cleaning of compute
    resources required to run these components, such as CPU, memory, and networking.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据转换**：一旦数据从各种来源摄取，它需要从原始形式转化为对机器学习模型训练和其他应用场景更有用的形式。根据福布斯的一项调查，*80%的数据科学家工作都与为模型训练准备数据相关*；这通常是数据科学团队中被认为最枯燥的阶段。然而，如果数据没有转换为合适的形式，它将导致不那么有用和/或低效的机器学习模型。一个机器学习平台使团队能够轻松编写、构建和部署数据转换管道和作业。该平台抽象了运行和管理数据转换组件（如
    Apache Spark 作业）的复杂性。平台不仅管理这些过程的执行，还管理运行这些组件所需的计算资源（如 CPU、内存和网络）的供应和清理。'
- en: '**Storage**: During the feature engineering process, you will read and write
    data at various stages. You might create a temporary representation of the dataset
    for further processing, or you could write the new dataset to be used for ML processes.
    In these scenarios, you will need storage resources that can be accessed with
    ease and scale as needed. An ML platform provides on-demand storage for your datasets
    to be stored in a reliable fashion.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储**：在特征工程过程中，您将在各个阶段读取和写入数据。您可能会创建数据集的临时表示以进行进一步处理，或者您可能会写入新数据集以供机器学习过程使用。在这些情况下，您将需要可以轻松访问并根据需要扩展的存储资源。一个机器学习平台提供按需存储，确保您的数据集能够以可靠的方式存储。'
- en: Now, let's see how the data engineer will use these components in their workflow.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看数据工程师将如何在他们的工作流中使用这些组件。
- en: Data engineer workflow
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据工程师工作流
- en: 'All the capabilities mentioned in the previous section are provided by the
    ML platform in a self-serving manner. The workflow that a data engineer using
    the platform would typically perform is as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节中提到的所有功能都由机器学习平台以自服务的方式提供。数据工程师在使用平台时通常会执行的工作流如下：
- en: '*Log in to the platform*: In this step, the data engineer authenticates to
    the platform.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*登录平台*：在此步骤中，数据工程师进行平台身份验证。'
- en: '*Provisioning of the development environment*: In this step, the data engineer
    requests the resource requirements for the development environment (such as the
    number of CPUs, amount of memory, and specific software libraries) to the platform.
    The platform then provisions the requested resources automatically.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*配置开发环境*：在此步骤中，数据工程师向平台请求开发环境所需的资源（如CPU数量、内存大小和特定的软件库）。平台随后会自动配置所请求的资源。'
- en: '*Build a data pipeline*: In this step, the data engineer writes the code for
    data ingestion and data transformation. The data engineer then runs the code in
    an isolated environment to verify its validity and perform the necessary refactoring
    and tuning of the code.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*构建数据管道*：在此步骤中，数据工程师编写用于数据摄取和数据转换的代码。然后，数据工程师将在隔离环境中运行代码，验证其有效性，并进行必要的重构和调优。'
- en: '*Run a data pipeline*: In this step, the data engineer schedules the code to
    run as needed. It can be a regular schedule with periodic intervals such as hourly
    or daily, or a one-off run, depending on the use case.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*运行数据管道*：在此步骤中，数据工程师按需安排代码运行。可以根据使用场景选择定期运行（如每小时或每日）或一次性运行。'
- en: You can see in the preceding steps that besides writing the code, all other
    steps are declarative. The data engineer's focus will be on building the code
    to ingest and transform data. All other aspects of the flow will be taken care
    of by the ML platform. This will result in improved efficiency and velocity for
    the team. The declarative capability of the platform will allow teams to standardize
    processes across your organization, which will reduce the number of bespoke toolchains
    and improve the security of the overall process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的步骤中可以看到，除了编写代码，其他所有步骤都是声明性的。数据工程师的重点将放在构建用于摄取和转换数据的代码上。流程的其他方面将由机器学习平台负责。这将提高团队的效率和工作速度。平台的声明式功能将帮助团队在整个组织内标准化流程，从而减少定制工具链的数量，并提升整体流程的安全性。
- en: The main output of the data engineering flow is a usable, transformed, and partially
    cleaned set of data that can be used to start building and training a model.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程流程的主要输出是一个可用的、已转换并部分清理的数据集，可以用来开始构建和训练模型。
- en: Exploring the model development components
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索模型开发组件
- en: Once the cleaned data is available, data scientists then go through the problem
    and try to determine what set of patterns would be helpful for the situation.
    The key here is that the data scientist's primary role is to find patterns in
    the data. Model development components of the ML platform explore data patterns,
    build and train ML models, and trial multiple configurations to find the best
    set of configurations and algorithms to achieve the desired performance of the
    model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦清理后的数据可用，数据科学家将对问题进行分析，尝试确定哪些模式对于该情况有帮助。关键是数据科学家的主要职责是从数据中找出模式。机器学习平台的模型开发组件会探索数据模式、构建和训练机器学习模型，并试验多种配置，找到最佳的配置和算法，以实现模型所需的性能。
- en: Within the course of model development, data scientists or ML engineers build
    multiple models based on multiple algorithms. These models are then trained using
    the data gathered and prepared from the data engineering flow. The data scientist
    then plays around with several hyperparameters to get different results from model
    testing. The result of such training and testing is then compared with each of
    the other models. These experimentation processes are then repeated multiple times
    until the desired results are achieved.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型开发过程中，数据科学家或机器学习工程师基于多个算法构建多个模型。这些模型将使用数据工程流程中收集和准备的数据进行训练。数据科学家接着会调整几个超参数，通过模型测试得到不同的结果。然后，这些训练和测试的结果将与其他模型进行比较。这些实验过程将重复多次，直到达到预期的结果。
- en: The experimentation phase will result in a selection of the most appropriate
    algorithm and configuration. The selected model will then be tagged for packaging
    and deployment.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 实验阶段将导致选择最合适的算法和配置。选定的模型将被标记以便打包和部署。
- en: '*Figure 4.3* shows the various stages of model development for an ML project:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.3* 显示了机器学习项目中模型开发的各个阶段：'
- en: '![Figure 4.3 – Data engineering stages for ML'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.3 – 机器学习数据工程阶段'
- en: '](img/B18332_04_003.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_003.jpg)'
- en: Figure 4.3 – Data engineering stages for ML
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – 机器学习数据工程阶段
- en: 'An ML platform that enables teams to perform model development will have the
    following components:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个能够支持团队进行模型开发的机器学习平台将包含以下组件：
- en: '**Data exploration**: We humans are better at finding patterns when the data
    is visualized as opposed to just looking at raw data sets. The ML platform enables
    you to visualize data. As a data scientist, you will need to collaborate with
    **subject matter experts** (**SMEs**) who have domain knowledge. Let''s say you
    are analyzing a dataset of coronavirus patients. If you are not an expert in the
    virology or medicine domains, you will need to work with an SME who can provide
    insights about the dataset, the relationships of features, and the quality of
    the data itself. An ML platform allows you to share the visualizations you have
    created with the wider team for improved feedback. The platform also allows non-technical
    people to look at the data in a more graphical approach. This will help them gain
    a better understanding of the data.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据探索**：我们人类在数据可视化时比仅仅查看原始数据集时更擅长发现模式。机器学习平台使你能够可视化数据。作为数据科学家，你需要与**领域专家**（**SMEs**）合作，后者拥有专业知识。假设你正在分析一组冠状病毒患者的数据集。如果你不是病毒学或医学领域的专家，你将需要与一个能够提供关于数据集、特征关系以及数据质量的见解的领域专家合作。机器学习平台允许你将自己创建的可视化图表分享给更广泛的团队，以便获得更好的反馈。平台还允许非技术人员以更图形化的方式查看数据，这有助于他们更好地理解数据。'
- en: '**Experimentation**: As a data scientist, you will split the data into training
    and testing sets, and then start building the model for the given metric. You
    will then experiment with multiple ML algorithms such as decision trees, XGBoost,
    and deep learning, and apply a variety of parameter tuning to each of the algorithms,
    for example, the number of layers or number of neurons for a deep learning model.
    This is what we call experimentation, and the platform enables the team to perform
    the experimentation in an autonomous way. Keep in mind that for each experiment,
    you may have different requirements for compute resources such as a GPU. This
    makes the self-service provisioning capability of the platform critical.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验**：作为数据科学家，你将把数据分为训练集和测试集，然后开始为给定的指标构建模型。接下来，你将尝试多种机器学习算法，如决策树、XGBoost
    和深度学习，并为每个算法应用不同的参数调优，例如深度学习模型中的层数或神经元数量。这就是我们所说的实验，平台使团队能够以自主的方式进行实验。请记住，对于每个实验，你可能需要不同的计算资源，如
    GPU。因此，平台的自助服务配置能力至关重要。'
- en: '**Tracking**: While doing multiple experiments, you need to keep track of the
    parameters used for each experiment and the metrics it has achieved. Some algorithms
    may require different sets of features, which means you also need to keep track
    of the version of the dataset that was used in training. There are two reasons
    for doing this. The first reason is that you will need a history of your experiments
    so that you can compare and pick the best combination. The second reason is that
    you may need to share the results with your fellow data scientists. The ML platform
    enables you to record the results of the experiments and share them seamlessly.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跟踪**：在进行多个实验时，你需要跟踪每个实验使用的参数以及它所取得的指标。一些算法可能需要不同的特征集，这意味着你还需要跟踪在训练中使用的数据集版本。这样做有两个原因。第一个原因是，你将需要保留实验历史，以便进行比较并挑选最佳组合。第二个原因是，你可能需要将结果与其他数据科学家共享。机器学习平台使你能够记录实验结果并无缝共享。'
- en: '**Model building and tuning**: In the experimentation stage, you have found
    the best algorithm and the best parameters for your model. You have compared the
    results and associated metrics for your model and have chosen the algorithm and
    parameters to be used. In this stage, you will train your model with these parameters,
    and register it with the model registry:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型构建与调优**：在实验阶段，你已经找到了最佳的算法和最佳参数。你已比较了模型的结果和相关指标，并选择了用于模型的算法和参数。在这个阶段，你将使用这些参数训练你的模型，并将其注册到模型注册表中：'
- en: '**Model registry**: As a data scientist, when you are satisfied with your model,
    you work with your team to deploy it. The real world changes, however, and you
    will need to update your model for new datasets or different metrics or simply
    for improved metrics. New versions of the models come all the time and the ML
    platform enables you to keep track of the versions of your models. The model versioning
    capability will help the team to compare the efficiency of new model versions
    with older model versions and allow the team to roll back a new model in production
    to previous versions if the need arises.'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型注册表**：作为数据科学家，当你对模型感到满意时，你将与团队一起部署它。然而，现实世界会发生变化，你需要为新数据集、不同指标或仅仅为了提高指标而更新模型。新版本的模型不断出现，ML平台使你能够追踪模型版本。模型版本控制功能将帮助团队比较新旧模型版本的效率，并在需要时允许团队将生产中的新模型回滚至以前的版本。'
- en: '**Storage**: Storage is not only important in the data engineering phase but
    also in model development. During the model development process, you read and
    write data at various stages. You split the dataset into a testing dataset and
    a training dataset, and you may choose to write it once so you can experiment
    with different model parameters but with the same datasets. The experiment tracking
    module and the model registry both need storage. The ML platform provides on-demand
    storage for your datasets to be stored in a reliable fashion.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储**：存储不仅在数据工程阶段重要，在模型开发过程中同样至关重要。在模型开发过程中，你会在多个阶段读取和写入数据。你将数据集分成测试集和训练集，你可能选择只写入一次数据，这样你可以在相同数据集上进行不同模型参数的实验。实验追踪模块和模型注册表都需要存储。ML平台为你的数据集提供按需存储，确保数据可靠存储。'
- en: Now, let's see how the data scientists use these components in their workflow.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看数据科学家如何在他们的工作流程中使用这些组件。
- en: Understanding the data scientist workflow
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解数据科学家的工作流程
- en: 'All the capabilities mentioned in the previous section are provided by the
    ML platform in a self-serving way. The typical workflow for the data scientist
    would be as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节中提到的所有功能都由ML平台以自助方式提供。数据科学家的典型工作流程如下：
- en: '*Log in to the platform*: The data scientists authenticate to the platform.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*登录平台*：数据科学家对平台进行身份验证。'
- en: '*Provisioning of the development environment*: In this step, the data scientist
    requests, to the platform, the resource requirements for the development environment,
    such as the number of CPUs, amount of memory, and specific software libraries.
    The platform then provisions the requested resources automatically.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*开发环境的配置*：在这一步骤中，数据科学家向平台请求开发环境的资源要求，如CPU数量、内存大小和特定的软件库。平台会自动为你配置所需资源。'
- en: '*Exploratory data analysis*: In this stage, data scientists perform several
    types of data transformations and visualization techniques to understand the patterns
    hidden in the data.'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*探索性数据分析*：在这个阶段，数据科学家进行多种数据转换和可视化技术，以理解数据中隐藏的模式。'
- en: '*Experimenting with different algorithms*: In this stage, data scientists split
    the full dataset into training and testing sets. Then, the data scientists apply
    different ML algorithms and hyperparameters to achieve the desired metrics. Data
    scientists then compare the parameters of each training run to select the best
    one for the given use case.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*尝试不同的算法*：在这个阶段，数据科学家将完整数据集拆分为训练集和测试集。然后，数据科学家应用不同的ML算法和超参数，以实现所需的指标。数据科学家接着比较每次训练运行的参数，选择最适合给定用例的参数。'
- en: '*Model training*: Data scientists train the model as per the most optimized
    parameters found in the previous stage, and register the model in the model registry.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*模型训练*：数据科学家根据前一阶段找到的最优化参数训练模型，并将模型注册到模型注册表中。'
- en: '*Run model deployment pipeline*: In this step, the data scientists package
    the model to be consumed as a service and build the pipeline to automate the deployment
    process. It can be scheduled regularly or as a one-off run, depending on the use
    case.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*运行模型部署管道*：在此步骤中，数据科学家将模型打包以作为服务消费，并构建自动化部署流程。根据用例，它可以定期调度或一次性运行。'
- en: You can see in the preceding steps that besides writing the code to facilitate
    model building and training, all other steps are declarative. The data scientists'
    focus will be on building more data science and ML engineering tasks. All other
    aspects of the flow will be taken care of by the ML platform. This will result
    in improved efficiency and velocity for the team, not to mention a happier data
    scientist. The declarative capability of the platform will also allow teams to
    standardize processes across your organization, which will reduce the use of bespoke
    toolchains improving consistency and improving the security of the overall process.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在前面的步骤中看到，除了编写便于模型构建和训练的代码之外，所有其他步骤都是声明性的。数据科学家的重点将放在构建更多的数据科学和ML工程任务上。流程的所有其他方面将由ML平台处理。这将提高团队的效率和速度，更不用说数据科学家的幸福感了。平台的声明能力还将允许团队在整个组织中标准化流程，从而减少使用定制工具链，提高一致性并改善整个流程的安全性。
- en: In the next section, you will explore the common services of the ML platform.
    These services are critical to making the platform production-ready and easier
    to adopt in the enterprise environment.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，您将探讨ML平台的常见服务。这些服务对于使平台达到生产就绪状态并在企业环境中更易于采用至关重要。
- en: Security, monitoring, and automation
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全性、监控和自动化
- en: 'In this section, you will see some common components of the ML platform that
    apply to all the components and stages we have discussed so far. These components
    assist you in operationalizing the platform in your organization:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将看到适用于我们到目前为止讨论的所有组件和阶段的ML平台的一些常见组件。这些组件帮助您在组织中实现平台的操作化：
- en: '**Data pipeline execution**: The outcome of data engineering is a data pipeline
    that ingests, cleans, and processes data. You have built this pipeline with scaled-down
    data for development purposes. Now, you need to run this code with production
    data, or you want a scheduled run with new data available, say, every week. An
    ML platform allows you to take your code and automate its execution in different
    environments. This is a big step because the platform not only allows you to run
    your code but will also manage the packaging of all the dependencies of your code
    so that it can run anywhere. If the code that you have built is using Apache Spark,
    the platform should allow you to automate the process of provisioning a Spark
    cluster and all other components required to run your data pipeline.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据管道执行**：数据工程的结果是一个数据管道，用于摄取、清理和处理数据。您已经用缩减版数据构建了这个管道以供开发目的使用。现在，您需要用生产数据运行这些代码，或者您希望定期运行新数据，比如每周。ML平台允许您获取代码并在不同环境中自动执行它。这是一大进步，因为平台不仅允许您运行代码，还将管理代码的所有依赖项的打包，使其可以在任何地方运行。如果您构建的代码使用Apache
    Spark，平台应允许您自动化提供Spark集群和运行数据管道所需的所有其他组件的过程。'
- en: '**Model deployment**: Once the model is ready to be used, it should be available
    to be consumed as a service. Without the automated model packaging and deployment
    capability of the ML platform, the process of packaging a model and hosting it
    as a service requires some software engineering work. This work requires tight
    collaboration with software engineers and the operations team and may take days,
    if not weeks, to accomplish. The ML platform automates this process and it usually
    takes only a few seconds to a few minutes. The result of this process is an ML
    model deployed in an environment and is accessible as a service – typically, as
    a REST API.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署**：一旦模型准备好供使用，它应该可以作为服务供消费。如果没有ML平台的自动化模型打包和部署能力，将模型打包并将其托管为服务的过程需要一些软件工程工作。这项工作需要与软件工程师和运维团队紧密合作，并可能需要花费数天甚至数周的时间才能完成。ML平台自动化了这个过程，通常只需几秒到几分钟的时间。这个过程的结果是在环境中部署的ML模型，并可以作为服务访问，通常以REST
    API的形式提供。'
- en: Deployment of the model is one aspect; over time, you may also need to re-train
    the model with new datasets. The platform also enables your team to automate the
    retraining process using the same training code you built for the first time when
    you trained your model. The retrained model is then redeployed automatically.
    This capability massively improves the efficiency of the team and this allows
    for more efficient use of time, such as working on newer challenges while delivering
    values for the business.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的部署是一个方面；随着时间的推移，你可能还需要用新数据集重新训练模型。该平台还使团队能够使用第一次训练模型时所编写的相同训练代码来自动化重新训练过程。重新训练的模型将自动重新部署。这项功能大大提高了团队的效率，允许更高效地利用时间，如处理新的挑战，同时为业务提供价值。
- en: '**Monitoring**: Monitoring does not just refer to having the capability to
    observe the dynamics of the components in production, such as monitoring the model
    response time, but it also enables the team to respond to events before they become
    problems. A good monitoring platform provides observability during the full ML
    project life cycle and not just monitoring in production. When you are writing
    code to process data, you may need to tune the joins expression between datasets
    from multiple systems. This is one of the examples of information you need during
    development. The ML platform allows you to dig into the details during the development
    process. The platform also provides capabilities to monitor the underlying IT
    infrastructure. For example, when you are running your code during the model training
    stage, the platform provides the metrics on hardware resource utilization.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控**：监控不仅仅是指拥有观察生产环境中组件动态的能力，例如监控模型响应时间，它还使团队能够在问题发生之前响应事件。一个好的监控平台在整个机器学习项目生命周期中提供可观测性，而不仅仅是生产环境中的监控。当你编写代码处理数据时，你可能需要调整来自多个系统的数据集之间的连接表达式。这是你在开发过程中需要的信息之一。该平台允许你在开发过程中深入了解细节。平台还提供监控底层IT基础设施的能力。例如，在模型训练阶段运行代码时，平台提供硬件资源利用率的度量。'
- en: '**Security and governance**: The platform you are building allows teams to
    work autonomously. Teams can use the tools in the platform to perform the work
    anytime. However, the question of who can access what and who can use which tools
    proves to be a challenge for many organizations. For this, the platform must have
    an access control capability and provide access to only authorized users. The
    security component of the platform allows the users to be authenticated and authorized
    through standard protocols such as **OAuth2** or **OpenID Connect**. You will
    be using open source components to bring authentication components to the platform.
    The platform also uses the Kubernetes namespace feature to provide workload isolation
    across different teams that are sharing the same cluster. Kubernetes also provides
    the capability to assign limits of hardware resources to be used by individual
    teams. These capabilities will enable teams to share the platform across many
    different units within your organization while providing well-defined isolation
    boundaries and hardware resource quotas.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性和治理**：你正在构建的平台使团队能够独立工作。团队可以随时使用平台中的工具进行工作。然而，谁可以访问什么资源、谁可以使用哪些工具，成为许多组织面临的挑战。为此，平台必须具备访问控制功能，只允许授权用户访问。平台的安全组件通过标准协议，如**OAuth2**或**OpenID
    Connect**，对用户进行认证和授权。你将使用开源组件将认证功能引入平台。平台还使用Kubernetes命名空间功能，在共享相同集群的不同团队之间提供工作负载隔离。Kubernetes还提供将硬件资源使用限制分配给各个团队的能力。这些功能将使团队能够在组织内的多个单位之间共享平台，同时提供明确的隔离边界和硬件资源配额。'
- en: '**Source code management**: When you build data pipelines or train your model,
    you write code. The platform provides capabilities to integrate with source code
    management solutions. **Git** is the default source code management solution integrated
    platform.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**源代码管理**：当你构建数据管道或训练模型时，你会编写代码。该平台提供与源代码管理解决方案的集成功能。**Git**是集成平台的默认源代码管理解决方案。'
- en: Now, let's move on to cover **Open Data Hub** (**ODH**).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续介绍**开放数据中心**（**ODH**）。
- en: Introducing ODH
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入 ODH
- en: ODH is an open source project that provides most of the components required
    by our ML platform. It comes with a Kubernetes operator and a curated set of open
    source software components that make up most of the ML platform. In this book,
    we will mainly use the ODH operator. There are also other components that we will
    be using in the platform that don't originally come with ODH. One good thing about
    the ODH operator is the ability to swap default components for another as you
    see fit for your case.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: ODH 是一个开源项目，提供了构建我们 ML 平台所需的大部分组件。它包括一个 Kubernetes 操作符和一套精心挑选的开源软件组件，这些组件构成了
    ML 平台的大部分。在本书中，我们将主要使用 ODH 操作符。平台中还有其他一些组件，它们并非 ODH 原生提供的。ODH 操作符的一个优点是，您可以根据实际需求，随时将默认组件替换为其他组件。
- en: 'To build the platform, you will use the following components. In the next few
    chapters, you will learn about the details of each of these components and how
    to use them. For now, you just need to understand their purpose at a very high-level:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 为了构建平台，您将使用以下组件。在接下来的几章中，您将学习每个组件的详细信息及其使用方法。目前，您只需了解这些组件的高层次用途：
- en: '**ODH operator**: A Kubernetes operator that manages the life cycle of different
    components of the ML platform. It controls and manages the installation and maintenance
    of the software components used in your ML platform.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ODH 操作符**：一个 Kubernetes 操作符，用于管理 ML 平台中不同组件的生命周期。它控制并管理 ML 平台中使用的软件组件的安装和维护。'
- en: '**JupyterHub**: Manages instances of Jupyter Notebook servers and their related
    resources.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**JupyterHub**：管理 Jupyter Notebook 服务器实例及其相关资源。'
- en: '**Jupyter notebooks**: An **integrated development environment** (**IDE**)
    is the main data engineering and data science workspace in the platform. Data
    scientists and engineers will use these workspaces to write and debug code for
    both data engineering and ML workflows.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Jupyter notebooks**：一个**集成开发环境**（**IDE**），是平台中主要的数据工程和数据科学工作区。数据科学家和工程师将使用这些工作区编写和调试数据工程及
    ML 工作流的代码。'
- en: '**Apache Spark**: A distributed, parallel data processing engine and framework
    for processing large datasets. It provides a wide array of data ingestion connectors
    to consume data from a variety of sources.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Spark**：一个分布式并行数据处理引擎和框架，用于处理大规模数据集。它提供了广泛的数据摄取连接器，能够从各种数据源中获取数据。'
- en: '**Apache Airflow**: A workflow engine that automates the execution and scheduling
    of data pipelines and model deployment. Airflow orchestrates different components
    of your data pipelines.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Apache Airflow**：一个工作流引擎，用于自动化执行和调度数据管道和模型部署。Airflow 协调数据管道中的不同组件。'
- en: '**Seldon Core**: A library for packaging and deploying ML models as a REST
    service. It also has the capability of monitoring the deployed models. It provides
    support for popular ML frameworks, which gives it the capability to wrap and package
    ML models built with frameworks such as TensorFlow, scikit-learn, XGBoost, and
    PyTorch, as REST services.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Seldon Core**：一个将 ML 模型打包并部署为 REST 服务的库。它还具有监控已部署模型的功能。它支持流行的 ML 框架，能够将使用
    TensorFlow、scikit-learn、XGBoost 和 PyTorch 等框架构建的 ML 模型包装成 REST 服务。'
- en: '**Prometheus and Grafana**: These two components provide the monitoring capabilities
    for our platform. Prometheus provides the metrics database to record telemetry
    data provided by the components of the platform, and Grafana provides the **graphical
    user interface** (**GUI**) to visualize the captured metrics.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus 和 Grafana**：这两个组件为我们的平台提供监控功能。Prometheus 提供度量数据库，用于记录平台组件提供的遥测数据，而
    Grafana 提供**图形用户界面**（**GUI**）来可视化捕获的度量数据。'
- en: '**Minio**: An object storage provider that is compatible with Amazon S3 APIs.
    The Minio component is not part of the ODH toolchain, but we will extend and configure
    the ODH operator to manage the Minio component on the ML platform.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Minio**：一个与 Amazon S3 API 兼容的对象存储提供者。Minio 组件并非 ODH 工具链的一部分，但我们将扩展并配置 ODH
    操作符以管理平台上的 Minio 组件。'
- en: '**MLFlow**: A component for tracking different model experiments and also serves
    as the model registry of the platform. The MLFlow component is not part of the
    ODH toolchain, but we will extend the ODH operator to manage the MLFlow component
    on the ML platform'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLFlow**：一个用于追踪不同模型实验的组件，同时也作为平台的模型注册中心。MLFlow 组件并非 ODH 工具链的一部分，但我们将扩展 ODH
    操作符以管理 MLFlow 组件。'
- en: You will also install an open source identity provider component. The goal for
    this component is to provide a common single sign-on feature for all the platform
    components. We will use **Keycloak** as the identity management system, but this
    could be swapped with an OAuth2-based system that may already exist in your case.
    Keycloak is not part of the ODH, and we will show you how to install it as a separate
    component on your Kubernetes cluster.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 您还将安装一个开源身份提供者组件。该组件的目标是为所有平台组件提供一个通用的单点登录功能。我们将使用 **Keycloak** 作为身份管理系统，但在您的情况下，可以使用基于
    OAuth2 的系统来替换 Keycloak。Keycloak 不是 ODH 的一部分，我们将展示如何将其作为独立组件安装到您的 Kubernetes 集群中。
- en: '*Figure 4.4* shows the major open source software that serves as the main components
    of the ML platform. The ODH extensibility model allows you to add or choose which
    products to use for which components as per the requirements. You can replace
    any of the components with other open source products of choice. However, for
    the exercises in this book, we will use the product listed here:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 4.4* 显示了作为 ML 平台主要组件的主要开源软件。ODH 可扩展性模型允许您根据需求添加或选择使用的产品。您可以用其他开源产品替换任何组件。不过，在本书的练习中，我们将使用此处列出的产品：'
- en: '![Figure 4.4 – Major components of the ML platform'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.4 – ML 平台的主要组件'
- en: '](img/B18332_04_004.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_004.jpg)'
- en: Figure 4.4 – Major components of the ML platform
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – ML 平台的主要组件
- en: In the next section, you will deploy the ODH operator and Keycloak server on
    your Kubernetes cluster. You will also install and configure the ingress controller
    to accept traffic from outside the cluster.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，您将部署 ODH 运算符和 Keycloak 服务器到您的 Kubernetes 集群中。您还将安装并配置入口控制器，以接受来自集群外部的流量。
- en: Installing the ODH operator on Kubernetes
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上安装 ODH 运算符
- en: In this section, you will install the ODH operator onto your Kubernetes cluster.
    At this stage, you will not enable any components of the platform. To install
    the operator, you first need to register the catalog source for the operator,
    and then you can install it.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将把 ODH 运算符安装到 Kubernetes 集群中。此时，您还不会启用平台的任何组件。要安装运算符，您首先需要注册运算符的目录源，然后才能安装它。
- en: 'First, let''s register the catalog for the ODH operator. A catalog source contains
    metadata through which the OLM can discover operators and their dependencies.
    The ODH operator is not available in the default OLM catalog, so we need to register
    a new catalog that contains the ODH metadata for the OLM:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们注册 ODH 运算符的目录。目录源包含元数据，通过这些元数据，OLM 可以发现运算符及其依赖项。ODH 运算符不在默认的 OLM 目录中，因此我们需要注册一个包含
    ODH 元数据的新目录，以供 OLM 使用：
- en: 'Validate that your Kubernetes cluster is running if you are using `minikube`:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您使用的是 `minikube`，请验证您的 Kubernetes 集群是否正在运行：
- en: '[PRE0]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You should see the following response:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下响应：
- en: '![Figure 4.5 – Validate that Kubernetes is running via minikube'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.5 – 验证 Kubernetes 是否通过 minikube 正在运行'
- en: '](img/B18332_04_005.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_005.jpg)'
- en: Figure 4.5 – Validate that Kubernetes is running via minikube
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – 验证 Kubernetes 是否通过 minikube 正在运行
- en: If your Kubernetes cluster is not running, please refer to [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040),
    *Exploring Kubernetes*, on how to configure and start the Kubernetes cluster.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您的 Kubernetes 集群没有运行，请参考[*第 3 章*](B18332_03_ePub.xhtml#_idTextAnchor040)，*探索
    Kubernetes*，了解如何配置和启动 Kubernetes 集群。
- en: 'Verify that the OLM is installed and is running by executing the following:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下命令来验证 OLM 是否已安装并正在运行：
- en: '[PRE1]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You should see the following response:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该看到以下响应：
- en: '![Figure 4.6 – Command output showing OLM pods are running'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.6 – 命令输出显示 OLM Pod 正在运行'
- en: '](img/B18332_04_006.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_006.jpg)'
- en: Figure 4.6 – Command output showing OLM pods are running
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 命令输出显示 OLM Pod 正在运行
- en: Make sure that all the OLM pods are running. If this is not the case for you,
    refer to [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040), *Exploring Kubernetes*,
    in the *How to install OLM in your cluster* section.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 确保所有 OLM Pod 都在运行。如果您遇到这种情况，请参考[*第 3 章*](B18332_03_ePub.xhtml#_idTextAnchor040)，*探索
    Kubernetes*，在 *如何在集群中安装 OLM* 部分。
- en: 'Clone the Git repository and navigate to the repository''s root directory.
    This repository contains all the source files, scripts, and manifests that you
    need to build the platform within the scope of this book: https://github.com/PacktPublishing/Machine-Learning-on-Kubernetes.git
    cd Machine-Learning-on-Kubernetes.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 克隆 Git 仓库并导航到仓库的根目录。该仓库包含你在本书范围内构建平台所需的所有源文件、脚本和清单： https://github.com/PacktPublishing/Machine-Learning-on-Kubernetes.git
    cd Machine-Learning-on-Kubernetes。
- en: 'Register a new `catalog source` operator by using the YAML file available in
    the source code of this book:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 使用本书源代码中提供的 YAML 文件注册一个新的 `catalog source` 操作员：
- en: '[PRE2]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'After a couple of minutes, validate that the operator is available in your
    cluster:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 几分钟后，验证操作员在你的集群中是否可用：
- en: '[PRE3]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You should see the following response:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 4.7 – Validate that the ODH operator is available'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.7 – 验证 ODH 操作员是否可用'
- en: '](img/B18332_04_007.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_007.jpg)'
- en: Figure 4.7 – Validate that the ODH operator is available
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – 验证 ODH 操作员是否可用
- en: On Windows PowerShell, you may need to replace the `grep` command with `findstr`.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Windows PowerShell 上，你可能需要将 `grep` 命令替换为 `findstr`。
- en: 'Now, create the subscription for the ODH operator. Recall from the third chapter
    that a subscription object triggers the installation of the operator via the OLM:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，创建 ODH 操作员的订阅。回想一下第三章，订阅对象通过 OLM 触发操作员的安装：
- en: '[PRE4]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You should see a response message that the subscription has been created.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到一个响应消息，显示订阅已创建。
- en: 'After creating the subscription, the OLM will automatically install the operator
    and all its components. Verify that the ODH pod is running by issuing the following
    command. It may take a few seconds before the pods start appearing. If the pods
    are not listed, wait for a few seconds and rerun the same command:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在创建订阅后，OLM 会自动安装操作员及其所有组件。通过执行以下命令验证 ODH pod 是否在运行。可能需要几秒钟才能看到 pod 出现。如果 pod
    未列出，等待几秒钟并重新运行相同的命令：
- en: '[PRE5]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You should see the following response:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 4.8 – Validate that the ODH pod is up and running'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.8 – 验证 ODH pod 是否已启动并运行'
- en: '](img/B18332_04_008.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_008.jpg)'
- en: Figure 4.8 – Validate that the ODH pod is up and running
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – 验证 ODH pod 是否已启动并运行
- en: You have just installed the ODH operator on your Kubernetes cluster. Notice
    that you have not used generic Kubernetes objects such as **Deployments** to run
    your operator. The OLM allows you to easily manage the installation of an operator
    via the **Subscription** object.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 你刚刚在 Kubernetes 集群上安装了 ODH 操作员。请注意，你并没有使用像 **Deployments** 这样的通用 Kubernetes
    对象来运行你的操作员。OLM 允许你通过 **Subscription** 对象轻松管理操作员的安装。
- en: In the next section, you install the ingress controller to allow traffic into
    your Kubernetes cluster.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，你将安装 ingress 控制器，以允许流量进入 Kubernetes 集群。
- en: Enabling the ingress controller on the Kubernetes cluster
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Kubernetes 集群上启用 ingress 控制器
- en: Recall from [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040), *Exploring
    Kubernetes*, that ingress provides a way for you to expose a particular service
    to make it accessible from outside the cluster. There are many ingress providers
    available on Kubernetes, and we leave it to you to select the right ingress provider
    for your cluster.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 回想一下 [*第 3 章*](B18332_03_ePub.xhtml#_idTextAnchor040)，*探索 Kubernetes* 中提到的，ingress
    提供了一种方式，让你可以暴露特定的服务，使其可以从集群外部访问。Kubernetes 上有许多 ingress 提供商，我们将它留给你选择合适的 ingress
    提供商来为你的集群提供服务。
- en: 'If you are using `minikube`, you need to follow these steps to enable the default
    ingress:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在使用 `minikube`，需要按照以下步骤启用默认的 ingress：
- en: 'Enable the NGINX-based ingress controller for your cluster by issuing the following
    command:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下命令，为你的集群启用基于 NGINX 的 ingress 控制器：
- en: '[PRE6]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You should see the following response:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 4.9 – Output for enabling minikube ingress plugin'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.9 – 启用 minikube ingress 插件的输出'
- en: '](img/B18332_04_009.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_009.jpg)'
- en: Figure 4.9 – Output for enabling minikube ingress plugin
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – 启用 minikube ingress 插件的输出
- en: 'Validate that the ingress pods are running in your cluster:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证你的集群中是否有 ingress pod 在运行：
- en: '[PRE7]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You should see the following response:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 4.10 – Validate that the Nginx ingress pods are in running state'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.10 – 验证 Nginx ingress pod 是否处于运行状态'
- en: '](img/B18332_04_010.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_010.jpg)'
- en: Figure 4.10 – Validate that the Nginx ingress pods are in running state
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.10 – 验证 Nginx ingress pod 是否处于运行状态
- en: Now that you have enabled the external traffic onto your cluster, the next step
    is to install the open source authentication and authorization component for your
    ML platform.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已将外部流量启用到您的集群，下一步是为您的 ML 平台安装开源身份验证和授权组件。
- en: Installing Keycloak on Kubernetes
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上安装 Keycloak
- en: 'We will use Keycloak ([https://www.keycloak.org](https://www.keycloak.org))
    as our identity provider and add authentication and access management capabilities
    for your platform. Keycloak supports industry-standard security mechanisms such
    as **OAuth2** and **OpenID Connect**. In this section, you will install the Keycloak
    server on the Kubernetes cluster and log in to the Keycloak UI to validate the
    installation:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 Keycloak ([https://www.keycloak.org](https://www.keycloak.org)) 作为我们的身份提供者，并为您的平台添加身份验证和访问管理功能。Keycloak
    支持行业标准的安全机制，如**OAuth2**和**OpenID Connect**。在本节中，您将在 Kubernetes 集群上安装 Keycloak
    服务器，并登录到 Keycloak UI 以验证安装：
- en: 'Start by creating a new namespace for the `keycloak` application:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过为 `keycloak` 应用程序创建一个新命名空间开始：
- en: '[PRE8]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You should see the following response:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 4.11 – Output for creating a new namespace for Keycloak'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.11 – 为 Keycloak 创建新命名空间的输出'
- en: '](img/B18332_04_011.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_011.jpg)'
- en: Figure 4.11 – Output for creating a new namespace for Keycloak
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.11 – 为 Keycloak 创建新命名空间的输出
- en: 'Create the Keycloak manifest using the provided YAML file:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用提供的 YAML 文件创建 Keycloak 清单：
- en: '[PRE9]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Validate that the `keycloak` pods are running. Note that the `--namespace`
    and `-n` flags are interchangeable in `kubectl`:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证 `keycloak` pod 是否正在运行。请注意，`--namespace` 和 `-n` 标志在 `kubectl` 中是可以互换的：
- en: '[PRE10]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'It may take a while to start, as it will start by pulling container images
    from the internet. The first time you run the command, you might see that the
    `Keycloak` pod is running, you should see the following response:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 启动可能需要一些时间，因为它会从互联网上拉取容器镜像。第一次运行命令时，您可能会看到 `Keycloak` pod 正在运行，您应该看到以下响应：
- en: '![Figure 4.12 – Validate that the Keycloak pods are in running state'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.12 – 验证 Keycloak pod 是否处于运行状态'
- en: '](img/B18332_04_012.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_012.jpg)'
- en: Figure 4.12 – Validate that the Keycloak pods are in running state
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.12 – 验证 Keycloak pod 是否处于运行状态
- en: In the next few steps, you will define and configure the ingress for your Keycloak
    pod so that it can be accessed from outside the cluster.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的几个步骤中，您将定义并配置 Keycloak pod 的 ingress，使其能够从集群外部访问。
- en: 'Get the IP address of your `minikube` machine by issuing the following command:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令获取 `minikube` 机器的 IP 地址：
- en: '[PRE11]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You should see the following response:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 4.13 – IP address of your minikube instance'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.13 – 您的 minikube 实例的 IP 地址'
- en: '](img/B18332_04_013.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_013.jpg)'
- en: Figure 4.13 – IP address of your minikube instance
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.13 – 您的 minikube 实例的 IP 地址
- en: Open the `chapter4/keycloak-ingress.yaml` file and replace the `KEYCLOAK_HOST`
    string with the `keycloak.<THE_IP_ADDRESS_OF_YOUR_MINIKUBE>.nip.io` string. So,
    if the IP address of your `minikube` is `192.168.61.72`, then the string value
    would be `keycloak.192.168.61.72.nip.io` .
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 打开 `chapter4/keycloak-ingress.yaml` 文件，并将 `KEYCLOAK_HOST` 字符串替换为 `keycloak.<YOUR_MINIKUBE_IP_ADDRESS>.nip.io`
    字符串。所以，如果您的 `minikube` 的 IP 地址是 `192.168.61.72`，那么字符串值将是 `keycloak.192.168.61.72.nip.io`。
- en: There are two places in the file where you need to put this new string. The
    file will look like *Figure 4.14*. Do not forget to save the changes in this file.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 文件中有两个地方需要放入这个新字符串。文件将呈现 *图 4.14* 的样式。不要忘记保存此文件中的更改。
- en: '![Figure 4.14 – The IP address of your minikube instance changed in the keycloak-ingress
    file'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.14 – 您的 minikube 实例的 IP 地址在 keycloak-ingress 文件中已更改'
- en: '](img/B18332_04_014.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_014.jpg)'
- en: Figure 4.14 – The IP address of your minikube instance changed in the keycloak-ingress
    file
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.14 – 您的 minikube 实例的 IP 地址在 keycloak-ingress 文件中已更改
- en: 'Apply the modified file to the Kubernetes cluster. This `ingress` object will
    create the required configuration for you to access the Keycloak server from outside
    the Kubernetes cluster. Run the following command to create the ingress object:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 将修改后的文件应用到 Kubernetes 集群。这个 `ingress` 对象将为您创建所需的配置，使您能够从集群外部访问 Keycloak 服务器。运行以下命令以创建
    ingress 对象：
- en: '[PRE12]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You should see the following response:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 4.15 – Modified ingress has been applied'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.15 – 修改后的 ingress 已应用'
- en: '](img/B18332_04_015.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_015.jpg)'
- en: Figure 4.15 – Modified ingress has been applied
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.15 – 修改后的 ingress 已应用
- en: 'Validate that the `ingress` object is available by issuing the following command:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令验证 `ingress` 对象是否可用：
- en: '[PRE13]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You should see the following response:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下响应：
- en: '![Figure 4.16 – Ingress object has been created'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.16 – Ingress 对象已创建'
- en: '](img/B18332_04_016.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_016.jpg)'
- en: Figure 4.16 – Ingress object has been created
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.16 – Ingress 对象已创建
- en: 'Now that you have validated that Keycloak is running and is exposed through
    the `ingress` object, open a browser on your machine where `minikube` is running
    and access the following URL. You need to replace the correct IP address, as stated
    in s*tep 5*: https://keycloak.192.168.61.72.nip.io/auth/.'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在你已经验证 Keycloak 正在运行，并通过 `ingress` 对象暴露，打开你机器上的浏览器（`minikube` 运行的地方），并访问以下网址。你需要根据步骤
    5 中的说明替换正确的 IP 地址：https://keycloak.192.168.61.72.nip.io/auth/。
- en: You will get a warning that the *certificate is not valid*. This is because
    the Keycloak server uses a self-signed certificate by default. You just need to
    click the **Advance** button presented by the browser and choose to continue to
    the website.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 你会收到一个警告，提示 *证书无效*。这是因为 Keycloak 服务器默认使用自签名证书。你只需要点击浏览器显示的 **高级** 按钮，然后选择继续访问该网站。
- en: 'You should see the following page; click on the **Administration Console**
    link to proceed further:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到以下页面；点击 **管理控制台** 链接继续操作：
- en: '![Figure 4.17 – Keycloak landing page'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.17 – Keycloak 登录页'
- en: '](img/B18332_04_017.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_017.jpg)'
- en: Figure 4.17 – Keycloak landing page
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.17 – Keycloak 登录页
- en: 'Log in using the credentials *admin/admin* in the following screen. After you
    enter the credentials, click **Sign in**:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在以下页面中使用凭据 *admin/admin* 登录。输入凭据后，点击 **登录**：
- en: '![Figure 4.18 – Keycloak login page'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.18 – Keycloak 登录页面'
- en: '](img/B18332_04_018.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_018.jpg)'
- en: Figure 4.18 – Keycloak login page
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.18 – Keycloak 登录页面
- en: 'Validate that the main administration page of Keycloak is displayed as follows:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 验证 Keycloak 的主管理页面是否如以下所示：
- en: '![Figure 4.19  – Keycloak administration page'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 4.19 – Keycloak 管理页面'
- en: '](img/B18332_04_019.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_019.jpg)'
- en: Figure 4.19 – Keycloak administration page
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.19 – Keycloak 管理页面
- en: Congratulations! You have successfully installed the ODH operator and Keycloak
    onto your Kubernetes cluster.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 恭喜你！你已成功将 ODH 操作员和 Keycloak 安装到你的 Kubernetes 集群中。
- en: Summary
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you have learned about the major components of your ML platform
    and how open source community projects provide software products for each of those
    components. Using open source software enables a great number of people to use
    software for free, while at the same time, contributing to improving the components
    while continuously evolving and adding new capabilities to the software.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你已经了解了 ML 平台的主要组件，以及开源社区项目如何为这些组件提供软件产品。使用开源软件不仅使大量用户可以免费使用软件，同时也促进了对组件的持续改进，并为软件不断发展与新增功能做出贡献。
- en: You have installed the operator required to set up the ML platform on your Kubernetes
    cluster. You have installed the ingress controller to allow traffic into your
    cluster and installed Keycloak to provide the identity and access management capabilities
    for your platform.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经安装了设置 ML 平台所需的操作员，并且已安装 ingress 控制器以允许流量进入你的集群，同时也安装了 Keycloak，为你的平台提供身份与访问管理功能。
- en: The foundation has been set for us to go deeper into each component of the ML
    life cycle. In the next chapter, you will learn to set up Spark and JupyterHub
    on your platform, which enables data engineers to build and deploy data pipelines.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 基础已经搭建好，我们可以深入探讨 ML 生命周期中的每个组件。在下一章中，你将学习如何在你的平台上设置 Spark 和 JupyterHub，这将使数据工程师能够构建和部署数据管道。
- en: Further reading
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Data preparation is the least enjoyable task in data science: [https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=1e5986216f63](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=1e5986216f63)'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据准备是数据科学中最不令人愉快的任务：[https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=1e5986216f63](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=1e5986216f63)
