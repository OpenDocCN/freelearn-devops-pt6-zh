- en: '*Chapter 4*: The Anatomy of a Machine Learning Platform'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第4章*：机器学习平台的构成'
- en: In this and the next few chapters, you will learn and install the components
    of a **machine learning** (**ML**) platform on top of Kubernetes. An ML platform
    should be capable of providing the tooling required to run the full life cycle
    of an ML project as described in [*Chapter 2*](B18332_02_ePub.xhtml#_idTextAnchor027),
    *Understanding MLOps*. This chapter starts with defining the different components
    of an ML platform in a technology-agnostic way. In the later parts, you will see
    the group of open source software that can satisfy the requirements of each component.
    We have chosen this approach to not tie you up with a specific technology stack;
    instead, you can replace components as you deem fit for your environment.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章及接下来的几章中，你将学习并安装构建在Kubernetes上的**机器学习**（**ML**）平台的各个组件。一个ML平台应当能够提供运行ML项目全生命周期所需的工具，如[*第2章*](B18332_02_ePub.xhtml#_idTextAnchor027)《理解MLOps》中所描述的那样。本章首先从技术无关的角度定义了ML平台的不同组件。在后续部分，你将看到一组开源软件，能够满足每个组件的要求。我们选择这种方式，是为了不将你束缚于特定的技术栈；相反，你可以根据自己的环境需要替换组件。
- en: The solution that you will build in this book will be based on open source technologies
    and will be hosted on the Kubernetes platform that you built in [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040),
    *Exploring Kubernetes*.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你将在本书中构建的解决方案将基于开源技术，并托管在你在[*第3章*](B18332_03_ePub.xhtml#_idTextAnchor040)《探索Kubernetes》中构建的Kubernetes平台上。
- en: 'In this chapter, you will learn about the following topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将学习以下主题：
- en: Defining a self-service platform
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义自助平台
- en: Exploring the data engineering components
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索数据工程组件
- en: Exploring the ML model life cycle components
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索ML模型生命周期组件
- en: Addressing security, monitoring, and automation
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决安全性、监控和自动化问题
- en: Exploring Open Data Hub
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索Open Data Hub
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter includes some hands-on setup. You will be needing a running Kubernetes
    cluster configured with the **Operator Life cycle Manager** (**OLM**). Building
    such a Kubernetes environment is covered in [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040),
    *Exploring Kubernetes*. Before attempting the technical exercises in this chapter,
    please make sure that you have a working Kubernetes cluster. You may choose to
    use a different flavor of Kubernetes than the one described in [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040),
    *Exploring Kubernetes*, as long as the cluster has the OLM installed.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章包括一些实践设置。你将需要一个配置了**操作符生命周期管理器**（**OLM**）的运行中Kubernetes集群。如何构建这样的Kubernetes环境已在[*第3章*](B18332_03_ePub.xhtml#_idTextAnchor040)《探索Kubernetes》中介绍。在尝试本章的技术练习之前，请确保你有一个正在工作的Kubernetes集群。你可以选择使用与[*第3章*](B18332_03_ePub.xhtml#_idTextAnchor040)《探索Kubernetes》中描述的不同版本的Kubernetes，只要该集群安装了OLM。
- en: Defining a self-service platform
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 定义自助服务平台
- en: '**Self-service** is defined as the capability of a platform that allows platform
    end users to provision resources on-demand without other human intervention. Take,
    for example, a data scientist user who needs an instance of a Jupyter notebook
    server, running on a host container with eight CPUs, to perform his/her work.
    A self-service ML platform should allow the data scientist to provision, through
    an end user friendly interface, the container that will run an instance of the
    Jupyter notebook server on it. Another example of self-service provisioning would
    be a data engineer requesting a new instance of an Apache Spark cluster to be
    provisioned to run his/her data pipelines. The last example is a data scientist
    who wants to package and deploy their ML model as a REST service so that the application
    can use the model.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '**自助服务**被定义为平台的一种能力，允许平台终端用户按需提供资源而无需其他人工干预。例如，数据科学家用户可能需要一个Jupyter notebook服务器实例，运行在一个具有8个CPU的主机容器上，以执行他的/她的工作。一个自助式的ML平台应当允许数据科学家通过一个终端用户友好的界面，提供容器并运行Jupyter
    notebook服务器实例。另一个自助服务的例子是，数据工程师请求提供一个新的Apache Spark集群实例，以运行他的/她的数据管道。最后一个例子是数据科学家希望将其ML模型打包并作为REST服务进行部署，以便应用程序可以使用该模型。'
- en: One benefit of a self-service platform is that it allows cross-functional teams
    to work together with minimal dependencies on other teams. This independence results
    in better team dynamics, less friction, and increased team velocity.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自助服务平台的一个好处是，它允许跨职能团队以最小的依赖关系共同工作。这种独立性带来了更好的团队动态、更少的摩擦和更高的团队速度。
- en: The self-service model, however, needs governance. Imagine every data scientist
    requesting GPUs or data engineers requesting tens of terabytes of storage! Self-service
    capability is great, but without proper governance, it could also create problems.
    To avoid such problems, the platform has to be managed by a platform team that
    can control or limit the things the end users can do. One example of this limit
    is resource quotas. Teams and/or individual users can be allocated with quotas
    and be responsible for managing their own resources within the allocated quotas.
    Luckily, Kubernetes has this capability, and our ML platform can utilize this
    capability to apply limits to the team's resources.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
- en: As part of governance, the platform must have role-based access control. This
    is to ensure that only the users with the right role will have access to the resources
    they manage. For example, the platform team may be able to change the resource
    quotas, while data engineers can only spin up new Spark clusters and run data
    pipelines.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: Another aspect of a self-service platform is the isolation of workloads. Many
    teams will be sharing the same platform and, while the quotas will keep the teams
    within their predefined boundaries, it is critical that there is a capability
    to isolate workloads from each other so that multiple unrelated projects running
    on the same platform do not overlap.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the data engineering components
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the context of this book, data engineering is the process of ingesting raw
    data from source systems and producing reliable data that could be used in scenarios
    such as analytics, business reporting, and ML. A data engineer is a person who
    builds software that collects and processes raw data to generate clean and meaningful
    datasets for data analysts and data scientists. These datasets will form the backbone
    for your organization's ML initiatives.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 4.1* shows the various stages of a typical data engineering area of
    an ML project:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Data engineering stages for ML'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_001.jpg)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.1 – Data engineering stages for ML
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: Data engineering often overlaps with **feature engineering**. While a data scientist
    decides on which features are more useful for the ML use case, he or she may work
    with the data engineer to retrieve particular data points that are not available
    in the current feature set. This is the main collaboration point between data
    engineers and data scientists. The datasets created by the data engineer in the
    data engineering block become the feature set in the ML block.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: An ML platform that enables teams to perform feature engineering will have the
    following components and processes.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '**Data ingestion**: Data ingestion is the process in which the team understands
    the data sources and builds and deploys software that collects data from one or
    more data sources. Data engineers understand the impact of reading data from source
    systems. For example, while reading data from a source, the performance of the
    source system may get affected. Therefore, it is important for the ML platform
    to have a workflow scheduling capability so that the data collection can be scheduled
    during a time when the source system is less active.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An ML platform enables the team to ingest data from various sources in multiple
    ways. For example, some data sources would allow data to be pulled, while other
    data sources may be able to push data. Data may come from a relational database,
    data warehouses, data lakes, data pools, data streams, API calls, or even from
    a raw filesystem. The platform should also have the capability to understand different
    protocols, for example, a messaging system may have multiple protocols, such as
    **Advanced Message Queuing Protocol** (**AMQP**), **Message Queuing Telemetry
    Transport** (**MQTT**), and Kafka. In other words, the ML platform should have
    the capability to gather data of various shapes and sizes from different types
    of data sources in various ways. *Figure 4.2* shows various sources of data from
    where the platform should be able to ingest the data:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Data ingestion integrations'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_002.jpg)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.2 – Data ingestion integrations
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
- en: '**Data transformation**: Once the data is ingested from various sources, it
    needs to be transformed from its original form into something that is more useful
    for the ML model training and other use cases. According to a Forbes survey, *80%
    of data scientists'' work is related to preparing data for the model training*;
    this is the stage that is generally considered as boring among the data science
    teams. However, if the data is not transformed into an appropriate form, it will
    lead to less useful and/or inefficient ML models. An ML platform enables teams
    to code, build, and deploy the data transformation pipelines and jobs with ease.
    The platform abstracts the complications of running and managing data transformation
    components such as Apache Spark jobs. Not only does the platform manage the execution
    of these processes, but it also manages the provisioning and cleaning of compute
    resources required to run these components, such as CPU, memory, and networking.'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage**: During the feature engineering process, you will read and write
    data at various stages. You might create a temporary representation of the dataset
    for further processing, or you could write the new dataset to be used for ML processes.
    In these scenarios, you will need storage resources that can be accessed with
    ease and scale as needed. An ML platform provides on-demand storage for your datasets
    to be stored in a reliable fashion.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now, let's see how the data engineer will use these components in their workflow.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看数据工程师将如何在他们的工作流中使用这些组件。
- en: Data engineer workflow
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据工程师工作流
- en: 'All the capabilities mentioned in the previous section are provided by the
    ML platform in a self-serving manner. The workflow that a data engineer using
    the platform would typically perform is as follows:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节中提到的所有功能都由机器学习平台以自服务的方式提供。数据工程师在使用平台时通常会执行的工作流如下：
- en: '*Log in to the platform*: In this step, the data engineer authenticates to
    the platform.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*登录平台*：在此步骤中，数据工程师进行平台身份验证。'
- en: '*Provisioning of the development environment*: In this step, the data engineer
    requests the resource requirements for the development environment (such as the
    number of CPUs, amount of memory, and specific software libraries) to the platform.
    The platform then provisions the requested resources automatically.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*配置开发环境*：在此步骤中，数据工程师向平台请求开发环境所需的资源（如CPU数量、内存大小和特定的软件库）。平台随后会自动配置所请求的资源。'
- en: '*Build a data pipeline*: In this step, the data engineer writes the code for
    data ingestion and data transformation. The data engineer then runs the code in
    an isolated environment to verify its validity and perform the necessary refactoring
    and tuning of the code.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*构建数据管道*：在此步骤中，数据工程师编写用于数据摄取和数据转换的代码。然后，数据工程师将在隔离环境中运行代码，验证其有效性，并进行必要的重构和调优。'
- en: '*Run a data pipeline*: In this step, the data engineer schedules the code to
    run as needed. It can be a regular schedule with periodic intervals such as hourly
    or daily, or a one-off run, depending on the use case.'
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*运行数据管道*：在此步骤中，数据工程师按需安排代码运行。可以根据使用场景选择定期运行（如每小时或每日）或一次性运行。'
- en: You can see in the preceding steps that besides writing the code, all other
    steps are declarative. The data engineer's focus will be on building the code
    to ingest and transform data. All other aspects of the flow will be taken care
    of by the ML platform. This will result in improved efficiency and velocity for
    the team. The declarative capability of the platform will allow teams to standardize
    processes across your organization, which will reduce the number of bespoke toolchains
    and improve the security of the overall process.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的步骤中可以看到，除了编写代码，其他所有步骤都是声明性的。数据工程师的重点将放在构建用于摄取和转换数据的代码上。流程的其他方面将由机器学习平台负责。这将提高团队的效率和工作速度。平台的声明式功能将帮助团队在整个组织内标准化流程，从而减少定制工具链的数量，并提升整体流程的安全性。
- en: The main output of the data engineering flow is a usable, transformed, and partially
    cleaned set of data that can be used to start building and training a model.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 数据工程流程的主要输出是一个可用的、已转换并部分清理的数据集，可以用来开始构建和训练模型。
- en: Exploring the model development components
  id: totrans-41
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索模型开发组件
- en: Once the cleaned data is available, data scientists then go through the problem
    and try to determine what set of patterns would be helpful for the situation.
    The key here is that the data scientist's primary role is to find patterns in
    the data. Model development components of the ML platform explore data patterns,
    build and train ML models, and trial multiple configurations to find the best
    set of configurations and algorithms to achieve the desired performance of the
    model.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦清理后的数据可用，数据科学家将对问题进行分析，尝试确定哪些模式对于该情况有帮助。关键是数据科学家的主要职责是从数据中找出模式。机器学习平台的模型开发组件会探索数据模式、构建和训练机器学习模型，并试验多种配置，找到最佳的配置和算法，以实现模型所需的性能。
- en: Within the course of model development, data scientists or ML engineers build
    multiple models based on multiple algorithms. These models are then trained using
    the data gathered and prepared from the data engineering flow. The data scientist
    then plays around with several hyperparameters to get different results from model
    testing. The result of such training and testing is then compared with each of
    the other models. These experimentation processes are then repeated multiple times
    until the desired results are achieved.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在模型开发过程中，数据科学家或机器学习工程师基于多个算法构建多个模型。这些模型将使用数据工程流程中收集和准备的数据进行训练。数据科学家接着会调整几个超参数，通过模型测试得到不同的结果。然后，这些训练和测试的结果将与其他模型进行比较。这些实验过程将重复多次，直到达到预期的结果。
- en: The experimentation phase will result in a selection of the most appropriate
    algorithm and configuration. The selected model will then be tagged for packaging
    and deployment.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 实验阶段将导致选择最合适的算法和配置。选定的模型将被标记以便打包和部署。
- en: '*Figure 4.3* shows the various stages of model development for an ML project:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '*图4.3* 显示了机器学习项目中模型开发的各个阶段：'
- en: '![Figure 4.3 – Data engineering stages for ML'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '![图4.3 – 机器学习数据工程阶段'
- en: '](img/B18332_04_003.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_04_003.jpg)'
- en: Figure 4.3 – Data engineering stages for ML
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – 机器学习数据工程阶段
- en: 'An ML platform that enables teams to perform model development will have the
    following components:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 一个能够支持团队进行模型开发的机器学习平台将包含以下组件：
- en: '**Data exploration**: We humans are better at finding patterns when the data
    is visualized as opposed to just looking at raw data sets. The ML platform enables
    you to visualize data. As a data scientist, you will need to collaborate with
    **subject matter experts** (**SMEs**) who have domain knowledge. Let''s say you
    are analyzing a dataset of coronavirus patients. If you are not an expert in the
    virology or medicine domains, you will need to work with an SME who can provide
    insights about the dataset, the relationships of features, and the quality of
    the data itself. An ML platform allows you to share the visualizations you have
    created with the wider team for improved feedback. The platform also allows non-technical
    people to look at the data in a more graphical approach. This will help them gain
    a better understanding of the data.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据探索**：我们人类在数据可视化时比仅仅查看原始数据集时更擅长发现模式。机器学习平台使你能够可视化数据。作为数据科学家，你需要与**领域专家**（**SMEs**）合作，后者拥有专业知识。假设你正在分析一组冠状病毒患者的数据集。如果你不是病毒学或医学领域的专家，你将需要与一个能够提供关于数据集、特征关系以及数据质量的见解的领域专家合作。机器学习平台允许你将自己创建的可视化图表分享给更广泛的团队，以便获得更好的反馈。平台还允许非技术人员以更图形化的方式查看数据，这有助于他们更好地理解数据。'
- en: '**Experimentation**: As a data scientist, you will split the data into training
    and testing sets, and then start building the model for the given metric. You
    will then experiment with multiple ML algorithms such as decision trees, XGBoost,
    and deep learning, and apply a variety of parameter tuning to each of the algorithms,
    for example, the number of layers or number of neurons for a deep learning model.
    This is what we call experimentation, and the platform enables the team to perform
    the experimentation in an autonomous way. Keep in mind that for each experiment,
    you may have different requirements for compute resources such as a GPU. This
    makes the self-service provisioning capability of the platform critical.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实验**：作为数据科学家，你将把数据分为训练集和测试集，然后开始为给定的指标构建模型。接下来，你将尝试多种机器学习算法，如决策树、XGBoost
    和深度学习，并为每个算法应用不同的参数调优，例如深度学习模型中的层数或神经元数量。这就是我们所说的实验，平台使团队能够以自主的方式进行实验。请记住，对于每个实验，你可能需要不同的计算资源，如
    GPU。因此，平台的自助服务配置能力至关重要。'
- en: '**Tracking**: While doing multiple experiments, you need to keep track of the
    parameters used for each experiment and the metrics it has achieved. Some algorithms
    may require different sets of features, which means you also need to keep track
    of the version of the dataset that was used in training. There are two reasons
    for doing this. The first reason is that you will need a history of your experiments
    so that you can compare and pick the best combination. The second reason is that
    you may need to share the results with your fellow data scientists. The ML platform
    enables you to record the results of the experiments and share them seamlessly.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跟踪**：在进行多个实验时，你需要跟踪每个实验使用的参数以及它所取得的指标。一些算法可能需要不同的特征集，这意味着你还需要跟踪在训练中使用的数据集版本。这样做有两个原因。第一个原因是，你将需要保留实验历史，以便进行比较并挑选最佳组合。第二个原因是，你可能需要将结果与其他数据科学家共享。机器学习平台使你能够记录实验结果并无缝共享。'
- en: '**Model building and tuning**: In the experimentation stage, you have found
    the best algorithm and the best parameters for your model. You have compared the
    results and associated metrics for your model and have chosen the algorithm and
    parameters to be used. In this stage, you will train your model with these parameters,
    and register it with the model registry:'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型构建与调优**：在实验阶段，你已经找到了最佳的算法和最佳参数。你已比较了模型的结果和相关指标，并选择了用于模型的算法和参数。在这个阶段，你将使用这些参数训练你的模型，并将其注册到模型注册表中：'
- en: '**Model registry**: As a data scientist, when you are satisfied with your model,
    you work with your team to deploy it. The real world changes, however, and you
    will need to update your model for new datasets or different metrics or simply
    for improved metrics. New versions of the models come all the time and the ML
    platform enables you to keep track of the versions of your models. The model versioning
    capability will help the team to compare the efficiency of new model versions
    with older model versions and allow the team to roll back a new model in production
    to previous versions if the need arises.'
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型注册表**：作为数据科学家，当你对模型感到满意时，你将与团队一起部署它。然而，现实世界会发生变化，你需要为新数据集、不同指标或仅仅为了提高指标而更新模型。新版本的模型不断出现，ML平台使你能够追踪模型版本。模型版本控制功能将帮助团队比较新旧模型版本的效率，并在需要时允许团队将生产中的新模型回滚至以前的版本。'
- en: '**Storage**: Storage is not only important in the data engineering phase but
    also in model development. During the model development process, you read and
    write data at various stages. You split the dataset into a testing dataset and
    a training dataset, and you may choose to write it once so you can experiment
    with different model parameters but with the same datasets. The experiment tracking
    module and the model registry both need storage. The ML platform provides on-demand
    storage for your datasets to be stored in a reliable fashion.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储**：存储不仅在数据工程阶段重要，在模型开发过程中同样至关重要。在模型开发过程中，你会在多个阶段读取和写入数据。你将数据集分成测试集和训练集，你可能选择只写入一次数据，这样你可以在相同数据集上进行不同模型参数的实验。实验追踪模块和模型注册表都需要存储。ML平台为你的数据集提供按需存储，确保数据可靠存储。'
- en: Now, let's see how the data scientists use these components in their workflow.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看数据科学家如何在他们的工作流程中使用这些组件。
- en: Understanding the data scientist workflow
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解数据科学家的工作流程
- en: 'All the capabilities mentioned in the previous section are provided by the
    ML platform in a self-serving way. The typical workflow for the data scientist
    would be as follows:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 上一节中提到的所有功能都由ML平台以自助方式提供。数据科学家的典型工作流程如下：
- en: '*Log in to the platform*: The data scientists authenticate to the platform.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*登录平台*：数据科学家对平台进行身份验证。'
- en: '*Provisioning of the development environment*: In this step, the data scientist
    requests, to the platform, the resource requirements for the development environment,
    such as the number of CPUs, amount of memory, and specific software libraries.
    The platform then provisions the requested resources automatically.'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*开发环境的配置*：在这一步骤中，数据科学家向平台请求开发环境的资源要求，如CPU数量、内存大小和特定的软件库。平台会自动为你配置所需资源。'
- en: '*Exploratory data analysis*: In this stage, data scientists perform several
    types of data transformations and visualization techniques to understand the patterns
    hidden in the data.'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*探索性数据分析*：在这个阶段，数据科学家进行多种数据转换和可视化技术，以理解数据中隐藏的模式。'
- en: '*Experimenting with different algorithms*: In this stage, data scientists split
    the full dataset into training and testing sets. Then, the data scientists apply
    different ML algorithms and hyperparameters to achieve the desired metrics. Data
    scientists then compare the parameters of each training run to select the best
    one for the given use case.'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*尝试不同的算法*：在这个阶段，数据科学家将完整数据集拆分为训练集和测试集。然后，数据科学家应用不同的ML算法和超参数，以实现所需的指标。数据科学家接着比较每次训练运行的参数，选择最适合给定用例的参数。'
- en: '*Model training*: Data scientists train the model as per the most optimized
    parameters found in the previous stage, and register the model in the model registry.'
  id: totrans-63
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*模型训练*：数据科学家根据前一阶段找到的最优化参数训练模型，并将模型注册到模型注册表中。'
- en: '*Run model deployment pipeline*: In this step, the data scientists package
    the model to be consumed as a service and build the pipeline to automate the deployment
    process. It can be scheduled regularly or as a one-off run, depending on the use
    case.'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '*运行模型部署管道*：在此步骤中，数据科学家将模型打包以作为服务消费，并构建自动化部署流程。根据用例，它可以定期调度或一次性运行。'
- en: You can see in the preceding steps that besides writing the code to facilitate
    model building and training, all other steps are declarative. The data scientists'
    focus will be on building more data science and ML engineering tasks. All other
    aspects of the flow will be taken care of by the ML platform. This will result
    in improved efficiency and velocity for the team, not to mention a happier data
    scientist. The declarative capability of the platform will also allow teams to
    standardize processes across your organization, which will reduce the use of bespoke
    toolchains improving consistency and improving the security of the overall process.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在前面的步骤中看到，除了编写便于模型构建和训练的代码之外，所有其他步骤都是声明性的。数据科学家的重点将放在构建更多的数据科学和ML工程任务上。流程的所有其他方面将由ML平台处理。这将提高团队的效率和速度，更不用说数据科学家的幸福感了。平台的声明能力还将允许团队在整个组织中标准化流程，从而减少使用定制工具链，提高一致性并改善整个流程的安全性。
- en: In the next section, you will explore the common services of the ML platform.
    These services are critical to making the platform production-ready and easier
    to adopt in the enterprise environment.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的部分中，您将探讨ML平台的常见服务。这些服务对于使平台达到生产就绪状态并在企业环境中更易于采用至关重要。
- en: Security, monitoring, and automation
  id: totrans-67
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 安全性、监控和自动化
- en: 'In this section, you will see some common components of the ML platform that
    apply to all the components and stages we have discussed so far. These components
    assist you in operationalizing the platform in your organization:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，您将看到适用于我们到目前为止讨论的所有组件和阶段的ML平台的一些常见组件。这些组件帮助您在组织中实现平台的操作化：
- en: '**Data pipeline execution**: The outcome of data engineering is a data pipeline
    that ingests, cleans, and processes data. You have built this pipeline with scaled-down
    data for development purposes. Now, you need to run this code with production
    data, or you want a scheduled run with new data available, say, every week. An
    ML platform allows you to take your code and automate its execution in different
    environments. This is a big step because the platform not only allows you to run
    your code but will also manage the packaging of all the dependencies of your code
    so that it can run anywhere. If the code that you have built is using Apache Spark,
    the platform should allow you to automate the process of provisioning a Spark
    cluster and all other components required to run your data pipeline.'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据管道执行**：数据工程的结果是一个数据管道，用于摄取、清理和处理数据。您已经用缩减版数据构建了这个管道以供开发目的使用。现在，您需要用生产数据运行这些代码，或者您希望定期运行新数据，比如每周。ML平台允许您获取代码并在不同环境中自动执行它。这是一大进步，因为平台不仅允许您运行代码，还将管理代码的所有依赖项的打包，使其可以在任何地方运行。如果您构建的代码使用Apache
    Spark，平台应允许您自动化提供Spark集群和运行数据管道所需的所有其他组件的过程。'
- en: '**Model deployment**: Once the model is ready to be used, it should be available
    to be consumed as a service. Without the automated model packaging and deployment
    capability of the ML platform, the process of packaging a model and hosting it
    as a service requires some software engineering work. This work requires tight
    collaboration with software engineers and the operations team and may take days,
    if not weeks, to accomplish. The ML platform automates this process and it usually
    takes only a few seconds to a few minutes. The result of this process is an ML
    model deployed in an environment and is accessible as a service – typically, as
    a REST API.'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**模型部署**：一旦模型准备好供使用，它应该可以作为服务供消费。如果没有ML平台的自动化模型打包和部署能力，将模型打包并将其托管为服务的过程需要一些软件工程工作。这项工作需要与软件工程师和运维团队紧密合作，并可能需要花费数天甚至数周的时间才能完成。ML平台自动化了这个过程，通常只需几秒到几分钟的时间。这个过程的结果是在环境中部署的ML模型，并可以作为服务访问，通常以REST
    API的形式提供。'
- en: Deployment of the model is one aspect; over time, you may also need to re-train
    the model with new datasets. The platform also enables your team to automate the
    retraining process using the same training code you built for the first time when
    you trained your model. The retrained model is then redeployed automatically.
    This capability massively improves the efficiency of the team and this allows
    for more efficient use of time, such as working on newer challenges while delivering
    values for the business.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 模型的部署是一个方面；随着时间的推移，你可能还需要用新数据集重新训练模型。该平台还使团队能够使用第一次训练模型时所编写的相同训练代码来自动化重新训练过程。重新训练的模型将自动重新部署。这项功能大大提高了团队的效率，允许更高效地利用时间，如处理新的挑战，同时为业务提供价值。
- en: '**Monitoring**: Monitoring does not just refer to having the capability to
    observe the dynamics of the components in production, such as monitoring the model
    response time, but it also enables the team to respond to events before they become
    problems. A good monitoring platform provides observability during the full ML
    project life cycle and not just monitoring in production. When you are writing
    code to process data, you may need to tune the joins expression between datasets
    from multiple systems. This is one of the examples of information you need during
    development. The ML platform allows you to dig into the details during the development
    process. The platform also provides capabilities to monitor the underlying IT
    infrastructure. For example, when you are running your code during the model training
    stage, the platform provides the metrics on hardware resource utilization.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**监控**：监控不仅仅是指拥有观察生产环境中组件动态的能力，例如监控模型响应时间，它还使团队能够在问题发生之前响应事件。一个好的监控平台在整个机器学习项目生命周期中提供可观测性，而不仅仅是生产环境中的监控。当你编写代码处理数据时，你可能需要调整来自多个系统的数据集之间的连接表达式。这是你在开发过程中需要的信息之一。该平台允许你在开发过程中深入了解细节。平台还提供监控底层IT基础设施的能力。例如，在模型训练阶段运行代码时，平台提供硬件资源利用率的度量。'
- en: '**Security and governance**: The platform you are building allows teams to
    work autonomously. Teams can use the tools in the platform to perform the work
    anytime. However, the question of who can access what and who can use which tools
    proves to be a challenge for many organizations. For this, the platform must have
    an access control capability and provide access to only authorized users. The
    security component of the platform allows the users to be authenticated and authorized
    through standard protocols such as **OAuth2** or **OpenID Connect**. You will
    be using open source components to bring authentication components to the platform.
    The platform also uses the Kubernetes namespace feature to provide workload isolation
    across different teams that are sharing the same cluster. Kubernetes also provides
    the capability to assign limits of hardware resources to be used by individual
    teams. These capabilities will enable teams to share the platform across many
    different units within your organization while providing well-defined isolation
    boundaries and hardware resource quotas.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性和治理**：你正在构建的平台使团队能够独立工作。团队可以随时使用平台中的工具进行工作。然而，谁可以访问什么资源、谁可以使用哪些工具，成为许多组织面临的挑战。为此，平台必须具备访问控制功能，只允许授权用户访问。平台的安全组件通过标准协议，如**OAuth2**或**OpenID
    Connect**，对用户进行认证和授权。你将使用开源组件将认证功能引入平台。平台还使用Kubernetes命名空间功能，在共享相同集群的不同团队之间提供工作负载隔离。Kubernetes还提供将硬件资源使用限制分配给各个团队的能力。这些功能将使团队能够在组织内的多个单位之间共享平台，同时提供明确的隔离边界和硬件资源配额。'
- en: '**Source code management**: When you build data pipelines or train your model,
    you write code. The platform provides capabilities to integrate with source code
    management solutions. **Git** is the default source code management solution integrated
    platform.'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**源代码管理**：当你构建数据管道或训练模型时，你会编写代码。该平台提供与源代码管理解决方案的集成功能。**Git**是集成平台的默认源代码管理解决方案。'
- en: Now, let's move on to cover **Open Data Hub** (**ODH**).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续介绍**开放数据中心**（**ODH**）。
- en: Introducing ODH
  id: totrans-76
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 引入 ODH
- en: ODH is an open source project that provides most of the components required
    by our ML platform. It comes with a Kubernetes operator and a curated set of open
    source software components that make up most of the ML platform. In this book,
    we will mainly use the ODH operator. There are also other components that we will
    be using in the platform that don't originally come with ODH. One good thing about
    the ODH operator is the ability to swap default components for another as you
    see fit for your case.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: 'To build the platform, you will use the following components. In the next few
    chapters, you will learn about the details of each of these components and how
    to use them. For now, you just need to understand their purpose at a very high-level:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: '**ODH operator**: A Kubernetes operator that manages the life cycle of different
    components of the ML platform. It controls and manages the installation and maintenance
    of the software components used in your ML platform.'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**JupyterHub**: Manages instances of Jupyter Notebook servers and their related
    resources.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Jupyter notebooks**: An **integrated development environment** (**IDE**)
    is the main data engineering and data science workspace in the platform. Data
    scientists and engineers will use these workspaces to write and debug code for
    both data engineering and ML workflows.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache Spark**: A distributed, parallel data processing engine and framework
    for processing large datasets. It provides a wide array of data ingestion connectors
    to consume data from a variety of sources.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache Airflow**: A workflow engine that automates the execution and scheduling
    of data pipelines and model deployment. Airflow orchestrates different components
    of your data pipelines.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Seldon Core**: A library for packaging and deploying ML models as a REST
    service. It also has the capability of monitoring the deployed models. It provides
    support for popular ML frameworks, which gives it the capability to wrap and package
    ML models built with frameworks such as TensorFlow, scikit-learn, XGBoost, and
    PyTorch, as REST services.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Prometheus and Grafana**: These two components provide the monitoring capabilities
    for our platform. Prometheus provides the metrics database to record telemetry
    data provided by the components of the platform, and Grafana provides the **graphical
    user interface** (**GUI**) to visualize the captured metrics.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Minio**: An object storage provider that is compatible with Amazon S3 APIs.
    The Minio component is not part of the ODH toolchain, but we will extend and configure
    the ODH operator to manage the Minio component on the ML platform.'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MLFlow**: A component for tracking different model experiments and also serves
    as the model registry of the platform. The MLFlow component is not part of the
    ODH toolchain, but we will extend the ODH operator to manage the MLFlow component
    on the ML platform'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You will also install an open source identity provider component. The goal for
    this component is to provide a common single sign-on feature for all the platform
    components. We will use **Keycloak** as the identity management system, but this
    could be swapped with an OAuth2-based system that may already exist in your case.
    Keycloak is not part of the ODH, and we will show you how to install it as a separate
    component on your Kubernetes cluster.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: '*Figure 4.4* shows the major open source software that serves as the main components
    of the ML platform. The ODH extensibility model allows you to add or choose which
    products to use for which components as per the requirements. You can replace
    any of the components with other open source products of choice. However, for
    the exercises in this book, we will use the product listed here:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.4 – Major components of the ML platform'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_004.jpg)'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.4 – Major components of the ML platform
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you will deploy the ODH operator and Keycloak server on
    your Kubernetes cluster. You will also install and configure the ingress controller
    to accept traffic from outside the cluster.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: Installing the ODH operator on Kubernetes
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you will install the ODH operator onto your Kubernetes cluster.
    At this stage, you will not enable any components of the platform. To install
    the operator, you first need to register the catalog source for the operator,
    and then you can install it.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let''s register the catalog for the ODH operator. A catalog source contains
    metadata through which the OLM can discover operators and their dependencies.
    The ODH operator is not available in the default OLM catalog, so we need to register
    a new catalog that contains the ODH metadata for the OLM:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'Validate that your Kubernetes cluster is running if you are using `minikube`:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You should see the following response:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.5 – Validate that Kubernetes is running via minikube'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_005.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.5 – Validate that Kubernetes is running via minikube
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
- en: If your Kubernetes cluster is not running, please refer to [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040),
    *Exploring Kubernetes*, on how to configure and start the Kubernetes cluster.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: 'Verify that the OLM is installed and is running by executing the following:'
  id: totrans-104
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-105
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You should see the following response:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.6 – Command output showing OLM pods are running'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_006.jpg)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.6 – Command output showing OLM pods are running
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that all the OLM pods are running. If this is not the case for you,
    refer to [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040), *Exploring Kubernetes*,
    in the *How to install OLM in your cluster* section.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: 'Clone the Git repository and navigate to the repository''s root directory.
    This repository contains all the source files, scripts, and manifests that you
    need to build the platform within the scope of this book: https://github.com/PacktPublishing/Machine-Learning-on-Kubernetes.git
    cd Machine-Learning-on-Kubernetes.'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Register a new `catalog source` operator by using the YAML file available in
    the source code of this book:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'After a couple of minutes, validate that the operator is available in your
    cluster:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You should see the following response:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.7 – Validate that the ODH operator is available'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_007.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.7 – Validate that the ODH operator is available
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: On Windows PowerShell, you may need to replace the `grep` command with `findstr`.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, create the subscription for the ODH operator. Recall from the third chapter
    that a subscription object triggers the installation of the operator via the OLM:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: You should see a response message that the subscription has been created.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'After creating the subscription, the OLM will automatically install the operator
    and all its components. Verify that the ODH pod is running by issuing the following
    command. It may take a few seconds before the pods start appearing. If the pods
    are not listed, wait for a few seconds and rerun the same command:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-125
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'You should see the following response:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.8 – Validate that the ODH pod is up and running'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_008.jpg)'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.8 – Validate that the ODH pod is up and running
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: You have just installed the ODH operator on your Kubernetes cluster. Notice
    that you have not used generic Kubernetes objects such as **Deployments** to run
    your operator. The OLM allows you to easily manage the installation of an operator
    via the **Subscription** object.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, you install the ingress controller to allow traffic into
    your Kubernetes cluster.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: Enabling the ingress controller on the Kubernetes cluster
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recall from [*Chapter 3*](B18332_03_ePub.xhtml#_idTextAnchor040), *Exploring
    Kubernetes*, that ingress provides a way for you to expose a particular service
    to make it accessible from outside the cluster. There are many ingress providers
    available on Kubernetes, and we leave it to you to select the right ingress provider
    for your cluster.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are using `minikube`, you need to follow these steps to enable the default
    ingress:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 'Enable the NGINX-based ingress controller for your cluster by issuing the following
    command:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'You should see the following response:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.9 – Output for enabling minikube ingress plugin'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_009.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.9 – Output for enabling minikube ingress plugin
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: 'Validate that the ingress pods are running in your cluster:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'You should see the following response:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.10 – Validate that the Nginx ingress pods are in running state'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_010.jpg)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.10 – Validate that the Nginx ingress pods are in running state
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have enabled the external traffic onto your cluster, the next step
    is to install the open source authentication and authorization component for your
    ML platform.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Installing Keycloak on Kubernetes
  id: totrans-148
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will use Keycloak ([https://www.keycloak.org](https://www.keycloak.org))
    as our identity provider and add authentication and access management capabilities
    for your platform. Keycloak supports industry-standard security mechanisms such
    as **OAuth2** and **OpenID Connect**. In this section, you will install the Keycloak
    server on the Kubernetes cluster and log in to the Keycloak UI to validate the
    installation:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 'Start by creating a new namespace for the `keycloak` application:'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'You should see the following response:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.11 – Output for creating a new namespace for Keycloak'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_011.jpg)'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.11 – Output for creating a new namespace for Keycloak
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the Keycloak manifest using the provided YAML file:'
  id: totrans-156
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'Validate that the `keycloak` pods are running. Note that the `--namespace`
    and `-n` flags are interchangeable in `kubectl`:'
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'It may take a while to start, as it will start by pulling container images
    from the internet. The first time you run the command, you might see that the
    `Keycloak` pod is running, you should see the following response:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.12 – Validate that the Keycloak pods are in running state'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_012.jpg)'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.12 – Validate that the Keycloak pods are in running state
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: In the next few steps, you will define and configure the ingress for your Keycloak
    pod so that it can be accessed from outside the cluster.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: 'Get the IP address of your `minikube` machine by issuing the following command:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'You should see the following response:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.13 – IP address of your minikube instance'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_013.jpg)'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.13 – IP address of your minikube instance
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Open the `chapter4/keycloak-ingress.yaml` file and replace the `KEYCLOAK_HOST`
    string with the `keycloak.<THE_IP_ADDRESS_OF_YOUR_MINIKUBE>.nip.io` string. So,
    if the IP address of your `minikube` is `192.168.61.72`, then the string value
    would be `keycloak.192.168.61.72.nip.io` .
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: There are two places in the file where you need to put this new string. The
    file will look like *Figure 4.14*. Do not forget to save the changes in this file.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.14 – The IP address of your minikube instance changed in the keycloak-ingress
    file'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_014.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.14 – The IP address of your minikube instance changed in the keycloak-ingress
    file
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'Apply the modified file to the Kubernetes cluster. This `ingress` object will
    create the required configuration for you to access the Keycloak server from outside
    the Kubernetes cluster. Run the following command to create the ingress object:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'You should see the following response:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.15 – Modified ingress has been applied'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_015.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.15 – Modified ingress has been applied
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'Validate that the `ingress` object is available by issuing the following command:'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'You should see the following response:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.16 – Ingress object has been created'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_016.jpg)'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.16 – Ingress object has been created
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: 'Now that you have validated that Keycloak is running and is exposed through
    the `ingress` object, open a browser on your machine where `minikube` is running
    and access the following URL. You need to replace the correct IP address, as stated
    in s*tep 5*: https://keycloak.192.168.61.72.nip.io/auth/.'
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You will get a warning that the *certificate is not valid*. This is because
    the Keycloak server uses a self-signed certificate by default. You just need to
    click the **Advance** button presented by the browser and choose to continue to
    the website.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: 'You should see the following page; click on the **Administration Console**
    link to proceed further:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.17 – Keycloak landing page'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_017.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.17 – Keycloak landing page
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: 'Log in using the credentials *admin/admin* in the following screen. After you
    enter the credentials, click **Sign in**:'
  id: totrans-194
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.18 – Keycloak login page'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_018.jpg)'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.18 – Keycloak login page
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: 'Validate that the main administration page of Keycloak is displayed as follows:'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 4.19  – Keycloak administration page'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B18332_04_019.jpg)'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4.19 – Keycloak administration page
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You have successfully installed the ODH operator and Keycloak
    onto your Kubernetes cluster.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-203
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have learned about the major components of your ML platform
    and how open source community projects provide software products for each of those
    components. Using open source software enables a great number of people to use
    software for free, while at the same time, contributing to improving the components
    while continuously evolving and adding new capabilities to the software.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: You have installed the operator required to set up the ML platform on your Kubernetes
    cluster. You have installed the ingress controller to allow traffic into your
    cluster and installed Keycloak to provide the identity and access management capabilities
    for your platform.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: The foundation has been set for us to go deeper into each component of the ML
    life cycle. In the next chapter, you will learn to set up Spark and JupyterHub
    on your platform, which enables data engineers to build and deploy data pipelines.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Data preparation is the least enjoyable task in data science: [https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=1e5986216f63](https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/?sh=1e5986216f63)'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
