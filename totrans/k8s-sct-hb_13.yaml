- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Case Studies and Real-World Examples
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, we will see real-world examples of how Kubernetes Secrets
    are used in production environments. The chapter will cover case studies of production
    Secrets management in Kubernetes and lessons learned from real-world deployments.
    Additionally, you will learn about managing Secrets in CI/CD pipelines and integrating
    Secrets management into the CI/CD process. The chapter will also cover how to
    manage Secrets in pipelines using Kubernetes tools and the best practices to secure
    CI/CD Secrets management. We will expand on the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Real-world examples of how Kubernetes Secrets are used in production environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secrets management from a CI/CD perspective
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lessons learned from real-world deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing the Secrets’ lifecycle end to end in the Kubernetes production system
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To link theory with practice, we are leveraging a series of tools and platforms
    commonly used to interact with the Google Cloud API and Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**gcloud CLI**: This is a set of tools used to create and manage Google Cloud
    resources ([https://cloud.google.com/sdk/gcloud#download_and_install_the](https://cloud.google.com/sdk/gcloud#download_and_install_the))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kubectl**: This is the command-line tool used for communicating with a Kubernetes
    cluster through the Kubernetes API ([https://kubernetes.io/docs/reference/kubectl/](https://kubernetes.io/docs/reference/kubectl/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**minikube**: This is a local Kubernetes distribution used for Kubernetes learning
    and development. To install minikube on your system, you can follow the instructions
    from the official documentation ([https://minikube.sigs.k8s.io/docs/start/](https://minikube.sigs.k8s.io/docs/start/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`sealed-secrets` installation on Kubernetes ([https://github.com/bitnami-labs/sealed-secrets#kubeseal](https://github.com/bitnami-labs/sealed-secrets#kubeseal))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**argocd**: This is a command-line utility that simplifies interactions with
    Argo CD ([https://argo-cd.readthedocs.io/en/stable/cli_installation/](https://argo-cd.readthedocs.io/en/stable/cli_installation/))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Real-world examples of how Kubernetes Secrets are used in production environments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: So far, we have seen some different approaches to managing Kubernetes Secrets.
    We will proceed and see examples of how Secrets are managed in a production environment.
    We will compare some different approaches, identifying their differences and looking
    at the pros and cons.
  prefs: []
  type: TYPE_NORMAL
- en: Qualities of Secrets management in production
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When it comes to Kubernetes Secrets management in production, regardless of
    the approach taken, certain qualities need to be satisfied. These qualities make
    our production deployment robust and secure. The qualities are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: High availability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disaster recovery
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encryption
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Auditing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let us deep dive into each one of them.
  prefs: []
  type: TYPE_NORMAL
- en: High availability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Kubernetes is highly available; we saw how in [*Chapter 1*](B20970_01.xhtml#_idTextAnchor015),
    *Understanding Kubernetes Secrets Management*. A secret stored in Kubernetes will
    be stored on etcd, and etcd nodes are part of the Kubernetes cluster. If one etcd
    node goes down, the Secrets will still be present on the other etcd nodes. This
    ensures that Kubernetes will continue to operate with all the Secrets functioning.
    Eventually, once the missing etcd node is up, it will resume operations along
    with the other nodes. High availability ensures the robustness of Kubernetes in
    scenarios where a node is lost. Apart from the plain unavailability of a node,
    high availability should also tackle the risk of a data center going down. All
    the nodes of a Kubernetes cluster should not be hosted in the same data center;
    instead, the nodes of the cluster should be spread through different data centers.
    If connectivity to a data center is lost, or if a data center has an issue, the
    nodes hosted on the other data centers will be able to carry over. However, we
    might encounter more extreme scenarios, scenarios where instead of a node or a
    data center becoming unavailable, an entire region becomes disconnected. In those
    cases, being able to perform disaster recovery in another region is crucial.
  prefs: []
  type: TYPE_NORMAL
- en: Disaster recovery
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In [*Chapter 6*](B20970_06.xhtml#_idTextAnchor117), *Disaster Recovery and Backups*,
    we focused extensively on disaster recovery. When it comes to Secrets, it is crucial
    to have a disaster recovery plan in place. From a Secrets management perspective,
    the disaster recovery scenarios will vary on the decisions taken on managing Secrets.
    Secrets can be managed either on Kubernetes etcd or through external secret storage.
  prefs: []
  type: TYPE_NORMAL
- en: Secret storage using etcd
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The approach taken to implement disaster recovery on a Kubernetes cluster will
    heavily influence the disaster recovery of Secrets that are managed through etcd.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have the following options:'
  prefs: []
  type: TYPE_NORMAL
- en: Cluster created on demand in another region
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Standby Kubernetes cluster in another region
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Active-active Kubernetes clusters in multiple regions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The option of creating a cluster on demand in another region can be achieved
    with internal tooling such as keeping backups of etcd or by using tools such as
    Velero. In the case of a cloud provider, for example, GCP, you can duplicate a
    Kubernetes cluster with the click of a button.
  prefs: []
  type: TYPE_NORMAL
- en: In maintaining a standby cluster or active-active clusters, many of the choices
    are heavily dependent on how you perform deployments on Kubernetes. CI/CD is crucial.
    For example, for your standby cluster to be functional, your CI/CD job might need
    to push Secrets to two clusters. You might also follow the GitOps model. When
    it comes to the GitOps model, you might utilize a tool such as Argo CD. In those
    cases, the standby Kubernetes cluster can be updated by pulling the changes from
    a Git repository. This way, the Secrets are applied to the available clusters
    without the need to push the secret changes directly to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to Kubernetes and disaster recovery, there are various options,
    as we saw in [*Chapter 6*](B20970_06.xhtml#_idTextAnchor117), *Disaster Recovery*
    *and Backups*.
  prefs: []
  type: TYPE_NORMAL
- en: External secret store
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: With an external secret store, disaster recovery is managed by the secret store
    itself and its features. All the cloud-based Secrets store options we examined
    supported either cross-regional availability or the option for cross-region replication.
    Azure Vault and Google Cloud Secret Manager provide cross-region availability,
    and AWS Secrets Manager provides cross-region replication. In HashiCorp Vault
    Enterprise, there is also the option of cross-region replication.
  prefs: []
  type: TYPE_NORMAL
- en: Encryption
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Encryption is crucial. We had a deep dive into encryption in [*Chapter 3*](B20970_03.xhtml#_idTextAnchor064),
    *Encrypting Secrets the Kubernetes-Native Way*. On every Kubernetes installation,
    it is crucial to follow encryption at rest, considering disk storage as well as
    the encryption of etcd Secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Auditing
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We have seen in [*Chapter 5*](B20970_05.xhtml#_idTextAnchor092), *Security,
    Auditing, and Compliance*, why auditing matters and why it is needed in the first
    place. On every cloud provider we have worked with, the option of auditing was
    always present. Auditing is also available on HashiCorp Vault and CyberArk Conjur.
  prefs: []
  type: TYPE_NORMAL
- en: We focused on and had an overview of the qualities that need to be in place
    when it comes to Secrets management in production. Next, we shall focus on how
    Secrets management and CI/CD come together and the risks to avoid.
  prefs: []
  type: TYPE_NORMAL
- en: Secrets management from a CI/CD perspective
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Managing Secrets in CI/CD pipelines is an interesting concept. In previous
    chapters, we focused primarily on the Git-based concept of Secrets management
    and the secret-storage-based Secrets management. We have not mentioned manual
    secret persistence to Kubernetes. There are many reasons for that:'
  prefs: []
  type: TYPE_NORMAL
- en: You lose track of your Kubernetes deployment needs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dependencies are not visible
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: No clear depiction of what is applied
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Not compatible with infrastructure as code
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, we will focus on interacting with Secrets on our CI/CD pipelines.
  prefs: []
  type: TYPE_NORMAL
- en: Integrating Secrets management into your CI/CD process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Your CI/CD strategy will differ significantly depending on the approach taken
    for managing Secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Git-based Secrets management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By managing Secrets through a Git-based approach, CI/CD should be able to interact
    with the components involved.
  prefs: []
  type: TYPE_NORMAL
- en: Depending on the encryption mechanism, you need to have credentials configured
    on the CI/CD account that will be able to interact with the KMS system that encrypts
    the credentials or a Kubernetes service account that can decrypt the Secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Let us examine the case of sealed Secrets, a concept we learned about in [*Chapter
    12*](B20970_12.xhtml#_idTextAnchor234), *Integrating with Secret Stores*, where
    a fine-grained Kubernetes role and a Kubernetes service account should be created.
    The reason is that the sealing operation happens inside the cluster. The sealed
    secret can then be stored on Git. To retrieve the actual value, you need to decrypt
    it through the cluster. The sealing operation can also happen offline; in this
    case, more steps are needed to make sure that the encryption key is securely handled.
  prefs: []
  type: TYPE_NORMAL
- en: External secret store and Workload Identity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, we have worked with Microsoft Azure Key Vault, Google Cloud Secret Manager,
    and AWS Secrets Manager. All of them support the integration of Workload Identity
    and GitHub Actions.
  prefs: []
  type: TYPE_NORMAL
- en: The traditional way to interact with a cloud component on a CI/CD pipeline was
    by attaching the credentials of the cloud provider on the CI/CD job. This practice
    increases security risks. The credentials, such as a service account or a key
    secret, are static credentials; if compromised and without a proper logging or
    audit system, these could be used for an extended period, creating a silent breach.
  prefs: []
  type: TYPE_NORMAL
- en: Workload Identity is a more secure solution. With Workload Identity, we can
    assign to a CI/CD job fine-grained permissions toward a cloud component. Workload
    Identity is not supported by all CI/CD providers out there; however, there is
    a strong adoption of the Workload Identity approach and it is expected to become
    the norm.
  prefs: []
  type: TYPE_NORMAL
- en: By using Workload Identity, a CI/CD job can have temporary credentials to interact
    with a cloud provider’s secret store. Since we have now had an introduction to
    Workload Identity, we will proceed and see it in action using GCP.
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Actions and GCP Workload Identity integration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the issues with CI/CD jobs interacting with cloud components is the permissions.
    Traditionally, this is resolved by uploading credentials to the CI/CD job variables
    with all the risks this solution can introduce, which we will cover later in this
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: GitHub Action supports **OpenID Connect** (**OIDC**). Through OIDC, it is possible
    to authenticate between cloud providers and GitHub, using short-lived tokens.
    This way, we avoid the need for storing long-lived cloud Secrets in GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 10*](B20970_10.xhtml#_idTextAnchor193), *Exploring Cloud Secret
    Store on GCP*, we integrated a GKE cluster with GCP’s Secret Manager, so we are
    already familiar with GCP as a platform. Imagine the scenario of our CI/CD jobs
    needing to interact with Secret Manager, which is integrated with GKE.
  prefs: []
  type: TYPE_NORMAL
- en: Without the support of OIDC, we would have to store a GCP service account key
    to the CI/CD job. Thanks to OIDC, we can set up the authentication from GitHub
    to GCP using Workload Identity Federation.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we will have to configure an identity pool:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we include GitHub as an identity provider:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The identity pool is provisioned, and GitHub is one of the identity providers.
    The next step is to bind a service account on GCP to a GitHub repository:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Through this configuration, we allow authentications from the Workload Identity
    provider to impersonate the desired service account. Also, note that when we specified
    the Workload Identity pool as a member, we specified the GitHub repository where
    we shall host the actions that would require GCP access.
  prefs: []
  type: TYPE_NORMAL
- en: 'We are set up to proceed with the GitHub job configuration:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: On the GitHub Actions console, we should be able to see the job successfully
    creating a token and authenticate upon the Workload Identity instance created,
    as well as receiving a secret from Secret Manager. Obviously, this way of authentication
    can be applied even when we want to interact with GCP.
  prefs: []
  type: TYPE_NORMAL
- en: Take note that the preceding steps print the secret on purpose since they serve
    as an example of how GitHub Actions and GCP Workload Identity integrate. You should
    not print any retrieved Secrets on the CI/CD console, as we shall mention later
    in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: In a nutshell, by utilizing Workload Identity, we can avoid storing long-lived
    credentials in a CI/CD job configuration. Also, we establish seamless integration
    with the cloud provider and make it easier to interact with cloud provider components
    such as Secret Manager on GCP.
  prefs: []
  type: TYPE_NORMAL
- en: Vault as an external secret store
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we have seen from the integration of Vault with Kubernetes, a token is needed
    to be able to interact with Vault. When we use a long-lived token, we face the
    risk of compromise. For this reason, instead of using a Vault token directly,
    we can proceed with the method of JWT with GitHub OIDC tokens.
  prefs: []
  type: TYPE_NORMAL
- en: Each GitHub action receives an auto-generated OIDC token. We can configure trust
    between a GitHub Actions workflow and Vault using the OIDC provider of GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: A similar concept was Kubernetes authentication. We were taking the JWTs, originating
    from a Kubernetes service account, and using them to retrieve Secrets from Vault.
    Since Vault had already established trust with our Kubernetes cluster, it could
    validate the Secrets and return the credentials.
  prefs: []
  type: TYPE_NORMAL
- en: A similar process happens with the GitHub OIDC provider and the HashiCorp integration.
  prefs: []
  type: TYPE_NORMAL
- en: Executing CI/CD pipelines on Kubernetes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another way to securely integrate CI/CD pipelines with a Kubernetes secret store
    is to run the pipeline inside Kubernetes. The CI/CD jobs run inside Kubernetes,
    so the credentials and other Kubernetes components are not exposed outside of
    our premises.
  prefs: []
  type: TYPE_NORMAL
- en: Many major cloud providers, such as GitHub Actions and GitLab, provide the option
    to manage CI/CD pipeline orchestration on GitHub and GitLab but execute the CI/CD
    jobs inside Kubernetes. There are numerous benefits to that approach.
  prefs: []
  type: TYPE_NORMAL
- en: By running a CI/CD job on-premises, you make it possible for the CI/CD job to
    interact with resources that reside only on-premises. For example, supposing a
    HashiCorp Vault installation is in a private network that is not publicly accessible.
    To integrate the Vault instance with an external CI/CD provider, we must make
    the Vault instance publicly accessible, which increases our security concerns.
  prefs: []
  type: TYPE_NORMAL
- en: By running a pipeline on-premises, that is not the case. Running CI/CD pipelines
    inside Kubernetes can harden the security of our CI/CD pipelines. Tekton is a
    very popular open source framework that enables us to create CI/CD systems in
    a Kubernetes installation.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on, there is another approach to continuous delivery, which is through
    the GitOps model. Let us see how the GitOps model works by running an example
    with Argo CD.
  prefs: []
  type: TYPE_NORMAL
- en: GitOps
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: GitOps is a set of practices that is used to manage infrastructure and application
    configurations via a Git-centric approach. Argo CD follows the GitOps model. It
    monitors a Git repository that we specify and ensures that the application is
    in the desired state. Argo CD is a Kubernetes controller that monitors the running
    infrastructure and compares it with the infrastructure specified in the Git repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can understand the model by doing a simple Argo CD installation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now port forward so that we can interact with Argo CD without the need
    to expose the service through an ingress:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'In another session, we can retrieve the default admin autogenerated password,
    in order to log in to `argocd`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'We can now create an application; we shall use the examples in the Argo CD
    repository ([https://github.com/argoproj/argocd-example-apps](https://github.com/argoproj/argocd-example-apps)):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: An application is now running based on a deployment file in another Git repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us examine GitOps and its compatibility with the Secrets management methods
    we have seen so far:'
  prefs: []
  type: TYPE_NORMAL
- en: Sealed Secrets can be supported without extra effort since the sealed Secrets
    controller will be able to apply any new Secrets distributed through Git.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solutions driven by external secret storage are not affected since the secret
    information resides on another component.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Helm Secrets support depends on the tool used for GitOps. Argo CD can support
    Helm Secrets; however, it requires modifications to facilitate the encryption
    and decryption of Secrets that are distributed through Helm charts.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have had an overview of Secrets management and CI/CD, let us proceed
    with the risks that come with the integration of CI/CD and Secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Risks to avoid with Secrets in CI/CD pipelines
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A CI/CD pipeline can be subject to various risks when it comes to Secrets. It
    is quite easy to misconfigure a CI/CD pipeline, which can lead to problems such
    as leaking sensitive information, running overprivileged pipelines, and supply
    chain attacks.
  prefs: []
  type: TYPE_NORMAL
- en: Leaking Secrets in a pipeline
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Leaking Secrets in a pipeline is easier to accidentally do than you’d think.
    CI/CD pipelines by default treat secret information differently from other configuration
    variables. Take, for example, a GitHub Actions workflow. If we try to print a
    secret in a job, the secret will be masked, and thus the information will not
    be leaked. This is not enough. By changing the pipeline’s configuration, we can
    persist the secret value in a file. This makes it possible to print the file and
    retrieve the secret information. To make matters worse, CI/CD pipelines keep the
    job history and logs. In certain cases, the history cannot be erased or will be
    erased after some time.
  prefs: []
  type: TYPE_NORMAL
- en: Another way that a secret can be leaked is by making it part of the artifacts
    generated by the CI/CD pipeline. In this situation, the Secrets can be downloaded
    through the CI/CD UI.
  prefs: []
  type: TYPE_NORMAL
- en: These examples of misconfigured pipelines can lead to security incidents. The
    secret information has been leaked and so it needs to be rotated.
  prefs: []
  type: TYPE_NORMAL
- en: Production Secrets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another risk is using the same Secrets used in a production workload with a
    CI/CD pipeline. A secret in a production environment is used to perform different
    operations from the ones that take place in a CI/CD environment. Having a production
    secret on a CI/CD environment can lead to code that might run with more privileges
    than the ones needed if the CI/CD is misconfigured, and its usage might affect
    an actual production system. In the case of a secret leak, the risk impact is
    much greater when using a dedicated secret for a CI/CD job.
  prefs: []
  type: TYPE_NORMAL
- en: Malevolent contributions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CI/CD can be a target for attackers trying to steal Secrets. A pull request
    on a repository that triggers a pipeline gives a variety of options for the pull
    request author to retrieve the secret value. For these cases, it is essential
    to protect the CI/CD jobs that interact with sensitive information. Branches should
    be protected, and certain pipelines should be segregated to enable fine-grained
    permissions and prevent access from individuals who might try to retrieve secret
    information through CI/CD jobs.
  prefs: []
  type: TYPE_NORMAL
- en: In open source projects, contributions might have the purpose of stealing Secrets
    or being part of a supply chain attack attempt. We can use GitHub Actions as an
    example, where workflows from forks do not have access to Secrets. Also, to prevent
    any abusive behavior on pull requests, GitHub Actions gives the option to approve
    workflow runs from public forks ([https://docs.github.com/en/actions/managing-workflow-runs/approving-workflow-runs-from-public-forks](https://docs.github.com/en/actions/managing-workflow-runs/approving-workflow-runs-from-public-forks)).
  prefs: []
  type: TYPE_NORMAL
- en: Untrusted software
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A pipeline can be as secure as the software that is used to implement it. Throughout
    the internet, there is a wide variety of CI/CD software utilities, ranging from
    libraries to Docker containers. These software components can be outdated, exposing
    the pipeline to security vulnerabilities, or some of them might have been compromised
    by an attacker with the goal of a supply chain attack.
  prefs: []
  type: TYPE_NORMAL
- en: Take, for example, a Jenkins plugin or a GitHub workflow action that reads the
    Secrets from a pipeline and sends them to an external location. The same can happen
    with any utility that is not trusted or has even been compromised.
  prefs: []
  type: TYPE_NORMAL
- en: Software should be used only from trusted sources, and its authenticity should
    be verified, for example, using hash-based verification. Also, the software used
    in the pipelines should be the latest software that incorporates the necessary
    security patches.
  prefs: []
  type: TYPE_NORMAL
- en: Pipelines with extra privileges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CI/CD is essential for every company that needs to build, test, and release
    software. Since it has a crucial role, it is expected to interact with Secrets
    that might be shared by a Kubernetes installation. Secrets privileges that exceed
    the scope of a CI/CD job can cause serious incidents in the case of a leak or
    misconfiguration.
  prefs: []
  type: TYPE_NORMAL
- en: Take, for example, a CI/CD job used for testing purposes interacting with an
    external secret storage used by a Kubernetes cluster. Suppose this job deletes
    Secrets from the secret storage, targeting a staging environment. However, the
    permissions assigned to the pipeline are broad enough to enable the deletion of
    Secrets in a production environment. A pipeline misconfiguration can lead to data
    loss or even a production outage.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have had an overview of the risks associated with Secrets and CI/CD
    integration, let us proceed with identifying the best practices.
  prefs: []
  type: TYPE_NORMAL
- en: Best practices for secure CI/CD Secrets management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We had an overview of CI/CD jobs interacting with Kubernetes Secrets. To ensure
    that we are secure, we need to follow certain practices:'
  prefs: []
  type: TYPE_NORMAL
- en: Do not commit clear text Secrets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If using tokens, rotate them and make them short-lived
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If an OICD-based integration is possible, use it, as it is more secure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moving pipelines to Kubernetes on-premises hardens security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The principle of least privilege should be followed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use dedicated Secrets for testing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not use the same Secrets for testing and production
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So far, we have focused on the ways to handle Kubernetes Secrets in production
    and the integration of Kubernetes Secrets and CI/CD. Next, we will focus on a
    case study for implementing a Secrets system within an organization.
  prefs: []
  type: TYPE_NORMAL
- en: Lessons learned from real-world deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Let us now look at how we can interact with Secrets on Kubernetes and what we
    should and should not do when we interact with Secrets on Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Case study – Developing Secrets management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As more organizations embrace container orchestration, the following case study
    illustrates the journey toward establishing a robust system for Secrets management
    within an organization.
  prefs: []
  type: TYPE_NORMAL
- en: The Keywhiz Secrets management system at Square
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Keywhiz is a system that Square developed to keep important digital keys and
    passwords, such as those used to secure websites, safe and in one place. This
    system is beneficial as the organization previously lacked secure methods for
    storing these Secrets. Keywhiz makes sure that only the right parts of Square
    can get to these Secrets when they need to, using secure connections.
  prefs: []
  type: TYPE_NORMAL
- en: Deep dive into Keywhiz’s secret system
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let us dive deep into Keywhiz to see how Square built the system end to end.
  prefs: []
  type: TYPE_NORMAL
- en: Business justification
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Square built Keywhiz with the idea that important Secrets should be hard to
    reach. They shouldn’t pop up in places where just anyone can see them, such as
    on a developer’s computer or the internet. Only the specific parts of Square that
    need these Secrets should be able to get them. This is especially true for services
    that use secure connections to protect data. Instead of using many steps or other
    services to get to these Secrets, Square’s services can get them directly. Even
    for special cases, such as when they need to use extra secure hardware, Keywhiz
    has a way to handle it.
  prefs: []
  type: TYPE_NORMAL
- en: Keywhiz also focuses on not having too many Secrets scattered around, which
    can be risky. By keeping them all in one system, it’s easier to keep track of
    them and make sure they are safe. Plus, this system lets Square check on the health
    of their digital keys and passwords, for instance, to see whether they are strong
    enough or need to be changed soon.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important for Square to know when and how a secret is used. So, Keywhiz
    keeps a detailed record of every time a secret is accessed. This isn’t something
    you can do if you just drop the Secrets onto servers as files. Although there
    are tools that can help keep an eye on this, they require extra work to set up.
  prefs: []
  type: TYPE_NORMAL
- en: Keywhiz is made to work with a lot of different services at Square. It has been
    set up to handle a wide range of needs, from securing websites to handling databases.
  prefs: []
  type: TYPE_NORMAL
- en: The reliability of this system is key. It has to work all the time because Square’s
    services rely on these Secrets to run.
  prefs: []
  type: TYPE_NORMAL
- en: The system is also designed to be easy to use. If it wasn’t, people might try
    to take shortcuts, which could be less safe.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, Keywhiz separates the process of changing keys from updating software.
    This means that Square can update its security without having to change the whole
    system, which makes things safer and more flexible.
  prefs: []
  type: TYPE_NORMAL
- en: Categorizing and centralizing the store Secrets
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Square’s Keywhiz system takes the security of its digital Secrets seriously.
    It begins by organizing these Secrets into clear categories. This isn’t just about
    keeping things tidy—it’s about knowing exactly which part of Square’s system needs
    which Secrets to operate. From there, all Secrets are kept in one central place.
    This means they’re not scattered across different spots where they could be forgotten
    or, worse, fall into the wrong hands.
  prefs: []
  type: TYPE_NORMAL
- en: But what makes Keywhiz stand out is how it locks up these Secrets. Before a
    secret is saved in Square’s databases, it gets wrapped up in a layer of encryption—like
    putting a letter into a safe that only certain people can open. This involves
    a specific type of encryption known as **AES-GCM** ([https://en.wikipedia.org/wiki/Galois/Counter_Mode](https://en.wikipedia.org/wiki/Galois/Counter_Mode)).
    It’s recommended by the **National Institute of Standards and Technology** (**NIST**)
    in their Special Publication 800-38D as a preferred method for block cipher ([https://en.wikipedia.org/wiki/Block_cipher](https://en.wikipedia.org/wiki/Block_cipher))
    modes of operation, focusing on **Galois/Counter Mode** (**GCM**) and **Galois
    Message Authentication Code** (**GMAC**). Each secret gets its own unique encryption
    key, created using a method known as **HKDF** ([https://en.wikipedia.org/wiki/HKDF](https://en.wikipedia.org/wiki/HKDF)),
    a simple **key derivation function** (**KDF**) based on the HMAC message authentication
    code, which is a way to make sure that even if one key is discovered, the others
    remain safe. Square uses hardware security modules to contain derivation keys.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, when it comes to delivering these Secrets, Keywhiz makes sure that only
    the right parts of Square’s system, which they call *clients*, can get to them.
    The structure of access control revolves around three key elements: clients, groups,
    and Secrets. A “client” refers to any certificate that gains access to Secrets.
    These clients can belong to multiple groups, which are collections of clients.
    For a client to access a particular secret, the secret must be associated with
    at least one of the groups to which the client belongs. Typically, Keywhiz organizes
    this by creating three main types of groups: one for each service on a specific
    server, one for each distinct service, and a universal group that includes all
    clients.'
  prefs: []
  type: TYPE_NORMAL
- en: Before, people tried other ways to keep Secrets safe, such as mixing them into
    the code where programs are written or manually adding them to servers. But these
    ways are risky—the Secrets can accidentally get shared with the world or get lost.
    Even trying to keep Secrets safe using systems that manage server settings isn’t
    ideal because those systems are meant to share their information across the company,
    which is not what you want for your Secrets.
  prefs: []
  type: TYPE_NORMAL
- en: PKI as a source of the truth for authentication
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '**Public key infrastructure** (**PKI**) is central to Square’s authentication
    process. It’s like a verification system that ensures that only the right parts
    of Square’s network can access the Secrets they need. To establish this trust,
    Square uses mTLS and X509 certificates, which are digital proofs of identity for
    services. Square simplifies this task with **certstrap**, a straightforward certificate
    management tool. This tool helps Square create its own certificate authorities,
    which you can think of as digital ID offices. With certstrap, Square can issue
    these digital IDs to its services, ensuring each one is recognized and trusted
    within its network.'
  prefs: []
  type: TYPE_NORMAL
- en: certstrap allows Square to avoid the complexities of traditional tools such
    as OpenSSL. It enables Square to create a chain of trust where each service’s
    identity is verified and secured. This verification is crucial for Square, as
    it keeps communication between services secure, ensuring that Secrets are only
    accessed by authorized entities within the company.
  prefs: []
  type: TYPE_NORMAL
- en: Authorization data model
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In Square’s Keywhiz system, authorization—deciding who gets access to what—is
    a structured process. Here’s how Square has set it up:'
  prefs: []
  type: TYPE_NORMAL
- en: Clients are parts of Square’s systems, such as a service or an application,
    that need access to Secrets to work properly. They prove who they are with something
    called a client certificate. It’s like an ID card for systems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Secrets are the sensitive bits of information that clients need to do their
    jobs, such as configuration files or passwords. Each secret has a unique name
    so there are no mixups, and they can’t be changed once they’re set. However, Square
    can keep multiple versions of a secret if updates are needed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Groups act as a meeting point for clients and Secrets. Think of groups as tags
    or labels. Square labels the clients and the Secrets with these group tags. When
    a client and a secret have the same group tag, the client can see and use the
    secret. It’s Square’s way of organizing which parts of their system can access
    which Secrets.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Users are the people who manage Keywhiz at Square. They’re the ones setting
    up the system and deciding which clients and Secrets get which group tags. They
    log in to Keywhiz with secure methods, and after they’re in, they need a special
    code from Keywhiz to keep doing their work securely.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Square’s Keywhiz manages access through a structured authorization model of
    clients, Secrets, groups, and user management, maintaining secure and orderly
    permissions.
  prefs: []
  type: TYPE_NORMAL
- en: Secrets distribution
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Square also maintains a Keywhiz client implementation called **Keysync**. Keysync
    is a program that connects to Square’s Keywhiz server securely and asks for the
    Secrets it needs to keep Square’s services running. It uses something called **mTLS**—a
    way of communicating securely—to make sure everything is safe and private.
  prefs: []
  type: TYPE_NORMAL
- en: Once Keysync gets these Secrets, it keeps them in a secure area of the server’s
    memory called **tmpfs**. This is a temporary space that doesn’t save anything
    once the server is turned off. So, if there’s a power cut or the server has to
    be restarted, those Secrets don’t get left behind where they could be seen by
    others.
  prefs: []
  type: TYPE_NORMAL
- en: The neat thing about Keysync is that it’s built to handle unexpected problems.
    If there’s an issue with the Keywhiz server, Keysync will still have the Secrets
    it previously downloaded, so Square’s services can keep working without interruption.
    It’s only after a full server reboot that Keysync needs to get all the Secrets
    again.
  prefs: []
  type: TYPE_NORMAL
- en: To handle these Secrets, Square’s administrators have an admin CLI that allows
    them to type commands directly into the system to add, remove, or change Secrets
    as needed. It’s a straightforward way for them to keep everything up to date and
    to check on the health of the Secrets management system without having to navigate
    through complicated interfaces.
  prefs: []
  type: TYPE_NORMAL
- en: Keysync, the CLI for Square’s Keywhiz interface, ensures the secure and confidential
    delivery of Secrets across different scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Challenges and lessons of Keywhiz from a third-party view
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Given that Keywhiz was deprecated on September 18, 2023, and is no longer maintained,
    reflecting on the challenges and lessons it presented during its service is insightful.
    The recommendation to transition to HashiCorp Vault highlights the need for robust
    and actively supported Secrets management solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Centralized management with Kubernetes cases is hard
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the core challenges Keywhiz faces in Kubernetes Secrets management is
    the inherent complexity of centralized management in a highly distributed and
    dynamic environment such as Kubernetes. Kubernetes environments often require
    a more flexible and decentralized approach to Secrets management. Although Keywhiz
    offers centralized control and strong encryption for Secrets, it may not be optimally
    configured for the decentralized and ephemeral nature of Kubernetes workloads.
  prefs: []
  type: TYPE_NORMAL
- en: For example, in Kubernetes, it’s essential to have a Secrets management solution
    that can handle the dynamic creation and deletion of Secrets, in line with the
    ephemeral nature of Kubernetes Pods and Services. Secrets management in Kubernetes
    also requires tight integration with Kubernetes’ **role-based access control**
    (**RBAC**) and the ability to manage Secrets across multiple clusters and namespaces
    efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: While Keywhiz excels at centralized Secrets management, providing strong encryption
    and a secure way to distribute Secrets to various services and platforms, adapting
    these capabilities to the specifics of Kubernetes can be challenging. Kubernetes
    environments often benefit from tools such as HashiCorp Vault, which offers extensive
    Kubernetes integration, including dynamic Secrets, integration with Kubernetes
    service accounts for authentication, and the ability to define fine-grained access
    control policies for Secrets.
  prefs: []
  type: TYPE_NORMAL
- en: A Secrets management system is not just one system but a whole ecosystem
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Keywhiz’s role in an organization’s ecosystem extends beyond its function as
    a standalone Secrets management tool. Its effectiveness relies heavily on its
    integration with the company’s existing workflows, policies, and organizational
    culture. This scenario illustrates that the efficacy of a Secrets management system
    is not determined solely by its technical capabilities but by how well it aligns
    with and supports the broader operational context of the organization.
  prefs: []
  type: TYPE_NORMAL
- en: For instance, consider a healthcare organization that adopts Keywhiz to manage
    sensitive data, such as patient records and login credentials for internal systems.
    In this setting, while Keywhiz serves as the repository for these Secrets, its
    utility is dependent on seamless integration with the organization’s existing
    healthcare information systems. This integration could involve syncing with employee
    directory services to manage access based on roles and departments. It would also
    entail aligning with healthcare compliance standards, where Keywhiz’s audit trails
    and encryption capabilities become critical in meeting regulatory requirements.
    In this way, Keywhiz becomes an integral part of the organization’s overall data
    security framework, influencing and being influenced by various factors beyond
    the immediate scope of secret storage.
  prefs: []
  type: TYPE_NORMAL
- en: Lack of auditing as a story
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A notable limitation of Keywhiz is its approach to auditing, especially considering
    how it handles secret distribution. Keysync works as a client where Secrets are
    downloaded as `tmpfs` files, which are then used by applications. However, this
    model does not inherently provide detailed auditing data for each action taken
    on these Secrets, and specifically, it lacks visibility into whether applications
    are actively using the downloaded Secrets, as this interaction occurs client-side
    and is not directly observable by the Keywhiz server.
  prefs: []
  type: TYPE_NORMAL
- en: 'This leads to potential gaps in the auditing process, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Identifying the specific user or service that accessed a secret
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recording the precise timestamp of each access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding the nature of the access, such as whether the secret was read,
    modified, and so on
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Detecting the IP address or machine from which the secret was accessed
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Keysync process does not reflect the real-time requirements for Secrets
    associated with applications, leading to challenges in maintaining a continuous
    and comprehensive audit trail. This gap can impact the ability to fully document
    the lifecycle of secret access within an organization, making it difficult to
    trace all interactions with sensitive data.
  prefs: []
  type: TYPE_NORMAL
- en: Managing the Secrets lifecycle from end to end in a Kubernetes production cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous chapter covered a broad range of topics, but there was a noticeable
    disconnect between the concepts discussed and practical examples for managing
    Secrets in a production environment. In this section, we will narrow our focus
    and delve into the end-to-end management of Secrets within a Kubernetes production
    cluster, offering a more practical, application-oriented perspective.
  prefs: []
  type: TYPE_NORMAL
- en: In exploring the management of Secrets in such an environment, we recognize
    that the process involves more than just secure storage. We shift our focus from
    mere storage repositories to a comprehensive view of Secrets usage throughout
    the system’s lifecycle. Secrets are integral to operational processes, embedded
    in the workflows that drive an organization’s digital operations.
  prefs: []
  type: TYPE_NORMAL
- en: The challenge lies in effectively managing the entire lifecycle of Secrets,
    from inception to decommissioning, with a rigorous emphasis on precision and security.
    This comprehensive approach is essential for organizations committed to high security
    and operational standards. Managing Secrets effectively is about understanding
    their generation, distribution, revocation, and decommissioning within the dynamic
    Kubernetes ecosystem. This section will guide you through the nuanced and vital
    role of Secrets management in maintaining a secure and efficient digital infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Finalizing your decision on comprehensive Secrets lifecycle management
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When it comes to managing Secrets in a Kubernetes production environment, adopting
    a holistic and comprehensive approach is paramount. Secrets lifecycle management
    extends far beyond the mere aspect of secure storage, encompassing a range of
    critical processes from the initial provisioning to the final decommissioning
    and revocation.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning involves the creation or generation of Secrets in a secure and
    controlled manner, ensuring that they are strong and unique and that they comply
    with organizational security policies. The storage phase requires a robust and
    secure repository, such as HashiCorp Vault or cloud Secrets stores, ensuring that
    Secrets are encrypted at rest and protected from unauthorized access. Distribution
    is a delicate operation, where Secrets must be securely transmitted to the required
    services or applications, ensuring integrity and confidentiality throughout transit.
  prefs: []
  type: TYPE_NORMAL
- en: Decommissioning comes into play when Secrets are no longer required, necessitating
    a secure process to retire them, ensuring that they cannot be reused or exploited.
    Finally, revocation is a critical step in the lifecycle, particularly in instances
    of compromise or when a secret’s integrity is in doubt. A swift and efficient
    revocation mechanism ensures that access is immediately cut off, mitigating potential
    damage.
  prefs: []
  type: TYPE_NORMAL
- en: Embracing a comprehensive Secrets lifecycle management approach ensures that
    Secrets are not just securely stored but are also properly managed throughout
    their entire lifecycle. This end-to-end perspective is not just a best practice
    but an organizational necessity to ensure the integrity of the Secrets and, by
    extension, the entire production system. As we delve deeper into each of these
    aspects in the subsequent sections, the overarching importance of a holistic approach
    to Secrets management in Kubernetes will become increasingly clear, highlighting
    its role as a critical component in the broader security and operational landscape
    of the organization.
  prefs: []
  type: TYPE_NORMAL
- en: High SLAs as the key to business sustainability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Maintaining high **service-level agreements** (**SLAs**) is vital for Secrets
    management within Kubernetes environments, emphasizing system reliability and
    availability as foundational aspects of business sustainability. This is particularly
    important in production environments where downtime or security breaches could
    have significant financial and operational implications.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this high level of reliability, businesses need to implement strong
    monitoring and alerting systems. Regular stress testing of the Secrets management
    system is also essential to identify and address potential vulnerabilities, ensuring
    the system can handle various operational stresses and maintain its SLA commitments.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of cloud Secrets storage, providers typically offer committed
    SLAs that meet the requirements of most use cases. However, for self-deployed
    Secrets management systems, different approaches are necessary to evaluate and
    ensure SLAs, especially when secret retrieval is critical for system infrastructure
    and platform usage.
  prefs: []
  type: TYPE_NORMAL
- en: One strategy to ensure high SLAs is the active-active replication model used
    by solutions such as HashiCorp Vault. This model provides continuous synchronization
    across multiple active systems, enhancing fault tolerance and availability. However,
    it’s not the only approach.
  prefs: []
  type: TYPE_NORMAL
- en: Alternative methods, such as using a secure Redis configuration for buffered
    Secrets, can offer temporary availability (e.g., for a few hours) and enhance
    platform reliability. In this scenario, Secrets are stored as encrypted ciphertext
    in Redis, which acts as a temporary buffer. This method not only secures the Secrets
    but also provides an additional layer of reliability, ensuring that Secrets are
    available during critical periods or in the event of primary system failures.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the approach to maintaining high SLAs in Secrets management should
    be tailored to the specific needs and architecture of the Kubernetes environment.
  prefs: []
  type: TYPE_NORMAL
- en: Emergency recovery – backup and restore
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Kubernetes production clusters, crafting an effective emergency recovery
    plan for Secrets management is essential. A robust recovery plan is key to quickly
    restoring operations in the event of data losses, system failures, or security
    incidents, thereby minimizing downtime. This proactive approach ensures that the
    Secrets management system can swiftly recover from unexpected disruptions, thus
    maintaining the continuity of the production environment.
  prefs: []
  type: TYPE_NORMAL
- en: Regular backups play a critical role in safeguarding the integrity and availability
    of Secrets and configurations. These backups form the foundation for a reliable
    recovery mechanism, ensuring that there’s a dependable process for retrieving
    sensitive information and configurations following unforeseen data loss, hardware
    failures, or security breaches.
  prefs: []
  type: TYPE_NORMAL
- en: For further details and insights on this topic, you may refer to [*Chapter 6*](B20970_06.xhtml#_idTextAnchor117),
    *Disaster Recovery* *and Backups*.
  prefs: []
  type: TYPE_NORMAL
- en: Not just storing but provisioning Secrets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Provisioning and storing Secrets are critical steps in managing Secrets within
    a Kubernetes environment, acting as the initial point of entry and a significant
    opportunity to enforce secure usage models. By controlling the origin of Secrets
    and clearly defining their target resources, organizations can establish a robust
    framework for long-term Secrets management.
  prefs: []
  type: TYPE_NORMAL
- en: When provisioning Secrets, it’s imperative to ensure transparency and traceability.
    Enforcing a clear and standardized process for secret creation helps in tracking
    where Secrets come from, their intended purpose, and their targeted resources.
    This practice aids in maintaining an organized Secrets inventory, making it simpler
    to manage and audit over time.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of storing Secrets securely in Kubernetes, adopting best practices
    such as encryption at rest and in transit, using dedicated service accounts, and
    implementing role-based access controls is essential. Organizations should leverage
    Kubernetes’ native capabilities, such as Namespaces and NetworkPolicies, to provide
    additional layers of isolation and protection.
  prefs: []
  type: TYPE_NORMAL
- en: A key aspect of ensuring long-term success in Secrets management is to enforce
    the use of specific secret types. Kubernetes supports various secret types, each
    tailored to specific use cases. By mandating the use of these types, organizations
    can benefit from Kubernetes’ built-in validation mechanisms, ensuring that Secrets
    conform to the expected structure and reducing the risk of misconfigurations.
    For instance, enforcing a secret type of `kubernetes.io/dockerconfigjson` for
    storing Docker registry credentials ensures that the secret’s content adheres
    to the expected format, reducing the risk of runtime errors.
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, utilizing specific secret types aids in creating a self-descriptive
    and more manageable environment. Developers and administrators can easily understand
    the purpose and usage of a secret based on its type, enhancing overall clarity
    and reducing the potential for mistakes. This practice also simplifies auditing
    and compliance processes, as it becomes straightforward to track and report on
    the usage of different types of Secrets across the Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Incorporating these practices into the provisioning and storage phases of Secrets
    management sets a solid foundation for secure and efficient secret handling. It
    ensures that Secrets are created, stored, and used in a manner that aligns with
    security best practices, providing a significant return on investment in terms
    of security, compliance, and manageability. By enforcing clear standards and utilizing
    Kubernetes’ native capabilities, organizations can create a robust and resilient
    Secrets management environment, ready to support their applications securely and
    efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: Secrets rotation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The rotation of Secrets stands as a crucial practice in maintaining a secure
    Kubernetes environment, primarily due to the inherent security implications tied
    to static, long-lived credentials. Secrets, once compromised, can serve as gateways
    for malicious entities, leading to unauthorized access and potential data breaches.
    To mitigate such risks, implementing the periodic rotation of Secrets is necessary,
    ensuring that even if a secret were to be compromised, its lifespan would be limited,
    thereby reducing the potential damage inflicted.
  prefs: []
  type: TYPE_NORMAL
- en: However, the task of rotating Secrets is not without its challenges, especially
    when dealing with a large number of Secrets distributed across various services.
    This is where automation steps in, offering a streamlined and efficient solution.
    By leveraging automated systems, organizations can ensure timely rotations, aligning
    with best practices and compliance requirements. These systems work by periodically
    updating Secrets and credentials, distributing the updated versions to the respective
    services, and ensuring the outdated Secrets are retired securely.
  prefs: []
  type: TYPE_NORMAL
- en: It is crucial to note that while automation plays a significant role in Secrets
    rotation, there may be exceptional cases where certain Secrets are exempt from
    rotation due to technical constraints or specific use cases. In these situations,
    it is imperative to maintain transparency and clear documentation, marking these
    Secrets accordingly to ensure visibility. Despite the exemption, a robust incident
    response plan must be in place, guaranteeing that if a security incident were
    to occur, these exempted Secrets could be rotated in a timely manner, mitigating
    potential risks and securing the environment. This comprehensive approach to Secrets
    rotation ensures not only the security of the Secrets themselves but also the
    resilience and integrity of the entire Kubernetes ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: Handling secret updates and rotation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Handling secret updates and rotations is a crucial aspect of maintaining security.
    As recommended by NIST, regularly rotating Secrets is essential to minimize security
    risks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our approach to updating Secrets involves several methods:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Monitoring and reloading**: We continually monitor for secret changes, updating
    them in application memory to ensure the latest values are used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Keyring mode**: This involves maintaining multiple versions of Secrets to
    prevent downtime. It’s important to monitor which version is in use and phase
    out older ones timely.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Restart as reload method**: Implement an automatic system to restart Pods
    when Secrets change, possibly using Kubernetes jobs or other tools to detect changes
    and initiate restarts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Each application’s needs dictate the chosen method, focusing on the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Timely secret consumption**: Depending on the server’s capability to handle
    multiple values'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Graceful secret changes**: Ensuring applications manage new Secrets smoothly,
    without losing state or causing downtime'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Downtime avoidance**: For applications that can’t afford downtime, use strategies
    such as multiple Pod replicas and rolling updates'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring and alerting**: Keep a robust system to monitor Secrets and Pods,
    with alerts for secret rotations and Pod restarts'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This strategy aims for both security and operational efficiency, adapting to
    various application requirements on secret rotation.
  prefs: []
  type: TYPE_NORMAL
- en: Sample Kubernetes manifest for automated secret rotation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The following is a simplified example to illustrate how you might set up a
    Kubernetes job to trigger Pod restarts upon secret rotation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is a diagram showing the additional Secrets rotation job:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 13.1 – Cro\uFEFFn job for secret rotation](img/B20970_13_01.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 13.1 – Cron job for secret rotation
  prefs: []
  type: TYPE_NORMAL
- en: In this example, the job runs a container that watches for secret rotations
    in Vault and restarts the relevant Pods in Kubernetes when a rotation is detected.
    This ensures that the init containers for the affected Pods run again, fetching
    the latest version of the Secrets. By adopting such strategies, you ensure that
    your applications remain secure with up-to-date Secrets while minimizing downtime
    and maintaining a robust and resilient deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Authorization sprawl issue
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In Kubernetes, managing access to Secrets requires careful attention due to
    the delicate balance involved.
  prefs: []
  type: TYPE_NORMAL
- en: The **authorization sprawl** issue in Kubernetes arises when permissions are
    set too broadly, often unintentionally, leading to significant security risks.
    This often occurs with RBAC configurations that are not adequately tailored, resulting
    in users or services gaining more privileges than necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 'Certainly, solutions such as Kubernetes RBAC and integration with identity
    management solutions are well known, but the real issues include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: How to enforce compliance and prevent users from exploiting or circumventing
    the configuration source
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to effectively monitor and promptly revoke any policy violations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to audit configuration-based access policy changes and understand their
    impact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'A typical misconfiguration in Kubernetes RBAC might unintentionally allow unexpected
    groups to access all Secrets:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: In this example, the `myapp-sa` service account is created with overly broad
    access to Pods and Secrets. The `myapp-role-binding` role binding exacerbates
    the issue by referencing `myapp-role`, which grants full access to these resources.
    As a result, `myapp-sa` is endowed with more permissions than necessary, posing
    a risk of unauthorized access to sensitive data.
  prefs: []
  type: TYPE_NORMAL
- en: Addressing this issue requires the implementation of fine-grained access controls
    that precisely define permissions for each role and user, adhering to the principle
    of least privilege. This entails granting only the level of access required for
    users to perform their specific tasks. Regular reviews and updates of RBAC policies
    are also essential.
  prefs: []
  type: TYPE_NORMAL
- en: Tagging, labeling, and masking on the client side
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Within a Kubernetes environment, the approach to managing Secrets should be
    holistic, accounting for not just how Secrets are stored but also how they are
    managed and interacted with on the client side. Tagging, labeling, and masking
    Secrets become pivotal in this context. The rationale behind adopting these practices
    is grounded in their ability to enhance security, manageability, and adherence
    to compliance standards. By tagging and labeling Secrets, teams embed essential
    metadata that elucidates the secret’s purpose, associated resources, and lifecycle
    stage. This metadata becomes a powerful tool, aiding in implementing granular
    access controls and simplifying the tracking of secret usage across the system.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to implementation, these practices should be seamlessly integrated
    into the development and deployment workflows. Developers and operators should
    be encouraged, or even mandated, to include relevant tags and labels as part of
    their deployment configurations, ensuring that every secret is appropriately annotated
    from the outset. Masking, on the other hand, involves obscuring secret values
    in logs or UIs to preclude accidental exposure, which is a common risk, especially
    in debugging scenarios. Systems need to be configured to automatically recognize
    and redact sensitive information, a task that can be achieved through pattern
    recognition, checksums, or the explicit marking of sensitive fields in the application’s
    logging configuration.
  prefs: []
  type: TYPE_NORMAL
- en: In the long term, the payoff of these practices is substantial. The wealth of
    metadata provided through tagging and labeling facilitates a robust and continuous
    audit trail, allowing teams to track and manage Secrets effectively over extended
    periods. This is crucial not just for day-to-day operational integrity but also
    for meeting stringent security and compliance requirements. Any unauthorized access
    or modifications can be quickly identified and rectified, ensuring that the organization’s
    Secrets management strategy is both secure and resilient. Meanwhile, masking ensures
    that even in scenarios where logs or UIs are exposed, the confidentiality of secret
    values is maintained, mitigating the risk of accidental exposure.
  prefs: []
  type: TYPE_NORMAL
- en: By adopting these client-side practices, organizations lay down a foundation
    for a comprehensive Secrets management strategy, ensuring that Secrets are managed,
    tracked, and protected end to end within their Kubernetes environments. This approach
    not only fortifies the organization’s security posture but also ensures that its
    Secrets management practices are aligned with industry best practices and compliance
    standards.
  prefs: []
  type: TYPE_NORMAL
- en: Auditing and monitoring on the server side
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: On the server side of Secrets management, regular auditing and robust monitoring
    play crucial roles in maintaining a secure and compliant Kubernetes environment.
    Auditing serves as a necessary practice for ensuring that all interactions with
    Secrets—be they accesses, modifications, or deletions—are meticulously recorded
    and reviewed. This practice is fundamental not just for maintaining the integrity
    of the Secrets themselves but also for verifying that all access patterns adhere
    to established security policies and compliance requirements. By implementing
    comprehensive auditing, organizations create a secure trail of evidence, facilitating
    accountability and transparency across all operations involving sensitive information.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this level of oversight, it is imperative to utilize both techniques
    and tools that are tailored for robust auditing and monitoring. This includes
    implementing solutions that can provide real-time alerts and detailed access logs,
    ensuring that any anomalous or unauthorized activities are promptly detected and
    addressed. Tools such as audit logs in Kubernetes, and monitoring solutions such
    as Prometheus or Grafana, can be configured to work seamlessly within the environment,
    providing teams with the visibility they need to safeguard their Secrets. Additionally,
    integrating these tools with existing **security information and event management**
    (**SIEM**) systems can further enhance the organization’s capability to correlate
    events, identify patterns, and respond to potential threats swiftly and effectively.
  prefs: []
  type: TYPE_NORMAL
- en: The importance of consistent auditing for security and adherence to regulations,
    along with strategies and instruments to enhance thorough auditing, guarantees
    the proper monitoring of access and changes to Secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring secure Secrets distribution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensuring the secure distribution of Secrets within a Kubernetes environment
    is paramount, as insecure practices can lead to severe vulnerabilities and security
    breaches. When Secrets are distributed in plain text at rest, whether within the
    host’s filesystem or within a container’s environment, they become susceptible
    to unauthorized access and potential exploitation. This vulnerability is especially
    concerning if an attacker gains access to the host or container, as they could
    easily retrieve and misuse these Secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding and establishing clear security boundaries is critical in mitigating
    these risks. Organizations must take a proactive stance, implementing stringent
    controls and adopting a principle of least privilege to minimize the blast radius
    in the event of a security incident. This approach involves restricting access
    to Secrets, ensuring that only the necessary parties have access and that Secrets
    are not unnecessarily exposed.
  prefs: []
  type: TYPE_NORMAL
- en: Building a trust chain during the Secrets distribution process is essential
    in maintaining the integrity and confidentiality of the Secrets. This involves
    verifying the authenticity and integrity of the Secrets at every step of the distribution
    process, from the moment they are generated or retrieved from the Secrets store,
    through their transmission, and finally, to their consumption by the intended
    services or applications. Various measures can be implemented to ensure this trust
    chain, including the use of encryption during transit, secure injection methods
    for Secrets delivery, and utilizing trusted platforms and identities for access
    control.
  prefs: []
  type: TYPE_NORMAL
- en: Decommissioning and revoking Secrets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Decommissioning and revoking Secrets are critical aspects of Secrets lifecycle
    management, ensuring that outdated, compromised, or otherwise unnecessary Secrets
    are removed promptly and securely. Implementing best practices for decommissioning
    involves safely retiring Secrets and ensuring that they are purged from both the
    Secrets store and any environments where they may reside. This process must be
    thorough and systematic to prevent any potential security risks associated with
    lingering Secrets.
  prefs: []
  type: TYPE_NORMAL
- en: Integration of Secrets management into broader service decommission workflows
    is paramount. As services are retired or replaced, the associated Secrets should
    simultaneously undergo decommissioning. This ensures a cohesive and streamlined
    process, reducing the risk of oversight and potential security vulnerabilities.
    By embedding Secrets considerations directly into service decommissioning processes,
    organizations can enforce consistency and adherence to security protocols.
  prefs: []
  type: TYPE_NORMAL
- en: Revocation protocols play a critical role in both proactive and reactive Secrets
    management. Proactively, Secrets should be rotated and revoked according to predefined
    schedules or triggers, such as the expiration of a certificate or the end of a
    service’s lifecycle. Reactively, in the event of a security incident or discovery
    of a compromised secret, immediate revocation is necessary to mitigate risks and
    prevent unauthorized access. Establishing clear and efficient revocation protocols
    ensures that teams can respond swiftly, minimizing the potential impact of a security
    breach.
  prefs: []
  type: TYPE_NORMAL
- en: Together, these practices fortify the Secrets management lifecycle, ensuring
    that Secrets are not only generated and used securely but are also retired and
    revoked with equal diligence. This comprehensive approach enhances the overall
    security posture of the Kubernetes environment, safeguarding sensitive information
    and maintaining the integrity of the production system.
  prefs: []
  type: TYPE_NORMAL
- en: Responsibility, on-call support, penetration testing, and risk evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The effective management of Secrets within a Kubernetes production environment
    necessitates a clear delineation of responsibilities, robust on-call support structures,
    and an ongoing commitment to security through penetration testing and risk evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: Responsibility and on-call support
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The team managing the deployment platform must clearly define and distribute
    the responsibilities associated with both Secrets distribution and Secrets store
    management. This encompasses not only the initial setup and distribution of Secrets
    but also their ongoing management, updates, and rotation. On-call responsibilities
    are a critical component of this, ensuring that there is always a knowledgeable
    and capable team member available to address any issues that may arise, ranging
    from access issues and misconfigurations to potential security incidents. These
    team members must be well versed in both the configuration and debugging of the
    Secrets management tools and the broader Kubernetes environment to effectively
    address and resolve incidents. Additionally, they should be actively involved
    in enhancement efforts, working to continuously improve the system’s stability,
    security, and efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Penetration testing and risk evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The regular penetration testing of the production Secrets store is paramount
    in identifying and mitigating potential security risks. This proactive approach
    to security helps in uncovering vulnerabilities, assessing the robustness of access
    policies, and evaluating potential paths through which Secrets could be exposed.
    The results of these penetration tests should feed directly into the organization’s
    broader risk evaluation efforts, helping to build a comprehensive understanding
    of the system’s security posture and guiding informed decisions around risk mitigation.
  prefs: []
  type: TYPE_NORMAL
- en: Penetration testing should not be a one-time effort but rather an ongoing practice,
    continuously evolving to address new threats and vulnerabilities as they emerge.
    It should cover various aspects of the Secrets management lifecycle, from the
    initial provisioning of Secrets, through their storage, distribution, and eventual
    decommissioning.
  prefs: []
  type: TYPE_NORMAL
- en: By integrating these practices into the organization’s overall risk evaluation
    framework, teams can ensure that they are not only addressing immediate threats
    but also building a resilient system capable of withstanding future challenges.
    This comprehensive approach to responsibility, on-call support, penetration testing,
    and risk evaluation forms a critical component of maintaining a secure and efficient
    Secrets management framework within Kubernetes production environments.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we delved into the intricacies of managing Kubernetes Secrets
    within production clusters. We highlighted the qualities necessary for effective
    Secrets management and examined various deployment strategies and their integration
    with CI/CD processes. Additionally, we explored a detailed case study on Keywhiz,
    which provided a thorough understanding of Secrets management development, emphasizing
    a holistic approach that covers the entire lifecycle of Secrets management.
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will offer a synthesis of the insights and knowledge we’ve
    gained throughout the book. It will also cast a forward-looking perspective on
    the evolution and future trends in Kubernetes Secrets management.
  prefs: []
  type: TYPE_NORMAL
