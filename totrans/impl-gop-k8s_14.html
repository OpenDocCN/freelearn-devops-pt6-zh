<html><head></head><body>
		<div id="_idContainer193">
			<h1 class="chapter-number" id="_idParaDest-270"><a id="_idTextAnchor274"/>14</h1>
			<h1 id="_idParaDest-271"><a id="_idTextAnchor275"/>FinOps, Sustainability, AI, and Future Trends for GitOps</h1>
			<p>In this chapter, we venture beyond the conventional boundaries of GitOps to explore its extensive scope and multifaceted impact across various domains not covered in the main sections of the book. Our journey is structured into distinct yet interconnected blocks, each shedding light on different dimensions where GitOps extends its influence, providing a comprehensive insight into the potential and versatility of <span class="No-Break">this practice.</span></p>
			<p>We commence with the fundamentals of <strong class="bold">FinOps</strong> and <strong class="bold">cost management</strong>, where the fusion of financial acumen and operational expertise comes to the forefront. This segment elucidates how the FinOps framework, integrated with GitOps methodologies, empowers organizations to wield granular control over their cloud expenditures. By leveraging tools such as <strong class="bold">OpenCost</strong> and <strong class="bold">Kubecost</strong> in a GitOps-driven environment, businesses can achieve unprecedented transparency and efficiency in managing costs for clusters, projects, and beyond, ensuring that every dollar spent is an investment toward innovation <span class="No-Break">and growth.</span></p>
			<p>Transitioning to the realm of sustainability and green operations, we delve into how GitOps can be a catalyst for eco-friendly IT practices. This block emphasizes the significance of sustainable operations, not only from an economic standpoint but also in contributing to environmental stewardship. We discuss practical strategies, such as the automated shutdown of development clusters, illustrating how GitOps can align technological advancements with ecological responsibility, thereby fostering a culture of sustainability within the <span class="No-Break">tech industry.</span></p>
			<p>The exploration expands to include GitOps and <strong class="bold">artificial intelligence</strong> (<strong class="bold">AI</strong>)-driven automation, a segment that bridges the advanced realms of AI and GitOps. This fusion is revolutionizing the way organizations deploy, monitor, and manage their IT landscapes, transcending the hype to deliver tangible, impactful automation solutions. Through real-world examples and case studies, we examine the dual benefits of AI in enhancing DevOps practices and streamlining the deployment of inter-company services, all within the <span class="No-Break">GitOps framework.</span></p>
			<p>Finally, we reflect on the evolving landscape of GitOps, contemplating the continuous evolution of GitOps principles and their transformative influence across various sectors. This concluding block forecasts the future trajectory of GitOps, speculating on its role amid emerging technologies and its potential to redefine industry standards. We delve into how GitOps is <strong class="bold">pivotal</strong> in forecasting and monitoring cloud costs, thereby enabling organizations to navigate the complexities of modern cloud environments with confidence and <span class="No-Break">strategic foresight.</span></p>
			<p>Each of these blocks, while distinct in focus, collectively underscores the expansive reach of GitOps, illustrating its role as a cornerstone in modern IT strategy. This chapter aims to broaden readers’ perspective, encouraging them to envision GitOps not merely as a tool for operational efficiency but as a holistic approach that harmonizes technological innovation with financial wisdom, environmental consciousness, and <span class="No-Break">forward-thinking adaptability.</span></p>
			<p>We will cover the following main topics in <span class="No-Break">this chapter:</span></p>
			<ul>
				<li>Covering the fundamentals <span class="No-Break">of FinOps</span></li>
				<li>Forecasting and monitoring costs <span class="No-Break">with GitOps</span></li>
				<li>Optimization techniques for <span class="No-Break">cloud spend</span></li>
				<li>Assessing carbon footprint and promoting <span class="No-Break">green operations</span></li>
				<li>Looking at GitOps and <span class="No-Break">AI-driven automation</span></li>
				<li>Future challenges and opportunities <span class="No-Break">in GitOps</span></li>
				<li>The role of GitOps in <span class="No-Break">emerging technologies</span></li>
			</ul>
			<h1 id="_idParaDest-272"><a id="_idTextAnchor276"/>Covering the fundamentals of FinOps</h1>
			<p><strong class="bold">FinOps</strong>, an <a id="_idIndexMarker1224"/>operational framework blending finance and DevOps principles, is fundamentally a cultural practice aimed at maximizing the business value of cloud investments. It fosters a collaborative environment where engineering, finance, and business teams work together to facilitate data-driven decisions, enhancing financial accountability and optimizing <span class="No-Break">cloud costs.</span></p>
			<p>The essence of FinOps lies in its ability to bridge the gap between traditionally siloed departments, promoting a shared responsibility model where all stakeholders are vested in the cloud’s cost-effectiveness and operational efficiency. This cross-functional synergy is crucial for enabling faster product delivery while ensuring financial transparency <span class="No-Break">and control.</span></p>
			<p>Key aspects of <a id="_idIndexMarker1225"/>FinOps include real-time monitoring of cloud expenses, enabling organizations to make informed decisions that balance cost, speed, and quality. The approach goes beyond mere cost-cutting; it’s about leveraging the cloud’s variable spending model to drive innovation, revenue growth, and strategic investments in the <span class="No-Break">tech infrastructure.</span></p>
			<p>Organizations looking to adopt FinOps can start by exploring resources offered by the FinOps Foundation, which provides education, best practices, and community engagement to support different maturity levels in the FinOps journey. The <strong class="bold">Crawl, Walk, Run</strong> maturity model <a id="_idIndexMarker1226"/>advocated by FinOps allows organizations to evolve their financial operations progressively, enhancing their cloud architecture and investment <span class="No-Break">strategies continuously.</span></p>
			<p class="callout-heading">The Crawl, Walk, Run model</p>
			<p class="callout">The <strong class="bold">Crawl, Walk, Run</strong> model is a <a id="_idIndexMarker1227"/>framework that describes the progressive stages of learning and implementation. In the <strong class="bold">Crawl</strong> stage, individuals or organizations focus on understanding basic principles with limited scope and high reliance on guidance. The <strong class="bold">Walk</strong> stage involves greater familiarity and confidence, with more complex tasks and increased efficiency. Finally, in the <strong class="bold">Run</strong> stage, there is full mastery and independent, innovative use of the new concept, process, or technology. This model helps manage expectations and provides a structured growth path to ensure a solid foundation before advancing to more <span class="No-Break">complex levels.</span></p>
			<p>Central to the FinOps framework are principles guiding collaborative efforts, personal ownership of cloud usage, and the strategic alignment of cloud investments with business value. These principles ensure that every team member, from executives to engineers, understands and contributes to the efficient and innovative use of <span class="No-Break">cloud resources.</span></p>
			<p>Incorporating FinOps into an organization’s operational model not only promises enhanced cost management and optimization but also aligns cloud expenditure with business outcomes, ensuring that investments translate into tangible value. This strategic alignment is crucial in today’s dynamic cloud environments, where adaptive planning and cost-effective resource utilization are key to sustaining competitive advantage and fostering<a id="_idIndexMarker1228"/> <span class="No-Break">long-term growth.</span></p>
			<p>In the next section, we will use OpenCost [<em class="italic">1</em>] and Kubecost [<em class="italic">2</em>] to determine the costs for a cluster or for a namespace, which could, for example, represent <span class="No-Break">a project.</span></p>
			<h1 id="_idParaDest-273"><a id="_idTextAnchor277"/>Forecasting and monitoring costs with GitOps</h1>
			<p>GitOps can be seamlessly integrated with FinOps to enhance the financial governance of cloud resources while <strong class="bold">maintaining agility</strong> and operational efficiency. The combination of GitOps and FinOps practices enables organizations to manage their cloud infrastructure and costs more effectively through automation, version control, and <span class="No-Break">continuous monitoring.</span></p>
			<h2 id="_idParaDest-274"><a id="_idTextAnchor278"/>How GitOps complements FinOps</h2>
			<p>First, let’s understand how GitOps <span class="No-Break">complements FinOps:</span></p>
			<ul>
				<li><strong class="bold">Automated cost optimization</strong>: GitOps allows for the automation of deployment and <a id="_idIndexMarker1229"/>scaling of cloud resources, which can be integrated with FinOps strategies to ensure that resource utilization is optimized for cost without sacrificing performance. This means infrastructure can scale up or down automatically, aligning with financial objectives and <span class="No-Break">operational demands.</span></li>
				<li><strong class="bold">Version-controlled spending</strong>: With GitOps, every change to the infrastructure is <a id="_idIndexMarker1230"/>version-controlled in Git repositories, providing an audit trail of what changes were made, who made them, and why. This aligns with FinOps principles by adding transparency to the financial impact of operational changes, enabling better budget tracking and <span class="No-Break">cost allocation.</span></li>
				<li><strong class="bold">Collaboration and visibility</strong>: GitOps fosters collaboration among development, operations, and<a id="_idIndexMarker1231"/> finance teams by using Git as <a id="_idIndexMarker1232"/>a <strong class="bold">single source of truth</strong> (<strong class="bold">SSOT</strong>). This collaborative environment ensures that financial considerations are integrated into the earliest stages of infrastructure planning and application development, promoting a <span class="No-Break">cost-aware culture.</span></li>
				<li><strong class="bold">Policy enforcement</strong>: Integrating <strong class="bold">policy-as-code</strong> (<strong class="bold">PaC</strong>) tools<a id="_idIndexMarker1233"/> within a GitOps workflow can enforce financial governance, ensuring that <a id="_idIndexMarker1234"/>resources are utilized efficiently and within budget. Policies can be set to prevent overspending, enforce the use of cost-optimized resources, or ensure adherence to <span class="No-Break">budgetary constraints.</span></li>
				<li><strong class="bold">Continuous cost monitoring and feedback</strong>: GitOps enables continuous monitoring and feedback<a id="_idIndexMarker1235"/> loops, allowing teams to quickly identify and address inefficiencies in cloud resource utilization. This constant vigilance helps in maintaining a balance between operational efficiency, cost, and speed, in line with <span class="No-Break">FinOps goals.</span></li>
				<li><strong class="bold">Proactive financial management</strong>: By using GitOps, organizations can proactively manage their cloud expenses. <strong class="bold">Infrastructure-as-code</strong> (<strong class="bold">IaC</strong>) templates<a id="_idIndexMarker1236"/> stored in Git repositories can be <a id="_idIndexMarker1237"/>analyzed to forecast costs and understand the financial implications of planned changes before they <span class="No-Break">are executed.</span></li>
			</ul>
			<h2 id="_idParaDest-275"><a id="_idTextAnchor279"/>Utilizing GitOps with FinOps</h2>
			<p>The following points describe how integrating <a id="_idIndexMarker1238"/>cost monitoring, budget<a id="_idIndexMarker1239"/> enforcement, resource optimization, and financial operations automation into a GitOps pipeline can enhance cost efficiency and ensure <span class="No-Break">financial governance:</span></p>
			<ul>
				<li><strong class="bold">Implementing cost monitoring tools</strong>: Integrate cloud cost monitoring tools into the GitOps pipeline to provide real-time feedback on the financial impact of code changes and <span class="No-Break">infrastructure updates</span></li>
				<li><strong class="bold">Enforcing budget policies</strong>: Use GitOps to enforce budget policies through IaC, ensuring that deployments conform to predefined financial constraints and <span class="No-Break">operational budgets</span></li>
				<li><strong class="bold">Optimizing resource allocation</strong>: Leverage GitOps to automate the deployment of cost-optimized resources, such as spot instances, and to shut down underutilized resources, ensuring efficient <span class="No-Break">cloud spend</span></li>
				<li><strong class="bold">Streamlining financial operations</strong>: Automate financial operations tasks such as cost reporting, budget alerts, and resource tagging through GitOps, ensuring that financial governance is consistently applied across all <span class="No-Break">cloud resources</span></li>
			</ul>
			<p>By integrating<a id="_idIndexMarker1240"/> GitOps with FinOps practices, organizations can <a id="_idIndexMarker1241"/>ensure that their cloud infrastructure is not only operationally efficient but also aligned with their financial objectives, delivering maximum value from their cloud investments. This holistic approach enables a more agile, transparent, and cost-effective cloud <span class="No-Break">management strategy.</span></p>
			<p>Now, let’s take a look at how it works in practice. For this, we will examine two tools: OpenCost as an open source option and Kubecost, which is built on OpenCost but offers many additional features on top in the <span class="No-Break">next part.</span></p>
			<h2 id="_idParaDest-276"><a id="_idTextAnchor280"/>OpenCost versus Kubecost with GitOps</h2>
			<p>OpenCost and Kubecost are tools used in the realm of Kubernetes cost monitoring and analysis, providing insights into resource utilization and assisting in managing costs associated with Kubernetes environments in the cloud. Let’s cover a brief description of both tools and the differences <span class="No-Break">between them.</span></p>
			<h3>OpenCost</h3>
			<p>OpenCost is an <a id="_idIndexMarker1242"/>open source tool that brings <strong class="bold">transparency</strong> to the costs and usage associated with Kubernetes clusters. It enables teams to monitor, analyze, and optimize their Kubernetes costs by providing detailed insights into resource utilization and associated expenses. OpenCost offers features such as <span class="No-Break">the following:</span></p>
			<ul>
				<li>Cost <a id="_idIndexMarker1243"/>breakdown at the pod, deployment, namespace, or <span class="No-Break">cluster level</span></li>
				<li>Support for <span class="No-Break">multi-cluster environments</span></li>
				<li>Integrations with cloud providers for more accurate <span class="No-Break">cost estimation</span></li>
				<li>Forever free and open source, supported and maintained <span class="No-Break">by experts</span></li>
			</ul>
			<p>How does this all fit with GitOps, or, more specifically, what value does GitOps add in the <a id="_idIndexMarker1244"/>FinOps context? OpenCost sets up on-premises pricing configurations based on the <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>) <strong class="source-inline">us-central-1</strong> region—for instance, <strong class="source-inline">"CPU": "0.031611"$</strong>, and <strong class="source-inline">"RAM": "0.004237"$</strong> on an hourly basis. Nevertheless, OpenCost also allows for the customization of pricing. This is where GitOps comes into play, enabling not just the deployment of the OpenCost tool across various clusters (<span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.1</em>) but also the capability to configure prices accordingly. For example, if you have three data centers in Europe, located in three different countries, the CPU and RAM prices will vary due to factors such as electricity prices, procurement, depreciation, and <span class="No-Break">so on.</span></p>
			<p>There are globally<a id="_idIndexMarker1245"/> defined values under <strong class="source-inline">optimization/opencost</strong>, and then there’s a custom pricing model for each specific country. Visually, it looks <span class="No-Break">as follows:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer180">
					<img alt="Figure 14.1 – OpenCost with GitOps and on-premise pricing configuration" src="image/B22100_14_01.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.1 – OpenCost with GitOps and on-premise pricing configuration</p>
			<p>For the <a id="_idIndexMarker1246"/>scenario in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.1</em>, we establish the following folder <span class="No-Break">structure [</span><span class="No-Break"><em class="italic">3</em></span><span class="No-Break">]:</span></p>
			<pre class="source-code">
.
├── applicationsets
│   └── optimization
│       └── opencost-applicationset.yaml
├── cluster
│   ├── in-cluster-austria
│   │   └── optimization
│   │       └── opencost
│   │           └── values.yaml
│   ├── in-cluster-germany
│   │   └── optimization
│   │       └── opencost
│   │           └── values.yaml
│   └── in-cluster-ireland
│       └── optimization
│           └── opencost
│               └── values.yaml
└── optimization
    └── opencost
        ├── Chart.yaml
        └── values.yaml</pre>			<p>It can also be <a id="_idIndexMarker1247"/>combined with <strong class="bold">hybrid cloud</strong> and <strong class="bold">multi-cloud</strong>; then, it might look <span class="No-Break">like this:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer181">
					<img alt="Figure 14.2 – OpenCost with GitOps and hybrid-setup pricing configuration" src="image/B22100_14_02.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.2 – OpenCost with GitOps and hybrid-setup pricing configuration</p>
			<p>GitOps, combined with<a id="_idIndexMarker1248"/> OpenCost, opens up new possibilities in FinOps, enabling more user- and infrastructure-defined cost visibility across distributed infrastructures, thus allowing for enhanced financial oversight, precise cost allocation, and strategic budget optimization in <span class="No-Break">cloud environments.</span></p>
			<p>However, if you require functionalities such as team collaboration, budget planning, alerting, estimated monthly savings, and more, then you should consider <span class="No-Break">exploring Kubecost.</span></p>
			<h3>Kubecost</h3>
			<p>Kubecost is a product that<a id="_idIndexMarker1249"/> builds on OpenCost. It’s a commercial solution that offers additional features and support for businesses that go beyond the core functionalities of the OpenCost project. Kubecost includes all the features of OpenCost, along with<a id="_idIndexMarker1250"/> <span class="No-Break">the following:</span></p>
			<ul>
				<li>Advanced budgeting and <span class="No-Break">cost forecasting</span></li>
				<li>Personalized <span class="No-Break">optimization recommendations</span></li>
				<li>Additional security and <span class="No-Break">compliance features</span></li>
				<li>Professional support <span class="No-Break">and consultation</span></li>
			</ul>
			<p>Additionally, you have the flexibility to utilize GitOps not just for deploying Kubecost across various clusters but also to <strong class="bold">empower teams</strong> to set <strong class="bold">budgets</strong> based on namespaces, clusters, or labels, along with specifying actions (<span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.3</em>) to take when budget thresholds <span class="No-Break">are exceeded:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer182">
					<img alt="Figure 14.3 – Kubecost with GitOps: defining budget and cost alerts" src="image/B22100_14_03.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.3 – Kubecost with GitOps: defining budget and cost alerts</p>
			<p>By integrating<a id="_idIndexMarker1251"/> GitOps with Kubecost, organizations empower their teams with enhanced control over their projects or clusters, streamlining the deployment of this powerful tool. This synergy allows teams not only to deploy Kubecost efficiently at scale but also to define essential parameters that align with their budgetary needs. Such integration is pivotal in fostering a collaborative environment for cost management, enabling various teams within the organization to share best practices, insights, and strategies to collectively <span class="No-Break">optimize resources.</span></p>
			<p>This collaborative atmosphere is further enriched by the capabilities of Kubecost combined with GitOps, which facilitate proactive cost management. With the ability to set predefined thresholds and configure automated alerts, teams are equipped to actively monitor and manage their cloud spending. This proactive stance ensures that any potential budget overruns are swiftly identified and addressed, and overall cloud expenditure is <span class="No-Break">optimized effectively.</span></p>
			<p>The confluence of GitOps and Kubecost transforms the approach to cloud cost management, moving from a reactive to a proactive model. Teams are no<a id="_idIndexMarker1252"/> longer in the dark about their spending trends and are instead provided with a clear, actionable framework that enables them to maintain financial efficiency while capitalizing on the scalability and flexibility of cloud resources. This integration ensures that cost optimization is not just an afterthought such as the end of the month but a fundamental aspect of <strong class="bold">daily operations</strong>, empowering teams to leverage cloud resources judiciously <span class="No-Break">and economically.</span></p>
			<h3>Differences between OpenCost and Kubecost</h3>
			<p>Here<a id="_idIndexMarker1253"/> are the most <a id="_idIndexMarker1254"/>important differences between the <span class="No-Break">two tools:</span></p>
			<ul>
				<li><strong class="bold">Open source versus commercial</strong>: OpenCost is an open source project inviting the community to freely use and adapt it, whereas Kubecost is a commercial version offering enhanced features and support for <span class="No-Break">business customers.</span></li>
				<li><strong class="bold">Feature set</strong>: Kubecost builds upon OpenCost, extending it with additional, commercial features specifically designed for enterprise customers. For example, while OpenCost provides basic cost monitoring for Kubernetes clusters, Kubecost offers advanced features such as automated cost optimization recommendations and detailed cost allocation reports for different teams <span class="No-Break">and projects.</span></li>
				<li><strong class="bold">Support</strong>: Kubecost provides professional support and consulting services that go beyond what is typically expected from an open <span class="No-Break">source project.</span></li>
			</ul>
			<p>Both tools aim to improve transparency and control over costs associated with Kubernetes usage, but they cater to different user groups and needs, ranging from the open source community to <span class="No-Break">large enterprises.</span></p>
			<p>This combination of GitOps and OpenCost or Kubecost not only streamlines operational efficiency but also significantly enhances the strategic financial management of <span class="No-Break">Kubernetes environments.</span></p>
			<p>In the next part, we look at how to optimize cloud costs and how GitOps with Kubecost contributes <span class="No-Break">to this.</span></p>
			<h1 id="_idParaDest-277"><a id="_idTextAnchor281"/>Optimization techniques for cloud spend</h1>
			<p>Optimization techniques for cloud spending are crucial for organizations looking to maximize their <strong class="bold">cloud investment</strong> while <a id="_idIndexMarker1255"/>minimizing unnecessary costs. Integrating GitOps with tools such as Kubecost can significantly streamline this process, providing a systematic approach to managing and reducing cloud expenses. Here’s how this combination can be leveraged to enhance cloud <span class="No-Break">spend optimization.</span></p>
			<h2 id="_idParaDest-278"><a id="_idTextAnchor282"/>Combining GitOps and Kubecost for cloud spend optimization</h2>
			<p>GitOps, by design, brings <a id="_idIndexMarker1256"/>automation, predictability, and transparency to cloud operations. It establishes a Git repository as the SSOT for the entire infrastructure, which means every change is version-controlled, traceable, and reversible. This methodical approach is instrumental in cloud <span class="No-Break">spend optimization.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">An example on GitHub under <a href="B22100_14.xhtml#_idTextAnchor274"><span class="No-Break"><em class="italic">Chapter 14</em></span></a>, <strong class="source-inline">...optimization/kubecost</strong>, demonstrates how to configure alerts in the Kubecost UI and via Helm Chart deployment using the <span class="No-Break"><strong class="source-inline">values.yaml</strong></span><span class="No-Break"> file.</span></p>
			<p>When GitOps and Kubecost are used together, they provide a powerful framework for ongoing cloud <span class="No-Break">spend optimization:</span></p>
			<ul>
				<li><strong class="bold">Automated resource optimization</strong>: GitOps can automate the deployment of Kubecost’s recommendations, ensuring that cost-saving measures are promptly and consistently applied across <span class="No-Break">the infrastructure</span></li>
				<li><strong class="bold">Continuous monitoring and adjustment</strong>: The combination allows for continuous monitoring of cloud spend and automatic adjustments based on predefined policies, ensuring that the cloud environment is always running in the most <span class="No-Break">cost-effective manner</span></li>
				<li><strong class="bold">Enhanced collaboration</strong>: By integrating these tools, financial and operational teams can collaborate more effectively, with GitOps providing the operational framework and Kubecost offering financial insights, leading to more <span class="No-Break">informed decision-making</span></li>
			</ul>
			<p>Let’s<a id="_idIndexMarker1257"/> imagine a new project comes in. The platform team provides the Kubernetes platform, but the FinOps team, which has a fixed budget of 500 USD per project, is responsible for managing the costs. The FinOps Team can create a budget with alerts in the UI or let the GitOps team deploy the alert via GitOps budgets for the project namespaces and clusters and set <span class="No-Break">up </span><span class="No-Break"><strong class="bold">alerts</strong></span><span class="No-Break">.</span></p>
			<p>If the FinOps team, for example, wonders why the cumulative budget across the namespaces is between 70-100 USD, but the total spent budget is around 600 USD, they can use the alerts and UI to investigate the root cause. The Kubecost UI (<span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.4</em>) reveals that the cluster efficiency, for example, is below 12%, and savings of about 50 USD are already possible with a <span class="No-Break">7-day retrospective:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer183">
					<img alt="Figure 14.4 – Kubecost cluster efficiency ~12% for 7 days" src="image/B22100_14_04.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.4 – Kubecost cluster efficiency ~12% for 7 days</p>
			<p>The FinOps team then examines the potential savings in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.5</em> to understand the origins of the costs. It quickly becomes apparent that the cluster for the project is oversized. Together with the platform team and by utilizing Kubecost, the teams involved in the project can implement sizing adjustments and mechanisms to modify actions accordingly. At this juncture, it’s crucial that collaboration between the teams is effective and that all teams act in the interest of the company, sustainability, and the project. This is how cloud costs can be <span class="No-Break">sensibly optimized:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer184">
					<img alt="Figure 14.5 – Kubecost savings recommendation" src="image/B22100_14_05.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.5 – Kubecost savings recommendation</p>
			<p>In conclusion, leveraging<a id="_idIndexMarker1258"/> GitOps alongside Kubecost can transform cloud spend optimization from a reactive to a proactive endeavor. This integration not only provides granular insights into cloud usage and expenses but also automates the application of cost-saving strategies, ensuring that cloud resources are utilized efficiently and economically, and aligning cloud expenditure with organizational budgetary goals and <span class="No-Break">operational requirements.</span></p>
			<p>In the following section, we will explore the utilization of GitOps along with diverse tools to progress <span class="No-Break">toward sustainability.</span></p>
			<h1 id="_idParaDest-279"><a id="_idTextAnchor283"/>Assessing carbon footprint and promoting green operations</h1>
			<p>Assessing the carbon footprint and promoting green operations in cloud environments are critical steps toward achieving sustainability in IT operations. Tools such<a id="_idIndexMarker1259"/> as <strong class="source-inline">kube-green</strong> [<em class="italic">4</em>] and <strong class="bold">Armada</strong> [<em class="italic">5</em>] offer<a id="_idIndexMarker1260"/> innovative approaches to managing and reducing the environmental impact of <span class="No-Break">cloud computing.</span></p>
			<h2 id="_idParaDest-280"><a id="_idTextAnchor284"/>Assessing carbon footprint with kube-green</h2>
			<p>The <strong class="source-inline">kube-green</strong> tool<a id="_idIndexMarker1261"/> focuses on optimizing resource usage in a way that correlates directly with energy consumption, thereby minimizing the <a id="_idIndexMarker1262"/>environmental impact. Here’s how it contributes to <span class="No-Break">green operations:</span></p>
			<ul>
				<li><strong class="bold">Workload scheduling</strong>: The <strong class="source-inline">kube-green</strong> tool can intelligently schedule workloads to run during times when the energy grid is supplied by renewable sources, thus promoting the use of <span class="No-Break">green energy</span></li>
				<li><strong class="bold">Resource optimization</strong>: It helps in fine-tuning the allocation of resources, ensuring that applications use only what they need and reducing the overall energy consumption of the <span class="No-Break">data center</span></li>
				<li><strong class="bold">Idle resource management</strong>: The tool can automatically scale down or turn off idle resources, significantly cutting down energy waste and associated <span class="No-Break">carbon emissions</span></li>
			</ul>
			<p>Implementing <strong class="source-inline">kube-green</strong> allows organizations to move toward carbon-neutral computing, aligning IT operations with broader environmental <span class="No-Break">sustainability goals.</span></p>
			<h2 id="_idParaDest-281"><a id="_idTextAnchor285"/>Promoting green operations with Armada</h2>
			<p>While not a direct<a id="_idIndexMarker1263"/> tool like <strong class="source-inline">kube-green</strong>, Armada represents the <a id="_idIndexMarker1264"/>concept of a fleet management approach in Kubernetes, which can be adapted to promote green operations. By managing clusters efficiently, Armada can help in the <span class="No-Break">following ways:</span></p>
			<ul>
				<li><strong class="bold">Cluster consolidation</strong>: Optimizing the number of active clusters and nodes based on demand, <strong class="bold">reducing energy consumption</strong> by avoiding the over-provisioning <span class="No-Break">of resources</span></li>
				<li><strong class="bold">Energy-efficient deployments</strong>: Facilitating the deployment of applications in an energy-efficient manner, potentially integrating with tools that forecast the availability of <span class="No-Break">green energy</span></li>
				<li><strong class="bold">Monitoring and reporting</strong>: Providing insights into the energy usage and efficiency of clusters, enabling informed decisions about how <a id="_idIndexMarker1265"/>to reduce the <span class="No-Break">carbon</span><span class="No-Break"><a id="_idIndexMarker1266"/></span><span class="No-Break"> footprint</span></li>
			</ul>
			<p>Adopting a strategy such as Armada allows organizations to oversee their Kubernetes clusters with an eye toward sustainability, ensuring that the infrastructure is as energy-efficient <span class="No-Break">as possible.</span></p>
			<h2 id="_idParaDest-282"><a id="_idTextAnchor286"/>Assessing carbon footprint by integrating with GitOps</h2>
			<p>Integrating<a id="_idIndexMarker1267"/> tools such as <strong class="source-inline">kube-green</strong> and concepts such as Armada into a GitOps workflow can further enhance <span class="No-Break">their effectiveness:</span></p>
			<ul>
				<li><strong class="bold">Automated implementation</strong>: GitOps can automate the deployment of <strong class="source-inline">kube-green</strong> policies and Armada strategies across all clusters, ensuring uniform adherence to <span class="No-Break">sustainability practices</span></li>
				<li><strong class="bold">Continuous optimization</strong>: With GitOps, the continual adjustment and optimization of green policies can be maintained across the life cycle of applications, keeping sustainability a priority in <span class="No-Break">every deployment</span></li>
				<li><strong class="bold">Transparency and accountability</strong>: The declarative nature of GitOps provides a clear, version-controlled history of all changes made to promote green operations, fostering transparency and accountability in <span class="No-Break">sustainability efforts</span></li>
			</ul>
			<p>By assessing the carbon footprint and promoting green operations, organizations not only contribute to the environmental sustainability of their cloud infrastructure but also align with global efforts to reduce carbon emissions. The integration of these practices with GitOps ensures a systematic, scalable, and effective approach to sustainable <span class="No-Break">cloud computing.</span></p>
			<p>As AI is becoming increasingly important and there are already tools that can provide teams with useful support, we will take a look at these in the <span class="No-Break">next section.</span></p>
			<h1 id="_idParaDest-283"><a id="_idTextAnchor287"/>Looking at GitOps and AI-driven automation</h1>
			<p>As the IT landscape becomes increasingly complex, especially when dissecting all aspects of Kubernetes in detail without the aid of GitOps or other tools, many layers accumulate, spanning from the operating system level through the network and<a id="_idIndexMarker1268"/> up to <strong class="bold">public key infrastructures</strong> (<strong class="bold">PKIs</strong>). I notice more frequently that new employees in this field are finding it increasingly difficult to get started and to know where exactly to begin, especially when they are thrust into a project. Hence, there are practical AI tools available that can provide support in <span class="No-Break">this area.</span></p>
			<p>In this chapter, we will explore two tools. The first<a id="_idIndexMarker1269"/> tool, <strong class="bold">Robusta.dev</strong>, serves as a <strong class="bold">troubleshooting co-pilot</strong> for developers, providing them with real-time insights and solutions. The second tool is a <strong class="bold">retrieval-augmented generation</strong> (<strong class="bold">RAG</strong>) model, a<a id="_idIndexMarker1270"/> self-implemented middleware<a id="_idIndexMarker1271"/> solution from <strong class="bold">iits</strong>, which can be used as an enhancement to support developers with a knowledge base. By combining these two tools and deploying them via GitOps in the relevant projects, I believe they can be extremely beneficial not only for developers new to the field but also for those who are already experienced. This integration is likely to result in a <span class="No-Break">productive boost.</span></p>
			<h2 id="_idParaDest-284"><a id="_idTextAnchor288"/>Robusta.dev</h2>
			<p>Robusta [<em class="italic">6</em>] is an open source <a id="_idIndexMarker1272"/>platform designed to enhance the observability and debugging capabilities of Kubernetes. It’s a tool that helps DevOps teams, <strong class="bold">site reliability engineers</strong> (<strong class="bold">SREs</strong>), and <a id="_idIndexMarker1273"/>developers to get more insights into their Kubernetes clusters, facilitating better monitoring, alerting, <span class="No-Break">and troubleshooting.</span></p>
			<p>Key features of <a id="_idIndexMarker1274"/>Robusta include <span class="No-Break">the following:</span></p>
			<ul>
				<li><strong class="bold">Enhanced observability</strong>: Robusta provides detailed insights into the Kubernetes environment, offering rich, actionable alerts and notifications. It transforms plain log files into more interactive, enriched data that helps in quicker understanding and resolution <span class="No-Break">of issues.</span></li>
				<li><strong class="bold">Automated troubleshooting</strong>: The platform can automate the troubleshooting process for common Kubernetes problems, reducing the manual effort required to diagnose and <span class="No-Break">resolve issues.</span></li>
				<li><strong class="bold">Customizable playbooks</strong>: Users can create custom playbooks to automate responses to specific incidents or alerts. This allows for a tailored response mechanism that can evolve with the needs of <span class="No-Break">the infrastructure.</span></li>
				<li><strong class="bold">Integration with existing tools</strong>: It integrates well with the existing ecosystem of DevOps tools, providing seamless connectivity with monitoring solutions, alerting tools, and messaging platforms such <span class="No-Break">as Slack.</span></li>
				<li><strong class="bold">Open source community</strong>: Being open source, it allows developers and users to contribute to the tool, fostering a community-driven approach to enhancing <a id="_idIndexMarker1275"/>Kubernetes observability <span class="No-Break">and management.</span></li>
			</ul>
			<p>We will use the<a id="_idIndexMarker1276"/> enhancement <strong class="bold">ChatGPT</strong> bot [<em class="italic">7</em>] with a customizable playbook to make the Robusta tool even more effective. But let’s follow the next steps in the guide. We will use Prometheus and ChatGPT in our <span class="No-Break">following example.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout"><strong class="bold">Prometheus</strong> is an <a id="_idIndexMarker1277"/>open source monitoring and alerting toolkit widely used for its powerful querying language and ability to handle multi-dimensional data such as metrics from cloud and containerized environments, while <strong class="bold">ChatGPT</strong> is an<a id="_idIndexMarker1278"/> advanced AI language model <a id="_idIndexMarker1279"/>developed by <strong class="bold">OpenAI</strong>, capable of generating human-like text, engaging in conversation, answering questions, and providing information across a vast range <span class="No-Break">of topics.</span></p>
			<p>Let’s <span class="No-Break">get started:</span></p>
			<ol>
				<li>Install the <a id="_idIndexMarker1280"/>Robusta <span class="No-Break">Python CLI:</span><pre class="source-code">
python3 -m pip install -U robusta-cli --no-cache</pre></li>				<li>Generate a values file <span class="No-Break">for Helm:</span><pre class="source-code">
robusta gen-config</pre><p class="list-inset">You will be guided through all <span class="No-Break">necessary steps:</span></p><pre class="source-code">Configure Slack integration? This is HIGHLY recommended. [Y/n]: Y
If your browser does not automatically launch, open the below url:
https://api.robusta.dev/integrations/slack?id=05b9c718-7f2e-4749-82fe-c3f545266692
You've just connected Robusta to the Slack of: poc-chatgpt-kubernetes
Which slack channel should I send notifications to? # pocs
Configure MsTeams integration? [y/N]: N
Configure Robusta UI sink? This is HIGHLY recommended. [Y/n]: Y
Enter your Google/Gmail/Azure/Outlook address. This will be used to……</pre></li>				<li>In the newest<a id="_idIndexMarker1281"/> version, they validate the Helm over Helm lint, so you have to <span class="No-Break">add </span><span class="No-Break"><strong class="source-inline">clusterName</strong></span><span class="No-Break">:</span><pre class="source-code">
clusterName: "aks-excelsior-development-2"
globalConfig:
  signing_key: ea657a0b******
  account_id: 7935371f******
sinksConfig:
- slack_sink:
    name: main_slack_sink
    slack_channel: pocs
    api_key: xoxb******
enablePrometheusStack: true
enablePlatformPlaybooks: true
runner:
  sendAdditionalTelemetry: true
rsa:
  private: ******
  public: ******</pre><p class="list-inset">Then, you can <a id="_idIndexMarker1282"/>modify the  <strong class="source-inline">generated_values.yaml</strong>  file to create multiple triggers. For the showcase, I will keep it simple and apply it over helm in the <span class="No-Break">next step.</span></p></li>				<li>Install Robusta <span class="No-Break">with Helm:</span><pre class="source-code">
<strong class="bold">kubectl create ns robusta</strong>
<strong class="bold">helm repo add robusta https://robusta-charts.storage.googleapis.com &amp;&amp; helm repo update</strong>
<strong class="bold">helm install robusta robusta/robusta -f .generated_values.yaml</strong></pre></li>				<li>Run a demo to see if the trigger (<strong class="bold">Prometheus</strong>), action (<strong class="bold">Logs-Enricher</strong>), and sink (<span class="No-Break">Slack) work:</span><pre class="source-code">
k apply -n robusta -f https://raw.githubusercontent.com/robusta-dev/kubernetes-demos/main/pending_pods/pending_pod_resources.yaml</pre><p class="list-inset">Now, trigger the Prometheus alert or wait <span class="No-Break">5-10 minutes:</span></p><pre class="source-code">robusta playbooks trigger prometheus_alert alert_name=KubePodCrashLooping namespace=robusta pod_name=pending-pod-resources-579664598d-j6s9n</pre><p class="list-inset">You should receive a notification in Slack, as illustrated in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.6</em>, containing metainformation along with the <span class="No-Break">pod’s logs:</span></p></li>			</ol>
			<div>
				<div class="IMG---Figure" id="_idContainer185">
					<img alt="Figure 14.6 – Robusta with Slack as sink without ChatGPT" src="image/B22100_14_06.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.6 – Robusta with Slack as sink without ChatGPT</p>
			<ol>
				<li value="6">We now need to <a id="_idIndexMarker1283"/>include the playbook repository and integrate our custom playbook tailored for the ChatGPT action, <span class="No-Break">as follows:</span><pre class="source-code">
clusterName: "aks-excelsior-development-2"
globalConfig:
  chat_gpt_token: sk-dw******
  signing_key: ea657a******
  account_id: 7935371f******
sinksConfig:
- slack_sink:
    name: main_slack_sink
    slack_channel: pocs
    api_key: xoxb******
- robusta_sink:
    name: robusta_ui_sink
    token: eyJhY2NvdW******
enablePrometheusStack: true
# This part is added to the default generated_values.yaml
enablePlatformPlaybooks: true
runner:
  sendAdditionalTelemetry: true
rsa:
  private: ******
  public: ******
<strong class="bold"># This part is added to the default generated_values.yaml</strong>
<strong class="bold">playbookRepos:</strong>
  chatgpt_robusta_actions:
    url: "https://github.com/robusta-dev/kubernetes-chatgpt-bot.git"
<strong class="bold"># This part is added to the default generated_values.yaml</strong>
<strong class="bold">customPlaybooks:</strong>
<strong class="bold"># Add the 'Ask ChatGPT' button to all Prometheus alerts</strong>
- triggers:
  - on_prometheus_alert: {}
  actions:
  - chat_gpt_enricher: {}</pre><p class="list-inset">The highlighted section is the <span class="No-Break">additional part.</span></p></li>				<li>Now, you <a id="_idIndexMarker1284"/>should activate the Prometheus alert again using the <span class="No-Break">following code:</span><pre class="source-code">
robusta playbooks trigger prometheus_alert alert_name=KubePodCrashLooping namespace=robusta pod_name=pending-pod-resources-579664598d-j6s9n</pre></li>			</ol>
			<p>You should now be able to view the <strong class="bold">Ask ChatGPT</strong> button, as depicted in <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.7</em></span><span class="No-Break">:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer186">
					<img alt="Figure 14.7 – Robusta with Slack as sink with ChatGPT" src="image/B22100_14_07.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.7 – Robusta with Slack as sink with ChatGPT</p>
			<p>Upon clicking the button, you<a id="_idIndexMarker1285"/> should receive a detailed explanation regarding the occurrence, common causes, potential troubleshooting steps, and viable solutions, as illustrated in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.8</em>. This feature significantly aids developers by saving them considerable time and reducing the hassle involved in troubleshooting issues. Utilizing GitOps with Argo CD, you can deploy not only Robusta but also the extension across multiple clusters, as we have repeatedly demonstrated throughout <span class="No-Break">this book:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer187">
					<img alt="Figure 14.8 – Robusta with Slack as sink with ChatGPT: support" src="image/B22100_14_08.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.8 – Robusta with Slack as sink with ChatGPT: support</p>
			<p>Robusta aims to<a id="_idIndexMarker1286"/> simplify the operational complexity of managing Kubernetes clusters, making it easier for teams to <a id="_idIndexMarker1287"/>maintain <strong class="bold">high availability</strong> (<strong class="bold">HA</strong>), performance, and reliability of their containerized applications. By integrating with GitOps, Robusta enhances automation, ensures consistent environments through declarative configuration, and facilitates swift recovery and scalability, thereby streamlining the deployment process and reinforcing <span class="No-Break">infrastructure resilience.</span></p>
			<h3>Private LLM solution with iitsAI</h3>
			<p>With tools such as <strong class="bold">Robusta.dev</strong>, we already <a id="_idIndexMarker1288"/>have good support for observability and <strong class="bold">incident management</strong> (<strong class="bold">IM</strong>) in <a id="_idIndexMarker1289"/>Kubernetes environments, but how can we further enhance productivity, onboard new developers, and improve existing ones? We are introducing an additional tool <a id="_idIndexMarker1290"/>called <strong class="bold">iitsAI</strong>, from the <strong class="bold">iits-consulting</strong> company, operating <a id="_idIndexMarker1291"/>under <strong class="bold">iitsAI</strong>. This tool allows developers to supplement their own data sources on top of a pre-trained module such as <strong class="bold">Mistral 7B</strong> and <a id="_idIndexMarker1292"/>leverage <a id="_idIndexMarker1293"/>multiple <strong class="bold">large language models</strong> (<strong class="bold">LLMs; </strong><span class="No-Break"><strong class="bold">mixed models</strong></span><span class="No-Break">).</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout"><strong class="bold">Ollama</strong> is a <a id="_idIndexMarker1294"/>cross-platform framework that lets you use LLMs such as <strong class="bold">Mistral 7B</strong> locally on<a id="_idIndexMarker1295"/> <span class="No-Break">your computer.</span></p>
			<p class="callout">An <a id="_idIndexMarker1296"/>LLM is a type of AI program that can recognize and generate text, translate languages, write different kinds of creative content, and answer your questions in an <span class="No-Break">informative way.</span></p>
			<p class="callout">RAG is a technique<a id="_idIndexMarker1297"/> that improves the accuracy and reliability of <strong class="bold">generative AI</strong> (<strong class="bold">GenAI</strong>) models<a id="_idIndexMarker1298"/> by incorporating factual information from <span class="No-Break">external sources.</span></p>
			<p class="callout"><strong class="bold">Mistral 7B</strong> is a <a id="_idIndexMarker1299"/>7.3 billion-parameter <strong class="bold">neural network</strong> (<strong class="bold">NN</strong>) model trained on a massive dataset of text and<a id="_idIndexMarker1300"/> code that can perform various tasks, including generating text, translating languages, writing different kinds of creative content, and answering your questions in an <span class="No-Break">informative way.</span></p>
			<p class="callout"><strong class="bold">iitsAI</strong> offers <a id="_idIndexMarker1301"/>a private LLM solution that runs on Kubernetes within your <strong class="bold">own infrastructure</strong>, enriched with your <strong class="bold">own data</strong>, providing you with complete end-to-end control. Alternatively, you can choose the hosted version by iits, available through a <strong class="bold">sovereign cloud provider</strong> in Germany. Both solutions include <strong class="bold">single sign-on</strong> (<strong class="bold">SSO</strong>) and<a id="_idIndexMarker1302"/> fine-grained access control to the data through role mapping defined <span class="No-Break">by you.</span></p>
			<p>The functionality of LLMs is simplified <span class="No-Break">as follows:</span></p>
			<ul>
				<li>The helpers of LLMs are large NNs trained on massive amounts <span class="No-Break">of data</span></li>
				<li>Each LLM processes its part of the prompt and generates a response based on its knowledge <span class="No-Break">and abilities</span></li>
				<li>The responses from the LLMs are then merged to create a comprehensive and informative response for <span class="No-Break">the user</span></li>
			</ul>
			<p>This way, complex tasks can be broken down into smaller parts and processed in parallel by multiple LLMs. The result is faster and more efficient processing of the prompt. Imagine a prompt that gets split into pieces and sent to different <strong class="bold">AI helpers</strong>. Each <a id="_idIndexMarker1303"/>helper works on its piece, then all the answers are combined for a <span class="No-Break">final response.</span></p>
			<p>The tool built by iits provides the <span class="No-Break">following architecture:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer188">
					<img alt="Figure 14.9 – Ollama with RAG: service architecture [8]" src="image/B22100_14_09.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.9 – Ollama with RAG: service architecture [8]</p>
			<p class="callout-heading">Important note</p>
			<p class="callout"><strong class="bold">Weaviate</strong> is<a id="_idIndexMarker1304"/> an open source vector database that enables you to store data objects <span class="No-Break">and vectors.</span></p>
			<p class="callout"><strong class="bold">Airbyte</strong> is an <a id="_idIndexMarker1305"/>open source data integration platform that helps you move data between different sources <span class="No-Break">and destinations.</span></p>
			<p>The user inputs a prompt into a web UI, as they are accustomed to <a id="_idIndexMarker1306"/>with <strong class="bold">ChatGPT</strong>, which references a model<a id="_idIndexMarker1307"/> via <strong class="bold">Ollama</strong>, such as <strong class="bold">Mistral 7B</strong>, and <a id="_idIndexMarker1308"/>provides the base LLM model in the background. Then, <strong class="bold">iitsAI</strong> developed a <a id="_idIndexMarker1309"/>middleware to conserve resources and extract the best possible outcome from the prompt. The prompt is divided into slices, undergoes several iterations, and is processed through multiple <strong class="bold">LLMs</strong>. Here, the LLMs act as a vector<a id="_idIndexMarker1310"/> database (<strong class="bold">Weaviate</strong>), which connects to <strong class="bold">Airbyte</strong> through<a id="_idIndexMarker1311"/> a custom-developed connector or uses Airbyte to load documents from various sources and provide them to the LLM agents. In the end, the user receives a response to their inquiry based on the provided <a id="_idIndexMarker1312"/>documents, which looks <span class="No-Break">like this:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer189">
					<img alt="Figure 14.10 – iitsAI and logistics industry develop an internal knowledge base" src="image/B22100_14_10.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.10 – iitsAI and logistics industry develop an internal knowledge base</p>
			<p>The intriguing <a id="_idIndexMarker1313"/>aspect of the solution is that it operates on Kubernetes and is deployed using GitOps. Consequently, the entire solution, from the UI to loading the base model and provisioning the files, is managed by the companies themselves on their own infrastructure. This autonomy is crucial for European businesses when employing technologies such as AI, Kubernetes, <span class="No-Break">and GitOps.</span></p>
			<p>Let’s now <a id="_idIndexMarker1314"/>explore how it can be integrated with GitOps and the opportunities this <span class="No-Break">combination presents.</span></p>
			<p>In use case A (<span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.11</em>), a product provided to various customers can be delivered by the development team. <strong class="bold">Simultaneously</strong>, the team can supply a knowledge base to the customers on how to use the product. Users can then resolve all necessary queries using simple language requests without the need to sift through <span class="No-Break">external documentation:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer190">
					<img alt="" role="presentation" src="image/B22100_14_11.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.11 – iitsAI and custom app knowledge base</p>
			<p>For use case B (<span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.12</em>), as the platform team deploys the platform, they can also create an internal knowledge base about all the delivered tools, potential issues, releases, response times, FAQs, and so on, which can be accessed through a chat assistant <a id="_idIndexMarker1315"/>in <strong class="bold">natural language</strong> (<strong class="bold">NL</strong>). This not only boosts efficiency but also eliminates several iterative steps, such as contacting the service desk, which <a id="_idIndexMarker1316"/>typically involves searching the documentation provided and assisting at the first level <span class="No-Break">of support:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer191">
					<img alt="" role="presentation" src="image/B22100_14_12.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.12 – iitsAI and platform knowledge base</p>
			<p>Thanks to GitOps, the deployment is straightforward and can be scaled across clusters. Moreover, the GitOps approach aids in conserving resources since LLMs are <strong class="bold">GPU-intensive</strong>. It <a id="_idIndexMarker1317"/>supports setups such as those shown in <span class="No-Break"><em class="italic">Figure 14</em></span><em class="italic">.13</em>, where only the UI is deployed on the workload cluster, while the middleware, the vector database, and the base model can operate on a service cluster that <a id="_idIndexMarker1318"/>provides <strong class="bold">GPU </strong><span class="No-Break"><strong class="bold">node pools</strong></span><span class="No-Break">:</span></p>
			<div>
				<div class="IMG---Figure" id="_idContainer192">
					<img alt="" role="presentation" src="image/B22100_14_13.jpg"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.13 – iitsAI split UI and LLMs backend to save resources</p>
			<p>As we can see, GitOps offers us tremendous flexibility at this juncture, reminding us of our <strong class="bold">Kubernetes Service Catalog</strong> (<strong class="bold">KSC</strong>) from previous chapters and how one can control their<a id="_idIndexMarker1319"/> stack using <a id="_idIndexMarker1320"/>labels. This allows for even more finely-grained control of the deployments. By now integrating AI, as just demonstrated, we can proactively assist with troubleshooting and provide an interactive knowledge base, hopefully making the added <span class="No-Break">value clear.</span></p>
			<p>In the next section, we will explore potential challenges and opportunities associated with the future use <span class="No-Break">of GitOps.</span></p>
			<h1 id="_idParaDest-285"><a id="_idTextAnchor289"/>Future challenges and opportunities in GitOps</h1>
			<p>In this section, it’s crucial to <a id="_idIndexMarker1321"/>address the collaborative dynamics and the overarching strategy required when multiple teams converge within the same operational framework, especially when they are required to share resources such as a repository. The key is to establish clear protocols from the outset, defining what is permissible and what needs coordination, much like setting contribution guidelines that dictate the sequence and considerations <span class="No-Break">for changes.</span></p>
			<p>This approach is reflective of <a id="_idIndexMarker1322"/>the <strong class="bold">open source software</strong> (<strong class="bold">OSS</strong>) model, where contributors worldwide collaborate effectively on a project without it being owned by a single entity. Such a model underscores the potential of GitOps to harmonize efforts across diverse teams, transcending the traditional boundaries of DevOps. GitOps aims to unify development, operations, finance, sustainability, privacy, security, and other disciplines, enabling them to deliver a cohesive and robust <span class="No-Break">product collectively.</span></p>
			<p>Sustainability is poised to play a significant role in the realm of GitOps. Unlike traditional <strong class="bold">continuous integration/continuous deployment</strong> (<strong class="bold">CI/CD</strong>) pipelines that may run based on code<a id="_idIndexMarker1323"/> changes, GitOps frequently reconciles the actual state of the system with the desired state <a id="_idIndexMarker1324"/>defined in Git. While this ensures consistency and <strong class="bold">reliability</strong>, it also means that as the number of applications grows, resource consumption might increase correspondingly. This necessitates a thoughtful approach to how GitOps practices can be optimized to mitigate environmental impact without compromising the efficiency and reliability of the system. The future of GitOps will likely see innovations that allow it to scale sustainably, managing resource consumption wisely while maintaining <strong class="bold">high standards</strong> of automated, consistent, and declarative <span class="No-Break">infrastructure management.</span></p>
			<h1 id="_idParaDest-286"><a id="_idTextAnchor290"/>The role of GitOps in emerging technologies</h1>
			<p>In the rapidly <a id="_idIndexMarker1325"/>evolving landscape of technology, GitOps stands out as a pivotal methodology, particularly in the realm of emerging technologies. It represents a paradigm shift, emphasizing the use of Git as an SSOT and automating the deployment process, thereby intertwining development and operations more closely than ever before. This methodology is becoming increasingly vital as organizations navigate the complexities of modern software deployment, especially in cloud-native environments and when dealing with innovative technologies. This list summarizes the role of GitOps in <span class="No-Break">emerging technologies:</span></p>
			<ul>
				<li><strong class="bold">Enhancing cloud-native ecosystems</strong>: As organizations increasingly adopt cloud-native technologies, the complexity of managing these environments <a id="_idIndexMarker1326"/>grows. GitOps provides a structured, predictable method of managing this complexity, using version control to manage the entire state of the cloud-native infrastructure. This is particularly beneficial for Kubernetes, serverless architectures, and service mesh technologies, where configuration and state are critical. GitOps not only simplifies the management of these technologies but also enhances security, auditability, and transparency, which are paramount in <span class="No-Break">cloud-native ecosystems.</span></li>
				<li><strong class="bold">Facilitating edge computing</strong>: With the rise of edge computing, managing numerous remote environments consistently and securely has become a challenge. GitOps offers a way to deploy and manage applications across various edge locations reliably. By keeping configurations in Git, organizations can ensure that changes are traceable, verifiable, and automatically deployed, reducing the potential for human error and increasing <span class="No-Break">operational efficiency.</span></li>
				<li><strong class="bold">Accelerating AI and machine learning (ML) operations</strong>: The integration of GitOps in AI and ML operations streamlines the deployment of complex AI models and the continuous delivery of ML infrastructure. It ensures that data scientists and ML engineers can focus on model development and experimentation without worrying about the underlying infrastructure. GitOps automates the deployment process, ensuring consistent, repeatable, and reliable delivery of <span class="No-Break">AI applications.</span></li>
				<li><strong class="bold">Supporting Internet of Things (IoT) deployments</strong>: IoT involves managing a vast number of devices, each potentially running different software versions. GitOps can play a crucial role in automating the deployment and management of software across these devices, ensuring consistency, reliability, and security at scale. The declarative approach of GitOps means that the desired state of the IoT infrastructure can be version-controlled and automatically applied, reducing the complexity and increasing the scalability of <span class="No-Break">IoT operations.</span></li>
				<li><strong class="bold">Enhancing security in DevSecOps</strong>: In the DevSecOps world, integrating security into the <strong class="bold">development and operations life cycle</strong> is crucial. GitOps supports this by ensuring that all changes are reviewed, approved, and traceable through Git. This facilitates <strong class="bold">rigorous audit trails</strong>, quick rollbacks in case of <a id="_idIndexMarker1327"/>issues, and a more secure infrastructure deployment pipeline, thereby enhancing the overall security posture of <span class="No-Break">the organization.</span></li>
			</ul>
			<p>GitOps is not just a trend but a fundamental shift in how we manage emerging technologies. It bridges the gap between development and operations, ensuring faster, more secure, and more reliable software delivery. As we continue to embrace new technologies and face new challenges, the principles of GitOps provide a solid foundation for managing the complexity of modern IT environments, making it an indispensable tool in the arsenal of today’s <span class="No-Break">technology leaders.</span></p>
			<h1 id="_idParaDest-287"><a id="_idTextAnchor291"/>Summary</h1>
			<p>In this chapter, we hopefully gained clarity on how GitOps, through the use of various tools, enables both economic and ecological action. The importance of cultural change in the adoption of GitOps should also have become evident, as it allows numerous teams to collaborate and autonomously deploy tools, policies, and so on that align with the company’s interests. While interpreting future trends isn’t straightforward, the potential unlocked by combining the discussed AI tools should now be apparent. Ultimately, GitOps serves to deploy, expand, and maintain various tools or policies from different teams across a distributed cluster landscape or logically grouped clusters <span class="No-Break">at scale.</span></p>
			<p>In <em class="italic">Implementing GitOps with Kubernetes</em>, we have taken a hands-on approach to explore scalable and straightforward solutions grounded in real-world scenarios. From foundational concepts to advanced implementations, this book has aimed to equip you with the knowledge and tools necessary to harness the full potential of GitOps within Kubernetes environments. Through practical examples, insights from industry experts, and detailed explanations of best practices, we hope you now feel prepared to implement GitOps <span class="No-Break">strategies effectively.</span></p>
			<p>As you conclude this book, the next step is to apply what you’ve learned to real-world projects. Experiment with different tools, refine your workflows, and continually seek ways to optimize and secure your deployments. Stay engaged with the community, keep up with the latest trends, and never <span class="No-Break">stop learning.</span></p>
			<p>We wish you the best of luck on your GitOps journey ahead. May you achieve new heights in operational excellence, scalability, and innovation. Thank you for joining us on this journey, and we wish you success in all your GitOps endeavors. Wishing you all the best, Pietro <span class="No-Break">and Artem.</span></p>
			<h1 id="_idParaDest-288"><a id="_idTextAnchor292"/>References</h1>
			<ul>
				<li>[<span class="No-Break"><em class="italic">1</em></span><span class="No-Break">] </span><a href="https://github.com/opencost/opencost"><span class="No-Break">https://github.com/opencost/opencost</span></a></li>
				<li>[<span class="No-Break"><em class="italic">2</em></span><span class="No-Break">] </span><a href="https://github.com/kubecost"><span class="No-Break">https://github.com/kubecost</span></a></li>
				<li>[<span class="No-Break"><em class="italic">3</em></span><span class="No-Break">] </span><a href="https://github.com/PacktPublishing/GitOps-for-Kubernetes-Deployment"><span class="No-Break">https://github.com/PacktPublishing/</span></a><span class="No-Break">Implementing-GitOps-with-Kubernetes</span></li>
				<li>[<span class="No-Break"><em class="italic">4</em></span><span class="No-Break">] </span><a href="https://github.com/kube-green/kube-green"><span class="No-Break">https://github.com/kube-green/kube-green</span></a></li>
				<li>[<span class="No-Break"><em class="italic">5</em></span><span class="No-Break">] </span><a href="https://github.com/armadaproject/armada"><span class="No-Break">https://github.com/armadaproject/armada</span></a></li>
				<li>[<span class="No-Break"><em class="italic">6</em></span><span class="No-Break">] </span><a href="https://home.robusta.dev"><span class="No-Break">https://home.robusta.dev</span></a></li>
				<li>[<span class="No-Break"><em class="italic">7</em></span><span class="No-Break">] </span><a href="https://github.com/robusta-dev/kubernetes-chatgpt-bot"><span class="No-Break">https://github.com/robusta-dev/kubernetes-chatgpt-bot</span></a></li>
				<li>[<span class="No-Break"><em class="italic">8</em></span><span class="No-Break">] </span><a href="https://github.com/iits-consulting/otc-terraform-template"><span class="No-Break">https://github.com/iits-consulting/otc-terraform-template</span></a></li>
			</ul>
		</div>
	</body></html>