- en: '9'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '9'
- en: Managing Incidents Using Alerts
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用警报管理事件
- en: This chapter will explore the concepts of **incident management**. We will discuss
    how to build a world-class incident management process, which treats those responding
    to incidents humanely and avoids burnout. The chapter will establish the responsibilities
    for this, from the senior leadership teams to the engineers responding to the
    callout. It will introduce the important concepts of building an organization
    that can handle incidents and excel at providing customers with a stable experience.
    With the process established, we’ll explain how to consider a service and pick
    critical measures that can be used to see the current service level, without being
    drowned out by noise.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将探讨**事件管理**的概念。我们将讨论如何建立一个世界级的事件管理流程，这个流程既能人性化地对待事件响应人员，又能避免他们的过度疲劳。章节将明确这一责任，从高级领导团队到响应呼叫的工程师。它还将介绍建立一个能够处理事件并为客户提供稳定体验的组织的重要概念。在流程建立之后，我们将解释如何考虑服务并挑选关键指标，以便查看当前的服务水平，而不会被噪音所干扰。
- en: This chapter will also explore the three tools available from Grafana for incident
    management. First, there’s **Grafana Alerting**, which is used to monitor metrics
    and logs for failures and trigger notifications to responding teams. Then, there’s
    **Grafana OnCall**, which expands on the features of Alerting with a dedicated
    mobile app for alerts, team schedules, and the ability to receive alerts from
    any third-party application that can send webhook data. OnCall lets you centralize
    all alerts for visibility and route them to the right response team. Finally,
    there’s **Grafana Incident**, which provides an easy-to-use incident tracking
    tool that keeps all highlighted information ready for your post-incident activities,
    helping your organization focus on improvements that prevent incidents.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章还将探讨Grafana提供的三个用于事件管理的工具。首先是**Grafana Alerting**，用于监控指标和日志中的故障，并触发通知给响应团队。然后是**Grafana
    OnCall**，它在Alerting的基础上扩展了功能，提供了一个专门的移动应用，用于处理警报、团队排班，并且可以接收任何第三方应用通过Webhook发送的警报。OnCall让你能够集中所有警报，方便查看并将其路由到正确的响应团队。最后是**Grafana
    Incident**，提供了一个易于使用的事件跟踪工具，帮助你准备好所有关键的信息，便于事后活动，帮助组织专注于防止事件发生的改进。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: Being alerted versus being alarmed – how to build great incident management
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 警觉与惊慌——如何建立优秀的事件管理
- en: Writing great alerts using **service-level indicators** (**SLIs**) and **service-level**
    **objectives** (**SLOs**)
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用**服务级指标**（**SLI**）和**服务级目标**（**SLO**）编写优秀的警报
- en: Grafana Alerting
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grafana Alerting
- en: Grafana OnCall
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grafana OnCall
- en: Grafana Incident
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grafana Incident
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we will go into technical details, aimed at readers such as
    *Ophelia Operator*, *Diego Developer*, and *Steven Service* (who represent operators,
    developers, and service delivery professionals, as introduced in [*Chapter 1*](B18277_01.xhtml#_idTextAnchor018)),
    and which may be of interest to readers such as *Masha Manager* (in leadership),
    to understand what is possible with Grafana’s tools and how they support established
    incident management.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将深入探讨技术细节，面向如*Ophelia Operator*、*Diego Developer*和*Steven Service*（他们代表了运营人员、开发人员和服务交付专业人员，如在[*第1章*](B18277_01.xhtml#_idTextAnchor018)中介绍的），并且可能对*玛莎经理*（领导层）等读者有所帮助，帮助他们了解Grafana的工具能做什么，以及它们如何支持已建立的事件管理。
- en: Being alerted versus being alarmed
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 警觉与惊慌
- en: Incident management is a common process used in many areas, from physical incidents
    such as fire and medical emergencies to computer security or service failure.
    While we may not handle life-threatening incidents in the computing world, the
    stress caused by bad incident management processes can be very significant, from
    anxiety and depression to complete burnout, and it can increase the chance of
    heart attacks and strokes. Our aim in this section is to explain how observability
    and Grafana’s tools fit into an incident management strategy, and how to use them
    to reduce the impact on your teams, the duration of incidents, and the frequency
    of incidents. We will explore the details of these concepts and the tools available
    in Grafana to support them further throughout the chapter.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 事故管理是许多领域中常用的过程，从火灾和医疗紧急情况等物理事故到计算机安全或服务故障。尽管在计算机领域我们可能不会处理危及生命的事故，但糟糕的事故管理流程所带来的压力是非常显著的，从焦虑和抑郁到彻底的精疲力竭，甚至可能增加心脏病和中风的风险。本节的目的是解释可观测性和Grafana工具如何融入事故管理策略，以及如何利用它们减少对团队的影响、缩短事故持续时间并降低事故发生的频率。在本章中，我们将进一步探讨这些概念的细节以及Grafana提供的支持工具。
- en: 'There are a lot of great public resources available on the topic of incident
    management; here are some for you to explore if you wish:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 事故管理这一主题有许多很好的公共资源可供利用；如果你愿意，可以探索以下资源：
- en: '*Emergency response and recovery* ([https://www.gov.uk/government/publications/emergency-response-and-recovery](https://www.gov.uk/government/publications/emergency-response-and-recovery)):
    This is guidance given to the emergency services in the UK. While most of you
    will not be handling incidents that involve risks to life or property, this document
    is a fantastic read for anyone looking to understand how to make incidents as
    easy as possible to handle.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*紧急响应与恢复* ([https://www.gov.uk/government/publications/emergency-response-and-recovery](https://www.gov.uk/government/publications/emergency-response-and-recovery)):
    这是英国对紧急服务提供的指南。虽然你们大多数人不会处理涉及生命或财产风险的事故，但这份文件是任何希望了解如何尽可能轻松应对事故的人的绝佳读物。'
- en: '*Atlassian Incident Handbook* ([https://www.atlassian.com/incident-management/handbook](https://www.atlassian.com/incident-management/handbook)):
    The *Atlassian Incident Handbook* is a great place to start when writing or reviewing
    an incident management process.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Atlassian事故手册* ([https://www.atlassian.com/incident-management/handbook](https://www.atlassian.com/incident-management/handbook)):
    *Atlassian事故手册*是编写或审查事故管理流程时的一个极好的起点。'
- en: '*What is incident management?* ([https://www.servicenow.com/uk/products/itsm/what-is-incident-management.html](https://www.servicenow.com/uk/products/itsm/what-is-incident-management.html)):
    Similar to the *Atlassian Incident Handbook*, the ServiceNow incident management
    guide is a great place to start when writing or reviewing an incident management
    process.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*什么是事故管理？* ([https://www.servicenow.com/uk/products/itsm/what-is-incident-management.html](https://www.servicenow.com/uk/products/itsm/what-is-incident-management.html)):
    类似于*Atlassian事故手册*，ServiceNow的事故管理指南也是编写或审查事故管理流程时的一个极好的起点。'
- en: '*Google Site Reliability Engineering* ([https://sre.google/sre-book/managing-incidents/](https://sre.google/sre-book/managing-incidents/)
    and [https://sre.google/workbook/incident-response/](https://sre.google/workbook/incident-response/)):
    Google''s *Site Reliability Engineering* books are packed with helpful information.
    Most organizations will not be running services at the same scale as Google, but
    these give a clear view of creating a highly scalable incident management process.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Google网站可靠性工程* ([https://sre.google/sre-book/managing-incidents/](https://sre.google/sre-book/managing-incidents/)
    和 [https://sre.google/workbook/incident-response/](https://sre.google/workbook/incident-response/)):
    Google的*网站可靠性工程*书籍充满了有用的信息。大多数组织不会像Google那样以同样的规模运营服务，但这些书籍清晰地展示了如何创建一个高度可扩展的事故管理流程。'
- en: This may seem like an oversimplification of incident management, but we will
    group these concepts into *before*, *during*, and *after* an incident.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这可能看起来是对事故管理的过于简化，但我们将这些概念分为*事故前*、*事故中*和*事故后*。
- en: Before an incident
  id: totrans-20
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事故前
- en: As the mantra says, “*Hope for the best, and prepare for the worst*.” Knowing
    how you will respond to an incident before it happens is crucial to responding
    effectively to an incident when it happens. In this section, we will discuss various
    aspects that need to be in place before an incident occurs.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 正如口号所说，“*期望最好的结果，准备最坏的情况*”。在事故发生之前，知道你将如何响应事故，对于在事故发生时有效地做出反应至关重要。在本节中，我们将讨论事故发生前需要落实的各个方面。
- en: Roles and responsibilities
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 角色和职责
- en: 'Incidents are messy, quickly evolving situations, and they are no place to
    be trying to figure out who is doing what. Roles and responsibilities for your
    organization’s incident response must be clearly documented and understood by
    everyone who *may* be called on to respond to an incident. It is not advisable
    to reinvent the wheel for incident management; there are several frameworks available,
    including the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 事件是混乱且迅速发展的情况，不适合在此时分辨谁在做什么。你组织的事件响应角色和责任必须被清晰文档化，并且所有可能被要求响应事件的人都应理解这些责任。在事件管理方面，重新发明轮子并不可取；有几种框架可供参考，包括以下几种：
- en: '**Information Technology Infrastructure Library** (**ITIL**) incident management'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**信息技术基础设施库**（**ITIL**）事件管理'
- en: '**Site Reliability Engineering** (**SRE**) incident management'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**站点可靠性工程**（**SRE**）事件管理'
- en: The **National Institute of Standards and Technology** (**NIST**) incident response
    framework
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**国家标准与技术研究院**（**NIST**）事件响应框架'
- en: The **SysAdmin, Audit, Network, and Security** (**SANS**) incident response
    framework
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统管理员、审计、网络和安全**（**SANS**）事件响应框架'
- en: 'There are some key roles that appear in all of these:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这些框架中有一些关键角色是共同出现的：
- en: '**Commander**: This is the person who has the authority to make decisions.
    These are some key features of this role:'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指挥官**：这是有权做出决策的人员。此角色的一些关键特点如下：'
- en: The range of decisions will be different for each incident, but the commander
    needs to be able to call in the correct people, sign off on communications to
    customers, and handle internal communications with senior leadership
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个事件的决策范围会有所不同，但指挥官需要能够召集正确的人，批准与客户的沟通，并处理与高级领导的内部沟通
- en: This is also the person who has overall control of an incident
  id: totrans-31
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这个人还掌控着整个事件的管理
- en: All other roles report to this person
  id: totrans-32
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 所有其他角色都向此人汇报
- en: '**Communications**: This is the person who is responsible for internal and
    external communications. These are some key features of the communications role:'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**沟通**：这是负责内部和外部沟通的人员。以下是沟通角色的一些关键特点：'
- en: Communicating effectively during an incident is vital for success, and this
    person is responsible for managing that
  id: totrans-34
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在事件中有效沟通对成功至关重要，这个人负责管理这一点
- en: Internal and third-party communications are their responsibility
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内部和第三方沟通是他们的责任
- en: Customer-facing communication is also their responsibility
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 面向客户的沟通也是他们的责任
- en: '**Technical leader**: This person is vital for directing the many technical
    people who may be involved in an incident. Some key features of technical leadership
    during an incident are as follows:'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**技术领导者**：此人对于指导可能涉及到事件的许多技术人员至关重要。事件中的技术领导力的一些关键特点如下：'
- en: When multiple people from multiple teams are investigating a problem, it’s important
    for one person to make the technical calls
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当多个团队的多人在调查一个问题时，一个人负责做出技术决策是非常重要的
- en: The technical leader needs to know who in the technical teams is looking at
    what and when to expect updates on findings
  id: totrans-39
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 技术领导者需要知道技术团队中的每个人在做什么，以及何时能获得最新的发现更新
- en: 'The roles outlined in these frameworks are very focused at the **operational**
    (*bronze*) level. The UK emergency services have documented a very effective command
    structure, **gold–silver–bronze**, which outlines responsibilities for **tactical**
    (*silver*) and **strategic** (*gold*) levels. It is valuable to be clear about
    the responsibilities of executive or senior leaders and their subordinates *before*
    any incidents are handled. This ensures everyone involved in an actual incident
    knows how to bring in the correct leaders when needed. What we mean here is that
    it’s better to have a plan that can handle a major incident that causes serious
    harm to an organization than to realize you need one during the incident. Let’s
    explore these levels in greater detail:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些框架中列出的角色非常侧重于**操作**（*铜*）层级。英国紧急服务已文档化了一种非常有效的指挥结构，**金银铜**，该结构概述了**战术**（*银*）和**战略**（*金*）层级的职责。在处理任何事件之前，明确高层或高级领导以及下属的责任是很有价值的。这能确保在实际事件中，所有相关人员都知道如何在需要时调动正确的领导者。我们的意思是，最好有一个可以应对造成严重损害的重大事件的计划，而不是在事件发生时才意识到需要一个。我们将更详细地探讨这些层级：
- en: '**Gold – strategic responsibilities**: Gold teams are made up of senior managers
    or the C-suite. Members of the gold team should always keep their focus on the
    strategic level and not get drawn into making tactical decisions. The main responsibilities
    of gold teams are as follows:'
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**金色团队 – 战略职责**：金色团队由高级经理或高层管理团队（C-suite）组成。金色团队的成员应始终保持关注战略层面，而不是被引入战术决策。金色团队的主要职责如下：'
- en: Set, review, and communicate the incident management strategy
  id: totrans-42
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置、审查并沟通事件管理战略
- en: Define whether any resources or specialist skills are needed
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义是否需要任何资源或专业技能
- en: Handle the media strategy
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理媒体策略
- en: Consider the legal issues that may arise from any incidents
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 考虑事件可能引发的法律问题
- en: Report to shareholders where appropriate
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在适当的情况下向股东报告
- en: Approve the silver team’s tactical plans before they are used
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在银色团队的战术计划使用之前进行审批
- en: Lead the de-brief or postmortem after an incident
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件后进行总结或事后检讨
- en: '**Silver – tactical responsibilities**: Silver teams are composed of managers
    from different departments. They provide tactical leadership for bronze teams,
    make decisions on how to implement the strategic vision set out by gold teams,
    and, during incidents, act as the conduit for information to flow between gold
    and bronze teams. Silver teams are responsible for the following:'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**银色团队 – 战术职责**：银色团队由不同部门的经理组成。他们为铜色团队提供战术领导，做出如何执行金色团队设定的战略愿景的决策，并且在事件发生时，作为信息流动的中介，连接金色团队和铜色团队。银色团队的职责包括：'
- en: Set, review, and communicate the tactical plan for incidents up and down the
    chain of command
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置、审查并沟通事件的战术计划，上下指挥链之间
- en: Document the incident management procedures
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 记录事件管理程序
- en: Capture how communication with customers should be handled
  id: totrans-52
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 捕捉与客户沟通应如何处理
- en: Choose the appropriate tools to manage incidents
  id: totrans-53
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择合适的工具来管理事件
- en: Understand which teams will be meeting which strategic objectives
  id: totrans-54
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 了解哪些团队将实现哪些战略目标
- en: Address any resource needs in critical teams
  id: totrans-55
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解决关键团队中的任何资源需求
- en: Update the gold team with any relevant information during an incident
  id: totrans-56
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在事件发生期间，向金色团队更新任何相关信息
- en: '**Bronze – operational responsibilities**: The bronze team is the team that
    is responsible for responding to an incident, from the initial alert to the conclusion
    of the post-incident process. The bronze team’s responsibilities include the following:'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**铜色团队 – 操作职责**：铜色团队负责响应事件，从初始警报到事件后的过程结束。铜色团队的职责包括以下内容：'
- en: Taking operational control of the incident
  id: totrans-58
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 承担事件的操作控制
- en: Informing the silver team when an incident is declared
  id: totrans-59
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当事件被声明时，通知银色团队
- en: Understanding the cause of an incident
  id: totrans-60
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解事件的根本原因
- en: Making decisions on how to resolve an incident
  id: totrans-61
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 做出解决事件的决策
- en: Communicating internally and externally within the tactical plan
  id: totrans-62
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在战术计划中进行内部和外部沟通
- en: Completing post-incident reports and meetings to address any ongoing issues
  id: totrans-63
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 完成事件后的报告和会议，处理任何持续的问题
- en: Cutting noise to improve the signal during incidents
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在事件中减少噪音，以提高信号
- en: It is impossible to know how an incident will occur and what the root cause
    will be. When they do occur, getting the right information quickly and communicating
    effectively are two very important factors in recovering from the incident as
    quickly as possible.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 无法预测事件将如何发生以及其根本原因是什么。当事件发生时，快速获取正确信息并有效沟通是两个非常重要的因素，有助于尽快从事件中恢复。
- en: 'The first place to reduce noise is in **observability systems**, which makes
    it easier to identify important signals. Doing this requires knowledge of a service,
    which is why it is best to do this before an incident occurs. The following practices
    can help engineers such as *Diego* share the detailed domain knowledge of their
    application with the wide experience of systems from engineers such as *Ophelia*
    and *Steven*:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 减少噪音的第一步是在**可观察性系统**中，这可以帮助更容易地识别重要信号。做到这一点需要了解服务，因此最好在事件发生之前就进行这一操作。以下做法可以帮助像*Diego*这样的工程师与像*Ophelia*和*Steven*这样的系统工程师共享其应用程序的详细领域知识：
- en: Identifying and documenting critical SLIs
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定并记录关键的SLI（服务级指标）
- en: Using distributed traces, so all calls can be seen in service graphs
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用分布式跟踪，这样所有调用都可以在服务图中看到
- en: Writing log messages that are easy to understand
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写易于理解的日志消息
- en: Writing logs that handle failures without producing lots of messages
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 编写能够处理故障的日志，而不会产生大量信息
- en: A lot of observability tools offer some form of **AIOps**; these effectively
    offer a tool that watches the standard flow of data and highlights times when
    something deviates from the previously seen data. This should not be treated as
    a reason for not identifying critical signals, as these tools do not replace specific
    domain knowledge in our experience.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 很多可观察性工具提供某种形式的**AIOps**；这些工具实际上是监控数据标准流并突出显示偏离先前数据的时间点。这不应被视为不识别关键信号的理由，因为这些工具在我们的经验中并不能替代特定领域的知识。
- en: 'The second form of noise that can occur is the inappropriate use of **communication
    channels**. Many of us will have seen messages such as *Is the site down right
    now?* in a Slack or Teams channel, dedicated to notifying us of incidents when
    they become a problem on a user’s computer. Noise and lack of signal can occur
    for customers as well, either repeatedly notifying customers of every minor blip,
    or more likely, not informing customers when an incident occurs. Getting these
    communications correct is a core part of an incident management strategy. Common
    practices include the following:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 可能发生的第二种噪声是**通信渠道**的不当使用。我们当中很多人可能曾在Slack或Teams频道中看到类似*现在网站宕机了吗？*的消息，这些频道本应专门用于通知我们当用户计算机上发生问题时的事故。噪声和缺乏信号同样会影响客户，可能会反复通知客户每一个小的波动，或者更常见的是，在事故发生时未能通知客户。正确的沟通是事件管理策略的核心部分。常见的做法包括：
- en: Giving a dedicated group of people authority to declare an incident and its
    severity
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 赋予专门的团队宣告事故及其严重性的权限。
- en: Automating the communication response to an incident when declared – for example,
    updating a customer-visible status page and posting in a dedicated internal communications
    channel
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在事件被宣告时自动化沟通响应——例如，更新客户可见的状态页面并在专用的内部沟通渠道中发布。
- en: Setting up protected internal channels of communication for incident teams (*bronze*)
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 为事件团队建立受保护的内部沟通渠道（*铜级*）。
- en: Setting up protected channels of communication between incident teams and senior
    leadership (*bronze* to *silver* and *silver* to *gold*)
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在事件团队与高级领导之间建立受保护的沟通渠道（*铜级*到*银级*，*银级*到*金级*）。
- en: Pre-writing status messages so that incident teams only select the most appropriate
    message for most consumers
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 预写状态消息，以便事件团队可以为大多数消费者选择最合适的消息。
- en: Supporting tools
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 支持工具。
- en: 'The adage that a bad workman always blames their tools is very appropriate
    here; there is no *perfect* tool and what works for one organization may not work
    for another, and there are many tools on the market. This is a list of capabilities
    that we believe all organizations should consider as part of their incident management
    strategy:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: “工人总是把坏工作归咎于工具”这一格言在这里非常适用；没有*完美*的工具，一个组织有效的工具可能对另一个组织无效，市场上有许多工具。这是我们认为所有组织在其事件管理策略中应考虑的一些功能：
- en: Alert notification – sending a page to the person on call. Also, consider mobile
    apps for out-of-hours notification.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 警报通知——向值班人员发送通知页面。同时，考虑使用移动应用进行非工作时间的通知。
- en: Process automation.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流程自动化。
- en: On-call rota management.
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 值班排班管理。
- en: Integration with other systems.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与其他系统的集成。
- en: Automatically capturing internal communications during an incident.
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动捕捉事件期间的内部沟通。
- en: Running practice or drill incidents.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 进行演练或模拟事故。
- en: Escalation processes.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 升级流程。
- en: Customer-facing communication during an incident.
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件发生期间与客户的沟通。
- en: Now that you have a lot of knowledge on preparing for the worst, let’s look
    at these plans in action during an incident.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经掌握了准备应对最坏情况的知识，让我们在事件发生时实际应用这些计划。
- en: During an incident
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 事件发生期间。
- en: Incidents happen, as much as we would prefer that they didn’t. In this section,
    we’ll discuss some key tasks that help make the process of resolving incidents
    as painless as possible.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 事故是不可避免的，尽管我们更希望它们不发生。在本节中，我们将讨论一些关键任务，帮助尽可能无痛地解决事件。
- en: Identifying the incident
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 识别事件。
- en: There are many failure modes that can be seen in computer systems, from immediate
    lights-out outages through cascading failures to intermittent failures. Having
    clear information to say when a service is behaving *as expected* is vital to
    identifying issues. It is the responsibility of domain experts such as *Diego*
    or *Ophelia* to write this information into software services, or ensure they
    are provided by systems from third parties, such as compute, storage, or network
    services. There are some common ways of capturing this information, including
    **white-box monitoring techniques** and **black-box** **monitoring techniques**.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机系统中可以观察到许多故障模式，从即时停机故障到级联故障，再到间歇性故障。拥有清晰的信息来说明服务是否按预期*正常运行*，对于识别问题至关重要。这是像*Diego*或*Ophelia*这样的领域专家的责任，他们需要将这些信息写入软件服务中，或确保它们由第三方系统提供，例如计算、存储或网络服务。捕获这些信息有一些常见的方式，包括**白盒监控技术**和**黑盒**
    **监控技术**。
- en: 'White-box monitoring is the practice of monitoring a system that you have access
    to. This practice helps identify whether a service is healthy, with detailed information
    of the state of the service. Here are some ways of presenting metrics that are
    commonly used in this process:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 白盒监控是指监控你有权限访问的系统。这种做法有助于识别服务是否健康，并提供有关服务状态的详细信息。以下是常用的几种呈现指标的方式：
- en: '**Rate, Errors, Duration (RED)**: This is a way of measuring services that
    are driven by requests. *Rate* is a measure of the volume of requests the service
    handles in a period. *Errors* is the number of requests that are encountering
    errors. *Duration* is the distribution of request durations, and it’s common to
    represent this as a set of percentiles or a histogram.'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**速率、错误、持续时间（RED）**：这是衡量由请求驱动的服务的一种方式。*速率*是服务在一段时间内处理的请求量。*错误*是遇到错误的请求数量。*持续时间*是请求持续时间的分布，通常将其表示为一组百分位数或直方图。'
- en: With these three signals, we can quickly compare the current state with a “normal”
    state, checking whether any service has a higher or lower number of requests hitting
    it, whether it has a higher than usual number of errors, or whether the duration
    of the requests are longer or shorter. With that knowledge, the incident response
    team can identify services that need further investigation.
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过这三个信号，我们可以快速将当前状态与“正常”状态进行比较，检查是否有服务接收到更多或更少的请求，是否有比平常更多的错误，或者请求的持续时间是否更长或更短。有了这些知识，事故响应团队可以识别出需要进一步调查的服务。
- en: RED is a great system to use for any service that responds to requests, such
    as a web server.
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: RED 是一个非常适合用于任何响应请求的服务系统，比如 web 服务器。
- en: '**Utilization, Saturation, Errors (USE)**: USE and RED are complementary to
    each other; RED looks at the requests to a service, and USE looks at the internal
    state of the service. *Utilization* measures the number of resources the service
    is using to process work (we’ll talk about resources shortly). *Saturation* is
    the amount of work that the service cannot process due to a lack of resources.
    *Errors* is the number of errors that are being produced. We’ve used the term
    *resources* here; these will be different in each service, and identifying them
    is an area for domain expertise. Common resources would be CPU and RAM availability,
    network or disk I/O, or even the number of threads available in an application.'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**利用率、饱和度、错误（USE）**：USE 和 RED 是相辅相成的；RED 关注服务的请求，而 USE 关注服务的内部状态。*利用率*衡量服务处理工作所使用的资源数量（稍后我们会讨论资源）。*饱和度*是服务因资源不足而无法处理的工作量。*错误*是产生的错误数量。我们在这里使用了“资源”这个术语；不同的服务会有不同的资源，识别这些资源是领域专家的工作。常见的资源包括
    CPU 和内存的可用性、网络或磁盘 I/O，甚至应用程序中可用的线程数量。'
- en: USE is best-suited to model a service that offers a resource, such as a storage
    system or Kubernetes cluster.
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: USE 最适合用于建模提供资源的服务，如存储系统或 Kubernetes 集群。
- en: '**Golden signals**: Golden signals were introduced in the Google SRE book,
    and they overlap very strongly with RED and USE. The golden signals are **latency**,
    **traffic**, **errors**, and **saturation**.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**黄金信号**：黄金信号在 Google 的 SRE 书中被引入，并且与 RED 和 USE 有很强的重叠。黄金信号包括**延迟**、**流量**、**错误**和**饱和度**。'
- en: '*Errors* and *saturation* are the same as described in RED and USE. *Traffic*
    is the measure of requests per second, so is equivalent to the rate from RED.
    *Latency* is the time it takes to service a request; this is like duration from
    RED. However, latency also captures whether a request is successful or not. This
    signal allows for differentiation between situations where a duration may be lower
    because the error is returned very quickly and the more challenging scenario of
    a service taking a long time to give an error.'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*错误*和*饱和度*与RED和USE中描述的一样。*流量*是每秒请求的度量，相当于RED中的速率。*延迟*是处理请求所需的时间；这类似于RED中的持续时间。然而，延迟还捕捉到请求是否成功。这一信号可以区分以下两种情况：一种是持续时间较短，因为错误被迅速返回；另一种是服务需要很长时间才返回错误的更具挑战性的情况。'
- en: '**Core web vitals**: The previous views of services were driven by the backend
    systems. Core web vitals are a set of metrics that are gathered from an end user’s
    browser, usually using a **Real User Monitoring** (**RUM**) agent such as Grafana
    Faro, which is embedded into web applications to collect data. This set of metrics
    is very focused on the end user experience for web applications.'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**核心网页重要指标**：以前对服务的视图是由后端系统驱动的。核心网页重要指标是一组从终端用户的浏览器收集的度量，通常使用**真实用户监控**（**RUM**）代理，如Grafana
    Faro，它嵌入到Web应用程序中以收集数据。这组指标非常关注Web应用程序的终端用户体验。'
- en: 'The current core web vitals include the following:'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当前的核心网页重要指标包括以下内容：
- en: '**Largest Contentful Paint (LCP)**: LCP measures the loading performance of
    a web page; it is a measure of when the largest element on a page is rendered.
    Historically similar metrics such as First Contentful Paint, First Meaningful
    Paint, Load, DOMContentLoaded, and SpeedIndex have been used; LCP is the current
    recommendation from Google’s web.dev team.'
  id: totrans-103
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**最大内容绘制（LCP）**：LCP衡量网页的加载性能；它是衡量页面上最大元素被渲染的时间。历史上，类似的度量指标如首个内容绘制、首次有意义绘制、加载、DOMContentLoaded和SpeedIndex也曾被使用；LCP是谷歌web.dev团队当前的推荐指标。'
- en: '**First Input Delay (FID)**: FID measures the interactivity of a page; it is
    a measure from when a user first interacts with a page to when the browser can
    process the event handlers in response.'
  id: totrans-104
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**首次输入延迟（FID）**：FID衡量页面的交互性；它是从用户首次与页面互动到浏览器能够处理事件处理程序响应的时间。'
- en: '**Cumulative Layout Shift (CLS)**: CLS measures how frequently the content
    rendered on a page changes position because another element was rendered.'
  id: totrans-105
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**累积布局偏移（CLS）**：CLS衡量页面上渲染的内容因另一个元素被渲染而改变位置的频率。'
- en: 'In contrast to white-box monitoring, black-box monitoring treats a service
    as an unknown and checks whether it is behaving as an end user would see it. There
    are broadly two categories of black-box monitoring:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 与白盒监控相对，黑盒监控将服务视为一个未知的实体，并检查它是否按照终端用户所看到的行为。黑盒监控大致分为两类：
- en: '`ping`), and **Google Remote Procedure Call** (**gRPC**). Other services on
    the market can also simulate critical user journeys if more granular external
    monitoring is needed. Where **service-level agreement** (**SLA**) adherence is
    a contractual obligation of an organization, using a third-party synthetic tool
    is a very easy way of proving that the SLA was (or was not) adhered to. This tool
    is offered as a managed service as part of Grafana Cloud as **Synthetic Monitoring**.
    All functionality except gRPC calls are supported.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ping`）和**谷歌远程过程调用**（**gRPC**）。市场上的其他服务也可以模拟关键用户旅程，如果需要更精细的外部监控。这种情况下，如果**服务级别协议**（**SLA**）的遵守是组织的合同义务，使用第三方合成工具是一种非常简单的方式来证明SLA是否被遵守。这个工具作为**合成监控**，是Grafana
    Cloud的一项托管服务提供的。除了gRPC调用，所有功能均受支持。'
- en: '**RUM** uses an agent embedded in frontend code to collect data from real end
    users using a service. While RUM offers much broader functionality than just black-box
    monitoring, it can also be used to provide the initial alert based on the actual
    experience of end users.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**RUM**使用嵌入在前端代码中的代理来收集实际终端用户使用服务的数据。虽然RUM提供的功能比单纯的黑盒监控更广泛，但它也可以用于根据终端用户的实际体验提供初步的警报。'
- en: Black-box monitoring does come with a risk of false positives. While white-box
    monitoring only covers items that are under the control of the organization such
    as internal networks, cloud-provided services, and so on, black-box monitoring
    must cover areas outside of control such as external internet provider networks
    or DNS services.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 黑盒监控确实存在误报的风险。虽然白盒监控仅覆盖组织控制范围内的项目，如内部网络、云服务等，黑盒监控则需要涵盖控制范围外的领域，如外部互联网提供商的网络或DNS服务。
- en: By using common groups of signals and clearly defining these critical SLIs for
    each service, organizations can effectively transfer the knowledge of a service’s
    health from domain experts to others in the organization. Detailed how-to guides
    commonly known as **runbooks**, which detail responses to situations, also transfer
    this knowledge. Finally, a robust post-incident process effectively allows organizations
    to step away from a *hero culture*. A hero culture is when a small group of individuals
    keep things working by responding to every incident, often at the expense of their
    health. A mature organization is one that moves from the chaos of frequent incidents
    to one that gives highly motivated individuals, and the organization as a whole,
    space to grow.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用常见的信号群组，并为每个服务明确这些关键的SLI，组织可以有效地将服务健康状况的知识从领域专家传递给组织中的其他人员。详细的操作手册（通常被称为**运行手册**），详细说明了应对各种情况的方式，也起到了知识传递的作用。最后，一个健全的事件后处理流程有效地帮助组织摆脱了*英雄文化*。英雄文化是指一小部分人通过响应每一个事件来维持运转，往往以牺牲健康为代价。一个成熟的组织应从频繁的事件混乱中走向一个能够为高度积极的个体及整个组织提供成长空间的阶段。
- en: Once our monitoring has notified us that there is something wrong, the next
    questions are *who* to bring into the incident and *when*.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦我们的监控系统通知我们出现问题，接下来的问题是*谁*应该参与事件处理，以及*何时*参与。
- en: Escalating an incident
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 事件升级
- en: 'If an incident can be resolved quickly with only the on-call person being involved,
    this is ideal. Unfortunately, some incidents need to be escalated, whether that
    is because someone with more specialized knowledge is needed, or because the scale
    of the incident is too large for one person to handle. Each organization is different,
    and a clear escalation policy needs to be part of the tactical plan for incidents.
    An escalation policy should give clear guidance and answer these questions:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 如果一个事件仅需值班人员参与就能快速解决，那是理想的。遗憾的是，有些事件需要升级处理，无论是因为需要更专业的知识，还是事件的规模超出了一个人能处理的范围。每个组织都有不同的情况，因此明确的事件升级政策必须是应急计划的一部分。升级政策应提供清晰的指导，并回答以下问题：
- en: Who should be notified when an issue is identified by an automated system?
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当自动化系统识别到问题时，应该通知谁？
- en: Does this change during in-hours and out-of-hours?
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在工作时间和非工作时间，这个决定是否会有所不同？
- en: Does this change depending on severity?
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件的严重程度是否会影响此决定？
- en: Who should be notified if the first responder isn’t available?
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果第一响应者不可用，应该通知谁？
- en: Who should take over if a first responder can’t resolve an issue alone?
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果第一响应者无法单独解决问题，应该由谁接手？
- en: What criteria are used to make that decision?
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 做出该决定时使用了哪些标准？
- en: The duration of the incident?
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件的持续时间？
- en: The severity level of the incident?
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件的严重程度？
- en: The time of day of the incident?
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件发生的时间？
- en: How should the handover of an incident occur?
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 事件的交接应该如何进行？
- en: What happens if there are multiple incidents at one time?
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果同时发生多个事件，会发生什么？
- en: With this guidance in place, it is the responsibility of leadership (*Masha*)
    to make sure everyone who is on call knows the policy. This is especially important
    for junior engineers who may feel that they need to avoid disturbing more senior
    colleagues. There is also a responsibility to regularly audit on-call schedules
    and ensure engineers on call are protected from overwork and burnout from the
    schedule.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些指导方针，确保所有值班人员了解政策是领导层（*玛莎*）的责任。特别是对于那些可能觉得需要避免打扰资深同事的初级工程师来说，这一点尤其重要。此外，还需要定期审核值班时间表，确保值班工程师不会因工作安排而过度疲劳或精疲力尽。
- en: Communication
  id: totrans-126
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 通信
- en: 'During an incident, communication is critical. We can split communication into
    three broad strands:'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在事件处理中，沟通至关重要。我们可以将沟通分为三个大类：
- en: '**Incident team communication**: Most organizations use some combination of
    in-person or video meeting rooms and chat tools. There are a few considerations
    that should be taken to make this communication easy during an incident:'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**事件团队沟通**：大多数组织使用面对面或视频会议室和聊天工具的组合。在发生事件时，有几个考虑因素需要纳入，以确保沟通顺畅：'
- en: What is the primary communication channel to tell someone to join an incident?
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通知某人加入事件的主要沟通渠道是什么？
- en: A chat channel, phone call/SMS, or mobile app (e.g., Grafana OnCall or PagerDuty)
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 聊天频道、电话/SMS 或移动应用（例如 Grafana OnCall 或 PagerDuty）
- en: Is there a primary conference bridge video meeting?
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 是否有主要的会议桥接视频会议？
- en: Make sure the details are included in any alerts sent on the primary communication
    channels
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保在主要沟通渠道发送的任何警报中都包含详细信息
- en: What is the expected response time for people called into an incident?
  id: totrans-133
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 召集人员进入事件的预期响应时间是多少？
- en: This has an impact on the time to recovery
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这会影响恢复时间
- en: This also has an impact on the health and well-being of people regularly called
    into incidents, which should be monitored
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这同样会影响经常被召集参与事件的人员的健康和福祉，需要进行监控
- en: How are team communications recorded for post-incident review?
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 团队沟通如何记录以便事后回顾？
- en: Peoples’ recollection will become fuzzy as the time between an incident and
    the post-incident review increases. Capturing communications is a good way of
    managing this to ensure that the post-incident process is as accurate as possible.
    The tools that can be used to make this process as simple as possible during an
    incident are very valuable to the entire incident management process.
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随着事件与事后回顾之间的时间增加，人们的记忆会变得模糊。记录沟通内容是管理这一点的好方法，确保事后回顾尽可能准确。在事件发生期间使用能够简化这一过程的工具对整个事件管理过程非常有价值。
- en: There are tools and processes to assist here. Grafana Incident will track a
    timeline of events from tools such as Slack. The communications and technical
    leads of an incident should also be responsible for regular status updates, which
    should be made with a post-incident review in mind.
  id: totrans-138
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 这里有工具和流程可以帮助。Grafana Incident 会跟踪来自 Slack 等工具的事件时间线。事件的沟通和技术负责人还应负责定期更新状态，这些更新应考虑到事后回顾。
- en: '**Internal communication**: The communications lead of a major incident is
    responsible for internal communication. For most channels, the tactical plan for
    incidents should specify a frequency of updates. This communication typically
    does not need to go into a lot of detail; even saying, “*We are still investigating
    the issue and working to resolve it*” is better than being silent. This communication
    is equally important during incidents of internal tooling as well.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内部沟通**：重大事件的沟通负责人负责内部沟通。对于大多数渠道，事件的战术计划应指定更新的频率。这类沟通通常不需要详细说明；即使仅仅说“*我们仍在调查问题并努力解决它*”，也比保持沉默要好。内部工具发生事件时，这种沟通同样重要。'
- en: The communications lead should keep senior stakeholders such as the gold and
    silver teams informed of the current state in more detail. As silver teams will
    typically include technical and managerial leadership for the products that may
    be the cause of the incident, this channel is especially important for escalating
    and bringing in experts where needed. Following the same primary communication
    channel for incident notification is the best practice – that is, if escalation
    is a case of notifying the correct on-call rota, then incidents can be resolved
    more quickly. However, this does come with the cost of placing more engineers
    on call.
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 沟通负责人应向高级利益相关者（如金银团队）详细通报当前状况。由于银团队通常包括可能是事件原因的产品的技术和管理领导，这个渠道对于在需要时升级并引入专家尤为重要。遵循相同的主要沟通渠道进行事件通知是最佳实践——也就是说，如果升级是通知正确的值班人员，那么事件可以更快速地解决。然而，这也意味着需要更多工程师值班。
- en: '**Customer communication**: This is likely the most important because when
    incidents affect external customers, it is important to get a message out quickly
    to reassure an organization’s customers that you are on top of the issue and working
    on restoring service. There are a whole host of options for communication with
    customers:'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**客户沟通**：这可能是最重要的，因为当事件影响外部客户时，迅速发出信息向客户保证组织正在积极处理问题并恢复服务至关重要。与客户沟通的方式有很多种：'
- en: Status pages, either dedicated and separate from the organization’s service
    or embedded into it
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Email notifications
  id: totrans-143
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Social media
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: SMS notifications
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Messages on any customer ticket management portal
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: During an incident, the communications lead should have a selection of pre-generated
    and approved messages for customers, with little need to modify the message. This
    helps keep the tone and feel of the messages correct, even if the communications
    lead has just been woken up at 3 a.m. It is also useful to have a message that
    informs customers there may be a problem but you are investigating; this is ideal
    for situations where you’ve been alerted to a situation but you’re unsure whether
    there is an actual impact on customers.
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: With all these things in place, you will have put your organization in a great
    place to resolve incidents quickly and let the team go back to bed. After the
    incident, the arguably harder pieces of work will begin, such as understanding
    why the incident happened and communicating how the organization is going to fix
    any underlying causes. Let’s explore how to approach this.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: After an incident
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Incidents happen to big organizations and small organizations; even organizations
    that have been meticulous in avoiding incidents will experience them. The most
    important thing from any incident is for the organization, as a whole, to learn
    about the vulnerabilities in a system or the gaps in processes that led to the
    incident.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: When incidents happen, it can be natural to look for a person or a department
    to blame; this human tendency is in direct contradiction to an organization’s
    best interest. Blame leads to burdensome procedures, a lack of innovation, and
    ultimately, to the organization’s stagnation, as staff stop being honest and seek
    to ensure they are not blamed, demoted, or even fired.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '**Blameless postmortems** are a space for an honest and objective examination
    of what happened, with the goal of understanding the true root cause(s). Good
    intentions from all staff and departments must be assumed. It is critical to understand
    that the goal of a blameless postmortem is not to remove accountability from an
    individual or team but to ensure that accountability is not accompanied by the
    fear of reprimands, job loss, or public shaming. The important aspects of a blameless
    postmortem include the following:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
- en: Open communication where mistakes are accepted as a part of life
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Encouraging honesty and the acceptance of failure
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharing detailed information on the timeline of events, which should be supported
    by the logs of internal communication and systems during the incident
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Making decisions and seeking approval for improvements
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are many guides that detail these processes in much greater detail than
    we have gone into here; our goal is to introduce those of you who fit the personas
    to the broad topic of incident response. We will now discuss in more detail how
    the practices of observability and the tools of Grafana can help build part of
    a great incident response plan. We will start this by looking more deeply at SLIs,
    as well as SLOs.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: Writing great alerts using SLIs and SLOs
  id: totrans-158
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An **SLI** is a measurement that is used to indicate a current service level.
    An example could be the number of errors over a 15-minute period.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: It is best practice to keep the number of SLIs small; three to five SLIs for
    a service is a good rule of thumb to follow. This reduces confusion and allows
    teams to focus on what is critical for their service. SLIs can also be thought
    of as a **fractal** concept; while a service team can have indicators for a component
    of a larger system, the system can also be tracked by a small number of SLIs –
    for example, the number of services that are failing their SLOs. By keeping the
    number of SLIs tracked relatively small, the potential for spurious alerts is
    reduced, and the impact of continuously monitoring services is kept small. This
    means more services can be monitored without scaling the tools used and increasing
    operating costs.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: The patterns we discussed earlier of RED, USE, golden signals, and core web
    vitals are good SLIs to consider when deciding what to track. These are not the
    only measures that can be used as SLIs, but they have good adoption in the industry
    and are well understood. Teams should think hard about whether they need to use
    something different.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: By agreeing on SLIs and objectives, the process of writing a great alert becomes
    much simpler, as the person implementing the alert only needs to consider how
    to translate the business description of the SLI (the number of errors in a 15-minute
    period) into a query, using LogQL or PromQL, and then create a threshold based
    on the set objective. Alerts written this way will also be easy to understand.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Another important concept is the SLO, which refers to an internally agreed-upon
    target that is considered acceptable for an SLI. An example would be no more than
    3% of requests resulting in errors during a 10-minute period.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: While not directly related to incident alerting, there is the concept of **error
    budgets**, which are strongly related to a good SLO setting. An error budget is
    an SLO that measures the meeting of other SLOs. When the error budget is exceeded,
    this is a good indicator that a service is unstable in some way, and this should
    serve as a trigger for focusing the team’s energy on remediating this. Conversely,
    if the error budget is high, this should give the team the space to experiment,
    or even take the service down in a planned way. This can be a great opportunity
    to expose issues that could be catastrophic if they were seen in an unplanned
    outage. This topic is discussed in much greater detail in publications that discuss
    SRE.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: An SLA is an agreement made with clients or users on what is acceptable for
    the service. These can be legal agreements. These are often made up of multiple
    SLIs and SLOs. An example would be an uptime of 99.9%. Setting objectives with
    SLOs helps an organization keep easily within their legally agreed SLAs, which
    is a great way to ensure that the SLAs are very rarely breached and customers
    feel they can trust your organization.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: We’ve explored the theory of a good incident response strategy and the choices
    to make, from the team level to the organization level, to support it. Let’s now
    take a look at the three tools Grafana offers to support incident response, Grafana
    Alerting, OnCall, and Incident.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: Grafana Alerting
  id: totrans-167
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Grafana Alerting** is the first of three major components of Grafana’s **Incident
    Response and Management** (**IRM**) toolset. Grafana Alerting itself comes with
    no additional licensing costs, and it is an ideal solution for smaller organizations
    while forming the foundation of the IRM tools in larger organizations.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: 'The IRM features can be accessed from the main Grafana menu under the **Alerts
    &** **IRM** tab:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.1 – The Grafana Alerts & IRM main screen](img/B18277_09_1.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
- en: Figure 9.1 – The Grafana Alerts & IRM main screen
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Grafana Alerting continuously evaluates user-created **alert rules** for alert-worthy
    states, following predefined steps to send messages to the chosen notification
    channel.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will see how to set up alert rules, get your contact points and notification
    policies right, silence alerts when needed, and set up teams and team members.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: Alert rules
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The main configuration screen for Grafana Alerting is the **Alert Rules** screen.
    This allows you to set up new rules and see the current state of existing rules.
    Setting up a rule should feel very familiar after learning LogQL and PromQL in
    *Chapters 4* and *5,* respectively.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: 'Setting up an alert rule requires several items to be configured; let’s walk
    through those now:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '**Set the alert rule name and define the query and alert condition**: First,
    a query is created and named; in our example, we have used the following query
    for a period of 10 minutes:'
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-178
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'This will calculate the percentage of all requests in the period that were
    completed, with a status code of `5xx`, which is the SLI. In the `3`, which is
    the SLO. The following screenshot shows the screen where these items can be filled
    in:'
  id: totrans-179
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.2 – Creating an alert rule](img/B18277_09_2.jpg)'
  id: totrans-180
  prefs: []
  type: TYPE_IMG
- en: Figure 9.2 – Creating an alert rule
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: '**Set the alert evaluation behavior**: With our SLI and SLO set, we now need
    to decide how we want Grafana to evaluate its next action. Grafana has three states
    an alert rule can be in – **normal**, **pending**, and **firing**. The **alert
    evaluation behavior** manages how an alert rule group will transition between
    states. An evaluation group will sequentially evaluate each rule in the group
    with the same evaluation period. In our example, we have created a frontend group,
    which would contain the RED metrics from the frontend service. As our frontend
    service is business-critical, the evaluation period is set to 1 minute, and our
    pending period is set to 5 minutes. With these settings, if our error percentage
    goes over 3, our rule will enter the pending state within 1 minute, and our alert
    will trigger within 5 minutes if the state persists. This can be seen in the next
    screenshot.'
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'It is very tempting to set these values as low as possible (10 seconds); however,
    this can have unintended consequences. Running the queries every minute would
    result in 1,440 queries per day, while every 10 seconds would give 8,640 queries
    per day. While compute power is relatively cheap, this still increases the resources
    required by Grafana by six and probably offers little advantage. Another consideration
    is the interaction of this frequency and the query period. If we evaluated every
    five minutes but our query only looked at the last minute, we would have minutes
    that were not evaluated, which could disguise legitimate intermittent errors.
    Let’s look at the lower part of the screen to manage an alert rule:'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 9.3 – Managing an alert rule](img/B18277_09_3.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
- en: Figure 9.3 – Managing an alert rule
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: '**Add annotations**: Annotations are used to add information that will be sent
    to the contact point when an alert triggers. It is good practice to include easy-to-read
    summaries that capture key information, such as which service is involved and
    what the problem is. The description should give more detail if needed, and it
    is best practice to include a runbook URL and dashboard link. These should guide
    a responder to quickly understand the problem and give information on remedial
    steps they can follow to quickly restore a service.'
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Configure notifications**: The **Configure notifications** section provides
    space to add labels. These can be used to manage alert routing, which we will
    cover when we discuss notification policies. Clicking the **Preview Routing**
    button will give information on how an alert will be routed with its current configuration.'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next few tabs in the **Alerting** menu allow us to configure other aspects
    of Grafana Alerting. These are smaller items than the main alert rules. Let’s
    take a look at them now.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: Contact points, notification policies, and silences
  id: totrans-189
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Contact points** are configured by Grafana admins. They consist of a name
    and one or more integrations. It’s typical for a contact point to be a team responsible
    for addressing an issue. With some of the integrations available, such as webhooks
    and Kafka message queues, it is relatively easy to establish more complex contacts
    that go beyond just alerting. In more complex environments, Grafana offers the
    option of creating notification templates on the **Contact points** page. These
    can be used to standardize the message structure across multiple contact points
    and integrations. Grafana provides a great guide to setting up custom notifications
    here: [https://grafana.com/docs/grafana/latest/alerting/manage-notifications/template-notifications/](https://grafana.com/docs/grafana/latest/alerting/manage-notifications/template-notifications/).'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '`service_name` label from the services in the OpenTelemetry Demo. Rules at
    the same level of nesting can also continue matching, meaning the service team
    and a central operations team can both be notified.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '**Silences** are defined periods when no notifications will be created. These
    can be used to manage maintenance periods when using Grafana Alerting.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: Groups and admin
  id: totrans-193
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The **Groups** section shows grouped alerts. Grafana will also display alerts
    here for data sources that have defined alerts but are not sending data.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: The admin page provides the configuration for Alertmanager in JSON format; this
    allows administrators to save a configuration and transfer it to other instances,
    or to use it as a configuration backup.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: Grafana OnCall
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Grafana OnCall** is the second major component of IRM and expands on Grafana
    Alerting, by adding capabilities to do the following:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
- en: Consume alert notifications from many external monitoring systems
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specify alert groupings to reduce noise during incidents
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Specify when alert groups should send notifications
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define on-call rotations and escalation paths
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Expand notification channels from what is offered in Grafana Alerting:'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create and update tickets in ServiceNow, Jira, and Zendesk
  id: totrans-203
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Notify the current on-call individual directly
  id: totrans-204
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Provide a mobile application for engineers to handle on-call responsibilities
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All features of Grafana OnCall are included with an IRM user license. A Cloud
    Free subscription includes access for three users. Both the Pro and Advanced accounts
    include access to 5 users; additional users are billed at $20 per month at the
    time of writing.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will look at alert groups and how to set up integrations
    for inbound and outbound data flow. We will also explore the templating language
    used in Grafana OnCall and how to manage escalation chains.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Alert groups
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'All alerts that flow into Grafana OnCall are grouped into **alert groups**.
    These groups can consist of one or more individual alerts, and the grouping behavior
    is managed by the integration template that is being applied. We will discuss
    templating after looking at integrations. An alert group can be in one of the
    following states at any time – **firing**, **acknowledged**, **silenced**, or
    **resolved.** Actions taken by on-call engineers or escalation chains can transition
    the state of an alert group. An alert group will look like this:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.4 – The alert group anatomy](img/B18277_09_4.jpg)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
- en: Figure 9.4 – The alert group anatomy
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: This web view mirrors the functionality available to on-call engineers via integrated
    communications channels, the mobile app, phone calls, and SMS. Alert groups can
    easily be acknowledged, unacknowledged, silenced, or resolved. Engineers can also
    notify additional responders if they need to bring in another team, declare an
    incident to trigger the processes in Grafana Incident (which is discussed later
    in this chapter), or combine alert groups if they are all related, meaning that
    cleaning up after an incident is much easier.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: Inbound integrations
  id: totrans-213
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The tools to set up an **inbound integration**, or **alert source**, are under
    the **Integrations** option. These interactions are used to send alert information
    from an external source to Grafana OnCall. There are currently over 20 integrations,
    and inbound webhooks can be used to integrate with any system that can send them.
    Clicking on **New Integration** will begin the process of connecting to a new
    alert source; we will use Grafana Alerting as our source, as we have just explored
    it. First, give the integration a name and description, and then select an alert
    manager and a contact point. Grafana OnCall is able to integrate with any Prometheus-compatible
    alert manager; a default alert manager is configured in Grafana Cloud, called
    *Grafana*. Finally, click **Create Integration** and you will see the following
    screen:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.5 – Grafana alerting integration](img/B18277_09_5.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
- en: Figure 9.5 – Grafana alerting integration
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: The **HTTP endpoint** is used to configure the alert source to send alerts to.
    If you need assistance in configuring a specific integration, the **How to connect**
    link offers additional information. To test the integration, the **Send demo**
    alert will create a test alert.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: The `grouping ID` field from the value in the `payload.groupKey` field. Similarly,
    the alert group will be resolved if `payload.status` is `resolved`. This means
    that the source of the alert can also send a resolution update as well.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: The next sections, **Web**, **Phone**, **Slack**, **Telegram**, **Email**, and
    **MS Teams**, hold the template for how a notification about an alert group will
    be sent to these ChatOps integrations.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: Adding routes allows you to select an escalation chain, based on a Jinja routing
    template for each alert group that originates from the integration. This is achieved
    by clicking on the **Add route** button. Routes also include the option to publish
    to any ChatOps integrations that have been configured.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: Another important function available on the triple dot menu on the integration
    page is the ability to start a maintenance period. Maintenance can be either a
    debug, which silences all escalation, or standard maintenance, which collects
    all alerts into one alert group.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Let’s cover templating and escalation chains next.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Templating
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Jinja** is a templating language with many useful features to parse multiple
    alerts in an alert group, enabling valuable information to be seen quickly in
    the messages sent to those on call. Here are some of the features and syntax of
    the language:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '**Loops**: The syntax for a loop is this:'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'We can then use the following Jinja template:'
  id: totrans-227
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'This will result in this output:'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '**Conditions**: Conditions can be constructed with this syntax:'
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '`time`: The current time'
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`tojson_pretty`: JSON prettified'
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`iso8601_to_time`: Converts time from `iso8601` (`2015-02-17T18:30:20.000Z`)
    to datetime format'
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`datetimeformat`: Converts time from datetime to the given format (`%H:%M`/`%d-%m-%Y`
    by default)'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`regex_replace`: Performs a regex find and replace'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`regex_match`: Performs a regex match, and returns `True` or `False`'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`b64decode`: Performs a Base64 string decode'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-`) to the start or end of a block to remove all white space before or after
    it. If `seq = [1,2,3,4,5,6,7,8,9]`, we can write this as follows:'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-241
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Without this white space management, it would be rendered as follows:'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE6]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Jinja also offers the ability to trim functions, which can remove white space
    as well. If you want to maintain white space, adding a plus sign (`+`) will indicate
    that it should be retained.
  id: totrans-244
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For more information on Jinja, please check out the website: https://jinja.palletsprojects.com.'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand how to use templates to format payloads and messages,
    let’s take a look at escalation chains.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: Escalation chains
  id: totrans-247
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Escalation chains** let us set up standard workflows for alert groups. This
    is great for routing alerts based on the severity or content of the alert, the
    time of day, or other factors. There are a number of steps that can be set up:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: '`Wait`: Wait for a specified amount of time and then continue to the next step.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Notify users`: Send a notification to a user or a group of users.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Notify users from on-call schedule`: Send a notification to a user or a group
    of users from an on-call schedule.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Resolve incident automatically`: Resolve the alert group right now with the
    status `Resolved automatically`.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Notify whole Slack channel`: Send a notification to a Slack channel.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Notify Slack User Group`: Send a notification to a Slack user group.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Trigger outgoing webhook`: Trigger an outgoing webhook.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Notify users one by one (round robin)`: Each notification will be sent to
    a group of users one by one, in sequential order and round-robin fashion.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Continue escalation if current time is in range`: Continue the escalation
    only if the current time is in a specified range. This can be used to pause escalations
    outside of working hours.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Continue escalation if >X alerts per Y minutes` (beta): Continue the escalation
    only if it passes some threshold.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Repeat escalation from beginning` (`5 times max`): Loop the escalation chain.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When a notification is sent to a user, either directly, via an on-call schedule,
    or via a round-robin, then the user’s personal notification steps are followed.
    These can be managed by the user. The user’s page will highlight the status of
    notification steps for all users; any users who have not configured notifications
    will be marked with a warning.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Outbound integrations
  id: totrans-261
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Grafana OnCall offers several ways to perform **outbound integration**, which
    involves integrating external tools so that outbound messages can be sent, either
    to a messaging tool or any system that can receive a webhook. There are two types
    of such integration:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '**ChatOps**, which are integrations that include Slack, Telegram, and MS Teams.
    These are configured via **Settings** | **ChatOps**.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Webhooks**: These outgoing Webhooks provide the ability to integrate with
    any system that can receive them, and they are triggered from events in OnCall.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following screenshot shows how to set up a webhook in Grafana OnCall:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.6 – Configuring an outbound webhook](img/B18277_09_6.jpg)'
  id: totrans-266
  prefs: []
  type: TYPE_IMG
- en: Figure 9.6 – Configuring an outbound webhook
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: Webhooks can be triggered from an escalation step, or when an alert group is
    created or transitions to particular states.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Schedules
  id: totrans-269
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Schedules** are the way Grafana OnCall manages who is on call from each team.
    These are very easy to set up, and they offer you the ability to have a standard
    rotation schedule and set up any overrides. Schedules will also notify a Slack
    channel about the current on-call shift and any unassigned shifts. The **New Schedule**
    screen is shown in the following screenshot:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 9.7 – Setting up a new schedule](img/B18277_09_7.jpg)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
- en: Figure 9.7 – Setting up a new schedule
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s look at Grafana Incident.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Grafana Incident
  id: totrans-274
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The final major component of Grafana’s IRM offering is **Incident**. This tool
    helps simplify and automate many aspects of the incident management tactical plan.
    The tool integrates with an organization’s chat tooling, such as Slack, and offers
    you the ability for team members to declare incidents in that tool.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: Once an incident is declared, Grafana Incident can automatically start a video
    conference, update status page tools, add context to the incident timeline from
    GitHub, and so on, depending on the integrations that have been configured. Team
    members of the incident can specify who takes what role in the incident and specify
    and assign tasks during the incident. As the incident evolves, Grafana Incident
    will record important information in a timeline, which can be published and easily
    reviewed in regular post-incident reviews.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: To begin using Grafana Incident in Grafana cloud, an administrator needs to
    agree to a few integrations being set up initially. It is also good to set up
    integrations with a messaging tool such as Slack and a video conferencing tool
    such as Zoom, as Grafana Incident will use these when an incident is declared.
    A new incident bridge will be created in video conferencing, and the tool can
    record chat messages when instructed so that they are available for a post-incident
    review. Where applicable, integrations with Statuspage, GitHub, and Jira should
    also be configured; these can update Statuspage, record the state of pull requests
    and issues, and manage bug tickets, respectively. We expect the list of available
    integrations to expand as this tool matures.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at how Grafana Incident is used during an incident:'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: '**During an incident**: During an incident, a commander and multiple investigators
    can be assigned. Predefined tags can be associated with the incident, and a severity
    can be set. Investigators can then record text updates in the incident timeline,
    as well as relevant queries, alerts, and panels visited. The tool will then collect
    all relevant chats, text updates, queries run, alerts that were fired, and panels
    that were used during the incident. Investigators can also fire outbound webhooks
    that have been configured. The incident screen includes a task list, and links
    to relevant resources can also be attached.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**After an incident**: The information collected during an incident is collated
    into a timeline of the incident. The timeline for this incident can then be reviewed.
    Grafana Incident also collates standard metrics, which can be viewed at a higher
    level on the **Insights** page.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The **Insights** page shows high-level metrics for all incidents in the last
    90 days by default. It is best practice for the silver leadership teams in organizations
    to review this page as part of a regular formal process, reporting to gold teams.
    This helps to ensure that incidents are being handled well and remediation work
    is being scheduled by teams, reducing the frequency and impact of incidents on
    an organization.
  id: totrans-281
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Grafana offers several AI and **machine learning** (**ML**) tools to help incident
    management:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '**Suggestbot**: This tool uses **Natural Language Processing** (**NLP**) to
    analyze the conversation during an incident and will suggest dashboards that have
    titles that are related to the subject that is being discussed.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**OpenAI integration**: This is a public preview tool at the time of writing.
    Its aim is to speed up the tedious process of writing post-incident summaries.
    The tool uses OpenAI’s ChatGPT to distill the incident timeline into a summary,
    which can be fine-tuned. An OpenAI account is required to use this integration.
    This integration can produce the following:'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A summarized description of incidents
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: An event timeline of what happened leading up to an incident
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Details of the actions that were taken to resolve an incident
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ML Forecasting**: This tool will forecast the future state of metrics based
    on the learned models of past states. This is only available for metric data (either
    from Prometheus, Graphite, or Loki metrics queries). These forecasts can be used
    in dashboards or to drive alerts.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ML Outlier Detection**: This tool builds a model of what *normal* looks like
    for a metric and will highlight when metrics are outside of this normal range.
    These outliers can be used in alerting.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ML Sift**: Sift is also a public preview tool. This is a powerful tool for
    incident management, as it will interrogate telemetry from infrastructure and
    help identify critical details that may be drowned out in the noise of an incident.
    Sift will look for the following:'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Patterns in error logs
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Crashes in Kubernetes clusters
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Noisy Kubernetes nodes, which have high loads
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Containers that have resource throttling
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Deployments that occurred recently
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Slow requests seen in Tempo
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: You should now feel confident in being prepared for and responding to incidents
    using the tools provided by Grafana.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-298
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we have seen how to establish a great incident management process,
    which will help you evaluate and work on your organization’s own process. We have
    also explored SLIs, SLOs, and SLAs and how to use them, seeing immediately whether
    a service is responding successfully or not. You have gained the skills to select
    appropriate SLIs, allowing you to transparently share with the rest of your organization
    whether the services you are responsible for are behaving as expected. In turn,
    this transparency helps the organization identify quickly where problems are and
    target resources to address them.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we looked at the tools offered by Grafana for incident management,
    seeing how to configure and use them to support great incident management processes.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter will look at how we can use the tools provided by Grafana and
    OpenTelemetry to automate the processes of collecting, storing, and visualizing
    data in an observability platform.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
