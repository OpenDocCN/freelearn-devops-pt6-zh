- en: Getting Started with Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'So far, we''ve learned about the benefits that containers can bring us, but
    what if we need to scale out our services to meet the needs of our business? Is
    there a way to build services across multiple machines without dealing with cumbersome
    network and storage settings? Is there an easy way to manage and roll out our
    microservices with a different service cycle? This is where Kubernetes comes into
    play. In this chapter, we''ll look at the following concepts:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Components of Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes resources and their configuration files
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to launch the kiosk application using Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes is a platform for managing containers across multiple hosts. It provides
    lots of management features for container-oriented applications, such as auto-scaling,
    rolling deployments, compute resources, and storage management. Like containers,
    it's designed to run anywhere, including on bare metal, in our data center, in
    the public cloud, or even in the hybrid cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes fulfills most application container operational needs. Its highlights
    include the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Container deployment
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Persistent storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container health monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute resource management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Auto-scaling
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High availability by cluster federation
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With Kubernetes, we can manage containerized applications easily. For example,
    by creating `Deployment`, we can roll out, roll over, or roll back selected containers
    ([Chapter 9](acaa9855-1a87-4fd4-ad40-0955f5d12f28.xhtml), *Continuous Delivery*)
    with just a single command. Containers are considered ephemeral. If we only have
    one host, we could mount host volumes into containers to preserve data. In the
    cluster world, however, a container might be scheduled to run on any host in the
    cluster. How do we mount a volume without specifying which host it's run on? Kubernetes
    **volumes** and **persistent volumes** were introduced to solve this problem ([Chapter
    4](c3083748-0f68-488f-87e0-f8c61deeeb80.xhtml), *Managing Stateful Workloads*).
  prefs: []
  type: TYPE_NORMAL
- en: The lifetime of containers might be short; they may be killed or stopped anytime
    when they exceed the resource limit. How do we ensure our services are always
    on and are served by a certain number of containers? Deployment in Kubernetes
    ensures that a certain number of groups of containers are up and running. Kubernetes
    also supports **liveness probes** to help you define and monitor your application's
    health. For better resource management, we can define the maximum capacity for
    Kubernetes nodes and the resource limit for each group of containers (also known
    as **pods**). The Kubernetes scheduler will select a node that fulfills the resource
    criteria to run the containers. We'll learn about this further in [Chapter 8](a7a72300-181d-41ad-a08a-7e42744d365f.xhtml), *Resource
    Management and Scaling*. Kubernetes also provides an optional horizontal pod auto-scaling
    feature, which we can use to scale a pod horizontally by core or custom metrics.
    Kubernetes is also designed to have **high availability** (**HA**). We're able
    to create multiple master nodes and prevent single points of failure.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes includes two major players:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Masters**: The master is the heart of Kubernetes; it controls and schedules
    all of the activities in the cluster'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Nodes**: Nodes are the workers that run our containers'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Master components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The master includes the **API Server**, the **Controller Manager**, the **Scheduler**,
    and **etcd**. All components can run on different hosts with clustering. However,
    in this case, we''ll make all of the components run on the same node as shown
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/a18ae85c-32c3-49cc-9d9f-4ffe4cb8cf54.png)'
  prefs: []
  type: TYPE_IMG
- en: Master components
  prefs: []
  type: TYPE_NORMAL
- en: API server (kube-apiserver)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The API server provides an HTTP/HTTPS server, which provides a RESTful API for
    the components in the Kubernetes master. For example, we could use `GET` to get
    the resource status or `POST` to create a new resource. We can also watch for
    updates for resources. The API server stores the object information into etcd,
    which is Kubernetes' backend data store.
  prefs: []
  type: TYPE_NORMAL
- en: Controller manager (kube-controller-manager)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The controller manager is a set of control loops that watch the changes in the
    API server and ensure the cluster is in the desired state. For example, the deployment
    controller ensures that the whole deployment is run on the desired amount of containers.
    The node controller responds and evicts the pod when the nodes go down. The endpoint
    controller is used to create a relationship between services and pods. The service
    account and the token controller are used to create a default account and API
    access tokens.
  prefs: []
  type: TYPE_NORMAL
- en: To accommodate different development paces and release cycles from different
    cloud providers, from Kubernetes version 1.6, cloud provider-specific logic was
    moved from `kube-controller-manager` to the cloud controller manager (`cloud-controller-manager`).
    This was promoted to beta in version 1.11.
  prefs: []
  type: TYPE_NORMAL
- en: etcd
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: etcd is an open source distributed key-value store ([https://coreos.com/etcd](https://coreos.com/etcd)).
    Kubernetes stores all of the RESTful API objects here. etcd is responsible for
    storing and replicating data.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduler (kube-scheduler)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The scheduler determines which nodes are suitable candidates for pods to run
    on. It uses not only resource capacity and the balance of the resource utilization
    on the node but also node affinity, taints, and toleration. For more information,
    refer to [Chapter 8](a7a72300-181d-41ad-a08a-7e42744d365f.xhtml)*,* *Resource
    Management and Scaling*.
  prefs: []
  type: TYPE_NORMAL
- en: Node components
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Node components are provisioned and run on every node, which report the runtime
    status of the pod to the **master**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ac50f8a6-f1f5-4154-b21b-1ca694c4ea13.png)'
  prefs: []
  type: TYPE_IMG
- en: Node components
  prefs: []
  type: TYPE_NORMAL
- en: Kubelet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubelet is a major process in the nodes. It reports node activities back to
    `kube-apiserver` periodically, including pod health, node health, and liveness
    probe. As the preceding diagram shows, it runs containers via container runtimes,
    such as Docker or rkt.
  prefs: []
  type: TYPE_NORMAL
- en: Proxy (kube-proxy)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The proxy handles the routing between a pod load balancer (also known as a **service**)
    and pods. It also provides routing from external internet to services. There are
    three proxy modes: `userspace`, `iptables`, and `ipvs`. The `userspace` mode creates
    a large overhead by switching the kernel space and user space. The `iptables`
    mode, on the other hand, is the latest default proxy mode. It changes the `iptables` Network
    Address Translation (NAT: [https://en.wikipedia.org/wiki/Network_address_translation](https://en.wikipedia.org/wiki/Network_address_translation))
    in Linux to achieve routing TCP and UDP packets across all containers. **IP Virtual
    Servers** (**IPVS**) was **general available** (**GA**) in Kubernetes 1.11 and
    is used to address performance degradations when running 1,000+ services in a
    cluster. It runs on a host and acts as a load balancer, forwarding the connection
    to real servers. IPVS mode will fall back to `iptables` in some scenarios; please
    refer to [https://github.com/kubernetes/kubernetes/tree/master/pkg/proxy/ipvs](https://github.com/kubernetes/kubernetes/tree/master/pkg/proxy/ipvs)
    for more detailed information.'
  prefs: []
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As described in [Chapter 2](05e2d0b4-0e70-4480-b5a0-f3860ddb24f2.xhtml), *DevOps
    with Containers*, Docker is a container runtime implementation. Kubernetes uses
    Docker as a default container engine, and it also supports other container runtimes,
    such as rkt ([https://coreos.com/rkt/](https://coreos.com/rkt/)) and runc ([https://github.com/opencontainers/runc](https://github.com/opencontainers/runc)).
  prefs: []
  type: TYPE_NORMAL
- en: The interaction between the Kubernetes master and nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we can see in the following diagram, the client uses **kubectl**, which is
    a command-line interface, to send requests to the **API Server**. The **API Server**,
    a hub between the master components, will respond to the client requests and push
    and pull the object information from etcd. If a new task is created, such as run
    pods, the scheduler will determine which node should be assigned to do that task.
    The **Controller Manager** monitors the running tasks and responds if any undesired
    state occurs.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **API Server** fetches the logs from pods via the **kubelet**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/61844dcf-b0e1-44f6-966a-ea04715091c4.png)'
  prefs: []
  type: TYPE_IMG
- en: Interaction between master and nodes
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll learn how to set up a single-node cluster. Then, we''ll
    learn how to interact with Kubernetes via its command-line tool: kubectl. We''ll
    go through all of the important Kubernetes API objects and their expressions in
    YAML format, which is the input to kubectl. We''ll then see how kubectl sends
    requests to the API server to create the desired objects accordingly.'
  prefs: []
  type: TYPE_NORMAL
- en: Preparing the environment
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Firstly, kubectl has to be installed. In major Linux distributions (such as
    Ubuntu or CentOS), you can just search for and install the package named `kubectl`
    via the package manager. In macOS, we can choose to use Homebrew ([https://brew.sh/](https://brew.sh/)) to
    install it. Homebrew is a useful package manager in macOS. We can easily install Homebrew
    via the `/usr/bin/ruby -e "$(curl` `-fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"` command.
    Then, we can run brew install kubernetes-cli to install kubectl via Homebrew.
  prefs: []
  type: TYPE_NORMAL
- en: Let's now start to provision a Kubernetes cluster. The easiest way to do this
    is to run minikube ([https://github.com/kubernetes/minikube](https://github.com/kubernetes/minikube)),
    which is a tool to run Kubernetes on a single-node locally. It can be run on Windows,
    Linux, and macOS. In the following example, we'll run on macOS. Minikube will
    launch a VM with Kubernetes installed. We'll then be able to interact with it
    via kubectl.
  prefs: []
  type: TYPE_NORMAL
- en: Note that minikube isn't suitable for production or any heavy-load environment.
    It has some limitations due to its single node nature. We'll learn how to run
    a real cluster in [Chapter 10](f55d3fa8-e791-4473-83ba-ed8c4f848a90.xhtml), *Kubernetes
    on AWS*,[Chapter 11](d4de05e3-eb24-4e8e-bfd3-e68819b5e66c.xhtml), *Kubernetes
    on GCP*, and [Chapter 12](89891610-4ca4-4216-9d76-2613d186421c.xhtml), *Kubernetes
    on Azure*, instead.
  prefs: []
  type: TYPE_NORMAL
- en: Before installing minikube, we have to install some dependencies first. Minikube's
    official GitHub repository ([https://github.com/kubernetes/minikube](https://github.com/kubernetes/minikube))
    lists the dependencies and drivers for the different platforms. In our case, we're
    using VirtualBox ([https://www.virtualbox.org/](https://www.virtualbox.org/))
    as the driver in macOS. You're free to use other drivers; visit the preceding
    minikube GitHub link to find more options.
  prefs: []
  type: TYPE_NORMAL
- en: 'After downloading and installing VirtualBox from its official website, we''re
    ready to go. We can install minikube via `brew cask install minikube`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'After minikube is installed, we can start the cluster via the `minikube start`
    command. This will launch a Kubernetes cluster locally. At the time of writing,
    the default Kubernetes version that minikube v0.30.0 supports is `v.1.12.0`. You
    also can add the `--kubernetes-version` argument to specify the particular Kubernetes
    version you''d like to run. For example, assume we want to run a cluster with
    the version v1.12.1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'This will then proceed to start a VM named `minikube` in VirtualBox and set
    up the cluster via `kubeadm`, a Kubernetes provisioning tool. It''ll also set
    up `kubeconfig`, which is a configuration file to define the context and authentication
    settings of the cluster. With `kubeconfig`, we''re able to switch to different
    clusters via the `kubectl` command. We could use the `kubectl config view` command
    to see the current settings in `kubeconfig`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Here, we're currently using the `minikube` context. The context is a combination
    of the authentication information and the cluster connection information. You
    could use `kubectl config` use-context `$context` to forcibly switch the context
    if you have more than one context.
  prefs: []
  type: TYPE_NORMAL
- en: kubectl
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`kubectl` is the command-line tool to manage Kubernetes clusters. The most
    general usage of `kubectl` is to check the `version` of the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'We then know our server version is upto date, which is the latest at the time
    of writing—version 1.12.0\. The general syntax of `kubectl` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`command` indicates the operation you want to perform. If you type `kubectl
    help` in Terminal, it''ll show the supported commands. `type` means the resource
    type. We''ll learn about the major resource types in the next section. `name`
    is how we name our resources. It''s always good practice to have clear and informative
    names throughout. For the `flags`, if you type `kubectl options`, the `stdout `will
    show all of the flags you could pass on.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We can always add `--help` to get more detailed information on specific commands,
    as in the example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: We can then get examples and supported options in the `kubectl logs` command.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes resources
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes objects are the entries in the cluster, which are stored in etcd.
    They represent the desired state of your cluster. When we create an object, we
    send the request to the API server by kubectl or a RESTful API. The API server
    will check whether the request is valid, store the state in etcd, and interact
    with other master components to ensure the object exists. Kubernetes uses namespaces
    to isolate the objects virtually, so we could create different namespaces for
    different teams, usages, projects, or environments. Every object has its own name
    and unique ID. Kubernetes also supports labels and annotations to let us tag our
    objects. Labels in particular can be used to group the objects together.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes objects
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The object `spec` describes the desired state of Kubernetes objects. Most of
    the time, we write an object `spec` and send it to the API server via `kubectl`.
    Kubernetes will try to fulfill that desired `state` and `update` the object's
    status.
  prefs: []
  type: TYPE_NORMAL
- en: 'The object `spec` could be written in YAML ([http://www.yaml.org/](http://www.yaml.org/))
    or JSON ([http://www.json.org/](http://www.json.org/)). YAML is more common in
    the Kubernetes world. We''ll use YAML to write object `spec` in the rest of this
    book. The following code block shows a YAML-formatted spec fragment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Namespaces
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes namespaces allow us to implement isolation of multiple virtual clusters.
    Objects in different namespaces are invisible to each other. This is useful when
    different teams or projects share the same cluster. Most resources come under
    a namespace (these are known as namespaced resources); however, some generic resources,
    such as nodes or namespaces themselves, don''t belong to any namespace. Kubernetes
    has three namespaces:'
  prefs: []
  type: TYPE_NORMAL
- en: '`default`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-system`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kube-public`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we don't explicitly assign a namespace to a namespaced resource, it'll be
    located in the namespace of the current context. If we never add a new namespace,
    a default namespace will be used.
  prefs: []
  type: TYPE_NORMAL
- en: Kube-system namespaces are used by objects created by the Kubernetes system,
    such as addon, which are the pods or services that implement cluster features,
    such as dashboard. Kube-public namespace was introduced in Kubernetes version
    1.6, which is used by a beta controller manager (BootstrapSigner: [https://kubernetes.io/docs/admin/bootstrap-tokens](https://kubernetes.io/docs/admin/bootstrap-tokens)),
    putting the signed cluster location information into the `kube-public` namespace.
    This information could be viewed by authenticated or unauthenticated users.
  prefs: []
  type: TYPE_NORMAL
- en: In the following sections, all of the namespaced resources are located in a
    default namespace. Namespaces are also very important for resource management
    and roles. We'll provide further information in [Chapter 8](a7a72300-181d-41ad-a08a-7e42744d365f.xhtml), *Resource
    Management and Scaling*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how to create a namespace. A namespace is a Kubernetes object. We
    can specify the type to be a namespace, just like other objects. An example of
    how to create a namespace called `project1` follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s now try to start two nginx containers via deployment in the `project1` namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'When we list pods by `kubectl get pods`, we''ll see nothing in our cluster.
    This is because Kubernetes uses the current context to decide which namespace
    is current. If we don''t explicitly specify namespaces in the context or the `kubectl` command
    line, the `default` namespace will be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: You could use `--namespace <namespace_name>`, `--namespace=<namespace_name>`, `-n
    <namespace_name>`, or `-n=<namespace_name>` to specify the namespace for a command.
    To list the resources across namespaces, use the `--all-namespaces` parameter.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to do this is to change the current context to point to the desired
    namespace rather than the `default` namespace.
  prefs: []
  type: TYPE_NORMAL
- en: Name
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Every object in Kubernetes owns its own name that's uniquely identified within
    the same namespace. Kubernetes uses object names as part of a resource's URL for
    the API server, so it has be a combination of lowercase alphanumeric characters
    and dashes and dots, and it has to be less than 254 characters long. Besides the
    object name, Kubernetes also assigns a **Unique ID** (**UID**) to every object
    to distinguish historical occurrences of similar entities.
  prefs: []
  type: TYPE_NORMAL
- en: Label and selector
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Labels are sets of key/pair values that attach to objects. They''re designed
    to provide meaningful, identifying information about objects. Common usages are
    to indicate the name of the micro-service, the tier, the environment, and the
    software version. Users can define meaningful labels that could be used with selectors
    later. The syntax of labels in an object `spec` is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Along with labels, label selectors are used to filter sets of objects. Separated
    by commas, multiple requirements will be joined by the `AND` logical operator.
    There are two ways to filter:'
  prefs: []
  type: TYPE_NORMAL
- en: Equality-based requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set-based requirements
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Equality-based requirements support the following operators: `=`, `==`, and
    `!=`. Take the following diagram as an example: if the selector is `chapter=2,version!=0.1`,
    the result will be **object C**. If the requirement is `version=0.1`, the result
    will be **object A** and **object B**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/cc386b25-27c1-4c82-b314-e58590b38c19.png)'
  prefs: []
  type: TYPE_IMG
- en: Selector example
  prefs: []
  type: TYPE_NORMAL
- en: 'If we write the requirement in the supported object `spec`, it''ll be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Set-based requirement supports `in`, `notin`, and `exists` (for `key` only).
    For example, if the requirement is `chapter in (3, 4),version`, then **object
    A** will be returned. If the requirement is `version notin (0.2), !author_info`,
    the result will be **object A** and **object B**. The following example shows
    an object `spec` that uses set-based requirements:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: The requirements of `matchLabels` and `matchExpressions` are combined together.
    This means that the filtered objects need to be true for both requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Annotation
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Annotation is a set of user-specified key-value pairs, used for specifying
    non-identifying metadata. With annotation acts such as normal tagging, for example,
    a user could add timestamps, commit hashes, or build numbers to an annotation.
    Some kubectl commands support the `--record` option to record commands that make
    changes to the objects. Another use case of annotation is storing the configuration,
    such as Kubernetes deployments ([https://kubernetes.io/docs/concepts/workloads/controllers/deployment](https://kubernetes.io/docs/concepts/workloads/controllers/deployment))
    or critical add-on pods ([https://coreos.com/kubernetes/docs/latest/deploy-addons.html](https://coreos.com/kubernetes/docs/latest/deploy-addons.html)).
    The syntax of annotations is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Namespace, name, label, and annotation are located in the metadata section of
    the object `spec`. Selector is located in the `spec` section of selector-supported
    resources, such as pod, service, ReplicaSet, and deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Pods
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A pod is the smallest deployable unit in Kubernetes. It can contain one or more
    containers. Most of the time, we just need one container per pod. In some special
    cases, more than one container is included in the same pod, such as sidecar containers
    ([http://blog.kubernetes.io/2015/06/the-distributed-system-toolkit-patterns.html](http://blog.kubernetes.io/2015/06/the-distributed-system-toolkit-patterns.html)).
    Containers in the same pod run in a shared context, on the same node, sharing
    the network namespace and shared volumes. Pods are also designed as mortal. When
    a pod dies for some reason, for example, if it's killed by Kubernetes controller
    if resources are lacking, it won't recover by itself. Instead, Kubernetes uses
    controllers to create and manage the desired state of pods for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use `kubectl explain <resource>` to get the detailed description of
    the resource by the command line. This will show the fields that the resource
    supports:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'In the following example, we''ll show how to create two containers in a pod,
    and demonstrate how they access each other. Please note that this is neither a
    meaningful nor a classic sidecar pattern example. Instead, it''s just an example
    of how we can access other containers within a pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram shows the relationship between containers in a **Pod**.
    They share the same network namespace:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c5d57b7a-537b-4e2a-8fd6-5b6745261a6d.png)'
  prefs: []
  type: TYPE_IMG
- en: Containers inside a pod are visible via localhost
  prefs: []
  type: TYPE_NORMAL
- en: This spec will create two containers, `web` and `centos`. Web is an `nginx`
    container ([https://hub.docker.com/_/nginx/](https://hub.docker.com/_/nginx/)). The
    container port `80` is exposed by default. Since `centos` shares the same context
    as nginx, when using `curl` in `http://localhost:80/`, it should be able to access
    nginx.
  prefs: []
  type: TYPE_NORMAL
- en: 'Next, use the `kubectl create` command to launch the pod. The `-f` argument
    allows us to feed a configuration file to the `kubectl` command and creates the
    desired resources specified in the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: If we add `--record=true` at the end of the `kubectl` command when we create
    the resources, Kubernetes will add the latest command while creating or updating
    this resource. Therefore, we won't forget which resources are created by which
    spec.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can use the `kubectl get <resource>` command to get the current status of
    the object. In this case, we use the `kubectl get pods` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Adding `--namespace=$namespace_name` allows us to access the object in different
    namespaces. The following is an example of how to check the pods in the `kube-system`
    namespace, which is used by system-type pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '`**// list pods in kube-system namespace**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**# kubectl get pods --namespace=kube-system**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**NAME                            READY STATUS RESTARTS AGE**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**coredns-99b9bb8bd-p2dvw               1/1 Running 0 1m**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**etcd-minikube                         1/1 Running 0 47s**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**kube-addon-manager-minikube           1/1 Running 0 13s**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**kube-apiserver-minikube               1/1 Running 0 38s**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**kube-controller-manager-minikube      1/1 Running 0 32s**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**kube-proxy-pvww2                      1/1 Running 0 1m**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**kube-scheduler-minikube               1/1 Running 0 26s**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**kubernetes-dashboard-7db4dc666b-f8b2w 1/1 Running 0 1m**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**storage-provisioner                   1/1 Running 0 1m**`'
  prefs: []
  type: TYPE_NORMAL
- en: The status of our example pod is `ContainerCreating`. In this phase, Kubernetes
    has accepted the request and is trying to schedule the pod and pull down the image.
    Zero containers are currently running.
  prefs: []
  type: TYPE_NORMAL
- en: Most objects have short names, which come in handy when we use `kubectl get
    <object>` to list their status. For example, pods could be called `po`, services
    could be called `svc`, and deployment could be called `deploy`. Type `kubectl
    get` to know more. Alternatively, the `kubectl api-resources` command could list
    all resources with their short names and attributes.
  prefs: []
  type: TYPE_NORMAL
- en: 'After waiting a moment, we could get the status again:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that two containers are currently running. The uptime is three seconds.
    Using `kubectl logs <pod_name> -c <container_name>` gets `stdout` for the container,
    similar to `docker logs <container_name>`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '`centos` in the pod shares the same networking with nginx via localhost. Kubernetes
    creates a network container along with the pod. One of the functions in the network
    container is to forward the traffic between containers within a pod. We''ll learn
    more about this in [Chapter 6](fc67e008-b601-45a6-8297-d2fa28360b1f.xhtml), *Kubernetes
    Network*.'
  prefs: []
  type: TYPE_NORMAL
- en: If we specify labels in the pod spec, we could use the `kubectl get pods -l
    <requirement>` command to get the pods that satisfy the requirements, for example, `kubectl
    get pods -l 'tier in (frontend, backend)'`. Additionally, if we use `kubectl pods
    -o wide`, this will list which pods are running on which nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could use `kubectl describe <resource> <resource_name>` to get detailed
    information about a resource:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'At this point, we know which node this pod is running on. In `minikube`, we
    only get a single node so it won''t make any difference. In the real cluster environment,
    knowing which node the pod is running on is useful for troubleshooting. We haven''t
    associated any labels, annotations, or controllers for it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'In the containers section, we''ll see there are two containers included in
    this pod. We can see their states, source images, port mappings, and restart count:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'A pod has `PodStatus`, which includes a map of array representations as `PodConditions`.
    The possible types of `PodConditions` are `PodScheduled`, `Ready`, `Initialized`, `Unschedulable`,
    and `ContainersReady`. The value will be `true`, `false`, or unknown. If the pod
    isn''t created accordingly, `PodStatus` will give us a brief overview of which
    part failed. In the preceding example, we launched the pod successfully in each
    phase without any errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: A pod is associated with a service account that provides an identity for processes
    that are running the pod. It's controlled by service account and a token controller
    in the API Server.
  prefs: []
  type: TYPE_NORMAL
- en: 'It''ll mount a read-only volume to each container under `/var/run/secrets/kubernetes.io/serviceaccount`
    in a pod that contains a token for API access. Kubernetes creates a default service
    account. We can use the `kubectl get serviceaccounts` command to list the service
    accounts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'We don''t assign any selectors to this pod yet. Toleration is used to restrict
    how many pods a node can use. We''ll learn more about this in [Chapter 8](a7a72300-181d-41ad-a08a-7e42744d365f.xhtml), *Resource
    Management and Scaling*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: By seeing the events, we can identify the steps required for Kubernetes to run
    a node. First, the scheduler assigns the task to a node, which here is called
    `minikube`. Then, kubelet starts pulling the first image and creates a container
    accordingly. After that, kubelet pulls down the second container and starts the
    container.
  prefs: []
  type: TYPE_NORMAL
- en: ReplicaSet
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A pod isn't self-healing. When a pod encounters failure, it won't recover on
    its own. This is where **ReplicaSet** (**RS**) comes into play. ReplicaSet ensures
    that the specified number of replica pods are always up and running in the cluster.
    If a pod crashes for any reason, ReplicaSet will send a request to spin up a new
    pod.
  prefs: []
  type: TYPE_NORMAL
- en: ReplicaSet is similar to **ReplicationController** (**RC**), which was used
    in older versions of Kubernetes. Unlike ReplicaSet, which uses set-based selector
    requirement, ReplicationController used equality-based selector requirements. It
    has now been completely replaced by ReplicaSet.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how ReplicaSet works:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/040fd899-1e2e-4a91-bef9-8cfb5eb08a1e.png)'
  prefs: []
  type: TYPE_IMG
- en: ReplicaSet with a desired count of 2
  prefs: []
  type: TYPE_NORMAL
- en: Let's say that we want to create a `ReplicaSet` object, with a desired count
    of 2\. This means that we'll always have two pods in the service. Before we write
    the spec for ReplicaSet, we'll have to decide on the pod template first. This
    is similar to the spec of a pod. In a ReplicaSet, labels are required in the metadata
    section. A ReplicaSet uses a pod selector to select which pods it manages. Labels
    allow ReplicaSet to distinguish whether all of the pods matching the selectors
    are all on track.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this example, we''ll create two pods, each with the labels `project`, `service`,
    and `version`, as shown in the preceding diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we can use `kubectl` to get the current RS status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'This shows that we desire two pods, we currently have two pods, and two pods
    are ready. How many pods do we have now? Let''s check it out via the `kubectl`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'This shows we have two pods up and running. As described previously, ReplicaSet
    manages all of the pods matching the selector. If we create a pod with the same
    label manually, in theory, it should match the pod selector of the RS we just
    created. Let''s try it out:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s see if it''s up and running:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s scheduled, and ReplicaSet catches it. The amount of pods becomes three,
    which exceeds our desired count. The pod is eventually killed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The following diagram is an illustration of how our self-created pod was evicted.
    The labels are matched with ReplicaSet, but the desired count is 2\. Therefore,
    the additional pod was evicted:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/892b39bb-e749-4a51-a070-90a0530ab9eb.png)'
  prefs: []
  type: TYPE_IMG
- en: ReplicaSet makes sure pods are in the desired state
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to scale on demand, we could simply use `kubectl edit <resource>
    <resource_name>` to update the spec. Here, we''ll change the replica count from
    `2` to `5`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check the RS information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'We now have five pods. Let''s check how RS works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: By describing the command, we can learn the spec of RS and the events. When
    we created the `nginx` RS, it launched two containers by spec. Then, we created
    another pod manually by another spec, named `our-nginx`. RS detected that the
    pod matches its pod selector. After the amount exceeded our desired count, it
    evicted it. Then, we scaled out the replicas to five. RS detected that it didn't
    fulfill our desired state and launched three pods to fill the gap.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we want to delete an RC, simply use the `kubectl` command: `kubectl delete
    <resource> <resource_name>`. Since we have a configuration file on hand, we could
    also use `kubectl delete -f <configuration_file>` to delete the resources listing
    in the file:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Deployments are the best primitive to manage and deploy our software in Kubernetes
    after version 1.2\. They allow us to deploy pods, carry out rolling updates, and
    roll back pods and ReplicaSets. We can define our desired software updates declaratively using
    Deployments and then Deployments will do them for us progressively.
  prefs: []
  type: TYPE_NORMAL
- en: Before Deployments, ReplicationController and kubectl rolling-update were the
    major ways to implement rolling updates for software. These methods were much
    more imperative and slower. Deployment is now the main high-level object used
    to manage our application.
  prefs: []
  type: TYPE_NORMAL
- en: Let's take a look at how it works. In this section, we'll get a taste of how
    a Deployment is created, how to perform rolling updates, and rollbacks. [Chapter
    9](acaa9855-1a87-4fd4-ad40-0955f5d12f28.xhtml), *Continuous Delivery*, has more
    information with practical examples about how we can integrate Deployments into
    our continuous delivery pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we use the `kubectl run` command to create `deployment` for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: Before Kubernetes 1.2, the `kubectl run` command would create pods instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two pods that are deployed by `deployment`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is a diagram of the relationship between Deployments, ReplicaSets,
    and pods. In general, Deployments manage ReplicaSets and ReplicaSets manage pods.
    Note that we shouldn''t manipulate ReplicaSets that are managed by Deployments,
    just like there''s no reason to directly change pods if they''re managed by ReplicaSets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/0dae5898-fe53-4992-9c95-5c96ab5dc84b.png)'
  prefs: []
  type: TYPE_IMG
- en: The relationship between Deployments, ReplicaSets, and pods
  prefs: []
  type: TYPE_NORMAL
- en: 'If we delete one of the pods, the replaced pod will be scheduled and launched
    immediately. This is because Deployments create a ReplicaSet behind the scenes,
    which will ensure that the number of replicas matches our desired count:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'We could also expose the port for deployment using the `kubectl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: 'Deployments can be created by spec as well. The previous Deployments and Service
    launched by kubectl can be converted into the following spec:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to perform rolling updates, we''ll need to add a rolling update strategy.
    There are three parameters used to control the process:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Parameters** | **Description** | **Default value** |'
  prefs: []
  type: TYPE_TB
- en: '| `minReadySeconds` | This is the warm-up time and indicates how long a newly
    created pod is considered to be available. By default, Kubernetes assumes the
    application will be available once it''s successfully launched. | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| `maxSurge` | This indicates how many pods can be surged when carrying out
    rolling update processes. | 25% |'
  prefs: []
  type: TYPE_TB
- en: '| `maxUnavailable` | This indicates how many pods can be unavailable when carrying
    out rolling update processes. | 25% |'
  prefs: []
  type: TYPE_TB
- en: '`minReadySecond` is an important setting. If our application isn''t available
    immediately when the pod is up, the pods will roll too fast without proper waiting.
    Although all of the new pods are up, the application might be still warming up;
    there''s a chance that a service outage might occur. In the following example,
    we''ll add the configuration into the `Deployment.spec` section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: This indicates that we allow only one of the pods to be unavailable at any time
    and one pod to be launched when rolling the pods. The warm-up time before proceeding
    to the next operation is three seconds. We can use either `kubectl edit deployments
    nginx` (edit directly) or `kubectl replace -f 3-2-3_deployments_rollingupdate.yaml`
    to update the strategy.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s say we want to simulate a new software rollout from nginx 1.12.0 to
    1.13.1\. We can still use the preceding two commands to change the image version
    or use `kubectl set image deployment nginx nginx=nginx``:1.13.1` to trigger the
    update. If we use `kubectl describe` to check what''s going on, we''ll see that
    Deployments have triggered rolling updates on ReplicaSets by deleting/creating
    pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is a diagram of how rolling update works in a Deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/ff5abaf1-dbb3-4c85-a2ee-84c98925e6cd.png)'
  prefs: []
  type: TYPE_IMG
- en: Illustration of a Deployment
  prefs: []
  type: TYPE_NORMAL
- en: The preceding diagram shows an illustration of a Deployment. At a certain point
    in time, our desired count is 2 and we have one maxSurge pod. After launching
    each new pod, Kubernetes will wait three seconds (`minReadySeconds`) and then
    perform the next action.
  prefs: []
  type: TYPE_NORMAL
- en: If we use the `kubectl set image deployment nginx nginx=nginx:1.12.0` command to
    roll back to the previous version 1.12.0, Deployments will do the rollback for
    us.
  prefs: []
  type: TYPE_NORMAL
- en: Services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Services in Kubernetes are abstraction layers for routing traffic to a logical
    set of pods. With Services, we don't need to trace the IP address of each pod.
    Services usually use the label selector to select the pods that they need to route
    to while, in some cases, Services are created without a selector on purpose. The
    Service abstraction is powerful. It enables decoupling and makes communication
    between micro-services possible. Currently, Kubernetes Services support TCP, UDP,
    and SCTP.
  prefs: []
  type: TYPE_NORMAL
- en: 'Services don''t care about how we create the pod. Just like ReplicaSet, it
    only cares that the pods match its label selectors, so the pods could belong to
    different ReplicaSets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/98efea3b-cc56-41b0-af68-a8f78701f916.png)'
  prefs: []
  type: TYPE_IMG
- en: Service maps pods via label selector
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding diagram, all of the pods match the service selector, `project=chapter3,
    service=web`, so the Service will be responsible for distributing the traffic
    into all of the pods without explicit assignment.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are four types of Services: `ClusterIP`, `NodePort`, `LoadBalancer`,
    and `ExternalName`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/1e5774fc-aeb4-4247-80d4-853782f8c68f.png)'
  prefs: []
  type: TYPE_IMG
- en: LoadBalancer includes the features of NodePort and ClusterIP
  prefs: []
  type: TYPE_NORMAL
- en: ClusterIP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '`ClusterIP` is the default Service type. It exposes the Service on a cluster-internal
    IP. Pods in the cluster could reach the Service via the IP address, environment
    variables, or DNS. In the following example, we''ll learn how to use both native
    Service environment variables and DNS to access the pods behind Services in the
    cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Before starting a Service, we''d like to create two sets of RS with different
    version labels, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we could make our pod selector, targeting project and service labels:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: Since a `Service` object might create a DNS label, the service name must be
    a combination of alphanumeric characters and hyphens. A hyphen at the beginning
    or end of a label isn't allowed.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can then use `kubectl describe service <service_name>` to check the Service
    information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: One Service could expose multiple ports. Just extend the `.spec.ports` list
    in the `service` spec.
  prefs: []
  type: TYPE_NORMAL
- en: We can see that it's a `ClusterIP` type Service and its assigned internal IP
    is `10.0.0.188`. The endpoints show that we have four IPs behind the Service.
    The pod IPs can be found by the `kubectl describe pods <pod_name>` command. Kubernetes
    creates an `endpoints` object along with a `service` object to route the traffic
    to the matching pods.
  prefs: []
  type: TYPE_NORMAL
- en: 'When the Service is created with selectors, Kubernetes will create corresponding
    endpoint entries and keep updating, which will indicate the destination that the
    Service routes to:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: The ClusterIP could be defined within your cluster, though most of the time
    we don't explicitly use the IP address to access clusters. Using `.spec.clusterIP`
    can do this for us.
  prefs: []
  type: TYPE_NORMAL
- en: 'By default, Kubernetes will expose seven environment variables for each Service.
    In most cases, the first two allow us to use the `kube-dns` add-on to carry out
    service discovery for us:'
  prefs: []
  type: TYPE_NORMAL
- en: '`${SVCNAME}_SERVICE_HOST`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`${SVCNAME}_SERVICE_PORT`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`${SVCNAME}_PORT`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}_PROTO`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}_PORT`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`${SVCNAME}_PORT_${PORT}_${PROTOCAL}_ADDR`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'In the following example, we''ll use `${SVCNAME}_SERVICE_HOST` in another pod
    to check whether we can access our nginx pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/96e290d8-2b77-4137-820c-8b48abf5c963.png)'
  prefs: []
  type: TYPE_IMG
- en: Accessing ClusterIP via environment variables and DNS names
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll then create a pod called `clusterip-chk` to access nginx containers
    via `nginx-service`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 'We can check `stdout` of the `cluserip-chk` pod via the `kubectl logs` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: This abstraction level decouples the communication between pods. Pods are mortal.
    With RS and Services, we can build robust services without worrying about whether
    one pod will influence all microservices.
  prefs: []
  type: TYPE_NORMAL
- en: With the DNS server enabled, the pods in the same cluster and the same namespace
    as the Services can access Services via their DNS records.
  prefs: []
  type: TYPE_NORMAL
- en: CoreDNS GA was introduced in Kubernetes 1.11 and is now the default option in
    Kubernetes. Before this, the kube-dns add-on was in charge of DNS-based service
    discovery
  prefs: []
  type: TYPE_NORMAL
- en: The DNS server creates DNS records for newly created services by watching the
    Kubernetes API. The DNS format for the cluster IP is `$servicename.$namespace` and
    the port is `_$portname_$protocal.$servicename.$namespace`. The spec of the `clusterip_chk`
    pod will be similar to the environment variables one. Change the URL to `http://nginx-service.default:_http_tcp.nginx-service.default/`
    in our previous example, and they should work exactly the same.
  prefs: []
  type: TYPE_NORMAL
- en: NodePort
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: If the Service is set as `NodePort`, Kubernetes will allocate a port within
    a certain range on each node. Any traffic going to the nodes on that port will
    be routed to the Service port. The port number may be user-specified. If not,
    Kubernetes will randomly choose a port between 30,000 and 32,767 that doesn't
    cause any collision. On the other hand, if it's specified, the user should be
    responsible for managing the collision by themselves. `NodePort` includes a `ClusterIP ` feature.
    Kubernetes assigns an internal IP to the Service.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the following example, we''ll see how we can create a `NodePort` Service
    and use it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: You should then be able to access the Service via `http://${NODE_IP}:80`. The
    node could be any node. The `kube-proxy` watches for any updates by the Service
    and the endpoints, and updates the iptable rules accordingly (if using default
    `iptables` proxy-mode).
  prefs: []
  type: TYPE_NORMAL
- en: If you're using minikube, you can access the Service via the `minikube service
    [-n NAMESPACE] [--url] NAME` command. In this example, this is `minikube service
    nginx-nodeport`.
  prefs: []
  type: TYPE_NORMAL
- en: LoadBalancer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This type is only usable with cloud provider support, such as Amazon Web Services
    ([Chapter 10](f55d3fa8-e791-4473-83ba-ed8c4f848a90.xhtml), *Kubernetes on AWS*), Google
    Cloud Platform ([Chapter 11](d4de05e3-eb24-4e8e-bfd3-e68819b5e66c.xhtml), *Kubernetes
    on GCP*), and Azure ([Chapter 12](89891610-4ca4-4216-9d76-2613d186421c.xhtml), *Kubernetes
    on Azure*). If we create a LoadBalancer Service, Kubernetes will provision a load
    balancer by the cloud provider to the Service.
  prefs: []
  type: TYPE_NORMAL
- en: ExternalName (kube-dns version >= 1.7)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sometimes, we use different services in the cloud. Kubernetes is flexible enough
    to be hybrid. We can use ExternalName to create a CNAME for the external endpoints
    in the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Service without selectors
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Services use selectors to match the pods to direct the traffic. However, sometimes
    you need to implement a proxy to be the bridge between the Kubernetes cluster
    and another namespace, another cluster, or an external resource. In the following
    example, we''ll demonstrate how to implement a proxy for [http://www.google.com](http://www.google.com)
    in your cluster. This is just an example; the source of the proxy in your case
    might be the endpoint of your database or another resource in the cloud:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/aad76cc0-0822-460d-9680-8ab29368220a.png)'
  prefs: []
  type: TYPE_IMG
- en: How a Service without a selector works
  prefs: []
  type: TYPE_NORMAL
- en: 'The configuration file is similar to the previous one, just without the selector
    section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: No Kubernetes endpoint will be created, since there's no selector. Kubernetes
    doesn't know where to route the traffic, since no selector can match the pods.
    We'll have to create the endpoints manually.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `Endpoints` object, the source addresses can''t be the DNS name, so
    we''ll use `nslookup` to find the current Google IP from the domain, and add it
    to `Endpoints.subsets.addresses.ip`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s create another pod in the cluster to access our Google proxy:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: 'Let''s check `stdout` from the pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: Hurray! We can now confirm that the proxy works. The traffic to the Service
    will be routed to the endpoints we specified. If it doesn't work, make sure you
    add the proper inbound rules to the network of your external resources.
  prefs: []
  type: TYPE_NORMAL
- en: Endpoints don't support DNS as a source. Alternatively, we can use the ExternalName,
    which doesn't have selectors either. This requires kube-dns version >= 1.7.
  prefs: []
  type: TYPE_NORMAL
- en: In some use cases, users need neither load balancing nor proxy functionalities
    for the Service. In those cases, we can set `CluterIP = "None"` as a so-called
    headless service. For more information, please refer to [https://kubernetes.io/docs/concepts/services-networking/service/#headless-services](https://kubernetes.io/docs/concepts/services-networking/service/#headless-services).
  prefs: []
  type: TYPE_NORMAL
- en: Volumes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A container is ephemeral and so is its disk. We either use the `docker commit
    [CONTAINER]` command or mount data volumes into a container ([Chapter 2](05e2d0b4-0e70-4480-b5a0-f3860ddb24f2.xhtml),
    *DevOps with Containers*). In the Kubernetes domain, volume management is critical,
    since pods might run on any node. Also, ensuring that containers in the same pod
    can share the same files becomes extremely hard. This is an important topic in
    Kubernetes. [Chapter 4](c3083748-0f68-488f-87e0-f8c61deeeb80.xhtml), *Managing
    Stateful Workloads*, introduces volume management.
  prefs: []
  type: TYPE_NORMAL
- en: Secrets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A secret, as its name suggests, is an object that stores secrets in key-value
    format for providing sensitive information to pods. It might be a password, an
    access key, or a token. A secret isn't stored in the disk; instead, it's stored
    in a per-node `tmpfs` filesystem. Kubelet on the node will create a `tmpfs` filesystem
    to store the secret. A secret isn't designed to store large amounts of data due
    to storage management considerations. The current size limit of one secret is
    1 MB.
  prefs: []
  type: TYPE_NORMAL
- en: 'We can create a secret based on a file, a directory, or a specified literal
    value by launching kubectl to create a secret command or by the spec. There are
    three types of secret format: generic (or opaque, if encoded), docker registry,
    and TLS.'
  prefs: []
  type: TYPE_NORMAL
- en: We'll use either the generic or opaque type in our application. The docker registry
    type is used to store the credentials of a private docker registry. A TLS secret
    is used to store the CA certificate bundle for cluster administration.
  prefs: []
  type: TYPE_NORMAL
- en: The `docker-registry` type of secret is also called `imagePullSecrets` and is
    used to pass the password of a private Docker registry via kubelet when pulling
    the image. This means we don't have to enter `docker login` for each provisioned
    node. The command is as follows: `kubectl create secret docker-registry` `<registry_name>`
    `--docker-server``=<docker_server> --docker-username=<docker_username>` `--docker-password=<docker_password>
    --docker-email=<docker_email>`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll start with a generic example to show how it works:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: The options for creating secrets based on a directory and a literal value are
    pretty similar to the file ones. If we specify a directory after `--from-file`,
    the files in the directory will be iterated. The filename will be the secret key
    if it's a legal secret name. Non-regular files, such as subdirectories, symlinks,
    devices, or pipes, will be ignored. On the other hand, `--from-literal=<key>=<value>`
    is the option to use if you want to specify plain text directly from the command,
    for example, `--from-literal=username=root`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here, we create a secret name, `mypassword`, from the `mypassword.txt` file.
    By default, the key of the secret is the filename, which is equivalent to the
    `--from-file=mypassword=./mypassword.txt` option. We could append multiple `--from-file` instances
    as well. We can use the `kubectl get secret -o yaml` command to see more detailed
    information about the secret:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: 'We can see that the type of the secret becomes `Opaque` since the text has
    been encrypted by kubectl. It''s `base64` encoded. We can use a simple `bash`
    command to decode it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: There are two ways for a pod to retrieve the secret. The first one is by a file,
    and the second one is by an environment variable. The first method is implemented
    by the volume. The syntax involves adding `containers.volumeMounts` in container
    specs and adding a volumes section with the secret configuration.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving secrets via files
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Let''s see how to read secrets from files inside a pod first:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: 'The secret file will be mounted in `/<mount_point>/<secret_name>` without specifying
    `items``key`, `path`, or `/<mount_point>/<path>` in the pod. In this case, the
    file path is `/secret/password-example`. If we describe the pod, we find that
    there are two mount points in this pod: the read-only volume that stores our secret
    and the one that stores the credentials to communicate with the API servers, which
    is created and managed by Kubernetes. We''ll learn more about this in [Chapter
    6](fc67e008-b601-45a6-8297-d2fa28360b1f.xhtml), *Kubernetes Network*:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: We can delete a secret using the `kubectl delete secret` `<secret_name>` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'After describing the pod, we can find a `FailedMount` event, since the volume
    no longer exists:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: If the pod is generated before a secret is created, the pod will encounter failure
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll now learn how to create a secret using the command line. We''ll briefly
    introduce its spec format:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: Since the spec is plain text, we need to encode the secret by our own `echo
    -n <password>` `| base64` command. Please note that the type here becomes `Opaque`.
    This should work in the same way as the one we create via the command line.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving secrets via environment variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Alternatively, we could use environment variables to retrieve secrets, which
    is more flexible for short credentials, such as a password. Applications are able
    to use environment variables to retrieve database passwords without tackling files
    and volumes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: A secret should always be created before the pods that need it. Otherwise, the
    pods won't be launched successfully.
  prefs: []
  type: TYPE_NORMAL
- en: The declaration is under `spec.containers[].env[]`. We'll need the secret name
    and the key name. Both are `mypassword` in this case. The example should work
    the same as the one we looked at previously.
  prefs: []
  type: TYPE_NORMAL
- en: ConfigMap
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: ConfigMap is a resource that allows you to leave your configuration outside
    a Docker image. It injects the configuration data as key-value pairs into pods.
    Its properties are similar to secrets, but, whereas secrets are used to store
    sensitive data, such as passwords, ConfigMaps are used to store insensitive configuration
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like secrets, ConfigMaps could be based on files, directories, or specified
    literal value. They also have a similar syntax to secrets but use `kubectl create
    configmap`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Since two `config` files are located in the same folder name, `config`, we could
    pass a `config` folder instead of specifying the files one by one. The equivalent
    command to the preceding command is `kubectl create configmap example --from-file=config`
    in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we describe the ConfigMap, it''ll show the current information:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: We could use `kubectl edit configmap` `<configmap_name>` to update the configuration
    after creation.
  prefs: []
  type: TYPE_NORMAL
- en: We also could use `literal` as the input. The equivalent commands for the preceding
    example would be `kubectl create configmap example --from-literal=app.properties.name=name=DevOps-with-Kubernetes`.
    This isn't always very practical when we have many configurations in an app.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s see how to use this inside a pod. There are two ways to use ConfigMap
    inside a pod: by volume or environment variables.'
  prefs: []
  type: TYPE_NORMAL
- en: Using ConfigMap via volume
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Similar to previous examples in the *Secrets* subsection, we mount a volume
    with `configmap` syntax and add `volumeMounts` inside a container template. The
    command in `centos` will loop to `cat ${MOUNTPOINT}/$CONFIG_FILENAME`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: We then could use this method to inject our non-sensitive configuration into
    the pod.
  prefs: []
  type: TYPE_NORMAL
- en: Using ConfigMap via environment variables
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To use ConfigMap inside a pod, you''ll have to use `configMapKeyRef` as the
    value source in the `env` section. This will populate whole ConfigMap pairs to
    environment variables:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: The Kubernetes system itself also uses ConfigMap to do some authentication.
    Check out the system ConfigMap by adding `--namespace=kube-system` in the `kubectl
    describe configmap` command.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-container orchestration
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we''ll revisit our ticketing service: a kiosk web service
    as a frontend that provides an interface for get/put tickets. There is a Redis
    acting as cache to manage how many tickets we have. Redis also acts as a publisher/subscriber
    channel. Once a ticket is sold, the kiosk will publish an event into it. The subscriber
    is called recorder and will write a timestamp and record it to the MySQL database.
    Please refer to the last section in [Chapter 2](05e2d0b4-0e70-4480-b5a0-f3860ddb24f2.xhtml),
    *DevOps with Containers*, for a detailed Dockerfile and Docker compose implementation.
    We''ll use `Deployment`, `Service`, `Secret`, `Volume`, and `ConfigMap` objects
    to implement this example in Kubernetes. The source code can be found at the following
    link: [https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter3/3-3_kiosk](https://github.com/DevOps-with-Kubernetes/examples/tree/master/chapter3/3-3_kiosk).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The service architecture with Kubernetes resources is shown in the following
    diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/c0837b43-ba18-449e-becf-62a3c83c5913.png)'
  prefs: []
  type: TYPE_IMG
- en: An example of a kiosk in the Kubernetes world
  prefs: []
  type: TYPE_NORMAL
- en: We'll need four kinds of pods. Deployment is the best choice to manage or deploy
    the pods. This will reduce the effort required when we carry out deployments in
    the future thanks to its deployment strategy feature. Since the kiosk, Redis,
    and MySQL will be accessed by other components, we'll associate services to their
    pods. MySQL acts as a datastore and, for simplicity, we'll mount a local volume
    to it. Note that Kubernetes offers a bunch of choices. Check out the details and
    examples in [Chapter 4](c3083748-0f68-488f-87e0-f8c61deeeb80.xhtml), *Managing
    Stateful Workload*s. We'll want to store sensitive information such as our MySQL
    root and user password in secrets. The other insensitive configuration, such as
    the DB name or username, we'll leave to ConfigMap.
  prefs: []
  type: TYPE_NORMAL
- en: 'We''ll launch MySQL first, as the recorder depends on it. Before creating MySQL,
    we''ll have to create a corresponding `secret` and `ConfigMap` first. To create
    a `secret`, we need to generate `base64` encrypted data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, we''re able to create the secret:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: 'After that, we come to our ConfigMap. Here, we put the database user and the
    database name as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: 'It''s then time to launch MySQL and its service:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: We can put more than one spec into a file by adding three dashes as separation.
    Here, we mount `hostPath /mysql/data` into pods with the path `/var/lib/mysql`.
    In the environment section, we use the secret and ConfigMap syntax with `secretKeyRef`
    and `configMapKeyRef`.
  prefs: []
  type: TYPE_NORMAL
- en: 'After creating MySQL, Redis would be the next best candidate, since other services
    are dependent on it but it doesn''t have any prerequisites:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: 'It would then be a good time to start the kiosk:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: Here, we expose `lcredis-service.default` to environment variables to kiosk
    pods. This is the DNS name that kube-dns creates for `Service` objects (referred
    to as Services in this chapter). Hence, the kiosk can access the Redis host via
    environment variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the end, we''ll create a recorder. This doesn''t expose any interface to
    others, so it doesn''t need a `Service` object:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: The recorder needs to access both Redis and MySQL. It uses root credentials
    that are injected via a secret. Both endpoints for Redis and MySQL are accessed
    via a service DNS name, `<service_name>.<namespace>`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could then check the `Deployment` objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: As expected, we have four `Deployment` objects with a different desired count
    of pods.
  prefs: []
  type: TYPE_NORMAL
- en: As we expose the kiosk as a NodePort, we should be able to access its service
    endpoint and see whether it works properly. Assume we have a node, the IP of which
    is `192.168.99.100`, and the NodePort that Kubernetes allocates is `30520`.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you''re using minikube, `minikube service [-n NAMESPACE] [--url] NAME` could
    help you access service NodePort via your default browser:'
  prefs: []
  type: TYPE_NORMAL
- en: '`**// open kiosk console**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**# minikube service kiosk-service**`'
  prefs: []
  type: TYPE_NORMAL
- en: '`**Opening kubernetes service default/kiosk-service in default browser...**`'
  prefs: []
  type: TYPE_NORMAL
- en: This will allow us to find out the IP and the port.
  prefs: []
  type: TYPE_NORMAL
- en: 'We could then create and get a ticket using `POST` and `GET /tickets`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned the basic concepts of Kubernetes. We learned that
    a Kubernetes master has kube-apiserver to handle requests and controller managers
    are the control center of Kubernetes. These ensure our desired container amount
    is fulfilled, they control the endpoint to associate pods and services, and they
    control API access tokens. We also have Kubernetes nodes, which are the workers
    to host the containers, receive the information from the master, and route the
    traffic based on the configuration.
  prefs: []
  type: TYPE_NORMAL
- en: We then used minikube to demonstrate basic Kubernetes objects, including pods,
    ReplicaSets, Deployments, Services, secrets, and ConfigMaps. Finally, we demonstrated
    how to combine all of the concepts we've learned into our kiosk application.
  prefs: []
  type: TYPE_NORMAL
- en: As we mentioned previously, the data inside containers will disappear when a
    container is gone. Therefore, volume is extremely important to persist the data
    in the container world. In [Chapter 4](c3083748-0f68-488f-87e0-f8c61deeeb80.xhtml),
    *Managing Stateful Workloads*, we'll be learning how volume works and how to use
    persistent volume.
  prefs: []
  type: TYPE_NORMAL
