- en: '*Chapter 6*: Securing Kubernetes Effectively'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In previous chapters, you learned how to design and provision the infrastructure
    of Kubernetes clusters, fine-tune their configuration, and deploy extra add-ons
    and services on top of the clusters, such as networking, security, monitoring,
    and scaling.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, you will learn about the different aspects of Kubernetes security,
    focusing on qualifying the cluster to have a production-grade security. We will
    follow an end-to-end security approach to cover all of the essential areas that
    every production cluster should have. We will know how to bring the cluster security
    closer to the production readiness state by fine-tuning the security configuration
    of the cluster and its infrastructure and deploying new security add-ons and tools,
    and finally ensure cluster security compliance and conformance to security standards
    and checks.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Securing Kubernetes infrastructure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing cluster access
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing secrets and certificates
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Securing workloads and apps
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring cluster security and compliance
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bonus security tips
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying the security configurations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Destroying the cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You should have the following tools installed from the previous chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: AWS CLI V2
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AWS IAM Authenticator
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kubectl`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Terraform
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Python3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: PIP 3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: virtualenv
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to have an up-and-running Kubernetes cluster
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The code for this chapter is available at [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06).
  prefs: []
  type: TYPE_NORMAL
- en: 'Check out the following link to see the Code in Action video:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://bit.ly/2MBwZNk](https://bit.ly/2MBwZNk)'
  prefs: []
  type: TYPE_NORMAL
- en: Securing Kubernetes infrastructure
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [*Chapter 2*](B16192_02_Final_PG_ePub.xhtml#_idTextAnchor051), *Architecting
    Production-Grade Kubernetes Infrastructure*, we discussed the best practices for
    the network infrastructure for Kubernetes clusters and we proposed design guidelines
    that are essential for the infrastructure security of clusters. While these guidelines
    are essential for you to consider and follow, you still need to evaluate the entire
    network security requirements of your infrastructure to be sure that you have
    a complete and appropriate security solution for your environment and product.
  prefs: []
  type: TYPE_NORMAL
- en: 'Most of these security recommendations and best practices are implemented within
    the Terraform and Ansible configurations that we did in the previous chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: Use multiple availability zones (three or more) to deploy your Kubernetes cluster
    for high availability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploy the control plane and worker nodes in private subnets only. Use the public
    subnets for internet-facing load balancers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Do not allow public access to worker nodes. Expose services externally through
    load balancers or ingress controllers, and not through node ports.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serve all the traffic between the API server and other control plane components
    or workers over TLS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Limit network access to the Kubernetes API endpoint.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Block access to `kubelet`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use security groups to block access to workers and control plane ports, except
    secure ones.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Disable SSH access to worker nodes. You can use AWS Systems Manager Session
    Manager instead of running SSHD to connect to nodes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Restrict access to the EC2 instance profile credentials. By default, the containers
    in a pod use the same IAM permissions assigned to the node instance profile. This
    is considered an insecure behavior, because it gives the containers full control
    over the node and the underlying AWS services. To avoid this behavior, you must
    disable the pod''s access to the node''s instance profile by executing the following
    `iptables` commands inside the node:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: As we are using EKS, it is highly recommended to use a regular `kubelet` agent.
    Another reason for avoiding EKS node groups is that it enforces the attachment
    of public IPs to the worker nodes, which can represent security threats.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The preceding list covers the essential production infrastructure security guidelines
    for your Kubernetes clusters. All of these guidelines are covered by cluster provisioning
    and configuration management, which we implemented in the previous chapters. It
    is worth mentioning that your cluster infrastructure may have extra security requirements
    that you should consider during infrastructure design and provisioning.
  prefs: []
  type: TYPE_NORMAL
- en: Managing cluster access
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Requests from a cluster''s users, either humans or service accounts, need to
    go through authentication and authorization stages before hitting the API server
    and manipulating the required Kubernetes objects. A typical request goes through
    three access stages before it gets either allowed or rejected:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – Kubernetes access stages'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16192_06_001.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.1 – Kubernetes access stages
  prefs: []
  type: TYPE_NORMAL
- en: The request has to go through the authentication stage to verify the client's
    identity by any of the mechanisms supported by Kubernetes, then it goes through
    the authorization stage to verify which actions are allowed for this user, and
    finally it goes through the admission controller stage to decide whether any modifications
    need to be made. You will learn about each of these in the following subsections.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster authentication
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes cluster users need to successfully authenticate into the cluster
    to access its objects. However, normal cluster users, such as developers and administrators,
    are not supposed to be managed by Kubernetes, but by an external service outside
    the cluster, such as **Lightweight Directory Access Protocol** (**LDAP**), **OpenID
    Connect** (**OIDC**), AWS **Identity and Access Management** (**IAM**), or even
    a file with users and password pairs. On the other hand, service accounts are
    managed by Kubernetes, and you can add or delete them using Kubernetes API calls.
  prefs: []
  type: TYPE_NORMAL
- en: As a cluster owner, you need to decide how you will manage the cluster's normal
    users, in other words, which external service to use. To authenticate users in
    the case of production clusters, we recommend using AWS IAM as the authentication
    service. However, it is also possible to use an OIDC identity provider, such as
    Azure Active Directory, or GitHub.
  prefs: []
  type: TYPE_NORMAL
- en: It's worth mentioning that Kubernetes has different authentication modules for
    different means of authentication, such as client TLS certificates, passwords,
    and tokens. And the cluster administrator can configure some or all of them during
    cluster provisioning.
  prefs: []
  type: TYPE_NORMAL
- en: Authenticating users with AWS IAM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: EKS supports the webhook token authentication and service account tokens. The
    webhook authentication verifies the bearer tokens. These bearer tokens are generated
    by the `aws-iam-authenticator` client when you execute `kubectl` commands. Then,
    the token is passed to `kube-apiserver` before being forwarded to the authentication
    webhook, which returns the user's account and ARN to `kube-apiserver`.
  prefs: []
  type: TYPE_NORMAL
- en: Once the user's identity has been authenticated by the AWS IAM service, `kube-apiserver`
    reads the `aws-auth` ConfigMap in the `kube-system` namespace to determine the
    `aws-auth` ConfigMap is used to create a mapping between the IAM users and roles,
    and Kubernetes RBAC groups for authorization purposes. These RBAC groups can be
    referenced in Kubernetes ClusterRoleBindings or RoleBindings.
  prefs: []
  type: TYPE_NORMAL
- en: 'We already learned how to create a custom `aws-auth` ConfigMap in [*Chapter
    4*](B16192_04_Final_PG_ePub.xhtml#_idTextAnchor100), *Managing Cluster Configuration
    with Ansible*, where we can add IAM users and IAM roles that users can assume
    to access the cluster. Please check the `aws-auth` ConfigMap''s full configuration
    code here: [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/auth/aws-auth.yaml](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/auth/aws-auth.yaml).'
  prefs: []
  type: TYPE_NORMAL
- en: We recommend using IAM roles to manage production cluster access, and you can
    assign these IAM roles to IAM groups and users, which makes Kubernetes authentication
    easier to operate and scale.
  prefs: []
  type: TYPE_NORMAL
- en: Modifying the EKS cluster creator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It is worth noting that EKS gives the IAM user or whatever IAM role that creates
    the cluster a permanent administrator authentication on the cluster''s Kubernetes
    API service. AWS does not provide any way to change this or to move it to a different
    IAM user or role. To minimize the security drawbacks of this limitation, we suggest
    doing the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Use a dedicated but temporary IAM role to provision each new cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: After provisioning the cluster, remove all IAM permissions from this role.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update the `aws-auth` ConfigMap in the `kube-system` namespace and add more
    IAM users and roles to be able to manage and use the cluster.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Add these groups as subjects of `RoleBindings` and `ClusterRoleBindings` in
    the cluster RBAC as needed.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You already learned in [*Chapter 4*](B16192_04_Final_PG_ePub.xhtml#_idTextAnchor100),
    *Managing Cluster Configuration with Ansible*, how to handle this drawback in
    the Ansible cluster configuration as we created a custom `aws-auth` ConfigMap
    and `ClusterRoleBindings`.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster authorization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The second stage of cluster access is authorization. This determines whether
    the operation requested is allowed. In order for Kubernetes to authorize a request,
    it considers three inputs; first, the user who initiated the request, then the
    requested action, and finally the Kubernetes resource to be modified by the action,
    such as pods and services.
  prefs: []
  type: TYPE_NORMAL
- en: When you create a cluster, you configure the authorization mode by passing its
    value to the API server. However, in EKS, all of the authorization modes (RBAC,
    attribute-based access control, and webhooks) are enabled by default, and Kubernetes
    will check each of them to authorize the requests.
  prefs: []
  type: TYPE_NORMAL
- en: Admission controller
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The final stage of cluster access is passing through the admission controller.
    In this step, requests are validated based on the rules defined in the admission
    controller and the requested object. There is also another type of admission controller,
    called a mutating controller, which can modify the request, such as injecting
    side car containers or modifying pod specs before sending the request to `kube-api-server`.
  prefs: []
  type: TYPE_NORMAL
- en: An admission controller is a powerful authorization mechanism, and it can be
    extended by cluster users or third parties to enforce special validations and
    rules on cluster users.
  prefs: []
  type: TYPE_NORMAL
- en: Managing secrets and certificates
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Secrets and TLS certificates are essential security needs for modern applications,
    and while Kubernetes provides a native solution to create and consume secrets
    and sensitive data, it remains in need of additional hardening. On the other hand,
    Kubernetes has no native answer to certificate issuing and management, which is
    why we will deploy one of the popular add-ons and use it for this purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and managing secrets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes has a secret resource type that can be used to store sensitive data,
    such as passwords, tokens, certificates, and SSH keys. Pods can consume these
    secrets by mounting them as volumes or environment variables. However, we do not
    recommend environment variables because they can leak out and get compromised.
  prefs: []
  type: TYPE_NORMAL
- en: Another challenge here arises when users decide to store the secrets that YAML
    manifests in Git repositories. In such a case, the sensitive data can be easily
    compromised because secrets do not use encryption, but Base64 encoding, which
    can simply be decoded.
  prefs: []
  type: TYPE_NORMAL
- en: Sealed Secrets solves this problem by providing a mechanism to encrypt the secret
    sensitive data and make it safe to store in Git repositories.
  prefs: []
  type: TYPE_NORMAL
- en: 'Sealed Secrets consists of two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: A command-line tool, `kubeseal`, to transform **Custom Resource Definition**
    (**CRD**) secrets into sealed secrets.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A Sealed Secrets controller that is used to generate the encryption key, and
    decrypt sealed secrets into secrets to be used by the pods.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'To learn more about Sealed Secrets and the `kubeseal` client, please review
    these here: [https://github.com/bitnami-labs/sealed-secrets](https://github.com/bitnami-labs/sealed-secrets).'
  prefs: []
  type: TYPE_NORMAL
- en: This is how it works. `kubeseal` communicates with the Sealed Secrets controller
    to retrieve the encryption public key, and then it uses this key to encrypt the
    secret CRD into a sealed secret CRD. And when a pod requires use of the sealed
    secret, the controller uses the encryption private key to decrypt the sealed secret
    CRD and convert it to a regular secret CRD.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is worthwhile mentioning that Sealed Secrets mitigates the security risks
    associated with secrets in a multi-tenant cluster by introducing the concept of
    scopes to limit secret use and manipulation within a namespace, or cluster-wide,
    and with the possibility to restrict or change the secret name and namespace.
    The details of the reasoning behind this can be found here in the official documentation:
    [https://github.com/bitnami-labs/sealed-secrets#scopes](https://github.com/bitnami-labs/sealed-secrets#scopes).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create the Ansible template and configuration to deploy the Sealed
    Secrets controller to the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the required configuration variables and add them to the `group_vars`
    directory in this path – `ansible/group_vars/all/sealed-secrets.yaml`. The basic
    configuration contains the number of deployment replicas and the image tag, which
    is useful for keeping track of the deployed version and controlling its upgrades:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can find the complete source code of the Sealed Secrets deployment template
    at [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Create the deployment template for the Sealed Secrets controller in this path
    – `ansible/templates/sealed-secrets/sealed-secrets.yaml`. In this controller,
    we will only set variables for the deployment replicas and image tags. You can
    check the complete manifest YAML file at [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets/sealed-secrets.yaml](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/sealed-secrets/sealed-secrets.yaml).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Install the `kubeseal` CLI for macOS as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install it for Linux using the following command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: To deploy the Sealed Secrets controller, please apply the deployment steps covered
    at the end of this chapter under the *Deploying the security configurations* section.
  prefs: []
  type: TYPE_NORMAL
- en: Managing TLS certificates with Cert-Manager
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Cert-Manager is a Kubernetes add-on and controller that allows certificates
    to be issued from different sources, such as SelfSigned, CA, Vault, and ACME/Let''s
    Encrypt, and external issuers, such as AWS Private Certificate Authority and AWS
    Key Management Service. It also ensures the validity of certificates and auto-renews
    and rotates them. You can learn more about the project here: [https://cert-manager.io/docs/](https://cert-manager.io/docs/).'
  prefs: []
  type: TYPE_NORMAL
- en: Cert-Manager will make TLS certificates available out of the box for Kubernetes
    workloads, and it will make issuing and managing these certificates a native feature
    within the Kubernetes cluster, which is easy to manage and operate.
  prefs: []
  type: TYPE_NORMAL
- en: Cert-Manager does not come pre-installed with the cluster, so you need to deploy
    it and specify its configuration, which includes its Docker image, the number
    of replicas to run, certificate issuers, DNS Route 53 zones, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'To deploy Cert-Manager, we will create three Kubernetes manifest files: namespace,
    controller, and certificate issuers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are various issuers supported by Cert-Manager. Please check here: [https://cert-manager.io/docs/configuration/](https://cert-manager.io/docs/configuration/).
    In this chapter, we decided to use Let''s Encrypt as it is free and commonly used,
    but you can use Cert-Manager documentation and the same deployment here with any
    of the other issuers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create the Ansible template and the configuration for it:'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You can find the complete source code of the Cert-Manager deployment template
    at [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/cert-manager](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/cert-manager).
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the required configuration variables and add them to the `group_vars`
    directory in this path – `ansible/group_vars/all/cert-manager.yaml`. The basic
    configuration contains the number of deployment replicas and the image tags for
    controller, webhook, and `cainjector`, which is useful for keeping track of the
    version deployed and for controlling its upgrades. Also, there is the configuration
    of Let''s Encrypt issuers for both `prod` and `nonprod` ACME URLs:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the namespace for Cert-Manager in this path – `ansible/templates/cert-manager/namespace.yaml`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the deployment template for the Cert-Manager controller resources in
    this path – `ansible/templates/cert-manager/cert-manager.yaml`. In this controller,
    we will only set variables for the deployment replicas and image tags. You can
    check the complete manifest YAML file here: [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/cert-manager/cert-manager.yaml](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/blob/master/Chapter06/ansible/templates/cert-manager/cert-manager.yaml).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create the issuer configuration for Let''s Encrypt in this path – `ansible/templates/cert-manager/letsencrypt-clusterissuer.yaml`.
    In this file, there are two configurations, the first for the certificates used
    for production workloads, and the other for non-production workloads. The main
    difference is that Let''s Encrypt will allow you to issue as many certificates
    as you want for non-production, but only limited numbers per week for production
    ones:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The second part of the previous issuer configuration is very similar to the
    production issuer, but with a different Let's Encrypt server.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To deploy the Cert-Manager add-on, please apply the deployment steps at the
    end of this chapter under the *Deploying the security configurations* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an example of how to use Cert-Manager and Let''s Encrypt and associate
    it with an ingress controller and a domain:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The previous `Ingress` resource uses the Cert-Manager annotation to connect
    to the Let's Encrypt TLS production certificate issuer, and it defines a host
    with a sample DNS `example.com` and `secretName` as `example-cert`, where Cert-Manager
    will store the TLS certificates retrieved from Let's Encrypt, and to be used by
    this `Ingress` resource. You can use the same `Ingress` resource, but with a domain
    name that you own.
  prefs: []
  type: TYPE_NORMAL
- en: To get an idea of how to use Cert-Manager in other use cases, please check the
    official documentation at [https://cert-manager.io/docs/usage/](https://cert-manager.io/docs/usage/).
  prefs: []
  type: TYPE_NORMAL
- en: Securing workloads and apps
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kubernetes provides different built-in and third-party solutions to ensure that
    your production workloads are running securely. We will explore what we regard
    as a must-have for your cluster before going to production, such as workload isolation
    techniques, pod security policies, network policies, and monitoring workload runtime
    security.
  prefs: []
  type: TYPE_NORMAL
- en: Isolating critical workloads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes, by design, has a single control plane for each cluster, which makes
    sharing a single cluster among tenants and workloads challenging, and requires
    the cluster owners to have a clear strategy about cluster multi-tenancy and resource
    sharing.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are different use cases where it is critical to address tenant and workload
    isolation:'
  prefs: []
  type: TYPE_NORMAL
- en: In many organizations, there are multiple teams, products, or environments that
    share a cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are cases where you provide Kubernetes as a service for your own organization
    or external organizations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Also, there is a common case when your Kubernetes infrastructure serves a **Software
    as a Service** (**SaaS**) product.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For the preceding use cases, we need to ensure that the cluster has the required
    configuration for workload isolation, where we can approach soft multi-tenancy
    using various Kubernetes objects, such as namespaces, RBAC, quotas, and limit
    ranges. This is what you will learn in this section and across this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we need to explore the different techniques for implementing tenants' isolation,
    while decreasing the risks associated with Kubernetes' single-tenancy design.
  prefs: []
  type: TYPE_NORMAL
- en: Using namespaces
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Namespaces are the first layer of isolation that Kubernetes provides. They provide
    a soft-tenancy mechanism to create boundaries for Kubernetes resources. A lot
    of Kubernetes security controls, such as network policies, access control, secrets,
    certificates, and other important security controls can be scoped on the namespace
    level. By separating tenant workloads into their own namespaces, you will be able
    to limit the impact of security attacks, as well as intentional and non-intentional
    mistakes by cluster users.
  prefs: []
  type: TYPE_NORMAL
- en: Creating separate node groups
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We usually avoid privileged containers, but in some cases, such as system pods
    or product-specific technical requirements, they are unavoidable. To reduce the
    impact of a security break, we isolate these pods on dedicated nodes and node
    groups where other tenants' workloads cannot get scheduled. The same can be applied
    to the pods with sensitive data. This approach decreases the risk of sensitive
    data being accessed by a less-secure application that shares the worker node.
    However, it does come with a drawback as it could increase the infrastructure
    cost, and when you take this design decision, you should weigh security versus
    cost.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing hard multi-tenancy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In specific use cases, hard multi-tenancy is a must, which is usually due to
    laws and regulatory requirements. In this situation, multi-tenancy can be achieved
    by provisioning separate clusters for each tenant, and this is what we call hard
    multi-tenancy. On the flip side, however, there are drawbacks, such as the challenges
    associated with managing these clusters when they grow in number, the increased
    total cost, and also the decreased compute utilization per cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Hardening the default pod security policy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**Pod security policy** (**PSP**) is a Kubernetes resource that is used to
    ensure that a pod has to meet specific requirements before getting created.'
  prefs: []
  type: TYPE_NORMAL
- en: PSPs have different security settings that you can configure either by increasing
    or decreasing pod privileges, aspects such as Linux capabilities allowed to the
    containers, host network access, and filesystem access.
  prefs: []
  type: TYPE_NORMAL
- en: It is still worthwhile mentioning that PSP is still in beta, and it would be
    unwelcome to deploy a beta feature for companies with strict production policies.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can define multiple PSPs in your cluster and assign them to different types
    of pods and namespaces to ensure that every workload and tenant has the correct
    access rights. EKS clusters come with a default PSP called `eks.privileged`, which
    is automatically created when you provision the cluster. You can view the specs
    of the `eks.privileged` PSP by describing it as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: This default `eks.privileged` PSP allows any authenticated user to run privileged
    containers across all namespaces. This behavior is intended to allow system pods
    such as the AWS VPC CNI and `kube-proxy` to run as privileged because they are
    responsible for configuring the host's network settings. However, you have to
    limit this behavior for other types of pods and namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a best practice, we recommend that you limit privileged pods to service
    accounts within the `kube-system` namespace or any other namespace that you use
    to isolate system pods. For all other namespaces that host other types of pods,
    we recommend assigning a restrictive default PSP. The following manifest defines
    a PSP to restrict privileged pods, and accessing the host network. We will add
    this manifest to our Ansible template''s automation at the following path: `ansible/templates/psp/default-psp.yaml`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'The following code snippet defines specs of the default PSP. It will not allow
    privileged containers, disables container privilege escalation, and drops all
    Linux capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'You can check the complete source code of the previous PSP resource here: [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/psp](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/psp).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following `ClusterRole` definition allows all roles that are bound to it
    to use the previous `default-psp` PSP:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'The following `ClusterRoleBinding` definition binds the `default-psp-user`
    `ClusterRole` to the `system:authenticated` RBAC group of users, which means that
    any user who is added to the cluster RBAC group, `system:authenticated`, has to
    create pods that comply with the `default-psp` PSP:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: You can create additional pod security policies according to your security requirements,
    but basically, your cluster needs to have two pod security policies; the first
    is `eks.privileged` for the pods in the `kube-system` namespace, and the second
    is `default-psp` for any other namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: Limiting pod access
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Usually, pods require access to the underlying cloud services, such as object
    stores, databases, and the DNS. Ideally, you do not want the production pods to
    access all services, or to access a service that they are not intended to use.
    This is why we need to limit pod access to just the services they use.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the AWS world, this can be achieved by utilizing the IAM roles and attaching
    this role and an access policy to the pod. `kube2iam` is one of Kubernetes'' add-ons
    that can do this job efficiently. It is an open source project that is battle-tested
    in production. It is easy to deploy, configure, and use. You can learn more about
    it here: [https://github.com/jtblin/kube2iam](https://github.com/jtblin/kube2iam).'
  prefs: []
  type: TYPE_NORMAL
- en: '`kube2iam` does not come pre-installed with the cluster, so you need to deploy
    it and specify its configuration, which includes its Docker image, iptables control,
    and the host network interface.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let''s create the Ansible template and configuration for them:'
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: You can find the complete source code at [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/kube2iam](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/kube2iam).
  prefs: []
  type: TYPE_NORMAL
- en: 'Define the required configuration variables and add them to the `group_vars`
    directory in this path – `ansible/group_vars/all/kube2iam.yaml`. The basic configuration
    contains the image tag for the `kube2iam` DaemonSet, which is useful for keeping
    track of the deployed version and for controlling its upgrades:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the deployment template for the Cert-Manager controller resources in
    this path – `ansible/templates/cert-manager/cert-manager.yaml`. In this controller,
    we will only set variables for the deployment replicas and image tags:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The following code snippet is the specification of the `kube2iam` DaemonSet.
    The most important part of the spec is the container runtime arguments'' section:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: The most notable configuration parameter in the previous YAML file is `"--iptables=true"`,
    which allows `kube2iam` to add iptables rules to block the pods from accessing
    the underlying worker node instance profile.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: To deploy `kube2iam`, please apply the deployment steps at the end of this chapter
    under the *Deploying the cluster's security configuration* section.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use `kube2iam` with a pod, you have to add the `iam.amazonaws.com/role annotation`
    to the pod annotations section, and add the IAM role to be used by the pod. Here
    is an example to illustrate how to use `kube2iam` with your pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: The preceding pod will run an `aws-cli` container that executes the S3 list
    command for a bucket. Please make sure to replace the placeholders with a valid
    IAM role ARN to the annotation section, and a valid S3 bucket name in the container
    command section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating network policies with Calico
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Communication between all pods within the cluster is allowed by default. This
    behavior is unsecure, especially in multi-tenant clusters. Earlier, you learned
    about the cluster network infrastructure and how to use security groups to control
    the network traffic among a cluster's nodes. However, security groups are not
    effective when it comes to controlling the traffic between pods. This is why Kubernetes
    provides the **Network Policy API**. These network policies allow the cluster's
    users to enforce ingress and egress rules to allow or deny network traffic among
    the pods.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes defines the Network Policy API specification, but it does not provide
    a built-in capability to enforce these network policies. So, to enforce them,
    you have to use a network plugin, such as Calico network policy.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can check your cluster to see whether there are any network policies in
    effect by using the following `kubectl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Calico is a network policy engine that can be deployed to Kubernetes, and it
    works smoothly with EKS as well. Calico implements all of Kubernetes' network
    policy features, but it also supports an additional richer set of features, including
    policy ordering, priority, deny rules, and flexible match rules. Calico network
    policy can be applied to different types of endpoints, including pods, VMs, and
    host interfaces. Unlike Kubernetes' network policies, Calico policies can be applied
    to namespaces, pods, service accounts, or globally across the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a default deny policy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As a security best practice, network policies should allow least privileged
    access. You start by creating a deny all policy that globally restricts all inbound
    and outbound traffic using Calico.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following Calico global network policy implements a default, deny-all ingress
    and egress policy across the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Once you have the default network policy to deny all traffic, you can add allow
    rules whenever needed by your pods. One of these policies is to add a global rule
    to allow pods to query CoreDNS for DNS resolution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: The preceding policy will allow egress network traffic from pods at any namespaces
    to query the CoreDNS in the `kube-system` namespace.
  prefs: []
  type: TYPE_NORMAL
- en: 'EKS does not come with Calico installed by default. So, we will include it
    in our Ansible configuration. You can view the full source code here: [https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/calico-np](https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter06/ansible/templates/calico-np).'
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring runtime with Falco
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There is an essential need to monitor workloads and containers for security
    violations at runtime. Falco enables the cluster's users to react in a timely
    manner for serious security threats and violations, or to catch security issues
    that bypassed cluster security scanning and testing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Falco is an open source project originally developed by Sysdig with a core
    functionality of threat detection in Kubernetes. It can detect violations and
    abnormally behaving applications and send alerts pertaining to them. You can learn
    more about the Falco project here: [https://github.com/falcosecurity/falco](https://github.com/falcosecurity/falco).'
  prefs: []
  type: TYPE_NORMAL
- en: Falco runs as a daemon on top of Kubernetes' worker nodes, and it has the violation
    rules defined in configuration files that you can customize according to your
    security requirements.
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the following commands at the worker nodes that you want to monitor.
    This will install and deploy Falco:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'To automate Falco''s deployment, we will include the previous commands in the
    worker node bootstrap user data using Terraform in this file: `terraform/modules/eks-workers/user-data.tf`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'One example of the security runtime violations that Falco can detect is detecting
    whenever a shell is started inside a container. The Falco rule for this violation
    appears as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'There are enormous rules that you can use and define in your Falco configuration.
    To learn more about them, refer to the Falco documentation and examples here:
    [https://falco.org/docs/examples/](https://falco.org/docs/examples/).'
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring cluster security and compliance
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are lots of moving parts and configurations that affect Kubernetes cluster
    security. And after deploying the security add-ons and adding more configurations,
    we need to make sure of the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The cluster security configuration is valid and intact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cluster is compliant with the standard security guidelines according to
    the **Center of Internet Security** (**CIS**) benchmark
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The cluster passes the conformance tests defined by the CNCF and its partners
    and community
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, you will learn how to validate and guarantee each of the previous
    points through using the relevant tools.
  prefs: []
  type: TYPE_NORMAL
- en: Executing Kubernetes conformance tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The Kubernetes community and CNCF have defined a set of tests that you can run
    against any Kubernetes cluster to ensure that this cluster passes tests in terms
    of specific storage features, performance tests, scaling tests, provider tests,
    and other types of validation that are defined by CNCF and the Kubernetes community.
    This gives the cluster operators the confidence to use it to serve in production.
  prefs: []
  type: TYPE_NORMAL
- en: Sonobuoy is a tool that you can use to run these conformance tests, and we recommend
    doing that for the new clusters, and periodically whenever you update your cluster.
    Sonobuoy makes it easier for you to ensure the state of your cluster without harming
    its operations or causing any downtime.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Sonobuoy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Apply the following instructions to install Sonobuoy on your local host:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Download the latest Sonobuoy release that matches your operating system: [https://github.com/vmware-tanzu/sonobuoy/releases](https://github.com/vmware-tanzu/sonobuoy/releases).'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Extract the Sonobuoy binary archive:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Move the Sonobuoy binary archive to your `bin` folder or to any directory on
    the `PATH` system.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Running Sonobuoy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Apply the following instructions to run Sonobuoy and then view the conformance
    test results:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Execute the following command to let Sonobuoy run the conformance tests and
    wait until it finishes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To get the test results, execute the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After you finish, you can delete Sonobuoy and it will remove its namespace
    and any resources that it created for testing purposes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: To ensure that your Kubernetes cluster is in a conformance state, we recommend
    automating execution of the Sonobuoy tests to run periodically on a daily basis
    or following the deployment of infrastructure and Kubernetes system-level changes.
    We do not recommend more frequent and continuous runs of Sonobuoy tests to avoid
    the excessive load this could bring to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Scanning cluster security configuration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: After completing the cluster conformance testing, you need to scan the configurations
    and security settings and ensure that there are no insecure or high-risk configurations.
    To achieve this, we will use `kube-scan`, which is a security scanning tool that
    scans cluster workloads and the runtime settings and assigns each one a rating
    from 0 (no risk) to 10 (high risk). `kube-scan` utilizes a scoring formula based
    on the Kubernetes Common Configuration Scoring System framework.
  prefs: []
  type: TYPE_NORMAL
- en: Installing kube-scan
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '`kube-scan` is installed as a Kubernetes deployment in your cluster by using
    the following `kubectl` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '`kube-scan` scans the cluster when it starts, and will periodically scan it
    once every day. This way, you can enforce rescanning by restarting the `kube-scan`
    pod.'
  prefs: []
  type: TYPE_NORMAL
- en: Running kube-scan
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Apply the following instructions to run `kube-scan` and view the scanning results:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To access the `kube-scan` results, you need to port forward the `kube-scan`
    service to port `8080` on your local machine:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Then, open `http://localhost:8080` in your browser to view the scan results.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Once you finish, you can delete `kube-scan` and its resources by using the
    following `kubectl` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: We recommend deploying `kube-scan` to your cluster and automating the scan result
    validation to run periodically on a daily basis or after deploying infrastructure
    and Kubernetes system-level changes. We do not recommend more frequent and continuous
    runs of Sonobuoy tests to avoid the excessive load this could bring to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Executing the CIS Kubernetes benchmark
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the final security validation stage of the cluster, you should test whether
    the cluster is deployed and configured according to the Kubernetes benchmark developed
    by the CIS.
  prefs: []
  type: TYPE_NORMAL
- en: To execute this test, you will use `kube-bench`, which is a tool that is used
    to run CIS Kubernetes benchmark checks.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: For managed Kubernetes services such as EKS, you cannot use `kube-bench` to
    inspect the master nodes as you do not have access to them. However, it is still
    possible to use `kube-bench` to inspect the worker nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Installing kube-bench
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are multiple ways to install `kube-bench`, one of them is to use a Docker
    container to copy the binary and the configurations to the host machine. The following
    command will install it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Running kube-bench
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Execute `kube-bench` against a Kubernetes node, and specify the Kubernetes
    version, such as 1.14 or any other supported version:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Instead of specifying a Kubernetes version, you can use a CIS Benchmark version,
    such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'And for EKS, you are allowed to run these specific targets: `master`, `node`,
    `etcd`, and `policies`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The outputs are either `PASS`; `FAIL`, which indicate that the test is completed;
    `WARN`, which means the test requires manual intervention; `INFO` is an informational
    output that requires no action.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: We recommend automating the execution of Sonobuoy, `kube-scan`, and `kube-bench`
    on a daily basis to verify security and compliance for your clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling audit logging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ensure that you enabled the cluster audit logs, and also that they are monitored
    for anomalous or unwanted API calls, especially any authorization failures. For
    EKS, you need to opt-in to enable these logs and have them streamed to CloudWatch.
  prefs: []
  type: TYPE_NORMAL
- en: 'To enable this, you need to update the Terraform EKS resource in this file,
    `terraform/modules/eks-cp/main.tf`, and add the following line of code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: After applying this Terraform change to the EKS configuration, the cluster audit
    logs will be streamed to CloudWatch, and you can take it from there and create
    alerts.
  prefs: []
  type: TYPE_NORMAL
- en: Bonus security tips
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'These are some general security best practices and tips that did not fit under
    any of the previous sections. However, I find them to be useful:'
  prefs: []
  type: TYPE_NORMAL
- en: Always keep Kubernetes updated to the latest version.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Update worker AMIs to the latest version. You have to be cautious because this
    change could introduce some downtime, especially if you are not using a managed
    node group.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Do not run Docker in Docker or mount the socket in a container.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Restrict the use of `hostPath` or, if `hostPath` is necessary, restrict which
    prefixes can be used and configure the volume as read-only.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Set requests and limits for each container to avoid resource contention and
    **Denial of Service** (**DoS**) attacks.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Whenever possible, use an optimized operating system for running containers.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Use immutable infrastructure, and automate the rotation of the cluster worker
    nodes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should not enable the Kubernetes dashboard.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Enable AWS VPC Flow Logs to capture metadata about the traffic flowing through
    a VPC, and then analyze it further for suspicious activities.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kubernetes security is a fast-growing domain, and you should keep following
    the latest guidelines and best practices, and integrate them into your processes
    and DevSecOps automations.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying the security configurations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The following instructions will deploy the cluster''s Ansible playbook, and
    it will deploy the security add-ons and configuration to the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Initialize the Terraform state and select the workspace by running the following
    commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Retrieve and configure `kubeconfig` for the target cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Execute the Ansible playbook:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will get the following output following successful Ansible execution:![Figure
    6.2 – Ansible execution output
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '](img/B16192_06_002.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Figure 6.2 – Ansible execution output
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Execute the following `kubectl` command to get all the pods running in the
    cluster. This will ensure that the cluster configuration is applied successfully:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should get the following output, which lists all the pods running in the
    cluster including the new pods for the security add-ons:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 6.3 – List of all pods'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16192_06_003.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 6.3 – List of all pods
  prefs: []
  type: TYPE_NORMAL
- en: Now you have completed applying the cluster configuration as per the previous
    instructions. And your cluster has all of the security add-ons and configuration
    deployed and ready for serving production.
  prefs: []
  type: TYPE_NORMAL
- en: Destroying the cluster
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'First, you should delete the `ingress-nginx` service to instruct AWS to destroy
    the NLB associated with the ingress controller. We need this step because Terraform
    will fail to destroy this NLB because it is created by Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'Then, you can follow the rest of the instructions in the *Destroying the network
    and cluster infrastructure* section in [*Chapter 3*](B16192_03_Final_PG_ePub.xhtml#_idTextAnchor073),
    *Provisioning Kubernetes Clusters Using AWS and Terraform*, to destroy the Kubernetes
    cluster and all related AWS resources. Please ensure that the resources are destroyed
    in the following order:'
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes cluster `packtclusters` resources
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Cluster VPC resources
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Terraform shared state resources
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: By executing the previous steps, you should have all Kubernetes and AWS infrastructure
    resources destroyed and cleaned up, ready for the hands-on practice in the next
    chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have learned about Kubernetes security best practices,
    and learned how to apply an end-to-end security approach to the cluster's infrastructure,
    network, containers, apps, secrets, apps, and the workload's runtime. You also
    learned how to apply and validate security compliance checks and tests. You developed
    all of the required templates and configuration as code for these best practices,
    controllers, and add-ons with Ansible and Terraform.
  prefs: []
  type: TYPE_NORMAL
- en: You deployed Kubernetes add-ons and controllers to provide essential services
    such as `kube2iam`, Cert-Manager, Sealed Secrets, and Falco, in addition to tuning
    Kubernetes-native security features such as pod security policies, network policies,
    and RBAC.
  prefs: []
  type: TYPE_NORMAL
- en: You acquired a solid knowledge of Kubernetes security in this chapter, but you
    should do a detailed evaluation of your cluster security requirements and take
    further action to deploy any extra tools and configurations that may be required.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, you will learn in detail about Kubernetes observability,
    and the monitoring and logging of best practices, tools, add-ons, and configurations
    that you need to deploy and optimize for production-grade clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can refer to the following links for more information on the topics covered
    in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Getting Started with Kubernetes – Third Edition* (*Chapter 14*, *Hardening
    Kubernetes*): [https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition](https://www.packtpub.com/virtualization-and-cloud/getting-started-kubernetes-third-edition)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Mastering Kubernetes – Second Edition* ([*Chapter 5*](B16192_05_Final_PG_ePub.xhtml#_idTextAnchor118),
    *Configuring Kubernetes Security, Limits, and Accounts*): [https://www.packtpub.com/application-development/mastering-kubernetes-second-edition](https://www.packtpub.com/application-development/mastering-kubernetes-second-edition)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Learn Kubernetes Security*: [https://www.packtpub.com/security/learn-kubernetes-security](https://www.packtpub.com/security/learn-kubernetes-security)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
