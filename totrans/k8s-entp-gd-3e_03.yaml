- en: '3'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '3'
- en: Kubernetes Bootcamp
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes训练营
- en: The previous chapter introduced you to deploying Kubernetes clusters using KinD
    (Kubernetes in Docker), which is useful for creating a development cluster on
    a single machine using containers instead of virtual machines. This approach reduces
    the system resource requirements and simplifies the entire setup process. We covered
    the installation and configuration of KinD, creating clusters, including add-ons
    like Ingress controllers, Calico as the CNI, and using persistent storage.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 上一章介绍了如何使用KinD（Kubernetes in Docker）部署Kubernetes集群，这对于在单台机器上使用容器而非虚拟机创建开发集群非常有用。此方法减少了系统资源的需求，并简化了整个设置过程。我们介绍了KinD的安装和配置，如何创建集群，包括Ingress控制器、Calico作为CNI以及如何使用持久存储。
- en: We understand that many of you have experience with Kubernetes, whether it’s
    running clusters in production or experimenting with tools like `kubeadm`, minikube,
    or Docker Desktop. Our intention with this book is to go beyond the fundamentals
    of Kubernetes, which is why we didn’t want to reiterate all the basics. Instead,
    we’ve included this chapter as a bootcamp for those who are new to Kubernetes
    or have only had limited exposure to it.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们理解，很多人已经具备Kubernetes的使用经验，无论是运行生产环境中的集群，还是尝试使用`kubeadm`、minikube或Docker Desktop等工具。本书的目的是超越Kubernetes的基础知识，因此我们不打算重复介绍所有的基础内容。相反，我们在本章中提供了一个针对新手或接触Kubernetes较少的人的训练营。
- en: In this chapter, we will explore the essential components of a Kubernetes cluster,
    including the control plane and worker nodes. We will provide detailed explanations
    of each Kubernetes resource and its respective use cases. If you have previous
    experience with Kubernetes and feel comfortable using `kubectl`, as well as an
    understanding of Kubernetes resources like **DaemonSets**, **StatefulSets**, and
    **ReplicaSets**, this chapter can serve as a helpful review before moving on to
    *Chapter 4*, where we will dive into **Services**, **Load Balancing**, **ExternalDNS**,
    **Global Balancing**, and **K8GB**.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探讨Kubernetes集群的基本组件，包括控制平面和工作节点。我们将详细解释每个Kubernetes资源及其相应的使用场景。如果你以前有Kubernetes经验，并且能够熟练使用`kubectl`，同时了解像**DaemonSets**、**StatefulSets**和**ReplicaSets**这样的Kubernetes资源，那么本章将作为一个有益的复习，帮助你为进入*第4章*做准备，在该章节中我们将深入讨论**服务**、**负载均衡**、**外部DNS**、**全局负载均衡**以及**K8GB**。
- en: 'Since this is a bootcamp chapter, we won’t get into every topic in detail.
    However, by the end of this chapter, you should have a solid understanding of
    the foundational concepts of Kubernetes, which will be crucial for comprehending
    the remaining chapters. Even if you already possess a strong background in Kubernetes,
    you may find this chapter valuable as a refresher before we get into more advanced
    topics. In this chapter, you will learn the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个训练营章节，我们不会对每个话题进行详细探讨。然而，在本章结束时，你应该能够扎实地理解Kubernetes的基础概念，这对于理解接下来的章节至关重要。即使你已经有了Kubernetes的扎实基础，本章也能作为一次复习，为接下来深入讨论更高级的主题做好准备。本章将涉及以下内容：
- en: An overview of Kubernetes components
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes组件概述
- en: Exploring the control plane
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索控制平面
- en: Understanding the worker node components
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解工作节点组件
- en: Interacting with the API server
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与API服务器交互
- en: Introducing Kubernetes resources
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍Kubernetes资源
- en: By the end of this chapter, you will have a solid understanding of the most
    commonly used cluster resources. Understanding Kubernetes resources is important
    for both cluster operators and cluster administrators.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将对最常用的集群资源有扎实的理解。了解Kubernetes资源对集群操作员和集群管理员都非常重要。
- en: Technical requirements
  id: totrans-12
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: This chapter has no technical requirements.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本章没有技术要求。
- en: If you want to execute commands while learning about the resources, you can
    use the KinD cluster that was deployed in the previous chapter.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在学习资源时想执行命令，可以使用上一章中部署的KinD集群。
- en: An overview of Kubernetes components
  id: totrans-15
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes组件概述
- en: Understanding the components of systems in an infrastructure is essential for
    delivering services effectively. In today’s wide landscape of installation options,
    many Kubernetes users may not have felt the need to fully comprehend the integration
    of different Kubernetes components.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 理解基础设施中系统组件的构成对于高效提供服务至关重要。在当今众多安装选项中，许多Kubernetes用户可能没有意识到完全理解不同Kubernetes组件的集成是必要的。
- en: Just a few years ago, establishing a Kubernetes cluster involved the manual
    installation and configuration of each component. This process presented a steep
    learning curve and often resulted in frustration. As a result, many individuals
    and organizations concluded that “Kubernetes is overly complex.” However, the
    benefit of manual installation was the in-depth understanding it provided regarding
    the interaction between each component. If any issues arose within the cluster
    after installation, you would have a clear understanding of where to investigate.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 几年前，建立Kubernetes集群需要手动安装和配置每个组件。这个过程具有陡峭的学习曲线，并且常常会导致挫败感。因此，许多人和组织得出结论：“Kubernetes过于复杂。”然而，手动安装的好处在于它能提供关于各个组件之间交互的深入理解。如果在安装后集群出现问题，你会清楚知道该从哪里开始调查。
- en: To understand how Kubernetes components work together, you must first understand
    the different components of a Kubernetes cluster.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 要理解Kubernetes组件如何协同工作，首先必须了解Kubernetes集群的不同组件。
- en: 'The following diagram is from the [http://Kubernetes.io](http://Kubernetes.io)
    site and shows a high-level overview of a Kubernetes cluster component:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 下图来自[http://Kubernetes.io](http://Kubernetes.io)网站，展示了Kubernetes集群组件的高级概览：
- en: '![Figure 5.1 – Kubernetes cluster components ](img/B21165_03_01.png)'
  id: totrans-20
  prefs: []
  type: TYPE_IMG
  zh: '![图5.1 – Kubernetes集群组件](img/B21165_03_01.png)'
- en: 'Figure 3.1: Kubernetes cluster components'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.1：Kubernetes集群组件
- en: As you can see, the Kubernetes cluster is made up of several components. As
    we progress through the chapter, we’ll discuss these components and the role they
    play in a Kubernetes cluster.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，Kubernetes集群由多个组件组成。在本章接下来的内容中，我们将讨论这些组件以及它们在Kubernetes集群中的作用。
- en: Exploring the control plane
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索控制平面
- en: The control plane, as its name suggests, has authority over every aspect of
    a cluster. In the absence of a functioning control plane, the cluster loses its
    ability to schedule workloads, create new deployments, and manage Kubernetes objects.
    Recognizing the criticality of the control plane, it is highly advisable to deploy
    with **high availability** (**HA**) support, deploying a minimum of three control
    plane nodes. Many production environments even utilize more than three control
    plane nodes, but the key principle is to have an odd number of nodes, which is
    required so we can maintain a highly available control plane if we lose a single
    `etcd` node.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 如其名称所示，控制平面对集群的各个方面具有控制权。如果控制平面无法正常工作，集群将失去调度工作负载、创建新部署和管理Kubernetes对象的能力。鉴于控制平面的重要性，强烈建议在部署时支持**高可用性**（**HA**），并至少部署三个控制平面节点。许多生产环境甚至使用三个以上的控制平面节点，但关键原则是保持奇数个节点，这样即使丢失一个`etcd`节点，我们也能保持高可用的控制平面。
- en: Now, let’s delve into the importance of the control plane and its components,
    providing a comprehensive understanding of their pivotal role in a functioning
    cluster.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们深入探讨控制平面的重要性及其组件，全面理解它们在集群中至关重要的作用。
- en: The Kubernetes API server
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes API服务器
- en: 'The first component to understand in a cluster is the `kube-apiserver` component.
    Since Kubernetes is **application programming interface** (**API**)-driven, every
    request that comes into a cluster goes through the API server. Let’s look at a
    simple `get nodes` request using an API endpoint, using the IP address for the
    control plane, which, in an enterprise, is usually fronted by a load balancer.
    In our example, our load balancer has an entry for the three control plane nodes
    on `10.240.100.100`:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在集群中要理解的第一个组件是`kube-apiserver`组件。由于Kubernetes是**应用程序编程接口**（**API**）驱动的，所有进入集群的请求都会通过API服务器。让我们来看一个简单的`get
    nodes`请求，使用控制平面的IP地址，通过API端点发送请求。在企业环境中，控制平面通常会通过负载均衡器来前置。在我们的示例中，负载均衡器有一个指向三个控制平面节点的条目，IP为`10.240.100.100`：
- en: '[https://10.240.100.100:6443/api/v1/nodes?limit=500](https://10.240.100.100:6443/api/v1/nodes?limit=500)'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://10.240.100.100:6443/api/v1/nodes?limit=500](https://10.240.100.100:6443/api/v1/nodes?limit=500)'
- en: If you attempt to make an API call without any credentials, you will receive
    a permission denied request. Using a pure API request directly is something that
    is very common when creating a pipeline for application deployment or even a Kubernetes
    add-on component. However, the most common method for users to interact with Kubernetes
    is the `kubectl` utility.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你尝试在没有任何凭证的情况下进行API调用，你将收到权限拒绝的请求。直接使用纯API请求是非常常见的做法，尤其是在创建应用程序部署管道或Kubernetes附加组件时。然而，用户与Kubernetes交互的最常见方式是使用`kubectl`工具。
- en: Every command that is issued using `kubectl` calls an API endpoint behind the
    scenes. In the preceding example, if we executed a `kubectl get nodes` command,
    an API request would be sent to the `kube-apiserver` process using the address
    `10.240.100.100` on port `6443`.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 每个使用`kubectl`发出的命令在幕后调用一个API端点。在前面的示例中，如果我们执行了`kubectl get nodes`命令，将向`kube-apiserver`进程发送一个API请求，使用地址`10.240.100.100`和端口`6443`。
- en: 'The API call requested the `/api/vi/nodes` endpoint, which returned a list
    of the nodes in the cluster:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: API调用请求了`/api/vi/nodes`端点，返回了集群中节点的列表：
- en: '[PRE0]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In the absence of a functioning API server, all requests directed to your cluster
    will fail. Therefore, it becomes crucial to ensure the continuous operation and
    health of the `kube-apiserver`.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 在没有正常运行的API服务器的情况下，所有发送到集群的请求都将失败。因此，确保`kube-apiserver`的持续运行和健康状态至关重要。
- en: By running three or more control plane nodes, we minimize any potential impact
    that could be caused by the loss of a control plane node.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 通过运行三个或更多的控制平面节点，可以最小化由于控制平面节点丢失可能造成的任何潜在影响。
- en: Remember, from the last chapter, that when running more than one control plane
    node, you need to have a load balancer in front of the cluster’s API server. The
    Kubernetes API server can be fronted by most standard solutions, including F5,
    HAProxy, and Seesaw.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 请记住，从上一章可以得知，当运行多个控制平面节点时，需要在集群的API服务器前面使用负载均衡器。Kubernetes API服务器可以由大多数标准解决方案（包括F5、HAProxy和Seesaw）提供支持。
- en: The etcd database
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: etcd数据库
- en: 'Describing `etcd` as the foundation of your Kubernetes cluster would not be
    an overstatement. `etcd` functions as a robust and highly efficient distributed
    key-value database that Kubernetes relies on to store all cluster data. Every
    resource present within the cluster is associated with a specific key in the `etcd`
    database. If you can access the node or pod that hosts `etcd`, you `will` be able
    to use the `etcdctl` executable to explore all the keys stored within the database.
    The code snippet provided below offers an example extracted from a cluster based
    on KinD:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 把`etcd`描述为你的Kubernetes集群的基础并不为过。`etcd`作为一个强大而高效的分布式键值数据库，Kubernetes依赖它来存储所有集群数据。集群中的每个资源都与`etcd`数据库中的特定键关联。如果你可以访问托管`etcd`的节点或Pod，你可以使用`etcdctl`可执行文件来探索数据库中存储的所有键。下面提供的代码片段展示了从基于KinD的集群中提取的示例：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The output from the preceding command contains too much data to list it all
    in this chapter. A base KinD cluster will return approximately 314 entries.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 前面命令的输出包含太多数据，无法在本章节中全部列出。一个基本的KinD集群将返回大约314个条目。
- en: 'All keys start with `/registry/<resource>`. For example, one of the keys that
    was returned is the `ClusterRole` for the `cluster-admin` key, as follows: `/registry/clusterrolebindings/cluster-admin`.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 所有键都以`/registry/<resource>`开头。例如，返回的键之一是`ClusterRole`为`cluster-admin`的键，如下所示：`/registry/clusterrolebindings/cluster-admin`。
- en: 'We can use the key name to retrieve the value using the `etcdctl` utility by
    slightly modifying our previous command, as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用键名通过略微修改之前的命令来使用`etcdctl`实用程序检索值，如下所示：
- en: '[PRE2]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The output will contain characters that cannot be interpreted by your shell,
    but you will get an idea of the data stored in `etcd`. For the `cluster-admin`
    key, the output shows us the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 输出将包含无法由你的Shell解释的字符，但你将了解到存储在`etcd`中的数据。对于`cluster-admin`键，输出向我们展示了以下内容：
- en: '[PRE3]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'We describe the entries in `etcd` to offer an understanding of how Kubernetes
    stores and utilizes data to manage cluster objects. While you’ve already observed
    the direct database output for the `cluster-admin` key, in typical scenarios,
    you would utilize the command `kubectl get clusterrolebinding cluster-admin -o
    yaml` to query the API server for the same data. Using `kubectl`, the command
    would yield the following information:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们描述了`etcd`中的条目，以便理解Kubernetes如何存储和利用数据来管理集群对象。虽然你已经观察到了`cluster-admin`键的直接数据库输出，但在典型情况下，你会使用`kubectl
    get clusterrolebinding cluster-admin -o yaml`命令来查询API服务器获取相同的数据。使用`kubectl`，该命令将返回以下信息：
- en: '![](img/B21165_03_02.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21165_03_02.png)'
- en: 'Figure 3.2: kubectl ClusterRoleBinding output'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.2：kubectl ClusterRoleBinding输出
- en: If you look at the output from the `kubectl` command and compare it with the
    output from the `etcdctl` query, you will see matching information. You will rarely
    have to interact with `etcd` directly; instead, you will execute `kubectl` commands,
    and the request will go to the API server, which then queries the `etcd` database
    for the resource’s information.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看 `kubectl` 命令的输出，并与 `etcdctl` 查询的输出进行比较，你会发现两者信息一致。你很少需要直接与 `etcd` 进行交互；你只需要执行
    `kubectl` 命令，请求会发送到 API 服务器，后者再查询 `etcd` 数据库以获取资源信息。
- en: It’s worth noting that while `etcd` is by far the most used backend database
    for Kubernetes, it isn’t the only one. The **k3s** project, which was originally
    built to strip down Kubernetes for edge use cases, replaced `etcd` with relational
    databases. When we dive into `vclusters`, which use k3s, we’ll see that it uses
    **SQLite** instead of `etcd`.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，虽然 `etcd` 是 Kubernetes 中最常用的后端数据库，但它并不是唯一的。最初为边缘使用场景简化 Kubernetes 的 **k3s**
    项目将 `etcd` 替换为关系型数据库。当我们深入了解使用 k3s 的 `vclusters` 时，我们会看到它使用的是 **SQLite** 而非 `etcd`。
- en: kube-scheduler
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kube-scheduler
- en: As its name suggests, the `kube-scheduler` component oversees the allocation
    of pods to nodes. Its primary task is to consistently monitor pods that have yet
    to be assigned to any specific node. The scheduler then assesses the resource
    requirements of each pod to determine the most suitable placement. This assessment
    takes multiple factors into account, including the availability of node resources,
    constraints, selectors, and affinity/anti-affinity rules. Nodes that satisfy these
    requirements are considered feasible nodes. Finally, from the resulting list of
    compatible nodes, the scheduler chooses the most appropriate one for scheduling
    the pod.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名称所示，`kube-scheduler` 组件负责监督将 Pod 分配到节点的过程。它的主要任务是持续监控那些尚未分配到任何特定节点的 Pod。调度器随后评估每个
    Pod 的资源需求，以确定最合适的放置位置。这个评估考虑了多个因素，包括节点资源的可用性、约束条件、选择器以及亲和性/反亲和性规则。满足这些要求的节点被视为可行节点。最终，调度器从符合条件的节点列表中选择最合适的节点来调度
    Pod。
- en: kube-controller-manager
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kube-controller-manager
- en: The **Kubernetes Controller Manager** is a central control system in the Kubernetes
    control plane; it’s responsible for managing and coordinating other controllers
    that handle specific tasks for the cluster.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes 控制器管理器** 是 Kubernetes 控制平面的核心控制系统；它负责管理和协调其他控制器，这些控制器处理集群中的特定任务。'
- en: The Controller Manager contains multiple controllers, each dedicated to a specific
    function within the cluster. These controllers continuously monitor the cluster’s
    current state and adapt dynamically to maintain the desired configuration.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 控制器管理器包含多个控制器，每个控制器负责集群中某个特定功能。这些控制器持续监控集群的当前状态，并动态调整以维持所需的配置。
- en: All of the controllers are contained in a single executable, reducing complexity
    and management. Some of the controllers included are shown in *Table 3.1*.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 所有控制器都包含在一个可执行文件中，减少了复杂性和管理工作。部分包含的控制器如 *表 3.1* 所示。
- en: 'Each controller provides a unique function to a cluster, and each controller
    and its function is listed here:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 每个控制器为集群提供独特的功能，以下是各个控制器及其功能：
- en: '| **Controller** | **Responsibilities** |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| **控制器** | **职责** |'
- en: '| Endpoints | Monitors new services and creates endpoints to the pods with
    matching labels |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| Endpoints | 监控新服务并为具有匹配标签的 Pod 创建端点 |'
- en: '| Namespace | Monitors actions for namespaces |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| Namespace | 监控命名空间的操作 |'
- en: '| Node | Monitors the status of nodes in the cluster, detecting node failures
    or additions, and taking appropriate actions to maintain the desired number of
    nodes |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| Node | 监控集群中节点的状态，检测节点故障或新增节点，并采取适当的行动以维持所需的节点数量 |'
- en: '| Replication | Monitors the replicas for pods, taking action to either remove
    a pod or add a pod to get to the desired state |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| Replication | 监控 Pod 的副本，采取行动以删除或添加 Pod 以达到所需状态 |'
- en: '| Service Accounts | Monitors Service accounts |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| Service Accounts | 监控服务账户 |'
- en: 'Table 3.1: Controllers and their functions'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.1：控制器及其功能
- en: Each controller runs a non-terminating (never-ending) control loop. These control
    loops monitor the state of each resource, making any changes required to normalize
    the state of the resource. For example, if you needed to scale a deployment from
    one to three nodes, the replication controller would notice that the current state
    has one pod running, and the desired state is to have three pods running. To move
    the current state to the desired state, two additional pods would be requested
    by the replication controller.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 每个控制器运行一个非终止（永不停歇）的控制循环。这些控制循环监控每个资源的状态，并根据需要进行更改，以使资源的状态恢复正常。例如，如果你需要将一个部署从一个节点扩展到三个节点，复制控制器会发现当前状态是运行了一个
    Pod，而期望的状态是有三个 Pod 运行。为了将当前状态移动到期望状态，复制控制器会请求再增加两个 Pod。
- en: cloud-controller-manager
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: cloud-controller-manager
- en: This is one component that you may not have run into, depending on how your
    clusters are configured. Similar to the `kube-controller-manager` component, this
    controller contains four controllers in a single binary.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个你可能没有接触过的组件，具体取决于你的集群配置。与 `kube-controller-manager` 组件类似，这个控制器包含四个控制器，在一个二进制文件中运行。
- en: The cloud controller provides integrations specific to a particular cloud provider’s
    Kubernetes service, enabling the utilization of cloud-specific functionalities
    such as load balancers, persistent storage, auto-scaling groups, and other features.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 云控制器提供与特定云提供商的 Kubernetes 服务相关的集成功能，使得可以利用云特定的功能，如负载均衡器、持久存储、自动扩展组等其他特性。
- en: Understanding the worker node components
  id: totrans-68
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解工作节点组件
- en: Worker nodes, as implied by their name, have the duty of carrying out tasks
    within a Kubernetes cluster. In our previous conversation about the `kube-scheduler`
    element in the control plane, we emphasized that when a new pod requires scheduling,
    the kube-scheduler selects the suitable node for its execution. The kube-scheduler
    relies on data provided by the worker nodes to make this determination. This data
    is regularly updated to ensure a distribution of pods throughout the cluster,
    making the most of the cluster resources.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 工作节点，顾名思义，负责在 Kubernetes 集群中执行任务。在我们之前讨论控制平面中 `kube-scheduler` 组件时，我们强调了当一个新的
    Pod 需要调度时，`kube-scheduler` 会选择合适的节点来执行该任务。`kube-scheduler` 依赖工作节点提供的数据来做出这一决定。这些数据会定期更新，以确保
    Pod 在集群中的分布，使集群资源得到充分利用。
- en: Each worker node has two main components, `kubelet` and `kube-proxy`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 每个工作节点都有两个主要组件，`kubelet` 和 `kube-proxy`。
- en: kubelet
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kubelet
- en: You may hear a worker node referred to as a `kubelet`. The `kubelet` is an agent
    that runs on all worker nodes, and it is responsible for ensuring that containers
    are running and healthy on the node.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能听到工作节点被称为 `kubelet`。`kubelet` 是一个在所有工作节点上运行的代理，负责确保容器在节点上运行并保持健康。
- en: kube-proxy
  id: totrans-73
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: kube-proxy
- en: Contrary to the name, `kube-proxy` is not a proxy server at all (though it was
    in the original version of Kubernetes).
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 与名称相反，`kube-proxy` 根本不是一个代理服务器（尽管它在 Kubernetes 的最初版本中是一个代理服务器）。
- en: Depending on the CNI deployed in your cluster, you may or may not have a `kube-proxy`
    component on your nodes. CNIs like **Cilium** can be run with `kube-proxy` or
    in a `kube-proxyless` mode. In our KinD clusters, we have deployed Calico, which
    relies on the presence of `kube-proxy`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 根据集群中部署的 CNI，你的节点可能会有也可能没有 `kube-proxy` 组件。像 **Cilium** 这样的 CNI 可以与 `kube-proxy`
    一起运行，或者在 `kube-proxyless` 模式下运行。在我们的 KinD 集群中，我们部署了 Calico，它依赖 `kube-proxy` 的存在。
- en: When `kube-proxy` is deployed, its main purpose is to oversee network connectivity
    for pods and services in the cluster, providing network traffic routing to the
    destination pod(s).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当 `kube-proxy` 被部署时，它的主要目的是管理集群中 Pods 和服务的网络连接，为目标 Pod(s) 提供网络流量路由。
- en: Container runtime
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器运行时
- en: Each node also needs a container runtime. A container runtime is responsible
    for running the containers. The first thing you might think of is Docker, and
    while Docker is a container runtime, it is not the only runtime option available.
    Over the last several years, other options have replaced Docker as the preferred
    container runtime for clusters.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 每个节点还需要一个容器运行时。容器运行时负责运行容器。你可能首先想到的是 Docker，虽然 Docker 是一个容器运行时，但它并不是唯一的运行时选项。近年来，其他选项已经取代了
    Docker，成为集群中首选的容器运行时。
- en: The two most prominent Docker replacements are **CRI-O** and **containerd**.
    At the time of writing this chapter, KinD only offers official support for Docker
    and Red Hat’s **Podman**.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 最突出的两种 Docker 替代品是 **CRI-O** 和 **containerd**。在撰写本章时，KinD 仅官方支持 Docker 和 Red
    Hat 的 **Podman**。
- en: Interacting with the API server
  id: totrans-80
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 与 API 服务器进行交互
- en: As we mentioned earlier, you interact with the API server using either direct
    API requests or the `kubectl` utility. We will focus on using `kubectl` for the
    majority of our interaction in this book, but we will call out using direct API
    calls wherever applicable.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前提到的，你可以通过直接的 API 请求或使用 `kubectl` 工具与 API 服务器进行交互。虽然我们在本书中主要集中使用 `kubectl`
    进行交互，但在适用的地方我们也会提到如何使用直接的 API 调用。
- en: Using the Kubernetes kubectl utility
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Kubernetes 的 kubectl 工具
- en: '`kubectl` is a single executable file that allows you to interact with the
    Kubernetes API using a **command-line interface** (**CLI**). It is available for
    most major operating systems and architectures, including Linux, Windows, and
    macOS.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl` 是一个单一的可执行文件，它允许你通过 **命令行界面**（**CLI**）与 Kubernetes API 进行交互。它支持大多数主流操作系统和架构，包括
    Linux、Windows 和 macOS。'
- en: 'Note: We have already installed `kubectl` using the KinD script that created
    our cluster in *Chapter 2*. Installation instructions for most operating systems
    are located on the Kubernetes site at [https://kubernetes.io/docs/tasks/tools/install-kubectl/](https://kubernetes.io/docs/tasks/tools/install-kubectl/).
    Since we are using Linux as our operating system for the exercises in the book,
    we will cover installing `kubectl` on a Linux machine. Follow these steps:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 注意：我们已经使用 KinD 脚本安装了 `kubectl`，该脚本创建了我们的集群，详见 *第 2 章*。大多数操作系统的安装说明可以在 Kubernetes
    网站上找到，网址为 [https://kubernetes.io/docs/tasks/tools/install-kubectl/](https://kubernetes.io/docs/tasks/tools/install-kubectl/)。由于我们使用
    Linux 作为本书练习的操作系统，接下来将介绍如何在 Linux 机器上安装 `kubectl`。请按照以下步骤操作：
- en: 'To download the latest version of `kubectl`, you can run a `curl` command that
    will download it, as follows:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要下载最新版本的 `kubectl`，你可以运行一个 `curl` 命令来下载它，如下所示：
- en: '[PRE4]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'After downloading, you need to make the file executable by running the following
    command:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载后，你需要运行以下命令使该文件变为可执行文件：
- en: '[PRE5]'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Finally, we will move the executable to our path, as follows:'
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将把可执行文件移动到系统路径中，如下所示：
- en: '[PRE6]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You now have the latest `kubectl` utility on your system and can execute `kubectl`
    commands from any working directory.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你的系统上已经安装了最新版本的 `kubectl` 工具，并且可以从任何工作目录执行 `kubectl` 命令。
- en: 'Kubernetes is updated about every 4 months. This includes upgrades to the base
    Kubernetes cluster components and the `kubectl` utility. You may run into a version
    mismatch between a cluster and your `kubectl` command, requiring you to either
    upgrade or download your `kubectl` executable. You can always check the version
    of both by running a `kubectl` `version` command, which will output the version
    of both the API server and the `kubectl` client. The output from a version check
    is shown in the following code snippet – please note, your output may differ from
    our example output:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 大约每 4 个月更新一次。这包括对基础 Kubernetes 集群组件和 `kubectl` 工具的升级。你可能会遇到集群与 `kubectl`
    命令版本不匹配的情况，这时你需要升级或下载新的 `kubectl` 可执行文件。你可以通过运行 `kubectl` `version` 命令来检查两个版本，这个命令会输出
    API 服务器和 `kubectl` 客户端的版本信息。版本检查的输出如下所示——请注意，你的输出可能与我们的示例输出不同：
- en: '[PRE7]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: As you can see from the output, the `kubectl` client is running version `1.30.0`
    and the cluster is running `1.30.0`. A minor version difference in the two will
    not cause any issues. In fact, the official supported version difference is within
    one major version release. So, if your client is running version 1.29 and the
    cluster is running 1.30.0, you would be within the supported version difference.
    While this may be supported, it doesn’t mean that you won’t run into issues if
    you are trying to use any new commands or resources included in the higher version.
    In general, you should try to keep your cluster and client version in sync to
    avoid any issues.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 从输出结果中可以看到，`kubectl` 客户端正在运行 `1.30.0` 版本，集群则运行 `1.30.0` 版本。两者之间的微小版本差异不会造成任何问题。事实上，官方支持的版本差异最多为一个主版本号。因此，如果你的客户端版本为
    1.29，而集群版本为 1.30.0，你仍然在支持的版本差异范围内。尽管这可能是被支持的，但如果你试图使用更高版本中包含的新命令或资源，可能会遇到一些问题。通常情况下，你应该尽量保持集群和客户端版本的一致性，以避免任何问题。
- en: 'Through the remainder of this chapter, we will discuss Kubernetes resources
    and how you interact with the API server to manage each one. But before diving
    into the different resources, we wanted to mention one commonly overlooked option
    of the `kubectl` utility: the `verbose` option.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的其余部分，我们将讨论 Kubernetes 资源以及如何与 API 服务器交互来管理每个资源。但在深入了解不同的资源之前，我们想提到一个经常被忽视的
    `kubectl` 工具选项：`verbose` 选项。
- en: Understanding the verbose option
  id: totrans-96
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解详细选项
- en: When you execute a `kubectl` command, the only outputs you will see by default
    are any direct responses to your command. If you were to look at all pods in the
    `kube-system` namespace, you would receive a list of all pods. In most cases,
    this is the desired output, but what if you issued a `get` `Pods` request and
    received an error from the API server? How could you get more information about
    what might be causing the error?
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 当你执行 `kubectl` 命令时，默认情况下你看到的唯一输出是对你的命令的任何直接响应。如果你查看 `kube-system` 命名空间中的所有 Pod，你将得到一个所有
    Pod 的列表。在大多数情况下，这是所期望的输出，但如果你发出 `get` `Pods` 请求并收到 API 服务器的错误，怎么办？你如何获取更多信息来找出导致错误的原因？
- en: By adding the `verbose` option to your `kubectl` command, you can get additional
    details about the API call itself and any replies from the API server. Often,
    the replies from the API server will contain additional information that may be
    useful to find the root cause of the issue.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在 `kubectl` 命令中添加 `verbose` 选项，你可以获取有关 API 调用本身以及 API 服务器的任何回复的附加信息。通常，API
    服务器的回复会包含一些额外的信息，这些信息可能对找到问题的根本原因很有帮助。
- en: The `verbose` option has multiple levels ranging from 0 to 9; the higher the
    number, the more output you will receive.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`verbose` 选项有多个级别，范围从 0 到 9，数字越高，输出的内容就越多。'
- en: 'The following screenshot has been taken from the Kubernetes site, detailing
    each level and what the output will include:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图来自 Kubernetes 官方网站，详细说明了每个级别及其输出内容：
- en: '![Figure 5.5 – Verbosity description ](img/B21165_03_03.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图 5.5 – 详细程度描述](img/B21165_03_03.png)'
- en: 'Figure 3.3: Verbosity description'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3.3：详细程度描述
- en: You can experiment with the levels by adding the `-v` or `--v` option to any
    `kubectl` command.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过向任何 `kubectl` 命令添加 `-v` 或 `--v` 选项来实验不同的级别。
- en: General kubectl commands
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一般 kubectl 命令
- en: The CLI allows you to interact with Kubernetes in an imperative and declarative
    manner. Using an imperative command involves you telling Kubernetes what to do—for
    example, `kubectl run nginx --image nginx`. This tells the API server to create
    a new pod called `nginx` that runs an image called `nginx`. While imperative commands
    are useful for development and quick fixes or testing, you will use declarative
    commands more often in a production environment. In a declarative command, you
    tell Kubernetes what you want. To use declarative commands, you send a manifest
    to the API server, written in either **JavaScript Object Notation** (**JSON**)
    or **YAML Ain’t Markup Language** (**YAML**), which declares what you want Kubernetes
    to create.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: CLI 允许你以命令式和声明式两种方式与 Kubernetes 进行交互。使用命令式命令意味着你告诉 Kubernetes 做什么——例如，`kubectl
    run nginx --image nginx`。这告诉 API 服务器创建一个名为 `nginx` 的 Pod，并运行一个名为 `nginx` 的镜像。虽然命令式命令在开发、快速修复或测试中很有用，但在生产环境中你将更多使用声明式命令。在声明式命令中，你告诉
    Kubernetes 你想要什么。要使用声明式命令，你需要向 API 服务器发送一个声明性清单，该清单使用 **JavaScript 对象表示法** (**JSON**)
    或 **YAML 不是标记语言** (**YAML**) 编写，声明你希望 Kubernetes 创建的内容。
- en: '`kubectl` includes commands and options that can provide general cluster information
    or information about a resource. The table below contains a cheat sheet of commands
    and what they are used for. We will use many of these commands in future chapters,
    so you will see them in action throughout the book:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '`kubectl` 包含可以提供一般集群信息或有关资源信息的命令和选项。下表包含了一些命令及其用途的小抄。我们将在未来的章节中使用这些命令，因此你将在本书中看到它们的实际应用：'
- en: '| **Cluster Commands** |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| **集群命令** |'
- en: '| `api-resources` | Lists supported API resources |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| `api-resources` | 列出支持的 API 资源 |'
- en: '| `api-versions` | Lists supported API versions |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| `api-versions` | 列出支持的 API 版本 |'
- en: '| `cluster-info` | Lists cluster information, including the API server and
    other cluster endpoints |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| `cluster-info` | 列出集群信息，包括 API 服务器和其他集群端点 |'
- en: '| **Object Commands** |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| **对象命令** |'
- en: '| `get <object>` | Retrieves a list of all objects (i.e., pods, ingress, etc.)
    |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| `get <object>` | 获取所有对象的列表（例如，pods、ingress 等） |'
- en: '| `describe <object>` | Provides details for the object |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| `describe <object>` | 提供对象的详细信息 |'
- en: '| `logs <pod name>` | Retrieve the logs for a pod |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| `logs <pod name>` | 获取某个 Pod 的日志 |'
- en: '| `edit <object>` | Edits an object interactively |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| `edit <object>` | 交互式编辑一个对象 |'
- en: '| `delete <object>` | Deletes an object |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| `delete <object>` | 删除一个对象 |'
- en: '| `label <object>` | Labels an object |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| `label <object>` | 给对象打标签 |'
- en: '| `annotate <object>` | Annotates an object |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| `annotate <object>` | 给对象添加注解 |'
- en: '| `run` | Creates a pod |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| `run` | 创建一个 pod |'
- en: 'Table 3.2: Cluster and object commands'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3.2：集群和对象命令
- en: With an understanding of each Kubernetes component and how to interact with
    the API server using imperative commands, we can now move on to Kubernetes resources
    and how we use `kubectl` to manage them.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 通过理解每个 Kubernetes 组件以及如何使用命令式命令与 API 服务器交互，我们现在可以继续了解 Kubernetes 资源以及如何使用 `kubectl`
    来管理它们。
- en: Introducing Kubernetes resources
  id: totrans-122
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Kubernetes 资源
- en: In this section, we will provide a substantial amount of information. However,
    as this is a bootcamp, we won’t go into exhaustive details about each resource.
    It’s worth noting that each resource could easily warrant its own dedicated chapter
    or even multiple chapters in a book. Since numerous books on basic Kubernetes
    already cover these resources extensively, we will focus on the essential aspects
    necessary for a basic understanding of each resource. As we progress through the
    subsequent chapters, we will supplement additional details about the resources
    as we expand our cluster using the exercises provided in the book.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将提供大量的信息。然而，由于这是一个训练营，我们不会深入讨论每个资源的详尽细节。值得注意的是，每个资源都可能需要单独一章，甚至是一本书的多个章节。由于许多关于基础
    Kubernetes 的书籍已经广泛讨论了这些资源，我们将集中讨论每个资源的基本理解所必需的核心内容。在接下来的章节中，我们将随着通过书中练习扩展集群，补充更多关于资源的细节。
- en: Prior to delving into a comprehensive understanding of Kubernetes resources,
    let’s begin by introducing the concept of Kubernetes manifests.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入全面理解 Kubernetes 资源之前，让我们先介绍一下 Kubernetes 清单的概念。
- en: Kubernetes manifests
  id: totrans-125
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 清单
- en: The files that we will use to create Kubernetes resources are referred to as
    manifests. A manifest can be created using YAML or JSON—most manifests use YAML,
    and that is the format we will use throughout the book.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用来创建 Kubernetes 资源的文件被称为清单。清单可以使用 YAML 或 JSON 创建——大多数清单使用 YAML，这也是我们在本书中使用的格式。
- en: It’s important to note that while we are working with YAML files, `kubectl`
    will convert all YAML into JSON when interacting with your API server. All API
    calls are made with JSON, even if the manifests are written in YAML.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，在使用 YAML 文件时，`kubectl` 会将所有 YAML 转换为 JSON 来与您的 API 服务器交互。所有 API 调用都是使用
    JSON，即使清单是用 YAML 编写的。
- en: 'The content of a manifest will vary depending on the resource, or resources,
    that will be created. At a minimum, all manifests require a base configuration
    that includes `apiVersion`, the `kind` of resource, and `metadata` fields, as
    can be seen here:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 清单的内容会根据将要创建的资源或多个资源而有所不同。最基本的，所有清单都需要包含一个基础配置，其中包括 `apiVersion`、资源的 `kind`
    和 `metadata` 字段，如下所示：
- en: '[PRE8]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The preceding manifest alone is not complete; we are only showing the beginning
    of a full `Deployment` manifest. As you can see in the file, we start with the
    three required fields that all manifests are required to have: the `apiVersion`,
    `kind`, and `metadata` fields.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的清单本身并不完整；我们仅展示了一个完整 `Deployment` 清单的开头。如您所见，文件中开始部分包含了所有清单必须具备的三个字段：`apiVersion`、`kind`
    和 `metadata` 字段。
- en: You may also notice that there is a format for fields in the file. YAML is very
    format-specific, and if the format of any line is off by even a single space,
    you will receive an error when you try to deploy the manifest. This takes time
    to get used to, and even after creating manifests for a long time, formatting
    issues will still pop up from time to time.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能还会注意到文件中的字段格式。YAML 格式非常严格，如果任何一行的格式错位了哪怕一个空格，您在尝试部署清单时会收到错误。这需要时间来适应，即使是创建清单很长时间的人，格式问题也时常会出现。
- en: What are Kubernetes resources?
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 Kubernetes 资源？
- en: When you want to add or delete something from a cluster, you are interacting
    with Kubernetes resources. This interaction is how you declare your desired state
    for the resource, which may be to create, delete, or scale a resource. Based on
    the desired state, the API server will make sure that the current state equals
    the desired state. For example, if you have a deployment that starts with a single
    replica, you can change the deployment resource from 1 to 3 replicas. When the
    API server sees that the current state is 1, it will scale the deployment out
    to 3 replicas by creating the additional 2 pods.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 当你想要添加或删除集群中的某个资源时，你实际上是在与Kubernetes资源进行交互。这种交互是你声明所需资源状态的方式，可能是创建、删除或扩展资源。根据期望的状态，API服务器会确保当前状态与期望状态一致。例如，如果你有一个从单个副本开始的部署，你可以将该部署资源的副本数从1更改为3。当API服务器发现当前状态为1时，它会通过创建额外的2个Pod将部署扩展到3个副本。
- en: To retrieve a list of resources a cluster supports, you can use the `kubectl
    api-resources` command. The API server will reply with a list of all resources,
    including any valid short name, namespace support, and supported API group.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 要获取集群支持的资源列表，可以使用`kubectl api-resources`命令。API服务器将返回一个资源列表，其中包括所有有效的短名称、命名空间支持以及支持的API组。
- en: There are approximately 58 base resources included with a Kubernetes cluster,
    but it’s very common to have many more than 58 in a production cluster. Many add-on
    components, like Calico, will extend the Kubernetes API with new objects. As a
    cluster has different add-ons deployed in the cluster, don’t be surprised at 100+
    resources in a list.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 一个Kubernetes集群大约包含58个基础资源，但在生产集群中，通常会有超过58个资源。许多附加组件，如Calico，会通过新对象扩展Kubernetes
    API。随着集群中部署了不同的附加组件，别对100+个资源的列表感到惊讶。
- en: 'An abbreviated list of the most common resources is shown below:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 显示了以下最常见资源的简要列表：
- en: '| **NAME** | **SHORT NAMES** | **API VERSION** | **NAMESPACED** |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| **NAME** | **SHORT NAMES** | **API VERSION** | **NAMESPACED** |'
- en: '| apiservices | apiregistration.k8s.io/v1 | FALSE |  |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| apiservices | apiregistration.k8s.io/v1 | FALSE |  |'
- en: '| certificatesigningrequests | Csr | certificates.k8s.io/v1 | FALSE |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| certificatesigningrequests | Csr | certificates.k8s.io/v1 | FALSE |'
- en: '| clusterrolebindings | rbac.authorization.k8s.io/v1 | FALSE |  |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| clusterrolebindings | rbac.authorization.k8s.io/v1 | FALSE |  |'
- en: '| clusterroles | rbac.authorization.k8s.io/v1 | FALSE |  |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| clusterroles | rbac.authorization.k8s.io/v1 | FALSE |  |'
- en: '| componentstatuses | Cs | v1 | FALSE |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| componentstatuses | Cs | v1 | FALSE |'
- en: '| configmaps | Cm | v1 | TRUE |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| configmaps | Cm | v1 | TRUE |'
- en: '| controllerrevisions | apps/v1 | TRUE |  |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| controllerrevisions | apps/v1 | TRUE |  |'
- en: '| cronjobs | Cj | batch/v1 | TRUE |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| cronjobs | Cj | batch/v1 | TRUE |'
- en: '| csidrivers | storage.k8s.io/v1 | FALSE |  |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| csidrivers | storage.k8s.io/v1 | FALSE |  |'
- en: '| csinodes | storage.k8s.io/v1 | FALSE |  |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| csinodes | storage.k8s.io/v1 | FALSE |  |'
- en: '| csistoragecapacities | storage.k8s.io/v1 | TRUE |  |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| csistoragecapacities | storage.k8s.io/v1 | TRUE |  |'
- en: '| customresourcedefinitions | crd,crds | apiextensions.k8s.io/v1 | FALSE |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| customresourcedefinitions | crd,crds | apiextensions.k8s.io/v1 | FALSE |'
- en: '| daemonsets | Ds | apps/v1 | TRUE |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| daemonsets | Ds | apps/v1 | TRUE |'
- en: '| deployments | Deploy | apps/v1 | TRUE |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| deployments | Deploy | apps/v1 | TRUE |'
- en: '| endpoints | Ep | v1 | TRUE |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| endpoints | Ep | v1 | TRUE |'
- en: '| endpointslices | discovery.k8s.io/v1 | TRUE |  |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| endpointslices | discovery.k8s.io/v1 | TRUE |  |'
- en: '| events | Ev | v1 | TRUE |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| events | Ev | v1 | TRUE |'
- en: '| events | Ev | events.k8s.io/v1 | TRUE |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| events | Ev | events.k8s.io/v1 | TRUE |'
- en: '| flowschemas | flowcontrol.apiserver.k8s.io/v1beta3 | FALSE |  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| flowschemas | flowcontrol.apiserver.k8s.io/v1beta3 | FALSE |  |'
- en: '| horizontalpodautoscalers | Hpa | autoscaling/v2 | TRUE |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| horizontalpodautoscalers | Hpa | autoscaling/v2 | TRUE |'
- en: '| ingressclasses | networking.k8s.io/v1 | FALSE |  |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| ingressclasses | networking.k8s.io/v1 | FALSE |  |'
- en: '| ingresses | Ing | networking.k8s.io/v1 | TRUE |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| ingresses | Ing | networking.k8s.io/v1 | TRUE |'
- en: '| jobs | batch/v1 | TRUE |  |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| jobs | batch/v1 | TRUE |  |'
- en: '| limitranges | Limits | v1 | TRUE |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| limitranges | Limits | v1 | TRUE |'
- en: '| localsubjectaccessreviews | authorization.k8s.io/v1 | TRUE |  |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| localsubjectaccessreviews | authorization.k8s.io/v1 | TRUE |  |'
- en: '| mutatingwebhookconfigurations | admissionregistration.k8s.io/v1 | FALSE |  |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| mutatingwebhookconfigurations | admissionregistration.k8s.io/v1 | FALSE |  |'
- en: '| namespaces | Ns | v1 | FALSE |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| namespaces | Ns | v1 | FALSE |'
- en: '| networkpolicies | Netpol | networking.k8s.io/v1 | TRUE |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| networkpolicies | Netpol | networking.k8s.io/v1 | TRUE |'
- en: '| nodes | No | v1 | FALSE |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| nodes | No | v1 | FALSE |'
- en: '| persistentvolumeclaims | Pvc | v1 | TRUE |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| persistentvolumeclaims | Pvc | v1 | TRUE |'
- en: '| persistentvolumes | pv | v1 | FALSE |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| persistentvolumes | pv | v1 | FALSE |'
- en: '| poddisruptionbudgets | pdb | policy/v1 | TRUE |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| poddisruptionbudgets | pdb | policy/v1 | TRUE |'
- en: '| pods | po | v1 | TRUE |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| pods | po | v1 | TRUE |'
- en: '| podtemplates | v1 | TRUE |  |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| podtemplates | v1 | TRUE |  |'
- en: '| priorityclasses | pc | scheduling.k8s.io/v1 | FALSE |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| priorityclasses | pc | scheduling.k8s.io/v1 | FALSE |'
- en: '| prioritylevelconfigurations | flowcontrol.apiserver.k8s.io/v1beta3 | FALSE
    |  |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| prioritylevelconfigurations | flowcontrol.apiserver.k8s.io/v1beta3 | FALSE
    |  |'
- en: '| profiles | projectcalico.org/v3 | FALSE |  |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| profiles | projectcalico.org/v3 | FALSE |  |'
- en: '| replicasets | rs | apps/v1 | TRUE |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| replicasets | rs | apps/v1 | TRUE |'
- en: '| replicationcontrollers | rc | v1 | TRUE |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| replicationcontrollers | rc | v1 | TRUE |'
- en: '| resourcequotas | quota | v1 | TRUE |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| resourcequotas | quota | v1 | TRUE |'
- en: '| rolebindings | rbac.authorization.k8s.io/v1 | TRUE |  |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| rolebindings | rbac.authorization.k8s.io/v1 | TRUE |  |'
- en: '| roles | rbac.authorization.k8s.io/v1 | TRUE |  |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| roles | rbac.authorization.k8s.io/v1 | TRUE |  |'
- en: '| runtimeclasses | node.k8s.io/v1 | FALSE |  |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| runtimeclasses | node.k8s.io/v1 | FALSE |  |'
- en: '| secrets | v1 | TRUE |  |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| secrets | v1 | TRUE |  |'
- en: '| selfsubjectaccessreviews | authorization.k8s.io/v1 | FALSE |  |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| selfsubjectaccessreviews | authorization.k8s.io/v1 | FALSE |  |'
- en: '| selfsubjectrulesreviews | authorization.k8s.io/v1 | FALSE |  |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| selfsubjectrulesreviews | authorization.k8s.io/v1 | FALSE |  |'
- en: '| serviceaccounts | sa | v1 | TRUE |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| serviceaccounts | sa | v1 | TRUE |'
- en: '| services | svc | v1 | TRUE |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| services | svc | v1 | TRUE |'
- en: '| statefulsets | sts | apps/v1 | TRUE |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| statefulsets | sts | apps/v1 | TRUE |'
- en: '| storageclasses | sc | storage.k8s.io/v1 | FALSE |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| storageclasses | sc | storage.k8s.io/v1 | FALSE |'
- en: '| subjectaccessreviews | authorization.k8s.io/v1 | FALSE |  |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| subjectaccessreviews | authorization.k8s.io/v1 | FALSE |  |'
- en: '| tokenreviews | authentication.k8s.io/v1 | FALSE |  |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| tokenreviews | authentication.k8s.io/v1 | FALSE |  |'
- en: '| validatingwebhookconfigurations | admissionregistration.k8s.io/v1 | FALSE
    |  |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| validatingwebhookconfigurations | admissionregistration.k8s.io/v1 | FALSE
    |  |'
- en: '| volumeattachments | storage.k8s.io/v1 | FALSE |  |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| volumeattachments | storage.k8s.io/v1 | FALSE |  |'
- en: 'Table 3.3: Kubernetes API resources'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3.3: Kubernetes API 资源'
- en: As this chapter functions as a bootcamp, we will provide a short overview of
    the resources found in *Table 3.3*. To effectively comprehend the following chapters,
    it is important for you to possess a strong understanding of the objects and their
    respective functions.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本章作为入门训练营，我们将简要概述*表3.3*中列出的资源。为了有效理解后续章节，您需要对这些对象及其各自的功能有深入了解。
- en: Some resources will also be explained in greater detail in future chapters,
    including `Ingress`, `RoleBindings`, `ClusterRoles`, `StorageClasses`, and more.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 一些资源将在后续章节中更详细地解释，包括 `Ingress`、`RoleBindings`、`ClusterRoles`、`StorageClasses`
    等。
- en: Reviewing Kubernetes resources
  id: totrans-195
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 审查 Kubernetes 资源
- en: Most resources in a cluster are run in a namespace, and to create/edit/read
    them, you should supply the `-n <namespace>` option to any `kubectl` command.
    To find a list of resources that accept a namespace option, you can reference
    the output from *Table 3.3*. If a resource can be referenced by a namespace, the
    `NAMESPACED` column will show `TRUE`. If the resource is only referenced by the
    cluster level, the `NAMESPACED` column will show `FALSE`.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 集群中的大多数资源运行在命名空间中，要创建、编辑或读取它们，您应当在任何`kubectl`命令中提供`-n <namespace>`选项。要查找接受命名空间选项的资源列表，您可以参考*表3.3*的输出。如果某个资源可以通过命名空间进行引用，则`NAMESPACED`列会显示`TRUE`。如果资源仅能通过集群级别进行引用，则`NAMESPACED`列会显示`FALSE`。
- en: Apiservices
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Apiservices
- en: Apiservices provide the primary entry point for communication and interaction
    between Kubernetes components and all external resources, such as users, applications,
    and other services. They provide a set of endpoints that allow users and applications
    to perform various operations, such as creating, updating, and deleting Kubernetes
    resources (i.e., pods, deployments, services, and namespaces).
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: Apiservices 提供 Kubernetes 组件与所有外部资源（如用户、应用程序和其他服务）之间通信和交互的主要入口点。它们提供一组端点，允许用户和应用程序执行各种操作，例如创建、更新和删除
    Kubernetes 资源（如 Pods、Deployments、Services 和 Namespaces）。
- en: Apiservices handle the authentication, authorization, and validation of requests,
    allowing only authorized users and applications to access or modify resources.
    They also handle resource versioning and other critical aspects of a Kubernetes
    cluster.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: Apiservices 处理请求的身份验证、授权和验证，只有经过授权的用户和应用程序才能访问或修改资源。它们还处理资源版本控制和 Kubernetes
    集群的其他关键方面。
- en: They can also extend Kubernetes functionality by developing custom controllers,
    operators, or other components that interact with the API Services to manage and
    automate various aspects of the cluster’s behavior. One example of this is our
    CNI, Calico, which adds 31 extra `api-resources` to a cluster.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 它们还可以通过开发自定义控制器、操作器或其他与 API Services 交互的组件来扩展 Kubernetes 功能，从而管理和自动化集群行为的各个方面。一个例子是我们的
    CNI 插件 Calico，它为集群添加了 31 个额外的 `api-resources`。
- en: CertificateSigningRequests
  id: totrans-201
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CertificateSigningRequests
- en: A **CertificateSigningRequest** (**CSR**) allows you to request a certificate
    from a certificate authority. These are typically used to obtain trusted certificates
    for securing communication within a Kubernetes cluster.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '**证书签名请求**（**CSR**）允许你向证书授权机构请求证书。这些请求通常用于获得可信证书，以保障Kubernetes集群内的通信安全。'
- en: ClusterRoles
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ClusterRoles
- en: 'A `ClusterRole` is a collection of permissions that enable interaction with
    the API of the cluster. It pairs an action, or verb, with an API group to define
    a specific permission. For example, if you intended to restrict a **continuous
    integration/continuous delivery** (**CI/CD**) pipeline’s ability to only patch
    Deployments for updating image tags, you could utilize a `ClusterRole` similar
    to the following:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '`ClusterRole`是权限的集合，它使得与集群API的交互成为可能。它将操作或动词与API组配对，定义特定的权限。例如，如果你想限制**持续集成/持续交付**（**CI/CD**）管道只能执行补丁操作以更新镜像标签，你可以使用类似于以下的`ClusterRole`：'
- en: '[PRE9]'
  id: totrans-205
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: A `ClusterRole` can apply to APIs at both the cluster and namespace levels.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '`ClusterRole`可以应用于集群和命名空间级别的API。'
- en: ClusterRoleBindings
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ClusterRoleBindings
- en: Once you have specified a `ClusterRole`, the next step is to create an association
    between the `ClusterRole` and a subject using a `ClusterRoleBinding`. This binding
    links the `ClusterRole` to a user, group, or service account, granting them the
    permissions defined within the `ClusterRole`.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你指定了`ClusterRole`，下一步是通过`ClusterRoleBinding`创建`ClusterRole`与主体之间的关联。这个绑定将`ClusterRole`与用户、组或服务账户关联，授予它们在`ClusterRole`中定义的权限。
- en: We’ll explore `ClusterRoleBinding` in more detail in *Chapter 7*, *RBAC Policies
    and Auditing*.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在*第7章*，*RBAC策略和审计*中详细探讨`ClusterRoleBinding`。
- en: ComponentStatus
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ComponentStatus
- en: The Kubernetes control plane is a crucial component for a cluster; it is essential
    for the operation of the cluster. `ComponentStatus` is an object that shows the
    health and status of different Kubernetes control plane components. It provides
    an indicator of the overall health of a component, providing information on whether
    it is operating correctly or has errors.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes控制平面是集群的关键组成部分，对于集群的正常运行至关重要。`ComponentStatus`是一个对象，展示不同Kubernetes控制平面组件的健康状况和状态。它提供了组件整体健康的指示，显示组件是否正常运行或是否存在错误。
- en: ConfigMaps
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ConfigMaps
- en: A ConfigMap is a resource that stores data in key-value pairs, enabling the
    separation of configuration from your application. `ConfigMaps` can hold various
    types of data, including literal values, files, or directories, allowing flexibility
    in managing your application’s configuration.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: ConfigMap是一种存储键值对数据的资源，使配置与应用程序分离。`ConfigMaps`可以保存各种类型的数据，包括文字值、文件或目录，从而在管理应用程序配置时提供灵活性。
- en: 'Here is an imperative example:'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一个命令式示例：
- en: '[PRE10]'
  id: totrans-215
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The `<data>` option will vary based on the source of the `ConfigMap`. To use
    a file or a directory, you supply the `--from-file` option and either the path
    to a file or an entire directory, as shown here:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '`<data>`选项将根据`ConfigMap`的来源而有所不同。要使用文件或目录，你需要提供`--from-file`选项，并指定文件路径或整个目录，如下所示：'
- en: '[PRE11]'
  id: totrans-217
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This would create a new `ConfigMap` named `config-test`, with the `nginx.conf`
    key containing the content of the `nginx.conf` file as the value.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个新的名为`config-test`的`ConfigMap`，其中`nginx.conf`键包含`nginx.conf`文件的内容作为值。
- en: 'If you need to have more than one key added in a single `ConfigMap`, you put
    each file into a directory and create the `ConfigMap` using all of the files in
    the directory. For example, you have three files in a directory located at `~/config/myapp`.
    The files each contain data and are called `config1`, `config2`, and `config3`.
    To create a `ConfigMap` that would add each file into a key, you need to supply
    the `--from-file` option and point to the directory, as follows:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要在一个`ConfigMap`中添加多个键，可以将每个文件放入一个目录，并使用该目录中的所有文件创建`ConfigMap`。例如，你在`~/config/myapp`目录中有三个文件，分别是`config1`、`config2`和`config3`。每个文件都包含数据。为了创建一个将每个文件添加为键的`ConfigMap`，你需要提供`--from-file`选项，并指向该目录，如下所示：
- en: '[PRE12]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This would create a new `ConfigMap` with three key values called `config1`,
    `config2`, and `config3`. Each key will contain a value equal to the content of
    each file in the directory.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个新的`ConfigMap`，包含三个键值`config1`、`config2`和`config3`。每个键的值将等于目录中每个文件的内容。
- en: 'To quickly show a `ConfigMap`, using the example mentioned above, we can retrieve
    `it` using the `get` command, `kubectl get configmaps config-test`, resulting
    in the following output:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 为了快速显示一个 `ConfigMap`，使用上述示例，我们可以通过 `get` 命令 `kubectl get configmaps config-test`
    来检索 `它`，并得到以下输出：
- en: '[PRE13]'
  id: totrans-223
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The `ConfigMap` is comprised of three keys, indicated by the presence of the
    number `3` under the `DATA` column. For a more detailed examination, we can utilize
    the `kubectl get` command with the additional “`-o yaml`" option appended to the
    `kubectl get configmaps config-test` command. This will show the output of each
    key’s value represented in YAML format, as demonstrated below:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConfigMap` 包含三个键，`DATA` 列下有数字 `3` 表示这一点。为了更详细地检查，我们可以使用带有额外“`-o yaml`”选项的
    `kubectl get` 命令，附加到 `kubectl get configmaps config-test` 命令中。这将显示每个键的值，以 YAML
    格式表示，如下所示：'
- en: '[PRE14]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: By examining the output, it shows that each key within the `ConfigMap` corresponds
    to the filenames found in the directory—`config1`, `config2`, and `config3`. Each
    key retains the value obtained from the data within its respective file.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 通过检查输出，显示每个 `ConfigMap` 中的键与目录中的文件名相对应——`config1`、`config2` 和 `config3`。每个键保留从其相应文件中的数据获得的值。
- en: One limitation of `ConfigMaps` that you should keep in mind is that the data
    is easily accessible to anyone with permission to the resource. As you can see
    from the preceding output, a simple `get` command shows the data in cleartext.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '`ConfigMaps` 的一个限制是，数据对于任何拥有资源访问权限的人来说都很容易访问。从前面的输出可以看出，一个简单的 `get` 命令就能以明文显示数据。'
- en: Due to this design, you should never store sensitive information such as a password
    in a `ConfigMap`. Later in this section, we will cover a resource that was designed
    to store secret data information, called a `Secret`.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这个设计，你永远不应该在 `ConfigMap` 中存储敏感信息，如密码。在本节后面，我们将介绍一个专门用于存储秘密数据的资源，叫做 `Secret`。
- en: ControllerRevisions
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ControllerRevisions
- en: A `ControllerRevision` is like a snapshot of a particular version or update
    to a controller’s settings. It’s mainly used by specific controllers, such as
    the `StatefulSet` controller, to keep track of and manage changes made to their
    configurations as time goes on.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '`ControllerRevision` 类似于控制器设置的特定版本或更新的快照。它主要由特定控制器使用，比如 `StatefulSet` 控制器，用来跟踪和管理随着时间推移对其配置所做的更改。'
- en: Whenever there are modifications or updates to the configuration of a resource
    managed by a controller, a new `ControllerRevision` is created. Each revision
    includes the desired setup of the controller and a revision number. These revisions
    are stored in the Kubernetes API server, allowing you to refer to or revert to
    them whenever necessary.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 每当有控制器管理的资源的配置被修改或更新时，都会创建一个新的 `ControllerRevision`。每个修订版包含控制器的期望设置和修订号。这些修订版存储在
    Kubernetes API 服务器中，允许你在需要时参考或恢复它们。
- en: CronJobs
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CronJobs
- en: If you have used Linux cronjobs in the past, then you already know what a Kubernetes
    `CronJob` resource is. If you don’t have a Linux background, a cronjob is used
    to create a scheduled task. As another example, if you are a Windows person, it’s
    similar to Windows scheduled tasks.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你曾使用过 Linux 的 cronjobs，那么你已经知道 Kubernetes 的 `CronJob` 资源是什么。如果你没有 Linux 背景，cronjob
    用于创建一个计划任务。举个例子，如果你是 Windows 用户，它类似于 Windows 的计划任务。
- en: 'An example manifest that creates a `CronJob` is shown in the following code
    snippet:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码片段显示了一个创建 `CronJob` 的示例清单：
- en: '[PRE15]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The `schedule` format follows the standard `cron` format. From left to right,
    each `*` represents the following:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '`schedule` 格式遵循标准的 `cron` 格式。从左到右，每个 `*` 代表以下内容：'
- en: Minute (0–59)
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分钟（0–59）
- en: Hour (0–23)
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 小时（0–23）
- en: Day (1–31)
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 天（1–31）
- en: Month (1–12)
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 月（1–12）
- en: Day of the week (0–6) (Sunday = 0, Saturday = 6)
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 星期几（0–6）（星期天 = 0，星期六 = 6）
- en: '`CronJob` accept step values, which allow you to create a schedule that can
    execute every minute, every 2 minutes, or every hour.'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '`CronJob` 接受步骤值，这允许你创建一个可以每分钟、每2分钟或每小时执行的计划。'
- en: Our example manifest will create a `CronJob` that runs an image called `hello-world`
    every minute and outputs `Hello World!` in the Pod log.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的示例清单将创建一个 `CronJob`，每分钟运行一个名为 `hello-world` 的镜像，并在 Pod 日志中输出 `Hello World!`。
- en: CSI drivers
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CSI 驱动程序
- en: Kubernetes uses the `CsiDriver` resource to connect nodes to a storage system.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 使用 `CsiDriver` 资源将节点连接到存储系统。
- en: 'You can list all CSI drivers that are available on a cluster by executing the
    `kubectl get csidriver` command. In one of our lab clusters, we are using NetApp’s
    SolidFire for storage, so our cluster has the Trident CSI driver installed, as
    can be seen here:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以通过执行 `kubectl get csidriver` 命令列出集群中所有可用的 CSI 驱动程序。在我们的一个实验室集群中，我们使用 NetApp
    的 SolidFire 存储，因此我们的集群已安装 Trident CSI 驱动程序，如下所示：
- en: '[PRE16]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: CSI nodes
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CSI 节点
- en: To avoid storing storage information in the node’s API resource, the `CSINode`
    resource was added to the API server to store information generated by the CSI
    drivers. The information that is stored includes mapping Kubernetes node names
    to CSI node names, CSI driver availability, and the volume topology.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免将存储信息存储在节点的 API 资源中，`CSINode` 资源被添加到 API 服务器中，以存储由 CSI 驱动程序生成的信息。存储的信息包括将
    Kubernetes 节点名称映射到 CSI 节点名称、CSI 驱动程序的可用性和存储卷拓扑。
- en: CSIStorageCapacities
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CSIStorageCapacities
- en: '`CSIStorageCapacity` is a component that stores information about the storage
    capacity for a given CSI, representing the available storage capacity for a given
    `StorageClass`. This information is used when K8s decides where to create new
    `PersistentVolumes`.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '`CSIStorageCapacity` 是一个存储有关给定 CSI 存储容量的组件，表示给定 `StorageClass` 的可用存储容量。当 Kubernetes
    决定在哪里创建新的 `PersistentVolumes` 时，使用这些信息。'
- en: CustomResourceDefinitions
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CustomResourceDefinitions
- en: A **CustomResourceDefinition** (**CRD**) is a way for users to make their own
    custom resources in a Kubernetes cluster.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '**CustomResourceDefinition**（**CRD**）是一种让用户在 Kubernetes 集群中创建自定义资源的方式。'
- en: It outlines the structure, format, and behavior of the custom resource, including
    its API endpoints and supported operations. Once a CRD is made and added to the
    cluster, it becomes a built-in resource type that can be managed using regular
    Kubernetes tools and APIs.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 它概述了自定义资源的结构、格式和行为，包括其 API 端点和支持的操作。一旦 CRD 被创建并添加到集群中，它就成为一个内建的资源类型，可以使用常规的
    Kubernetes 工具和 API 来管理。
- en: DaemonSets
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DaemonSets
- en: A `DaemonSet` enables the deployment of a pod on each node in a cluster or on
    a specific set of nodes. It is commonly utilized to deploy essential components
    like logging, which are required on every node in the cluster. Once a `DaemonSet`
    is set up, it automatically creates a pod on each existing node.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '`DaemonSet` 使得在集群中的每个节点或特定节点集上部署 pod 成为可能。它通常用于部署诸如日志记录等在集群每个节点上都需要的关键组件。一旦设置了
    `DaemonSet`，它会自动在每个现有节点上创建一个 pod。'
- en: Moreover, as new nodes are added to the cluster, the `DaemonSet` ensures that
    a pod is deployed on the newly joined nodes.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，随着新节点加入集群，`DaemonSet` 会确保在新加入的节点上部署一个 pod。
- en: Deployments
  id: totrans-258
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Deployments
- en: 'We mentioned earlier that you should never deploy a pod directly. One reason
    for this is that you cannot scale a pod or perform a rolling upgrade when a pod
    is created in this way. `Deployments` offer you many advantages, including a way
    to manage your upgrades declaratively and the ability to roll back to previous
    revisions. Creating a `Deployment` is actually a three-step process that is executed
    by the API server: a `Deployment` is created, which creates a `ReplicaSet`, which
    then creates the pod(s) for the application.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前提到过，你不应该直接部署一个 pod。这样做的一个原因是，你无法对 pod 进行扩缩容或执行滚动升级。`Deployments` 为你提供了许多优势，包括以声明方式管理升级以及能够回滚到先前的修订版本。创建一个
    `Deployment` 实际上是一个三步过程，由 API 服务器执行：首先创建一个 `Deployment`，然后创建一个 `ReplicaSet`，接着该
    `ReplicaSet` 会为应用程序创建 pod(s)。
- en: Even if you don’t plan to scale or perform rolling upgrades to the application,
    you should still use `Deployments` by default so that you can leverage the features
    at a future date.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 即使你不打算对应用程序进行扩缩容或执行滚动升级，默认情况下你仍然应该使用 `Deployments`，以便将来能够利用其功能。
- en: Endpoints
  id: totrans-261
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Endpoints
- en: 'An `Endpoint` maps a service to a pod or pods. This will make more sense when
    we explain the `Service` resource. For now, you only need to know that you can
    use the CLI to retrieve endpoints by using the `kubectl get endpoints` command.
    In a new KinD cluster, you will see a value for the Kubernetes API server in the
    default namespace, as illustrated in the following code snippet:'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '`Endpoint` 将一个服务映射到一个或多个 pod。当我们解释 `Service` 资源时，这将更容易理解。现在，你只需要知道，你可以使用 CLI
    执行 `kubectl get endpoints` 命令来检索端点。在一个新的 KinD 集群中，你将看到默认命名空间中的 Kubernetes API
    服务器值，如下的代码片段所示：'
- en: '[PRE17]'
  id: totrans-263
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: The output shows that the cluster has a service called `kubernetes` that has
    an endpoint at the **Internet Protocol** (**IP**) address `172.17.0.2` on port
    `6443`. The IP that is returned in our example is the address to which our Docker
    control plane container has been assigned.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 输出显示，集群中有一个名为 `kubernetes` 的服务，其端点位于 **互联网协议** (**IP**) 地址 `172.17.0.2` 的 `6443`
    端口。我们示例中返回的 IP 是分配给 Docker 控制平面容器的地址。
- en: Later, you will see how looking at endpoints can be used to troubleshoot service
    and ingress issues.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 稍后，你将看到如何通过查看端点来解决服务和入口问题。
- en: EndPointSlices
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: EndPointSlices
- en: '`Endpoints` do not scale well—they store all endpoints in a single resource.
    When dealing with a smaller deployment that may have a handful of pods, this isn’t
    an issue. As clusters grow and applications scale, endpoint sizes also grow, and
    this will impact the performance of your control plane and cause additional network
    traffic as endpoints change.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '`Endpoints` 的扩展性较差——它们将所有端点存储在一个单一的资源中。当处理一个小规模的部署时，可能只有几个 Pod，这时不会出现问题。然而，随着集群的扩展和应用程序的规模增长，端点数量也会增加，这会影响控制平面的性能并造成额外的网络流量，因为端点会发生变化。'
- en: '`EndPointSlices` are designed to take on more significant and larger scenarios
    that require scalability and precise control over network endpoints. By default,
    each `EndPointSlice` can hold up to 100 endpoints, which can be increased by adding
    the `--max-endpoints-per-slice` option to the `kube-controller-manager`.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '`EndPointSlices` 旨在处理更大规模的场景，这些场景需要可扩展性并对网络端点进行精确控制。默认情况下，每个 `EndPointSlice`
    最多可以容纳 100 个端点，可以通过向 `kube-controller-manager` 添加 `--max-endpoints-per-slice`
    选项来增加该数量。'
- en: Imagine that you have a deployment of a Service in Kubernetes with a large number
    of pods. If one of those pods is deleted, Kubernetes will only update the specific
    slice that contains the information about that pod. When the updated slice is
    distributed across the cluster, it will only include details for a smaller subset
    of pods. By doing so, the cluster network remains efficient and avoids becoming
    overwhelmed with excessive data.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你在 Kubernetes 中部署了一个包含大量 Pod 的服务。如果其中一个 Pod 被删除，Kubernetes 只会更新包含该 Pod 信息的特定切片。当更新后的切片分发到集群时，它将只包含更小子集的
    Pod 详细信息。通过这种方式，集群网络保持高效，避免因过多数据而被淹没。
- en: Events
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Events
- en: The `Events` resource will display any events for a namespace. To get a list
    of events for the `kube-system` namespace, you would use the `kubectl get events
    -n kube-system` command.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '`Events` 资源将显示命名空间中的所有事件。要获取 `kube-system` 命名空间的事件列表，可以使用 `kubectl get events
    -n kube-system` 命令。'
- en: FlowSchemas
  id: totrans-272
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: FlowSchemas
- en: Kubernetes clusters have predefined settings that manage the handling of concurrent
    requests to the API server, ensuring that the traffic does not overload the server.
    However, you have the flexibility to customize and configure your own flow schema
    and priority levels for requests directed at the API server in your clusters.
    This allows you to define specific rules and preferences for how requests are
    handled and prioritized, tailoring the behavior of the API server to suit your
    specific requirements and workload.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 集群具有预定义的设置来管理并发请求的处理，以确保流量不会超载 API 服务器。然而，你可以灵活地自定义并配置自己的流量模式和请求的优先级级别，以便根据你的具体要求和工作负载调整
    API 服务器的行为。
- en: For example, you have a namespace that has an important application deployed.
    You could create a `FlowSchema` with a high priority so the API server would handle
    requests for the namespace before other requests.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你有一个命名空间，其中部署了一个重要的应用程序。你可以创建一个高优先级的 `FlowSchema`，这样 API 服务器就会先处理该命名空间的请求，再处理其他请求。
- en: HorizontalPodAutoscalers
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: HorizontalPodAutoscalers
- en: One of the biggest advantages of running a workload on a Kubernetes cluster
    is the ability to automatically scale your pods. While you can scale using the
    `kubectl` command or by editing a manifest’s replica count, these are not automated
    and require manual intervention.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 集群上运行工作负载的最大优势之一就是能够自动扩展你的 Pods。虽然你可以使用 `kubectl` 命令或通过编辑清单的副本数量来进行扩展，但这些都不是自动化的，需要手动干预。
- en: '**Horizontal Pod Autoscalers** (**HPAs**) provide the ability to scale an application
    based on a set of criteria. Using metrics such as CPU and memory usage, or your
    own custom metrics, you can set a rule to scale your pods out when you need more
    pods to maintain your service level.'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '**水平 Pod 自动扩展器** (**HPAs**) 提供了根据一组标准扩展应用程序的能力。使用 CPU 和内存使用率或你自己定义的自定义指标，你可以设置规则，当你需要更多的
    Pod 来维持服务水平时，就会扩展 Pod 数量。'
- en: After a cooldown period, Kubernetes will scale the application back to the minimum
    number of pods defined in the policy.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 在冷却期过后，Kubernetes 将根据策略将应用程序的 Pod 数量缩减到最小值。
- en: 'To quickly create an HPA for an NGINX Deployment, we can execute a `kubectl`
    command using the `autoscale` option, as follows:'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 要快速为 NGINX 部署创建一个 HPA，我们可以执行一个 `kubectl` 命令，并使用 `autoscale` 选项，具体如下：
- en: '[PRE18]'
  id: totrans-280
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You can also create a Kubernetes manifest to create your HPAs. Using the same
    options as those we did in the CLI, our manifest would look like this:'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以创建一个 Kubernetes 清单来创建你的 HPA。使用与 CLI 中相同的选项，我们的清单看起来是这样的：
- en: '[PRE19]'
  id: totrans-282
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Both options will create an HPA that will scale `nginx-deployment` up to 5 replicas
    when the `Deployment` hits a CPU utilization of 50%. Once the `Deployment` usage
    falls below 50% and the cooldown period is reached (by default, 5 minutes), the
    replica count will be reduced to 1.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 两个选项都将创建一个 HPA，当 `Deployment` 的 CPU 利用率达到 50% 时，`nginx-deployment` 会扩展到 5 个副本。一旦
    `Deployment` 使用量降到 50% 以下，并且冷却期已达到（默认情况下为 5 分钟），副本数量将减少到 1。
- en: IngressClasses
  id: totrans-284
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IngressClasses
- en: '`IngressClasses` allow you to define and oversee various types of Ingress controllers.
    They offer the ability to personalize and adjust the behavior of these controllers
    according to specific needs, providing customizable routing of incoming traffic
    to services. `IngressClasses` allow you to manage and fine-tune Ingress controllers,
    ensuring that traffic is handled in a manner that aligns with your requirements.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '`IngressClasses` 允许你定义和管理各种类型的 Ingress 控制器。它们提供了根据特定需求个性化和调整这些控制器行为的能力，提供可定制的传入流量路由到服务的功能。`IngressClasses`
    使你能够管理和精细调整 Ingress 控制器，确保流量以符合你需求的方式进行处理。'
- en: The most important role an `IngressClass` has is to let you define multiple
    Ingress controllers in a single cluster. For instance, the Kubernetes Dashboard
    version 3 uses a specific `IngressClass` to make sure its `Ingress` objects are
    bound to an NGINX instance that doesn’t have a `LoadBalancer`, so it can’t be
    accessed from outside the cluster. You can also use this feature to connect Ingress
    controllers to different networks.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '`IngressClass` 最重要的作用是让你在单一集群中定义多个 Ingress 控制器。例如，Kubernetes Dashboard 版本 3
    使用特定的 `IngressClass`，确保其 `Ingress` 对象绑定到没有 `LoadBalancer` 的 NGINX 实例，这样它就不能从集群外部访问。你也可以使用这个功能将
    Ingress 控制器连接到不同的网络。'
- en: Ingress
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Ingress
- en: An `Ingress` resource is a tool that lets you create rules for incoming HTTP
    and HTTPS traffic to services using options like hostnames, paths, or request
    headers. It acts as a middleman between the external traffic and the services
    running in the cluster. By using `Ingress`, you can define how different types
    of traffic should be routed to specific services, giving you granular control
    over the flow of incoming requests.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '`Ingress` 资源是一个工具，允许你为传入的 HTTP 和 HTTPS 流量创建规则，通过主机名、路径或请求头等选项来服务。它充当外部流量与集群中运行的服务之间的中介。通过使用
    `Ingress`，你可以定义不同类型的流量应该如何路由到特定的服务，从而对传入请求的流量进行细粒度的控制。'
- en: We will discuss `Ingress` in depth in the next chapter, but a quick description
    of what `Ingress` provides is that it allows you to expose your application to
    the outside world using an assigned URL.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一章深入讨论 `Ingress`，但快速描述 `Ingress` 提供的功能是，它允许你使用指定的 URL 将你的应用程序暴露到外部世界。
- en: Jobs
  id: totrans-290
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Jobs
- en: '`Jobs` allow you to execute a specific number of executions of a pod or pods.
    Unlike a `CronJob` resource, these pods are not run on a set schedule, but rather
    they will execute once when they are created.'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '`Jobs` 允许你执行一定数量的 Pod 或 Pod 执行。与 `CronJob` 资源不同，这些 Pod 不会按固定计划运行，而是会在创建时执行一次。'
- en: LimitRanges
  id: totrans-292
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LimitRanges
- en: We will discuss the `Quota` resource later in this chapter, but a `LimitRange`
    is a configuration that allows you to establish and enforce specific boundaries
    and restrictions on resource allocations for pods and containers within a given
    namespace. By utilizing `LimitRanges`, you can define limits on resources, such
    as CPU, memory, and storage, ensuring that pods and containers operate efficiently
    and prevent any negative impact on the overall cluster environment.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在本章后面讨论`Quota`资源，但`LimitRange`是一种配置，允许你为指定命名空间内的Pod和容器建立并强制执行资源分配的特定边界和限制。通过使用`LimitRanges`，你可以定义资源限制，例如CPU、内存和存储，确保Pod和容器高效运行，并防止对整个集群环境造成负面影响。
- en: LocalSubjectAccessReview
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: LocalSubjectAccessReview
- en: '`LocalSubjectAccessReview` is a feature that helps you check if a user or group
    in the cluster has the required permissions to perform a specific action on a
    local resource. It enables you to review access permissions directly within the
    cluster without relying on external API requests.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '`LocalSubjectAccessReview`是一个功能，帮助你检查集群中某个用户或用户组是否具备在本地资源上执行特定操作所需的权限。它使你能够直接在集群内审查访问权限，而无需依赖外部API请求。'
- en: Using `LocalSubjectAccessReview`, you can specify the user or group identity
    along with the action and resource you want to evaluate. The Kubernetes API server
    will then verify the permissions against the local access control policies. It
    will respond with whether the requested action is allowed or denied.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`LocalSubjectAccessReview`，你可以指定用户或用户组的身份以及你希望评估的操作和资源。然后，Kubernetes API 服务器将根据本地访问控制策略验证权限，并响应请求的操作是允许还是拒绝。
- en: MutatingWebhookConfiguration
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 变更Webhook配置（MutatingWebhookConfiguration）
- en: '`MutatingWebhookConfiguration` is used to create webhooks that can intercept
    and modify requests sent to the API server, providing a way to automatically modify
    the requested resources.'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '`MutatingWebhookConfiguration`用于创建能够拦截并修改发送到API服务器请求的webhook，提供了一种自动修改请求资源的方式。'
- en: A `MutatingWebhookConfiguration` contains a set of rules that determine which
    requests should be intercepted and processed by a webhook. When a request matches
    the defined rules, the `MutatingWebhookConfiguration` triggers the corresponding
    webhooks, which can then modify the payload. Modifications can include adding,
    removing, or modifying fields and annotations in the resource being created or
    updated.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '`MutatingWebhookConfiguration`包含一组规则，决定哪些请求应该被拦截并由Webhook处理。当请求与定义的规则匹配时，`MutatingWebhookConfiguration`会触发相应的webhook，这些webhook可以修改请求的数据包。修改内容可以包括添加、删除或修改正在创建或更新的资源中的字段和注释。'
- en: Namespaces
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 命名空间（Namespaces）
- en: A `Namespace` is a resource to divide a cluster into logical units. Each `Namespace`
    allows granular management of resources, including permissions, quotas, and reporting.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '`Namespace`是一个资源，用于将集群划分为逻辑单元。每个`Namespace`允许对资源进行细粒度的管理，包括权限、配额和报告。'
- en: The `Namespace` resource is used for namespace tasks, which are cluster-level
    operations. Using the `namespace` resource, you can execute commands including
    `create`, `delete`, `edit`, and `get`.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '`Namespace`资源用于命名空间任务，这是集群级别的操作。使用`namespace`资源，你可以执行包括`create`、`delete`、`edit`和`get`等命令。'
- en: The syntax for the command is `kubectl <verb> ns <namespace name>`.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 命令的语法是`kubectl <verb> ns <namespace name>`。
- en: For example, to describe the `kube-system` namespace, we would execute a `kubectl
    describe namespaces kube-system` command.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，要描述`kube-system`命名空间，我们将执行`kubectl describe namespaces kube-system`命令。
- en: 'This will return information for the namespace, including any labels, annotations,
    and assigned quotas, as illustrated in the following code snippet:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 这将返回该命名空间的信息，包括任何标签、注释和分配的配额，如下面的代码片段所示：
- en: '[PRE20]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: In the preceding output, you can see that this namespace does not have any labels,
    annotations, or resource quotas assigned.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的输出中，你可以看到该命名空间没有分配任何标签、注释或资源配额。
- en: This section is only meant to introduce the concept of namespaces as a management
    unit in multi-tenant clusters. If you plan to run clusters with multiple tenants,
    you need to understand how namespaces can be used to secure a cluster.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 本节仅旨在介绍命名空间的概念，作为多租户集群中的管理单元。如果你计划运行具有多个租户的集群，你需要了解如何使用命名空间来保护集群。
- en: NetworkPolicies
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络策略（NetworkPolicies）
- en: '`NetworkPolicy` resources let you define how network traffic, both ingress
    (incoming) and egress (outgoing), can flow through your cluster. They allow you
    to use Kubernetes native constructs to define which pods can talk to other Pods.
    If you’ve ever used security groups in **Amazon Web Services** (**AWS**) to lock
    down access between two groups of systems, it’s a similar concept. As an example,
    the following policy will allow traffic on port `443` to pods in the `myns` namespace
    from any namespace with the `app.kubernetes.io/name: ingress-nginx` label on it
    (which is the default label for the `nginx-ingress` namespace):'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '`NetworkPolicy` 资源允许你定义网络流量的进出方式（即入站流量和出站流量）。它们使你能够使用 Kubernetes 的本地构造定义哪些
    Pod 可以与其他 Pod 通信。如果你曾经在 **Amazon Web Services**（**AWS**）中使用过安全组来限制两个系统组之间的访问，那么它的概念类似。举个例子，以下策略将允许来自任何具有
    `app.kubernetes.io/name: ingress-nginx` 标签的命名空间的流量访问 `myns` 命名空间中的端口 `443` 的 Pod（这是
    `nginx-ingress` 命名空间的默认标签）：  '
- en: '[PRE21]'
  id: totrans-311
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: A `NetworkPolicy` is another resource that you can use to secure a cluster.
    They should be used in all production clusters, but in a multi-tenant cluster,
    they should be considered a **must-have** to secure each namespace in the cluster.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '`NetworkPolicy` 是你可以用来保护集群的另一个资源。它们应该在所有生产集群中使用，但在多租户集群中，应该被视为**必需**的，以确保集群中每个命名空间的安全。  '
- en: Nodes
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'Nodes  '
- en: The `nodes` resource is a cluster-level resource that is used to interact with
    the cluster’s nodes. This resource can be used with various actions including
    `get`, `describe`, `label`, and `annotate`.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '`nodes` 资源是一个集群级别的资源，用于与集群的节点进行交互。此资源可以与各种操作一起使用，包括 `get`、`describe`、`label`
    和 `annotate`。  '
- en: 'To retrieve a list of all of the nodes in a cluster using `kubectl`, you need
    to execute a `kubectl get nodes` command. On a new KinD cluster running a simple
    one-node cluster, this would display as follows:'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '要使用 `kubectl` 获取集群中所有节点的列表，你需要执行 `kubectl get nodes` 命令。在一个新创建的 KinD 集群中运行一个简单的单节点集群时，显示内容如下：  '
- en: '[PRE22]'
  id: totrans-316
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: You can also use the nodes resource to get details of a single node using the
    `describe` command. To get a description of the KinD node listed previously, we
    can execute `kubectl describe node kind-control-plane`, which would return details
    on the node, including consumed resources, running pods, IP **classless inter-domain
    routing** (**CIDR**) ranges, and more.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: '你还可以使用节点资源通过 `describe` 命令获取单个节点的详细信息。要获取先前列出的 KinD 节点描述，我们可以执行 `kubectl describe
    node kind-control-plane`，这将返回节点的详细信息，包括消耗的资源、运行的 Pod、IP **无类域间路由**（**CIDR**）范围等。  '
- en: PersistentVolumeClaims
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'PersistentVolumeClaims  '
- en: A PVC is a namespaced resource that is used by a pod to consume persistent storage.
    A PVC uses a **persistent volume** (**PV**) to map the actual storage resource,
    which can be on any support storage system, including **NFS** and **iSCSI**.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 'PVC 是一个命名空间资源，供 Pod 使用以消耗持久存储。PVC 使用**持久卷**（**PV**）来映射实际的存储资源，这些资源可以位于任何支持的存储系统上，包括**NFS**和**iSCSI**。  '
- en: As with most resources we have discussed, you can issue `get`, `describe`, and
    `delete` commands on a PVC resource. Since these are used by pods in the namespace,
    PVCs must be created in the same namespace as the pod(s) that will use the PVC.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: '与我们讨论的大多数资源一样，你可以对 PVC 资源执行 `get`、`describe` 和 `delete` 命令。由于这些是由命名空间中的 Pod
    使用的，因此 PVC 必须在与将使用该 PVC 的 Pod 相同的命名空间中创建。  '
- en: PersistentVolumes
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PersistentVolumes
- en: PVs are used by PVCs to create a link between the PVC and the underlying storage
    system. Manually maintaining PVs is a messy, manual task, and it should be avoided.
    Instead, Kubernetes includes the ability to manage most common storage systems
    using the **Container Storage Interface** (**CSI**).
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 'PV 被 PVC 使用来创建 PVC 与底层存储系统之间的链接。手动维护 PV 是一项繁琐的手动任务，应避免进行。相反，Kubernetes 包括通过**容器存储接口**（**CSI**）管理大多数常见存储系统的能力。  '
- en: Most CSI solutions that are used in an Enterprise cluster provide auto-provisioning
    support, as we discussed in *Chapter 2* when we introduced Rancher’s local provisioner.
    Solutions that support auto-provisioning remove the administrative overhead that
    is required to create PVs manually, taking care of the creation and mapping of
    the PVs to PVCs automatically.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: '大多数在企业集群中使用的 CSI 解决方案提供自动配置支持，正如我们在*第二章*中介绍 Rancher 的本地配置器时所讨论的那样。支持自动配置的解决方案可以消除手动创建
    PV 所需的管理工作负担，自动处理 PV 的创建和与 PVC 的映射。  '
- en: PodDisruptionBudgets
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 'PodDisruptionBudgets  '
- en: A `PodDisruptionBudget` (PDB) is a resource that creates boundaries on the maximum
    number of unavailable pods at any given time. Its purpose is to prevent situations
    where multiple pods are terminated simultaneously, which could result in service
    disruptions or failures. By defining the minimum number of available pods, referred
    to as the `"minAvailable"` parameter, you can guarantee that a specific quantity
    of pods remains functional during maintenance or other disruptive occurrences.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '`PodDisruptionBudget`（PDB）是一种资源，用于限制在任何给定时间内不可用的 Pod 的最大数量。其目的是防止多个 Pod 同时终止，导致服务中断或故障。通过定义最小可用
    Pod 数量，称为 `"minAvailable"` 参数，你可以确保在维护或其他中断事件期间，特定数量的 Pod 保持可用。'
- en: The `kube-scheduler` in a cloud will use this information to figure out how
    to replace nodes during an upgrade. You need to be careful when using a `PodDisruptionBudget`
    because you could find a situation where an upgrade is halted.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在云环境中，`kube-scheduler` 将使用这些信息来确定如何在升级过程中替换节点。使用 `PodDisruptionBudget` 时需要小心，因为你可能会遇到升级被暂停的情况。
- en: Pods
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Pods
- en: 'The pod resource is used to interact with the pods that are running your container(s).
    Using the `kubectl` utility, you can use commands such as `get`, `delete`, and
    `describe`. For example, if you wanted to get a list of all pods in the `kube-system`
    namespace, you would execute a `kubectl get Pods -n kube-system` command that
    would return all pods in the namespace, as follows:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: Pod 资源用于与运行容器的 Pod 进行交互。使用 `kubectl` 工具，你可以使用诸如 `get`、`delete` 和 `describe`
    等命令。例如，如果你想列出 `kube-system` 命名空间中的所有 Pod，可以执行 `kubectl get Pods -n kube-system`
    命令，它会返回该命名空间中的所有 Pod，如下所示：
- en: '[PRE23]'
  id: totrans-329
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: While you can create a pod directly, you should avoid doing so unless you are
    using a pod for quick troubleshooting. pods that are created directly cannot use
    many of the features provided by Kubernetes, including scaling, automatic restarts,
    or rolling upgrades.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管你可以直接创建 Pod，但除非你仅使用 Pod 进行快速故障排除，否则不应直接创建。直接创建的 Pod 无法使用 Kubernetes 提供的许多功能，包括扩展、自动重启或滚动升级。
- en: Instead of creating a pod directly, you should use a `Deployment`, `StatefulSet`,
    or, in some rare cases, `ReplicaSet` resource or replication controller.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 与其直接创建 Pod，不如使用 `Deployment`、`StatefulSet` 或在某些特殊情况下使用 `ReplicaSet` 资源或复制控制器。
- en: PodTemplates
  id: totrans-332
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: PodTemplates
- en: '`PodTemplates` provide a way to create templates or blueprints for creating
    pods. They function as reusable configurations that include the desired specifications
    and settings for pods. They include the metadata and specifications of a pod,
    including the name, labels, containers, volumes, and other attributes.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: '`PodTemplates` 提供了一种创建 Pod 模板或蓝图的方法。它们作为可重用的配置，包括 Pod 的所需规格和设置。它们包含 Pod 的元数据和规格，包括名称、标签、容器、卷以及其他属性。'
- en: '`PodTemplates` are commonly used in other Kubernetes objects such as `ReplicaSets`,
    `Deployments`, and `StatefulSets`. These resources rely on a `PodTemplate` to
    generate and manage a collection of pods with consistent configurations and behavior.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '`PodTemplates` 通常用于其他 Kubernetes 对象，如 `ReplicaSets`、`Deployments` 和 `StatefulSets`。这些资源依赖于
    `PodTemplate` 来生成和管理具有一致配置和行为的 Pod 集合。'
- en: PriorityClasses
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优先级类（PriorityClasses）
- en: '`PriorityClasses` provide a way to prioritize pods based on their importance.
    This allows the Kubernetes scheduler to make better decisions regarding resource
    allocation and pod scheduling in a cluster.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: '`PriorityClasses` 提供了一种根据 Pod 重要性来优先处理的方式。这使得 Kubernetes 调度器能够在资源分配和 Pod 调度方面做出更好的决策。'
- en: To define `PriorityClasses`, you create a new `PriorityClass` resource associated
    with numeric values that indicate the priority level. pods with higher priority
    values are given priority over lower values when it comes to resource allocation
    and scheduling.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 定义 `PriorityClasses` 时，你需要创建一个新的 `PriorityClass` 资源，并为其分配数字值，以表示优先级水平。具有更高优先级值的
    Pod 会在资源分配和调度时优先于较低优先级的 Pod。
- en: Using `PriorityClasses`, you can guarantee that crucial workloads are given
    higher priority in terms of resource allocation and scheduling, providing the
    necessary resources to run smoothly.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `PriorityClasses`，你可以确保关键工作负载在资源分配和调度时优先获得所需的资源，从而保证其平稳运行。
- en: PriorityLevelConfigurations
  id: totrans-339
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 优先级配置（PriorityLevelConfigurations）
- en: '`PriorityLevelConfigurations` are objects that help define priority levels
    for requests sent to the API server. They provide control over how API requests
    are processed and prioritized within a cluster. Using `PriorityLevelConfigurations`,
    you can establish multiple priority levels, assigned to specific attributes. These
    attributes include setting limits on the maximum number of queries per second
    (QPS) and concurrent requests for a particular priority level. This allows for
    more efficient resource management and allocation based on the importance of different
    API requests.'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: '`PriorityLevelConfigurations` 是帮助定义请求发送到 API 服务器时的优先级的对象。它们控制 API 请求在集群中如何处理和优先级排序。通过使用
    `PriorityLevelConfigurations`，您可以建立多个优先级，并为特定属性分配优先级。这些属性包括设置每秒最大查询数（QPS）和特定优先级下的并发请求数量。这使得根据不同
    API 请求的重要性，能够更有效地管理和分配资源。'
- en: '`PriorityLevelConfigurations` allow you to enforce policies that ensure critical
    requests always receive enough resources, providing flexibility in managing the
    processing and allocation of resources for API requests.'
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: '`PriorityLevelConfigurations` 允许您强制执行策略，确保关键请求始终能够获得足够的资源，从而提供灵活性来管理 API 请求的处理和资源分配。'
- en: ReplicaSets
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ReplicaSets
- en: '`ReplicaSets` can be used to create a pod or a set of pods (replicas). Similar
    to the `ReplicationController` resource, a `ReplicaSet` will maintain the set
    number of pods defined in the replica count. If there are too few pods, Kubernetes
    will make up the difference and create the missing pods. If there are too many
    pods for a `ReplicaSet`, Kubernetes will delete pods until the number is equal
    to the replica count set.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '`ReplicaSets` 可以用来创建一个 Pod 或一组 Pod（副本）。与 `ReplicationController` 资源类似，`ReplicaSet`
    会保持副本计数中定义的 Pod 数量。如果 Pod 数量过少，Kubernetes 会补充差额并创建缺失的 Pod。如果 `ReplicaSet` 中的 Pod
    数量过多，Kubernetes 会删除 Pod，直到数量与设置的副本数相等。'
- en: In general, you should avoid creating `ReplicaSets` directly. Instead, you should
    create a `Deployment`, which will create and manage a `ReplicaSet`.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，您应避免直接创建 `ReplicaSets`。相反，您应该创建一个 `Deployment`，它将创建并管理一个 `ReplicaSet`。
- en: Replication controllers
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 复制控制器
- en: Replication controllers will manage the number of running pods, keeping the
    desired replicas specified running at all times. If you create a replication controller
    and set the replica count to `5`, the controller will always keep five pods of
    the application running.
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 复制控制器将管理正在运行的 Pod 数量，始终保持所需副本的运行。如果您创建一个复制控制器并将副本计数设置为 `5`，控制器将始终保持五个应用程序 Pod
    运行。
- en: Replication controllers have been replaced by the `ReplicaSet` resource, which
    we just discussed in its own section. While you can still use replication controllers,
    you should consider using a `Deployment` or a `ReplicaSet`.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 复制控制器已被 `ReplicaSet` 资源所取代，我们已经在其单独的部分进行了讨论。虽然您仍然可以使用复制控制器，但应考虑使用 `Deployment`
    或 `ReplicaSet`。
- en: ResourceQuotas
  id: totrans-348
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ResourceQuotas
- en: It is becoming very common to share a Kubernetes cluster between multiple teams,
    referred to as a **multi-tenant cluster**. Since you will have multiple teams
    working in a single cluster, you should create quotas to limit the potential of
    a single tenant consuming all the resources in a cluster or on a node.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在多个团队共享一个 Kubernetes 集群的情况下，**多租户集群**变得非常常见。由于您将有多个团队在同一个集群中工作，您应该创建配额，以限制单个租户消耗集群或节点上所有资源的潜力。
- en: 'Limits can be set on most cluster resources, including the following:'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数集群资源都可以设置限制，包括以下内容：
- en: Central processing unit (CPU)
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 中央处理单元（CPU）
- en: Memory
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 内存
- en: PVCs
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PVCs
- en: '`ConfigMaps`'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ConfigMaps`'
- en: Deployments
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署
- en: Pods, and more
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pods，等等
- en: Setting a limit will stop any additional resources from being created once the
    limit is hit. If you set a limit of 10 pods for a namespace and a user creates
    a new `Deployment` that attempts to start 11 Pods, the eleventh pod will fail
    to start up and the user will receive an error.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 设置限制后，一旦达到限制，将停止创建任何额外的资源。如果您为命名空间设置了 10 个 Pod 的限制，而用户创建了一个新的 `Deployment`，试图启动
    11 个 Pod，第 11 个 Pod 将无法启动，用户将收到错误信息。
- en: 'A basic manifest file to create a quota for memory and CPU would look like
    this:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 创建内存和 CPU 配额的基本清单文件如下所示：
- en: '[PRE24]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: This will set a limit on the total amount of resources the namespace can use
    for CPU and memory requests and limits.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 这将设置命名空间可以用于 CPU 和内存请求及限制的总资源量限制。
- en: Many of the options you can set in a quota are self-explanatory, like pods,
    PVCs, services, etc. When you set a limit, it means that the set limit is the
    maximum allowed for that resource in the namespace. For example, if you set a
    limit on a pod to 5, when an attempt is made to create a sixth pod in that namespace,
    it will be denied.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在配额中设置的许多选项是显而易见的，如 pods、PVCs、services 等。当你设置限制时，这意味着设置的限制是该命名空间中该资源的最大允许值。例如，如果你将
    pod 的限制设置为 5，当尝试在该命名空间中创建第六个 pod 时，它将被拒绝。
- en: 'Some quotas have more than one option that can be set: specifically, CPU and
    memory. In our example, both resources have set a request and a limit. Both values
    are very important to understand to ensure efficient use of your resources and
    to limit the potential availability of the application.'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: 一些配额有多个可以设置的选项：特别是 CPU 和内存。在我们的示例中，两个资源都设置了请求和限制。理解这两个值对于确保资源的高效使用以及限制应用程序的潜在可用性非常重要。
- en: A request is essentially a reservation of that specific resource. When a pod
    is deployed, you should always set a request on your CPU and memory, and the value
    should be the minimum required to start your application. This value will be used
    by the scheduler to find a node that meets the request that has been set. If there
    are no nodes with the requested resource available, the pod will fail to be scheduled.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 请求本质上是对特定资源的预留。当 pod 被部署时，你应该始终为 CPU 和内存设置请求，且该值应为启动应用程序所需的最小值。调度程序将使用这个值来寻找满足请求的节点。如果没有节点有可用的请求资源，pod
    将无法调度。
- en: Now, since a request will reserve the resource, that means once all nodes in
    the cluster have 100% of requests assigned, any additional pod creations will
    be denied since the requests are at 100%. Even if your actual cluster CPU or memory
    utilization is at 10%, pods will fail to be scheduled since the request, or **reservation**,
    is at 100%. If requests are not carefully thought out, it will lead to wasted
    resources, and that will lead to an increased cost to run the platform.
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，由于请求会保留资源，这意味着一旦集群中的所有节点都分配了 100% 的请求，任何额外的 pod 创建都将被拒绝，因为请求已经达到 100%。即使你实际集群的
    CPU 或内存使用率只有 10%，由于请求或 **预留** 已达到 100%，pod 仍然无法调度。如果请求没有经过仔细考虑，就会导致资源浪费，从而增加运行平台的成本。
- en: Limits on CPU and memory set the maximum value that the pod will be able to
    utilize. This is different from a request since limits are not a reservation of
    the resource. However, limits still need to be carefully planned out from an application
    side. If you set the CPU limit too low, the application may experience performance
    issues, and if you set the memory limit too low, the pod will be terminated, impacting
    availability while it is restarted.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: CPU 和内存的限制设置了 pod 可以使用的最大值。这与请求不同，因为限制不是对资源的预留。然而，从应用程序的角度来看，限制仍然需要仔细规划。如果你将
    CPU 限制设置得太低，应用程序可能会出现性能问题，如果你将内存限制设置得太低，pod 将被终止，影响可用性，直到重新启动。
- en: Once a quota has been created, you can view the usage using the `kubectl describe`
    command. In our example, we named the `ResourceQuota` as `base-memory-cpu`.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦创建了配额，你可以使用 `kubectl describe` 命令查看资源的使用情况。在我们的示例中，我们将 `ResourceQuota` 命名为
    `base-memory-cpu`。
- en: 'To view the usage, we will execute the `kubectl get resourcequotas base-memory-cpu`
    command, resulting in the following output:'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看使用情况，我们将执行 `kubectl get resourcequotas base-memory-cpu` 命令，结果如下所示：
- en: '[PRE25]'
  id: totrans-368
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: '`ResourceQuotas` serve as a means to manage and control the allocation of resources
    within a cluster. They allow you to assign specific CPU and memory resources to
    individual namespaces, ensuring that each tenant has sufficient resources to run
    their applications effectively. Additionally, `ResourceQuotas` act as a safeguard,
    preventing a poorly optimized or resource-intensive application from adversely
    affecting the performance of other applications in the cluster.'
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: '`ResourceQuotas` 作为一种手段，用于管理和控制集群内资源的分配。它们允许你为每个命名空间分配特定的 CPU 和内存资源，确保每个租户都有足够的资源来有效地运行他们的应用程序。此外，`ResourceQuotas`
    还充当保护机制，防止优化不良或资源密集型的应用程序对集群中其他应用程序的性能产生不利影响。'
- en: RoleBindings
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RoleBindings
- en: 'The `RoleBinding` resource is how you associate a `Role` or `ClusterRole` with
    a subject and namespace. For instance, the following `RoleBinding` will allow
    the `aws-codebuild` user to apply the `patch-openunison ClusterRole` to the `openunison`
    namespace:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: '`RoleBinding` 资源用于将 `Role` 或 `ClusterRole` 与主体和命名空间关联起来。例如，以下的 `RoleBinding`
    将允许 `aws-codebuild` 用户将 `patch-openunison ClusterRole` 应用到 `openunison` 命名空间：'
- en: '[PRE26]'
  id: totrans-372
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Even though this references a `ClusterRole`, it will only apply to the `openunison`
    namespace. If the `aws-codebuild` user tries to patch a Deployment in another
    namespace, the API server will stop it.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这里引用了一个 `ClusterRole`，它只会应用于 `openunison` 命名空间。如果 `aws-codebuild` 用户尝试修补另一个命名空间中的
    Deployment，API 服务器会阻止它。
- en: Roles
  id: totrans-374
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Roles
- en: As with a `ClusterRole`, Roles combine API groups and actions to define a set
    of permissions that can be assigned to a subject. The difference between a `ClusterRole`
    and a `Role` is that a `Role` can only have resources defined at the namespace
    level and they apply only within a specific namespace.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 与 `ClusterRole` 类似，Roles 结合了 API 组和操作，定义了一组可以分配给主体的权限。`ClusterRole` 和 `Role`
    的区别在于，`Role` 只能拥有在命名空间级别定义的资源，并且仅适用于特定的命名空间。
- en: RuntimeClasses
  id: totrans-376
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: RuntimeClasses
- en: '`RuntimeClasses` are used to set up and customize different runtime environments
    for running containers. They provide the flexibility to choose and configure the
    container runtime that best suits your workloads. By using `RuntimeClasses`, you
    can fine-tune the container runtime according to your specific requirements.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: '`RuntimeClasses` 用于设置和定制不同的运行时环境，以便运行容器。它们提供了灵活性，可以选择和配置最适合工作负载的容器运行时。通过使用
    `RuntimeClasses`，你可以根据特定的需求来微调容器运行时。'
- en: Each `RuntimeClass` is linked to a specific container runtime, like Docker or
    Containerd. They include configurable parameters that define how the chosen container
    runtime behaves. These parameters include resource limits, security configurations,
    and environment variables.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 每个 `RuntimeClass` 都与特定的容器运行时（如 Docker 或 Containerd）相关联。它们包含可配置的参数，定义所选容器运行时的行为。这些参数包括资源限制、安全配置和环境变量。
- en: Secrets
  id: totrans-379
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Secrets
- en: Earlier, we described how to use a `ConfigMap` resource to store configuration
    information. We mentioned that `ConfigMap` should never be used to store any type
    of sensitive data. This is the job of a `Secret`.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们描述了如何使用 `ConfigMap` 资源来存储配置信息。我们提到过，`ConfigMap` 永远不应该用于存储任何类型的敏感数据。这是 `Secret`
    的职责。
- en: '`Secrets` are stored as Base64-encoded strings, which aren’t a form of encryption.
    So, why separate `Secrets` from `ConfigMap`? Providing a separate resource type
    offers an easier way to maintain access controls and the ability to inject sensitive
    information using an external secret management system.'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: '`Secrets` 作为 Base64 编码的字符串存储，这并不是一种加密方式。那么，为什么要将 `Secrets` 与 `ConfigMap` 分开存储呢？提供一个独立的资源类型可以更容易地维护访问控制，并且能够使用外部的秘密管理系统来注入敏感信息。'
- en: '`Secrets` can be created using a file, directory, or from a literal string.
    As an example, we have a MySQL image we want to execute, and we would like to
    pass the password to the pod using a Secret. On our workstation, we have a file
    called `dbpwd` in our current working directory that has our password in it. Using
    the `kubectl` command, we can create a `Secret` by executing `kubectl create secret
    generic mysql-admin --from-file=./dbpwd`.'
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
  zh: '`Secrets` 可以通过文件、目录或文字字符串来创建。例如，我们有一个 MySQL 镜像，想要执行它，并且希望通过 Secret 将密码传递给 Pod。在我们的工作站中，我们的当前工作目录下有一个名为
    `dbpwd` 的文件，里面存储了密码。使用 `kubectl` 命令，我们可以通过执行 `kubectl create secret generic mysql-admin
    --from-file=./dbpwd` 来创建一个 `Secret`。'
- en: 'This would create a new `Secret` called `mysql-admin` in the current namespace,
    with the content of the `dbpwd` file. Using `kubectl`, we can get the output of
    the `Secret` by running the `kubectl get secret mysql-admin -o yaml` command,
    which would output the following:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 这将创建一个名为 `mysql-admin` 的新 `Secret`，内容为 `dbpwd` 文件中的内容。使用 `kubectl`，我们可以通过运行
    `kubectl get secret mysql-admin -o yaml` 命令来获取该 `Secret` 的输出，结果如下：
- en: '[PRE27]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Looking at the preceding output, you can see that the `data` section contains
    the name of our file and then a Base64-encoded value, which was created from the
    content of the file.
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出可以看到，`data` 部分包含了我们的文件名，然后是一个 Base64 编码的值，这是由文件内容生成的。
- en: 'If we copy the Base64 value from the `Secret` and pipe it out to the `base64`
    utility, we can easily decode the password, as follows:'
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们从 `Secret` 中复制 Base64 值，并将其传递给 `base64` 工具，我们可以轻松解码密码，如下所示：
- en: '[PRE28]'
  id: totrans-387
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: When using the `echo` command to Base64-encode strings, add the `-n` flag to
    avoid adding an additional `\n`. Instead of `echo 'test' | base64`, use `echo
    -n 'test' | base64`.
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`echo`命令对字符串进行Base64编码时，添加`-n`标志以避免添加额外的`\n`。改用`echo -n 'test' | base64`，而不是`echo
    'test' | base64`。
- en: Everything is stored in `etcd` but we are concerned that someone may be able
    to hack into the `etcd` node and steal a copy of the etcd database. Once someone
    has a copy of the database, they could easily use the `etcdctl` utility to look
    through the content to retrieve all of our Base64-encoded Secrets. Luckily, Kubernetes
    added a feature to encrypt `Secrets` when they are written to a database.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 所有内容都存储在`etcd`中，但我们担心有人可能会入侵`etcd`节点并窃取`etcd`数据库的副本。一旦有人获得了数据库的副本，他们可以轻松使用`etcdctl`工具浏览内容，检索我们所有的Base64编码的Secrets。幸运的是，Kubernetes添加了一个功能，在写入数据库时加密`Secrets`。
- en: Enabling this feature can be fairly complex for many users, and while it sounds
    like a good idea, it does present some potential issues that you should consider
    before implementing it. If you would like to read the steps on encrypting your
    Secrets at rest, you can view these on the Kubernetes site at [https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/).
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
  zh: 启用此功能对于许多用户来说可能相当复杂，尽管它听起来是个好主意，但它确实存在一些潜在的问题，你应该在实施之前考虑这些问题。如果你想阅读有关加密静态Secrets的步骤，可以访问Kubernetes网站的[https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/](https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/)。
- en: Another option to secure Secrets is to use a third-party secrets management
    tool such as HashiCorp’s Vault or CyberArk’s Conjur. We’ll cover integration with
    secret management tools in *Chapter 9*, *Managing Secrets in Kubernetes*.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个保护Secrets的选项是使用第三方秘密管理工具，如HashiCorp的Vault或CyberArk的Conjur。我们将在*第9章*，*Kubernetes中的Secrets管理*中介绍与秘密管理工具的集成。
- en: SelfSubjectAccessReviews
  id: totrans-392
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SelfSubjectAccessReviews
- en: '`SelfSubjectAccessReviews` objects enable users or entities to check their
    own permissions for performing specific actions on resources in their namespace.'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
  zh: '`SelfSubjectAccessReviews`对象使用户或实体能够检查他们在命名空间内执行特定操作所需的权限。'
- en: To use `SelfSubjectAccessReviews`, users provide their username along with the
    desired action and resource to check. The cluster evaluates the permissions of
    the provided user against the access control policies in the namespace, and the
    API server responds with whether the requested action is allowed or denied.
  id: totrans-394
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`SelfSubjectAccessReviews`，用户提供用户名以及要检查的操作和资源。集群根据命名空间中的访问控制策略评估提供的用户权限，API服务器会响应是否允许或拒绝请求的操作。
- en: '`SelfSubjectAccessReviews` and the next resource, `SelfSubjectRulesReviews`,
    may look very similar, but they serve different functions. The main point to keep
    in mind for `SelfSubjectAccessReviews` is that they assess individual access permissions
    for specific actions on resources.'
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
  zh: '`SelfSubjectAccessReviews`和下一个资源`SelfSubjectRulesReviews`看起来非常相似，但它们的功能不同。记住`SelfSubjectAccessReviews`的关键点是，它评估针对特定操作和资源的单独访问权限。'
- en: SelfSubjectRulesReviews
  id: totrans-396
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SelfSubjectRulesReviews
- en: '`SelfSubjectRulesReviews` objects are used to determine the set of rules that
    a user or entity has permissions for within a namespace, providing the ability
    to investigate the access control rules for their own actions and resources.'
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
  zh: '`SelfSubjectRulesReviews`对象用于确定用户或实体在命名空间内具有权限的规则集，提供了调查自己操作和资源的访问控制规则的能力。'
- en: To use a `SelfSubjectRulesReview`, you provide your identity, and the API server
    assesses the permissions associated with the identity in a namespace.
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用`SelfSubjectRulesReview`，你需要提供你的身份，API服务器将评估在命名空间中与该身份关联的权限。
- en: '`SelfSubjectRulesReviews` offer a more comprehensive view over `SelfSubjectAccessReviews`,
    providing a deeper understanding of the entire set of rules that govern a user’s
    permissions within a namespace.'
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
  zh: '`SelfSubjectRulesReviews`提供比`SelfSubjectAccessReviews`更全面的视图，深入理解用户在命名空间内的权限规则集。'
- en: Service accounts
  id: totrans-400
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务账户
- en: Kubernetes uses `ServiceAccounts` to enable access controls for workloads. When
    you create a `Deployment`, you may need to access other services or Kubernetes
    resources.
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes使用`ServiceAccounts`来启用工作负载的访问控制。当你创建`Deployment`时，可能需要访问其他服务或Kubernetes资源。
- en: Since Kubernetes is a secure system, each resource or service your application
    tries to access will evaluate **role-based access control** (**RBAC**) rules to
    accept or deny the request.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
  zh: 由于Kubernetes是一个安全的系统，你的应用程序尝试访问的每个资源或服务将评估**基于角色的访问控制**（**RBAC**）规则，以接受或拒绝请求。
- en: 'Creating a service account using a manifest is a straightforward process, requiring
    only a few lines in the manifest. The following code snippet shows a service account
    manifest to create a service account for a Grafana Deployment:'
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 使用清单创建服务账户是一个简单的过程，只需要在清单中添加几行代码。以下代码片段展示了一个服务账户清单，用于为Grafana部署创建一个服务账户：
- en: '[PRE29]'
  id: totrans-404
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: You combine the service account with role bindings and `Roles` to allow access
    to the required services or objects.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
  zh: 你将服务账户与角色绑定和`Roles`结合，允许访问所需的服务或对象。
- en: We’ll cover how to use `ServiceAccounts` in depth in *Chapter 6*, *Integrating
    Enterprise Authentication into Your Cluster*.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在*第6章*《将企业身份验证集成到你的集群》中深入讲解如何使用`ServiceAccounts`。
- en: Services
  id: totrans-407
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 服务
- en: When you create a pod, it will receive an IP address from the CIDR range that
    was assigned when the cluster was created. In most clusters, the assigned IPs
    are only addressable within the cluster itself, referred to as “**island mode**.”
    Since pods are ephemeral, the assigned IP address will likely change during an
    application’s life cycle, which becomes problematic when any service or application
    needs to connect to the pod. To address this, we can create a Kubernetes service,
    which will also receive an IP address, but since services aren’t deleted during
    an application’s life cycle, the address will remain the same.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 当你创建一个Pod时，它将从集群创建时分配的CIDR范围中获得一个IP地址。在大多数集群中，分配的IP仅在集群内部可访问，这种模式称为“**岛屿模式**”。由于Pod是临时性的，分配的IP地址可能会在应用生命周期中发生变化，这在任何服务或应用需要连接到Pod时会造成问题。为了解决这个问题，我们可以创建一个Kubernetes服务，它也会获得一个IP地址，但由于服务在应用生命周期中不会被删除，因此地址将保持不变。
- en: A service will dynamically maintain a list of pods to target based on labels
    that match the service selector, creating a list of endpoints for the service.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 服务将动态维护一个Pod列表，以根据与服务选择器匹配的标签来确定目标Pod，创建服务的端点列表。
- en: A service stores information about how to expose the application, including
    which pods are running the application and the network ports to reach them.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 服务存储有关如何暴露应用程序的信息，包括运行应用程序的Pod以及访问这些Pod的网络端口。
- en: 'Each service has a network type that is assigned when they are created, and
    they include the following:'
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
  zh: 每个服务都有一个在创建时分配的网络类型，包括以下几种：
- en: '`ClusterIP`: A network type that is only accessible inside the cluster itself.
    This type can still be used for external requests using an Ingress controller,
    which will be discussed in a later chapter. The ClusterIP type is the default
    type that will be used if no type is specified when you create a service.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ClusterIP`：一种仅能在集群内部访问的网络类型。通过使用Ingress控制器，仍然可以用于外部请求，这将在后续章节中讨论。`ClusterIP`类型是默认类型，当创建服务时，如果未指定类型，则会使用此类型。'
- en: '`NodePort`: A network type that exposes the service to a random port between
    ports `30000` and `32767`. This port becomes accessible by targeting any worker
    node in a cluster on the assigned `NodePort`. Once created, each node in the cluster
    will receive the port information, and incoming requests will be routed via `kube-proxy`.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NodePort`：一种将服务暴露到`30000`至`32767`之间随机端口的网络类型。此端口可以通过目标集群中任何工作节点的分配`NodePort`来访问。创建后，集群中的每个节点将收到端口信息，传入请求将通过`kube-proxy`进行路由。'
- en: '`LoadBalancer`: This type requires an add-on to use inside a cluster. If you
    are running Kubernetes on a public cloud provider, this type will create an external
    load balancer that will assign an IP address to your service. Most on-premises
    Kubernetes installations do not include support for the `LoadBalancer` type, but
    some offerings such as Google’s Anthos do offer support for it. In a later chapter,
    we will explain how to add an open-source project called `MetalLB` to a Kubernetes
    cluster to provide support for the `LoadBalancer` type.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LoadBalancer`：此类型需要集群内的附加组件。如果你在公共云提供商上运行Kubernetes，此类型将创建一个外部负载均衡器，并为你的服务分配一个IP地址。大多数本地Kubernetes安装不支持`LoadBalancer`类型，但像谷歌的Anthos等一些产品支持此类型。在后续章节中，我们将解释如何将一个开源项目`MetalLB`添加到Kubernetes集群中，以支持`LoadBalancer`类型。'
- en: '`ExternalName`: This type is different from the other three. Unlike the other
    three options, this type will not assign an IP address to the service. Instead,
    this is used to map the internal Kubernetes **Domain Name System** (**DNS**) name
    to an external service.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ExternalName`：这种类型与其他三种类型不同。与其他三种选项不同，这种类型不会为服务分配IP地址。相反，它用于将内部Kubernetes
    **域名系统**（**DNS**）名称映射到外部服务。'
- en: 'As an example, we have deployed a pod running Nginx on port `80`. We want to
    create a service that will allow this pod to receive incoming requests on port
    `80` from within the cluster. The code for this can be seen in the following snippet:'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: 作为示例，我们已经部署了一个运行Nginx的Pod，监听端口`80`。我们希望创建一个服务，使得这个Pod能够在集群内部接收端口`80`的传入请求。相关代码如下所示：
- en: '[PRE30]'
  id: totrans-417
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In our manifest, we create a label with a value of `app` and assign a value
    of `nginx-web-frontend`. We have called the service itself `nginx-web` and we
    exposed the service on port `80`, targeting the pod port of `80`. The last two
    lines of the manifest are used to assign the pods that the service will forward
    to, also known as Endpoints. In this manifest, any pod that has the label of `app`
    with a value of `nginx-web` in the namespace will be added as an endpoint to the
    service. Finally, you may have noticed that we didn’t specify a service type in
    our manifest. Since we didn’t specify the type, it will be created as the default
    service type of `ClusterIP`.
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的清单中，我们创建了一个名为`app`的标签，并将其值设置为`nginx-web-frontend`。我们将服务本身命名为`nginx-web`，并将服务暴露在端口`80`上，目标Pod端口为`80`。清单的最后两行用于指定服务将转发到的Pod，也称为端点（Endpoints）。在这个清单中，任何具有`app`标签并且值为`nginx-web`的Pod都会被添加为服务的端点。最后，你可能已经注意到，我们没有在清单中指定服务类型。由于没有指定类型，它将创建为默认的`ClusterIP`服务类型。
- en: StatefulSets
  id: totrans-419
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: StatefulSets
- en: '`StatefulSets` offer some unique features when creating pods. They provide
    features that none of the other pod creation methods offer, including the following:'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '`StatefulSets`在创建Pod时提供了一些独特的功能。它们提供了其他Pod创建方法没有的功能，包括以下内容：'
- en: Known pod names
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已知的Pod名称
- en: Ordered Deployment and scaling
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有序部署和扩展
- en: Ordered updates
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有序更新
- en: Persistent storage creation
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 持久化存储创建
- en: 'The best way to understand the advantages of a `StatefulSet` is to review an
    example manifest from the Kubernetes site, shown in the following screenshot:'
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
  zh: 理解`StatefulSet`的优势最好的方法是查看Kubernetes网站上的示例清单，如下截图所示：
- en: '![Figure 5.9 – StatefulSet manifest example ](img/B21165_03_04.png)'
  id: totrans-426
  prefs: []
  type: TYPE_IMG
  zh: '![图5.9 – StatefulSet清单示例](img/B21165_03_04.png)'
- en: 'Figure 3.4: StatefulSet manifest example'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
  zh: 图3.4：StatefulSet清单示例
- en: Now, we can look at the resources that the `StatefulSet` created.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们可以查看`StatefulSet`创建的资源。
- en: 'The manifest specifies that there should be three replicas of a pod named `nginx`.
    When we get a list of pods, you will see that three pods were created using the
    `nginx` name, with an additional dash and an incrementing number. This is what
    we meant in the overview when we mentioned that Pods will be created with known
    names, as illustrated in the following code snippet:'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: 该清单指定应该有三个名为`nginx`的Pod副本。当我们获取Pod列表时，你会看到三个Pod是以`nginx`为名称创建的，并附加了一个短横线和递增的数字。这就是我们在概述中提到的Pod将以已知名称创建的意思，如下代码片段所示：
- en: '[PRE31]'
  id: totrans-430
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: The pods are also created in order—`web-0` must be fully deployed before `web-1`
    is created, and then, finally, `web-2`.
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: Pod也是按顺序创建的——`web-0`必须完全部署后，`web-1`才能创建，最后是`web-2`。
- en: 'Finally, for this example, we also added a PVC to each pod using the `VolumeClaimTemplate`
    in the manifest. If you look at the output of the `kubectl get pvc` command, you
    will see that three PVCs were created with the names we expected (note that we
    removed the `VOLUME` column due to space), as illustrated in the following code
    snippet:'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，对于这个示例，我们还在清单中使用`VolumeClaimTemplate`为每个Pod添加了一个PVC。如果你查看`kubectl get pvc`命令的输出，你会看到三个PVC已经被创建，并且命名符合我们的预期（注意，由于空间限制，我们删除了`VOLUME`列），如下代码片段所示：
- en: '[PRE32]'
  id: totrans-433
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: In the `VolumeClaimTemplate` section of the manifest, you will see that we assigned
    the name `www` to the PVC claim. When you assign a volume in a `StatefulSet`,
    the PVC name will combine the name used in the claim template, combined with the
    name of the pod. Using this naming, you can see why Kubernetes assigned the PVC
    names `www-web-0`, `www-web-1`, and `www-web-2`.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
  zh: 在清单的`VolumeClaimTemplate`部分，你会看到我们将PVC声明命名为`www`。当你在`StatefulSet`中分配一个卷时，PVC名称将结合声明模板中使用的名称和Pod的名称。通过这种命名方式，你可以理解为什么Kubernetes将PVC命名为`www-web-0`、`www-web-1`和`www-web-2`。
- en: Storage classes
  id: totrans-435
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 存储类
- en: Storage classes are used to define a storage endpoint. Each storage class can
    be assigned labels and policies, allowing a developer to select the best storage
    location for their persistent data. You may create a storage class for a backend
    system that has all **Non-Volatile Memory Express** (**NVMe**) drives, assigning
    it the name `fast`, while assigning a different class to a NetApp **Network File
    System** (**NFS**) volume running standard drives, using the name `standard`.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 存储类用于定义存储端点。每个存储类可以分配标签和策略，使开发人员能够选择最佳的存储位置来存储其持久化数据。您可以为一个后端系统创建一个存储类，该系统拥有所有**非易失性内存快闪存储器**（**NVMe**）硬盘，并将其命名为
    `fast`，同时为运行标准硬盘的 NetApp **网络文件系统**（**NFS**）卷分配一个不同的存储类，命名为 `standard`。
- en: When a PVC is requested, the user can assign a `StorageClass` that they wish
    to use. When the API server receives the request, it finds the matching name and
    uses the `StorageClass` configuration to create the volume on the storage system
    using a provisioner.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 当请求 PVC 时，用户可以分配他们希望使用的 `StorageClass`。当 API 服务器收到请求时，它会找到匹配的名称，并使用 `StorageClass`
    配置通过供给器在存储系统中创建卷。
- en: 'At a very high level, a `StorageClass` manifest does not require a lot of information.
    Here is an example of a storage class using a provisioner from the Kubernetes
    incubator project to provide NFS auto-provisioned volumes, named `nfs`:'
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，`StorageClass` 清单不需要太多信息。以下是一个使用 Kubernetes 孵化项目中的供给器来提供 NFS 自动供给卷的存储类示例，名为
    `nfs`：
- en: '[PRE33]'
  id: totrans-439
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: Storage classes allow you to offer multiple storage solutions to your users.
    You may create a class for cheaper, slower storage while offering a second class
    that supports high throughput for high data requirements. By providing a different
    class to each offering, you allow developers to select the best choice for their
    application.
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 存储类允许您为用户提供多种存储解决方案。您可以创建一个便宜、较慢的存储类，同时提供另一个支持高吞吐量以满足高数据需求的存储类。通过为每个提供的存储解决方案提供不同的存储类，您允许开发者选择最适合其应用的选项。
- en: SubjectAccessReviews
  id: totrans-441
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: SubjectAccessReviews
- en: '`SubjectAccessReviews` are used to check if an entity has permission to perform
    a specific action on a resource. They allow users to request access reviews and
    get information about their privileges. By providing an identity, desired action,
    and resource, the API server determines if the action is allowed or denied. This
    helps users verify their permissions to a resource, which can help to identify
    access issues to a Kubernetes resource.'
  id: totrans-442
  prefs: []
  type: TYPE_NORMAL
  zh: '`SubjectAccessReviews` 用于检查实体是否有权限在资源上执行特定操作。它们允许用户请求访问审查并获取有关其权限的信息。通过提供身份、所需操作和资源，API
    服务器确定该操作是否被允许或拒绝。这有助于用户验证他们对资源的权限，进而帮助识别 Kubernetes 资源的访问问题。'
- en: For example, Scott wants to verify his ability to create pods in a namespace
    called `sales`. To do this, Scott creates a `SubjectAccessReview` in the `sales`
    namespace, including his username, the create action, and the target resource,
    pods.
  id: totrans-443
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Scott 想要验证自己是否有权限在名为 `sales` 的命名空间中创建 pod。为此，Scott 在 `sales` 命名空间中创建了一个 `SubjectAccessReview`，其中包含他的用户名、创建操作和目标资源（pods）。
- en: The API server verifies whether he has permission to create pods in the `sales`
    namespace and sends a response back. The response from the API server includes
    whether the requested action is permitted or denied.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: API 服务器验证用户是否有权限在 `sales` 命名空间中创建 pod，并返回响应。API 服务器的响应包括请求的操作是否被允许或拒绝。
- en: Knowing if an entity has permission to execute an action on a resource helps
    to minimize frustrations when a deployment fails due to permissions.
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 知道一个实体是否有权限在资源上执行操作，有助于减少由于权限问题导致部署失败时的挫败感。
- en: TokenReviews
  id: totrans-446
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: TokenReviews
- en: '`TokenReviews` are API objects used to authenticate and verify the legitimacy
    of an authentication token linked to a user or entity in the cluster. If the token
    is valid, the API server retrieves the details about the associated user or entity.'
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: '`TokenReviews` 是用于验证和验证与集群中的用户或实体相关联的身份验证令牌的 API 对象。如果令牌有效，API 服务器将检索与该令牌关联的用户或实体的详细信息。'
- en: When users submit an authentication token to the Kubernetes API server, it validates
    the token against the internal authentication system. It verifies that the token
    is legitimate and determines the user or entity associated with it.
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 当用户向 Kubernetes API 服务器提交身份验证令牌时，服务器会将令牌与内部身份验证系统进行验证。它会验证令牌是否合法，并确定与其相关联的用户或实体。
- en: The API server provides information about the token’s validity and the user
    or entity, including the username, **user identifier** (**UID**), and group membership.
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: API 服务器提供有关令牌有效性以及用户或实体的信息，包括用户名、**用户标识符**（**UID**）和组成员信息。
- en: ValidatingWebhookConfigurations
  id: totrans-450
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: ValidatingWebhookConfigurations
- en: '`ValidatingWebhookConfiguration` is a collection of rules that determine what
    admission requests are intercepted and handled by a webhook. Each rule contains
    the specific resources and operations that the webhook should handle.'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: '`ValidatingWebhookConfiguration` 是一组规则，决定哪些准入请求会被 Webhook 拦截和处理。每条规则都包含 Webhook
    应处理的特定资源和操作。'
- en: It provides a way to enforce specific policies or rules by applying validation
    logic to admission requests. Many add-ons to Kubernetes provide a `ValidatingWebhookConfiguration`
    – one of the most common is the NGINX ingress controller.
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 它提供了一种通过对准入请求应用验证逻辑来强制执行特定策略或规则的方法。许多 Kubernetes 的附加组件提供 `ValidatingWebhookConfiguration`，其中最常见的之一是
    NGINX ingress 控制器。
- en: 'You can view all of the `ValidatingWebhookConfigurations` in your cluster by
    executing `kubectl get validatingwebhookconfigurations`. For the KinD clusters
    we have deployed, you will have a single entry for NGINX ingress admissions:'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以通过执行 `kubectl get validatingwebhookconfigurations` 查看集群中所有的 `ValidatingWebhookConfigurations`。对于我们部署的
    KinD 集群，您将看到一个针对 NGINX Ingress 准入的条目：
- en: '[PRE34]'
  id: totrans-454
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: VolumeAttachments
  id: totrans-455
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VolumeAttachments
- en: '`VolumeAttachments` create connections between external storage volumes and
    nodes in a cluster. They control the association of persistent volumes with specific
    nodes, enabling the nodes to access and utilize the storage resources.'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: '`VolumeAttachments` 在集群中的外部存储卷和节点之间创建连接。它们控制持久化卷与特定节点的关联，使得节点能够访问和利用存储资源。'
- en: Summary
  id: totrans-457
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, you were provided with a fast-paced Kubernetes bootcamp, where
    you were exposed to a wealth of technical information. Remember that as you get
    deeper into the world of Kubernetes, everything will become more manageable and
    easier to grasp. It’s important to note that many of the resources discussed in
    this chapter will be further explored and explained in subsequent chapters, providing
    you with a deeper understanding.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，您接受了一个快速节奏的 Kubernetes 启动训练营，您接触到了大量的技术信息。请记住，随着您深入 Kubernetes 的世界，一切将变得更加可管理，且更容易掌握。需要注意的是，本章中讨论的许多资源将在后续章节中进一步探讨和解释，帮助您更深入地理解。
- en: You gained insights into each Kubernetes component and their interdependencies,
    which form the cluster. Armed with this knowledge, you now possess the necessary
    skills to investigate and identify the root causes of errors or issues within
    a cluster. We explored the control plane, which encompasses `api-server`, `kube-scheduler`,
    `etcd`, and controller managers. Additionally, you familiarized yourself with
    Kubernetes nodes that run the `kubelet` and `kube-proxy` components, along with
    a container runtime.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
  zh: 您深入了解了每个 Kubernetes 组件及其相互依赖关系，这些组件共同构成了集群。凭借这些知识，您现在具备了调查和识别集群内错误或问题根源的必要技能。我们探讨了控制平面，其中包括
    `api-server`、`kube-scheduler`、`etcd` 和控制器管理器。此外，您还熟悉了运行 `kubelet` 和 `kube-proxy`
    组件的 Kubernetes 节点，以及容器运行时。
- en: We also delved into the practical use of the `kubectl` utility, which will be
    your primary tool for interacting with a cluster. You learned about several essential
    commands, such as commands for accessing logs and providing descriptive information,
    which you will utilize on a daily basis.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还深入探讨了 `kubectl` 工具的实际应用，它将是您与集群互动的主要工具。您了解了几个基本命令，如访问日志和提供描述性信息的命令，这些命令将是您日常使用的工具。
- en: In the next chapter, we will create a development Kubernetes cluster that we
    will use as the base cluster for the remaining chapters. Throughout the remainder
    of the book, we will reference many of the resources that were presented in this
    chapter, helping to explain them by using them in real-world examples.
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将创建一个开发用的 Kubernetes 集群，它将作为剩余章节的基础集群。在本书的剩余部分，我们将引用本章中呈现的许多资源，并通过实际案例来帮助解释这些资源。
- en: Questions
  id: totrans-462
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: A Kubernetes control plane does not include which of the following components?
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个组件不包含在 Kubernetes 控制平面中？
- en: api-server
  id: totrans-464
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: api-server
- en: kube-scheduler
  id: totrans-465
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: kube-scheduler
- en: etcd
  id: totrans-466
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: etcd
- en: Ingress controller
  id: totrans-467
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ingress 控制器
- en: 'Answer: d'
  id: totrans-468
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：d
- en: What is the name of the component that keeps all of the cluster information?
  id: totrans-469
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 保持所有集群信息的组件是什么名称？
- en: api-server
  id: totrans-470
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: api-server
- en: Master controller
  id: totrans-471
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 主控制器
- en: kubelet
  id: totrans-472
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: kubelet
- en: etcd
  id: totrans-473
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: etcd
- en: 'Answer: d'
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：d
- en: Which component is responsible for selecting the node that will run a workload?
  id: totrans-475
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个组件负责选择将运行工作负载的节点？
- en: kubelet
  id: totrans-476
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: kubelet
- en: api-server
  id: totrans-477
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: api-server
- en: kube-scheduler
  id: totrans-478
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: kube-scheduler
- en: Pod-scheduler
  id: totrans-479
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pod调度器
- en: 'Answer: c'
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：c
- en: Which option would you add to a `kubectl` command to see additional output from
    a command?
  id: totrans-481
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你会在 `kubectl` 命令中添加哪个选项，以查看命令的附加输出？
- en: Verbose
  id: totrans-482
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 详细模式
- en: -v
  id: totrans-483
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: -v
- en: –verbose
  id: totrans-484
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: –verbose
- en: -log
  id: totrans-485
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: -log
- en: 'Answer: b'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：b
- en: Which service type creates a randomly generated port, allowing incoming traffic
    to any worker node on the assigned port to access the service?
  id: totrans-487
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种服务类型会创建一个随机生成的端口，使得所有进入分配端口的工作节点流量都可以访问该服务？
- en: LoadBalancer
  id: totrans-488
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 负载均衡器
- en: ClusterIP
  id: totrans-489
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: ClusterIP
- en: None—it’s the default for all services
  id: totrans-490
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无—这是所有服务的默认设置
- en: NodePort
  id: totrans-491
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: NodePort
- en: 'Answer: d'
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：d
- en: If you need to deploy an application on a Kubernetes cluster that requires known
    pod names and a controlled startup of each pod, which object would you create?
  id: totrans-493
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你需要在 Kubernetes 集群上部署一个需要已知 Pod 名称和控制每个 Pod 启动顺序的应用程序，你会创建哪个对象？
- en: StatefulSet
  id: totrans-494
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: StatefulSet
- en: Deployment
  id: totrans-495
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Deployment
- en: ReplicaSet
  id: totrans-496
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: ReplicaSet
- en: ReplicationController
  id: totrans-497
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: ReplicationController
- en: 'Answer: a'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: 答案：a
- en: Join our book’s Discord space
  id: totrans-499
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们书籍的 Discord 空间
- en: 'Join the book’s Discord workspace for a monthly *Ask Me Anything* session with
    the authors:'
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: 加入本书的 Discord 工作区，参加每月与作者的 *问我任何问题*（Ask Me Anything）环节：
- en: '[https://packt.link/K8EntGuide](https://packt.link/K8EntGuide)'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/K8EntGuide](https://packt.link/K8EntGuide)'
- en: '![](img/QR_Code965214276169525265.png)'
  id: totrans-502
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code965214276169525265.png)'
