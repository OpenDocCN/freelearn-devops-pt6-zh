<html><head></head><body><div id="sbo-rt-content"><div id="_idContainer026">
			<h1 id="_idParaDest-74"><em class="italic"><a id="_idTextAnchor100"/>Chapter 4</em>: Managing Cluster Configuration with Ansible</h1>
			<p>In <a href="B16192_03_Final_PG_ePub.xhtml#_idTextAnchor073"><em class="italic">Chapter 3</em></a>, <em class="italic">Provisioning Kubernetes Clusters Using AWS and Terraform</em>, you learned how to create a Kubernetes infrastructure with Terraform and AWS, and you also learned how to develop infrastructure as code and provisioned your first production-like cluster.</p>
			<p>This was just the first step towards building operational and production-ready Kubernetes clusters. By now, you should have an up-and-running cluster with Terraform infrastructure modules to provision other similar clusters.</p>
			<p>These clusters are still plain; they're not configured or optimized to run production workloads. To make these clusters fully operational, we simply need to deploy and configure the required Kubernetes services for them.</p>
			<p>In this chapter, you will design and develop a configuration management solution that you can use to manage the configuration of Kubernetes clusters and their supporting services. This solution is automated and scalable, and it requires a minimum effort to maintain and operate.</p>
			<p>In this chapter, we will cover the following topics:</p>
			<ul>
				<li>Understanding Kubernetes configuration management challenges</li>
				<li>Designing a configuration management solution for Kubernetes</li>
				<li>Developing a configuration management solution with Ansible</li>
				<li>Applying the solution to configure Kubernetes clusters</li>
			</ul>
			<h1 id="_idParaDest-75"><a id="_idTextAnchor101"/>Technical requirements</h1>
			<p>In addition to the tools that you installed in <a href="B16192_03_Final_PG_ePub.xhtml#_idTextAnchor073"><em class="italic">Chapter 3</em></a>, <em class="italic">Provisioning Kubernetes Clusters Using AWS and Terraform</em>, you will need to install the following tools:</p>
			<ul>
				<li><strong class="source-inline">python3</strong></li>
				<li><strong class="source-inline">pip3</strong></li>
				<li><strong class="source-inline">virtualenv</strong></li>
			</ul>
			<p>I will go into the specifics of these tools' installation and configuration in the next section. If you already know how to do this, you can go ahead and set them up now.</p>
			<p>You need to have an up-and-running Kubernetes cluster as per the instructions in <a href="B16192_03_Final_PG_ePub.xhtml#_idTextAnchor073"><em class="italic">Chapter 3</em></a>, <em class="italic">Provisioning Kubernetes Clusters Using AWS and Terraform</em>.</p>
			<p>The code for this chapter is located at <a href="https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter04">https://github.com/PacktPublishing/Kubernetes-in-Production-Best-Practices/tree/master/Chapter04</a>.</p>
			<p>Check out the following link to see the Code in Action video:</p>
			<p><a href="https://bit.ly/3cGtqjx">https://bit.ly/3cGtqjx</a></p>
			<h1 id="_idParaDest-76"><a id="_idTextAnchor102"/>Installing the required tools</h1>
			<p><strong class="source-inline">python3</strong>, <strong class="source-inline">pip3</strong>, and <strong class="source-inline">virtualenv</strong> are the prerequisites<a id="_idIndexMarker249"/> to execute the Ansible configuration <a id="_idIndexMarker250"/>playbooks that we will develop in this chapter. If you do not have these tools <a id="_idIndexMarker251"/>installed on your system, you can follow these <a id="_idIndexMarker252"/>instructions:</p>
			<ul>
				<li>Execute the following commands to install <strong class="source-inline">python3</strong>, <strong class="source-inline">pip3</strong>, and <strong class="source-inline">virtualenv</strong> on Ubuntu Linux:<p class="source-code"><strong class="bold">$ sudo apt-get update</strong></p><p class="source-code"><strong class="bold">$ sudo apt-get install python3</strong></p><p class="source-code"><strong class="bold">$ sudo apt-get install python3-pip</strong></p><p class="source-code"><strong class="bold">$ sudo pip3 install virtualenv</strong></p></li>
				<li>Execute the following commands to install <strong class="source-inline">python3</strong>, <strong class="source-inline">pip3</strong>, and <strong class="source-inline">virtualenv</strong> on Amazon Linux 2:<p class="source-code"><strong class="bold">$ sudo yum update</strong></p><p class="source-code"><strong class="bold">$ sudo yum install python3</strong></p><p class="source-code"><strong class="bold">$ sudo python3 -m pip install --upgrade pip</strong></p><p class="source-code"><strong class="bold">$ sudo python3 -m pip install virtualenv</strong></p></li>
				<li>Execute the following commands to install <strong class="source-inline">python3</strong>, <strong class="source-inline">pip3</strong>, and <strong class="source-inline">virtualenv</strong> on macOS:<p class="source-code"><strong class="bold">$ brew install python3</strong></p><p class="source-code"><strong class="bold">$ curl -O https://bootstrap.pypa.io/get-pip.py</strong></p><p class="source-code"><strong class="bold">$ sudo python3 get-pip.py</strong></p><p class="source-code"><strong class="bold">$ sudo -H pip3 install virtualenv</strong></p></li>
				<li>Execute the following commands to install <strong class="source-inline">python3</strong>, <strong class="source-inline">pip3</strong>, and <strong class="source-inline">virtualenv</strong> on Windows:<p class="source-code"><strong class="bold">C:\&gt; choco install python3</strong></p><p class="source-code"><strong class="bold">C:\&gt; pip install virtualenv </strong></p></li>
			</ul>
			<p>By installing <strong class="source-inline">python3</strong>, <strong class="source-inline">pip3</strong>, and <strong class="source-inline">virtualenv</strong>, you will be able to execute Ansible playbooks against your Kubernetes clusters. You will learn how to do that later in this chapter, but first, we<a id="_idIndexMarker253"/> need to go through the design details of our Kubernetes configuration management solution.</p>
			<h1 id="_idParaDest-77"><a id="_idTextAnchor103"/>Implementation principles</h1>
			<p>In <a href="B16192_01_Final_PG_ePub.xhtml#_idTextAnchor014"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Kubernetes Infrastructure and Production-Readiness</em>, you learned about the infrastructure design principles that we will follow in this book. I would like to start this chapter by highlighting the notable principles that influenced the configuration management solution and the technical decisions in this chapter:</p>
			<ul>
				<li><strong class="bold">Everything as code</strong>: In this chapter, we will keep our commitment to having everything in the infrastructure as code – cluster configuration is not an exception. You will use Ansible to achieve this goal by creating a configuration management solution for your Kubernetes cluster.</li>
				<li><strong class="bold">Automation</strong>: In the previous chapter, we used Terraform tool to automate infrastructure provisioning. We designed a solution around Terraform that can scale to serve a growing number of clusters without the need to scale up your infrastructure teams. Here, you will create a similar solution to manage the Kubernetes configuration while keeping it automated, scalable, and easy to operate and maintain.</li>
				<li><strong class="bold">Simplicity</strong>: Ansible fulfills this principle in many aspects as it is easy to learn and to use. It has a simple syntax compared to other configuration management tools. It uses YAML, which you do not need to learn a programming language to write. Moreover, it is agentless, which means you do not need a server to run it, as you can run Ansible from your computer. Also, it is modular, which enables separation of concerns and code reusability, which is similar to Terraform. So, they can easily live together and simplify the automation of the infrastructure. </li>
			</ul>
			<h1 id="_idParaDest-78"><a id="_idTextAnchor104"/>Kubernetes configuration management</h1>
			<p>The beauty of Kubernetes<a id="_idIndexMarker254"/> is that every part of it is abstracted as an object that can be managed and configured declaratively with YAML or JSON through its API server. This makes Kubernetes configuration easier to manage as code. However, it is still challenging to manage this configuration when you have groups of clusters that run hundreds of add-ons and services.</p>
			<p>Imagine a scenario where you manage a company's infrastructure with Kubernetes, and you have multiple clusters for development, testing, and production. Add to them the cluster add-ons that run on the Kubernetes services layer as per the following diagram:</p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="Images/B16192_04_001.jpg" alt="Figure 4.1 – Kubernetes infrastructure layers&#13;&#10;" width="1100" height="1013"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.1 – Kubernetes infrastructure layers</p>
			<p>This means that you <a id="_idIndexMarker255"/>can have <em class="italic">N</em> clusters with a growing number of add-ons and different environment types, such as development, QA, and production. If we put these together, we end up with a complex and redundant configuration to manage.</p>
			<p>The recommended <a id="_idIndexMarker256"/>way to manage clusters' configuration is through <strong class="bold">Configuration as Code</strong> (<strong class="bold">CaC</strong>). We will deploy these services and add-ons to the cluster and add their configuration manifests to the source code control. By adopting this pattern, you will be able to redeploy the same configuration in a seamless and automated fashion to your clusters. This solution appears to be easy when you start with a single cluster, but it will be difficult to maintain and scale when provisioning multiple clusters with different configuration values.</p>
			<p>This leads us to an enhanced solution, which is configuration templating. Let's assume you have a group of clusters that serve product X, and these clusters have different configurations, such as different users' authentication and authorization, namespaces, resource quotas, and so on.</p>
			<p>This solution uses Ansible templating and Jinja2. You write the templates for the Kubernetes manifests<a id="_idIndexMarker257"/> once, and then Ansible substitutes the variables in these templates and generates the appropriate manifests for each target cluster. This solution is scalable and easy to maintain, and it fulfills the infrastructure design principles that we introduced in <a href="B16192_01_Final_PG_ePub.xhtml#_idTextAnchor014"><em class="italic">Chapter 1</em></a>, <em class="italic">Introduction to Kubernetes Infrastructure and Production-Readiness</em>.</p>
			<h2 id="_idParaDest-79"><a id="_idTextAnchor105"/>Kubernetes configuration management workflow</h2>
			<p>After considering<a id="_idIndexMarker258"/> the preceding templating solution, our Kubernetes configuration management workflow looks like the following:</p>
			<ol>
				<li>Create Ansible Jinja2 templates for the Kubernetes cluster services that you want to configure and deploy.</li>
				<li>Define the values of the variables and categorize them based on the environments and the cluster's group.</li>
				<li>Provisioning the clusters with Terraform.</li>
				<li>Pass the Terraform outputs to Ansible.</li>
				<li>Substitute the variables in the Ansible template with the corresponding values.</li>
				<li>Use Ansible to apply the Kubernetes manifests to the target clusters.</li>
			</ol>
			<p>In the next sections, we will implement this workflow with Ansible and Jinja2 templates, then learn how to use it with a basic example.</p>
			<h2 id="_idParaDest-80"><a id="_idTextAnchor106"/>Configuration management with Ansible</h2>
			<p>In this chapter, we <a id="_idIndexMarker259"/>will use Ansible as the <a id="_idIndexMarker260"/>configuration management tool, and we will build around it our solution for Kubernetes configuration management. In this section, we are going to briefly discuss the reasoning behind this choice, and some Ansible key concepts. If you are willing to learn more about Ansible, you can use its official guide here: <a href="https://www.ansible.com/resources/get-started">https://www.ansible.com/resources/get-started</a>.</p>
			<h3>Why Ansible?</h3>
			<p>When it comes to<a id="_idIndexMarker261"/> templating Kubernetes configuration, we have battle-tested tools. Most notable among them are Ansible and Helm, and both of them have pros and cons. But I am not here to run a full comparison between them. My decision is based on having used both tools in serving production environments, and also our specific use case here. When it comes to pure configuration management and templating, Ansible remains the strongest contender. While Helm supports templating, it remains more like a Kubernetes package manager than a full configuration management tool. This is why we decided to use Ansible to develop a configuration management solution for Kubernetes infrastructure.</p>
			<h3>What is Ansible?</h3>
			<p>Ansible is an <a id="_idIndexMarker262"/>automation and <strong class="bold">configuration management</strong> (<strong class="bold">CM</strong>) tool. It can <a id="_idIndexMarker263"/>configure systems, deploy applications and containers, and provision cloud resources. It can orchestrate advanced tasks such as continuous deployments and rolling updates.</p>
			<p>In this book, we are not going to dig deep into Ansible's features and use cases. We believe that there are a lot of good books dedicated to this purpose; our main focus is on how to use Ansible to solve Kubernetes' CM problem in a simple and efficient way.</p>
			<h3>Ansible key concepts</h3>
			<p>The CM solution <a id="_idIndexMarker264"/>that we will implement and use in this book is built with key Ansible concepts. I will not dive deep into these concepts; rather, I will provide brief details about them, as well as highlight how we will utilize each one of them in our CM framework:</p>
			<ul>
				<li><strong class="bold">Inventory</strong>: This is <a id="_idIndexMarker265"/>used by Ansible to group similar hosts into groups. This is accomplished by defining the inventory files with the addresses of the hosts.</li>
				<li><strong class="bold">Modules</strong>: This is how<a id="_idIndexMarker266"/> Ansible abstracts and groups a specific task to be reused against your host's inventories; modules can even be made public and used by other Ansible users. In our solution, we will use one of the ready-made Kubernetes modules to execute configuration manifests against the clusters.</li>
				<li><strong class="bold">Tasks</strong>: This is where we<a id="_idIndexMarker267"/> instruct Ansible about the steps that it should do; it could be installing a piece of software or provisioning a whole system. In our solution, we will create a separate task to configure each Kubernetes component and add-on on its own.</li>
				<li><strong class="bold">Playbooks</strong>: These are the building blocks of Ansible. They are used to gather everything together and provide a sequence of instructions that involves other Ansible blocks, such as<a id="_idIndexMarker268"/> tasks, variables, and modules. They then instruct Ansible on how to configure the target system to reach the desired state. In our solution, we will use a playbook to hold the configuration tasks for all of the components and add-ons that are required by all clusters, and we will also have variables and selectors to enable cluster maintainers to switch specific add-ons on/off.</li>
				<li><strong class="bold">Variables</strong>: We will use variables<a id="_idIndexMarker269"/> to hold the values for the configuration that is used for each cluster add-on, and we will split these variables into groups that represent different clusters and environments.</li>
				<li><strong class="bold">Templates</strong>: Ansible uses Jinja2 templates<a id="_idIndexMarker270"/> to enable dynamic expressions using variables. This enables Ansible to generate new configuration files based on these templates during execution time. In our solution, we will define Kubernetes manifests as Ansible Jinja2 templates, and during configuration execution time, Ansible will be able to generate the correct Kubernetes manifests for each cluster based on the provided or predefined <a id="_idIndexMarker271"/>variables.</li>
			</ul>
			<p>The previous Ansible concepts are essential to understanding how Ansible works. We will utilize each of them to develop the CM solution in the next section. You will learn about each concept and how to use it as you move forward in this chapter.</p>
			<h1 id="_idParaDest-81"><a id="_idTextAnchor107"/>Configuring the clusters</h1>
			<p>Now we put the <a id="_idIndexMarker272"/>solution we designed in the previous section into action. We will start by developing the Ansible framework skeleton, which will consist of the following parts:</p>
			<ul>
				<li><strong class="source-inline">group_vars</strong>: This directory contains the manifest configuration files with variables' default unless a cluster defines its own private variables in its own inventory.</li>
				<li><strong class="source-inline">inventories</strong>: This directory contains the configuration files with variables' values, which are specific to each cluster or cluster group, meaning that variables defined here override default variables defined under the <strong class="source-inline">groups_vars</strong> directory.</li>
				<li><strong class="source-inline">tasks</strong>: In this directory, we define a separate task for each cluster service and add-on that we need to deploy and configure; the task definition file is standard across tasks, as we will use Ansible's k8s module and pass to it the YAML templates to deploy against the target cluster.</li>
				<li><strong class="source-inline">templates</strong>: This directory contains the Kubernetes manifest YAMLs and configuration files for each Kubernetes object we need to manage, and these template files will have the required variables written in Jinja2 expressions format.</li>
				<li><strong class="source-inline">cluster.yaml</strong>: This is the main playbook that will be passed to Ansible to execute against the target cluster. It contains all the tasks that we need to invoke to configure the cluster objects and add-ons. The playbook also has tags for each task, and this enables the cluster maintainer to switch specific tasks on/off for each target cluster whenever needed.</li>
			</ul>
			<p>After creating the Ansible skeleton for Kubernetes cluster configuration management, we will be able to grow it to handle more cluster services and deployments. The development workflow looks as the following:</p>
			<ol>
				<li value="1">Write Kubernetes manifests in YAML format for the cluster add-ons that you want to deploy, then deploy them to a test cluster to ensure correctness.</li>
				<li>Convert the Kubernetes manifests from YAML to Jinja2 templates.</li>
				<li>Create a task file to invoke these templates and add this file under the Ansible <strong class="source-inline">tasks</strong> directory.</li>
				<li>Create the variable values:<p>- For default variable values, under the <strong class="source-inline">group_vars</strong> directory, add the values of the variables you created in the template in an appropriate YAML file.</p><p>- For cluster-specific variables, under the <strong class="source-inline">inventories</strong> directory, create a new directory with the name of the cluster or cluster group that you want to target, and then create its own <strong class="source-inline">group_vars</strong> directory, and create under that a YAML file to contain the variable values mapping.</p></li>
				<li>Update the <a id="_idIndexMarker273"/>playbook file and add a step to invoke the targeted task. Then, associate to this task the appropriate tags and properties.</li>
			</ol>
			<p>In the hands-on exercise, we will configure <strong class="source-inline">aws-auth</strong> and create a Kubernetes namespace to illustrate how this Ansible solution works. In the coming chapters, we will use this solution to deploy more services and add-ons on top of Kubernetes.</p>
			<h2 id="_idParaDest-82"><a id="_idTextAnchor108"/>The ansible directory's structure</h2>
			<p>The <strong class="source-inline">ansible</strong> directory is where all the Ansible source code resides in your <a id="_idIndexMarker274"/>infrastructure repository. As a best practice, I recommend having a dedicated infrastructure source code repository that contains all the infrastructure as code and configuration for your Kubernetes clusters and the rest of your infrastructure. The following is the proposed directory structure of the Ansible configuration that we will develop in this chapter:</p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="Images/B16192_04_002.jpg" alt="Figure 4.2 – Ansible directory structure&#13;&#10;" width="796" height="825"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.2 – Ansible directory structure</p>
			<p>You will learn in detail and with hands-on practices how to develop this solution and all of the configuration code under the <strong class="source-inline">ansible</strong> directory.</p>
			<h2 id="_idParaDest-83"><a id="_idTextAnchor109"/>Creating Ansible templates</h2>
			<p>In this section, you will <a id="_idIndexMarker275"/>create two templates to learn how you can rewrite Kubernetes manifests into Ansible Jinja2 format.</p>
			<p>The second template is for a Kubernetes namespace, which you will use to create new namespaces.</p>
			<h3>Creating the aws-auth template</h3>
			<p>The first<a id="_idIndexMarker276"/> template<a id="_idIndexMarker277"/> is for <strong class="source-inline">aws-auth</strong> ConfigMap, which you will use to define AWS IAM users and roles and then authenticate them to the cluster. You will learn in detail about <strong class="source-inline">aws-auth</strong> and how to use it for cluster access in <a href="B16192_06_Final_PG_ePub.xhtml#_idTextAnchor131"><em class="italic">Chapter 6</em></a>, <em class="italic">Securing Kubernetes Effectively</em>.</p>
			<p>You will create a Jinja2 template for the <strong class="source-inline">aws-auth</strong> ConfigMap. However, let's first have a look at the default <strong class="source-inline">aws-auth</strong> ConfigMap without templating:</p>
			<p class="source-code">apiVersion: v1</p>
			<p class="source-code">kind: ConfigMap</p>
			<p class="source-code">metadata:</p>
			<p class="source-code">  name: aws-auth</p>
			<p class="source-code">  namespace: kube-system</p>
			<p class="source-code">data:</p>
			<p class="source-code">  mapRoles: |</p>
			<p class="source-code">    - rolearn: &lt;ARN of instance role (not instance profile)&gt;</p>
			<p class="source-code">      username: system:node:{{EC2PrivateDNSName}}</p>
			<p class="source-code">      groups:</p>
			<p class="source-code">        - system:bootstrappers</p>
			<p class="source-code">        - system:nodes</p>
			<p>The previous<a id="_idIndexMarker278"/> code<a id="_idIndexMarker279"/> block creates an <strong class="source-inline">aws-auth</strong> ConfigMap with one role for the worker EC2. But what if we need to add more roles and users? What if we need to use the same ConfigMap with<a id="_idIndexMarker280"/> different clusters and with different worker <strong class="bold">Amazon Resource Names</strong> (<strong class="bold">ARNs</strong>)? We either create multiple ConfigMaps with different configurations or create a single template and let Ansible use it to generate the correct <strong class="source-inline">aws-auth</strong> ConfigMap for each cluster.</p>
			<p>The next code block for the <strong class="source-inline">aws-auth</strong> template defines a list of specific users and roles who can access the cluster. In the first part of the code, you define the Kubernetes <strong class="source-inline">apiVersion</strong>, the object type as <strong class="source-inline">ConfigMap</strong>, and the metadata:</p>
			<p class="source-code">apiVersion: v1</p>
			<p class="source-code">kind: ConfigMap</p>
			<p class="source-code">metadata:</p>
			<p class="source-code">  name: aws-auth</p>
			<p>In the second part of the code, you define the ConfigMap <strong class="source-inline">data</strong> section that includes the <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) users. First, instead of adding each user's <a id="_idIndexMarker281"/>data (name, ARN, and Kubernetes group), you define them inside a Jinja2 <strong class="source-inline">for</strong> loop with Jinja2 variables that can be substituted by Ansible during the execution time. You notice that we<a id="_idIndexMarker282"/> use a <strong class="source-inline">for</strong> loop so we can add multiple users:</p>
			<p class="source-code">data:</p>
			<p class="source-code">  mapUsers: |</p>
			<p class="source-code">{% for user in map_users.system_masters %}</p>
			<p class="source-code">    - userarn: "{{ user.arn }}"</p>
			<p class="source-code">      username: "{{ user.name }}"</p>
			<p class="source-code">      groups:</p>
			<p class="source-code">        - system:masters</p>
			<p class="source-code">{% endfor %}</p>
			<p>In the second part of the code, you define another ConfigMap <strong class="source-inline">data</strong> section that includes the IAM roles. First, instead of adding each user's data (name, ARN, and Kubernetes group), you define them inside a Jinja2 <strong class="source-inline">for</strong> loop with Jinja2 variables that can be substituted by Ansible during execution. You notice that we use a <strong class="source-inline">for</strong> loop so we can add multiple roles:</p>
			<p class="source-code">  mapRoles: |</p>
			<p class="source-code">{% for role in map_roles.workers_roles %}</p>
			<p class="source-code">    - rolearn: "{{ role }}"</p>
			<p class="source-code">      username: {% raw -%} "system:node:{{ '{{' }}EC2PrivateDNSName{{ '}}' }}" {%- endraw %}</p>
			<p class="source-code">      groups:</p>
			<p class="source-code">        - system:bootstrappers</p>
			<p class="source-code">        - system:nodes</p>
			<p class="source-code">{% endfor %}</p>
			<p class="source-code">{% for role in map_roles.system_masters %}</p>
			<p class="source-code">    - rolearn: "{{ role }}"</p>
			<p class="source-code">      username: {% raw -%} "admin:{{ '{{' }}SessionName{{ '}}' }}" {%- endraw %}</p>
			<p class="source-code">      groups:</p>
			<p class="source-code">        - system:masters</p>
			<p class="source-code">{% endfor %}</p>
			<p>The previous template authenticates IAM users and roles to any cluster, and you can even extend it more with <a id="_idIndexMarker283"/>different group types according to your needs. But the original concept remains <a id="_idIndexMarker284"/>the same, as you have a single template for the <strong class="source-inline">aws-auth</strong> ConfigMap that can work for any cluster and for any users and roles.</p>
			<h3>Creating a Kubernetes namespace template</h3>
			<p>The next code<a id="_idIndexMarker285"/> block is for a Jinja2 template that <a id="_idIndexMarker286"/>generates a YAML for a Kubernetes namespace manifest. This template defines the basic namespace configuration, such as names, labels, and annotations. </p>
			<p>This template can create multiple namespaces as it reads a list of namespaces from the target cluster's Ansible variables and generates the Kubernetes manifest YAMLs for each one of these namespaces:</p>
			<p class="source-code">{% for namespace in namespaces_list %}</p>
			<p class="source-code">---</p>
			<p class="source-code">apiVersion: v1</p>
			<p class="source-code">kind: Namespace</p>
			<p class="source-code">metadata:</p>
			<p class="source-code">  name: {{ namespace.name }}</p>
			<p class="source-code">  labels:</p>
			<p class="source-code">    name: {{ namespace.name }}</p>
			<p class="source-code">    owner: {{ namespace.owner }}    </p>
			<p class="source-code">{% endfor %}</p>
			<p>The previous template is an example of how you can create your own templates for Kubernetes objects. I recommend going to the Ansible Jinja2 official documentation when you write these templates to get more ideas about the code blocks and how to use them: <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_templating.html">https://docs.ansible.com/ansible/latest/user_guide/playbooks_templating.html</a>.</p>
			<h2 id="_idParaDest-84"><a id="_idTextAnchor110"/>Creating Ansible variables</h2>
			<p>As you learned earlier<a id="_idIndexMarker287"/> in this chapter, the Ansible <strong class="source-inline">group_vars</strong> will contain the global configuration variables that you want to apply to all clusters unless you want to specify a different value for a specific cluster. In this section, you will define default variables for the admin user in the <strong class="source-inline">aws-auth</strong> ConfigMap and define a new namespace.</p>
			<h3>Defining the aws-auth variables</h3>
			<p>The following code <a id="_idIndexMarker288"/>snippet defines the default <a id="_idIndexMarker289"/>variables for a cluster's configuration whenever the cluster does not have its own private variables. The first variable is <strong class="source-inline">worker_iam_role_arn</strong>. Ansible will get the value of <strong class="source-inline">worker_iam_role_arn</strong> from the Terraform outputs. The second variable is the clusters' admin. You also add the ARN or the IAM user that is called <strong class="source-inline">admin</strong>:</p>
			<p class="source-code">map_roles:</p>
			<p class="source-code">  workers_roles:</p>
			<p class="source-code">    - "{{ worker_iam_role_arn }}"</p>
			<p class="source-code">  system_masters: []</p>
			<p class="source-code">map_users:</p>
			<p class="source-code">  system_masters:</p>
			<p class="source-code">    - arn: "&lt;ARN of the admin user&gt;"</p>
			<p class="source-code">      name: "admin"</p>
			<p>You can extend the previous variables and add more roles and users to the cluster according to your needs. You <a id="_idIndexMarker290"/>will also learn in <a href="B16192_06_Final_PG_ePub.xhtml#_idTextAnchor131"><em class="italic">Chapter 6</em></a>, <em class="italic">Securing Kubernetes Effectively</em>, about<a id="_idIndexMarker291"/> the<a id="_idIndexMarker292"/> Kubernetes <strong class="bold">Role-Based Access Control</strong> (<strong class="bold">RBAC</strong>) and access management best practices.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">In Jinja2 templates, you define the variables between double braces, <strong class="source-inline">{{ }}</strong>. Please refer to Ansible templating documentation: <a href="https://docs.ansible.com/ansible/latest/user_guide/playbooks_templating.html">https://docs.ansible.com/ansible/latest/user_guide/playbooks_templating.html</a>.</p>
			<h3>Configuring the default namespace</h3>
			<p>You will add <a id="_idIndexMarker293"/>a single namespace<a id="_idIndexMarker294"/> to the <strong class="source-inline">namespaces_list</strong> variable. However, you can add more namespaces according to your needs. This is an illustration to show you how namespace configuration should work with Ansible:</p>
			<p class="source-code">namespaces_list:</p>
			<p class="source-code">- name: default-namespace</p>
			<p class="source-code">  owner: admin</p>
			<p>In this section, you<a id="_idIndexMarker295"/> should have learned how to create default <a id="_idIndexMarker296"/>configuration variables for your clusters. It is a simple configuration mechanism but is very powerful and efficient.</p>
			<h2 id="_idParaDest-85"><a id="_idTextAnchor111"/>Creating Ansible inventories</h2>
			<p>Not all clusters are<a id="_idIndexMarker297"/> equal. In the previous section, you learned how to set default variables for your configuration. But what if you need to have different values for one of your clusters? Ansible inventories are the answer. In this section, you will create inventories to define local cluster variables that override the default variables. </p>
			<h3>Create Ansible's inventory</h3>
			<p>The way that Ansible <a id="_idIndexMarker298"/>configures hosts (servers/VMs) is very simple. Usually, there is a host or group of hosts and you have configuration tasks that you want to apply against these hosts. But our solution is a different use case, as we will use the same concept but not against any remote hosts. This is because, in reality, we do not configure hosts – instead, we configure Kubernetes clusters. Ansible just needs to communicate with the Kubernetes API server.</p>
			<p>All you need is to set the Ansible <strong class="source-inline">hosts</strong> to target the <strong class="source-inline">localhost</strong>. Then in turn, <strong class="source-inline">localhost</strong> will use the <strong class="source-inline">kube-server</strong> API endpoint defined in <strong class="source-inline">kubeconfig</strong> to apply the intended configurations:</p>
			<p class="source-code">[all]</p>
			<p class="source-code">localhost</p>
			<p class="source-code">[override]</p>
			<p class="source-code">localhost</p>
			<p>As you will notice in this previous code block, there is only the <strong class="source-inline">localhost</strong> value defined as the target <a id="_idIndexMarker299"/>host for Ansible. This <strong class="source-inline">hosts</strong> file should exist for each inventory that Ansible manages.</p>
			<h3>Overriding the aws-auth variables</h3>
			<p>To override the <strong class="source-inline">aws-auth</strong> default variables <a id="_idIndexMarker300"/>defined in <strong class="source-inline">group_vars</strong>, you need to recreate the <strong class="source-inline">aws-auth</strong> template file under the <strong class="source-inline">packtclusters</strong> inventory with the new variables' values. The next code block shows you how to override <strong class="source-inline">aws-auth</strong>. There are two IAM roles defined: the first role for workers and the second for the cluster administrator role. The second part of the code defines a different user other than the default one:</p>
			<p class="source-code">map_roles:</p>
			<p class="source-code">  workers_roles: </p>
			<p class="source-code">    - "{{ worker_iam_role_arn }}"</p>
			<p class="source-code">  system_masters:</p>
			<p class="source-code">    - "&lt;ARN of the admin-role user&gt;"</p>
			<p class="source-code">map_users:</p>
			<p class="source-code">  system_masters:</p>
			<p class="source-code">    - arn: "arn:aws:iam::AWS_ACCOUNT_NO:user/packtclusters-admin"</p>
			<p class="source-code">      name: "packtclusters-admin"</p>
			<p>The previous configuration template will <a id="_idIndexMarker301"/>replace the default one for <strong class="source-inline">packtclusters</strong>. You can do the same for any other template.</p>
			<h3>Overriding the namespaces variables</h3>
			<p>To override the <strong class="source-inline">namespaces</strong> default<a id="_idIndexMarker302"/> variables defined in <strong class="source-inline">group_vars</strong>, you need to recreate the <strong class="source-inline">namespaces</strong> template file under the <strong class="source-inline">packtclusters</strong> inventory with the new variables' values. In the next code block, there is a new variable that will override <strong class="source-inline">default-namespace</strong> with a new one called <strong class="source-inline">packtclusters-namespace</strong>. So, when you apply this configuration, <strong class="source-inline">packtclusters</strong> will have the new <a id="_idIndexMarker303"/>namespace instead of the default one:</p>
			<p class="source-code">namespaces_list:</p>
			<p class="source-code">- name: packtsclusters-namespace</p>
			<p class="source-code">  owner: packtclusters-admin</p>
			<p>In this section, you have learned how to override Ansible's default variables to use different configuration values based on the cluster.</p>
			<h2 id="_idParaDest-86"><a id="_idTextAnchor112"/>Creating Ansible tasks</h2>
			<p>The second step <a id="_idIndexMarker304"/>after creating the Ansible templates is creating Ansible tasks. In this section, you will learn how to create Ansible tasks to deploy your configuration templates.</p>
			<p>The tasks will use the Ansible k8s module. This module accepts the templated Kubernetes YAMLs and then instructs Ansible to apply these tasks against the target cluster. Ansible can identify the target cluster from the current context in the <strong class="source-inline">kubeconfig</strong> file.</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">You can learn more about Ansible's k8s module<a id="_idIndexMarker305"/> from the official documentation: <a href="https://docs.ansible.com/ansible/latest/user_guide/modules_intro.html">https://docs.ansible.com/ansible/latest/user_guide/modules_intro.html</a>.</p>
			<h3>Creating the aws-auth task</h3>
			<p>The following task <a id="_idIndexMarker306"/>instructs Ansible on how to generate and<a id="_idIndexMarker307"/> apply the <strong class="source-inline">aws-auth</strong> ConfigMap to the cluster. It takes the path to the template file as an input and applies it to the target cluster. </p>
			<p>In the next code block, you define the task specs, with properties such as <strong class="source-inline">name</strong>, the <strong class="source-inline">kubeconfig</strong> path, <strong class="source-inline">state</strong>, and whether to force applying the configuration to the cluster or not. Then, the task defines which Jinja2 template to load and substitutes its variables with the values from the <strong class="source-inline">group_vars</strong> or <strong class="source-inline">inventory</strong> directories. </p>
			<p>You will notice that there is a <strong class="source-inline">loop</strong> directive if there are multiple Jinja2 templates to be applied by the <strong class="source-inline">k8s</strong> module. The other important parameters are <strong class="source-inline">retries</strong>, which tells Ansible the number of retries until the task succeeds, and <strong class="source-inline">delay</strong>, which tells Ansible the time in seconds between each of these retries:</p>
			<p class="source-code"># ansible/tasks/auth/aws-auth.yaml</p>
			<p class="source-code">- name: deploy aws auth ConfigMap</p>
			<p class="source-code">  k8s:</p>
			<p class="source-code">    definition: "{{ item }}"</p>
			<p class="source-code">    kubeconfig: "{{ k8s_kubeconfig }}"</p>
			<p class="source-code">    state: "{{ k8s_manifests_state }}"</p>
			<p class="source-code">    force: "{{ k8s_force }}"</p>
			<p class="source-code">  loop: </p>
			<p class="source-code">    - "{{ lookup('template', k8s_manifests_base_dir + 'auth/aws-auth.yaml') | from_yaml_all | list }}"</p>
			<p class="source-code">  register: k8s_result</p>
			<p class="source-code">  until: k8s_result is success</p>
			<p class="source-code">  retries: 3</p>
			<p class="source-code">  delay: 2</p>
			<p class="source-code">  no_log: "{{ k8s_no_log }}"  </p>
			<p>The previous code<a id="_idIndexMarker308"/> for the <strong class="source-inline">aws-auth</strong> task will be invoked by <a id="_idIndexMarker309"/>an Ansible playbook that you will learn about later in this chapter.</p>
			<h3>Creating the namespaces task</h3>
			<p>The following Ansible<a id="_idIndexMarker310"/> task file is for creating the cluster <a id="_idIndexMarker311"/>namespaces. It takes the path to the namespaces object template file and applies it to the target cluster.</p>
			<p>The code structure for the <strong class="source-inline">namespaces</strong> task is very similar to the previous <strong class="source-inline">aws-auth</strong> task, except it has a different name, and it reads a different Jinja2 template file for <strong class="source-inline">namespaces.yaml</strong>:</p>
			<p class="source-code"># ansible/tasks/namespaces.yaml</p>
			<p class="source-code">- name: create cluster namespaces</p>
			<p class="source-code">  k8s:</p>
			<p class="source-code">    definition: "{{ item }}"</p>
			<p class="source-code">    kubeconfig: "{{ k8s_kubeconfig }}"</p>
			<p class="source-code">    state: "{{ k8s_manifests_state }}"</p>
			<p class="source-code">    force: "{{ k8s_force }}"</p>
			<p class="source-code">  loop: "{{ lookup('template', k8s_manifests_base_dir + 'namespaces/namespaces.yaml') | from_yaml_all | list }}"</p>
			<p class="source-code">  register: k8s_result</p>
			<p class="source-code">  until: k8s_result is success</p>
			<p class="source-code">  retries: 3</p>
			<p class="source-code">  delay: 2</p>
			<p class="source-code">  no_log: "{{ k8s_no_log }}"</p>
			<p>The previous code for the <strong class="source-inline">namespaces</strong> task will be invoked by an Ansible playbook that you will <a id="_idIndexMarker312"/>learn <a id="_idIndexMarker313"/>about later in this chapter.</p>
			<h2 id="_idParaDest-87"><a id="_idTextAnchor113"/>Creating the cluster's playbook</h2>
			<p>An Ansible playbook<a id="_idIndexMarker314"/> is an Ansible file where you put all tasks in the order that you want Ansible to execute them in. The following cluster playbook is a simple and standard Ansible playbook, and it has three sections: the first section is to define the target hosts, the second section is to define any variables that you want the tasks to use the values of during execution, and the third section is the list of tasks that Ansible will execute.</p>
			<p>The following code block defines the hosts and the connection type. In our solution, we will use <strong class="source-inline">localhost</strong> as the target host, as explained before:</p>
			<p class="source-code"># ansible/cluster.yaml</p>
			<p class="source-code">---</p>
			<p class="source-code">- name: deploy k8s add-ons</p>
			<p class="source-code">  hosts: localhost</p>
			<p class="source-code">  connection: local</p>
			<p class="source-code">  gather_facts: no</p>
			<p>The following code block defines the variables that are required during the execution of the tasks. The most notable ones are the physical path to the <strong class="source-inline">kubeconfig</strong> file and the base directory where the Kubernetes templates reside. These variables override any variables with similar <a id="_idIndexMarker315"/>names in the <strong class="source-inline">group_vars</strong> and <strong class="source-inline">inventory</strong> directories:</p>
			<p class="source-code">  vars:</p>
			<p class="source-code">    Ansible_python_interpreter: "{{ Ansible_playbook_python }}"</p>
			<p class="source-code">    k8s_kubeconfig: ~/.kube/config</p>
			<p class="source-code">    k8s_manifests_base_dir: templates/</p>
			<p class="source-code">    k8s_manifests_state: present</p>
			<p class="source-code">    k8s_force: false</p>
			<p class="source-code">    k8s_no_log: false</p>
			<p>The following code block defines the list of tasks that Ansible executes against the target cluster. You add new tasks to this list and assign meaningful tags to them:</p>
			<p class="source-code">  tasks:</p>
			<p class="source-code">  - import_tasks: tasks/aws-auth.yaml</p>
			<p class="source-code">    tags: aws-auth</p>
			<p class="source-code">  - import_tasks: tasks/namespaces.yaml</p>
			<p class="source-code">    tags: namespaces</p>
			<p>By completing the <a id="_idIndexMarker316"/>development of the playbook, tasks, and all the configurations, you are ready to put all the Ansible pieces together apply the playbook and have Ansible configure your cluster. In the next section, you will use the <strong class="source-inline">packtclusters-prod1</strong> cluster, which you created in the previous chapter, to apply the Ansible playbook.</p>
			<h2 id="_idParaDest-88"><a id="_idTextAnchor114"/>Applying the cluster's Ansible playbook</h2>
			<p>The next instructions <a id="_idIndexMarker317"/>will deploy the Ansible playbook, which will configure your cluster with the intended configuration:</p>
			<ol>
				<li value="1">Initialize the Terraform state and select the workspace by running the following commands:<p class="source-code"><strong class="bold">$ cd terraform/packtclusters</strong></p><p class="source-code"><strong class="bold">$ terraform init</strong></p><p class="source-code"><strong class="bold">$ terraform workspace select prod1</strong></p></li>
				<li>Retrieve and configure the localhost <strong class="source-inline">kubeconfig</strong> with the target cluster:<p class="source-code"><strong class="bold">$ aws eks --region $(terraform output aws_region) update-kubeconfig --name $(terraform output cluster_full_name)</strong></p></li>
				<li>Use Python <strong class="source-inline">virtualenv</strong> to install and execute Ansible:<p class="source-code"><strong class="bold">$ virtualenv $HOME/ansible-k8s-workspace</strong></p><p class="source-code"><strong class="bold">$ source $HOME/ansible-k8s-workspace/bin/activate</strong></p></li>
				<li>Install Ansible and the prerequisite modules, <strong class="source-inline">openshift</strong>, <strong class="source-inline">pyyaml</strong>, and <strong class="source-inline">requests</strong>:<p class="source-code"><strong class="bold">$ pip install ansible==2.9 openshift pyyaml requests</strong></p></li>
				<li>Execute the Ansible playbook:<p class="source-code"><strong class="bold">$ ansible-playbook -i \</strong></p><p class="source-code"><strong class="bold">../../ansible/inventories/packtclusters/ \</strong></p><p class="source-code"><strong class="bold">-e "worker_iam_role_arn=$(terraform output worker_iam_role_arn)" \</strong></p><p class="source-code"><strong class="bold">../../ansible/cluster.yaml</strong></p><p>You will get the <a id="_idIndexMarker318"/>following output after successful execution:</p><div id="_idContainer024" class="IMG---Figure"><img src="Images/B16192_04_003.jpg" alt="Figure 4.3 – Ansible execution output&#13;&#10;" width="1290" height="482"/></div><p class="figure-caption">Figure 4.3 – Ansible execution output</p></li>
				<li>Execute the following <strong class="source-inline">kubectl</strong> command to ensure that the cluster configuration is applied successfully:<p class="source-code"><strong class="bold">$ kubectl get namespaces</strong></p><p>You should see an output similar to the following. There is a new namespace called <strong class="source-inline">packtclusters-namespace</strong>:</p></li>
			</ol>
			<div>
				<div id="_idContainer025" class="IMG---Figure">
					<img src="Images/B16192_04_004.jpg" alt="Figure 4.4 – List of cluster namespaces&#13;&#10;" width="1027" height="198"/>
				</div>
			</div>
			<p class="figure-caption">Figure 4.4 – List of cluster namespaces</p>
			<p>You applied the <a id="_idIndexMarker319"/>cluster playbook and tasks as per the previous instructions. In the following chapters, you will learn how to use the same configuration management solution to create other tasks to deploy and configure services on top of your clusters.</p>
			<h1 id="_idParaDest-89"><a id="_idTextAnchor115"/>Destroying the cluster's resources</h1>
			<p>You can follow the<a id="_idIndexMarker320"/> instructions in the <em class="italic">Destroying the network and cluster infrastructure</em> section of <a href="B16192_03_Final_PG_ePub.xhtml#_idTextAnchor073"><em class="italic">Chapter 3</em></a>, <em class="italic">Provisioning Kubernetes Clusters Using AWS and Terraform</em>, to destroy the Kubernetes cluster and its related AWS resources. Please be sure to destroy the resources in the following order:</p>
			<ol>
				<li value="1">Cluster <strong class="source-inline">packtclusters</strong> resources</li>
				<li>Cluster VPC resources</li>
				<li>Terraform shared state resources</li>
			</ol>
			<p>After executing the previous steps, all of the cluster AWS resources should be destroyed successfully. You can still log in to the AWS web console and double-check the destruction of the resources to avoid any unwanted AWS charges.</p>
			<h1 id="_idParaDest-90"><a id="_idTextAnchor116"/>Summary</h1>
			<p>In this chapter, you learned about Kubernetes configuration management challenges and how to scale your configuration management solution to manage multiple clusters and environments. We designed and developed a solution that is based on Ansible, and we went through practical hands-on examples to deploy this code. </p>
			<p>We started by creating Ansible templates for Kubernetes objects and add-ons. Then, we developed the tasks and the playbook to execute the Ansible configuration in sequence against the targeted clusters.</p>
			<p>This chapter introduced you to Ansible basic concepts. It showed you how to use the best practices of infrastructure and configuration as code, automation, and Ansible development.</p>
			<p>This sets up the base for the coming chapters, where you will use this configuration management solution to configure and deploy clusters' add-ons and services where these add-ons are essential to reach production-readiness.</p>
			<p>In the next chapter, you will learn about Kubernetes networking and connectivity. The best practices of deploying and configuring Kubernetes network plugins, cluster DNS, ingresses, network policies, and service mesh will be covered.</p>
			<h1 id="_idParaDest-91"><a id="_idTextAnchor117"/>Further reading</h1>
			<p>You can refer to the following links for more information on the topics covered in this chapter:</p>
			<ul>
				<li><em class="italic">Ansible 2 for Configuration Management [Video]</em>: <a href="https://www.packtpub.com/product/ansible-2-for-configuration-management-video/9781838826475">https://www.packtpub.com/product/ansible-2-for-configuration-management-video/9781838826475</a></li>
				<li><em class="italic">Practical Ansible 2</em>: <a href="https://www.packtpub.com/product/practical-ansible-2/9781789807462">https://www.packtpub.com/product/practical-ansible-2/9781789807462</a></li>
				<li><em class="italic">Automation with Ansible Playbooks [Video]</em>:<em class="italic"> </em><a href="https://www.packtpub.com/product/automation-with-ansible-playbooks-video/9781800206496">https://www.packtpub.com/product/automation-with-ansible-playbooks-video/9781800206496</a></li>
			</ul>
		</div>
	</div></body></html>