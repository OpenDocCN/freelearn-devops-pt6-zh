- en: '4'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Exploring Container Runtimes, Interfaces, and Service Meshes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ll go further into exploring container runtimes, networking,
    interfaces, and learning about service meshes. We will see which runtime implementations
    exist and the difference between them, learn how containers can communicate with
    each other over the network, which container interfaces exist in Kubernetes, and
    get to know what a service mesh is and its applications. We will also do a few
    more exercises using the Docker tooling we have previously installed to support
    our journey.
  prefs: []
  type: TYPE_NORMAL
- en: The contents of this chapter will cover topics from the *Container Orchestration*
    domain of the KCNA certification, which is the second biggest part of the exam,
    so make sure to answer all questions at the end of the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the topics we’re going to cover:'
  prefs: []
  type: TYPE_NORMAL
- en: Container runtimes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container networking
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container storage
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Container security
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing service meshes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s get started!
  prefs: []
  type: TYPE_NORMAL
- en: Container runtimes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As you know from the previous chapters, containers can run on virtual machines,
    in the cloud, on-premise, on bare-metal servers, or simply on your laptop. The
    software responsible for basic operations such as downloading images from the
    registry and creating, starting, stopping, or deleting containers is called the
    **container runtime**. We’ve already learned about Docker tooling and runtime,
    but there are more runtimes that exist, including the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Containerd**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**CRI-O**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**kata**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**gVisor**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before going into runtime specifics, we need to understand what a **Container
    Runtime Interface** (**CRI**) is.
  prefs: []
  type: TYPE_NORMAL
- en: CRI
  prefs: []
  type: TYPE_NORMAL
- en: The CRI is a plugin interface that allows Kubernetes to use different container
    runtimes. In the first releases of Kubernetes before the CRI was introduced, it
    was only possible to use Docker as a runtime.
  prefs: []
  type: TYPE_NORMAL
- en: 'As you might remember, Kubernetes does not have its own runtime to do basic
    container operations, so it needs a runtime to manage containers and this runtime
    has to be CRI compatible. For example, Docker Engine does not support the CRI,
    but most of the other runtimes, including *containerd* or *CRI-O*, do. Essentially,
    the CRI defines the protocol for communication between Kubernetes and the runtime
    of choice using **gRPC** (the high-performance **Remote Procedure Call** framework),
    as shown in *Figure 4**.1*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.1 – Container runtime integration with CRI](img/B18970_04_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.1 – Container runtime integration with CRI
  prefs: []
  type: TYPE_NORMAL
- en: Initially, there was no CRI implementation in Kubernetes, but as new container
    runtimes were developed, it became increasingly hard to incorporate all of them
    into Kubernetes, so the solution was to define a standard interface that would
    allow compatibility with any runtime. The introduction of the CRI in Kubernetes
    version 1.5 allowed the use of multiple container runtimes within a single K8s
    cluster and also made it easier to develop compatible runtimes. Today, *containerd*
    is the most used runtime with newer versions of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: 'But why would you need to run a mix of different runtimes in the same cluster?
    This is a rather advanced scenario and the main reason behind it is that some
    runtimes can provide better security for more sensitive container workloads. Therefore,
    when we talk about containers and their runtimes, we need to distinguish three
    main types:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Namespaced** – The fastest and most used type that is based on Linux kernel
    *cgroups* and *namespaces* functionality we covered in the previous chapter. This
    type shares the same kernel to run multiple containers and thus is considered
    the least secure out of all container types. Examples include *Docker*, *containerd*,
    and *CRI-O*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Virtualized** – The slowest type of container, which in fact requires a hypervisor
    as virtual machines do. Each container is started inside its own lightweight VM
    with its own dedicated kernel. This type is considered the most secure as it provides
    maximum isolation for container workloads. Virtualized containers are still faster
    to start than VMs and their advantage over traditional VMs is their easy integration
    with container orchestration systems such as Kubernetes. The *Kata* project is
    an example of virtualized containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Sandboxed** – This is a container type in-between the other two, providing
    better security than namespaced containers and being faster than virtualized containers.
    Better security is achieved with another layer of isolation that intercepts the
    system calls coming from the container workload. *gVisor* is an open source project
    from Google that allows the creation of sandboxed containers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While this might sound very complicated, for the scope of the KCNA exam, you
    don’t really need to know all the details about container runtimes. This knowledge
    will be needed if you ever go for a CKS exam or have a special use case for using
    *sandboxed* or *virtualized* containers. For now, make sure to remember which
    container runtimes exist and the fact that in most scenarios, *namespaced* containers
    are used. Also, don’t confuse *CRI* with *OCI*, which we covered in [*Chapter
    2*](B18970_02.xhtml#_idTextAnchor026), *Overview of CNCF and* *Kubernetes Certifications*.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: The **Open Container Initiative** (**OCI**) provides the industry specifications
    for containers (image, runtime, and distribution specs) while CRI is a part of
    Kubernetes that makes it possible to use different runtimes with K8s in a pluggable
    way.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, you do not interact with container runtimes directly but instead
    use orchestration systems such as Kubernetes or Docker Swarm. We can also use
    a CLI to talk to container runtimes as we did with the Docker CLI or as you can
    with the `ctr` or `nerdctl` CLI when using the *containerd* runtime.
  prefs: []
  type: TYPE_NORMAL
- en: Moving on, in the following section, we are going to learn more about container
    networking.
  prefs: []
  type: TYPE_NORMAL
- en: Container networking
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We have only tried creating individual containers so far, however, in the real
    world, we would need to deal with tens and often hundreds of containers. As the
    microservice architectures gained wider adoption, the applications were split
    into multiple smaller parts that communicate with each other over the network.
    One application could be represented by the frontend part, several backend services,
    and the database layer, where end-user requests hitting the frontend will trigger
    communication with the backend, and the backend will talk with the database. When
    each component is running in its own container across multiple servers, it is
    important to understand how they can all talk with each other. Networking is a
    large part of containers and Kubernetes, and it can be really challenging to understand
    how things work. For the moment, we are only going to touch the surface of container-to-container
    communication and continue with more details such as exposing containers and K8s
    specifics in the later chapters.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get back to the Docker tooling we installed in the previous chapter and
    try starting another Ubuntu container.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Make sure that Docker Desktop is running before attempting to spawn containers.
    If you have not enabled auto-start previously, you might need to start it manually.
    On Linux with Docker Engine, you might need to execute `$ sudo systemctl` `start
    docker`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Open the terminal and run the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Because the image is stripped down to the minimum to save space, there are
    no preinstalled basic packages such as `net-tools`. Let’s install those inside
    our container by calling `apt update` and `apt install`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Now that we have `net-tools` installed, we can use the `ifconfig` tool inside
    the container. The output you’ll see should be similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'We can also see the container’s routing table by calling the `route` tool inside
    the container. The output will be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: As we can see, our container has an `eth0` interface with the `172.17.0.2` IP
    address. In your case, the address might be different, but the important part
    is that our containers, by default, will have their own isolated networking stack
    with their own (virtual) interfaces, routing table, default gateway, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'If we now open another terminal window and execute `docker network ls`, we
    will see which network types are supported using which drivers. The output will
    be similar to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'There are three basic network types:'
  prefs: []
  type: TYPE_NORMAL
- en: '`bridge` – This is the default type and driver for Docker containers we create.
    It allows containers connected to the same bridge network on the host to communicate
    with each other and provides isolation from other containers (that can also be
    attached to their own bridge network). Communication with the *outside world*
    is possible with the help of **Network Address Translation** (**NAT**) done via
    the **IPtables** of the host.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`host` – This is a type that is used when we want to create containers without
    network isolation. A container spawned with a host network won’t be isolated from
    the network of the host system where it was created. For example, you can start
    a container with the Apache web server listening on port `80` and it will be reachable
    from any other hosts on the same network right away unless protected by a firewall.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`none` – This is a rarely used option that means all networking will be disabled
    for the container.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pay attention that those types in the output of `docker network ls` have the
    `local` scope, meaning that they can be used on individual hosts where we spawn
    containers with Docker. But they won’t allow containers created on one server
    to communicate with containers created on another server directly (unless host
    networking is used, which is similar to running applications directly on the host
    when no containers are involved).
  prefs: []
  type: TYPE_NORMAL
- en: In order to establish networking between multiple hosts where we spawn containers
    communicating with each other, we need a so-called *overlay* network. Overlay
    networks connect multiple servers together, allowing communication between containers
    located on different hosts.
  prefs: []
  type: TYPE_NORMAL
- en: Overlay network
  prefs: []
  type: TYPE_NORMAL
- en: An overlay network is a virtual network running on top of another network, typically
    using packet encapsulation – an overlay network packet resides inside another
    packet that is forwarded to a particular host.
  prefs: []
  type: TYPE_NORMAL
- en: Whether you are running Kubernetes, Docker Swarm, or another solution to orchestrate
    containers, in the real world, you’ll always run multiple hosts for your workloads,
    and containers running on those hosts need to talk with each other using overlay
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to Kubernetes, similar to the CRI, it implements a **Container
    Network Interface** (**CNI**) that allows the usage of different overlay networks
    in a pluggable manner.
  prefs: []
  type: TYPE_NORMAL
- en: CNI
  prefs: []
  type: TYPE_NORMAL
- en: A CNI is an interface that allows Kubernetes to use different overlay networking
    plugins for containers.
  prefs: []
  type: TYPE_NORMAL
- en: The introduction of the CNI has allowed third parties to develop their own solutions
    that are compatible with Kubernetes and offer their own unique features, such
    as traffic encryption or network policies (firewall rules) in container networks.
  prefs: []
  type: TYPE_NORMAL
- en: Some of the CNI network plugins used with Kubernetes today are **flannel**,
    **Cilium**, **Calico**, and **Weave**, just to name a few. Kubernetes also makes
    it possible to use multiple plugins at the same time with **Multus** (a Multi-Network
    Plugin); however, this is an advanced topic that is out of scope for the KCNA
    exam. In *Part 3*, *Learn Kubernetes Fundamentals*, of the book, we will have
    another closer look at networking in Kubernetes, but now it is time to look further
    into container storage.
  prefs: []
  type: TYPE_NORMAL
- en: Container storage
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Containers are lightweight by design and, as we saw earlier, often even the
    basic tools such as `ifconfig` and `ping` might not be included in container images.
    That is because containers represent a minimal version of the OS environment where
    we only install an application we are going to containerize with its dependencies.
    You don’t usually need many packages or tools pre-installed inside container images
    except for those required for your application to run.
  prefs: []
  type: TYPE_NORMAL
- en: Containers also don’t keep the state by default, meaning that if you’ve placed
    some files inside the container filesystem while it was running and deleted the
    container after, all those files will be completely gone. Therefore, it is common
    to call containers **stateless** and the on-disk files in containers **ephemeral**.
  prefs: []
  type: TYPE_NORMAL
- en: That does not mean we cannot use containers for important data that we need
    to persist in case a container fails or an application exits.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: In case the application running inside the container fails, crashes, or simply
    terminates, the container also stops by default.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to keep the important data from the container by using *external*
    storage systems.
  prefs: []
  type: TYPE_NORMAL
- en: External storage can be a block volume attached to the container with a protocol
    such as **iSCSI** or it could be a **Network File System** (**NFS**) mount, for
    example. Or, external could also simply be a *local* directory on your container
    host. There are many options out there, but we commonly refer to external container
    storage as *volumes*.
  prefs: []
  type: TYPE_NORMAL
- en: One container can have multiple volumes attached and those volumes can be backed
    by different technologies, protocols, and hardware. Volumes can also be shared
    between containers or detached from one container and attached to another container.
    Volume content exists outside of the container life cycle, allowing us to decouple
    container and application data. Volumes allow us to run **stateful** applications
    in containers that need to write to disk, whether it is a database, application,
    or any other files.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s get back to our computer with Docker tooling and try to run the following
    in the terminal:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'As we run it and attach *tty* to a container, we should be able to see our
    new `myvolume` mounted inside container at `/app`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: What happened is that Docker automatically created and attached a `local` volume
    for our container at the start. Local means the volume is backed by a directory
    on the host where the container was started.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: Local storage can be used for testing or some development, but by no means is
    it suitable for production workloads and business-critical data!
  prefs: []
  type: TYPE_NORMAL
- en: 'If we now write any files to `/app`, they will persist:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Even if we remove the container by calling `docker rm`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'By calling `docker volume ls`, we are able to see which volumes currently exist
    on our host:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'To find more details about the volume, we can use the `docker volume` `inspect`
    command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Feel free to experiment more with volumes yourself at this point. For example,
    you could create a new container and attach the existing volume to make sure the
    data is still there:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Now, when it comes to Kubernetes, you’ve probably already guessed it – similar
    to the CRI and the CNI, K8s implements the **Container Storage** **Interface**
    (**CSI**).
  prefs: []
  type: TYPE_NORMAL
- en: CSI
  prefs: []
  type: TYPE_NORMAL
- en: The CSI allows using pluggable storage layers. External storage systems can
    be integrated for use in Kubernetes in a standardized way with the CSI.
  prefs: []
  type: TYPE_NORMAL
- en: The CSI allows vendors and cloud providers to implement support for their storage
    services or hardware appliances. For example, there is an **Amazon Elastic Block
    Store** (**EBS**) CSI driver that allows you to fully manage the life cycle of
    EBS volumes in the AWS cloud via Kubernetes. There is a **NetApp Trident** CSI
    project, which supports a variety of NetApp storage filers that can be used by
    containers in Kubernetes. And plenty of other CSI-compatible storage solutions
    available today.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes is very powerful when it comes to managing storage; it can automatically
    provision, attach, and re-attach volumes between hosts and containers in the cluster.
    We will learn in more detail about Kubernetes features for stateful applications
    in *Chapter 6*, *Deploying and Scaling Applications with Kubernetes*, and now
    let’s move on to learn about container security.
  prefs: []
  type: TYPE_NORMAL
- en: Container security
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Container security is an advanced and complex topic and yet even for an entry-level
    KCNA certification, you are expected to know a few basics. As we’ve learned, *Namespaced*
    containers are the most commonly used containers and they share the kernel of
    an underlying OS. That means a process running in a container cannot see other
    processes running in other containers or processes running on the host. However,
    all processes running on one host still use the same kernel. If one of the containers
    gets compromised, there is a chance of the host and all other containers being
    compromised as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s get back to our Docker setup for a quick demonstration. Start an Ubuntu
    container as we did before and run the `uname -r` command to see which kernel
    version is used:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The output you’ll see depends on your host OS and kernel version. Don’t get
    surprised if you see another version. For example, you might see this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Now exit the container and start another one with an older version of `Ubuntu:16.04`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: See? We took an `Ubuntu:16.04` image that is more than 5 years old by now, but
    the kernel version used is exactly the same as in the first container. Even if
    you take a different flavor of Linux, the kernel version of your host OS will
    be used.
  prefs: []
  type: TYPE_NORMAL
- en: So, how can we protect the kernel of our host where we run *Namespaced* containers?
    Perhaps the two most well-known technologies are **AppArmor** for Ubuntu and **Security-Enchanced
    Linux** (**SELinux**) for Red Hat and the CentOS Linux family. Essentially, those
    projects allow you to enforce access control policies for all user applications
    and system services. Access to specific files or network resources can also be
    restricted. There is also a special tool for SELinux that helps to generate security
    profiles specifically for applications running in containers ([https://github.com/containers/udica](https://github.com/containers/udica)).
    Kubernetes has integration with both AppArmor and SELinux that allows you to apply
    profiles and policies to containers managed with K8s.
  prefs: []
  type: TYPE_NORMAL
- en: 'Moving on, it is considered a bad practice and a security risk to run containers
    as a `root` user. In Linux, a `root` user is a user with an ID of `0` and a group
    ID of `0` (UID=0, GID=0). In all our hands-on exercises, we’ve used a `root` user
    inside containers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: In a real production environment, you should consider running applications as
    a non-root user because `root` is essentially a super-admin that can do anything
    in the system. Now comes the interesting part – a `root` user inside a container
    can also be a `root` user on the host where the container is running *(very bad
    practice!)*. Or, thanks to the Namespace functionality of the Linux kernel, the
    `root` user inside the container can be mapped to a different user ID on the host
    OS (such as `UID=1001`, for example). This is still not perfect, but in case a
    container is compromised, `root` inside the container won’t automatically gain
    `root` privileges on the host OS.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: 'It is possible to specify which user and group to use for the application packaged
    in the container during the image build process. You can simply add the `USER
    mynewuser` instruction to a `Dockerfile` to define which user to use. You might
    need to first create this user by adding one more instruction above it. For example:
    `RUN useradd -r -u` `1001 mynewuser`'
  prefs: []
  type: TYPE_NORMAL
- en: Last but not least, keep in mind which container images you are using in your
    environments. If you go to Docker Hub ([https://hub.docker.com/](https://hub.docker.com/))
    or any other online container registry, you’ll find lots and lots of third-party
    images that anybody can download and run. You might encounter an image that does
    exactly what you need. For example, an image might package a tool or an application
    you wanted to try (e.g., to monitor the database you are running). But it may
    well package malicious code inside. Therefore, make sure to run trusted code in
    your containers.
  prefs: []
  type: TYPE_NORMAL
- en: It is also better to build the image yourself and store it in your own repository
    because third-party public image repositories are completely out of your control.
    Their owner might simply delete or replace the image at any given point in time
    or make the repository private. You won’t notice that immediately and this might
    cause an incident when the image isn’t available for download. Finally, there
    are a number of tools available today that perform container image scanning for
    security vulnerabilities (**Clair**, **Dagda**, and **Anchore**, to name a few).
    Those tools can be integrated into the image build process to reduce the risks
    of using outdated packages or installing software with known security exposures.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we know more about container security and networking, we will look
    into *service meshes* – a rather new technology for managing traffic and securing
    cloud-native applications.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing service meshes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Before jumping into the definition of the service mesh, let’s reiterate quickly
    what we’ve learned previously about the architecture of cloud-native applications.
  prefs: []
  type: TYPE_NORMAL
- en: Modern cloud-native applications rely on microservices that work together as
    a part of bigger applications and communicate with each other over a network.
    Those microservices are packaged as container images and run with the help of
    an orchestration system such as Kubernetes. The nature of cloud-native applications
    is highly dynamic, and the number of running containers varies a lot depending
    on the current load and infrastructure events or outages.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a situation where you are responsible for running an application your
    company has developed that consists of 20 different microservices. You have implemented
    autoscaling for all services and in the peak load times, the number of running
    containers goes well over a hundred (e.g., several container replicas for each
    service spread across multiple cloud instances). Even if using Kubernetes to effectively
    orchestrate that fleet, you still want to make sure your application runs reliably,
    infrastructure is secure, and if any problem occurs, you’re able to detect it
    and act fast. This is where a service mesh comes into play.
  prefs: []
  type: TYPE_NORMAL
- en: Service mesh
  prefs: []
  type: TYPE_NORMAL
- en: A service mesh is a dedicated infrastructure layer for making communication
    between services safe, observable, and reliable.
  prefs: []
  type: TYPE_NORMAL
- en: 'A service mesh is a special layer for handling service-to-service communication.
    The service here is typically a microservice running in a container orchestrated
    by Kubernetes. Technically, a service mesh can be used without Kubernetes and
    even containers, but in practice, most of the time, a service mesh is used together
    with containers orchestrated by Kubernetes. Examples of service meshes include
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Linkerd**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Istio**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Open Service** **Mesh** (**OSM**)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consul Connect** **Service Mesh**'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The first three in the list are in fact open source CNCF projects, although
    of different maturity levels.
  prefs: []
  type: TYPE_NORMAL
- en: Now, what does *safe communication* mean in the context of a service mesh?
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding part, we covered the basics of container security, but we have
    not looked further into securing network communication *between* containers. Securing
    network communication is often a part of the so-called **Zero Trust** security
    approach.
  prefs: []
  type: TYPE_NORMAL
- en: Zero Trust
  prefs: []
  type: TYPE_NORMAL
- en: Zero Trust is an approach where no one is trusted by default from within the
    network or outside of the network. Verification is required to gain access to
    services connected to the network.
  prefs: []
  type: TYPE_NORMAL
- en: The traditional network security approach is based on securing the perimeter
    of the infrastructure, that is, it is hard to obtain access to the network from
    the *outside*, but *inside* the network everyone is trusted by default. Obviously,
    if an attacker can breach perimeter security and access internal networks, they
    are very likely to gain access everywhere else, including confidential data. This
    is the reason why more and more enterprises are implementing the Zero Trust approach,
    and this is where a service mesh is very helpful.
  prefs: []
  type: TYPE_NORMAL
- en: One of the major advantages of a service mesh is that you do not need any changes
    in the application code to use a service mesh and its features. A service mesh
    is implemented *on the platform layer*, meaning that, once installed on the platform,
    all the applications (e.g., microservices in containers) can benefit from its
    features. With a service mesh, all traffic between containers can be automatically
    encrypted and decrypted and the applications running inside *won’t require a single
    line of* *code change*.
  prefs: []
  type: TYPE_NORMAL
- en: The traditional approach to accomplishing this without a service mesh would
    require managing SSL certificates, requesting and renewing them on expiration,
    and potentially making further changes to the application or the infrastructure
    levels.
  prefs: []
  type: TYPE_NORMAL
- en: In fact, all service meshes from the aforementioned list offer **mutually-authenticated
    Transport Layer Security** (**mTLS**) for all TCP traffic between containers connected
    to the mesh. It is similar to regular *TLS* when the server identity is presented
    with a certificate, with the difference that in the case of *mTLS*, both sides
    have to identify themselves to start communicating. That means the client also
    needs to present a certificate that the server will verify. In our example, the
    client and server are two services in containers connected to the service mesh.
    And again, mTLS can be enabled completely automatically with no extra work required
    on the application part.
  prefs: []
  type: TYPE_NORMAL
- en: Before exploring other features, let’s first understand better how a service
    mesh works. The service mesh layer is interfaced with microservices through an
    array of lightweight network proxies and all traffic between microservices is
    routed via those proxies in their own infrastructure layer. Typically, proxies
    run alongside each service in so-called *sidecar* containers, and altogether,
    those sidecar proxies form a service mesh network, as depicted in *Figure 4**.2*.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 4.2 – Service mesh overview](img/B18970_04_02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4.2 – Service mesh overview
  prefs: []
  type: TYPE_NORMAL
- en: 'The service mesh is usually made up of two parts:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data plane** – This consists of network proxies that run next to containers
    with microservices. For example, in the case of the *Linkerd* service mesh, a
    *linkerd-proxy* is used, and in the case of *Istio*, an extended version of the
    *Envoy* proxy is used.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Control plane** – This consists of multiple components responsible for configuring
    network proxies, service discovery, certificate management, and other features.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For a service mesh to work with Kubernetes, it has to be compatible with the
    K8s **Service Mesh** **Interface** (**SMI**).
  prefs: []
  type: TYPE_NORMAL
- en: SMI
  prefs: []
  type: TYPE_NORMAL
- en: This is a specification defining a standard, common, and portable set of APIs
    for smooth service mesh integration in a vendor-agnostic way. *SMI* serves the
    same purpose as *CRI*, *CNI*, and *CSI*, but for service meshes.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to observability, a service mesh offers detailed telemetry for
    all communications happening within the mesh. Automatically collected metrics
    from all proxies allow operators and engineers to troubleshoot, maintain, and
    optimize their applications. With a service mesh, we can trace the calls and service
    dependencies as well as inspecting traffic flows and individual requests. This
    information is extremely helpful to audit service behavior and response times,
    and to detect abnormalities in complex distributed systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Finally, a service mesh offers traffic management and reliability features.
    The exact functionality might vary from project to project, therefore some features
    provided by one service mesh might not be offered by another one. For the sake
    of example, let’s see what a *Linkerd* mesh has to offer:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Load balancing** – This is used for **HTTP**, **HTTP/2**, and **gRPC** requests
    as well as **TCP** connections. A service mesh can also automatically detect the
    fastest service endpoints and send requests there.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automatic retry and timeouts** – This allows you to gracefully handle transient
    service failures by transparently doing retries.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Traffic splitting** – This allows you to dynamically shift a portion of service
    traffic from one service to another to implement complex rollout strategies for
    new service versions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fault injection** – This allows you to artificially introduce errors and
    faults to test the impact on the system or connected services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All in all, a service mesh is a complex and advanced topic and we have only
    scratched the surface to learn the minimum required for passing the KCNA exam.
    If you are interested in knowing more, it is recommended to check the *Further*
    *reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: One question you might be asking yourself at this point is *what’s the difference
    between overlay networks and service meshes and why do we* *need both?*
  prefs: []
  type: TYPE_NORMAL
- en: The short answer is that most overlay networks operate on the lower layer of
    the **Open Systems Interconnection** (**OSI**) model (Network layer 3) whereas
    a service mesh operates on layer 7 of the OSI model, focusing on services and
    high-level application protocols (if you’re not familiar with the OSI model, check
    the *Further reading* section). The functionality of one is not a replacement
    for the other, and service meshes are still gaining momentum meaning, that not
    every microservice-based or containerized application running on Kubernetes will
    use a service mesh. Technically, we are also not obligated to always use overlay
    networks with containers, as we saw in our exercises with Docker, but in the upcoming
    chapters, we’ll see why it is favorable.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we’ve learned a lot about container runtimes, container interfaces,
    and service meshes. A container runtime is low-level software that manages basic
    container operations such as image downloading and the start or deletion of containers.
    Kubernetes does not have its own runtime, but it provides interfaces that allow
    you to use different runtimes, different network plugins, different storage solutions,
    and different service meshes. Those interfaces are called CRI, CNI, CSI, and SMI
    respectively and their introduction allowed a lot of flexibility when using K8s.
  prefs: []
  type: TYPE_NORMAL
- en: We’ve also learned about container runtime types and their differences. *Namespaced*
    containers are the most popular and lightweight, however, they are not as secure
    as other types. *Virtualized* containers are the slowest, but they provide maximum
    security as each container uses an individual Linux kernel. *Sandboxed* containers
    fill the gap between the other two – they are more secure than namespaced ones
    and faster than virtualized ones.
  prefs: []
  type: TYPE_NORMAL
- en: When it comes to container networking, there are many options. For container-to-container
    communication in a cluster, we would typically use an overlay network. Kubernetes
    supports third-party network plugins through CNI, and those plugins provide a
    different set of features and capabilities. It is also possible to run containers
    in a non-isolated network environment, for example, directly in the network namespace
    of the host where the container is started.
  prefs: []
  type: TYPE_NORMAL
- en: Containers are *stateless* by design, meaning that they don’t preserve the data
    on the disk by default. To run a *stateful* application in a container, we need
    to attach external storage volumes that can be anything ranging from an iSCSI
    block device to a specific vendor or cloud provider solution or even a simple
    local disk. Kubernetes with a pluggable CSI allows a lot of flexibility when it
    comes to integrating external storage to containers orchestrated by K8s.
  prefs: []
  type: TYPE_NORMAL
- en: We additionally touched on the basics of container security. *Namespaced* containers
    share the same kernel, which is why it is important to make sure that no container
    gets compromised. There are security extensions such as *AppArmor* and *SELinux*
    that add an extra kernel protection layer with configurable profiles and there
    are best practices that help to minimize the risks.
  prefs: []
  type: TYPE_NORMAL
- en: One of the practices is to use regular *(non-root)* user accounts in containers
    and another one is to ensure that you execute trusted code in a container. It
    is recommended to build your own images and keep them in your own registries,
    rather than using images from unknown third-party repositories. Additionally,
    you could implement automatic vulnerability scanning as a part of the image build
    process.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we learned about the service mesh – a special infrastructure layer
    that allows securing network communication between services without any changes
    to the application code. A service mesh also provides a rich set of features for
    observability and traffic management and even allows you to automatically retry
    requests and split traffic.
  prefs: []
  type: TYPE_NORMAL
- en: In the upcoming chapter, we will get to a major part of the KCNA exam and this
    book – namely, Kubernetes for container orchestration. Now make sure to answer
    all of the following recap questions to test your knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As we conclude, here is a list of questions for you to test your knowledge
    regarding this chapter’s material. You will find the answers in the *Assessments*
    section of the *Appendix*:'
  prefs: []
  type: TYPE_NORMAL
- en: Which of the following is software responsible for starting and stopping containers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Container hypervisor
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Container daemon
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Kubernetes
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Container runtime
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following are valid types of containers (pick multiple)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Hyperspaced`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Sandboxed`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Namespaced`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`Virtualized`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is an example of sandboxed containers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Kata
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: gVisor
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: containerd
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is an example of virtualized containers?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Docker
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: containerd
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: gVisor
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Kata
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following allows you to use different container runtimes with Kubernetes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CSI
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: SMI
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CNI
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CRI
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following allows you to use different service meshes with Kubernetes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CRI
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: SMI
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CNI
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: CSI
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Why are Namespaced containers considered less secure?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They use old kernel features
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They need Kubernetes to run
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They share a host kernel
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: They share a host network
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which container type is considered the most lightweight and fast?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Virtualized
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Sandboxed
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Namespaced
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Hyperspaced
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following storage solutions can be used with Kubernetes?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Any that supports NFS v4.1
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Any that is CSI compatible
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Any that is CNI compatible
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Any third-party cloud provider storage
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What has to be changed in the application code for the service mesh to work?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The application has to be rewritten in Golang
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The application needs to expose the SMI
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: The application has to be stateless
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: No application changes needed
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is a feature of a service mesh (pick multiple)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: mTLS
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Traffic management
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Observability
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Traffic compression
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which component does the service mesh data plane include?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Lightweight network firewall
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Lightweight network proxy
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Lightweight load balancer
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Lightweight web server
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is a service mesh (pick multiple)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Istio
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Prometheus
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Falco
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Linkerd
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following is considered best practice when it comes to container
    security (pick multiple)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the application as `UID=0`
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Scan container images for vulnerabilities
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Run the application as non-root
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Run containers with Kubernetes
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which of the following technologies can be used to improve container security
    (pick multiple)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: AppArmor
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ansible
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: SELinux
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Firewalld
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which potential problems can you encounter when using public container registries
    (pick multiple)?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Third-party images might be deleted at any time
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Third-party images might fail to download due to rate limiting
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Third-party images might contain malware
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Third-party images might work in development but fail in production
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which containers can Kubernetes spawn?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Namespaced containers
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: K8s does not spawn containers; the runtime does
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Virtualized containers
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Sandboxed containers
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What is typically used for multi-host container networkin[g?](https://www.beyondcorp.com/)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[IPtables](https://www.beyondcorp.com/)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[CNI](https://www.beyondcorp.com/)'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '[Service mes](https://www.beyondcorp.com/)h'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Overlay network
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Zero Trust: [https://www.beyondcorp.com/](https://www.beyondcorp.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Linkerd overview: [https://linkerd.io/2.12/overview/](https://linkerd.io/2.12/overview/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'About Istio: [https://istio.io/latest/about/service-mesh/](https://istio.io/latest/about/service-mesh/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Open Systems Interconnection (OSI): [https://en.wikipedia.org/wiki/OSI_model](https://en.wikipedia.org/wiki/OSI_model)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 3: Learning Kubernetes Fundamentals'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this part, you’ll learn about Kubernetes from the basics: the architecture,
    resources and components, features, and use cases. You will install Kubernetes
    and get practical experience with it using minikube. You will learn how to run
    stateless and stateful workloads, debug applications, and follow best practices
    with Kubernetes.'
  prefs: []
  type: TYPE_NORMAL
- en: 'This part contains the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 5*](B18970_05.xhtml#_idTextAnchor059), *Orchestrating Containers
    with Kubernetes*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 6*](B18970_06.xhtml#_idTextAnchor068), *Deploying and Scaling Applications
    with Kubernetes*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 7*](B18970_07.xhtml#_idTextAnchor077), *Application Placement and
    Debugging with Kubernetes*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B18970_08.xhtml#_idTextAnchor085), *Following Kubernetes Best
    Practices*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
