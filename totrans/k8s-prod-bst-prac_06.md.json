["```\n    kube2iam add-on. It manages the pod's IAM access, and it will block the containers from accessing the instance profile credentials. You will learn about kube2iam in detail later in this chapter.\n    ```", "```\n    sealed_secrets_replicas: 1\n    seald_secrets:\n      image: \"quay.io/bitnami/sealed-secrets-controller\"\n      tag: \"v0.12.4\"\n    ```", "```\n    $ brew install kubeseal\n    ```", "```\n    $ wget https://github.com/bitnami-labs/sealed-secrets/releases/download/v0.12.4/kubeseal-linux-amd64 -O kubeseal\n    $ sudo install -m 755 kubeseal /usr/local/bin/kubeseal\n    ```", "```\n    log_level: error\n    letsencrypt_email: security@packt.com\n    letsencrypt_prod_url: https://acme-v02.api.letsencrypt.org/directory\n    letsencrypt_nonprod_url: https://acme-staging-v02.api.letsencrypt.org/directory\n    cert_manager_replicas: 1\n    cert_manager_controller:\n      image: \"quay.io/jetstack/cert-manager-controller\"\n      tag: \"v0.15.2\"\n    cert_manager_cainjector:\n      image: \"quay.io/jetstack/cert-manager-cainjector\"\n      tag: \"v0.15.2\"\n    cert_manager_webhook:\n      image: \"quay.io/jetstack/cert-manager-webhook\"\n      tag: \"v0.15.2\"\n    ```", "```\n    ---\n    apiVersion: v1\n    kind: Namespace\n    metadata:\n      name: cert-manager\n      labels:\n        certmanager.k8s.io/disable-validation: \"true\"\n    ```", "```\n    ---\n    apiVersion: certmanager.k8s.io/v1alpha1\n    kind: ClusterIssuer\n    metadata:\n      name: letsencrypt-prod\n    spec:\n      acme:\n        email: {{ letsencrypt_email }}\n        server: {{ letsencrypt_prod_url }}\n        privateKeySecretRef:\n          name: letsencrypt-prod\n        solvers:\n        - http01:\n            ingress:\n              class: nginx\n        - selector:\n            matchLabels:\n              use-dns01-solver: \"true\"\n          dns01:\n            route53:\n              region: {{ aws_default_region }}\n              hostedZoneID: {{ route53_zone_id }}\n    ```", "```\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  annotations:\n    cert-manager.io/cluster-issuer: letsencrypt-prod\n  name: test-ingress\n  namespace: test-ingress\nspec:\n  rules:\n  - host: example.com\n    http:\n      paths:\n      - backend:\n          serviceName: myservice\n          servicePort: 80\n        path: /\n  tls: \n  - hosts:\n    - example.com\n    secretName: example-cert\n```", "```\n$ kubectl describe psp eks.privileged\nName:  eks.privileged\nSettings:\n  Allow Privileged:                       true\n  Allow Privilege Escalation:             0xc0004ce5f8\n  Default Add Capabilities:               <none>\n  Required Drop Capabilities:             <none>\n  Allowed Capabilities:                   *\n  Allowed Volume Types:                   *\n  Allow Host Network:                     true\n  Allow Host Ports:                       0-65535\n  Allow Host PID:                         true\n  Allow Host IPC:                         true\n  Read Only Root Filesystem:              false\n  SELinux Context Strategy: RunAsAny\n    User:                                 <none>\n    Role:                                 <none>\n    Type:                                 <none>\n    Level:                                <none>\n  Run As User Strategy: RunAsAny\n    Ranges:                               <none>\n  FSGroup Strategy: RunAsAny\n    Ranges:                               <none>\n  Supplemental Groups Strategy: RunAsAny\n    Ranges:                               <none>\n```", "```\n---\napiVersion: extensions/v1beta1\nkind: PodSecurityPolicy\nmetadata:\n  name: default-psp\n  annotations:\n    seccomp.security.alpha.kubernetes.io/allowedProfileNames: 'docker/default,runtime/default'\n    apparmor.security.beta.kubernetes.io/allowedProfileNames: 'runtime/default'\n    seccomp.security.alpha.kubernetes.io/defaultProfileName:  'runtime/default'\n    apparmor.security.beta.kubernetes.io/defaultProfileName:  'runtime/default'\n```", "```\nspec:\n  privileged: false\n  defaultAllowPrivilegeEscalation: false\n  allowedCapabilities: []\n  requiredDropCapabilities:\n    - ALL\n```", "```\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRole\nmetadata:\n  name: default-psp-user\nrules:\n- apiGroups:\n  - extensions\n  resources:\n  - podsecuritypolicies\n  resourceNames:\n  - default-psp\n  verbs:\n  - use\n```", "```\n---\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: default-psp-users\nsubjects:\n- kind: Group\n  name: system:authenticated\nroleRef:\n   apiGroup: rbac.authorization.k8s.io\n   kind: ClusterRole\n   name: default-psp-user\n```", "```\n    kube2iam:\n      image: \"jtblin/kube2iam\"\n      tag: \"0.10.9\"\n    ```", "```\n    ---\n    apiVersion: apps/v1\n    kind: DaemonSet\n    metadata:\n      name: kube2iam\n      namespace: kube-system\n      labels:\n        app: kube2iam\n    ```", "```\n    spec:\n    ---\n          containers:\n            - image: {{ kube2iam.image }}:{{ kube2iam.tag }}\n              name: kube2iam\n              args:\n                - \"--auto-discover-base-arn\"\n                - \"--auto-discover-default-role=true\"\n                - \"--iptables=true\"\n                - \"--host-ip=$(HOST_IP)\"\n                - \"--node=$(NODE_NAME)\"\n                - \"--host-interface=eni+\"\n                - \"--use-regional-sts-endpoint\"\n    ```", "```\napiVersion: v1\nkind: Pod\nmetadata:\n  name: aws-cli\n  labels:\n    name: aws-cli\n  annotations:\n    iam.amazonaws.com/role: <add-role-arn-here>\nspec:\n  containers:\n  - image: fstab/aws-cli\n    command:\n      - \"/home/aws/aws/env/bin/aws\"\n      - \"s3\"\n      - \"ls\"\n      - \"add-any-bucket-name-here\"\n    name: aws-cli\n```", "```\n$ kubectl get networkpolicies --all-namespaces\nNo resources found.\n```", "```\napiVersion: crd.projectcalico.org/v1\nkind: GlobalNetworkPolicy\nmetadata:\n  name: default-deny\nspec:\n  selector: all()\n  types:\n  - Ingress\n  - Egress\n```", "```\napiVersion: crd.projectcalico.org/v1\nkind: GlobalNetworkPolicy\nmetadata:\n  name: allow-dns-egress\nspec:\n  selector: all()\n  types:\n  - Egress\n  egress:\n  - action: Allow\n    protocol: UDP  \n    destination:\n      namespaceSelector: name == \"kube-system\"\n      ports: \n      - 53\n```", "```\ncurl -o install_falco -s https://falco.org/script/install\nsudo bash install_falco\n```", "```\n- macro: container\n  condition: container.id != host\n- macro: spawned_process\n  condition: evt.type = execve and evt.dir=<\n- rule: run_shell_in_container\n  desc: a shell was spawned by a non-shell program in a container. Container entrypoints are excluded.\n  condition: container and proc.name = bash and spawned_process and proc.pname exists and not proc.pname in (bash, docker)\n  output: \"Shell spawned in a container other than entrypoint (user=%user.name container_id=%container.id container_name=%container.name shell=%proc.name parent=%proc.pname cmdline=%proc.cmdline)\"\n  priority: WARNING\n```", "```\n    $ tar -xvf <RELEASE_TARBALL_NAME>.tar.gz\n    ```", "```\n    $ sonobuoy run --wait --mode quick\n    ```", "```\n    $ sonobuoy_results=$(sonobuoy retrieve)\n    $ sonobuoy results $sonobuoy_results\n    ```", "```\n    $ sonobuoy delete --wait\n    ```", "```\n$ kubectl apply -f https://raw.githubusercontent.com/octarinesec/kube-scan/master/kube-scan.yaml\n```", "```\n    $ kubectl port-forward --namespace kube-scan svc/kube-scan-ui 8080:80\n    ```", "```\n    $ kubectl delete -f https://raw.githubusercontent.com/octarinesec/kube-scan/master/kube-scan.yaml\n    ```", "```\n$ docker run --rm -v `pwd`:/host aquasec/kube-bench:latest install\n```", "```\n$ kube-bench node --version 1.14\n```", "```\n$ kube-bench node --benchmark cis-1.5\n```", "```\n$ kube-bench --benchmark cis-1.5 run --targets master,node,etcd,policies\n```", "```\nenabled_cluster_log_types = var.cluster_log_types\n```", "```\n    $ cd terraform/packtclusters\n    $ terraform workspace select prod1\n    ```", "```\n    $ aws eks --region $(terraform output aws_region) update-kubeconfig --name $(terraform output cluster_full_name)\n    ```", "```\n    $ source ~/ansible/bin/activate\n    $ ansible-playbook -i \\\n    ../../ansible/inventories/packtclusters/ \\\n    -e \"worker_iam_role_arn=$(terraform output worker_iam_role_arn) \\\n    cluster_name=$(terraform output cluster_full_name)\n    aws_default_region=$(terraform output aws_region)\" \\\n    ../../ansible/cluster.yaml\n    ```", "```\n    $ kubectl get pods --all-namespaces\n    ```", "```\n$ kubectl -n nginx-ingress destroy svc nginx-ingress\n```"]