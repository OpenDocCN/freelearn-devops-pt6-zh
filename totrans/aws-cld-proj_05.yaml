- en: <st c="0">5</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="2">Implementing an Image Analyzer to Detect Photo Friendliness</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="61">This chapter is</st> <st c="77">focused on the value that</st> **<st
    c="104">machine learning</st>** <st c="120">(</st>**<st c="122">ML</st>**<st c="124">)
    can bring to your applications.</st> <st c="159">You are going to build another
    serverless application, but this time, you will take advantage of AWS-native ML
    services instead of complex</st> <st c="298">programming logic.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="316">You are going to build your application using Python and architecture</st>
    <st c="387">using Terraform.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="403">This chapter covers the following main topics</st> <st c="450">in
    order:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="459">What you are going to build – a photo</st> <st c="498">quality analyzer</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="514">How you are going to build it – using serverless</st> <st c="564">AWS
    services</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="576">Building it – using Terraform</st> <st c="607">and Python</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="617">How to improve the application – using ML, advanced security features,
    and custom</st> <st c="700">domain names</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="712">By the end of this chapter, you will have your own application that
    uses ML to identify if a photo is professional-looking enough for a profile picture.</st>
    <st c="866">This is an introduction to more advanced ML applications that you
    will see in</st> [*<st c="944">Chapter 7</st>*](B22051_07.xhtml#_idTextAnchor203)<st
    c="953">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="954">Technical requirements</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="977">To implement your own photo analyzer following these chapter instructions,
    you will need access to an</st> <st c="1080">AWS account.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1092">This chapter has a dedicated folder in the GitHub repository of
    this book, where you will find the code snippets required to follow</st> <st c="1225">along:</st>
    [<st c="1232">https://github.com/PacktPublishing/AWS-Cloud-Projects/tree/main/chapter5/code</st>](https://github.com/PacktPublishing/AWS-Cloud-Projects/tree/main/chapter5/code)<st
    c="1309">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1310">Scenario</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="1319">You work for a</st> <st c="1335">marketing company.</st> <st c="1354">Your
    company receives customers’ information and photos, curates them, and creates
    social media profiles</st> <st c="1459">for them.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1468">However, your clients complain that they are not getting enough
    hits.</st> <st c="1539">After a study, the data science team attributes the lack
    of hits to</st> <st c="1607">unprofessional-looking photos.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1637">You are tasked to create a system that identifies if a photo is
    professional-looking enough before it is uploaded to</st> <st c="1755">social
    media.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="1768">Requirements</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="1781">You want to build something that</st> <st c="1814">evaluates if
    a photo is professional-looking.</st> <st c="1861">But what does it mean to be
    professional-looking?</st> <st c="1911">You decide that professional-looking photos
    require the subject to be smiling and have their</st> <st c="2004">eyes open.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2014">How can you identify these characteristics in a photo?</st> <st
    c="2070">It is not an easy task to program logic that identifies specific characteristics
    in photos, especially when photos can come in so many file formats.</st> <st c="2219">An
    ML model has the best odds of yielding</st> <st c="2261">good results.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2274">Because of the security compliance standards your company is subject
    to, your solution should not store</st> <st c="2379">personal information.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2400">This application, unlike the others you built in previous chapters,
    does not require a user interface.</st> <st c="2504">It does, however, require
    that it integrates with existing applications at your</st> <st c="2584">marketing
    company.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2602">All of these requirements can be translated into functional, non-functional,
    data, and</st> <st c="2690">technical requirements.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2713">Functional requirements</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="2737">Functional</st> <st c="2748">requirements define the specific features,
    functionalities, and capabilities that the solution must provide, which, in this
    case, are</st> <st c="2883">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="2897">Ability to recognize if a photo is good enough for a</st> <st c="2951">profile
    picture</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="2966">Interactable with</st> <st c="2985">other applications</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="3003">Support</st> <st c="3011">for multiple photo formats:</st> `<st
    c="3040">.</st>``<st c="3041">png</st>`<st c="3045">,</st> `<st c="3047">.jpeg</st>`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="3052">Non-functional requirements</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="3080">Non-functional</st> <st c="3095">requirements define the qualitative
    attributes that the solution must provide, which, in this case, are</st> <st c="3200">the
    following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3214">Highly-available</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="3231">Low-cost</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="3240">Scalable – up to 20 requests</st> <st c="3270">per second</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="3280">Data requirements</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="3298">Data requirements</st> <st c="3316">define data sources, processing,
    governance, and compliance needs, which, in this case, is</st> <st c="3408">the
    following</st><st c="3421">:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3423">Must not store any</st> <st c="3442">personal data</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="3455">Technical requirements</st>
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: <st c="3478">Technical requirements</st> <st c="3502">define specific technologies,
    programming languages, frameworks, and tools that the solution must use or integrate
    with, which, in this case, are</st> <st c="3648">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="3662">Must integrate with multiple other</st> <st c="3698">Python applications</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="3717">New infrastructure must be provisioned</st> <st c="3757">using
    Terraform</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="3772">The classification algorithm must</st> <st c="3807">use ML</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="3813">Architecture patterns</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="3835">Starting in the AWS</st> <st c="3856">Architecture Center, you
    can search for</st> `<st c="3896">image recognition</st>` <st c="3913">or</st>
    `<st c="3917">image classification</st>`<st c="3937">. The results, unfortunately,
    do not output any reference architecture.</st> <st c="4009">However, a prescriptive
    guidance document</st> <st c="4050">named</st> *<st c="4057">Image classification
    solutions on AWS</st>* <st c="4094">stands</st> <st c="4102">out (</st>[<st c="4107">https://docs.aws.amazon.com/prescriptive-guidance/latest/image-classification/introduction.html</st>](https://docs.aws.amazon.com/prescriptive-guidance/latest/image-classification/introduction.html)<st
    c="4203">).</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4206">Although the focus of this document is to identify objects in images,
    it also applies to your use case.</st> <st c="4311">For the image analysis, AWS
    recommends you follow one of</st> <st c="4368">four approaches:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4384">Use a pre-trained managed solution, for example,</st> <st c="4434">Amazon
    Rekognition</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="4452">Fine-tune a managed solution, for example, Amazon Rekognition</st>
    <st c="4515">Custom Labels</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="4528">Train a model using a no-code solution, for example, Amazon</st>
    <st c="4589">SageMaker Canvas</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="4605">Manually</st> <st c="4614">train a model on</st> <st c="4632">your
    own</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="4640">For each of these options, they detail benefits and drawbacks,
    such as flexibility, effort, and cost.</st> <st c="4743">You can contrast these
    with</st> <st c="4771">your requirements.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="4789">Architecture</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="4802">A possible agnostic</st> <st c="4823">architecture, applying what
    you have learned in previous chapters, looks like</st> *<st c="4901">Figure 5</st>**<st
    c="4909">.1</st>*<st c="4911">. Different applications connect to a frontend component,
    which handles connection termination, SSL certificates, and so on, and orchestrates
    and load balances backend connections where the submitted photos are parsed</st>
    <st c="5129">and analyzed.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.1 – Photo classification architecture](img/B22051_05_1.jpg)'
  prefs: []
  type: TYPE_IMG
- en: <st c="5233">Figure 5.1 – Photo classification architecture</st>
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="5279">A diagram</st> <st c="5290">using AWS services looks like the
    one in</st> *<st c="5331">Figure 5</st>**<st c="5339">.2</st>*<st c="5341">: a
    three-component diagram, with API Gateway,</st> <st c="5389">Lambda, and Rekognition.</st>
    <st c="5414">Different types of applications will connect to API Gateway using
    HTTPS, invoking a Lambda function, which queries Rekognition for image analysis
    and parses the</st> <st c="5575">response accordingly.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.2 – Photo classification architecture on AWS](img/B22051_05_2.jpg)'
  prefs: []
  type: TYPE_IMG
- en: <st c="5729">Figure 5.2 – Photo classification architecture on AWS</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5782">In the following section, you will find a detailed explanat</st><st
    c="5842">ion of why Rekognition is the better tool for this use case.</st> <st
    c="5904">For now,</st> <st c="5913">trust us.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="5922">In this architecture, you collapse the frontend and the backend
    in API Gateway</st> <st c="6002">and Lambda.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6013">You might be asking yourself, “Why can’t I allow my consuming applications
    to int</st><st c="6095">eract with Rekognition directly?” You can’t do this for</st>
    <st c="6152">several reasons:</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6168">It requires all consuming applications to have access to</st> <st
    c="6226">AWS credentials</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="6241">It does not allow for parsing and customization of</st> <st c="6293">the
    response</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="6305">It does not allow</st> <st c="6324">custom authentication/authorization</st>
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="6359">As shown, your</st> <st c="6375">consumer applications can be any
    type, and be anywhere; they can be virtual machines on EC2, containers on other
    cloud providers, or simply</st> <st c="6515">your workstation.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6532">AWS services</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="6545">This architecture uses three services, but you have used two of
    them before.</st> <st c="6623">In this section, you will understand how they address
    this</st> <st c="6682">project’s requireme</st><st c="6701">nts.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6706">Amazon Rekognition</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="6725">For this use case, you</st> <st c="6749">don’t want to create programming
    logic to identify photo features, so you choose to implement the same functionality</st>
    <st c="6866">using ML.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="6875">As mentioned in the AWS prescriptive guidance, you can create your
    own model from scratch.</st> <st c="6967">But how does it compare with using a
    pre-trained</st> <st c="7016">managed service?</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="7032">First, before comparing the two, you need to identify a service
    that can handle the task.</st> <st c="7123">AWS has a vast suite of AI and</st>
    <st c="7154">ML serv</st><st c="7161">ices:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="7167">Amazon Rekognition</st>**<st c="7186">: A</st> <st c="7191">computer
    vision service that is designed to analyze images and videos for various use cases,
    such as facial analysis, object detection, and</st> <st c="7331">text recognition.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="7348">Amazon Transcribe</st>**<st c="7366">: An</st> **<st c="7372">automatic
    speech recognition</st>** <st c="7400">(</st>**<st c="7402">ASR</st>**<st c="7405">)
    service that converts audio</st> <st c="7436">files</st> <st c="7442">to</st>
    <st c="7444">text.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="7450">Amazon Translate</st>**<st c="7467">: A</st> <st c="7472">neural
    machine translation service that can translate text between</st> <st c="7539">multiple
    languages.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="7558">Amazon Comprehend</st>**<st c="7576">: A</st> **<st c="7581">natural
    language processing</st>** <st c="7608">(</st>**<st c="7610">NLP</st>**<st c="7613">)
    service that can extract insights and relationships</st> <st c="7668">from unstructured</st>
    <st c="7685">text data.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="7696">Amazon Kendra</st>**<st c="7710">: An</st> <st c="7716">intelligent
    search service that can be used for indexing and searching multimedia content,
    including images</st> <st c="7824">and videos.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="7835">Amazon Lex</st>**<st c="7846">: A service</st> <st c="7858">for
    building conversational interfaces and chatbots, using natural language understanding
    and automatic</st> <st c="7963">speech recognition.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="7982">Amazon Polly</st>**<st c="7995">: A</st> <st c="8000">text-to-speech
    service that can convert text into</st> <st c="8050">lifelike speech.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8066">Amazon Rekognition seems like a perfect fit.</st> <st c="8112">Its
    main capabilities are</st> <st c="8138">as follows:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="8149">Facial analysis</st>**<st c="8165">:</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8167">Detect</st> <st c="8173">and analyze faces in images</st> <st c="8202">and
    videos.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8213">Identify facial attributes, such as gender, age range, emotions,
    and</st> <st c="8283">facial hair.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8295">Recognize and identify faces by comparing them against a user-provided
    dataset</st> <st c="8375">of faces.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8384">Detect unsafe content in images or videos based on explicit or</st>
    <st c="8448">suggestive content.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="8467">Object and</st>** **<st c="8479">scene detection</st>**<st c="8494">:</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8496">Detect and label</st> <st c="8513">objects, people, text, scenes,
    and activities in images</st> <st c="8569">and videos.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8580">Identify objects and concepts with</st> <st c="8616">high accuracy.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8630">Provide bounding boxes around detected objects</st> <st c="8678">and
    scenes.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="8689">Text recognition</st>**<st c="8706">:</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8708">Detect and recognize</st> <st c="8729">text in images</st> <st
    c="8744">and videos.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8755">Extract textual content from different surfaces</st> <st c="8804">and
    orientations.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="8821">Moderation</st>**<st c="8832">:</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8834">Detect and filter out</st> <st c="8856">explicit or suggestive
    content in images</st> <st c="8897">and videos.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8908">Automatically flag inappropriate or</st> <st c="8945">offensive
    content.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="8963">Important note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="8978">Take into consideration that when using Amazon Rekognition or any
    facial recognition technology, it’s crucial to consider privacy and ethical concerns,
    as well as compliance with relevant laws</st> <st c="9172">and regulations.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="9188">So, should you use Rekognition facial analysis capabilities or
    build your own model?</st> <st c="9274">Both approaches are valid, and the</st>
    <st c="9309">main comparison points are</st> <st c="9336">as follows:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="9347">Ease</st>** **<st c="9353">of use</st>**<st c="9359">:</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="9361">Rekognition is a fully managed service, which means you don’t have
    to worry about setting up and maintaining the underlying infrastructure or training
    models.</st> <st c="9520">It provides an API to</st> <st c="9542">analyze images.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="9557">Training your own ML model requires expertise in data preparation,
    model architecture selection, training techniques, and deployment strategies.</st>
    <st c="9703">It involves a significant learning curve and hands-on work.</st>
    <st c="9763">It also requires vast amounts</st> <st c="9793">of data.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="9801">Customization</st>** **<st c="9816">and control</st>**<st c="9827">:</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="9829">Rekognition offers pre-trained models.</st> <st c="9868">While
    it provides some customization options, such as creating custom collections for
    facial recognition, the level of customization</st> <st c="10001">is limited.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="10012">Training your own model allows you to have complete control over
    the model architecture, training data, and fine-tuning processes.</st> <st c="10144">This
    enables you to tailor the model specifically to your use case and achieve higher
    accuracy for</st> <st c="10243">specialized tasks.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="10261">Data privacy</st>** **<st c="10275">and security</st>**<st
    c="10287">:</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="10289">Using Rekognition, your data – images, in this case – is sent
    to AWS for processing, which can raise data privacy and</st> <st c="10407">security
    concerns.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="10425">When training your own model, you have complete control over the
    data and can ensure that sensitive information never leaves your environment,
    providing better data privacy</st> <st c="10599">and security.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="10612">Scalability</st>** **<st c="10625">and performance</st>**<st
    c="10640">:</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="10642">Rekognition is a highly scalable service that can handle large
    volumes of data and</st> <st c="10725">concurrent requests.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="10745">Training and deploying your own model at scale can be challenging,
    as it requires provisioning and managing compute resources, optimizing performance,
    and handling</st> <st c="10910">infrastructure-related tasks.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="10939">Cost and</st>** **<st c="10949">resource management</st>**<st
    c="10968">:</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="10970">Rekognition follows a pay-as-you-go pricing model, where you pay
    for API requests.</st> <st c="11053">This is cost-effective for smaller workloads
    or</st> <st c="11101">intermittent usage.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="11120">Training your</st> <st c="11135">own model requires upfront investment
    in hardware resources, as well as ongoing costs for managing and maintaining</st>
    <st c="11250">the infrastructure.</st>
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="11269">In summary, Rekognition provides a convenient and scalable solution
    for common computer vision tasks, but with limited customization options.</st>
    <st c="11412">Training your own ML model offers more flexibility and control but
    requires significant expertise, data,</st> <st c="11517">and resources.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11531">In this case, Rekognition is the winner.</st> <st c="11573">You
    do not have thousands of images labeled with the features you want to identify,
    nor do you have the data science knowledge or time to build an end-to-end</st>
    <st c="11731">ML framework.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="11744">Relating it to your requirements, Rekognition is a highly available
    scalable service, that supports up to 100 requests per second.</st> <st c="11876">It
    supports both the</st> `<st c="11897">.jpeg</st>` <st c="11902">and</st> `<st
    c="11907">.png</st>` <st c="11911">image formats and does not store your submitted
    images.</st> <st c="11968">It also qualifies as low-cost; in the N.</st> <st c="12009">Virginia
    region, it costs a tenth of a cent, 0.001$, to analyze 1 image.</st> <st c="12082">Because
    of its pay-as-you-go model, you will only pay if you analyze images; sitting idle
    has</st> <st c="12176">no cost.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12184">Amazon API Gateway and AWS Lambda</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="12218">In the</st> *<st c="12226">Architecture</st>* <st c="12238">section
    of this chapter, you learned why interacting directly with Rekognition was not
    ideal.</st> <st c="12333">However, you ask yourself, “What indirection layer should</st>
    <st c="12391">I use?”</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12398">You could use</st> <st c="12413">Lambda directly.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12429">Lambda</st> <st c="12436">allows you to parse requests and Rekognition
    responses.</st> <st c="12493">Using Lambda function URLs, you will</st> <st c="12530">be
    able to access your function from other applications using HTTPS (see</st> [<st
    c="12603">https://docs.aws.amazon.com/lambda/latest/dg/lambda-urls.html</st>](https://docs.aws.amazon.com/lambda/latest/dg/lambda-urls.html)<st
    c="12664">).</st> <st c="12668">However, Lambda function URLs only support IAM
    authentication or no authentication, and one of your requirements was not to have
    AWS credentials</st> <st c="12813">spread everywhere.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="12831">Or, maybe, you could use only</st> <st c="12862">API Gateway.</st>
    <st c="12875">As you learned in the previous chapter, it provides you with a unique
    domain name that you can interact with through HTTP and a multitude of features.</st>
    <st c="13026">However, it comes with drawbacks, too; although you can do some
    request and response mapping, it is hard to implement programming logic.</st>
    <st c="13163">Rekognition will not return a good/bad photo diagnosis, but rather
    a list of image attributes that you must parse to compute</st> <st c="13288">a
    decision.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13299">There is a blocking limitation for the API Gateway-only approach.</st>
    <st c="13366">API Gateway does not integrate directly with all AWS services, more
    specifically it does not integrate directly with Rekognition.</st> <st c="13496">For
    this, you need to use a</st> <st c="13524">Lambda integration.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13543">For this project, your indirection layer should be a combination</st>
    <st c="13609">of both.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13617">Important note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13632">Lambda function URLs are fit for use cases where you need a single
    function with a public endpoint that doesn’t require advanced API Gateway functionalities,
    such as request validation, throttling, custom authorizers, custom domain names,</st>
    <st c="13872">and caching.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13884">They are a great way to invoke your Lambda functions</st> <st
    c="13938">during testing.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="13953">You could use them for this chapter’s use case, however, to mimic
    a real project,</st> <st c="14036">you won’t.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="14046">API Gateway together with Lambda</st> <st c="14079">will allow
    you to do</st> <st c="14101">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '**<st c="14115">Control access to your services by authenticating and authorizing
    requests</st>**<st c="14190">: You can configure API keys, IAM roles, and other
    custom</st> <st c="14249">authentication mechanisms.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="14275">Simplify API versioning and life cycle management</st>**<st
    c="14325">: You can create and deploy multiple versions of your Rekognition integration
    API, and manage the transition between</st> <st c="14443">versions seamlessly.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**<st c="14463">Implement built-in request throttling and rate limiting capabilities</st>**<st
    c="14532">: This helps to protect your backend services, such as Rekognition,
    from being overwhelmed by excessive requests, which could lead to service disruptions
    and</st> <st c="14691">higher costs.</st>'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="14704">Relating it to your requirements, Lambda and API Gateway allow
    you to receive requests from many types of applications using a well-known and
    accepted protocol, HTTPS, integrate with Rekognition for image analysis, process
    the response into a diagnosis of good/bad photos in a pay-as-you-go serverless
    manner without storing the image in any of the underlying architecture components.</st>
    <st c="15090">You can do all of this using highly available and</st> <st c="15140">scalable
    components.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15160">Coding the solution</st>
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: <st c="15180">Congratulations again – you designed an architecture that meets
    all your company’s requirements.</st> <st c="15278">Now, it’s time to build it.</st>
    <st c="15306">During this chapter, we are going to use the AWS N.</st> <st c="15358">Virginia
    region.</st> <st c="15375">You can change the Terraform variable to your</st>
    <st c="15421">preferred region.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15438">Building the infrastructure</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="15466">The</st> <st c="15470">solution requirements mandated that the
    infrastructure be built using Terraform because the IaC language is already being
    used in</st> <st c="15601">the company.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15613">In this book’s GitHub repository, in the</st> `<st c="15655">chapter5/code</st>`
    <st c="15668">folder, you will find the following files:</st> `<st c="15712">interact.py</st>`<st
    c="15723">,</st> `<st c="15725">lambda.tf</st>`<st c="15734">,</st> `<st c="15736">apigw.tf</st>`<st
    c="15744">,</st> `<st c="15746">badphoto.png</st>`<st c="15758">,</st> `<st c="15760">goodphoto.jpeg</st>`<st
    c="15774">, and a</st> <st c="15782">Python subdirectory.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="15802">Start by focusing on the two terraform files:</st> `<st c="15849">apigw.tf</st>`
    <st c="15857">and</st> `<st c="15862">lambda.tf</st>`<st c="15871">. Recall that
    your architecture had three components.</st> <st c="15925">You don’t need to create
    your own Amazon Rekognition because it</st> <st c="15989">is</st> **<st c="15992">Software
    as a Service</st>** <st c="16013">(</st>**<st c="16015">SaaS</st>**<st c="16019">)
    , and because of that, it doesn’t have a Terraform</st> <st c="16073">resource
    representation.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16097">Important note</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16112">Although many people use a</st> `<st c="16140">main.tf</st>` <st
    c="16147">file to describe their infrastructure in Terraform, Terraform considers
    all files with a</st> `<st c="16237">.tf</st>` <st c="16240">extension in the
    directory.</st> <st c="16269">Filenames do</st> <st c="16282">not matter.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="16293">Start by exploring the</st> `<st c="16317">lambda.tf</st>` <st
    c="16326">file.</st> <st c="16333">Inside, you</st> <st c="16345">will find five
    resource definitions;</st> `<st c="16382">aws_lambda_function</st>` <st c="16401">is
    the one that creates your lambda function</st> <st c="16447">named</st> `<st c="16453">Detection_Lambda_Function</st>`<st
    c="16478">.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: <st c="17267">In this same Terraform file,</st> `<st c="17297">lambda.tf</st>`<st
    c="17306">, you also create an IAM role named</st> `<st c="17342">Detection_Lambda_Function_Role</st>`<st
    c="17372">, which has two IAM policies attached:</st> `<st c="17411">aws_iam_policy_for_terraform_aws_lambda_role</st>`
    <st c="17455">and</st> `<st c="17460">AmazonRekognitionReadOnlyAccess</st>`<st
    c="17491">. This is necessary for your Lambda function to be able to access other
    AWS services, in this case, Rekognition and CloudWatch Logs.</st> <st c="17624">Notice
    how the IAM policies are based on the least privilege principle, allowing the
    Lambda function only read access to the</st> <st c="17749">required services.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="17767">Because your</st> <st c="17780">marketing company is already using
    Python, you also choose Python for your Lambda function.</st> <st c="17873">Maintaining
    a single, or few, programming languages helps with developer productivity.</st>
    <st c="17960">You will dive deeper into the application code in the next section,
    but note how this Terraform project handles code deployment; it’s using a</st>
    `<st c="18102">.zip</st>` <st c="18106">file.</st> <st c="18113">This Lambda function
    uses Python 3.8 as runtime, but by the time you are reading this, you might have
    to upgrade it to a higher version.</st> <st c="18250">If that’s the case, simply
    change the</st> <st c="18288">runtime variable.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '<st c="18305">In the second Terraform file,</st> `<st c="18336">apigw.tf</st>`<st
    c="18344">, you will find eight resources.</st> <st c="18377">An API gateway,
    to work, has to have multiple components: stages, resources, and methods.</st>
    <st c="18467">Also, it needs permissions to interact with other components, in
    this case, your</st> <st c="18548">Lambda function.</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: <st c="18888">The first two</st> <st c="18901">Terraform resources,</st> `<st
    c="18923">my-api</st>` <st c="18929">and</st> `<st c="18934">root</st>`<st c="18938">,
    create a regional API gateway named</st> `<st c="18976">my-api</st>`<st c="18982">,
    and a</st> `<st c="18990">/friendly</st>` <st c="18999">resource path on the root
    resource.</st> <st c="19036">This will be accessible at</st> `<st c="19063">API_Gateway_URL/friendly</st>`<st
    c="19087">, as you will</st> <st c="19101">see later.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="19111">The four following resources in</st> `<st c="19144">apigw.tf</st>`
    <st c="19152">define a</st> `<st c="19162">POST</st>` <st c="19166">method for
    the</st> `<st c="19182">/friendly</st>` <st c="19191">resource path:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: <st c="20307">This</st> <st c="20312">code creates four components, as shown
    in</st> *<st c="20355">Figure 5</st>**<st c="20363">.3</st>*<st c="20365">:</st>
    `<st c="20403">aws_api_gateway_method</st>` <st c="20425">resource,</st> `<st
    c="20476">aws_api_gateway_integration</st>` <st c="20503">resource,</st> `<st
    c="20554">aws_api_gateway_integration_response</st>` <st c="20590">resource, and</st>
    `<st c="20641">aws_api_gateway_method_response</st>` <st c="20672">resource.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="20682">This is where you can do things such as request and response processing.</st>
    <st c="20756">In this case, you define the method request as a</st> `<st c="20805">POST</st>`
    <st c="20809">method without authentication, and the integration request type
    as Lambda.</st> <st c="20885">You don’t alter the response of the Lambda, just
    proxy</st> <st c="20940">it back.</st>
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 5.3 – API gateway method settings](img/B22051_05_3.jpg)'
  prefs: []
  type: TYPE_IMG
- en: <st c="21043">Figure 5.3 – API gateway method settings</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21083">At the end of</st> `<st c="21098">apigw.tf</st>`<st c="21106">,
    you will find a resource named</st> `<st c="21139">apigw_lambda</st>`<st c="21151">,
    which alters your Lambda permissions to allow the API gateway to</st> <st c="21218">invoke
    it.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="21228">In your favorite terminal, navigate to the</st> `<st c="21272">chapter5/code</st>`
    <st c="21285">folder, run the following Terraform command, and</st> <st c="21335">confirm.</st>
    <st c="21344">This will create all the resources mentioned in</st> <st c="21392">this
    section:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: <st c="21423">If your</st> `<st c="21432">apply</st>` <st c="21437">command
    is successful, it should output something like</st> <st c="21493">the following:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: <st c="23041">Note down your</st> <st c="23057">deployment URL.</st> <st c="23073">You
    will use</st> <st c="23086">it later.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23095">Open your AWS console and navigate to API Gateway, Lambda, and
    IAM to verify everything that</st> <st c="23189">was created.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23201">Understanding the image analyzer code</st>
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: <st c="23239">The Terraform infrastructure</st> <st c="23268">code you deployed
    in the previous section created a Lambda function with application logic.</st>
    <st c="23361">Open the</st> `<st c="23370">rekognition.py</st>` <st c="23384">file
    in the directory named</st> `<st c="23413">python</st>` <st c="23419">of the</st>
    `<st c="23427">chapter5/code</st>` <st c="23440">folder.</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23448">You will find boilerplate code, as in the previous chapter, to
    integrate with the Lambda ecosystem.</st> <st c="23549">But more</st> <st c="23558">interesting
    than that is the way it interacts with the Rekognition</st> `<st c="23625">DetectFaces</st>`
    <st c="23636">API (</st><st c="23642">see</st> [<st c="23647">https://docs.aws.amazon.com/rekognition/latest/APIReference/API_DetectFaces.html</st>](https://docs.aws.amazon.com/rekognition/latest/APIReference/API_DetectFaces.html)<st
    c="23727">).</st>
  prefs: []
  type: TYPE_NORMAL
- en: <st c="23730">The code calls the</st> `<st c="23750">DetectFaces</st>` <st c="23761">API
    and parses the response to make sure the photo does not contain more than one
    person, and that the person is smiling and has their</st> <st c="23897">eyes open:</st>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '#''HAPPY''|''SAD''|''ANGRY''|''CONFUSED''|''DISGUSTED''|''SURPRISED''|''CALM''|'
  prefs: []
  type: TYPE_NORMAL
- en: '''UNKNOWN''|''FEAR'' <st c="24589">Emotions = rekognition_response[''FaceDetails''][0][''Emotions'']</st>'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '{ "image": "b64"}'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: openssl base64 -A -in <infile> -out <outfile>
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'def analyze_image(url, image):'
  prefs: []
  type: TYPE_NORMAL
- en: 'with open(image, ''rb'') as image_file:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: image_bytes = image_file.read()
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'data = base64.b64encode(image_bytes).decode("utf8") <st c="28510">payload =
    {"image": data}</st><st c="28535">response = requests.post(url, json=payload)</st>
    return response.json()'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'def main():'
  prefs: []
  type: TYPE_NORMAL
- en: 'try:'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: parser = argparse.ArgumentParser(usage=argparse.SUPPRESS)
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: parser.add_argument("url", help="The url of your API Gateway")
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: parser.add_argument("image", help="The local image that you want to analyze.")
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'args = parser.parse_args() <st c="28919">chapter5/code</st> directory, test
    this application using the following syntax. You will only need to replace <st
    c="29024">invoke_url</st> with your own. This application converts the image into
    <st c="29091">base64</st> for you, so you don’t need to use the <st c="29136">openssl</st>
    tool:'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: <st c="29197">This application</st> <st c="29215">returns the response to your
    terminal window.</st> <st c="29261">Other applications, more complex ones, could
    just parse it and make a decision based on it.</st> <st c="29353">For example,
    when someone tries to upload a photo, block</st> <st c="29410">the upload.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="29421">Cleaning up</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="29433">This architecture does not cost you anything if no requests are
    made.</st> <st c="29504">All services used are paid for by the request and have
    no provisioning cost.</st> <st c="29581">Nonetheless, it is a good practice to
    delete the solution when you are done</st> <st c="29657">using it.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="29666">To delete all the resources, run the following command in the</st>
    `<st c="29729">chapter5/code</st>` <st c="29742">directory</st> <st c="29753">and
    confirm:</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: <st c="29785">Terraform keeps a state file of its deployed resources, and it
    will only delete the ones it is managing.</st> <st c="29891">If you have other
    resources manually deployed on the same account, those will not</st> <st c="29973">be
    deleted.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="29984">Future work</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="29996">There is only so much a book chapter can cover.</st> <st c="30045">Your
    project works and covers the requirements.</st> <st c="30093">It identifies if
    a photo is professional-looking enough, but you can still</st> <st c="30168">improve
    it.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="30179">Implementing authentication and authorization</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="30225">Currently, anyone can</st> <st c="30247">discover and call your
    API</st> <st c="30275">gateway to verify if their photo is professional-looking.</st>
    <st c="30333">A malicious actor can take advantage of this, and you will incur</st>
    <st c="30398">high costs.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="30409">In the previous chapter, you already implemented Cognito to manage
    authentication and authorization.</st> <st c="30511">You could do the same for
    this application, or if your client applications also run on AWS, you could change
    your REST API to a private API.</st> <st c="30652">In this case, your API gateway
    will only be reachable within the VPC and no longer be internet-reachable.</st>
    <st c="30758">You can read</st> <st c="30771">more about it in the AWS documentation</st>
    <st c="30810">at</st> [<st c="30813">https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-private-apis.html</st>](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-private-apis.html)<st
    c="30902">.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="30903">Improving your security posture</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="30935">You are way past the</st> <st c="30956">static websites you learned
    in</st> [*<st c="30988">Chapter 2</st>*](B22051_02.xhtml#_idTextAnchor032)<st
    c="30997">. This chapter’s application receives users’ input.</st> <st c="31049">This
    is a potential attack vector, as a malicious persona can upload custom software
    to</st> <st c="31137">exploit vulnerabilities.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="31161">One way to mitigate this is to attach a WAF with security policies
    to your API gateway and benefit from all its security features described in</st>
    [*<st c="31305">Chapter 2</st>*](B22051_02.xhtml#_idTextAnchor032)<st c="31314">.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="31315">To implement it, follow the</st> <st c="31344">AWS</st> <st c="31348">documentation:</st>
    [<st c="31363">https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-control-access-aws-waf.html</st>](https://docs.aws.amazon.com/apigateway/latest/developerguide/apigateway-control-access-aws-waf.html)<st
    c="31462">.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="31463">Implementing custom names</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="31489">You are calling</st> <st c="31506">your API using the URL given
    to you by AWS.</st> <st c="31550">It’s not a</st> <st c="31561">human-friendly
    name.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="31581">To change this, you will need to have your own domain name and
    create</st> <st c="31652">a certificate.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="31666">In</st> [*<st c="31670">Chapter 3</st>*](B22051_03.xhtml#_idTextAnchor054)<st
    c="31679">, you did this for a load balancer.</st> <st c="31715">API Gateway also
    supports custom domain names</st> <st c="31761">and certificates.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="31778">To implement it, follow</st> <st c="31803">the AWS</st> <st c="31811">documentation:</st>
    [<st c="31826">https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains.html</st>](https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-custom-domains.html)<st
    c="31913">.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="31914">Improving the image analysis algorithm</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="31953">Currently, your</st> <st c="31970">algorithm detects if the photo
    has a single person, if that person has their eyes open, and if they are smiling.</st>
    <st c="32083">If you implemented the emotions functionality, that is also taken
    into consideration for the</st> <st c="32176">final verdict.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '<st c="32190">However, consider the following scenario: a photo of a fully
    naked person with their eyes open and smiling.</st> <st c="32299">Is it a professional-looking
    photo?</st> <st c="32335">Your algorithm</st> <st c="32350">thinks so.</st>'
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="32360">You’ve already exhausted all the useful</st> `<st c="32401">DetectFaces</st>`
    <st c="32412">Rekognition API response fields.</st> <st c="32446">However, you
    can use other APIs to enhance</st> <st c="32489">your solution.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="32503">For example,</st> `<st c="32517">DetectModerationLabels</st>`
    <st c="32539">detects if images contain inappropriate or offensive content.</st>
    <st c="32602">Examples include explicit nudity, violence, hate symbols, and drugs.</st>
    <st c="32671">You can see all the supported</st> <st c="32701">content and how
    to use it on AWS</st> <st c="32734">documentation,</st> [<st c="32749">https://docs.aws.amazon.com/rekognition/latest/dg/procedure-moderate-images.html</st>](https://docs.aws.amazon.com/rekognition/latest/dg/procedure-moderate-images.html)<st
    c="32829">.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="32830">To implement it, you could follow different two approaches depending
    on</st> <st c="32903">your preference:</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="32919">Chain API calls on your already existing Lambda and mash all the
    results into</st> <st c="32998">a decision.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="33009">Create a different API resource, for example,</st> `<st c="33056">/moderate</st>`<st
    c="33065">, and a different Lambda function, and chain calls from the consuming</st>
    <st c="33135">client applications.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: <st c="33155">Your application is synchronous.</st> <st c="33189">If you add
    a lot of different functionality to do the image verification, the response latency
    will increase, and your user experience will</st> <st c="33329">feel degraded.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="33343">You can</st> <st c="33352">change your clients’ expectations to
    submit a photo and wait to receive the verdict at a later date.</st> <st c="33453">Then,
    transform your application into an asynchronous processing application where you
    chain a bunch of verifications, and deliver the decision at</st> <st c="33600">the
    end.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="33608">Hosting your own ML model</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="33634">What if the</st> <st c="33647">functionality you a</st><st c="33666">re
    looking for does not exist in a managed service?</st> <st c="33719">Or, maybe
    it exists, but it does not yield the results you are looking for.</st> <st c="33795">For
    example, let’s say you want to identify if the photo was taken by a</st> <st c="33867">professional
    photographer.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="33893">In these cases, you can train and host your own</st> <st c="33942">ML
    models.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="33952">As briefly mentioned before in this chapter, training your own
    ML models requires expertise in data engineering, model training, and selection
    and</st> <st c="34100">deployment strategies.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="34122">If you already have this expertise, or, if you want to practice,
    create a model using Amazon SageMaker and call it from your API gateway in a new
    resource path.</st> <st c="34284">This integration will also</st> <st c="34311">require
    a</st> <st c="34321">Lambda function.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="34337">SageMaker is a fully</st> <st c="34358">managed AWS service that
    aims to simplify and streamline the entire ML workflow, from data preparation
    to the deployment and operation of</st> <st c="34497">ML models.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="34507">Summary</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="34515">In this chapter, you saw how AI and ML can help you solve problems
    that are traditionally hard for regular programming to solve.</st> <st c="34645">You,
    again, followed a structured methodology to approach the project, starting from
    the requirements, checking for reusable assets, and</st> <st c="34782">lastly,
    architecting.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="34803">This time, you built</st> <st c="34825">using Terraform.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="34841">You dove deep into application logic using Python to retrieve
    and parse API responses.</st> <st c="34929">Then, again,</st> <st c="34942">for
    testing.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="34954">At the end of this chapter, you have multiple ideas that you can
    implement on your own using the AWS documentation to improve this chapter’s project.</st>
    <st c="35105">You can now, confidently, take advantage of AI/ML in your</st> <st
    c="35163">future projects.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: <st c="35179">In the next chapter, you are going to continue to learn about
    ML systems, this time applied to dynamic content translation.</st> <st c="35304">But
    that is not all; you will also start your journey into</st> <st c="35363">CI/CD
    tooling.</st>
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
