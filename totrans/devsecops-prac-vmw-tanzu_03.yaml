- en: '3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Building Secure Container Images with Build Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed how Application Accelerator for VMware
    Tanzu helps organizations with a uniform and efficient way of building greenfield
    applications. This is a great start to building cloud-native applications that
    are based on predefined templates. These templates help developers purely focus
    on the business logic, which brings revenue to the organization.
  prefs: []
  type: TYPE_NORMAL
- en: Greenfield and cloud-native applications
  prefs: []
  type: TYPE_NORMAL
- en: 'Greenfield is a term from the construction industry that refers to undeveloped
    land. In the IT world, greenfield describes a software project that is developed
    from scratch rather than built from an existing program. It is often contrasted
    with *brownfield*, which describes software built from an existing program. Reference:
    [https://techterms.com/definition/greenfield](https://techterms.com/definition/greenfield).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Cloud-native applications, as you might surmise, are written to take advantage
    of cloud computing. They are characterized by such technologies as containers,
    service meshes, microservices, immutable infrastructure, and declarative APIs.
    Reference: [https://github.com/cncf/toc/blob/main/DEFINITION.md](https://github.com/cncf/toc/blob/main/DEFINITION.md).'
  prefs: []
  type: TYPE_NORMAL
- en: However, to get the true benefit out of a cloud-native application on a container
    platform such as Kubernetes, we need to run these applications as containers.
    And, to run them as containers, we need to build container images for those applications.
    While there are various ways we can build such container images for our applications,
    one of the most popular approaches in the industry is to build them using configuration
    files known as Dockerfiles. A **Dockerfile** contains the definition, requirements,
    and attributes of the container image that should be built for the application.
    Though using Dockerfile is one of the most popular approaches to building container
    images, it is not always the most optimal one.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will take a deep dive into this concept and cover the following
    topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Why Tanzu Build Service?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unboxing Tanzu Build Service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Getting started with Tanzu Build Service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common day-2 activities for Tanzu Build Service
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: So, let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Some technical requirements need to be fulfilled before we start installing
    **Tanzu Build Service** (**TBS**). These requirements will be covered later in
    this chapter at the beginning of the *Getting started with Tanzu Build Service*
    section. However, you may not need them to understand the benefits TBS brings
    to the table. Let’s start looking into it.
  prefs: []
  type: TYPE_NORMAL
- en: Why Tanzu Build Service?
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: There are various business, technical, and security challenges in building container
    images for applications. This becomes even more complex when we do it at scale
    in a large enterprise. Let’s understand what those challenges are and how TBS
    addresses them.
  prefs: []
  type: TYPE_NORMAL
- en: Increasing developer productivity
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As discussed, one of the most popular approaches to building container images
    today is using Dockerfiles. And, in most cases, the application teams are responsible
    for building and maintaining such Dockerfiles for their applications. These Dockerfiles
    contain details such as the base container operating system and its version, application
    bundles such as JAR files for a Java application, environment variables, and useful
    libraries and their versions.
  prefs: []
  type: TYPE_NORMAL
- en: JAR files
  prefs: []
  type: TYPE_NORMAL
- en: A **Java ARchive** (**JAR**) file is a package of an application containing
    compiled source code files, configuration files, and external libraries required
    by the application. A JAR file can either be a supporting library or an application
    package that can be run in a **Java Runtime** **Environment** (**JRE**).
  prefs: []
  type: TYPE_NORMAL
- en: Developers know their applications more than anybody. So, it makes sense that
    they define what goes in their applications’ Dockerfiles. But at the same time,
    building and managing Dockerfiles are additional overheads for developers. Developers
    should spend all their time building more business-impacting functionalities in
    their applications. You might argue that building and changing such Dockerfiles
    is not a frequent task. Also, you may build some automation around building containers
    to reduce the amount of effort. However, such in-house automation brings other
    maintenance challenges. It would not eliminate the time required from the application
    teams. It’s not just about the time the developers need to spend to create or
    update the Dockerfiles. They also need the time required to research and decide
    on the content of it. And finally, these Dockerfiles have to be kept up to date
    to reflect the latest security patches of the libraries referenced in them. That
    ensures the best possible security posture for the running containers. Such endless
    ongoing maintenance consumes a lot of productive time of developers for unproductive
    activities.
  prefs: []
  type: TYPE_NORMAL
- en: Layers in container images
  prefs: []
  type: TYPE_NORMAL
- en: A final container image of an application could be a combination of multiple
    smaller images that are stacked as layers on top of each other to provide reusability,
    separation, and ease of usage.
  prefs: []
  type: TYPE_NORMAL
- en: To address these challenges, Pivotal Software Inc. (which was acquired by VMware
    Inc. in 2020) and Heroku collaborated. They incepted an open source project called
    **buildpacks.io** under the **Cloud Native Computing Foundation** (**CNCF**).
    We will discuss this project later in this chapter in detail. TBS is commercially-supported
    packaging containing buildpacks.io and a few other open source tools.
  prefs: []
  type: TYPE_NORMAL
- en: TBS addresses this challenge by providing a complete automation engine to build
    container images when you supply application code or built artifacts. As an output,
    TBS generates an OCI-compliant container image for the application. This image
    can be deployed on Kubernetes or any other OCI-compliant container orchestration
    platform. With TBS, developers are off the hook to build and maintain their container
    images. The reduced amount of responsibilities helps developers focus on what
    is more important for the business.
  prefs: []
  type: TYPE_NORMAL
- en: What is OCI?
  prefs: []
  type: TYPE_NORMAL
- en: '**Open Container Initiative** (**OCI**) is a standard set by The Linux Foundation
    describing the characteristics of a container image that can be implemented by
    various container image-building tools and understood by different container scheduling
    platforms such as Kubernetes. All major container platforms, including Kubernetes,
    support OCI-compliant container images.'
  prefs: []
  type: TYPE_NORMAL
- en: TBS supports different languages including Java, .Net, Python, Go, NodeJS, and
    many more.
  prefs: []
  type: TYPE_NORMAL
- en: Reduction of bespoke automation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is a commonly observed practice that organizations create **continuous integration**
    (**CI**) pipelines to build their applications’ container images. These pipelines
    are often developed using tools such as Jenkins and written mostly using languages
    such as Python or Shell script. Organizations may need to invest in resources
    to first develop such custom automation and then to maintain them ongoingly. Furthermore,
    the lack of good documentation around such custom automation makes such maintenance
    a nightmare. Hence, such people-dependent automation becomes a pain to maintain
    when their parents leave the organization. Additionally, the organizations could
    get better business outcomes if these people could rather be used for a better
    business-value-oriented assignment instead of such below-value-line engineering
    efforts.
  prefs: []
  type: TYPE_NORMAL
- en: TBS also helps address this challenge. It automates the container image-building
    process to a significant level. Although this will not replace the entire CI pipeline,
    it will reduce its complexity by covering the various steps required to build
    container images with full automation.
  prefs: []
  type: TYPE_NORMAL
- en: Standardization of container build process
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is often seen that there are many departmental silos in enterprises with
    large development shops. Such silos have tools and practices to follow. This could
    be a huge waste of crucial resources for the organizations in terms of duplication
    at various levels. Such duplication could be people’s time spent for similar outcomes,
    the license cost of tools, and the infrastructure used by the automation. This
    could lead to a whole new issue of lack of standardization. Such non-standard
    practices result in decreased transparency, governance, and security posture.
    When it comes to building container images, such an absence of standardization
    could be proven to be a very costly mistake for security risk exposures. This
    is caused by using unapproved libraries or not patching them quickly. When different
    teams have different ways of building container images, they could follow different
    practices. They might use different container operating systems, open source tools,
    third-party libraries, and their versions. It would be very difficult to apply
    an enterprise-wide standard. Such enforced standards should not affect different
    teams’ productivity and freedom of choice.
  prefs: []
  type: TYPE_NORMAL
- en: TBS solves this problem in two ways. First, it includes a centralized software
    library provided by VMware in the form of buildpacks and Stacks. Here, **buildpacks**
    include all the required libraries for the application to work in the container,
    including application runtimes such as **Java Runtime Environment** (**JRE**)
    and middleware such as Tomcat Server. On the other side, **Stacks** include different
    flavors of container operating systems. Second, TBS provides a standardized container
    image-building automation engine. Hence, when an organization uses TBS to build
    containers, it automatically implements standardization in the container-building
    process. This standardization comes in the form of the required automation and
    the application supporting content in the images.
  prefs: []
  type: TYPE_NORMAL
- en: TBS does not only help to standardize the container build process across the
    company but also improves the overall security posture around the same, as explained
    in the following section.
  prefs: []
  type: TYPE_NORMAL
- en: Stronger security posture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Security exposure is a major concern for the most established organizations
    in their journey to cloud transformation. Most cloud-native applications are deployed
    as containers in either public or private cloud platforms for several benefits.
    Containers are nothing but tiny virtual machines where the applications run. It
    is critical that such containers are built with secure ingredients that do not
    contain security vulnerabilities. But today’s secure library version could be
    found vulnerable tomorrow since it is very common to see new security vulnerabilities
    getting announced often for all operating systems and libraries that could be
    used in those container images. The corresponding organizations behind such operating
    systems and libraries would release newer versions to address those **Common Vulnerabilities
    and Exposures** (**CVE**). However, it is on the user organizations to take the
    newer versions of the software and use them to rebuild the impacted container
    images. Such container image rebuild exercises may introduce two big pain points.
    The first is when there are multiple development teams managing hundreds of containerized
    applications. In that case, it is very difficult to find the impacted applications.
    Such an identification and remediation process may take weeks, keeping those applications
    vulnerable to attacks. It would be very difficult to push all the application
    teams at the same time to rebuild their applications’ container images using the
    newer version of the software. The patching gets delayed as the application teams
    would have their product backlogs and priorities to manage. And history has proven
    time and again that most major software-related security breaches were driven
    by unpatched software components running for a long time.
  prefs: []
  type: TYPE_NORMAL
- en: TBS can greatly speed up the CVE patching of the impacted container images with
    its centralized resource library and container image rebuild automation using
    that library. As a new CVE patch is announced for the impacted component in the
    library, VMware releases a new version of the repository component (either a buildpack
    or a stack) containing the fix for the vulnerability. TBS identifies impacted
    application container images using an internal map of container images and their
    linked dependencies. So, when VMware releases a new component version in the centralized
    repository to fix any CVE, TBS immediately triggers the patching of the impacted
    application images using the patched version. Such an automatic rebuilding of
    images for hundreds of applications may be complete in a few hours rather than
    needing weeks in the absence of TBS. This could be one of the most important reasons
    to consider using a tool such as TBS. Such mappings of applications, their container
    images, and the associated software components used in them provide the required
    transparency and auditability to the security team. Using TBS, we can quickly
    generate a **Bill of Material** (**BOM**) for any application managed by TBS.
    A BOM is a detailed report listing all the components and their versions used
    in the respective container images. It greatly simplifies security audits of containerized
    environments.
  prefs: []
  type: TYPE_NORMAL
- en: Optimized network bandwidth and storage utilization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'As described previously, an OCI-compliant container image is a collection of
    other smaller images containing different components required for the final resultant
    container image. These layers are made up of application code, configurations,
    third-party libraries, and operating systems. Container image repositories such
    as Docker Hub and Harbor store such layers separately. They also maintain maps
    of which image layer depends on which other image layers. So, when you pull a
    specific container image from the container image registry, the registry pushes
    all dependent container image layers as a result. Due to this, when an application
    goes through any change, only the corresponding impacted layer will get transferred
    over the network into the container registry. All other non-impacted image layers
    will not move over the network. This makes the image push and pull operations
    a lot more efficient. It also helps to reduce the storage requirements for the
    container image registry because of the reuse of the unchanged layers. However,
    to get the full benefit of these layers, you should follow some discipline in
    the image-building process. If the authors of Dockerfiles do not take enough care,
    they end up with fewer image layers than what is optimally possible. The following
    figures show the anatomy of the same application’s container images. They both
    have a different number of layers. They are built with two different Dockerfile
    approaches. These snapshots were taken using an open source tool named **Dive**
    ([https://github.com/wagoodman/dive](https://github.com/wagoodman/dive)), which
    gives a detailed view of layers and their content for a container image:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 3.1 – A demo Java application’s container image built using \uFEFF\
    four layers](img/B18145_03_01.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 3.1 – A demo Java application’s container image built using four layers
  prefs: []
  type: TYPE_NORMAL
- en: 'As you can see, *Figure 3**.1* has only four layers, whereas *Figure 3**.2*
    has eight layers, even though the total resultant image size is almost the same.
    There are various ways to build a container image, which may result in different
    outputs for the same application code:'
  prefs: []
  type: TYPE_NORMAL
- en: "![Figure 3.2 – The same demo Java application’s container image but built using\
    \ \uFEFFeight layers](img/B18145_03_02.jpg)"
  prefs: []
  type: TYPE_IMG
- en: Figure 3.2 – The same demo Java application’s container image but built using
    eight layers
  prefs: []
  type: TYPE_NORMAL
- en: When the developers do not have the required awareness or there are no enterprise-level
    guidelines on how to build application container images, every team might end
    up with their own standards and practices. With such a lack of knowledge and controls
    in place, large organizations may end up with several suboptimal application container
    images, which may lead to a waste of network bandwidth and storage for every container
    image push and pull operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the other side, TBS uses a highly acclaimed **Cloud Native Computing Foundation**
    (**CNCF**) ([https://cncf.io](https://cncf.io)) certified project named **Cloud
    Native Buildpacks** (**CNB**) ([https://buildpack.io](https://buildpack.io)) as
    a tool under the hood, which provides a way to build container images with several
    smaller layers when the application container images are built using this tool.
    It provides an organization-level standardized approach to building container
    images that are also very resource efficient, along with having other benefits,
    as discussed previously. Here is a high-level representation depicting how TBS
    performs this operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.3 – High-level representation of how TBS builds container images
    with layers](img/B18145_03_03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.3 – High-level representation of how TBS builds container images with
    layers
  prefs: []
  type: TYPE_NORMAL
- en: The preceding figure shows how TBS takes some application code, performs various
    operations internally, and creates a final OCI-compliant application container
    image that has different smaller layers.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, TBS is useful to enhance developer productivity, reduce the learning
    curve, reduce operational toil, and increase security posture, along with several
    other benefits listed here for building secure container images. With all that,
    it just helps you accelerate your cloud-native application journey. After learning
    about the different benefits of using a tool such as TBS, let’s unbox it to check
    its anatomy. We will take a deep dive into all the different components that are
    bundled together as TBS.
  prefs: []
  type: TYPE_NORMAL
- en: Unboxing Tanzu Build Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As described previously, TBS is built on top of two main open source projects:
    CNB and kpack. The following figure depicts the whole packaging of TBS:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 3.4 – Building blocks of Tanzu Build Service](img/B18145_03_04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3.4 – Building blocks of Tanzu Build Service
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding figure, kpack includes engine and CLIs, whereas CNB
    includes things such as Builder, buildpacks and their groups, the stack, build
    and run images, and the life cycle process. Additionally, there are some VMware-supplied
    components for additional functionalities that are bundled in TBS. Let’s understand
    them in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud-native buildpacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The concept of CNB was derived from the concept of buildpacks in Cloud Foundry,
    which is another container orchestration platform for cloud-native applications.
    The buildpacks in Cloud Foundry have been proven a battle-tested tool for over
    a decade. Buildpacks in Cloud Foundry are used to scan application source code,
    determine application requirements based on the technology and language used,
    club all required dependencies with application packages, and create an offline
    container called a **droplet**. These droplets are large binary objects that contain
    everything required by the corresponding applications to run as containers on
    the Cloud Foundry platform. Though droplets have a solid track record, they have
    some limitations, listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Foundry buildpacks generate droplets that are very large as they contain
    everything required by the application. They do not have a layer concept like
    modern OCI-compliant container images do. Hence, every small change in the application
    or its dependency creates a new version of the heavy droplet again. Such droplets
    require more storage as they do not contain just the delta but a full-blown application
    package. Because of this, deploying containers using droplets in Cloud Foundry
    is a relatively slower process than deploying containers using an OCI image for
    a newer version of the application on an OCI-compatible platform such as Kubernetes.
    This slowness of container scheduling impacts application deployment times while
    scaling or redeploying the applications.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Buildpack project was designed to work only on Cloud Foundry. So, there
    was no way to use them on platforms such as Kubernetes that support only OCI-compliant
    container images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The extendibility or customization of Cloud Foundry buildpacks is very limited.
    Rather than adding newer changes as layers or plugins, they must be modified by
    opening them completely.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Foundry buildpacks are slow in building new droplets as they do not optimally
    use cached resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keeping all these limitations in mind and using the power of the buildpack concept
    in more broader and popular platforms such as Kubernetes, two software companies,
    Heroku and Pivotal (acquired by VMware in 2019), joined hands and announced that
    they were to collaborate on a new open source project called CNB, which retains
    all the goodness of the original Buildpack project but addresses its weaknesses.
    With this background, let’s discuss the anatomy of CNB in detail.
  prefs: []
  type: TYPE_NORMAL
- en: The following are some of the key concepts and terminologies of CNB that are
    important constructs of TBS.
  prefs: []
  type: TYPE_NORMAL
- en: Build image
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a base container operating system layer that is used to create a builder’s
    container image. A build container is short-lived. It executes the life cycle
    process to build the application’s container image and gets terminated.
  prefs: []
  type: TYPE_NORMAL
- en: Run image
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a base container operating system layer that is used to create an application’s
    container image. This is the main outcome of TBS. All the application-specific
    container images built by TBS use this image as the base container operating system
    layer.
  prefs: []
  type: TYPE_NORMAL
- en: Stack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a configuration entity that contains details of the build image and
    runs image flavors to be used in the container image build process. As a part
    of the package, TBS provides four different flavors of stacks that contain different
    flavors of build-and-run operating systems. These operating systems layers could
    be either thin or thick, depending on the requirements of the applications that
    need to use them.
  prefs: []
  type: TYPE_NORMAL
- en: Buildpack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a collection of executables that inspect your application code and determines
    whether the buildpack would apply to the application and hence should be a part
    of the resultant application’s container image. For example, there is a buildpack
    for Java applications, which detects the presence of Java-specific files in the
    application code or artifact, and then takes a call if the application needs required
    support to run as a Java application. In the TBS architecture, such buildpacks
    are stored in a container registry as container images.
  prefs: []
  type: TYPE_NORMAL
- en: Buildpack group
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This is a collection of buildpacks that are typically used together to build
    a container image of a specific type of application. The buildpacks that are members
    of a buildpack group could either be mandatory or optional, depending on their
    use case and the requirement of the application. For example, buildpacks for **Java
    Runtime Environment** (**JRE**), Maven, Gradle, Tomcat Server, and Jetty Server
    may all fall in the same group as they are all Java application-related dependencies.
    However, the buildpack for JRE would be a compulsory one for a Java application,
    but all others listed before would fall into the optional category as the application
    might or might not need them. There are various such buildpack groups for different
    types of applications, such as Python, .Net, NodeJS, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Life cycle
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This determines the application of buildpacks and orchestrates their execution.
    The life cycle process has various components that execute its stages. At the
    end of all the stages, we get the final OCI-compliant container image of an application.
    Let’s review these life cycle components:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Analyzer**: This retrieves and examines all required files that would be
    required during the image build process and used by the buildpacks. It also checks
    whether all the required images for the build are accessible in the container
    registry used by TBS. With such quick checking of dependencies, the build process
    fails fast if something is missing rather than realizing that later in the build
    process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Detector**: This checks which buildpack group is applicable for the application
    under the build process. It also gets a list of all available buildpack groups
    in a specific order. Then, it checks the applicability of each of these groups
    one by one until the first group passes the required criteria. The detector then
    creates a plan of execution to perform the container image build process as a
    resulting artifact.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Restorer**: This restores all the required dependency image layers based
    on the selected buildpack group from the cache put in by previous container build
    processes using the same image layers. This phase reduces the build time and the
    network traffic to transfer frequently used images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**App Builder**: This transforms the application source code into a runnable
    artifact that can be packaged for execution inside a container. For example, this
    stage converts a Java application source code into a JAR file with compiled class
    files as an executable artifact. The application of this stage could be optional,
    depending on the supplied artifact of the application or even based on the technology
    requirements. For example, if the build process gets an already prepared JAR file
    for a Java application instead of the source code, then there is no need to prepare
    a build for the application and this stage may be skipped.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Exporter**: This creates the final OCI-compliant container image file. It
    also prepares a report containing the BOM for the components and their versions
    used in the container image. Finally, it pushes the container image into the target
    registry.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Builder
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To build a container image of an application, TBS needs to deploy a temporary
    container on Kubernetes that executes the life cycle components, as previously
    described, to create the resultant container image. A builder is a container image
    that deploys this container, which contains the executables for the life cycle
    processes, along with a list of buildpack groups and a build image.
  prefs: []
  type: TYPE_NORMAL
- en: kpack
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: kpack ([https://github.com/pivotal/kpack](https://github.com/pivotal/kpack))
    is an open source project initiated by Pivotal and is now actively being maintained
    by VMware. kpack provides a way to use CNB on the Kubernetes platform. kpack uses
    some Kubernetes **Custom Resource Definitions** (**CRDs**) to deploy itself as
    a tool running on top of Kubernetes. Hence, kpack is a tool that runs on Kubernetes
    and uses CNB to build OCI-compliant container images.
  prefs: []
  type: TYPE_NORMAL
- en: Custom Resource Definitions (CRDs)
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes has several out-of-the-box APIs that are referred to as resources.
    Some examples of such resources are Pod, Node, Deployment, Service, ReplicaSet,
    and many others. Though Kubernetes comes with many such out-of-the-box resources,
    it is a very extensible platform that allows adding more resources that are custom.
    Such custom resources are called CRDs. You may learn more about CRDs here: [https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'kpack has two main components, as depicted in *Figure 3**.4*:'
  prefs: []
  type: TYPE_NORMAL
- en: kpack Kubernetes CRDs to help use CNB and define the container image specification.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The kpack **command-line interface** (**CLI**), which provides the required
    user interface to use kpack resources. The kpack CLI provides ways to create and
    manage container image build specifications using kpack.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: kpack CRD objects used by TBS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Though kpack is an internal component of TBS, the following are some of the
    key kpack CRD objects that are used by TBS:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Image` object references the application source code or package location,
    the runtime details for the build process, and the container registry details
    to store the built images.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ClusterStore**: This contains references to buildpacks in the form of their
    respective container image locations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**ClusterStack**: This contains references to the OS layers in terms of the
    build image and run image, along with their container registry locations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ClusterStore` and `ClusterStack` combinations. A `ClusterBuilder` object also
    defines an order of buildpacks to be validated against any application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VMware-provided components and features
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In addition to the two main open source build blocks of TBS – CNB and kpack
    – there are also a few additional components and functionalities provided by VMware
    that the enterprises can get as a part of TBS packaging. Let’s quickly visit them:'
  prefs: []
  type: TYPE_NORMAL
- en: TBS comes with a proprietary installation and upgrades the user experience using
    an open source toolkit named Carvel ([https://carvel.dev](https://carvel.dev)).
    It is a Kubernetes application packaging and deployment toolkit mainly maintained
    by VMware. We will use it to install TBS in the next section.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TBS has a dependency updater component that keeps all the container images built
    by TBS up to date with changes made in their corresponding buildpacks or stack.
    This feature helps to keep all the container images patched and secured with the
    latest updates in the operating system and application dependency changes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TBS also comes with a bundle of VMware-supplied buildpacks. This includes the
    support for offline buildpacks, Windows containers, and quick and reliable release
    engineering of the new buildpack versions to include new features and fixes of
    CVEs.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this section, we saw the structure and components of TBS. We also learned
    the role that each of them plays to build the whole solution. Now, let’s get started
    with working with TBS. In the next section, you will learn how to install and
    configure TBS in your Kubernetes cluster and rip all the benefits we discussed
    previously.
  prefs: []
  type: TYPE_NORMAL
- en: Getting started with Tanzu Build Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After learning about the challenges addressed by TBS and the details of what
    TBS contains, let’s learn how we can quickly get started with it running in a
    Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: All these instructions are for **Tanzu Build Service** (**TBS**) v1.3.
  prefs: []
  type: TYPE_NORMAL
- en: The following section details different prerequisites that you may need to get
    TBS fully up and running in your Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You will need the following to configure TBS in your Kubernetes environment:'
  prefs: []
  type: TYPE_NORMAL
- en: Administrator-level `kubectl` CLI access to a Kubernetes cluster with version
    1.19 or later. If administrator-level access is not feasible, then the user must
    at least have permissions listed at [https://github.com/tandcruz/DevSecOps-in-Practice-with-VMware-Tanzu/blob/main/chapter-03/tbs-k8s-cluster-permissions.yml](https://github.com/tandcruz/DevSecOps-in-Practice-with-VMware-Tanzu/blob/main/chapter-03/tbs-k8s-cluster-permissions.yml)
    on the cluster to install and configure TBS.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The worker nodes of the Kubernetes cluster should at least have 50 GB of ephemeral
    storage as TBS stores the historical versions of the built images for records.
    The number of historical versions stored by TBS can be configured. This will be
    covered later in this chapter under day-2 activities.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Access to any container registry with required permission that supports Docker
    HTTP API V2 with at least a 5 GB storage quota, which excludes the space required
    for application images built by TBS. To keep things simple, we will use Docker
    Hub ([https://hub.docker.com/](https://hub.docker.com/)), which provides a free
    account that is good enough for TBS integration.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There should be a default **StorageClass** configured in your Kubernetes cluster
    that TBS can use to create the required storage volumes. By default, TBS will
    need a **PersistentVolumeClaim** that it uses to cache already-built artifacts.
    Such caching helps the subsequent builds complete faster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The operator machine that will be used for this installation should have Carvel
    CLI tools installed. The following are those Carvel tools that TBS uses, along
    with their download locations and purposes:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kapp` version 0.41.0 ([https://network.tanzu.vmware.com/products/kapp](https://network.tanzu.vmware.com/products/kapp)/)
    to deploy the bundle of Kubernetes resources required for TBS.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ytt` version 0.37.0 ([https://network.tanzu.vmware.com/products/ytt/](https://network.tanzu.vmware.com/products/ytt/))
    to replace custom configuration values in the YAML template files used for TBS
    Kubernetes resource deployments.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`kbld` version 0.31.0 ([https://network.tanzu.vmware.com/products/kbld/](https://network.tanzu.vmware.com/products/kbld/))
    to reference container images in Kubernetes configuration files that are relocated
    based on your choice of container registry.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`imgpkg` version 0.23.1 ([https://network.tanzu.vmware.com/products/imgpkg/](https://network.tanzu.vmware.com/products/imgpkg/))
    to deploy the packaged application bundle for TBS that contains the required configuration
    and OCI images. For an air-gapped (an environment that has no outbound internet
    connectivity) installation, it helps to relocate all the required OCI images to
    the private container registry in use.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: The operator machine should have `kp` CLI v0.4.*, which can be downloaded from
    the Tanzu Network website at [https://network.tanzu.vmware.com/products/build-service/](https://network.tanzu.vmware.com/products/build-service/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The operator machine should have the `docker` CLI: [https://docs.docker.com/get-docker/](https://docs.docker.com/get-docker/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The operator machine should have the Dependency Descriptor file in the `descriptor-<version>.yaml`
    format downloaded from the TBS dependencies page on the Tanzu Network website
    at [https://network.tanzu.vmware.com/products/build-service/](https://network.tanzu.vmware.com/products/build-service/).
    This book has used the `descriptor-100.0.229.yaml` file. This file contains container
    image paths that TBS will need to execute image builds. You may find a different
    version, depending on when you download it, which is fine.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'The Kubernetes cluster running with Containerd v1.4.1 is not compatible with
    TBS. The following `kubectl` command will get the version of the underneath container
    runtime to check this:'
  prefs: []
  type: TYPE_NORMAL
- en: '`kubectl get` `nodes -o=jsonpath=''{.items[0].status.nodeInfo.containerRuntimeVersion}''`'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s start our journey working with TBS by first installing it and then performing
    some basic tests to confirm whether it is working as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Installation procedure
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, we will use Docker Hub as the container registry to be used
    with TBS. Also, the installation steps assume that the base Kubernetes cluster
    has full outbound internet connectivity. The procedure to install and configure
    TBS is different for an air-gapped environment and a custom container registry
    to be used instead of Docker Hub. You may follow the official product documentation
    ([https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-installing.html](https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-installing.html))
    for a different use case.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the `p********t` value used in all the commands should be replaced
    with your respective username and `**********` with your respective password.
  prefs: []
  type: TYPE_NORMAL
- en: 'With those expectations set, let’s install and configure TBS by performing
    the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Make sure you are working in the right Kubernetes cluster and context where
    you want to install TBS:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Relocate the required container images from the Tanzu Network registry to your
    Docker Hub account. For that, log in to your Docker Hub account, as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Log in to the Tanzu Network container registry to pull the required images
    for installation using your Tanzu Network credentials:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Relocate the images from Tanzu Network to your Docker Hub registry using the
    following `imgpkg` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You may ignore the warning given before the success message because TBS excludes
    Windows components by default as they are licensed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Pull the TBS bundle image locally using the `imgpkg` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE23]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install TBS using the relevant Carvel tools – `ytt`, `kbld`, and `kapp` – with
    the following command. It is a very long command that injects the provided custom
    parameter values with the `-v` flag into the deployment configuration files using
    `ytt`. Then, the command replaces the container image locations based on your
    registry location using `kbld`. And finally, it deploys TBS using the configuration
    files with custom parameter values and the required container image files pulled
    from your repository using `kapp`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: At the time of writing this book, all the binaries supplied under Carvel, including
    `ytt`, `kbld`, and `kapp,` are unsigned binaries. Because of this, your operating
    system, especially macOS, may raise a security concern against using them. However,
    you may explicitly allow the execution of these binaries in your operating system’s
    security settings. Additionally, as this command performs various long image pull
    operations to deploy TBS in your Kubernetes cluster, you may see the command complete
    unsuccessfully with an error – `use of closed network connection`. In that case,
    you may run the same command again and it may just work.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may need to replace the highlighted values in the preceding command as
    per the following specification:'
  prefs: []
  type: TYPE_NORMAL
- en: Replace `p********t` in the `kp_default_repository` and `kp_default_repository_username`
    parameters with your Docker Hub username
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace `**********` in the `kp_default_repository_password` parameter with
    your Docker Hub account password
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace `p********t@*******.io` in `tanzunet_username` with your Tanzu Network
    username
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace `**********` in `tanzunet_password` with your Tanzu Network password
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With that last command completed successfully, TBS should be up and running
    in your Kubernetes cluster. Let’s verify the installation and ensure TBS is working
    fine.
  prefs: []
  type: TYPE_NORMAL
- en: Verifying the installation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To verify the TBS installation, execute the following `kp` command to list
    the cluster builders available in your TBS environment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: 'The result of the preceding command should look as follows, where you should
    see your Docker Hub username instead of `p********t`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: If you see the preceding output, then congratulations to you as you have TBS
    running in your Kubernetes environment, waiting to build container images of your
    application!
  prefs: []
  type: TYPE_NORMAL
- en: Now that we’ve got started with TBS, let’s investigate common day-2 operations
    that we can perform on TBS for various use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Common day-2 activities for Tanzu Build Service
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will go through some useful operations we can perform on
    TBS.
  prefs: []
  type: TYPE_NORMAL
- en: Building application container images
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will learn how to register our application with TBS for
    the first time, create the first container image, run that container image locally,
    retrigger the image build process again by modifying the application configuration,
    and, finally, verify the newly created container image to reflect the application
    change. This will be an exciting journey to use TBS for its main purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Registering an application with TBS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The main reason to use TBS is to gain the ability to build application container
    images in a fully automatic and secure way. Let’s see how we can build container
    images of a cloud-native application using the TBS setup we have completed. We
    will use a sample Spring Framework-based application, Spring Pet Clinic, available
    at [https://github.com/tandcruz/DevSecOps-in-Practice-with-VMware-Tanzu/tree/main/spring-petclinic](https://github.com/tandcruz/DevSecOps-in-Practice-with-VMware-Tanzu/tree/main/spring-petclinic).
    To follow along, you need to fork this project in your Git repository.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the `kp` CLI to register our application with TBS. To register
    an application, we must create an `image` resource, which is a kpack CRD object
    to create a record of the application in its list. Once an image resource has
    been created, TBS creates a `build`, which is also a kpack CRD object that creates
    a container image of a registered application. There can be one-to-many relationships
    between an `image` and its `build` objects, depending on the number of instances
    to create a new container image for an application. But before we register our
    application, let’s verify the current image objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: As you might have guessed, we don’t have any existing `image` objects managed
    by our newly deployed TBS in our Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, we will also need to provide TBS with the credentials to our
    Docker Hub account so that it can push built images there. You may also use a
    different container registry or a Docker Hub account to push built application
    images. But, to keep things simple, we will use the same Docker Hub account that
    we used previously to install TBS. To supply the login credentials of our Docker
    Hub account, we need to create a Kubernetes `Secret` object, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s work on creating an `image` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are three different ways in which we may configure an application to
    use TBS for building container images. Let’s take a look at them so that you can
    understand which one you should use when:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Using a Git repository URL**: In this approach, we register the Git repository
    URL and the branch of the repository that we want to monitor for changes and trigger
    TBS image builds based on the changes committed in this branch. This is the most
    automated approach to creating container images as soon as application changes
    are merged in the final code branch. We will use this approach in this book.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Using a local path**: In this approach, we supply either the location of
    the application’s package such as a JAR file for a Java application that is precompiled
    and packaged on the local system, or provide the location of the application’s
    source code on the local system. This approach is not fully automated using TBS
    and assumes that you have an external CI process that will explicitly call TBS
    whenever there is a need to create a container image of the application, rather
    than creating new images automatically based on the new changes pushed into the
    Git repository branch.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`zip`, `tar.gz`, `tar`, or `jar` file. This approach is also used for explicit
    build triggers like the previous one.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now, let’s register the application, Spring Pet Clinic, to be used with TBS,
    along with its Git repository. See the following command and its results, which
    explain how to do this. The command uses the application’s Git repository and
    the branch that we want TBS to monitor for changes and build container images
    from:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: In this command, replace the value of `--git` and `--git-revision` with the
    repository details that you would have forked.
  prefs: []
  type: TYPE_NORMAL
- en: Important note
  prefs: []
  type: TYPE_NORMAL
- en: 'This command may take several minutes to run since it’s the first build and
    application registration. Also, it assumes that the Git repository is publicly
    accessible. But if the repository requires user credentials to pull the source
    code, you may need to create a TBS `secret` object for the Git repository credentials,
    as described here: [https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-managing-secrets.html#create-a-git-ssh-secret](https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-managing-secrets.html#create-a-git-ssh-secret).'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, this command performs several operations, including accessing
    the application’s source code, downloading all required dependencies, performing
    all CNB life cycle stages, and finally, pushing the application image into your
    Docker Hub registry, as specified in the command.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s check the presence of `image` objects for our application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see that one `image` object has been created called `tbs-spring-petclinic`.
    Now, let’s check the number of `build` objects that have been created for our
    application:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we can see one `build` object created for our application `image` object.
    We may see more `build` objects if there were a greater number of image builds
    triggered for application changes. The column named `REASON` indicates the reason
    to get this build triggered by TBS. There are the following possible reasons:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CONFIG** to indicate when a change is made to commit, branch, Git repository,
    or build fields on the image’s configuration file'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**COMMIT** to indicate a build as a result of a change pushed in an application’s
    code repository under TBS’s watch'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**STACK** to indicate a change in the run image OS layer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**BUILDPACK** to indicate a change in the buildpack versions that are made
    available through an updated builder'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TRIGGER** to indicate a build triggered manually'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Now that the application has been registered with TBS, when you commit a small
    change in the monitored branch, you should see a new build getting created in
    a few seconds, as shown here:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: You may now pull the old and the new images to deploy their containers within
    your local Docker environment to verify the changes that have been made to the
    application. Now that we’ve learned how to create new builds of the container
    images for the registered applications, let’s learn how to check the build logs
    to see the execution details of the life cycle stages.
  prefs: []
  type: TYPE_NORMAL
- en: Checking image build logs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To check the TBS logs of the newly built image, use the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: The output has been truncated for brevity.
  prefs: []
  type: TYPE_NORMAL
- en: With that, we’ve learned how to create the first application configuration,
    trigger a new build, and check build logs on TBS. Now, let’s discuss another very
    important activity around TBS, which is to keep our container images always secured
    and patched with the latest versions of the software libraries and operating system
    layers used in the application container images.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading buildpacks and stacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we saw in the *Why Tanzu Build Service* section, one of the main benefits
    of using this tool is to enhance the security posture by staying up to date using
    the latest patched application dependencies and the OS layer used to build container
    images. As we know, buildpacks contain references to different software library
    versions and stacks contain the OS layers for the container image building. So,
    when there are new patch releases of the libraries that are referenced in the
    buildpacks or the OS in the stacks, VMware releases a new version of the impacted
    buildpacks and stacks to provide the latest patched version of the software that
    they reference.
  prefs: []
  type: TYPE_NORMAL
- en: 'The most recommended way to stay up to date with TBS component versions is
    to enable the automatic update ability that TBS is equipped with. When we deploy
    TBS with our Tanzu Network account credentials, TBS deploys a CRD object in our
    Kubernetes cluster named **TanzuNetDependencyUpdater**. This CRD object is responsible
    for keeping our TBS components up to date automatically. We used the same approach
    in our installation, which we performed earlier in this chapter. You can verify
    this setup by running the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: Here, the value of `DESCRIPTIONVERSION` may be different, depending on the latest
    available release of the description file that you would have downloaded as a
    part of the prerequisites at the beginning of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the automatic update was not enabled during the installation process, then
    the following link shows how to enable it post-installation or how to manually
    update various components to retain more control over time and the impact of the
    changes: [https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-updating-deps.html](https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-updating-deps.html).'
  prefs: []
  type: TYPE_NORMAL
- en: Managing images and builds
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There are various day-to-day operations that we may need to perform to work
    with the application configuration, in the form of image objects, and their corresponding
    build processes, created in the form of build objects, that are triggered for
    different possible reasons we saw earlier, including STACK, BUILDPACK, CONFIG,
    COMMIT, and TRIGGER. You can learn more about such operations at [https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-managing-images.html](https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-managing-images.html).
    Additionally, TBS keeps the last 10 successful and failed pieces of build history
    information, including their completed pods and hence the logs for each `Image`
    resource. Such historical builds help you obtain historical logs and details but
    also occupy a lot of storage space on the cluster. In a large enterprise-scale
    environment, it could impact more because of several `Image` resources being created.
    You may refer to this documentation if you want to change the default configuration
    of 10 historical builds to a different number: [https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-faq.html#faq-18](https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-faq.html#faq-18).'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring role-based access controls
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It is recommended to install TBS on a Kubernetes cluster that is dedicated
    to such platform services that are different from the cluster running actual business
    workloads. Such supporting services clusters are under the control of a specific
    user group of platform operators. Such cluster-level separation is one good way
    to selectively allow users to access TBS in the first place. An accidental change
    in a `ClusterBuilder` definition may cause a trigger to build possibly hundreds
    of container images for the applications that are linked with that `ClusterBuilder`.
    And if there is an automated deployment pipeline in place that deploys new versions
    of all the applications with the new container images, then such a mistake could
    be even more severe. That is why putting the required guardrail around TBS is
    very important. For that reason, TBS provides some level of access control using
    two Kubernetes ClusterRoles, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '`build-service-user-role`: To allow working with images and build resources'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`build-service-admin-role`: To allow all other administrative activities on
    TBS'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The TBS users with access to images and builds should create these objects
    in their respective Kubernetes namespace to restrict access to these objects to
    the members of the same namespace. This way, we can combine the power of Kubernetes
    access control capabilities for greater control. You may find more details on
    how to configure these permissions here: [https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-tbs-with-projects.html#rbac-support-in-tanzu-build-service](https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-tbs-with-projects.html#rbac-support-in-tanzu-build-service).'
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading TBS to a newer version
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Upgrading TBS to a newer version is very simple. You just need to perform the
    same steps that we walked through for the installation process other than re-importing
    the dependencies if they’re not required.
  prefs: []
  type: TYPE_NORMAL
- en: Uninstalling TBS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To uninstall TBS from your Kubernetes cluster, just run the following `kapp`
    command; it will delete all TBS objects from your cluster other than the container
    images created by TBS. This command is very destructive and should be used with
    extreme caution:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: Customizing buildpacks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'TBS is built with a very modular, customizable, and extendable architecture.
    It allows us to perform various custom changes, such as including new buildpacks,
    changing buildpack order, adding new OS layers, and many more. You may learn more
    about such customizations using the following references:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Managing `ClusterStores`: [https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-managing-stores.html](https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-managing-stores.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Managing `ClusterStacks`: [https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-managing-stacks.html](https://docs.vmware.com/en/Tanzu-Build-Service/1.3/vmware-tanzu-build-service/GUID-managing-stacks.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Creating and managing buildpacks: [https://buildpacks.io/docs/buildpack-author-guide/](https://buildpacks.io/docs/buildpack-author-guide/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned about different problems around building secured
    container images for our applications and how TBS targets them with different
    capabilities. Later, we took a deep dive into the full anatomy of TBS to understand
    all its building blocks. After that, we walked through the installation process
    of TBS to get started with it. And finally, we saw how to perform various key
    operations on TBS. Using a solution such as TBS that is based on CNB is one of
    the most recommended approaches suggested by CNCF, and now, we can appreciate
    why that is the case.
  prefs: []
  type: TYPE_NORMAL
- en: In any Kubernetes environment, we deploy two different types of container images
    – either they belong to our application or a third-party software. Now that we’ve
    learned how to build secured container images for our applications using an out-of-box
    automation tool, in the next chapter, we will learn how to consume secured container
    images of popular open source software to provide backing services to our applications.
  prefs: []
  type: TYPE_NORMAL
