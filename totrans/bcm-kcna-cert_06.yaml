- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: Deploying and Scaling Applications with Kubernetes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Kubernetes部署和扩展应用程序
- en: In this chapter, we’ll continue exploring Kubernetes with its rich functionality
    and ecosystem. We’ll see which other Kubernetes resources exist and what their
    purpose is, how to implement the self-healing and scaling of applications with
    Kubernetes, how to use Kubernetes service discovery, and how to run stateful workloads
    with Kubernetes. We will also perform several exercises with the minikube Kubernetes
    we’ve installed in the previous chapter (in case you’ve skipped it – check the
    last section of [*Chapter 5*](B18970_05.xhtml#_idTextAnchor059)).
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们将继续探索Kubernetes丰富的功能和生态系统。我们将了解Kubernetes中还存在哪些资源及其目的，如何实现应用程序的自我修复和扩展，如何使用Kubernetes的服务发现，如何在Kubernetes中运行有状态的工作负载。我们还将使用上一章中安装的minikube
    Kubernetes进行若干练习（如果你跳过了这一部分，请查看[第*5章*](B18970_05.xhtml#_idTextAnchor059)的最后部分）。
- en: This is going to be one of the densest and most important chapters, so make
    sure to answer all the questions at the end and complete all practical assignments
    firsthand before moving further on. If you find it hard to understand some parts,
    read them twice and refer to the *Further* *reading* section.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 这是本书中最密集且最重要的一章之一，所以请确保在继续前进之前回答所有问题并完成所有实际操作任务。如果你觉得某些部分难以理解，可以读两遍并参考*进一步阅读*部分。
- en: 'We’re about to cover the following exciting topics:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 我们即将涵盖以下激动人心的话题：
- en: Deployments, ReplicaSets, and DaemonSets
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deployments、ReplicaSets和DaemonSets
- en: Running stateful workloads
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行有状态的工作负载
- en: Application configuration and service discovery
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 应用程序配置与服务发现
- en: Ensuring applications are alive and healthy
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保应用程序处于正常运行并健康状态
- en: So, let’s jump right into it!
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，直接进入正题吧！
- en: Deployments, ReplicaSets, and DaemonSets
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Deployments、ReplicaSets和DaemonSets
- en: As we saw in the previous chapter, there are more resources in Kubernetes than
    just *Pods* and *namespaces*. Let’s learn about *Deployments*, for starters.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一章中看到的，Kubernetes中有比*Pods*和*命名空间*更多的资源。首先让我们来了解一下*Deployments*。
- en: Deployment
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: Deployment
- en: It is a wrapper for declarative updates for Pods and ReplicaSets. After you
    describe the desired state in the Deployment resource spec, the Kubernetes Deployment
    controller changes the current state to the desired state at a configured rate.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个声明式更新Pod和ReplicaSet的封装器。你在Deployment资源规格中描述所需状态后，Kubernetes Deployment控制器会按照配置的速率将当前状态更改为所需状态。
- en: It sounds complicated, but essentially Deployment is for controlling Pods and
    managing the application life cycle of those Pods. Pods are the smallest deployment
    units that wrap around containers, but they don’t provide any advanced Kubernetes
    features, such as *self-healing*, *rolling updates,* or *autoscaling*. However,
    Deployments do.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 听起来有些复杂，但本质上Deployment是用来控制Pods并管理这些Pods的应用程序生命周期的。Pods是最小的部署单元，用来封装容器，但它们不提供任何高级Kubernetes功能，如*自我修复*、*滚动更新*或*自动扩展*。然而，Deployment是提供这些功能的。
- en: Because Pods are not resilient, an application container that fails in a pod
    *takes* the pod *down* with it. That is why in practice you’ll often use one of
    the advanced Kubernetes resources such as Deployment to automatically recreate
    Pods in case of failure. The deployment controller constantly watches the current
    state of the Pods it is managing and ensures that the desired number of Pods is
    running. We will shortly have a demonstration to see how this works.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 因为Pods本身没有弹性，一个失败的应用程序容器会将Pod*带*下去。这就是为什么在实际操作中，你通常会使用Kubernetes中的高级资源之一，如Deployment，来在失败时自动重新创建Pods。Deployment控制器不断监视它所管理的Pods的当前状态，并确保所需数量的Pods在运行。我们很快会展示如何实现这一点。
- en: ReplicaSet
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet
- en: A ReplicaSet is used to maintain the given number of replica Pods running at
    any given time. ReplicaSets are also used by Deployments to ensure the desired
    number of Pods (even if only one pod should be running at a time).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ReplicaSet用于确保在任何给定时间运行指定数量的副本Pod。ReplicaSet也被Deployment使用，以确保所需数量的Pod运行（即使只有一个Pod应当运行）。
- en: Compared to ReplicaSet, Deployment is a higher-level wrapper resource that manages
    ReplicaSets itself and provides other useful features. ReplicaSet does not allow
    you to implement custom update orchestration and therefore it is recommended that
    you use Deployments instead of directly using ReplicaSets.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 与ReplicaSet相比，Deployment是一个更高级的封装资源，它管理着ReplicaSet并提供其他有用的功能。ReplicaSet不允许你实现自定义更新编排，因此建议使用Deployment而不是直接使用ReplicaSet。
- en: 'Let’s get back to our minikube Kubernetes setup from the previous chapter for
    a quick demo. If you’ve stopped the cluster before, start it first with the `minikube`
    `start` command:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到上一章中使用的 minikube Kubernetes 设置，进行一个快速演示。如果你之前已经停止了集群，请先使用 `minikube` `start`
    命令启动它：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you are not sure about the state of your minikube Kubernetes, you can also
    use the `minikube status` command. Make sure that you have `host`, `kubelet`,
    and `apiserver` in a `Running` state:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你不确定 minikube Kubernetes 的状态，你也可以使用 `minikube status` 命令。确保 `host`、`kubelet`
    和 `apiserver` 处于 `Running` 状态：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Previously, we created a simple pod running the `Nginx` web server in the `kcna`
    Kubernetes namespace. Let’s create a Deployment of the same nginx web server,
    but with three replicas (three Pods):'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们在 `kcna` Kubernetes 命名空间中创建了一个运行 `Nginx` Web 服务器的简单 pod。现在，让我们创建一个相同的 nginx
    Web 服务器的 Deployment，但带有三个副本（即三个 Pods）：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The complete Deployment specification (found in `nginx-deployment.yaml` in
    the GitHub repository accompanying this book) looks like the following:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的 Deployment 规范（可以在本书随附的 GitHub 仓库中的 `nginx-deployment.yaml` 文件中找到）如下所示：
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'It is somewhat similar to the specification of the pod we used previously,
    but with a number of differences, such as the following:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 这在某种程度上类似于我们之前使用的 pod 规范，但有一些不同之处，例如以下几点：
- en: '`kind: Deployment`'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`kind: Deployment`'
- en: '`apps/v1` indicating the API version'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`apps/v1` 表示 API 版本'
- en: 'An additional `app: nginx` label in the metadata'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '在元数据中增加了一个 `app: nginx` 标签'
- en: 'The number of Pods is defined by `replicas: 3`'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Pods 的数量由 `replicas: 3` 定义。'
- en: There is a selector for matching Pods by the `app:` `nginx` label
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有一个用于通过 `app:` `nginx` 标签匹配 Pods 的选择器
- en: It labels templates with an `app:` `nginx` label
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它为模板添加了一个 `app:` `nginx` 标签
- en: The `selector:` under the `spec:` field defines how this Deployment finds the
    pods that it manages. In this example, it picks the Pods that have an `app:` `nginx`
    label.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '`spec:` 字段下的 `selector:` 定义了这个 Deployment 如何找到它管理的 Pods。在这个示例中，它选择了带有 `app:`
    `nginx` 标签的 Pods。'
- en: 'The `template` block has the same pod `containers:` specification with the
    `image:` and `ports:` fields like we used in the previous chapter for the standalone
    pod scenario. Additionally, it has metadata with an `app: nginx` label that will
    be added to each pod created by this specification. Once again, the label is needed
    for the Deployment to be able to find its Pods.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '`template` 块具有与我们在上一章中用于独立 pod 情境中的 `containers:` 规格相同的 `image:` 和 `ports:`
    字段。此外，它还包含带有 `app: nginx` 标签的元数据，该标签将添加到此规范创建的每个 pod 中。再次强调，标签对于 Deployment 找到其
    Pods 是必须的。'
- en: 'Let’s check what happened in the `kcna` namespace after we applied our Deployment
    specification:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下在应用了 Deployment 规范后，`kcna` 命名空间发生了什么：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'We can see the three `nginx` Pods, each with its own unique name. Those names
    will look slightly different for you because the second part of the string is
    randomized. Now let’s query ReplicaSets in the `kcna` namespace with the `kubectl
    get` `replicasets` command:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到三个 `nginx` Pods，每个都有一个独特的名称。这些名称对你来说可能略有不同，因为字符串的第二部分是随机生成的。现在，让我们用 `kubectl
    get` `replicasets` 命令查询 `kcna` 命名空间中的 ReplicaSets：
- en: '[PRE5]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: OK, we can see one ReplicaSet; however, we did not define it! It was the nginx
    Deployment that automatically created a ReplicaSet in order to keep the desired
    number of Pods. So, it is the Deployment that works on top of ReplicaSets; ReplicaSets
    that works on top of Pods; and Pods are wrappers on top of containers, as shown
    in *Figure 6**.1*. You can also see that ReplicaSet gets a unique ID, and the
    final Pods inherit this ID in their names.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 好的，我们看到一个 ReplicaSet；然而，我们并没有定义它！是 nginx Deployment 自动创建了一个 ReplicaSet，以保持所需的
    Pod 数量。所以，实际上是 Deployment 在 ReplicaSets 上工作；ReplicaSets 在 Pods 上工作；Pods 是在容器之上的包装层，如
    *图 6.1* 所示。你还可以看到 ReplicaSet 获得了一个唯一的 ID，最终的 Pods 会在其名称中继承这个 ID。
- en: '![Figure 6.1 – The hierarchy of Deployment, ReplicaSet, and Pod](img/B18970_06_01.jpg)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.1 – Deployment、ReplicaSet 和 Pod 的层次结构](img/B18970_06_01.jpg)'
- en: Figure 6.1 – The hierarchy of Deployment, ReplicaSet, and Pod
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1 – Deployment、ReplicaSet 和 Pod 的层次结构
- en: 'Let’s carry out a quick experiment, let’s delete one of the three `nginx` pods
    created by our Deployment and see what happens (*you’ll have to specify the name
    of one pod that you have as pod names* *are unique*):'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们做一个快速实验，删除我们 Deployment 创建的三个 `nginx` Pods 中的一个，看看会发生什么（*你需要指定一个 Pod 的名称，因为
    Pod 名称* *是唯一的*）：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Now, even if you are really fast at typing, you probably won’t notice how the
    deleted pod terminated and a new one was created. Next, get the list of Pods in
    the `kcna` namespace:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，即使你打字非常快，你也可能不会注意到已删除的 Pod 已经终止并且一个新的 Pod 被创建了。接下来，获取 `kcna` 命名空间中 Pods 的列表：
- en: '[PRE7]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: And there we go – we have a new pod with an `AGE` of `3` seconds with a status
    of `Running`, and the old, deleted pod (`nginx-deployment-9456bbbf9-cl95h`) is
    completely gone. Now that’s the *Kubernetes self-healing magic* we’ve talked about
    so much! In just a couple of seconds, Kubernetes detected that the current state
    of the Nginx deployment was different because only two replicas (Pods) were running
    when the desired state is three replicas. The Kubernetes *reconciliation loop*
    kicked in and spawned a new, third replica of the `nginx` pod.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们有一个新的 Pod，其 `AGE` 为 `3` 秒，状态为 `Running`，而旧的已删除的 Pod（`nginx-deployment-9456bbbf9-cl95h`）已经完全消失。这就是我们一直谈论的*Kubernetes
    自愈魔法*！仅仅几秒钟内，Kubernetes 就检测到 Nginx 部署的当前状态发生了变化，因为只有两个副本（Pods）在运行，而期望的状态是三个副本。Kubernetes
    的*协调循环*启动了，并创建了第三个 `nginx` Pod 副本。
- en: '*Self-healing* is great and helps to keep our applications running in situations
    such as node hardware failure (of course, assuming that you run multiple Kubernetes
    nodes **as you should do in production**); when an application has a bug and crashes
    on a certain request type; and in the case of planned or unplanned maintenance
    when we have to migrate the payloads to another node.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '*自愈*是非常棒的，它帮助我们保持应用在某些情况下正常运行，例如节点硬件故障（当然，前提是你在生产环境中运行多个 Kubernetes 节点）；当应用在某些请求类型下崩溃时；以及在计划内或计划外的维护期间，当我们需要将负载迁移到另一个节点时。'
- en: 'But that’s only the beginning. Let’s imagine for a second that we are anticipating
    a high number of requests for an application we run on Kubernetes, so we have
    to get ready and add additional replicas in our application. With Kubernetes,
    it is as easy as executing a single `kubectl scale` `deployment` command:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 但这仅仅是开始。让我们假设我们预计应用会收到大量请求，因此我们需要提前做好准备，并在应用中增加额外的副本。在 Kubernetes 中，只需执行一个 `kubectl
    scale` `deployment` 命令就可以做到这一点：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you check the state of the respective ReplicaSet fast enough, you might
    see that new Pods are spawning:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你足够快地检查相关的 ReplicaSet 状态，你可能会看到新 Pods 正在生成：
- en: '[PRE9]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'And voilà! Just a moment later, both new Pods are already up and running:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！不久之后，两个新 Pods 就已经启动并运行：
- en: '[PRE10]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Note
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Obviously, adding more application replicas on a single node K8s cluster does
    not bring a lot of practicality for performance or service availability. In production,
    you should always run multi-node Kubernetes clusters and spread the replicas of
    your applications across multiple nodes. We are doing these exercises on a single
    node Kubernetes instance, only for demonstration and educational purposes.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，在单节点 K8s 集群中添加更多的应用副本并不会对性能或服务可用性带来太多实用性。在生产环境中，你应该始终运行多节点的 Kubernetes 集群，并将应用的副本分布在多个节点上。我们在这里进行这些练习是基于单节点
    Kubernetes 实例，仅用于演示和教学目的。
- en: Next, let’s see how we can perform *rolling updates* with Deployments. Rolling
    updates play an important role because they help to ensure rapid software development
    cycles with frequent releases and allow us to make updates with *zero downtime*
    for customers.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们看看如何使用 Deployments 执行*滚动更新*。滚动更新非常重要，因为它有助于确保快速的软件开发周期和频繁的发布，并且使我们能够在没有*零停机时间*的情况下进行更新，避免对客户造成影响。
- en: Zero downtime
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 零停机时间
- en: Zero downtime is a deployment method where the updated application is able to
    serve requests as usual, with no interruptions or errors.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 零停机时间是一种部署方法，在这种方法下，更新后的应用能够正常处理请求，不会中断或出错。
- en: 'With rolling updates, we can do the following:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 通过滚动更新，我们可以执行以下操作：
- en: Promote application changes from one environment to another (for example, a
    new image version, configuration, or labels)
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将应用变更从一个环境推广到另一个环境（例如，新的镜像版本、配置或标签）
- en: Rollback to the previous version in case of any issues
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在出现任何问题时回滚到先前的版本
- en: Define how many application replicas can be replaced at a time
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 定义每次可以替换多少个应用副本
- en: 'Let’s see this in action with our Nginx deployment. We will update the `nginx`
    container image version tag to `1.20` using `kubectl`. First, check that our deployment
    is intact:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过 Nginx 部署来看看这一切是如何运作的。我们将使用 `kubectl` 更新 `nginx` 容器镜像版本标签为 `1.20`。首先，检查我们的部署是否完好：
- en: '[PRE11]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Now, change the image to `nginx:1.20`:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，修改镜像为 `nginx:1.20`：
- en: '[PRE12]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Then observe what is happening to the Nginx Pods right after you have changed
    the image (*you have to be quick to witness* *the process!*):'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 然后观察更改镜像后 Nginx Pods 的状态变化（*你必须快速观察* *这个过程！*）：
- en: '[PRE13]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'From five replicas of our Nginx deployment, we see that one has a `Terminating`
    status, four have a `Running` status, and three new have appeared and are in the
    `ContainerCreating` status. Just a moment later, we may see that the last few
    Pods with an old Nginx image are have a `Terminating` status, four new ones are
    in the `Running` state and one more is in the `ContainerCreating` state:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们五个 Nginx 部署的副本中，我们看到其中一个处于`Terminating`状态，四个处于`Running`状态，另外三个新副本处于`ContainerCreating`状态。稍过片刻，我们可能会看到最后几个使用旧
    Nginx 镜像的 Pods 进入`Terminating`状态，四个新副本进入`Running`状态，还有一个进入`ContainerCreating`状态：
- en: '[PRE14]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'It won’t take long before all old Pods are gone and the last new ones enter
    a `Running` state. We can also verify that the new image is used, by performing
    `kubectl describe pod` on any new pod (on Windows, use `findstr` instead of `grep`
    command):'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 不久之后，所有旧的 Pods 都会消失，最后一个新的 Pod 会进入`Running`状态。我们还可以通过对任何新 Pod 执行`kubectl describe
    pod`命令来验证是否使用了新镜像（在 Windows 上使用`findstr`代替`grep`命令）：
- en: '[PRE15]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Now, what do we do if a new image of the deployed application is not the right
    one or if it has a bug that may cause Pods to crash? Just as easy as updating
    a Kubernetes Deployment, we can roll back to the previous revision of our Deployment.
    Each change will be tracked by Kubernetes and gets its own revision version that
    we can see with the `kubectl rollout` `history` command:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，如果部署的应用的新镜像不正确，或者它有可能导致 Pods 崩溃的 bug，该怎么办呢？就像更新 Kubernetes 部署一样，我们可以回滚到之前的部署版本。Kubernetes
    会追踪每个更改，并为每个版本分配一个修订版本，我们可以使用`kubectl rollout history`命令查看：
- en: '[PRE16]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Note
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: '`CHANGE-CAUSE` is an optional description that can be set by adding an annotation
    to the Deployment. For example, we can do the following: `kubectl -n kcna annotate
    deployment/nginx-deployment kubernetes.io/change-cause="image updated` `to 1.20"`.'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '`CHANGE-CAUSE` 是一个可选描述，可以通过向部署添加注释来设置。例如，我们可以执行以下命令：`kubectl -n kcna annotate
    deployment/nginx-deployment kubernetes.io/change-cause="image updated to 1.20"`。'
- en: 'If we realized that we need to get our deployment back to a previous revision,
    we can simply call `kubectl rollout undo` and optionally specify the exact, possibly
    older deployment revision. Let’s try to roll back to the previous, first revision
    of the `nginx` deployment (current revision is `2`):'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们意识到需要将部署回滚到以前的修订版本，只需调用`kubectl rollout undo`，并可以选择指定确切的、可能是较旧的部署修订版本。我们可以尝试回滚到`nginx`部署的前一个修订版本（当前修订版本为`2`）：
- en: '[PRE17]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'A moment later, all Pods are recreated in the same rolling update fashion.
    And we can verify that the image version tag is back to `1.14.2` using the `kubectl
    get` `pods` command with an extra `-o yaml` option that will show us complete,
    detailed information about the pod (*the naming will be different in your case,
    pick any pod from your* *output list*):'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 片刻之后，所有 Pods 都会按照滚动更新的方式重新创建。我们可以使用`kubectl get pods`命令，并加上额外的`-o yaml`选项来验证镜像版本标签是否已回到`1.14.2`（*命名可能与你的情况不同，从你的*
    *输出列表中选择任何一个 pod*）：
- en: '[PRE18]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'You’ll see a long, long output with all the details about this particular pod.
    You can also use `kubectl get` in combination with `-o yaml` for any other Kubernetes
    resources (*namespaces*, *Deployments*, and others we’re about to learn) to get
    full information about the object. You don’t need to understand each and every
    line of the output at this stage, but it is very helpful to know about `imagePullPolicy`,
    which defines the rules for how container images should be pulled from the registry.
    The policy can be one of the following:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 你会看到非常长的输出，包含该 Pod 的所有详细信息。你也可以结合`kubectl get`和`-o yaml`选项查询其他 Kubernetes 资源（如*namespaces*、*Deployments*等，我们即将学习的）以获取关于该对象的完整信息。在此阶段，你不需要理解输出的每一行，但了解`imagePullPolicy`非常有用，它定义了如何从注册表中拉取容器镜像的规则。该策略可以是以下之一：
- en: '`IfNotPresent` – this is the default setting. The image will be downloaded
    only if the requested `name:tag` combination is not already present locally (cached)
    on the node where the pod was scheduled.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`IfNotPresent` – 这是默认设置。当请求的`name:tag`组合在 Pod 被调度到的节点上尚未存在（缓存）时，镜像才会被下载。'
- en: '`Always` – this means that every time a pod with the respective container is
    started, the image registry will be asked for an image digest (resolved from the
    image tag). If an image with this *exact digest* is already cached locally on
    the node, it will be used; otherwise, a Kubernetes kubelet will pull the image
    with the digest resolved by the registry on the target node.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Always` - 这意味着每次启动包含相应容器的Pod时，镜像注册中心会请求一个镜像摘要（从镜像标签解析得到）。如果该镜像的*确切摘要*已经在节点本地缓存，它将被使用；否则，Kubernetes的kubelet将从目标节点的注册中心拉取该镜像。'
- en: '`Never` – this means the kubelet won’t attempt to fetch the image from the
    registry. The image should be delivered to the node somehow in advance; otherwise,
    the container will fail to spawn.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Never` - 这意味着kubelet不会尝试从注册中心拉取镜像。镜像应该提前以某种方式传送到节点，否则容器将无法启动。'
- en: 'Additionally, we can control the rolling update process with a number of optional
    settings and timeouts. The two most important ones are as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们可以通过一些可选的设置和超时来控制滚动更新过程。最重要的两个设置如下：
- en: '`maxUnavailable` – this defines the maximum number of unavailable pods during
    a rolling update. It can be specified as a percentage (for example, `25%`) or
    as an absolute number (for example, `3`).'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxUnavailable` - 这定义了滚动更新过程中不可用的最大Pod数。可以用百分比（例如，`25%`）或绝对数字（例如，`3`）来指定。'
- en: '`maxSurge` – this defines the maximum number of pods that can be created over
    the desired number of replicas. It can also be specified as a percentage or an
    absolute number. If set, for example to `25%`, then the total number of *old*
    and *new* Pods won’t exceed `125%` of the desired number of replicas.'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`maxSurge` - 这定义了可以创建的Pods数量，超过了所需副本数。它也可以以百分比或绝对数值指定。例如，如果设置为`25%`，那么*旧*和*新*
    Pods的总数将不超过所需副本数的`125%`。'
- en: Finally, if we don’t want to do rolling updates, we can instead choose the `Recreate`
    strategy, which means all existing Pods are killed at once and new ones are only
    created after all old Pods have been terminated. Obviously, this strategy doesn’t
    allow you to perform zero-downtime updates, as all Pods of an application will
    be down for at least a few seconds. The strategy can be configured by defining
    the `.spec.strategy.type` setting in the YAML spec file of the respective deployment.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，如果我们不想进行滚动更新，我们可以选择`Recreate`策略，这意味着所有现有的Pods会一次性被销毁，只有在所有旧Pods被终止之后，新的Pods才会被创建。显然，这种策略无法实现零停机更新，因为应用的所有Pods至少会停机几秒钟。可以通过在相应部署的YAML规格文件中定义`.spec.strategy.type`设置来配置该策略。
- en: Now that we know about deployments, let’s move on to `sshd,` a service that
    allows us to log in to remote systems over the **Secure** **Shell** protocol.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们了解了部署的相关内容，接下来让我们讲解一下`sshd`，它是一个允许我们通过**安全****外壳**协议远程登录系统的服务。
- en: DaemonSet
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: DaemonSet
- en: DaemonSet is a wrapper for pods that ensures that all or certain nodes in the
    Kubernetes cluster each run a single replica of the target pod. If more nodes
    are added to the cluster, DaemonSet will ensure that a pod is automatically spawned
    on a new node as soon as it joins the cluster.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: DaemonSet是一个Pods的封装器，它确保Kubernetes集群中的所有或某些节点每个运行目标Pod的单个副本。如果集群中增加了更多节点，DaemonSet会确保在新节点加入集群后，自动在该节点上生成一个Pod。
- en: 'Where Deployment is considered a universal resource in Kubernetes for all kinds
    of user workloads, DaemonSet’s typical use cases are as follows:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes中，Deployment被认为是适用于各种用户工作负载的通用资源，而DaemonSet的典型用例如下：
- en: To run a log collection service on every Kubernetes node (for example, software
    such as **Fluent Bit**)
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每个Kubernetes节点上运行日志收集服务（例如，**Fluent Bit**等软件）
- en: To run a node-monitoring daemon on every node (for example, a node exporter
    for **Prometheus**)
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每个节点上运行节点监控守护进程（例如，**Prometheus**的节点出口程序）
- en: To run a cluster storage daemon on every node
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在每个节点上运行集群存储守护进程
- en: 'Similar to ReplicaSet, DaemonSet will ensure that the desired state is met,
    meaning that in the case of a pod failure, it will automatically spawn a new one.
    By default, DaemonSet will create Pods on all worker nodes in the cluster, but
    it is also possible to select specific nodes in the cluster or control plane nodes
    (how to do this will be covered in the next chapter, [*Chapter 7*](B18970_07.xhtml#_idTextAnchor077)).
    What cannot be done with DaemonSet is setting the number of replicas per node,
    because DaemonSet will always run only one pod per node. The spec file of DaemonSet
    is very similar to that of a Deployment, with a few differences, such as `kind:
    DaemonSet` or a lack of the `replicas:` setting.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '类似于 ReplicaSet，DaemonSet 会确保达到期望的状态，这意味着在 Pod 发生故障的情况下，它会自动重新创建一个新的 Pod。默认情况下，DaemonSet
    会在集群中的所有工作节点上创建 Pod，但也可以选择集群中的特定节点或控制平面节点（如何做将在下一章的[*第 7 章*](B18970_07.xhtml#_idTextAnchor077)中讨论）。DaemonSet
    无法做的是设置每个节点的副本数量，因为 DaemonSet 每个节点只会运行一个 Pod。DaemonSet 的 spec 文件与 Deployment 的
    spec 文件非常相似，只有一些差异，例如 `kind: DaemonSet` 或缺少 `replicas:` 设置。'
- en: Moving on, we will not create a DaemonSet now, because a proper demonstration
    requires a multi-node Kubernetes cluster. Feel free to check out the *Further
    reading* section at the end of the chapter and try it out yourself if you’d like.
    In the following section, we’ll see how to run applications that need to persist
    information on the disk with Kubernetes.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们不会现在创建一个 DaemonSet，因为一个合适的演示需要一个多节点的 Kubernetes 集群。如果你有兴趣，可以查看章节末尾的*进一步阅读*部分，自己动手尝试一下。在接下来的部分，我们将展示如何使用
    Kubernetes 运行需要在磁盘上持久化信息的应用程序。
- en: Running stateful workloads
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 运行有状态的工作负载
- en: Everything we’ve tried so far with Kubernetes has not answered one important
    question – what do we do if we need to persist the application state between pod
    restarts? Data written on a container filesystem is not persisted by default.
    If you just take a deployment spec from the recent examples with Nginx and replace
    the image with **PostgreSQL**, that won’t be enough. Technically, your pod with
    PostgreSQL will come up, and the database will run, but any data written to that
    database instance won’t survive a pod restart. But, of course, Kubernetes has
    something to offer for stateful applications too.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们在 Kubernetes 中尝试的所有操作并没有回答一个重要问题——如果我们需要在 Pod 重启之间保持应用程序的状态该怎么办？默认情况下，写入容器文件系统中的数据是不会持久化的。如果你只是将最近
    Nginx 示例中的部署 spec 拷贝过来，并将镜像替换为 **PostgreSQL**，这还不够。技术上讲，你的 PostgreSQL Pod 会启动，数据库会运行，但写入该数据库实例的任何数据都不会在
    Pod 重启后保留。不过，当然，Kubernetes 也为有状态的应用程序提供了解决方案。
- en: 'As you hopefully remember from [*Chapter 4*](B18970_04.xhtml#_idTextAnchor048),
    *Exploring Container Runtimes, Interfaces, and Service Meshes*, Kubernetes has
    a **Container Storage Interface** or **CSI** that allows you to integrate various
    storage solutions into a K8s cluster. In order to augment Pods with external storage,
    we need *volumes* that can be dynamically provisioned via the Kubernetes API.
    Let’s begin with two new resource definitions:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如你可能还记得，来自[*第 4 章*](B18970_04.xhtml#_idTextAnchor048)的内容，《探索容器运行时、接口和服务网格》一章中，Kubernetes
    提供了一个 **容器存储接口**（**CSI**），它允许你将各种存储解决方案集成到 K8s 集群中。为了通过 Kubernetes API 为 Pods
    增加外部存储，我们需要可以动态分配的 *卷*。让我们从两个新的资源定义开始：
- en: '**PersistentVolume** (**PV**): This is a piece of storage in the cluster that
    can be provisioned either dynamically (by K8s when requested) or statically (for
    example, provisioned in some way by the cluster administrator and exposed for
    use in K8s).'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持久卷** (**PV**)：这是集群中的一块存储，可以通过动态（由 K8s 在请求时自动分配）或静态（例如，由集群管理员以某种方式预配置并在 K8s
    中暴露）方式进行配置。'
- en: '**PersistentVolumeClaim** (**PVC**): This is a request for storage by the user
    that consumes *PVs*.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持久卷声明** (**PVC**)：这是用户对存储的请求，消耗 *PVs*。'
- en: 'When we want to use persistent storage for our containerized application, we
    need to define a PVC spec in YAML format that can look like the following:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们希望为容器化的应用程序使用持久存储时，我们需要定义一个 PVC 的 spec，格式为 YAML，类似以下内容：
- en: '[PRE19]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'This PVC can then be referenced in deployments and Pods as a volume. Claim
    allows you to request a specific size (`3Gi` in the previous example) and one
    of the following four `accessModes`:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，可以在部署和 Pod 中将此 PVC 作为一个卷进行引用。声明允许你请求特定的大小（如前面例子中的 `3Gi`）和以下四种 `accessModes`
    中的一种：
- en: '`ReadWriteOnce` – this allows the volume to be mounted as a read-write by a
    single node. This mode can allow multiple Pods on this node to access the volume.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReadWriteOnce` – 这允许卷被单个节点以读写模式挂载。此模式可以允许此节点上的多个Pod访问该卷。'
- en: '`ReadOnlyMany` – this allows the volume to be mounted as read-only by one or
    multiple nodes.'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReadOnlyMany` – 这允许卷被一个或多个节点以只读方式挂载。'
- en: '`ReadWriteMany` – this allows the volume to be mounted as read-write by many
    nodes. This should be supported by the storage solution and protocol (for example,
    **NFS**).'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReadWriteMany` – 这允许卷被多个节点以读写模式挂载。这应由存储解决方案和协议（例如，**NFS**）支持。'
- en: '`ReadWriteOncePod` – This is the same as `ReadWriteOnce`, but with a hard limit
    of only one pod in the whole cluster being able to write to this volume.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ReadWriteOncePod` – 这与`ReadWriteOnce`相同，但有一个严格的限制：整个集群中只有一个Pod能够写入该卷。'
- en: 'Since PVs are the actual storage resources in the Kubernetes cluster, we might
    have a situation when there is no suitable PV for the PVC request. In that case,
    Kubernetes can dynamically provision a PV based on the storage class specified
    in the PVC spec (`storageClassName: standard` in the previous example).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '由于PVs是Kubernetes集群中的实际存储资源，我们可能会遇到没有适合的PV来满足PVC请求的情况。在这种情况下，Kubernetes可以根据PVC规范中指定的存储类动态地提供PV（在前面的示例中是`storageClassName:
    standard`）。'
- en: Storage classes
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 存储类
- en: Storage classes provide a way to classify different storage options available
    in the cluster. Those might differ by performance, supported access modes and
    protocols, backup policies, and more.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 存储类提供了一种分类集群中不同存储选项的方法。这些存储类可能在性能、支持的访问模式和协议、备份策略等方面有所不同。
- en: 'It is also possible to instruct Kubernetes to only use already provisioned
    (possibly statically) and available PVs by setting `storageClassName: ""` (empty
    string) in the PVC spec. In the case of dynamic PV provisioning, the volume will
    always be of the exact size requested in the PVC spec. However, where we ask to
    only use already available PVs, we might get a larger volume than specified in
    PVC resource requests (for example, `3Gi` is requested, but if the closest available
    PV in the cluster is `5Gi`, it will be taken and all `5Gi` will be usable by the
    container that mounts it).'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '还可以通过在PVC规范中设置`storageClassName: ""`（空字符串），指示Kubernetes仅使用已经提供（可能是静态提供）的可用PV。在动态PV提供的情况下，卷的大小将始终与PVC规范中请求的大小一致。然而，如果我们要求仅使用已存在的PV，我们可能会得到一个比PVC资源请求中指定的更大的卷（例如，虽然请求了`3Gi`，但如果集群中最接近的可用PV是`5Gi`，则会使用该`5Gi`卷，并且该容器可以使用全部`5Gi`）。'
- en: 'Let’s get back to the minikube setup to see this in action. First, create `kcna-pv-claim`
    with the previous specification (the file can be downloaded from the book’s GitHub
    repository):'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到minikube设置，看看这个如何发挥作用。首先，使用先前的规范创建`kcna-pv-claim`（文件可以从本书的GitHub仓库下载）：
- en: '[PRE20]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, get the list of PVs in the cluster (the name will be unique in this case):'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，获取集群中所有PV的列表（在这种情况下，名称将是唯一的）：
- en: '[PRE21]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'A PV was automatically provisioned by Kubernetes in seconds! At this point,
    we can start using `kcna-pv-claim` as a volume in our deployment or pod specifications.
    Let’s delete the old `nginx-deployment` that we created at the beginning of this
    chapter:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: PV已被Kubernetes自动分配，速度非常快！此时，我们可以开始在我们的部署或Pod规范中使用`kcna-pv-claim`作为卷。让我们删除在本章开头创建的旧`nginx-deployment`：
- en: '[PRE22]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'And create another one, with our new volume attached. For that, we’ll need
    to make a few changes to the old `nginx-deployment.yaml` spec file (the modified
    version is available on GitHub):'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 并创建另一个新PV，并附加我们的新卷。为此，我们需要对原来的`nginx-deployment.yaml`规范文件进行一些更改（修改后的版本可以在GitHub上找到）：
- en: '[PRE23]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Besides a new name for the deployment (`nginx-deployment-with-volume`) and
    the number of replicas being set to `1`, the changes are as follows:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 除了为部署指定一个新名称（`nginx-deployment-with-volume`）并将副本数设置为`1`外，其他更改如下：
- en: We have added a `volumeMounts:` block under the respective `nginx` container
    stating which volume (`kcna-volume`) should be mounted at which path (`"/usr/share/nginx/html"`
    – this is a location for static HTML content).
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们在相应的`nginx`容器下添加了`volumeMounts:`块，说明哪个卷（`kcna-volume`）应挂载到哪个路径（`"/usr/share/nginx/html"`
    – 这是用于静态HTML内容的位置）。
- en: Additionally, we have defined the `volumes:` block that maps `kcna-volume` to
    our PVC named `kcna-pv-claim` that we created in the previous step.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 此外，我们还定义了`volumes:`块，将`kcna-volume`映射到我们在前一步创建的名为`kcna-pv-claim`的PVC。
- en: Note
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The `volumeMounts` is located within the individual container section because
    different containers in one pod can mount different (or the same) volumes. The
    `volumes` block is located at the same level as `containers`, and it should list
    all volumes that will be used within the Pods.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '`volumeMounts` 位于每个容器的部分，因为同一个 Pod 中的不同容器可以挂载不同的（或相同的）卷。`volumes` 块与 `containers`
    在同一层级，它应该列出所有将在 Pod 中使用的卷。'
- en: 'Now, let’s create a modified nginx deployment and see what happens:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个修改过的 nginx 部署，看看会发生什么：
- en: '[PRE24]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'At this stage, nothing looks different, but we can use the `kubectl exec -it`
    command to get inside our container by starting a new shell process. You might
    remember that we did something similar in [*Chapter 3*](B18970_03.xhtml#_idTextAnchor038),
    when we used `docker run -it`. You’ll need to specify the name of your unique
    pod here:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 目前看起来一切都没有变化，但我们可以使用 `kubectl exec -it` 命令，通过启动一个新的 shell 进程进入容器。你可能记得我们在[*第三章*](B18970_03.xhtml#_idTextAnchor038)中做过类似的事情，当时我们使用了
    `docker run -it`。你需要在这里指定你唯一的 Pod 名称：
- en: '[PRE25]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Let’s see whether there is a volume mount at `/usr/share/nginx/html` as we’ve
    requested:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们检查一下我们要求的 `/usr/share/nginx/html` 路径下是否有挂载卷：
- en: '[PRE26]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'There it is! Our dynamically provisioned PV was automatically mounted to the
    node where our pod runs. If the pod dies, the data on the volume is preserved,
    and if the new pod starts on another node, Kubernetes will take care of unmounting
    and remounting the volume to the right node reaching the desired state we described
    in the spec file. To make sure that the data really is persisted, we can do a
    small exercise inside the container. Let’s install the `curl` utility and try
    to run it against `localhost`:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！我们动态分配的 PV 被自动挂载到我们的 Pod 所在的节点上。如果 Pod 死亡，卷上的数据将被保留，如果新的 Pod 在另一个节点上启动，Kubernetes
    会处理卷的卸载和重新挂载到正确的节点，达到我们在规格文件中描述的期望状态。为了确保数据确实被持久化，我们可以在容器内做个小练习。让我们安装 `curl` 工具并尝试对
    `localhost` 进行测试：
- en: '[PRE27]'
  id: totrans-135
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'Next, let’s create a simple one-liner `index.html` file in the `/usr/share/nginx/html`
    path and try running `curl` again:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们在 `/usr/share/nginx/html` 路径下创建一个简单的一行 `index.html` 文件，再次尝试运行 `curl`：
- en: '[PRE28]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The last part of this exercise is on you. Log out of the container (by either
    entering the `exit` command or by pressing *Ctrl* + *D*) and delete the pod with
    the `kubectl delete pods` command and log in to the new pod when it is spawned.
    Check whether the `index.html` file that we created is still present at the mount
    point and has the correct `Kubernetes Rocks!` string inside.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 本练习的最后一步由你来完成。退出容器（可以通过输入 `exit` 命令或按 *Ctrl* + *D*）并使用 `kubectl delete pods`
    命令删除 Pod，待新 Pod 启动后再登录进去。检查我们创建的 `index.html` 文件是否仍然存在于挂载点，并且文件中是否包含正确的 `Kubernetes
    Rocks!` 字符串。
- en: While it is normal practice to use PVs with Kubernetes deployments, another
    workload resource was specifically made to manage stateful applications.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在 Kubernetes 部署中使用 PV 是常规做法，但另一个工作负载资源专门用于管理有状态的应用。
- en: StatefulSet
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: StatefulSet
- en: '`StatefulSet` is a resource to manage the deployment and scaling of Pods that
    guarantees the ordering and uniqueness of these Pods.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '`StatefulSet` 是一个用于管理 Pod 部署和扩展的资源，保证这些 Pod 的顺序性和唯一性。'
- en: 'What that means is that Pods created by StatefulSets have stable naming (without
    randomly generated UUIDs) and allow ordered, graceful deployment as well as ordered
    rolling updates. In addition to that, StatefulSets can provision a PV per pod
    replica. That means you won’t need to define and apply a new PVC every time you
    want to scale your application by adding a new replica. Let’s have a quick look
    at a StatefulSet example spec:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，由 StatefulSet 创建的 Pods 具有稳定的命名（没有随机生成的 UUID），并且允许按顺序、优雅地部署，以及按顺序滚动更新。除此之外，StatefulSet
    还可以为每个 Pod 副本分配一个 PV。这意味着每当你想通过添加新副本来扩展应用时，不需要为每个副本定义并应用新的 PVC。让我们快速看一下 StatefulSet
    的一个示例规格：
- en: '[PRE29]'
  id: totrans-143
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: As you can see, the PVC spec is essentially a part of the StatefulSet spec located
    under the `volumeClaimTemplates` block at the end. Feel free to apply this StatefulSet
    spec yourself and see what happens. You should get three new PVCs and three new
    Pods spawned with PVs automatically provisioned and attached.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，PVC 规格本质上是位于 `volumeClaimTemplates` 块下的 StatefulSet 规格的一部分。你可以自由地应用这个 StatefulSet
    规格并观察发生了什么。你应该会看到三个新的 PVC 和三个新的 Pod 自动创建，并且 PV 会被自动分配并附加。
- en: While this might seem complicated at first, think about how many *manual* steps
    you’d have to do to achieve the same result *without* Kubernetes. How much time
    would it take to create multiple volumes, download container images, and configure
    and start containers? Kubernetes makes many operational tasks trivial, and in
    the upcoming section, we will learn more about how Kubernetes allows you to configure
    applications running in containers and how service discovery works.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这看起来一开始可能比较复杂，但想想看，如果*没有* Kubernetes，你需要做多少*手动*步骤才能达到相同的结果。你需要花多长时间来创建多个卷、下载容器镜像、配置并启动容器？Kubernetes
    使得许多操作任务变得非常简单，在接下来的部分中，我们将进一步了解 Kubernetes 如何让你配置运行在容器中的应用，以及服务发现如何工作。
- en: Application configuration and service discovery
  id: totrans-146
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 应用配置与服务发现
- en: So far, we have explored quite a few of K8s features and resources, but how
    do we do application configuration? We could add configuration files or environment
    variables to the container images during the build, but *this is wrong*. If you
    do so, for even the smallest configuration change, you’ll have to rebuild container
    images. Also, where you need to have different settings for different environments,
    you’ll need to maintain multiple images of the same application. Things get messy,
    complicated, and error-prone, so don’t do this.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经探索了 Kubernetes 的许多功能和资源，但如何进行应用配置呢？我们可以在构建过程中将配置文件或环境变量添加到容器镜像中，但*这是错误的*。如果这样做，即使是最小的配置更改，你也必须重新构建容器镜像。而且，当需要为不同环境设置不同配置时，你还需要维护多个相同应用的镜像。这样会导致混乱、复杂和容易出错，因此不要这样做。
- en: Instead, the better approach in Kubernetes is to use **ConfigMaps** and **Secrets**.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，更好的做法是使用**ConfigMaps**和**Secrets**。
- en: ConfigMap
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: ConfigMap
- en: A ConfigMap is a resource to store non-confidential data and configuration settings
    in key-value pairs that can be consumed inside Pods as environment variables,
    command-line arguments, or configuration files. ConfigMaps do not provide secrecy
    or encryption, so they are not suitable for keeping confidential information,
    such as passwords or access tokens.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: ConfigMap 是一个用于存储非机密数据和配置设置的资源，以键值对的形式，可以在 Pods 内部作为环境变量、命令行参数或配置文件使用。ConfigMap
    不提供保密性或加密功能，因此不适合用于存储机密信息，例如密码或访问令牌。
- en: Secret
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Secret
- en: A Secret is a resource to store sensitive data such as passwords, tokens, and
    access keys. Similar to ConfigMaps, Secrets can be consumed inside Pods as environment
    variables or configuration files.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: Secret 是一个用于存储敏感数据的资源，如密码、令牌和访问密钥。与 ConfigMap 类似，Secret 也可以作为环境变量或配置文件在 Pods
    内部使用。
- en: Both ConfigMaps and Secrets allow us to decouple configuration from container
    images, enabling better application portability and reuse of the same container
    images for different environments.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: ConfigMap 和 Secrets 都允许我们将配置与容器镜像解耦，从而实现更好的应用可移植性，并使同一个容器镜像可以在不同环境中重用。
- en: Let’s explore a quick example. Imagine you are developing a web application
    that requires access to the database. The application is written in a way that
    it looks for the `DATABASE_HOST`, `DATABASE_USERNAME`, and `DATABASE_PASSWORD`
    environment variables. In this case, you can use a ConfigMap to set `DATABASE_HOST`
    and a Secret to keep information about the username and the password. This configuration
    would be consumed in the container with the application and would allow us to
    use different settings for different environments (for example, different databases
    and passwords for development, testing, and production).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个简单的例子来探索。假设你正在开发一个需要访问数据库的 web 应用。该应用的设计是查找 `DATABASE_HOST`、`DATABASE_USERNAME`
    和 `DATABASE_PASSWORD` 环境变量。在这种情况下，你可以使用 ConfigMap 来设置 `DATABASE_HOST`，并使用 Secret
    来保存用户名和密码的信息。这些配置会在容器内与应用一起使用，并允许我们在不同环境中使用不同的设置（例如，在开发、测试和生产环境中使用不同的数据库和密码）。
- en: Besides mapping ConfigMaps and Secrets to environment variables inside containers,
    we can also mount them inside as if they were regular files. This is done with
    the *volume* concept that we have just covered in the preceding section when learning
    about PVs and PVCs.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 除了将 ConfigMap 和 Secrets 映射到容器内的环境变量外，我们还可以像挂载常规文件一样将它们挂载到容器内。这是通过我们在前一节学习 PV
    和 PVC 时提到的*卷*概念来实现的。
- en: 'Let’s get back to the keyboard and create a simple Secret using the `kubectl
    create` `secret` command:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们回到键盘，使用 `kubectl create` `secret` 命令来创建一个简单的 Secret：
- en: '[PRE30]'
  id: totrans-157
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: Note
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Needless to say, it is also possible to create Secrets by defining a YAML spec
    file with `kind: Secret` and calling `kubectl create -f` like we previously did
    for other resources.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '不用说，也可以通过定义一个带有`kind: Secret`的 YAML 规范文件，并像我们之前对待其他资源一样，使用`kubectl create -f`来创建
    Secrets。'
- en: 'Next, find the `nginx-statefulset` spec file that we used in the last section
    and modify it to mount our new `kcna-secret` as an additional volume at `/etc/nginx/kcna.secret`.
    Try to do this on your own, but if you experience any difficulties, the following
    are the relevant changes to the spec file (a complete modified spec file is also
    available on GitHub):'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，找到我们在上一节中使用的`nginx-statefulset`规范文件，并将其修改为将新创建的`kcna-secret`作为额外的卷挂载到`/etc/nginx/kcna.secret`。请尝试自行完成，但如果遇到任何困难，以下是规范文件中相关的修改（完整的修改版规范文件也可以在
    GitHub 上找到）：
- en: '[PRE31]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Note
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: It is possible to modify resources already created in Kubernetes instead of
    deleting them and creating them again from the scratch. However, some fields and
    resources are immutable and cannot be modified *on* *the fly*.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中，除了删除并重新创建资源外，还可以修改已创建的资源。然而，某些字段和资源是不可变的，不能*实时*修改。
- en: 'Now, let’s apply the modified spec file using the `kubectl apply -f` command
    (the spec filename is `statefulset_with_secret.yaml`, as follows):'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们使用`kubectl apply -f`命令应用修改后的规范文件（规范文件名为`statefulset_with_secret.yaml`，如下所示）：
- en: '[PRE32]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'Because we’ve added a new volume, Pods will be recreated straight after:'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们添加了一个新的卷，所以 Pod 将会在之后直接重新创建：
- en: '[PRE33]'
  id: totrans-167
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Let’s execute into one of the pods to see whether our Secret was correctly
    mounted inside:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们执行进入其中一个 pod，看看我们的 Secret 是否已正确挂载：
- en: '[PRE34]'
  id: totrans-169
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'There you go, the Secret has been mounted inside our nginx containers. It is
    worth mentioning that Kubernetes makes it possible to perform all sorts of combinations:
    Secrets (and individual keys) can be used as environment variables; Secrets can
    be created from existing files; Secrets can be used to store and mount SSL certificates
    or SSH keys; individual keys from K8s Secrets can be mounted into different paths
    and more.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 好了，Secret 已经挂载到我们的 nginx 容器中。值得一提的是，Kubernetes 使得各种组合变得可能：Secrets（以及单独的密钥）可以作为环境变量使用；Secrets
    可以从现有文件创建；Secrets 可以用来存储和挂载 SSL 证书或 SSH 密钥；K8s Secrets 中的单独密钥可以挂载到不同的路径等等。
- en: ConfigMaps are very similar in terms of their capabilities, but their purpose
    is to store generic configuration. For example, we can create a new `ConfigMap`
    with nginx configuration and mount it over the `/etc/nginx/nginx.conf` in container
    overriding the default config file.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: ConfigMap 和 Secrets 在功能上非常相似，但它们的用途是存储通用配置。例如，我们可以创建一个新的`ConfigMap`，并将 nginx
    配置挂载到容器中的`/etc/nginx/nginx.conf`，从而覆盖默认的配置文件。
- en: In terms of the scope of the KCNA exam, you are not expected to know all details,
    but as you get to work with Kubernetes, you’ll encounter the need to do one or
    another, therefore, feel free to check out the links in the *Further reading*
    section at the end of the chapter if you have time.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 在 KCNA 考试的范围内，你不需要了解所有细节，但随着你开始使用 Kubernetes，你会遇到需要进行服务发现的情况，因此，如果你有时间，随时可以查看章节末尾的*进一步阅读*部分中的链接。
- en: Coming next, we will talk about service discovery in Kubernetes.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论 Kubernetes 中的服务发现。
- en: Service discovery
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 服务发现
- en: Service discovery provides the automatic detection of devices and the services
    offered by these devices on a network.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 服务发现提供了设备以及这些设备所提供的服务在网络上的自动检测功能。
- en: As you may remember, in the case of microservice architectures, we have a lot
    of small services that need to talk to each other over the network. That means
    service discovery plays a huge role because it helps services to find their counterparts,
    for example, a backend service that has to discover the database it shall connect
    to. Luckily, Kubernetes solves that problem, too, with its service discovery mechanism
    based on **Domain Name** **System** (**DNS**).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可能记得的那样，在微服务架构中，我们有许多小服务需要通过网络相互通信。这意味着服务发现起着至关重要的作用，因为它帮助服务找到它们的对应服务，例如，一个后端服务需要发现它要连接的数据库。幸运的是，Kubernetes
    也通过基于**域名系统**（**DNS**）的服务发现机制解决了这个问题。
- en: Kubernetes implements an internal DNS system that keeps track of applications
    with their names and respective pod IPs (each pod gets its own unique cluster-wide
    IP address on start). This allows different applications to easily find the endpoints
    of each other by resolving application names to pod IPs. Kubernetes **Service**
    resource comes into play here.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 实现了一个内部 DNS 系统，跟踪应用程序及其名称和相应的 Pod IP（每个 Pod 启动时都会获得一个唯一的集群范围的 IP
    地址）。这使得不同的应用可以轻松找到彼此的端点，通过解析应用名称到 Pod IP。此时，Kubernetes **服务**资源就派上用场了。
- en: Service
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 服务
- en: Service is an abstraction layer that enables loose coupling between dependent
    pods. It is a resource that allows you to publish application names *inside* the
    cluster and expose applications to be reachable from *outside* the cluster.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 服务是一种抽象层，能够实现依赖 Pod 之间的松耦合。它是一个资源，允许你在集群内部发布应用名称，并将应用暴露出来，使其可以从集群外部访问。
- en: Kubernetes Pods can have a relatively short life cycle. If we add a new volume
    or update the deployment image, or if the node dies, in all cases, Pods are recreated
    with a new name and a new IP address. That means we cannot rely on pod names,
    and we should use a Service that will target one or multiple Pods by matching
    Kubernetes **labels** and **selectors**.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes Pod 的生命周期相对较短。如果我们添加新的卷、更新部署镜像，或者节点出现故障，在所有这些情况下，Pod 会使用新名称和新 IP
    地址重新创建。这意味着我们不能依赖 Pod 名称，而应该使用服务，它将通过匹配 Kubernetes **标签**和 **选择器**来定向一个或多个 Pod。
- en: Labels and selectors
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 标签和选择器
- en: Labels are simple key/value metadata pairs that can be attached to any Kubernetes
    objects during or after creation. Labels can contain the name of the application,
    version tags, or any other object classification.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 标签是可以附加到任何 Kubernetes 对象的简单键/值元数据对，可以在创建期间或创建后添加。标签可以包含应用程序名称、版本标签或任何其他对象分类。
- en: Selectors allow the identification of a set of Kubernetes objects. For example,
    a label selector can be used to find a group of objects that have the same `app`
    label, as shown in *Figure 6**.2*.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 选择器允许识别一组 Kubernetes 对象。例如，可以使用标签选择器来查找具有相同 `app` 标签的对象组，如 *图 6.2* 所示。
- en: '![Figure 6.2 – Service abstraction in Kubernetes](img/B18970_06_02.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.2 – Kubernetes 中的服务抽象](img/B18970_06_02.jpg)'
- en: Figure 6.2 – Service abstraction in Kubernetes
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.2 – Kubernetes 中的服务抽象
- en: '*Figure 6**.2* demonstrates how a Service selects all pods that have an `app:
    nginx` label assigned. Those can be pods created by a Deployment as well as any
    other pods that have the selected label assigned. You can list the labels of objects
    by adding the `--show-labels` parameter to `kubectl get` commands, for example:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '*图 6.2* 演示了一个服务如何选择所有带有 `app: nginx` 标签的 Pod。这些 Pod 可以是由 Deployment 创建的，也可以是任何其他带有该标签的
    Pod。你可以通过在 `kubectl get` 命令中添加 `--show-labels` 参数来列出对象的标签，例如：'
- en: '[PRE35]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'See, our nginx deployment pod as well as pods from the `nginx-statefulset`
    all have the same `app=nginx` label because both the Deployment and StatefulSet
    have it defined in their spec templates:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 看，我们的 nginx 部署 Pod 以及 `nginx-statefulset` 中的 Pod 都有相同的 `app=nginx` 标签，因为 Deployment
    和 StatefulSet 都在其规范模板中定义了这个标签：
- en: '[PRE36]'
  id: totrans-189
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Now, let’s create a Service that will target all pods with this label. The
    following is what a simple spec targeting port `80` of selected pods might look
    like:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个服务，目标是所有带有该标签的 Pod。以下是一个简单的规范示例，目标是选定的 Pod 的端口`80`：
- en: '[PRE37]'
  id: totrans-191
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: 'Go on and create the Service:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，创建服务：
- en: '[PRE38]'
  id: totrans-193
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'After creation, you should be able to see the endpoints behind the Service
    that are, in fact, the IPs of running pods with an `app=nginx` label. Listing
    endpoints can be done with the `kubectl get endpoints` command, as follows:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 创建后，你应该能够看到服务背后的端点，它们实际上是带有 `app=nginx` 标签的运行中 Pod 的 IP 地址。列出端点可以通过执行 `kubectl
    get endpoints` 命令来完成，如下所示：
- en: '[PRE39]'
  id: totrans-195
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'If we’re now execute inside to one of the Pods again and run `curl nginx` (the
    name of the service we created) we should get a reply. Run it a few times (5-10
    times) after installing curl into the container:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们现在再次进入其中一个 Pod，运行`curl nginx`（我们创建的服务名称），应该会得到响应。在容器中安装 curl 后，执行几次（5-10
    次）：
- en: '[PRE40]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: And we get different replies! One of the four pods that we’re currently running
    has a custom `index.html` file that we created earlier in this chapter, while
    the three others don’t.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们得到不同的响应！我们当前运行的四个 Pod 中，有一个 Pod 包含我们在本章早些时候创建的自定义`index.html`文件，而其他三个没有。
- en: What happens is the service we created load balances the requests between all
    available `nginx` pod IPs. The Service will also automatically update the list
    of endpoints if we scale out the number of replicas or if we do the opposite.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 发生的情况是，我们创建的服务在所有可用的`nginx` Pod IP之间进行负载均衡。如果我们扩展副本数量，或者进行相反的操作，服务还会自动更新端点列表。
- en: 'Now, let’s see which Service types exist and what they allow you to accomplish:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看存在哪些服务类型，以及它们允许你完成什么任务：
- en: '**ClusterIP**: This type exposes an application on an internal cluster IP.
    Only Pods running in the same cluster can reach such a service. This is the default
    type that gets created unless overridden in the spec.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ClusterIP**: 这种类型将在内部集群IP上暴露应用程序。只有在同一集群中运行的Pod才能访问此类服务。这是默认类型，除非在规范中被覆盖。'
- en: '**NodePort**: This type exposes the application on the same static port of
    each node in the cluster. Users will be able to reach the application from outside
    the cluster by requesting the IP of any node and configured port.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**NodePort**: 这种类型将应用程序暴露在集群中每个节点的相同静态端口上。用户可以通过请求任何节点的IP和配置的端口，从集群外部访问该应用程序。'
- en: '**LoadBalancer**: This type exposes the application outside of cluster using
    a cloud provider’s load balancer.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LoadBalancer**: 这种类型通过云服务提供商的负载均衡器将应用程序暴露到集群外部。'
- en: '`mybestservice.app.com`) by returning a `ExternalName` is not acting as a proxy
    for application requests like other service types do.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`mybestservice.app.com`通过返回`ExternalName`并不像其他服务类型那样充当应用程序请求的代理。'
- en: What that means is that in practice you’ll use the `LoadBalancer` type in most
    cases when you need to expose an application running in Kubernetes outside of
    the cluster (assuming your cloud provider or on-premises infrastructure offers
    load balancers). And in case of multiple applications that need to communicate
    with each other within the cluster, you’ll use the default `ClusterIP` type. For
    example, when your backend deployment needs to talk with the database running
    as a StatefulSet and the database should not be exposed to the internet.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，实际上，当你需要将Kubernetes中运行的应用程序暴露到集群外部时，通常会使用`LoadBalancer`类型（假设你的云服务提供商或本地基础设施提供负载均衡器）。而在集群内需要相互通信的多个应用程序之间，你将使用默认的`ClusterIP`类型。例如，当你的后端部署需要与作为StatefulSet运行的数据库通信，而该数据库不应暴露到互联网时。
- en: Coming next is the final section of the chapter. As you were doing all of the
    exercises, you might have wondered how Kubernetes knows that the application is
    actually running when a pod is running. What happens if an application needs time
    before it can serve the requests? How do we know that the application is not stuck
    in a deadlock? Let’s figure that out!
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是本章的最后一部分。在进行所有练习时，你可能会想，当Pod正在运行时，Kubernetes是如何知道应用程序实际上正在运行的。如果应用程序在响应请求之前需要时间怎么办？我们怎么知道应用程序没有陷入死锁？让我们弄明白这一点！
- en: Ensuring applications are alive and healthy
  id: totrans-207
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确保应用程序处于存活和健康状态
- en: By default, Kubernetes ensures that the desired state of applications in a cluster
    is reached. It will restart and recreate failed containers when a process exits
    or a node fails. However, that might not be enough to tell if the application
    running inside the pod is healthy. In order to ensure that the workloads are alive
    and healthy, Kubernetes implements the concept of **probes**.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，Kubernetes确保集群中应用程序的期望状态已达到。当进程退出或节点失败时，它会重启并重新创建失败的容器。然而，仅仅这样可能不足以判断Pod内部运行的应用程序是否健康。为了确保工作负载处于存活和健康状态，Kubernetes实现了**探针**的概念。
- en: Probe
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 探针
- en: A probe is a diagnostic that is performed by a Kubernetes kubelet on a container.
    A diagnostic can be an arbitrary command executed inside a container or TCP probe,
    or an HTTP request.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 探针是由Kubernetes kubelet在容器上执行的诊断。诊断可以是执行容器内任意命令或TCP探测，或是HTTP请求。
- en: 'Kubernetes offers three types of probes, as shown in the following list:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes提供了三种类型的探针，如下所示：
- en: '**Liveness**: Ensures that a process in a container is alive and, if not, restarts
    the container. For the case when the application catches a deadlock, restarting
    the container usually helps to make the application more available despite bugs.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Liveness**: 确保容器中的进程存活，如果没有，则重启容器。在应用程序发生死锁时，重启容器通常有助于使应用程序在出现故障时仍保持可用。'
- en: '**Readiness**: Ensures that the application is ready to accept traffic. A pod
    with multiple containers is considered ready when all its containers are ready
    and all readiness probes succeed.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**就绪性**：确保应用程序已经准备好接收流量。当一个 Pod 中的所有容器都准备好并且所有的就绪性探针都成功时，该 Pod 被认为是就绪的。'
- en: '**Startup**: Allows you to know when an application in a container has started.
    If a startup probe is configured, it disables liveness and readiness probes until
    it succeeds. This might be needed for slow-starting applications to avoid them
    being killed due to a failed liveness probe before they are up.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**启动探针**：允许您知道容器中的应用程序何时启动。如果配置了启动探针，它将在启动探针成功之前禁用活跃性和就绪性探针。这对于启动较慢的应用程序可能是必要的，以避免在应用程序启动之前由于活跃性探针失败而导致它们被终止。'
- en: All those probes serve the purpose of increasing the availability of containerized
    applications, but they cover different scenarios. For example, a liveness probe
    will cause a container to restart if a probe fails. Complex applications running
    for a long time might eventually transition to a broken state, and this is where
    the Kubernetes liveness probe helps.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些探针的目的是提高容器化应用程序的可用性，但它们覆盖了不同的场景。例如，如果探针失败，活跃性探针会导致容器重新启动。长时间运行的复杂应用程序最终可能过渡到故障状态，这时
    Kubernetes 的活跃性探针就发挥了作用。
- en: Note
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The whole pod is not recreated when the liveness probe of a single container
    has failed. Only a certain container within the pod is restarted. This is different
    from the case when the application in the container exits and the pod gets recreated
    by a controller such as a Deployment, ReplicaSet, or StatefulSet.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 当单个容器的活跃性探针失败时，不会重新创建整个 Pod。只有 Pod 中的特定容器会被重新启动。这与容器中的应用程序退出并且 Pod 被如 Deployment、ReplicaSet
    或 StatefulSet 等控制器重新创建的情况不同。
- en: A readiness probe is needed when an application in a container is unable to
    serve the traffic. Some applications might take a long time to start because of
    the large datasets they are loading into memory or because they need to perform
    an initial configuration that takes time. An application might also depend on
    an external service. In all those situations, we don’t want to kill and restart
    the container; rather, we don’t want to send any traffic to it.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 当容器中的应用程序无法处理流量时，需要就绪性探针。一些应用程序可能需要很长时间才能启动，因为它们需要加载大量数据集到内存中，或者需要执行一些耗时的初始化配置。应用程序还可能依赖外部服务。在所有这些情况下，我们不希望终止并重新启动容器；而是希望避免向它发送任何流量。
- en: Readiness probes help to determine which Pods behind a Service are ready to
    accept connections and serve traffic. If a container fails the readiness probe,
    its pod IP is automatically taken out from the list of endpoints of the Service.
    This helps prevent situations when a user request is routed to a *not-yet-working*
    application replica.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 就绪性探针有助于确定 Service 后面的哪些 Pods 已经准备好接收连接并处理流量。如果容器未通过就绪性探针，它的 Pod IP 会被自动从 Service
    的端点列表中移除。这有助于防止将用户请求路由到一个*尚未正常工作的*应用程序副本。
- en: Note
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: If both liveness and readiness probes are defined, the first does not wait for
    the second to succeed. It is possible to set initial delays for probes (via the
    `initialDelaySeconds` setting) or use a `startupProbe` that temporarily disables
    the liveness and readiness checks.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 如果同时定义了活跃性和就绪性探针，前者不会等待后者成功。可以为探针设置初始延迟（通过`initialDelaySeconds`设置），或者使用`startupProbe`临时禁用活跃性和就绪性检查。
- en: 'Each probe can execute a custom command, perform an HTTP request, or a TCP
    probe. In addition to that, liveness and readiness probes are tunable with several
    parameters: how often the check should be performed (configurable via `periodSeconds`),
    how long to wait for a probe to finish (configurable via `timeoutSeconds`) or
    the thresholds for how many times the probe should be retried before giving up
    and either restarting the container or stopping the traffic depending on the probe
    type.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 每个探针可以执行自定义命令、执行 HTTP 请求或进行 TCP 探测。除此之外，活跃性和就绪性探针可以通过多个参数进行调整：检查执行的频率（可通过`periodSeconds`配置）、等待探针完成的时间（可通过`timeoutSeconds`配置）或探针在放弃之前应该重试的次数阈值，具体取决于探针的类型。
- en: 'Now, let’s examine the following pod with a simple liveness probe defined:'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们来检查以下定义了简单活跃性探针的 Pod：
- en: '[PRE41]'
  id: totrans-224
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: When the pod container is started it creates an empty file at the `/tmp/healthy`
    path, waits for `30` seconds, and deletes that file. After that, the container
    does nothing for another `600` seconds before exiting. The liveness probe executes
    the `cat /tmp/healthy` command every `5` seconds after an initial check delay
    of `5` seconds.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 当 pod 容器启动时，它会在 `/tmp/healthy` 路径下创建一个空文件，等待 `30` 秒，然后删除该文件。之后，容器将再等待 `600`
    秒后退出。健康检查探针会在初始检查延迟 `5` 秒后每 `5` 秒执行一次 `cat /tmp/healthy` 命令。
- en: 'Let’s create the spec and see it in action:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们创建规格并查看其实际效果：
- en: '[PRE42]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'At first, the pod runs fine, its liveness probe succeeds, and its restart counter
    shows `0` restarts:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，pod 运行正常，它的健康检查成功，重启计数器显示 `0` 次重启：
- en: '[PRE43]'
  id: totrans-229
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Sometime later, we can see that there was a restart:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 稍后，我们可以看到发生了重启：
- en: '[PRE44]'
  id: totrans-231
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'If we describe the pod, we can see the timeline of events:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们描述该 pod，可以看到事件的时间线：
- en: '[PRE45]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: We are now approaching the end of this long and intense chapter. By now, you’ve
    learned a lot about Kubernetes features and some of its advanced resources. Many
    of the in-depth details explained here are not required to pass the KCNA exam,
    but they will be required to start working with Kubernetes and will undoubtedly
    help you in the future if you decide to become CKA or CKAD certified. If you have
    not been able to grasp 100% of this chapter’s content, that is unlikely to stop
    you from passing the KCNA exam, but try to get into it as much as you can now.
    Check out the *Further reading* section resources and do additional research if
    needed.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在接近这一长篇章的结束。到目前为止，你已经学到了许多关于 Kubernetes 特性以及一些其高级资源的内容。这里讲解的许多深入细节不要求通过 KCNA
    考试，但它们对开始使用 Kubernetes 至关重要，如果你决定获得 CKA 或 CKAD 认证，它们无疑会帮助你。如果你没有完全掌握这一章的内容，这不会妨碍你通过
    KCNA 考试，但尽量现在多了解一些。请查看*进一步阅读*部分的资源，必要时进行额外的研究。
- en: Summary
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we’ve seen Kubernetes’ self-healing capabilities in action
    and how K8s reconciliation loops allow it to reach the desired state of resources
    in a very short time. Since Pods themselves do not have any means to recover from
    a failure, we commonly use Kubernetes *Deployments* to ensure that the requested
    number of application replicas are running. *Deployments* also allow us to perform
    controllable *rolling updates*, *rollbacks,* and *zero-downtime* deployments to
    enable rapid software development cycles that require the frequent release of
    versions.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一章中，我们已经看到 Kubernetes 的自愈能力以及 K8s 的资源调和循环如何使其在极短时间内达到所需的资源状态。由于 Pods 本身没有任何从故障中恢复的机制，我们通常使用
    Kubernetes 的*Deployments*来确保所请求数量的应用副本正在运行。*Deployments* 还允许我们执行可控的*滚动更新*、*回滚*和*零停机*部署，以支持需要频繁发布版本的快速软件开发周期。
- en: '*DaemonSet* is another resource for the scenario when we need to run one replica
    of the application on each or a particular set of nodes. *DaemonSets* are often
    used for running logging or monitoring agents across the cluster.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '*DaemonSet* 是一种资源，适用于我们需要在每个节点或特定节点集群中运行一个副本的场景。*DaemonSets* 通常用于在集群中运行日志记录或监控代理。'
- en: '*StatefulSet* is a resource for managing stateful workloads with Kubernetes.
    It allows us to easily integrate volumes to Pods to keep persistent data between
    container restarts and automate the dynamic provisioning of PVs.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '*StatefulSet* 是一种管理有状态工作负载的 Kubernetes 资源。它使我们能够轻松地将卷集成到 Pods 中，以保持容器重启后的持久数据，并自动化
    PVs 的动态配置。'
- en: Next, we have explored ways to provide configuration and sensitive information
    to applications running in Kubernetes. *ConfigMaps* are suitable for generic non-confidential
    data, and *Secrets* are intended to be used for passwords, tokens, and so on.
    Both ConfigMaps and Secrets are essentially volumes that can be mounted into specific
    file paths inside containers.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们探索了为在 Kubernetes 中运行的应用提供配置和敏感信息的方法。*ConfigMaps* 适用于通用的非机密数据，而 *Secrets*
    则用于存储密码、令牌等信息。ConfigMaps 和 Secrets 本质上都是可以挂载到容器内部特定文件路径的卷。
- en: We have also learned that service discovery plays an important role and allows
    applications to find and communicate with each other within the Kubernetes cluster.
    The *Service* resource allows for the exposure of the application with its Pods
    both inside and outside of the cluster using distinct Service types such as `LoadBalancer`,
    `NodePort`, or `ClusterIP`.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还学习了服务发现的重要性，它允许应用程序在 Kubernetes 集群内部找到并与彼此通信。*Service* 资源允许将应用程序及其 Pods 通过不同的
    Service 类型（如 `LoadBalancer`，`NodePort` 或 `ClusterIP`）暴露到集群内部和外部。
- en: Last but not least, we’ve explored the options for ensuring that applications
    running in Kubernetes are alive and healthy. Kubernetes offers three types of
    probes (*liveness*, *readiness*, and *startup*) that serve the purpose of verifying
    the state of the application on startup or periodically at regular intervals.
    If the application fails the liveness probes, its container is restarted and in
    case it fails the Readiness probes, it just won’t receive any traffic, and the
    pod IP will be excluded from the list of Service endpoints. The startup probes
    are intended for slow-starting applications that need extra time before they can
    handle other probes or real traffic.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，我们已经探索了确保 Kubernetes 中运行的应用程序始终处于活动和健康状态的选项。Kubernetes 提供了三种类型的探针（*liveness*，*readiness*
    和 *startup*），它们的作用是验证应用程序在启动时或定期在常规间隔时的状态。如果应用程序未通过 liveness 探针，它的容器会被重新启动；如果未通过
    Readiness 探针，它将不会接收任何流量，且 Pod 的 IP 会从服务端点列表中排除。Startup 探针用于启动缓慢的应用程序，这些应用程序需要更多时间才能处理其他探针或实际流量。
- en: Note
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Feel free to delete any Kubernetes resources created in this chapter unless
    you’re planning to come back to them later.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 随时删除本章中创建的任何 Kubernetes 资源，除非你计划稍后再回来使用它们。
- en: In the upcoming chapter, we will continue exploring Kubernetes and its features.
    We will learn about placement controls, resource requests, and ways to debug applications
    running on Kubernetes. Make sure to answer all recap questions and check out the
    *Further reading* section if you’d like to learn more about the topics in this
    chapter.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将继续探索 Kubernetes 及其特性。我们将学习关于调度控制、资源请求以及调试在 Kubernetes 上运行的应用程序的方法。确保回答所有回顾问题，并查看
    *进一步阅读* 部分，如果你想深入了解本章中的主题。
- en: Questions
  id: totrans-245
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'As we conclude, here is a list of questions for you to test your knowledge
    regarding this chapter’s material. You will find the answers in the *Assessments*
    section of the *Appendix*:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在总结时，这里有一系列问题，帮助你测试自己对本章内容的理解。你可以在 *评估* 部分的 *附录* 中找到答案：
- en: Which of the following Kubernetes resources allows you to recover an application
    if the node it was running on has failed (select multiple)?
  id: totrans-247
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个 Kubernetes 资源可以在其运行的节点失败时帮助恢复应用程序（可选择多个）？
- en: Pod
  id: totrans-248
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pod
- en: Service
  id: totrans-249
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Service
- en: StatefulSet
  id: totrans-250
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: StatefulSet
- en: Deployment
  id: totrans-251
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Deployment
- en: Which of the following Kubernetes resources ensures that the defined number
    of replicas are always running (select multiple)?
  id: totrans-252
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个 Kubernetes 资源确保定义的副本数始终运行（可选择多个）？
- en: Pod
  id: totrans-253
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pod
- en: ReplicaSet
  id: totrans-254
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: ReplicaSet
- en: Deployment
  id: totrans-255
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Deployment
- en: DaemonSet
  id: totrans-256
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: DaemonSet
- en: Which of the following Kubernetes resources allows us to perform rolling updates
    and zero-downtime deployments?
  id: totrans-257
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个 Kubernetes 资源允许我们执行滚动更新和零停机部署？
- en: Service
  id: totrans-258
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Service
- en: Deployment
  id: totrans-259
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Deployment
- en: ReplicaSet
  id: totrans-260
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: ReplicaSet
- en: DeploySet
  id: totrans-261
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: DeploySet
- en: Which statement best describes the relationship between Pods and various Kubernetes
    controllers (resources)?
  id: totrans-262
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪项描述最准确地阐明了 Pods 与各类 Kubernetes 控制器（资源）之间的关系？
- en: Pods are managing the resources
  id: totrans-263
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pods 管理资源
- en: Pods are managed by the container runtime
  id: totrans-264
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pods 由容器运行时管理
- en: Pods are always managed by one of the Kubernetes controllers
  id: totrans-265
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pods 始终由一个 Kubernetes 控制器管理
- en: Pods can be managed by one of the Kubernetes controllers
  id: totrans-266
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pods 可以由一个 Kubernetes 控制器管理
- en: What is the purpose of label selectors?
  id: totrans-267
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标签选择器的作用是什么？
- en: They help to determine the purpose of each pod in the cluster
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们帮助确定集群中每个 Pod 的用途
- en: They help to distinguish more important Pods from less important ones
  id: totrans-269
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们帮助区分更重要的 Pods 和不太重要的 Pods
- en: They are simply auxiliary metadata
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们仅仅是辅助元数据
- en: They allow us to group and select resources by labels
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 它们允许我们通过标签对资源进行分组和选择
- en: Which of the following image pull policies will cause a download from the registry
    only when the image is not already cached on the node?
  id: totrans-272
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个镜像拉取策略将在镜像未被节点缓存时才从注册中心下载镜像？
- en: '`IfNotCached`'
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`IfNotCached`'
- en: '`IfNotPresent`'
  id: totrans-274
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`IfNotPresent`'
- en: '`IfNotAvailable`'
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`IfNotAvailable`'
- en: '`Always`'
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Always`'
- en: How does a Service determine the Pods that are ready to accept traffic?
  id: totrans-277
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 服务如何确定哪些Pods已经准备好接收流量？
- en: 'Pods that are ready will have the `ready: true` label on them'
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '准备好的Pods会有`ready: true`标签'
- en: Only Pods managed by Deployment can accept traffic from a Service
  id: totrans-279
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 只有由部署（Deployment）管理的Pods才能接受来自服务（Service）的流量
- en: A pod’s readiness probe has to succeed
  id: totrans-280
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个Pod的就绪探针必须成功
- en: A pod’s startup probe has to succeed
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个Pod的启动探针必须成功
- en: Which type of probe delays the execution of other probes?
  id: totrans-282
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种类型的探针会延迟其他探针的执行？
- en: Delayed
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 延迟
- en: Liveness
  id: totrans-284
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存活性
- en: Startup
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动
- en: Readiness
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就绪性
- en: Which spec setting controls the number of Pods managed by a Deployment?
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个规格设置控制由Deployment管理的Pod数量？
- en: podnum
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: podnum
- en: Replicas
  id: totrans-289
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 副本
- en: Containers
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 容器
- en: Instances
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 实例
- en: Which Kubernetes controller is best suited for applications that need to save
    data to disk?
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个Kubernetes控制器最适合需要将数据保存到磁盘的应用程序？
- en: '`Deployment`'
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`Deployment`'
- en: '`DaemonSet`'
  id: totrans-294
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`DaemonSet`'
- en: '`ReplicaSet`'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ReplicaSet`'
- en: '`StatefulSet`'
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`StatefulSet`'
- en: Which of the following allows Kubernetes controllers to detect drift from the
    desired state?
  id: totrans-297
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个选项允许Kubernetes控制器检测与期望状态的偏差？
- en: Replica controller
  id: totrans-298
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 副本控制器
- en: Kubelet
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubelet
- en: Reconciliation loop
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 协调循环
- en: Liveness probes
  id: totrans-301
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存活性探针
- en: Which type of service allows the exposure of applications inside the cluster?
  id: totrans-302
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种类型的服务允许在集群内暴露应用程序？
- en: '`LoadBalancer`'
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`LoadBalancer`'
- en: '`ClusterIP`'
  id: totrans-304
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ClusterIP`'
- en: '`InternalIP`'
  id: totrans-305
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`InternalIP`'
- en: '`NodePort`'
  id: totrans-306
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`NodePort`'
- en: Which technology is used behind service discovery in Kubernetes?
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在Kubernetes中，服务发现背后使用了什么技术？
- en: Avahi
  id: totrans-308
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Avahi
- en: Iptables
  id: totrans-309
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Iptables
- en: NTP
  id: totrans-310
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: NTP
- en: DNS
  id: totrans-311
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: DNS
- en: Which of the following service types are suitable for exposing applications
    outside of the Kubernetes cluster (select multiple)?
  id: totrans-312
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪些服务类型适合将应用程序暴露到Kubernetes集群外部（请选择多个）？
- en: '`ClusterIP`'
  id: totrans-313
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ClusterIP`'
- en: '`NodePort`'
  id: totrans-314
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`NodePort`'
- en: '`LoadBalancer`'
  id: totrans-315
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`LoadBalancer`'
- en: '`ExternalIP`'
  id: totrans-316
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`ExternalIP`'
- en: Which of the following resources is suitable for storing and injecting generic
    configuration into containers?
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个资源适合存储并注入通用配置到容器中？
- en: ConfigMap
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: ConfigMap
- en: Secret
  id: totrans-319
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Secret
- en: SettingMap
  id: totrans-320
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: SettingMap
- en: PV
  id: totrans-321
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: PV
- en: Which object in Kubernetes represents an actual storage volume?
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kubernetes中哪个对象表示实际的存储卷？
- en: StatefulSet
  id: totrans-323
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`StatefulSet`'
- en: PVC
  id: totrans-324
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: PVC
- en: PV
  id: totrans-325
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: PV
- en: SV
  id: totrans-326
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: SV
- en: Which resource is suitable for representing sensitive information to applications
    in containers?
  id: totrans-327
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种资源适合表示容器中应用程序的敏感信息？
- en: ConfigMap
  id: totrans-328
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: ConfigMap
- en: Secret
  id: totrans-329
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Secret
- en: Volume
  id: totrans-330
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卷
- en: PVC
  id: totrans-331
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: PVC
- en: Which probe will restart the container if failed?
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种探针失败时会重启容器？
- en: Aliveness
  id: totrans-333
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存活性
- en: Readiness
  id: totrans-334
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就绪性
- en: Startup
  id: totrans-335
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 启动
- en: Liveness
  id: totrans-336
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存活性
- en: Further reading
  id: totrans-337
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'To learn more about the topics that were covered in this chapter, take a look
    at the following resources:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于本章涵盖的主题，请查看以下资源：
- en: 'Dynamic Volume provisioning: [https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/](https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/)'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 动态卷提供：[https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/](https://kubernetes.io/docs/concepts/storage/dynamic-provisioning/)
- en: 'Managing Kubernetes Secrets: [https://kubernetes.io/docs/tasks/configmap-secret/](https://kubernetes.io/docs/tasks/configmap-secret/)'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理Kubernetes密钥：[https://kubernetes.io/docs/tasks/configmap-secret/](https://kubernetes.io/docs/tasks/configmap-secret/)
- en: 'Creating and using ConfigMaps: [https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/](https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/)'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 创建和使用ConfigMaps：[https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/](https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/)
- en: 'Kubernetes probes configuration: [https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes探针配置：[https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)
