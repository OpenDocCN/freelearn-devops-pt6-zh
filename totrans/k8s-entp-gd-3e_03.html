<html><head></head><body>
<div id="sbo-rt-content"><div class="Basic-Text-Frame" id="_idContainer095">
<h1 class="chapterNumber">3</h1>
<h1 class="chapterTitle" id="_idParaDest-80">Kubernetes Bootcamp</h1>
<p class="normal">The previous chapter introduced you to deploying Kubernetes clusters using KinD (Kubernetes in Docker), which is useful for creating a development cluster on a single machine using containers instead of virtual machines. This approach reduces the system resource requirements and simplifies the entire setup process. We covered the installation and configuration of KinD, creating clusters, including add-ons like Ingress controllers, Calico as the CNI, and using persistent storage.</p>
<p class="normal">We understand that many of you have experience with Kubernetes, whether it’s running clusters in production or experimenting with tools like <code class="inlineCode">kubeadm</code>, minikube, or Docker Desktop. Our intention with this book is to go beyond the fundamentals of Kubernetes, which is why we didn’t want to reiterate all the basics. Instead, we’ve included this chapter as a bootcamp for those who are new to Kubernetes or have only had limited exposure to it.</p>
<p class="normal">In this chapter, we will explore the essential components of a Kubernetes cluster, including the control plane and worker nodes. We will provide detailed explanations of each Kubernetes resource and its respective use cases. If you have previous experience with Kubernetes and feel comfortable using <code class="inlineCode">kubectl</code>, as well as an understanding of Kubernetes resources like <strong class="keyWord">DaemonSets</strong>, <strong class="keyWord">StatefulSets</strong>, and <strong class="keyWord">ReplicaSets</strong>, this chapter can serve as a helpful review before moving on to <em class="chapterRef">Chapter 4</em>, where we will dive into <strong class="keyWord">Services</strong>, <strong class="keyWord">Load Balancing</strong>, <strong class="keyWord">ExternalDNS</strong>, <strong class="keyWord">Global Balancing</strong>, and <strong class="keyWord">K8GB</strong>.</p>
<p class="normal">Since this is a bootcamp chapter, we won’t get into every topic in detail. However, by the end of this chapter, you should have a solid understanding of the foundational concepts of Kubernetes, which will be crucial for comprehending the remaining chapters. Even if you already possess a strong background in Kubernetes, you may find this chapter valuable as a refresher before we get into more advanced topics. In this chapter, you will learn the following topics:</p>
<ul>
<li class="bulletList">An overview of Kubernetes components</li>
<li class="bulletList">Exploring the control plane</li>
<li class="bulletList">Understanding the worker node components</li>
<li class="bulletList">Interacting with the API server</li>
<li class="bulletList">Introducing Kubernetes resources</li>
</ul>
<p class="normal">By the end of this chapter, you will have a solid understanding of the most commonly used cluster resources. Understanding Kubernetes resources is important for both cluster operators and cluster administrators.</p>
<h1 class="heading-1" id="_idParaDest-81">Technical requirements</h1>
<p class="normal">This chapter has no technical requirements.</p>
<p class="normal">If you want to execute commands while learning about the resources, you can use the KinD cluster that was deployed in the previous chapter.</p>
<h1 class="heading-1" id="_idParaDest-82">An overview of Kubernetes components</h1>
<p class="normal">Understanding the components of systems in an infrastructure is essential for delivering services effectively. In today’s wide landscape of installation options, many Kubernetes users may not have <a id="_idIndexMarker162"/>felt the need to fully comprehend the integration of different Kubernetes components.</p>
<p class="normal">Just a few years ago, establishing a Kubernetes cluster involved the manual installation and configuration of each component. This process presented a steep learning curve and often resulted in frustration. As a result, many individuals and organizations concluded that “Kubernetes is overly complex.” However, the benefit of manual installation was the in-depth understanding it provided regarding the interaction between each component. If any issues arose within the cluster after installation, you would have a clear understanding of where to investigate.</p>
<p class="normal">To understand how Kubernetes components work together, you must first understand the different components of a Kubernetes cluster.</p>
<p class="normal">The following diagram is from the <a href="http://Kubernetes.io"><span class="url">http://Kubernetes.io</span></a> site and shows a high-level overview of a Kubernetes cluster component:</p>
<figure class="mediaobject"><img alt="Figure 5.1 – Kubernetes cluster components " height="466" src="../Images/B21165_03_01.png" width="717"/></figure>
<p class="packt_figref">Figure 3.1: Kubernetes cluster components</p>
<p class="normal">As you can see, the<a id="_idIndexMarker163"/> Kubernetes cluster is made up of several components. As we progress through the chapter, we’ll discuss these components and the role they play in a Kubernetes cluster.</p>
<h1 class="heading-1" id="_idParaDest-83">Exploring the control plane</h1>
<p class="normal">The control plane, as its name suggests, has authority over every aspect of a cluster. In the absence of a functioning <a id="_idIndexMarker164"/>control plane, the cluster loses its ability to schedule workloads, create new deployments, and manage Kubernetes objects. Recognizing the criticality of the control plane, it is highly advisable to deploy with <strong class="keyWord">high availability</strong> (<strong class="keyWord">HA</strong>) support, deploying a minimum of three control plane nodes. Many production environments even utilize more than three control plane nodes, but the key principle is to have an odd number of nodes, which is required so we can maintain a highly available control plane if we lose a single <code class="inlineCode">etcd</code> node.</p>
<p class="normal">Now, let’s delve into the importance of the control plane and its components, providing a comprehensive<a id="_idIndexMarker165"/> understanding of their pivotal role in a functioning cluster.</p>
<h2 class="heading-2" id="_idParaDest-84">The Kubernetes API server</h2>
<p class="normal">The first component to understand in a<a id="_idIndexMarker166"/> cluster is the <code class="inlineCode">kube-apiserver</code> component. Since Kubernetes is <strong class="keyWord">application programming interface</strong> (<strong class="keyWord">API</strong>)-driven, every request that comes into a cluster goes through the API server. Let’s look at a simple <code class="inlineCode">get nodes</code> request using an API endpoint, using the IP address for the control plane, which, in an enterprise, is usually fronted by a load balancer. In our example, our load balancer has an entry for the three control plane nodes on <code class="inlineCode">10.240.100.100</code>:</p>
<p class="normal"><a href="https://10.240.100.100:6443/api/v1/nodes?limit=500"><span class="url">https://10.240.100.100:6443/api/v1/nodes?limit=500</span></a></p>
<p class="normal">If you attempt to make an API call without any credentials, you will receive a permission denied request. Using a pure API request directly is something that is very common when creating a pipeline for application deployment or even a Kubernetes add-on component. However, the most common method for users to interact with Kubernetes is the <code class="inlineCode">kubectl</code> utility.</p>
<p class="normal">Every command that is issued using <code class="inlineCode">kubectl</code> calls an API endpoint behind the scenes. In the preceding example, if we executed a <code class="inlineCode">kubectl get nodes</code> command, an API request would be sent to the <code class="inlineCode">kube-apiserver</code> process using the address <code class="inlineCode">10.240.100.100</code> on port <code class="inlineCode">6443</code>.</p>
<p class="normal">The API call requested the <code class="inlineCode">/api/vi/nodes</code> endpoint, which returned a list of the nodes in the cluster:</p>
<pre class="programlisting con"><code class="hljs-con">NAME                     STATUS    ROLES                  AGE     VERSION
home-k8s-control-plane   Ready     control-plane,master   45d     v1.27.3
home-k8s-control-plane2  Ready     control-plane,master   45d     v1.27.3
home-k8s-control-plane3  Ready     control-plane,master   45d     v1.27.3
home-k8s-worker          Ready     worker                 45d     v1.27.3
home-k8s-worker2         Ready     worker                 45d     v1.27.3
home-k8s-worker3         Ready     worker                 45d     v1.27.3
</code></pre>
<p class="normal">In the absence of a functioning API server, all requests directed to your cluster will fail. Therefore, it becomes crucial to ensure the continuous operation and health of the <code class="inlineCode">kube-apiserver</code>.</p>
<p class="normal">By running three or more control plane nodes, we minimize any potential impact that could be caused by the loss of a control plane node.</p>
<p class="normal">Remember, from the last chapter, that when running more than one control plane node, you need to have a load balancer in front of the cluster’s API server. The Kubernetes API server can<a id="_idIndexMarker167"/> be fronted by most standard solutions, including F5, HAProxy, and Seesaw.</p>
<h2 class="heading-2" id="_idParaDest-85">The etcd database</h2>
<p class="normal">Describing <code class="inlineCode">etcd</code> as the foundation of your Kubernetes cluster would not be an overstatement. <code class="inlineCode">etcd</code> functions as a<a id="_idIndexMarker168"/> robust and highly efficient distributed key-value database that Kubernetes relies on to store all cluster data. Every resource present within the cluster is associated with a specific key in the <code class="inlineCode">etcd</code> database. If you can access the node or pod that hosts <code class="inlineCode">etcd</code>, you <code class="inlineCode">will</code> be able to use the <code class="inlineCode">etcdctl</code> executable to explore all the keys stored within the database. The code snippet provided below offers an example extracted from a cluster based on KinD:</p>
<pre class="programlisting con"><code class="hljs-con">etcdctl-3.5.12 --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --key=/etc/kubernetes/pki/etcd/server.key --cert=/etc/kubernetes/pki/etcd/server.crt get / --prefix --keys-only
</code></pre>
<p class="normal">The output from the preceding command contains too much data to list it all in this chapter. A base KinD cluster will return approximately 314 entries.</p>
<p class="normal">All keys start with <code class="inlineCode">/registry/&lt;resource&gt;</code>. For example, one of the keys that was returned is the <code class="inlineCode">ClusterRole</code> for the <code class="inlineCode">cluster-admin</code> key, as follows: <code class="inlineCode">/registry/clusterrolebindings/cluster-admin</code>.</p>
<p class="normal">We can use the key name to retrieve the value using the <code class="inlineCode">etcdctl</code> utility by slightly modifying our previous command, as follows:</p>
<pre class="programlisting con"><code class="hljs-con">etcdctl-3.5.12 --endpoints=https://127.0.0.1:2379 --cacert=/etc/kubernetes/pki/etcd/ca.crt --key=/etc/kubernetes/pki/etcd/server.key --cert=/etc/kubernetes/pki/etcd/server.crt get /registry/clusterrolebindings/cluster-admin
</code></pre>
<p class="normal">The output will contain characters that cannot be interpreted by your shell, but you will get an idea of the data stored in <code class="inlineCode">etcd</code>. For the <code class="inlineCode">cluster-admin</code> key, the output shows us the following:</p>
<pre class="programlisting con"><code class="hljs-con">/registry/clusterrolebindings/cluster-admin
k8s
2
rbac.authorization.k8s.io/v1ClusterRoleBinding▒
▒
cluster-admin"*$7b235e81-52de-4001-b354-994dad0279ee2▒▒▒▒Z,
rbac-defaultsb3otstrapping
+rbac.authorization.kubernetes.io/autoupdatetrue▒▒
kube-apiserverUpdaterbac.authorization.k8s.io/v▒▒▒▒FieldsV1:▒
▒{"f:metadata":{"f:annotations":{".":{},"f:rbac.authorization.kubernetes.io/autoupdate":{}},"f:labels":{".":{},"f:kubernetes.io/bootstrapping":{}}},"f:roleRef":{},"f:subjects":{}}B4
Grouprbac.authorization.k8s.iosystem:masters"7
rbac.authorization.k8s.io
cluster-admin"           ClusterRole
</code></pre>
<p class="normal">We describe the entries in <code class="inlineCode">etcd</code> to offer an understanding of how Kubernetes stores and utilizes data to manage <a id="_idIndexMarker169"/>cluster objects. While you’ve already observed the direct database output for the <code class="inlineCode">cluster-admin</code> key, in typical scenarios, you would utilize the command <code class="inlineCode">kubectl get clusterrolebinding cluster-admin -o yaml</code> to query the API server for the same data. Using <code class="inlineCode">kubectl</code>, the command would yield the following information:</p>
<figure class="mediaobject"><img alt="" height="446" src="../Images/B21165_03_02.png" width="877"/></figure>
<p class="packt_figref">Figure 3.2: kubectl ClusterRoleBinding output</p>
<p class="normal">If you look at the output from the <code class="inlineCode">kubectl</code> command and compare it with the output from the <code class="inlineCode">etcdctl</code> query, you <a id="_idIndexMarker170"/>will see matching information. You will rarely have to interact with <code class="inlineCode">etcd</code> directly; instead, you will execute <code class="inlineCode">kubectl</code> commands, and the request will go to the API server, which then queries the <code class="inlineCode">etcd</code> database for the resource’s information.</p>
<p class="normal">It’s worth noting that while <code class="inlineCode">etcd</code> is by far the most used backend database for Kubernetes, it isn’t the only one. The <strong class="keyWord">k3s</strong> project, which was originally built to strip down Kubernetes for edge use cases, replaced <code class="inlineCode">etcd</code> with relational databases. When we dive into <code class="inlineCode">vclusters</code>, which use k3s, we’ll see that it uses <strong class="keyWord">SQLite</strong> instead of <code class="inlineCode">etcd</code>.</p>
<h2 class="heading-2" id="_idParaDest-86">kube-scheduler</h2>
<p class="normal">As its name suggests, the <code class="inlineCode">kube-scheduler</code> component oversees the allocation of pods to nodes. Its primary task is to consistently monitor pods that have yet to be assigned to any specific node. The<a id="_idIndexMarker171"/> scheduler then assesses the resource requirements of each pod to determine the most suitable placement. This assessment takes multiple factors into account, including the availability of node resources, constraints, selectors, and affinity/anti-affinity rules. Nodes that satisfy these requirements are considered feasible nodes. Finally, from the resulting list of compatible nodes, the scheduler chooses the most appropriate one for scheduling the pod.</p>
<h2 class="heading-2" id="_idParaDest-87">kube-controller-manager</h2>
<p class="normal">The <strong class="keyWord">Kubernetes Controller Manager </strong>is a central control system in the Kubernetes control plane; it’s responsible for managing and coordinating other controllers that handle specific tasks for the cluster.</p>
<p class="normal">The Controller Manager contains<a id="_idIndexMarker172"/> multiple controllers, each dedicated to a specific function within the cluster. These controllers continuously monitor the cluster’s current state and adapt dynamically to maintain the desired configuration.</p>
<p class="normal">All of the controllers are contained in a single executable, reducing complexity and management. Some of the controllers included are shown in <em class="italic">Table 3.1</em>.</p>
<p class="normal">Each controller provides a unique function to a cluster, and each controller and its function is listed here:</p>
<table class="table-container" id="table001-3">
<tbody>
<tr>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Controller</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">Responsibilities </strong></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Endpoints</p>
</td>
<td class="table-cell">
<p class="normal">Monitors new services and creates endpoints to the pods with matching labels</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Namespace</p>
</td>
<td class="table-cell">
<p class="normal">Monitors actions for namespaces</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Node</p>
</td>
<td class="table-cell">
<p class="normal">Monitors the status of nodes in the cluster, detecting node failures or additions, and taking appropriate actions to maintain the desired number of nodes</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Replication</p>
</td>
<td class="table-cell">
<p class="normal">Monitors the replicas for pods, taking action to either remove a pod or add a pod to get to the desired state</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">Service Accounts</p>
</td>
<td class="table-cell">
<p class="normal">Monitors Service accounts</p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref">Table 3.1: Controllers and their functions</p>
<p class="normal">Each controller runs a non-terminating (never-ending) control loop. These control loops monitor the state of each resource, making any changes required to normalize the state of the resource. For example, if you needed to scale a deployment from one to three nodes, the replication controller would notice that the current state has one pod running, and the desired state is to have three pods running. To move the current state to the desired state, two additional pods would be requested by the replication controller.</p>
<h2 class="heading-2" id="_idParaDest-88">cloud-controller-manager</h2>
<p class="normal">This is one component that you may not have run into, depending on how your clusters are configured. Similar<a id="_idIndexMarker173"/> to the <code class="inlineCode">kube-controller-manager</code> component, this controller contains four controllers in a single binary.</p>
<p class="normal">The cloud controller provides integrations specific to a particular cloud provider’s Kubernetes service, enabling the utilization of cloud-specific functionalities such as load balancers, persistent storage, auto-scaling groups, and other features.</p>
<h1 class="heading-1" id="_idParaDest-89">Understanding the worker node components</h1>
<p class="normal">Worker nodes, as implied by their name, have the duty of carrying out tasks within a Kubernetes cluster. In our previous conversation about the <code class="inlineCode">kube-scheduler</code> element in the control plane, we emphasized that when a new pod requires scheduling, the kube-scheduler selects the suitable node for its execution. The kube-scheduler relies on data provided by the worker nodes to<a id="_idIndexMarker174"/> make this determination. This data is regularly updated to ensure a distribution of pods throughout the cluster, making the most of the cluster resources.</p>
<p class="normal">Each worker node has two main components, <code class="inlineCode">kubelet</code> and <code class="inlineCode">kube-proxy</code>.</p>
<h2 class="heading-2" id="_idParaDest-90">kubelet</h2>
<p class="normal">You may hear a worker node <a id="_idIndexMarker175"/>referred to as a <code class="inlineCode">kubelet</code>. The <code class="inlineCode">kubelet</code> is an agent that <a id="_idIndexMarker176"/>runs on all worker nodes, and it is responsible for ensuring that containers are running and healthy on the node.</p>
<h2 class="heading-2" id="_idParaDest-91">kube-proxy</h2>
<p class="normal">Contrary to the name, <code class="inlineCode">kube-proxy</code> is not <a id="_idIndexMarker177"/>a proxy server at all (though it was in the original version of Kubernetes).</p>
<p class="normal">Depending on the CNI deployed in your cluster, you may or may not have a <code class="inlineCode">kube-proxy</code> component on your nodes. CNIs like <strong class="keyWord">Cilium</strong> can be run with <code class="inlineCode">kube-proxy</code> or in a <code class="inlineCode">kube-proxyless</code> mode. In our KinD clusters, we have deployed Calico, which relies on the presence of <code class="inlineCode">kube-proxy</code>.</p>
<p class="normal">When <code class="inlineCode">kube-proxy</code> is deployed, its main purpose is to oversee network connectivity for pods and services in the cluster, providing network traffic routing to the destination pod(s).</p>
<h2 class="heading-2" id="_idParaDest-92">Container runtime</h2>
<p class="normal">Each node also needs a container runtime. A container runtime is responsible for running the containers. The first thing you might think of is Docker, and while Docker is a container runtime, it is <a id="_idIndexMarker178"/>not the only runtime option available. Over the last several years, other options have replaced Docker as the preferred container runtime for clusters.</p>
<p class="normal">The two most prominent Docker replacements are <strong class="keyWord">CRI-O</strong> and <strong class="keyWord">containerd</strong>. At the time of writing this chapter, KinD only offers official support for Docker and Red Hat’s <strong class="keyWord">Podman</strong>.</p>
<h1 class="heading-1" id="_idParaDest-93">Interacting with the API server</h1>
<p class="normal">As we mentioned earlier, you<a id="_idIndexMarker179"/> interact with the API server using either direct API requests or the <code class="inlineCode">kubectl</code> utility. We will focus on using <code class="inlineCode">kubectl</code> for the majority of our interaction in this book, but we will call out using direct API calls wherever applicable.</p>
<h2 class="heading-2" id="_idParaDest-94">Using the Kubernetes kubectl utility</h2>
<p class="normal"><code class="inlineCode">kubectl</code> is a single executable file that allows you to interact with the Kubernetes API using a <strong class="keyWord">command-line interface</strong> (<strong class="keyWord">CLI</strong>). It is available for most major operating systems and architectures, including<a id="_idIndexMarker180"/> Linux, Windows, and macOS.</p>
<p class="normal">Note: We have already installed <code class="inlineCode">kubectl</code> using the KinD script that created our cluster in <em class="chapterRef">Chapter 2</em>. Installation instructions for most operating systems are located on the Kubernetes site at <a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/"><span class="url">https://kubernetes.io/docs/tasks/tools/install-kubectl/</span></a>. Since we are using Linux as our operating system for the exercises in the book, we will cover installing <code class="inlineCode">kubectl</code> on a Linux machine. Follow these steps:</p>
<ol>
<li class="numberedList" value="1">To download the latest version of <code class="inlineCode">kubectl</code>, you can run a <code class="inlineCode">curl</code> command that will download it, as follows:
        <pre class="programlisting con-one"><code class="hljs-con">curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl
</code></pre>
</li>
<li class="numberedList">After downloading, you need to make the file executable by running the following command:
        <pre class="programlisting con-one"><code class="hljs-con">chmod +x ./kubectl
</code></pre>
</li>
<li class="numberedList">Finally, we will move the executable to our path, as follows:
        <pre class="programlisting con-one"><code class="hljs-con">sudo mv ./kubectl /usr/local/bin/kubectl
</code></pre>
</li>
</ol>
<p class="normal">You now have the latest <code class="inlineCode">kubectl</code> utility on your system and can execute <code class="inlineCode">kubectl</code> commands from any working directory.</p>
<p class="normal">Kubernetes is updated about every 4 months. This includes upgrades to the base Kubernetes cluster components and the <code class="inlineCode">kubectl</code> utility. You may run into a version mismatch between a<a id="_idIndexMarker181"/> cluster and your <code class="inlineCode">kubectl</code> command, requiring you to either upgrade or download your <code class="inlineCode">kubectl</code> executable. You can always check the version of both by running a <code class="inlineCode">kubectl</code> <code class="inlineCode">version</code> command, which will output the version of both the API server and the <code class="inlineCode">kubectl</code> client. The output from a version check is shown in the following code snippet – please note, your output may differ from our example output:</p>
<pre class="programlisting con"><code class="hljs-con">Client Version: v1.30.0-6+43a0480e94cee1
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.30.0-6+43a0480e94cee1
</code></pre>
<p class="normal">As you can see from the output, the <code class="inlineCode">kubectl</code> client is running version <code class="inlineCode">1.30.0</code> and the cluster is running <code class="inlineCode">1.30.0</code>. A minor version difference in the two will not cause any issues. In fact, the official supported version difference is within one major version release. So, if your client is running version 1.29 and the cluster is running 1.30.0, you would be within the supported version difference. While this may be supported, it doesn’t mean that you won’t run into issues if you are trying to use any new commands or resources included in the higher version. In general, you should try to keep your cluster and client version in sync to avoid any issues.</p>
<p class="normal">Through the remainder of this chapter, we will discuss Kubernetes resources and how you interact with the API server to manage each one. But before diving into the different resources, we wanted to mention one commonly overlooked option of the <code class="inlineCode">kubectl</code> utility: the <code class="inlineCode">verbose</code> option.</p>
<h2 class="heading-2" id="_idParaDest-95">Understanding the verbose option</h2>
<p class="normal">When you execute a <code class="inlineCode">kubectl</code> command, the only outputs you will see by default are any direct responses to your<a id="_idIndexMarker182"/> command. If you were to look at all pods in the <code class="inlineCode">kube-system</code> namespace, you would receive a list of all pods. In most cases, this is the desired output, but what if you issued a <code class="inlineCode">get</code> <code class="inlineCode">Pods</code> request and received an error from the API server? How could you get more information about what might be causing the error?</p>
<p class="normal">By adding the <code class="inlineCode">verbose</code> option to your <code class="inlineCode">kubectl</code> command, you can get additional details about the API call itself and any replies from the API server. Often, the replies from the API server will contain additional information that may be useful to find the root cause of the issue.</p>
<p class="normal">The <code class="inlineCode">verbose</code> option has multiple levels ranging from 0 to 9; the higher the number, the more output you will receive.</p>
<p class="normal">The following screenshot has <a id="_idIndexMarker183"/>been taken from the Kubernetes site, detailing each level and what the output will include:</p>
<figure class="mediaobject"><img alt="Figure 5.5 – Verbosity description " height="396" src="../Images/B21165_03_03.png" width="878"/></figure>
<p class="packt_figref">Figure 3.3: Verbosity description</p>
<p class="normal">You can experiment with the levels by adding the <code class="inlineCode">-v</code> or <code class="inlineCode">--v</code> option to any <code class="inlineCode">kubectl</code> command.</p>
<h2 class="heading-2" id="_idParaDest-96">General kubectl commands</h2>
<p class="normal">The CLI allows you to interact with Kubernetes in an imperative and declarative manner. Using an imperative command<a id="_idIndexMarker184"/> involves you telling Kubernetes what to do—for example, <code class="inlineCode">kubectl run nginx --image nginx</code>. This tells the API server to create a new pod called <code class="inlineCode">nginx</code> that runs an image called <code class="inlineCode">nginx</code>. While imperative commands are useful for development and quick fixes or testing, you will use declarative commands more often in a production environment. In a declarative command, you tell Kubernetes what you want. To use declarative commands, you send a manifest to<a id="_idIndexMarker185"/> the API server, written in either <strong class="keyWord">JavaScript Object Notation</strong> (<strong class="keyWord">JSON</strong>) or <strong class="keyWord">YAML Ain’t Markup Language</strong> (<strong class="keyWord">YAML</strong>), which declares what you want Kubernetes to<a id="_idIndexMarker186"/> create.</p>
<p class="normal"><code class="inlineCode">kubectl</code> includes commands and options that can provide general cluster information or information about a resource. The table below contains a cheat sheet of commands and what they <a id="_idIndexMarker187"/>are used for. We will use many of these commands in future chapters, so you will see them in action throughout the book:</p>
<table class="table-container" id="table002-2">
<tbody>
<tr>
<td class="table-cell" colspan="2">
<p class="normal"><strong class="keyWord">Cluster Commands</strong></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><code class="inlineCode">api-resources</code></p>
</td>
<td class="table-cell">
<p class="normal">Lists supported API resources</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><code class="inlineCode">api-versions</code></p>
</td>
<td class="table-cell">
<p class="normal">Lists supported API versions</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><code class="inlineCode">cluster-info</code></p>
</td>
<td class="table-cell">
<p class="normal">Lists cluster information, including the API server and other cluster endpoints</p>
</td>
</tr>
<tr>
<td class="table-cell" colspan="2">
<p class="normal"><strong class="keyWord">Object Commands</strong></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><code class="inlineCode">get &lt;object&gt;</code></p>
</td>
<td class="table-cell">
<p class="normal">Retrieves a list of all objects (i.e., pods, ingress, etc.)</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><code class="inlineCode">describe &lt;object&gt;</code></p>
</td>
<td class="table-cell">
<p class="normal">Provides details for the object</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><code class="inlineCode">logs &lt;pod name&gt;</code></p>
</td>
<td class="table-cell">
<p class="normal">Retrieve the logs for a pod</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><code class="inlineCode">edit &lt;object&gt;</code></p>
</td>
<td class="table-cell">
<p class="normal">Edits an object interactively</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><code class="inlineCode">delete &lt;object&gt;</code></p>
</td>
<td class="table-cell">
<p class="normal">Deletes an object</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><code class="inlineCode">label &lt;object&gt;</code></p>
</td>
<td class="table-cell">
<p class="normal">Labels an object</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><code class="inlineCode">annotate &lt;object&gt;</code></p>
</td>
<td class="table-cell">
<p class="normal">Annotates an object</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal"><code class="inlineCode">run </code></p>
</td>
<td class="table-cell">
<p class="normal">Creates a pod</p>
</td>
</tr>
</tbody>
</table>
<p class="packt_figref">Table 3.2: Cluster and object commands</p>
<p class="normal">With an understanding of each Kubernetes component and how to interact with the API server using imperative commands, we can now move on to Kubernetes resources and how we use <code class="inlineCode">kubectl</code> to manage them.</p>
<h1 class="heading-1" id="_idParaDest-97">Introducing Kubernetes resources</h1>
<p class="normal">In this section, we will provide a substantial amount of information. However, as this is a bootcamp, we won’t go into exhaustive <a id="_idIndexMarker188"/>details about each resource. It’s worth noting that each resource could easily warrant its own dedicated chapter or even multiple chapters in a book. Since numerous books on basic Kubernetes already cover these resources extensively, we will focus on the essential aspects necessary for a basic understanding of each resource. As we progress through the subsequent chapters, we will supplement additional details about the resources as we expand our cluster using the exercises provided in the book.</p>
<p class="normal">Prior to delving into a comprehensive understanding of Kubernetes resources, let’s begin by introducing the concept <a id="_idIndexMarker189"/>of Kubernetes manifests.</p>
<h2 class="heading-2" id="_idParaDest-98">Kubernetes manifests</h2>
<p class="normal">The files that we will use to create Kubernetes resources are referred to as manifests. A manifest can be created <a id="_idIndexMarker190"/>using YAML or JSON—most manifests use<a id="_idIndexMarker191"/> YAML, and that is the format we will use throughout the book.</p>
<div class="note">
<p class="normal">It’s important to note that while we are working with YAML files, <code class="inlineCode">kubectl</code> will convert all YAML into JSON when interacting with your API server. All API calls are made with JSON, even if the manifests are written in YAML.</p>
</div>
<p class="normal">The content of a manifest will vary depending on the resource, or resources, that will be created. At a minimum, all manifests require a base configuration that includes <code class="inlineCode">apiVersion</code>, the <code class="inlineCode">kind</code> of resource, and <code class="inlineCode">metadata</code> fields, as can be seen here:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">labels:</span>
    <span class="hljs-attr">app:</span> <span class="hljs-string">grafana</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">grafana</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">monitoring</span>
</code></pre>
<p class="normal">The preceding manifest alone is not complete; we are only showing the beginning of a full <code class="inlineCode">Deployment</code> manifest. As you can see in the file, we start with the three required fields that all manifests are required to have: the <code class="inlineCode">apiVersion</code>, <code class="inlineCode">kind</code>, and <code class="inlineCode">metadata</code> fields.</p>
<p class="normal">You may also notice that there is a format for fields in the file. YAML is very format-specific, and if the format of any line is off by even a single space, you will receive an error when you try to deploy the manifest. This takes time to get used to, and even after creating manifests for a long time, formatting issues will still pop up from time to time.</p>
<h2 class="heading-2" id="_idParaDest-99">What are Kubernetes resources?</h2>
<p class="normal">When you want to add or delete something from a cluster, you are interacting with Kubernetes resources. This interaction is how you declare your desired state for the resource, which may be to create, delete, or scale a resource. Based on the desired state, the API server will make sure<a id="_idIndexMarker192"/> that the current state equals the desired state. For example, if you have a deployment that starts with a single replica, you can change the deployment resource from 1 to 3 replicas. When the API server sees that the current state is 1, it will scale the deployment out to 3 replicas by creating the additional 2 pods.</p>
<p class="normal">To retrieve a list of resources a cluster supports, you can use the <code class="inlineCode">kubectl api-resources</code> command. The API server will reply with a list of all resources, including any valid short name, namespace support, and supported API group.</p>
<p class="normal">There are approximately 58 base resources included with a Kubernetes cluster, but it’s very common to have many more than 58 in a production cluster. Many add-on components, like Calico, will extend the Kubernetes API with new objects. As a cluster has different add-ons deployed in the cluster, don’t be surprised at 100+ resources in a list.</p>
<p class="normal">An abbreviated list of the most common resources is shown below:</p>
<table class="table-container" id="table003-2">
<tbody>
<tr>
<td class="table-cell">
<p class="normal"><strong class="keyWord">NAME</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">SHORT NAMES</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">API VERSION</strong></p>
</td>
<td class="table-cell">
<p class="normal"><strong class="keyWord">NAMESPACED</strong></p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">apiservices</p>
</td>
<td class="table-cell">
<p class="normal">apiregistration.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">certificatesigningrequests</p>
</td>
<td class="table-cell">
<p class="normal">Csr</p>
</td>
<td class="table-cell">
<p class="normal">certificates.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">clusterrolebindings</p>
</td>
<td class="table-cell">
<p class="normal">rbac.authorization.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">clusterroles</p>
</td>
<td class="table-cell">
<p class="normal">rbac.authorization.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">componentstatuses</p>
</td>
<td class="table-cell">
<p class="normal">Cs</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">configmaps</p>
</td>
<td class="table-cell">
<p class="normal">Cm</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">controllerrevisions</p>
</td>
<td class="table-cell">
<p class="normal">apps/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">cronjobs</p>
</td>
<td class="table-cell">
<p class="normal">Cj</p>
</td>
<td class="table-cell">
<p class="normal">batch/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">csidrivers</p>
</td>
<td class="table-cell">
<p class="normal">storage.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">csinodes</p>
</td>
<td class="table-cell">
<p class="normal">storage.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">csistoragecapacities</p>
</td>
<td class="table-cell">
<p class="normal">storage.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">customresourcedefinitions</p>
</td>
<td class="table-cell">
<p class="normal">crd,crds</p>
</td>
<td class="table-cell">
<p class="normal">apiextensions.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">daemonsets</p>
</td>
<td class="table-cell">
<p class="normal">Ds</p>
</td>
<td class="table-cell">
<p class="normal">apps/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">deployments</p>
</td>
<td class="table-cell">
<p class="normal">Deploy</p>
</td>
<td class="table-cell">
<p class="normal">apps/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">endpoints</p>
</td>
<td class="table-cell">
<p class="normal">Ep</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">endpointslices</p>
</td>
<td class="table-cell">
<p class="normal">discovery.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">events</p>
</td>
<td class="table-cell">
<p class="normal">Ev</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">events</p>
</td>
<td class="table-cell">
<p class="normal">Ev</p>
</td>
<td class="table-cell">
<p class="normal">events.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">flowschemas</p>
</td>
<td class="table-cell">
<p class="normal">flowcontrol.apiserver.k8s.io/v1beta3</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">horizontalpodautoscalers</p>
</td>
<td class="table-cell">
<p class="normal">Hpa</p>
</td>
<td class="table-cell">
<p class="normal">autoscaling/v2</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">ingressclasses</p>
</td>
<td class="table-cell">
<p class="normal">networking.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">ingresses</p>
</td>
<td class="table-cell">
<p class="normal">Ing</p>
</td>
<td class="table-cell">
<p class="normal">networking.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">jobs</p>
</td>
<td class="table-cell">
<p class="normal">batch/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">limitranges</p>
</td>
<td class="table-cell">
<p class="normal">Limits</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">localsubjectaccessreviews</p>
</td>
<td class="table-cell">
<p class="normal">authorization.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">mutatingwebhookconfigurations</p>
</td>
<td class="table-cell">
<p class="normal">admissionregistration.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">namespaces</p>
</td>
<td class="table-cell">
<p class="normal">Ns</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">networkpolicies</p>
</td>
<td class="table-cell">
<p class="normal">Netpol</p>
</td>
<td class="table-cell">
<p class="normal">networking.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">nodes</p>
</td>
<td class="table-cell">
<p class="normal">No</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">persistentvolumeclaims</p>
</td>
<td class="table-cell">
<p class="normal">Pvc</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">persistentvolumes</p>
</td>
<td class="table-cell">
<p class="normal">pv</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">poddisruptionbudgets</p>
</td>
<td class="table-cell">
<p class="normal">pdb</p>
</td>
<td class="table-cell">
<p class="normal">policy/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">pods</p>
</td>
<td class="table-cell">
<p class="normal">po</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">podtemplates</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">priorityclasses</p>
</td>
<td class="table-cell">
<p class="normal">pc</p>
</td>
<td class="table-cell">
<p class="normal">scheduling.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">prioritylevelconfigurations</p>
</td>
<td class="table-cell">
<p class="normal">flowcontrol.apiserver.k8s.io/v1beta3</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">profiles</p>
</td>
<td class="table-cell">
<p class="normal">projectcalico.org/v3</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">replicasets</p>
</td>
<td class="table-cell">
<p class="normal">rs</p>
</td>
<td class="table-cell">
<p class="normal">apps/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">replicationcontrollers</p>
</td>
<td class="table-cell">
<p class="normal">rc</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">resourcequotas</p>
</td>
<td class="table-cell">
<p class="normal">quota</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">rolebindings</p>
</td>
<td class="table-cell">
<p class="normal">rbac.authorization.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">roles</p>
</td>
<td class="table-cell">
<p class="normal">rbac.authorization.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">runtimeclasses</p>
</td>
<td class="table-cell">
<p class="normal">node.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">secrets</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">selfsubjectaccessreviews</p>
</td>
<td class="table-cell">
<p class="normal">authorization.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">selfsubjectrulesreviews</p>
</td>
<td class="table-cell">
<p class="normal">authorization.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">serviceaccounts</p>
</td>
<td class="table-cell">
<p class="normal">sa</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">services</p>
</td>
<td class="table-cell">
<p class="normal">svc</p>
</td>
<td class="table-cell">
<p class="normal">v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">statefulsets</p>
</td>
<td class="table-cell">
<p class="normal">sts</p>
</td>
<td class="table-cell">
<p class="normal">apps/v1</p>
</td>
<td class="table-cell">
<p class="normal">TRUE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">storageclasses</p>
</td>
<td class="table-cell">
<p class="normal">sc</p>
</td>
<td class="table-cell">
<p class="normal">storage.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
</tr>
<tr>
<td class="table-cell">
<p class="normal">subjectaccessreviews</p>
</td>
<td class="table-cell">
<p class="normal">authorization.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">tokenreviews</p>
</td>
<td class="table-cell">
<p class="normal">authentication.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">validatingwebhookconfigurations</p>
</td>
<td class="table-cell">
<p class="normal">admissionregistration.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
<tr>
<td class="table-cell">
<p class="normal">volumeattachments</p>
</td>
<td class="table-cell">
<p class="normal">storage.k8s.io/v1</p>
</td>
<td class="table-cell">
<p class="normal">FALSE</p>
</td>
<td class="table-cell"/>
</tr>
</tbody>
</table>
<p class="packt_figref">Table 3.3: Kubernetes API resources</p>
<p class="normal">As this chapter functions as<a id="_idIndexMarker193"/> a bootcamp, we will provide a short overview of the resources found in <em class="italic">Table 3.3</em>. To effectively comprehend the following chapters, it is important for you to possess a strong understanding of the objects and their respective functions.</p>
<p class="normal">Some resources will also be <a id="_idIndexMarker194"/>explained in greater detail in future chapters, including <code class="inlineCode">Ingress</code>, <code class="inlineCode">RoleBindings</code>, <code class="inlineCode">ClusterRoles</code>, <code class="inlineCode">StorageClasses</code>, and more.</p>
<h2 class="heading-2" id="_idParaDest-100">Reviewing Kubernetes resources</h2>
<p class="normal">Most resources in a cluster are run in a namespace, and to create/edit/read them, you should supply the <code class="inlineCode">-n &lt;namespace&gt;</code> option to any <code class="inlineCode">kubectl</code> command. To find a list of resources that accept a <a id="_idIndexMarker195"/>namespace option, you can reference the output from <em class="italic">Table 3.3</em>. If a resource can be referenced by a namespace, the <code class="inlineCode">NAMESPACED</code> column will show <code class="inlineCode">TRUE</code>. If the resource is only referenced by the cluster level, the <code class="inlineCode">NAMESPACED</code> column will show <code class="inlineCode">FALSE</code>.</p>
<h3 class="heading-3" id="_idParaDest-101">Apiservices</h3>
<p class="normal">Apiservices provide the primary entry point for communication and interaction between Kubernetes components and all <a id="_idIndexMarker196"/>external resources, such as users, applications, and other services. They provide a set of endpoints that allow users and applications to perform various operations, such as creating, updating, and deleting Kubernetes resources (i.e., pods, deployments, services, and namespaces).</p>
<p class="normal">Apiservices handle the authentication, authorization, and validation of requests, allowing only authorized <a id="_idIndexMarker197"/>users and applications to access or modify resources. They also handle resource versioning and other critical aspects of a Kubernetes cluster.</p>
<p class="normal">They can also extend Kubernetes functionality by developing custom controllers, operators, or other components that interact with the API Services to manage and automate various aspects of the cluster’s behavior. One example of this is our CNI, Calico, which adds 31 extra <code class="inlineCode">api-resources</code> to a cluster.</p>
<h3 class="heading-3" id="_idParaDest-102">CertificateSigningRequests</h3>
<p class="normal">A <strong class="keyWord">CertificateSigningRequest</strong> (<strong class="keyWord">CSR</strong>) allows you to<a id="_idIndexMarker198"/> request a certificate from a certificate authority. These are<a id="_idIndexMarker199"/> typically used to obtain trusted certificates for securing communication within a Kubernetes cluster.</p>
<h3 class="heading-3" id="_idParaDest-103">ClusterRoles</h3>
<p class="normal">A <code class="inlineCode">ClusterRole</code> is a collection of permissions<a id="_idIndexMarker200"/> that enable interaction with the <a id="_idIndexMarker201"/>API of the cluster. It pairs an action, or verb, with an API group to define a specific permission. For example, if you intended to restrict a <strong class="keyWord">continuous integration/continuous delivery</strong> (<strong class="keyWord">CI/CD</strong>) pipeline’s ability to only patch Deployments for updating image tags, you could utilize a <code class="inlineCode">ClusterRole</code> similar to the following:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">patch-deployment</span>
  <span class="hljs-attr">rules:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">apiGroups:</span> [<span class="hljs-string">"apps/v1"</span>]
    <span class="hljs-attr">resources:</span> [<span class="hljs-string">"deployments"</span>]
    <span class="hljs-attr">verbs:</span> [<span class="hljs-string">"get"</span>, <span class="hljs-string">"list"</span>, <span class="hljs-string">"patch"</span>]
</code></pre>
<p class="normal">A <code class="inlineCode">ClusterRole</code> can apply to <a id="_idIndexMarker202"/>APIs at both the cluster and namespace<a id="_idIndexMarker203"/> levels.</p>
<h3 class="heading-3" id="_idParaDest-104">ClusterRoleBindings</h3>
<p class="normal">Once you have specified a <code class="inlineCode">ClusterRole</code>, the<a id="_idIndexMarker204"/> next step is to create an association between the <code class="inlineCode">ClusterRole</code> and a subject using a <code class="inlineCode">ClusterRoleBinding</code>. This binding links the <code class="inlineCode">ClusterRole</code> to a user, group, or service <a id="_idIndexMarker205"/>account, granting them the permissions defined within the <code class="inlineCode">ClusterRole</code>.</p>
<p class="normal">We’ll explore <code class="inlineCode">ClusterRoleBinding</code> in more detail in <em class="chapterRef">Chapter 7</em>, <em class="italic">RBAC Policies and Auditing</em>.</p>
<h3 class="heading-3" id="_idParaDest-105">ComponentStatus</h3>
<p class="normal">The Kubernetes control plane is a crucial <a id="_idIndexMarker206"/>component for a cluster; it is essential for the operation of the cluster. <code class="inlineCode">ComponentStatus</code> is an object that shows the health and status of different Kubernetes <a id="_idIndexMarker207"/>control plane components. It provides an indicator of the overall health of a component, providing information on whether it is operating correctly or has errors.</p>
<h3 class="heading-3" id="_idParaDest-106">ConfigMaps</h3>
<p class="normal">A ConfigMap is a resource that stores data in key-value pairs, enabling the separation of configuration from your <a id="_idIndexMarker208"/>application. <code class="inlineCode">ConfigMaps</code> can hold <a id="_idIndexMarker209"/>various types of data, including literal values, files, or directories, allowing flexibility in managing your application’s configuration.</p>
<p class="normal">Here is an imperative example:</p>
<pre class="programlisting con"><code class="hljs-con">kubectl create configmap &lt;name&gt; &lt;data&gt;
</code></pre>
<p class="normal">The <code class="inlineCode">&lt;data&gt;</code> option will vary based on the source of the <code class="inlineCode">ConfigMap</code>. To use a file or a directory, you supply the <code class="inlineCode">--from-file</code> option and either the path to a file or an entire directory, as shown<a id="_idIndexMarker210"/> here:</p>
<pre class="programlisting con"><code class="hljs-con">kubectl create configmap config-test --from-file=/apps/nginx-config/nginx.conf
</code></pre>
<p class="normal">This would create a new <code class="inlineCode">ConfigMap</code> named <code class="inlineCode">config-test</code>, with the <code class="inlineCode">nginx.conf</code> key containing the content of the <code class="inlineCode">nginx.conf</code> file as the value.</p>
<p class="normal">If you need to have more than one key added in a single <code class="inlineCode">ConfigMap</code>, you put each file into a directory and create<a id="_idIndexMarker211"/> the <code class="inlineCode">ConfigMap</code> using all of the files in the directory. For example, you have three files in a directory located at <code class="inlineCode">~/config/myapp</code>. The files each contain data and are called <code class="inlineCode">config1</code>, <code class="inlineCode">config2</code>, and <code class="inlineCode">config3</code>. To create a <code class="inlineCode">ConfigMap</code> that would add each file into a key, you need to supply the <code class="inlineCode">--from-file</code> option and point to the directory, as follows:</p>
<pre class="programlisting con"><code class="hljs-con">kubectl create configmap config-test --from-file=/apps~/config/myapp
</code></pre>
<p class="normal">This would create a new <code class="inlineCode">ConfigMap</code> with three key values called <code class="inlineCode">config1</code>, <code class="inlineCode">config2</code>, and <code class="inlineCode">config3</code>. Each key will contain a value equal to the content of each file in the directory.</p>
<p class="normal">To quickly show a <code class="inlineCode">ConfigMap</code>, using the example mentioned above, we can retrieve <code class="inlineCode">it</code> using the <code class="inlineCode">get</code> command, <code class="inlineCode">kubectl get configmaps config-test</code>, resulting in the following output:</p>
<pre class="programlisting con"><code class="hljs-con">NAME             DATA    AGE
config-test      3       7s
</code></pre>
<p class="normal">The <code class="inlineCode">ConfigMap</code> is comprised of three keys, indicated by the presence of the number <code class="inlineCode">3</code> under the <code class="inlineCode">DATA</code> column. For a more detailed examination, we can utilize the <code class="inlineCode">kubectl get</code> command with the additional “<code class="inlineCode">-o yaml</code>" option appended to the <code class="inlineCode">kubectl get configmaps config-test</code> command. This will show the output of each key’s value represented in YAML format, as demonstrated below:</p>
<pre class="programlisting con"><code class="hljs-con">apiVersion: v1
data:
  config1: |
    First Configmap Value
  config2: |
    Yet Another Value from File2
  config3: |
    The last file - Config 3
kind: ConfigMap
metadata:
  creationTimestamp: "2023-06-10T01:38:51Z"
  name: config-test
  namespace: default
  resourceVersion: "6712"
  uid: a744d772-3845-4631-930c-e5661d476717
</code></pre>
<p class="normal">By examining the output, it shows that each key within the <code class="inlineCode">ConfigMap</code> corresponds to the filenames found in the directory—<code class="inlineCode">config1</code>, <code class="inlineCode">config2</code>, and <code class="inlineCode">config3</code>. Each key retains the value obtained from<a id="_idIndexMarker212"/> the data within its respective file.</p>
<p class="normal">One limitation of <code class="inlineCode">ConfigMaps</code> that <a id="_idIndexMarker213"/>you should keep in mind is that the data is easily accessible to anyone with permission to the resource. As you can see from the preceding output, a simple <code class="inlineCode">get</code> command shows the data in cleartext.</p>
<p class="normal">Due to this design, you should never store sensitive information such as a password in a <code class="inlineCode">ConfigMap</code>. Later in this section, we will cover a resource that was designed to store secret data information, called a <code class="inlineCode">Secret</code>.</p>
<h3 class="heading-3" id="_idParaDest-107">ControllerRevisions</h3>
<p class="normal">A <code class="inlineCode">ControllerRevision</code> is like a snapshot of a particular <a id="_idIndexMarker214"/>version or update to a controller’s settings. It’s mainly used by specific controllers, such as the <code class="inlineCode">StatefulSet</code> controller, to keep track of and manage changes made to <a id="_idIndexMarker215"/>their configurations as time goes on.</p>
<p class="normal">Whenever there are modifications or updates to the configuration of a resource managed by a controller, a new <code class="inlineCode">ControllerRevision</code> is created. Each revision includes the desired setup of the controller and a revision number. These revisions are stored in the Kubernetes API server, allowing you to refer to or revert to them whenever necessary.</p>
<h3 class="heading-3" id="_idParaDest-108">CronJobs</h3>
<p class="normal">If you have used Linux cronjobs in the <a id="_idIndexMarker216"/>past, then you already know what a Kubernetes <code class="inlineCode">CronJob</code> resource is. If you don’t have a Linux background, a cronjob is used to<a id="_idIndexMarker217"/> create a scheduled task. As another example, if you are a Windows person, it’s similar to Windows scheduled tasks.</p>
<p class="normal">An example manifest that creates a <code class="inlineCode">CronJob</code> is shown in the following code snippet:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">batch/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">CronJob</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">hello-world</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">schedule:</span> <span class="hljs-string">"*/1 * * * *"</span>
  <span class="hljs-attr">jobTemplate:</span>
    <span class="hljs-attr">spec:</span>
      <span class="hljs-attr">template:</span>
        <span class="hljs-attr">spec:</span>
          <span class="hljs-attr">containers:</span>
          <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">hello-world</span>
            <span class="hljs-attr">image:</span> <span class="hljs-string">busybox</span>
            <span class="hljs-attr">args:</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">/bin/sh</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">-c</span>
            <span class="hljs-bullet">-</span> <span class="hljs-string">date;</span> <span class="hljs-string">echo</span> <span class="hljs-string">Hello</span> <span class="hljs-string">World!</span>
  <span class="hljs-attr">restartPolicy:</span> <span class="hljs-string">OnFailure</span>
</code></pre>
<p class="normal">The <code class="inlineCode">schedule</code> format follows the standard <code class="inlineCode">cron</code> format. From left to right, each <code class="inlineCode">*</code> represents the following:</p>
<ul>
<li class="bulletList">Minute (0–59)</li>
<li class="bulletList">Hour (0–23)</li>
<li class="bulletList">Day (1–31)</li>
<li class="bulletList">Month (1–12)</li>
<li class="bulletList">Day of the week (0–6) (Sunday = 0, Saturday = 6)</li>
</ul>
<p class="normal"><code class="inlineCode">CronJob</code> accept step<a id="_idIndexMarker218"/> values, which allow you to create a schedule that can execute every minute, every 2 minutes, or every hour.</p>
<p class="normal">Our example manifest <a id="_idIndexMarker219"/>will create a <code class="inlineCode">CronJob</code> that runs an image called <code class="inlineCode">hello-world</code> every minute and outputs <code class="inlineCode">Hello World!</code> in the Pod log.</p>
<h3 class="heading-3" id="_idParaDest-109">CSI drivers</h3>
<p class="normal">Kubernetes uses the <code class="inlineCode">CsiDriver</code> resource to<a id="_idIndexMarker220"/> connect nodes to a storage system.</p>
<p class="normal">You can list all CSI drivers that are available on a cluster by executing the <code class="inlineCode">kubectl get csidriver</code> command. In one <a id="_idIndexMarker221"/>of our lab clusters, we are using NetApp’s SolidFire for storage, so our cluster has the Trident CSI driver installed, as can be seen here:</p>
<pre class="programlisting con"><code class="hljs-con">NAME CREATED AT
csi.trident.netapp.io 2019-09-04T19:10:47Z
</code></pre>
<h3 class="heading-3" id="_idParaDest-110">CSI nodes</h3>
<p class="normal">To avoid storing storage information<a id="_idIndexMarker222"/> in the node’s API resource, the <code class="inlineCode">CSINode</code> resource was added to the API server to store information generated by the CSI <a id="_idIndexMarker223"/>drivers. The information that is stored includes mapping Kubernetes node names to CSI node names, CSI driver availability, and the volume topology.</p>
<h3 class="heading-3" id="_idParaDest-111">CSIStorageCapacities</h3>
<p class="normal"><code class="inlineCode">CSIStorageCapacity</code> is a component that stores information about the storage capacity for a given CSI, representing the<a id="_idIndexMarker224"/> available storage<a id="_idIndexMarker225"/> capacity for a given <code class="inlineCode">StorageClass</code>. This information is used when K8s decides where to create new <code class="inlineCode">PersistentVolumes</code>.</p>
<h3 class="heading-3" id="_idParaDest-112">CustomResourceDefinitions</h3>
<p class="normal">A <strong class="keyWord">CustomResourceDefinition</strong> (<strong class="keyWord">CRD</strong>) is a way<a id="_idIndexMarker226"/> for users to make their own custom resources in a Kubernetes cluster.</p>
<p class="normal">It outlines the structure, format, and behavior <a id="_idIndexMarker227"/>of the custom resource, including its API endpoints and supported operations. Once a CRD is made and added to the cluster, it becomes a built-in resource type that can be managed using regular Kubernetes tools and APIs.</p>
<h3 class="heading-3" id="_idParaDest-113">DaemonSets</h3>
<p class="normal">A <code class="inlineCode">DaemonSet</code> enables the deployment<a id="_idIndexMarker228"/> of a pod on each node in a cluster or on a specific set of nodes. It is commonly <a id="_idIndexMarker229"/>utilized to deploy essential components like logging, which are required on every node in the cluster. Once a <code class="inlineCode">DaemonSet</code> is set up, it automatically creates a pod on each existing node.</p>
<p class="normal">Moreover, as new nodes are added to the cluster, the <code class="inlineCode">DaemonSet</code> ensures that a pod is deployed on the newly joined nodes.</p>
<h3 class="heading-3" id="_idParaDest-114">Deployments</h3>
<p class="normal">We mentioned earlier that you <a id="_idIndexMarker230"/>should never deploy a pod directly. One reason for this is that you cannot scale a pod or <a id="_idIndexMarker231"/>perform a rolling upgrade when a pod is created in this way. <code class="inlineCode">Deployments</code> offer you many advantages, including a way to manage your upgrades declaratively and the ability to roll back to previous revisions. Creating a <code class="inlineCode">Deployment</code> is actually a three-step<a id="_idIndexMarker232"/> process that is executed by the API server: a <code class="inlineCode">Deployment</code> is created, which creates a <code class="inlineCode">ReplicaSet</code>, which then creates the pod(s) for the application.</p>
<p class="normal">Even if you don’t plan to scale or perform rolling upgrades to the application, you should still use <code class="inlineCode">Deployments</code> by<a id="_idIndexMarker233"/> default so that you can leverage the features at a future date.</p>
<h3 class="heading-3" id="_idParaDest-115">Endpoints</h3>
<p class="normal">An <code class="inlineCode">Endpoint</code> maps a service to a pod or pods. This will make more sense when we explain the <code class="inlineCode">Service</code> resource. For <a id="_idIndexMarker234"/>now, you only need to know that you can<a id="_idIndexMarker235"/> use the CLI to retrieve endpoints by using the <code class="inlineCode">kubectl get endpoints</code> command. In a new KinD cluster, you will see a value for the Kubernetes API server in the default namespace, as illustrated in the following code snippet:</p>
<pre class="programlisting con"><code class="hljs-con">NAMESPACE   NAME         ENDPOINTS         AGE
default     Kubernetes   172.17.0.2:6443   22h
</code></pre>
<p class="normal">The output shows that the cluster has a service called <code class="inlineCode">kubernetes</code> that has an endpoint at the <strong class="keyWord">Internet Protocol</strong> (<strong class="keyWord">IP</strong>) address <code class="inlineCode">172.17.0.2</code> on port <code class="inlineCode">6443</code>. The IP that is returned in our example is the <a id="_idIndexMarker236"/>address to which our Docker control plane container has been assigned.</p>
<p class="normal">Later, you will see how looking at endpoints can be used to troubleshoot service and ingress issues.</p>
<h3 class="heading-3" id="_idParaDest-116">EndPointSlices</h3>
<p class="normal"><code class="inlineCode">Endpoints</code> do not scale well—they store all <a id="_idIndexMarker237"/>endpoints in a single resource. When dealing with a smaller deployment <a id="_idIndexMarker238"/>that may have a handful of pods, this isn’t an issue. As clusters grow and applications scale, endpoint sizes also grow, and this will impact the performance of your control plane and cause additional network traffic as endpoints change.</p>
<p class="normal"><code class="inlineCode">EndPointSlices</code> are designed to take on more significant and larger scenarios that require scalability and precise control over network endpoints. By default, each <code class="inlineCode">EndPointSlice</code> can hold up to 100 endpoints, which can be increased by adding the <code class="inlineCode">--max-endpoints-per-slice</code> option to the <code class="inlineCode">kube-controller-manager</code>.</p>
<p class="normal">Imagine that you have a deployment of a Service in Kubernetes with a large number of pods. If one of those pods is deleted, Kubernetes will only update the specific slice that contains the information about that pod. When the updated slice is distributed across the cluster, it will <a id="_idIndexMarker239"/>only include details for a smaller subset of pods. By doing so, the cluster network remains efficient and avoids becoming overwhelmed with excessive data.</p>
<h3 class="heading-3" id="_idParaDest-117">Events</h3>
<p class="normal">The <code class="inlineCode">Events</code> resource will display <a id="_idIndexMarker240"/>any events for a namespace. To get a list of events for the <code class="inlineCode">kube-system</code> namespace, you<a id="_idIndexMarker241"/> would use the <code class="inlineCode">kubectl get events -n kube-system</code> command.</p>
<h3 class="heading-3" id="_idParaDest-118">FlowSchemas</h3>
<p class="normal">Kubernetes clusters have predefined <a id="_idIndexMarker242"/>settings that manage the handling of <a id="_idIndexMarker243"/>concurrent requests to the API server, ensuring that the traffic does not overload the server. However, you have the flexibility to customize and configure your own flow schema and priority levels for requests directed at the API server in your clusters. This allows you to define specific rules and preferences for how requests are handled and prioritized, tailoring the behavior of the API server to suit your specific requirements and workload.</p>
<p class="normal">For example, you have a namespace that has an important application deployed. You could create a <code class="inlineCode">FlowSchema</code> with a high priority so the API server would handle requests for the namespace before other requests.</p>
<h3 class="heading-3" id="_idParaDest-119">HorizontalPodAutoscalers</h3>
<p class="normal">One of the biggest advantages of running a<a id="_idIndexMarker244"/> workload on a Kubernetes cluster is the ability to automatically scale your pods. While<a id="_idIndexMarker245"/> you can scale using the <code class="inlineCode">kubectl</code> command or by editing a manifest’s replica count, these are not automated and require manual intervention.</p>
<p class="normal"><strong class="keyWord">Horizontal Pod Autoscalers</strong> (<strong class="keyWord">HPAs</strong>) provide the ability to scale an application based on a set of criteria. Using <a id="_idIndexMarker246"/>metrics such as CPU and memory usage, or your own custom metrics, you can set a rule to scale your pods out when you need more pods to maintain your service level.</p>
<p class="normal">After a cooldown period, Kubernetes will scale the application back to the minimum number of pods defined in the policy.</p>
<p class="normal">To quickly create an HPA for an NGINX Deployment, we can execute a <code class="inlineCode">kubectl</code> command using the <code class="inlineCode">autoscale</code> option, as follows:</p>
<pre class="programlisting con"><code class="hljs-con">kubectl autoscale deployment nginx --cpu-percent=50 --min=1 --max=5
</code></pre>
<p class="normal">You can also create a Kubernetes manifest to create your HPAs. Using the same options as those we did in the CLI, our manifest would look like this:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">autoscaling/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">HorizontalPodAutoscaler</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-deployment</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">maxReplicas:</span> <span class="hljs-number">5</span>
  <span class="hljs-attr">minReplicas:</span> <span class="hljs-number">1</span>
  <span class="hljs-attr">scaleTargetRef:</span>
    <span class="hljs-attr">apiVersion:</span> <span class="hljs-string">apps/v1</span>
    <span class="hljs-attr">kind:</span> <span class="hljs-string">Deployment</span>
    <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-deployment</span>
  <span class="hljs-attr">targetCPUUtilizationPercentage:</span> <span class="hljs-number">50</span>
</code></pre>
<p class="normal">Both options will create an HPA that will scale <code class="inlineCode">nginx-deployment</code> up to 5 replicas when the <code class="inlineCode">Deployment</code> hits a CPU utilization of 50%. Once the <code class="inlineCode">Deployment</code> usage falls below 50% and the cooldown <a id="_idIndexMarker247"/>period is reached (by default, 5 minutes), the replica count will be reduced to 1.</p>
<h3 class="heading-3" id="_idParaDest-120">IngressClasses</h3>
<p class="normal"><code class="inlineCode">IngressClasses</code> allow you to define <a id="_idIndexMarker248"/>and oversee various types of Ingress controllers. They offer the ability to<a id="_idIndexMarker249"/> personalize and adjust the behavior of these controllers according to specific needs, providing customizable routing of incoming traffic to services. <code class="inlineCode">IngressClasses</code> allow you to manage and fine-tune Ingress controllers, ensuring that traffic is handled in a manner that aligns with your requirements.</p>
<p class="normal">The most important role an <code class="inlineCode">IngressClass</code> has is to let you define multiple Ingress controllers in a single cluster. For instance, the Kubernetes Dashboard version 3 uses a specific <code class="inlineCode">IngressClass</code> to make sure its <code class="inlineCode">Ingress</code> objects are bound to an NGINX instance that doesn’t have a <code class="inlineCode">LoadBalancer</code>, so it can’t be accessed from outside the cluster. You can also use this feature to connect Ingress controllers to different networks.</p>
<h3 class="heading-3" id="_idParaDest-121">Ingress</h3>
<p class="normal">An <code class="inlineCode">Ingress</code> resource is a tool<a id="_idIndexMarker250"/> that lets you <a id="_idIndexMarker251"/>create rules for incoming HTTP and HTTPS traffic to services using options like hostnames, paths, or request headers. It acts as a middleman between the external traffic and the services running in the cluster. By using <code class="inlineCode">Ingress</code>, you can define how different types of traffic should be routed to specific services, giving you granular control over the flow of incoming requests.</p>
<p class="normal">We will discuss <code class="inlineCode">Ingress</code> in depth<a id="_idIndexMarker252"/> in the next chapter, but a quick description of what <code class="inlineCode">Ingress</code> provides is that it allows you to expose your application to the outside world using an assigned URL.</p>
<h3 class="heading-3" id="_idParaDest-122">Jobs</h3>
<p class="normal"><code class="inlineCode">Jobs</code> allow you to execute <a id="_idIndexMarker253"/>a specific number of executions of a pod or pods. Unlike a <code class="inlineCode">CronJob</code> resource, these pods are<a id="_idIndexMarker254"/> not run on a set schedule, but rather they will execute once when they are created.</p>
<h3 class="heading-3" id="_idParaDest-123">LimitRanges</h3>
<p class="normal">We will discuss the <code class="inlineCode">Quota</code> resource later<a id="_idIndexMarker255"/> in this chapter, but a <code class="inlineCode">LimitRange</code> is a configuration that allows you to establish and enforce specific boundaries and <a id="_idIndexMarker256"/>restrictions on resource allocations for pods and containers within a given namespace. By utilizing <code class="inlineCode">LimitRanges</code>, you can define limits on resources, such as CPU, memory, and storage, ensuring that pods and containers operate efficiently and prevent any negative impact on the overall cluster environment.</p>
<h3 class="heading-3" id="_idParaDest-124">LocalSubjectAccessReview</h3>
<p class="normal"><code class="inlineCode">LocalSubjectAccessReview</code> is a<a id="_idIndexMarker257"/> feature that helps you check if a user or group in the cluster has the required permissions<a id="_idIndexMarker258"/> to perform a specific action on a local resource. It enables you to review access permissions directly within the cluster without relying on external API requests.</p>
<p class="normal">Using <code class="inlineCode">LocalSubjectAccessReview</code>, you can specify the user or group identity along with the action and resource you want to evaluate. The Kubernetes API server will then verify the permissions against the local access control policies. It will respond with whether the requested action is allowed or denied.</p>
<h3 class="heading-3" id="_idParaDest-125">MutatingWebhookConfiguration</h3>
<p class="normal"><code class="inlineCode">MutatingWebhookConfiguration</code> is used to<a id="_idIndexMarker259"/> create webhooks<a id="_idIndexMarker260"/> that can intercept and modify requests sent to the API server, providing a way to automatically modify the requested resources.</p>
<p class="normal">A <code class="inlineCode">MutatingWebhookConfiguration</code> contains a set of rules that determine which requests should be intercepted and processed by a webhook. When a request matches the defined rules, the <code class="inlineCode">MutatingWebhookConfiguration</code> triggers the corresponding webhooks, which <a id="_idIndexMarker261"/>can then modify the payload. Modifications can include adding, removing, or modifying fields and annotations in the resource being created or updated.</p>
<h3 class="heading-3" id="_idParaDest-126">Namespaces</h3>
<p class="normal">A <code class="inlineCode">Namespace</code> is a resource to divide a cluster<a id="_idIndexMarker262"/> into logical units. Each <code class="inlineCode">Namespace</code> allows granular management of<a id="_idIndexMarker263"/> resources, including permissions, quotas, and reporting.</p>
<p class="normal">The <code class="inlineCode">Namespace</code> resource is used for namespace tasks, which are cluster-level operations. Using the <code class="inlineCode">namespace</code> resource, you can execute commands including <code class="inlineCode">create</code>, <code class="inlineCode">delete</code>, <code class="inlineCode">edit</code>, and <code class="inlineCode">get</code>.</p>
<p class="normal">The syntax for the command is <code class="inlineCode">kubectl &lt;verb&gt; ns &lt;namespace name&gt;</code>.</p>
<p class="normal">For example, to describe the <code class="inlineCode">kube-system</code> namespace, we would execute a <code class="inlineCode">kubectl describe namespaces kube-system</code> command.</p>
<p class="normal">This will return information for the namespace, including any labels, annotations, and assigned quotas, as illustrated in the following code snippet:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">Name:</span> <span class="hljs-string">kube-system</span>
<span class="hljs-attr">Labels:</span> <span class="hljs-string">&lt;none&gt;</span>
<span class="hljs-attr">Annotations:</span> <span class="hljs-string">&lt;none&gt;</span>
<span class="hljs-attr">Status:</span> <span class="hljs-string">Active</span>
<span class="hljs-literal">No</span> <span class="hljs-string">resource</span> <span class="hljs-string">quota.</span>
<span class="hljs-literal">No</span> <span class="hljs-string">LimitRange</span>
 <span class="hljs-string">resource.</span>
</code></pre>
<p class="normal">In the preceding output, you can see that this namespace does not have any labels, annotations, or resource quotas assigned.</p>
<p class="normal">This section is only meant to introduce the concept of namespaces as a management unit in multi-tenant clusters. If you plan to run clusters with multiple tenants, you need to understand how namespaces can be used to secure a cluster.</p>
<h3 class="heading-3" id="_idParaDest-127">NetworkPolicies</h3>
<p class="normal"><code class="inlineCode">NetworkPolicy</code> resources let you define how network traffic, both ingress (incoming) and egress (outgoing), can flow through <a id="_idIndexMarker264"/>your cluster. They allow you to use Kubernetes native constructs to<a id="_idIndexMarker265"/> define which pods can talk to other Pods. If you’ve ever used security groups in <strong class="keyWord">Amazon Web Services</strong> (<strong class="keyWord">AWS</strong>) to lock down access between two groups of systems, it’s a similar <a id="_idIndexMarker266"/>concept. As an example, the following policy will allow traffic on port <code class="inlineCode">443</code> to pods in the <code class="inlineCode">myns</code> namespace from any namespace with the <code class="inlineCode">app.kubernetes.io/name: ingress-nginx</code> label on it (which is the default label for the <code class="inlineCode">nginx-ingress</code> namespace):</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">networking.k8s.io/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">NetworkPolicy</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">allow-from-ingress</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">myns</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">PodSelector:</span> {}
  <span class="hljs-attr">policyTypes:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-string">Ingress</span>
  <span class="hljs-attr">ingress:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">from:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">namespaceSelector:</span>
        <span class="hljs-attr">matchLabels:</span>
          <span class="hljs-attr">app.kubernetes.io/name:</span> <span class="hljs-string">ingress-nginx</span>
    <span class="hljs-attr">ports:</span>
    <span class="hljs-bullet">-</span> <span class="hljs-attr">protocol:</span> <span class="hljs-string">TCP</span>
      <span class="hljs-attr">port:</span> <span class="hljs-number">443</span>
</code></pre>
<p class="normal">A <code class="inlineCode">NetworkPolicy</code> is another resource that you can use to secure a cluster. They should be used in all production<a id="_idIndexMarker267"/> clusters, but in a multi-tenant cluster, they should be considered a <strong class="keyWord">must-have</strong> to secure each namespace in the cluster.</p>
<h3 class="heading-3" id="_idParaDest-128">Nodes</h3>
<p class="normal">The <code class="inlineCode">nodes</code> resource is a <a id="_idIndexMarker268"/>cluster-level resource that is used to interact with the cluster’s nodes. This resource can be used with various actions including <code class="inlineCode">get</code>, <code class="inlineCode">describe</code>, <code class="inlineCode">label</code>, and <code class="inlineCode">annotate</code>.</p>
<p class="normal">To retrieve a list of all of the nodes in a cluster using <code class="inlineCode">kubectl</code>, you need to execute a <code class="inlineCode">kubectl get nodes</code> command. On a new KinD cluster running a simple one-node cluster, this would display as follows:</p>
<pre class="programlisting con"><code class="hljs-con">NAME                STATUS   ROLES   AGE   VERSION
kind-control-plane  Ready    master  22h   v1.30.0
</code></pre>
<p class="normal">You can also use the nodes resource to get details of a single node using the <code class="inlineCode">describe</code> command. To get a description of the KinD node listed previously, we can execute <code class="inlineCode">kubectl describe node kind-control-plane</code>, which would return details on the node, including consumed resources, running pods, IP <strong class="keyWord">classless inter-domain routing</strong> (<strong class="keyWord">CIDR</strong>) ranges, and more.</p>
<h3 class="heading-3" id="_idParaDest-129">PersistentVolumeClaims</h3>
<p class="normal">A PVC is a namespaced resource that is <a id="_idIndexMarker269"/>used by a pod to consume persistent storage. A PVC uses a <strong class="keyWord">persistent volume</strong> (<strong class="keyWord">PV</strong>) to map the<a id="_idIndexMarker270"/> actual storage resource, which <a id="_idIndexMarker271"/>can be on any support storage system, including <strong class="keyWord">NFS</strong> and <strong class="keyWord">iSCSI</strong>.</p>
<p class="normal">As with most resources we have discussed, you can issue <code class="inlineCode">get</code>, <code class="inlineCode">describe</code>, and <code class="inlineCode">delete</code> commands on a PVC <a id="_idIndexMarker272"/>resource. Since these are used by pods in the namespace, PVCs must be created in the same namespace as the pod(s) that will use the PVC.</p>
<h3 class="heading-3" id="_idParaDest-130">PersistentVolumes</h3>
<p class="normal">PVs are used by PVCs to create a link <a id="_idIndexMarker273"/>between the PVC and the underlying storage system. Manually maintaining PVs is a messy, manual task, and it should be <a id="_idIndexMarker274"/>avoided. Instead, Kubernetes includes the ability to manage most common storage systems using the <strong class="keyWord">Container Storage Interface</strong> (<strong class="keyWord">CSI</strong>).</p>
<p class="normal">Most CSI solutions that are <a id="_idIndexMarker275"/>used in an Enterprise cluster provide auto-provisioning support, as we discussed in <em class="chapterRef">Chapter 2</em> when we introduced Rancher’s local provisioner. Solutions that support auto-provisioning remove the administrative overhead that is required to create PVs manually, taking care of the creation and mapping of the PVs to PVCs automatically.</p>
<h3 class="heading-3" id="_idParaDest-131">PodDisruptionBudgets</h3>
<p class="normal">A <code class="inlineCode">PodDisruptionBudget</code> (PDB) is a resource<a id="_idIndexMarker276"/> that creates boundaries on the maximum number of unavailable pods at any given<a id="_idIndexMarker277"/> time. Its purpose is to prevent situations where multiple pods are terminated simultaneously, which could result in service disruptions or failures. By defining the minimum number of available pods, referred to as the <code class="inlineCode">"minAvailable"</code> parameter, you can guarantee that a specific quantity of pods remains functional during maintenance or other disruptive occurrences.</p>
<p class="normal">The <code class="inlineCode">kube-scheduler</code> in a cloud will use this information to figure out how to replace nodes during an upgrade. You need to be careful when using a <code class="inlineCode">PodDisruptionBudget</code> because you could find a situation where an upgrade is halted.</p>
<h3 class="heading-3" id="_idParaDest-132">Pods</h3>
<p class="normal">The pod resource is used to<a id="_idIndexMarker278"/> interact with the pods that are running your container(s). Using the <code class="inlineCode">kubectl</code> utility, you <a id="_idIndexMarker279"/>can use commands such as <code class="inlineCode">get</code>, <code class="inlineCode">delete</code>, and <code class="inlineCode">describe</code>. For example, if you wanted to get a list of all pods in the <code class="inlineCode">kube-system</code> namespace, you would execute a <code class="inlineCode">kubectl get Pods -n kube-system</code> command that would return all pods in the namespace, as follows:</p>
<pre class="programlisting con"><code class="hljs-con">NAME                                             READY  STATUS   RESTARTS   AGE
calico-kube-controllers-c6c8dc655-vnrt7          1/1    Running  0          15m
calico-node-4d9px                                1/1    Running  0          15m
calico-node-r4zsj                                1/1    Running  0          15m
coredns-558bd4d5db-8mxzp                         1/1    Running  0          15m
coredns-558bd4d5db-fxnkt                         1/1    Running  0          15m
etcd-cluster01-control-plane                     1/1    Running  0          15m
kube-apiserver-cluster01-control-plane           1/1    Running  0          15m
kube-controller-manager-cluster01-control-plane  1/1    Running  0          15m
kube-proxy-npxqd                                 1/1    Running  0          15m
kube-proxy-twn7s                                 1/1    Running  0          15m
kube-scheduler-cluster01-control-plane           1/1    Running  0          15m
</code></pre>
<p class="normal">While you can create a pod directly, you should avoid doing so unless you are using a pod for quick troubleshooting. pods that <a id="_idIndexMarker280"/>are created directly cannot use many of the features provided by Kubernetes, including scaling, automatic restarts, or rolling upgrades.</p>
<p class="normal">Instead of creating a pod directly, you should use a <code class="inlineCode">Deployment</code>, <code class="inlineCode">StatefulSet</code>, or, in some rare cases, <code class="inlineCode">ReplicaSet</code> resource or replication controller.</p>
<h3 class="heading-3" id="_idParaDest-133">PodTemplates</h3>
<p class="normal"><code class="inlineCode">PodTemplates</code> provide a way to<a id="_idIndexMarker281"/> create templates or blueprints for creating <a id="_idIndexMarker282"/>pods. They function as reusable configurations that include the desired specifications and settings for pods. They include the metadata and specifications of a pod, including the name, labels, containers, volumes, and other attributes.</p>
<p class="normal"><code class="inlineCode">PodTemplates</code> are commonly used in other Kubernetes objects such as <code class="inlineCode">ReplicaSets</code>, <code class="inlineCode">Deployments</code>, and <code class="inlineCode">StatefulSets</code>. These resources rely on a <code class="inlineCode">PodTemplate</code> to generate and manage a collection of pods with<a id="_idIndexMarker283"/> consistent configurations and behavior.</p>
<h3 class="heading-3" id="_idParaDest-134">PriorityClasses</h3>
<p class="normal"><code class="inlineCode">PriorityClasses</code> provide a way to prioritize pods based on their importance. This allows the Kubernetes scheduler to<a id="_idIndexMarker284"/> make better decisions regarding resource<a id="_idIndexMarker285"/> allocation and pod scheduling in a cluster.</p>
<p class="normal">To define <code class="inlineCode">PriorityClasses</code>, you create a new <code class="inlineCode">PriorityClass</code> resource associated with numeric values that indicate the priority level. pods with higher priority values are given priority over lower values when it comes to resource allocation and scheduling.</p>
<p class="normal">Using <code class="inlineCode">PriorityClasses</code>, you can guarantee that crucial workloads are given higher priority in terms of resource allocation and scheduling, providing the necessary resources to run smoothly.</p>
<h3 class="heading-3" id="_idParaDest-135">PriorityLevelConfigurations</h3>
<p class="normal"><code class="inlineCode">PriorityLevelConfigurations</code> are objects <a id="_idIndexMarker286"/>that help define priority levels for requests sent to the API server. They provide <a id="_idIndexMarker287"/>control over how API requests are processed and prioritized within a cluster. Using <code class="inlineCode">PriorityLevelConfigurations</code>, you can establish multiple priority levels, assigned to specific attributes. These attributes include setting limits on the maximum number of queries per second (QPS) and concurrent requests for a particular priority level. This allows for more efficient resource management and allocation based on the importance of different API requests.</p>
<p class="normal"><code class="inlineCode">PriorityLevelConfigurations</code> allow you to enforce policies that ensure critical requests always receive enough resources, providing flexibility in managing the processing and allocation of resources for API requests.</p>
<h3 class="heading-3" id="_idParaDest-136">ReplicaSets</h3>
<p class="normal"><code class="inlineCode">ReplicaSets</code> can be used to create a<a id="_idIndexMarker288"/> pod or a set of pods (replicas). Similar to the <code class="inlineCode">ReplicationController</code> resource, a <code class="inlineCode">ReplicaSet</code> will maintain the set number of pods defined in the replica count. If there <a id="_idIndexMarker289"/>are too few pods, Kubernetes will make up the difference and create the missing pods. If there are too many pods for a <code class="inlineCode">ReplicaSet</code>, Kubernetes will delete pods until the <a id="_idIndexMarker290"/>number is equal to the replica count set.</p>
<p class="normal">In general, you should avoid creating <code class="inlineCode">ReplicaSets</code> directly. Instead, you should create a <code class="inlineCode">Deployment</code>, which will create and manage a <code class="inlineCode">ReplicaSet</code>.</p>
<h3 class="heading-3" id="_idParaDest-137">Replication controllers</h3>
<p class="normal">Replication controllers will manage the<a id="_idIndexMarker291"/> number of running pods, keeping the desired replicas specified running at all times. If you<a id="_idIndexMarker292"/> create a replication controller and set the replica count to <code class="inlineCode">5</code>, the controller will always keep five pods of the application running.</p>
<p class="normal">Replication controllers have been replaced by the <code class="inlineCode">ReplicaSet</code> resource, which we just discussed in its own section. While you can still use replication controllers, you should consider using a <code class="inlineCode">Deployment</code> or a <code class="inlineCode">ReplicaSet</code>.</p>
<h3 class="heading-3" id="_idParaDest-138">ResourceQuotas</h3>
<p class="normal">It is becoming very common to share a<a id="_idIndexMarker293"/> Kubernetes cluster between multiple teams, referred to as a <strong class="keyWord">multi-tenant cluster</strong>. Since you will have<a id="_idIndexMarker294"/> multiple teams working in a single cluster, you should create quotas to limit the <a id="_idIndexMarker295"/>potential of a single tenant consuming all the resources in a cluster or on a node.</p>
<p class="normal">Limits can be set on most cluster resources, including the following:</p>
<ul>
<li class="bulletList">Central processing unit (CPU)</li>
<li class="bulletList">Memory</li>
<li class="bulletList">PVCs</li>
<li class="bulletList"><code class="inlineCode">ConfigMaps</code></li>
<li class="bulletList">Deployments</li>
<li class="bulletList">Pods, and more</li>
</ul>
<p class="normal">Setting a limit will stop any additional resources from being created once the limit is hit. If you set a limit of 10 pods for a namespace and a user creates a new <code class="inlineCode">Deployment</code> that attempts to start 11 Pods, the eleventh pod will fail to start up and the user will receive an error.</p>
<p class="normal">A basic manifest file to create a quota for memory and CPU would look like this:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">ResourceQuota</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">base-memory-cpu</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">hard:</span>
    <span class="hljs-attr">requests.cpu:</span> <span class="hljs-string">"</span><span class="hljs-string">2"</span>
    <span class="hljs-attr">requests.memory:</span> <span class="hljs-string">8Gi</span>
    <span class="hljs-attr">limits.cpu:</span> <span class="hljs-string">"4"</span>
    <span class="hljs-attr">limits.memory:</span> <span class="hljs-string">16Gi</span>
</code></pre>
<p class="normal">This will set a limit on the total amount of resources the namespace can use for CPU and memory requests and limits.</p>
<p class="normal">Many of the options you can <a id="_idIndexMarker296"/>set in a quota are self-explanatory, like pods, PVCs, services, etc. When you set a limit, it means that the set limit is the maximum allowed for that resource in the namespace. For example, if you set a limit on a pod to 5, when an attempt is made to <a id="_idIndexMarker297"/>create a sixth pod in that namespace, it will be denied.</p>
<p class="normal">Some quotas have more than one option that can be set: specifically, CPU and memory. In our example, both resources have set a request and a limit. Both values are very important to understand to ensure efficient use of your resources and to limit the potential availability of the application.</p>
<p class="normal">A request is essentially a reservation of that specific resource. When a pod is deployed, you should always set a request on your CPU and memory, and the value should be the minimum required to start your application. This value will be used by the scheduler to find a node that meets the request that has been set. If there are no nodes with the requested resource available, the pod will fail to be scheduled.</p>
<p class="normal">Now, since a request will reserve the resource, that means once all nodes in the cluster have 100% of requests assigned, any additional pod creations will be denied since the requests are at 100%. Even if your actual cluster CPU or memory utilization is at 10%, pods will fail to be scheduled since the request, or <strong class="keyWord">reservation</strong>, is at 100%. If requests are not carefully thought out, it will lead to wasted resources, and that will lead to an increased cost to run the platform.</p>
<p class="normal">Limits on CPU and memory set the maximum value that the pod will be able to utilize. This is different from a request since limits are not a reservation of the resource. However, limits still need to be carefully planned out from an application side. If you set the CPU limit too low, the application may experience performance issues, and if you set the memory limit too low, the pod will be terminated, impacting availability while it is restarted.</p>
<p class="normal">Once a quota has been created, you can view the usage using the <code class="inlineCode">kubectl describe</code> command. In our example, we named the <code class="inlineCode">ResourceQuota</code> as <code class="inlineCode">base-memory-cpu</code>.</p>
<p class="normal">To view the usage, we will execute the <code class="inlineCode">kubectl get resourcequotas base-memory-cpu</code> command, resulting in the following output:</p>
<pre class="programlisting con"><code class="hljs-con">Name: base-memory-cpu
Namespace: default
Resource Used Hard
-------- ---- ----
limits.cpu 0 4
limits.memory 0 16Gi
requests.cpu 0 2
requests.memory 0 8Gi
</code></pre>
<p class="normal"><code class="inlineCode">ResourceQuotas</code> serve as a means to manage and control the allocation of resources within a cluster. They allow you to assign specific CPU and memory resources to individual namespaces, ensuring that each<a id="_idIndexMarker298"/> tenant has sufficient resources to run their applications effectively. Additionally, <code class="inlineCode">ResourceQuotas</code> act as a safeguard, preventing a poorly optimized<a id="_idIndexMarker299"/> or resource-intensive application from adversely affecting the performance of other applications in the cluster.</p>
<h3 class="heading-3" id="_idParaDest-139">RoleBindings</h3>
<p class="normal">The <code class="inlineCode">RoleBinding</code> resource is how you <a id="_idIndexMarker300"/>associate a <code class="inlineCode">Role</code> or <code class="inlineCode">ClusterRole</code> with a <a id="_idIndexMarker301"/>subject and namespace. For instance, the following <code class="inlineCode">RoleBinding</code> will allow the <code class="inlineCode">aws-codebuild</code> user to apply the <code class="inlineCode">patch-openunison ClusterRole</code> to the <code class="inlineCode">openunison</code> namespace:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">rbac.authorization.k8s.io/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">RoleBinding</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">patch-openunison</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">openunison</span>
<span class="hljs-attr">subjects:</span>
<span class="hljs-bullet">-</span> <span class="hljs-attr">kind:</span> <span class="hljs-string">User</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">aws-codebuild</span>
  <span class="hljs-attr">apiGroup:</span> <span class="hljs-string">rbac.authorization.k8s.io</span>
<span class="hljs-attr">roleRef:</span>
  <span class="hljs-attr">kind:</span> <span class="hljs-string">ClusterRole</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">patch-deployment</span>
  <span class="hljs-attr">apiGroup:</span> <span class="hljs-string">rbac.authorization.k8s.io</span>
</code></pre>
<p class="normal">Even though this references a <code class="inlineCode">ClusterRole</code>, it will only apply to the <code class="inlineCode">openunison</code> namespace. If the <code class="inlineCode">aws-codebuild</code> user tries to patch a Deployment in another namespace, the API server will stop it.</p>
<h3 class="heading-3" id="_idParaDest-140">Roles</h3>
<p class="normal">As with a <code class="inlineCode">ClusterRole</code>, Roles combine API groups and actions to define a set of permissions that can be assigned to a<a id="_idIndexMarker302"/> subject. The difference between a <code class="inlineCode">ClusterRole</code> and a <code class="inlineCode">Role</code> is that a <code class="inlineCode">Role</code> can only have resources defined at the namespace level <a id="_idIndexMarker303"/>and they apply only within a specific namespace.</p>
<h3 class="heading-3" id="_idParaDest-141">RuntimeClasses</h3>
<p class="normal"><code class="inlineCode">RuntimeClasses</code> are used to set up and customize different runtime environments for running containers. They provide the<a id="_idIndexMarker304"/> flexibility to<a id="_idIndexMarker305"/> choose and configure the container runtime that best suits your workloads. By using <code class="inlineCode">RuntimeClasses</code>, you can fine-tune the container runtime according to your specific requirements.</p>
<p class="normal">Each <code class="inlineCode">RuntimeClass</code> is linked to a specific container runtime, like Docker or Containerd. They include configurable parameters that define how the chosen container runtime behaves. These parameters include resource limits, security configurations, and environment variables.</p>
<h3 class="heading-3" id="_idParaDest-142">Secrets</h3>
<p class="normal">Earlier, we described how to <a id="_idIndexMarker306"/>use a <code class="inlineCode">ConfigMap</code> resource to store configuration information. We mentioned that <code class="inlineCode">ConfigMap</code> should<a id="_idIndexMarker307"/> never be used to store any type of sensitive data. This is the job of a <code class="inlineCode">Secret</code>.</p>
<p class="normal"><code class="inlineCode">Secrets</code> are stored as Base64-encoded strings, which aren’t a form of encryption. So, why separate <code class="inlineCode">Secrets</code> from <code class="inlineCode">ConfigMap</code>? Providing a separate resource type offers an easier way to maintain access controls and the ability to inject sensitive information using an external secret management system.</p>
<p class="normal"><code class="inlineCode">Secrets</code> can be created using a file, directory, or from a literal string. As an example, we have a MySQL image we want to execute, and we would like to pass the password to the pod using a Secret. On our workstation, we have a file called <code class="inlineCode">dbpwd</code> in our current working directory that has our password in it. Using the <code class="inlineCode">kubectl</code> command, we can create a <code class="inlineCode">Secret</code> by executing <code class="inlineCode">kubectl create secret generic mysql-admin --from-file=./dbpwd</code>.</p>
<p class="normal">This would create a new <code class="inlineCode">Secret</code> called <code class="inlineCode">mysql-admin</code> in the current namespace, with the content of the <code class="inlineCode">dbpwd</code> file. Using <code class="inlineCode">kubectl</code>, we can get the output of the <code class="inlineCode">Secret</code> by running the <code class="inlineCode">kubectl get secret mysql-admin -o yaml</code> command, which would output the following:</p>
<pre class="programlisting con"><code class="hljs-con">apiVersion: v1
data:
  dbpwd: c3VwZXJzZWNyZXQtcGFzc3dvcmQK
kind: Secret
metadata:
  creationTimestamp: "2020-03-24T18:39:31Z"
  name: mysql-admin
  namespace: default
  resourceVersion: "464059"
  uid: 69220ebd-c9fe-4688-829b-242ffc9e94fc
type: Opaque
</code></pre>
<p class="normal">Looking at the preceding output, you<a id="_idIndexMarker308"/> can see that the <code class="inlineCode">data</code> section contains the name of our file and then a Base64-encoded value, which was created from the content of the file.</p>
<p class="normal">If we copy the Base64 value <a id="_idIndexMarker309"/>from the <code class="inlineCode">Secret</code> and pipe it out to the <code class="inlineCode">base64</code> utility, we can easily decode the password, as follows:</p>
<pre class="programlisting con"><code class="hljs-con">echo c3VwZXJzZWNyZXQtcGFzc3dvcmQK | base64 -d
supersecret-password
</code></pre>
<p class="normal">When using the <code class="inlineCode">echo</code> command to Base64-encode strings, add the <code class="inlineCode">-n</code> flag to avoid adding an additional <code class="inlineCode">\n</code>. Instead of <code class="inlineCode">echo 'test' | base64</code>, use <code class="inlineCode">echo -n 'test' | base64</code>.</p>
<p class="normal">Everything is stored in <code class="inlineCode">etcd</code> but we are concerned that someone may be able to hack into the <code class="inlineCode">etcd</code> node and steal a copy of the etcd database. Once someone has a copy of the database, they could easily use the <code class="inlineCode">etcdctl</code> utility to look through the content to retrieve all of our Base64-encoded Secrets. Luckily, Kubernetes added a feature to encrypt <code class="inlineCode">Secrets</code> when they are written to a database.</p>
<p class="normal">Enabling this feature can be fairly complex for many users, and while it sounds like a good idea, it does present some potential issues that you should consider before implementing it. If you would like to read the steps on encrypting your Secrets at rest, you can view these on the Kubernetes site at <a href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/"><span class="url">https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/</span></a>.</p>
<p class="normal">Another option to secure Secrets is to use a third-party secrets management tool such as HashiCorp’s Vault or CyberArk’s Conjur. We’ll cover integration with secret management tools in <em class="chapterRef">Chapter 9</em>, <em class="italic">Managing Secrets in Kubernetes</em>.</p>
<h3 class="heading-3" id="_idParaDest-143">SelfSubjectAccessReviews</h3>
<p class="normal"><code class="inlineCode">SelfSubjectAccessReviews</code> objects enable users or entities to check their own permissions for performing specific <a id="_idIndexMarker310"/>actions on resources in their namespace.</p>
<p class="normal">To use <code class="inlineCode">SelfSubjectAccessReviews</code>, users provide their username along with the desired action and resource to check. The <a id="_idIndexMarker311"/>cluster evaluates the permissions of the provided user against the access control policies in the namespace, and the API server responds with whether the requested action is allowed or denied.</p>
<p class="normal"><code class="inlineCode">SelfSubjectAccessReviews</code> and the next resource, <code class="inlineCode">SelfSubjectRulesReviews</code>, may look very similar, but they serve different functions. The main point to keep in mind for <code class="inlineCode">SelfSubjectAccessReviews</code> is that they assess individual access permissions for specific actions on resources.</p>
<h3 class="heading-3" id="_idParaDest-144">SelfSubjectRulesReviews</h3>
<p class="normal"><code class="inlineCode">SelfSubjectRulesReviews</code> objects are <a id="_idIndexMarker312"/>used to determine the set of rules that a user or entity has permissions for within a <a id="_idIndexMarker313"/>namespace, providing the ability to investigate the access control rules for their own actions and resources.</p>
<p class="normal">To use a <code class="inlineCode">SelfSubjectRulesReview</code>, you provide your identity, and the API server assesses the permissions associated with the identity in a namespace.</p>
<p class="normal"><code class="inlineCode">SelfSubjectRulesReviews</code> offer a more comprehensive view over <code class="inlineCode">SelfSubjectAccessReviews</code>, providing a deeper understanding of the entire set of rules that govern a user’s permissions within a namespace.</p>
<h3 class="heading-3" id="_idParaDest-145">Service accounts</h3>
<p class="normal">Kubernetes uses <code class="inlineCode">ServiceAccounts</code> to <a id="_idIndexMarker314"/>enable access controls for workloads. When you create a <code class="inlineCode">Deployment</code>, you may need to access other services or <a id="_idIndexMarker315"/>Kubernetes resources.</p>
<p class="normal">Since Kubernetes is a secure system, each resource or service your application tries to access will evaluate <strong class="keyWord">role-based access control</strong> (<strong class="keyWord">RBAC</strong>) rules to accept or deny the request.</p>
<p class="normal">Creating a service account using a manifest is a straightforward process, requiring only a few lines in the manifest. The following code snippet shows a service account manifest to create a service account for a Grafana Deployment:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">ServiceAccount</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">grafana</span>
  <span class="hljs-attr">namespace:</span> <span class="hljs-string">monitoring</span>
</code></pre>
<p class="normal">You combine the<a id="_idIndexMarker316"/> service account with role bindings and <code class="inlineCode">Roles</code> to allow access to the required services or objects.</p>
<p class="normal">We’ll cover how to use <code class="inlineCode">ServiceAccounts</code> in depth in <em class="chapterRef">Chapter 6</em>, <em class="italic">Integrating Enterprise Authentication into Your Cluster</em>.</p>
<h3 class="heading-3" id="_idParaDest-146">Services</h3>
<p class="normal">When you create a pod, it will receive<a id="_idIndexMarker317"/> an IP address from the CIDR range that<a id="_idIndexMarker318"/> was assigned when the cluster was created. In most clusters, the assigned IPs are only addressable within the cluster itself, referred to as “<strong class="keyWord">island mode</strong>.” Since pods are<a id="_idIndexMarker319"/> ephemeral, the assigned IP address will likely change during an application’s life cycle, which becomes problematic when any service or application needs to connect to the pod. To address this, we can create a Kubernetes service, which will also receive an IP address, but since services aren’t deleted during an application’s life cycle, the address will remain the same.</p>
<p class="normal">A service will dynamically maintain a list of pods to target based on labels that match the service selector, creating a list of endpoints for the service.</p>
<p class="normal">A service stores information about<a id="_idIndexMarker320"/> how to expose the application, including which pods are running the application and the network ports to reach them.</p>
<p class="normal">Each service has a network type that is assigned when they are created, and they include the following:</p>
<ul>
<li class="bulletList"><code class="inlineCode">ClusterIP</code>: A network type that is only accessible inside the cluster itself. This type can still be used for external requests using an Ingress controller, which will be discussed in a later chapter. The ClusterIP type is the default type that will be used if no type is specified when you create a service.</li>
<li class="bulletList"><code class="inlineCode">NodePort</code>: A network type that exposes the service to a random port between ports <code class="inlineCode">30000</code> and <code class="inlineCode">32767</code>. This port becomes accessible by targeting any worker node in a cluster on the assigned <code class="inlineCode">NodePort</code>. Once created, each node in the cluster will receive the port information, and incoming requests will be routed via <code class="inlineCode">kube-proxy</code>.</li>
<li class="bulletList"><code class="inlineCode">LoadBalancer</code>: This type requires an add-on to use inside a cluster. If you are running Kubernetes on a public cloud provider, this type will create an external load balancer that will assign an IP address to your service. Most on-premises Kubernetes installations do not include support for the <code class="inlineCode">LoadBalancer</code> type, but some offerings such as Google’s Anthos do offer support for it. In a later chapter, we will explain how to add an open-source project called <code class="inlineCode">MetalLB</code> to a Kubernetes cluster to provide support for the <code class="inlineCode">LoadBalancer</code> type.</li>
<li class="bulletList"><code class="inlineCode">ExternalName</code>: This type is different from the other three. Unlike the other three options, this type will not assign an IP address to the service. Instead, this is used to map the internal <a id="_idIndexMarker321"/>Kubernetes <strong class="keyWord">Domain Name System</strong> (<strong class="keyWord">DNS</strong>) name to an external service.</li>
</ul>
<p class="normal">As an example, we have deployed a pod running Nginx on port <code class="inlineCode">80</code>. We want to create a service that will allow this pod to receive incoming requests on port <code class="inlineCode">80</code> from within the cluster. The code<a id="_idIndexMarker322"/> for this can be seen in the following snippet:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">Service</span>
<span class="hljs-attr">metadata:</span>
  <span class="hljs-attr">labels:</span>
    <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-web-frontend</span>
  <span class="hljs-attr">name:</span> <span class="hljs-string">nginx-web</span>
<span class="hljs-attr">spec:</span>
  <span class="hljs-attr">ports:</span>
  <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">http</span>
    <span class="hljs-attr">port:</span> <span class="hljs-number">80</span>
    <span class="hljs-attr">targetPort:</span> <span class="hljs-number">80</span>
  <span class="hljs-attr">selector:</span>
    <span class="hljs-attr">app:</span> <span class="hljs-string">nginx-web</span>
</code></pre>
<p class="normal">In our manifest, we create a label with a value of <code class="inlineCode">app</code> and assign a value of <code class="inlineCode">nginx-web-frontend</code>. We have called the service itself <code class="inlineCode">nginx-web</code> and we exposed the service on port <code class="inlineCode">80</code>, targeting the <a id="_idIndexMarker323"/>pod port of <code class="inlineCode">80</code>. The last two lines of the manifest are used to assign the pods that the service will forward to, also known as Endpoints. In this <a id="_idIndexMarker324"/>manifest, any pod that has the label of <code class="inlineCode">app</code> with a value of <code class="inlineCode">nginx-web</code> in the namespace will be added as an endpoint to the service. Finally, you may have noticed that we didn’t specify a service type in our manifest. Since we didn’t specify the type, it will be created as the default service type of <code class="inlineCode">ClusterIP</code>.</p>
<h3 class="heading-3" id="_idParaDest-147">StatefulSets</h3>
<p class="normal"><code class="inlineCode">StatefulSets</code> offer some unique features<a id="_idIndexMarker325"/> when creating pods. They provide<a id="_idIndexMarker326"/> features that none of the other pod creation methods offer, including the following:</p>
<ul>
<li class="bulletList">Known pod names</li>
<li class="bulletList">Ordered Deployment and scaling</li>
<li class="bulletList">Ordered updates</li>
<li class="bulletList">Persistent storage creation</li>
</ul>
<p class="normal">The best way to understand the advantages of a <code class="inlineCode">StatefulSet</code> is to review an example manifest from the Kubernetes site, shown in the following screenshot:</p>
<figure class="mediaobject"><img alt="Figure 5.9 – StatefulSet manifest example " height="839" src="../Images/B21165_03_04.png" width="818"/></figure>
<p class="packt_figref">Figure 3.4: StatefulSet manifest example</p>
<p class="normal">Now, we can look at the resources that the <code class="inlineCode">StatefulSet</code> created.</p>
<p class="normal">The manifest specifies that there should be three replicas of a pod named <code class="inlineCode">nginx</code>. When we get a list of<a id="_idIndexMarker327"/> pods, you will see that three pods were created using the <code class="inlineCode">nginx</code> name, with an additional dash and an incrementing number. This<a id="_idIndexMarker328"/> is what we meant in the overview when we mentioned that Pods will be created with known names, as illustrated in the following code snippet:</p>
<pre class="programlisting con"><code class="hljs-con">NAME   READY  STATUS   RESTARTS  AGE
web-0  1/1    Running  0         4m6s
web-1  1/1    Running  0         4m2s
web-2  1/1    Running  0         3m52s
</code></pre>
<p class="normal">The pods are also created in order—<code class="inlineCode">web-0</code> must be fully deployed before <code class="inlineCode">web-1</code> is created, and then, finally, <code class="inlineCode">web-2</code>.</p>
<p class="normal">Finally, for this example, we <a id="_idIndexMarker329"/>also added a PVC to each pod using the <code class="inlineCode">VolumeClaimTemplate</code> in the manifest. If you look at the output of the <code class="inlineCode">kubectl get pvc</code> command, you will see that three PVCs were created with the names we expected (note that we removed the <code class="inlineCode">VOLUME</code> column due to space), as illustrated in the following code snippet:</p>
<pre class="programlisting con"><code class="hljs-con">NAME       STATUS  CAPACITY  ACCESS MODES   STORAGECLASS AGE
www-web-0  Bound   1Gi       RWO            nfs          13m
www-web-1  Bound   1Gi       RWO            nfs          13m
www-web-2  Bound   1Gi       RWO            nfs          12m
</code></pre>
<p class="normal">In the <code class="inlineCode">VolumeClaimTemplate</code> section of the manifest, you will see that we assigned the name <code class="inlineCode">www</code> to the PVC claim. When you assign a volume in a <code class="inlineCode">StatefulSet</code>, the PVC name will combine the name used in the claim template, combined with the name of the pod. Using this naming, you can see why Kubernetes assigned the PVC names <code class="inlineCode">www-web-0</code>, <code class="inlineCode">www-web-1</code>, and <code class="inlineCode">www-web-2</code>.</p>
<h3 class="heading-3" id="_idParaDest-148">Storage classes</h3>
<p class="normal">Storage classes are used to define a <a id="_idIndexMarker330"/>storage endpoint. Each storage class can be assigned labels and policies, allowing a developer to select the best storage location for their persistent data. You may<a id="_idIndexMarker331"/> create a storage class for a backend system that has all <strong class="keyWord">Non-Volatile Memory Express</strong> (<strong class="keyWord">NVMe</strong>) drives, assigning<a id="_idIndexMarker332"/> it the name <code class="inlineCode">fast</code>, while assigning a different class to a NetApp <strong class="keyWord">Network File System</strong> (<strong class="keyWord">NFS</strong>) volume running standard drives, using the name <code class="inlineCode">standard</code>.</p>
<p class="normal">When a PVC is requested, the user <a id="_idIndexMarker333"/>can assign a <code class="inlineCode">StorageClass</code> that they wish to use. When the API server receives the request, it finds the matching name and uses the <code class="inlineCode">StorageClass</code> configuration to create the volume on the storage system using a provisioner.</p>
<p class="normal">At a very high level, a <code class="inlineCode">StorageClass</code> manifest does not require a lot of information. Here is an example of a storage class using a provisioner from the Kubernetes incubator project to provide NFS auto-provisioned volumes, named <code class="inlineCode">nfs</code>:</p>
<pre class="programlisting code"><code class="hljs-code"><span class="hljs-attr">apiVersion:</span> <span class="hljs-string">storage.k8s.io/v1</span>
<span class="hljs-attr">kind:</span> <span class="hljs-string">StorageClass</span>
<span class="hljs-attr">metadata:</span>
<span class="hljs-attr">name:</span> <span class="hljs-string">nfs</span>
<span class="hljs-attr">provisioner:</span> <span class="hljs-string">nfs</span>
</code></pre>
<p class="normal">Storage classes allow you to offer multiple storage solutions to your users. You may create a class for cheaper, slower storage while offering a second class that supports high throughput for high data<a id="_idIndexMarker334"/> requirements. By providing a different class to each offering, you allow developers to select the best choice for their application.</p>
<h3 class="heading-3" id="_idParaDest-149">SubjectAccessReviews</h3>
<p class="normal"><code class="inlineCode">SubjectAccessReviews</code> are used to<a id="_idIndexMarker335"/> check if an entity has permission to perform a specific action on a resource. They allow users to request access<a id="_idIndexMarker336"/> reviews and get information about their privileges. By providing an identity, desired action, and resource, the API server determines if the action is allowed or denied. This helps users verify their permissions to a resource, which can help to identify access issues to a Kubernetes resource.</p>
<p class="normal">For example, Scott wants to verify his ability to create pods in a namespace called <code class="inlineCode">sales</code>. To do this, Scott creates a <code class="inlineCode">SubjectAccessReview</code> in the <code class="inlineCode">sales</code> namespace, including his username, the create action, and the target resource, pods.</p>
<p class="normal">The API server verifies whether he has permission to create pods in the <code class="inlineCode">sales</code> namespace and sends a response back. The response from the API server includes whether the requested action is permitted or denied.</p>
<p class="normal">Knowing if an entity has permission to execute an action on a resource helps to minimize frustrations when a deployment fails due to permissions.</p>
<h3 class="heading-3" id="_idParaDest-150">TokenReviews</h3>
<p class="normal"><code class="inlineCode">TokenReviews</code> are API objects used to authenticate and verify the legitimacy of an authentication token linked to a user<a id="_idIndexMarker337"/> or entity in the cluster. If the<a id="_idIndexMarker338"/> token is valid, the API server retrieves the details about the associated user or entity.</p>
<p class="normal">When users submit an authentication token to the Kubernetes API server, it validates the token against the internal authentication system. It verifies that the token is legitimate and determines the user or entity associated with it.</p>
<p class="normal">The API server provides information about the token’s validity and the user or entity, including the username, <strong class="keyWord">user identifier</strong> (<strong class="keyWord">UID</strong>), and group membership.</p>
<h3 class="heading-3" id="_idParaDest-151">ValidatingWebhookConfigurations</h3>
<p class="normal"><code class="inlineCode">ValidatingWebhookConfiguration</code> is a collection of rules that determine what admission requests are intercepted and<a id="_idIndexMarker339"/> handled by a webhook. Each rule contains the specific resources and operations that the webhook should handle.</p>
<p class="normal">It provides a way to enforce<a id="_idIndexMarker340"/> specific policies or rules by applying validation logic to admission requests. Many add-ons to Kubernetes provide a <code class="inlineCode">ValidatingWebhookConfiguration</code> – one of the most common is the NGINX ingress controller.</p>
<p class="normal">You can view all of the <code class="inlineCode">ValidatingWebhookConfigurations</code> in your cluster by executing <code class="inlineCode">kubectl get validatingwebhookconfigurations</code>. For the KinD clusters we have deployed, you will have a single entry for NGINX ingress admissions:</p>
<pre class="programlisting con"><code class="hljs-con">NAME                      		WEBHOOKS   	AGE ingress-nginx-admission   		1       	3d10h
</code></pre>
<h3 class="heading-3" id="_idParaDest-152">VolumeAttachments</h3>
<p class="normal"><code class="inlineCode">VolumeAttachments</code> create connections <a id="_idIndexMarker341"/>between external storage volumes and nodes in a cluster. They control the association of persistent volumes with specific nodes, enabling the nodes to access and utilize the storage resources.</p>
<h1 class="heading-1" id="_idParaDest-153">Summary</h1>
<p class="normal">In this chapter, you were provided with a fast-paced Kubernetes bootcamp, where you were exposed to a wealth of technical information. Remember that as you get deeper into the world of Kubernetes, everything will become more manageable and easier to grasp. It’s important to note that many of the resources discussed in this chapter will be further explored and explained in subsequent chapters, providing you with a deeper understanding.</p>
<p class="normal">You gained insights into each Kubernetes component and their interdependencies, which form the cluster. Armed with this knowledge, you now possess the necessary skills to investigate and identify the root causes of errors or issues within a cluster. We explored the control plane, which encompasses <code class="inlineCode">api-server</code>, <code class="inlineCode">kube-scheduler</code>, <code class="inlineCode">etcd</code>, and controller managers. Additionally, you familiarized yourself with Kubernetes nodes that run the <code class="inlineCode">kubelet</code> and <code class="inlineCode">kube-proxy</code> components, along with a container runtime.</p>
<p class="normal">We also delved into the practical use of the <code class="inlineCode">kubectl</code> utility, which will be your primary tool for interacting with a cluster. You learned about several essential commands, such as commands for accessing logs and providing descriptive information, which you will utilize on a daily basis.</p>
<p class="normal">In the next chapter, we will create a development Kubernetes cluster that we will use as the base cluster for the remaining chapters. Throughout the remainder of the book, we will reference many of the resources that were presented in this chapter, helping to explain them by using them in real-world examples.</p>
<h1 class="heading-1" id="_idParaDest-154">Questions</h1>
<ol>
<li class="numberedList" value="1">A Kubernetes control plane does not include which of the following components?<ol class="alphabeticList level-2" style="list-style-type: lower-alpha;">
<li class="alphabeticList level-2" value="1">api-server</li>
<li class="alphabeticList level-2">kube-scheduler</li>
<li class="alphabeticList level-2">etcd</li>
<li class="alphabeticList level-2">Ingress controller</li>
</ol>
</li>
</ol>
<p class="normal-one">Answer: d</p>
<ol>
<li class="numberedList" value="2">What is the name of the component that keeps all of the cluster information?<ol class="alphabeticList level-2" style="list-style-type: lower-alpha;">
<li class="alphabeticList level-2" value="1">api-server</li>
<li class="alphabeticList level-2">Master controller</li>
<li class="alphabeticList level-2">kubelet</li>
<li class="alphabeticList level-2">etcd</li>
</ol>
</li>
</ol>
<p class="normal-one">Answer: d</p>
<ol>
<li class="numberedList" value="3">Which component is responsible for selecting the node that will run a workload?<ol class="alphabeticList level-2" style="list-style-type: lower-alpha;">
<li class="alphabeticList level-2" value="1">kubelet</li>
<li class="alphabeticList level-2">api-server</li>
<li class="alphabeticList level-2">kube-scheduler</li>
<li class="alphabeticList level-2">Pod-scheduler</li>
</ol>
</li>
</ol>
<p class="normal-one">Answer: c</p>
<ol>
<li class="numberedList" value="4">Which option would you add to a <code class="inlineCode">kubectl</code> command to see additional output from a command?<ol class="alphabeticList level-2" style="list-style-type: lower-alpha;">
<li class="alphabeticList level-2" value="1">Verbose</li>
<li class="alphabeticList level-2">-v</li>
<li class="alphabeticList level-2">–verbose</li>
<li class="alphabeticList level-2">-log</li>
</ol>
</li>
</ol>
<p class="normal-one">Answer: b</p>
<ol>
<li class="numberedList" value="5">Which service type creates a randomly generated port, allowing incoming traffic to any worker node on the assigned port to access the service?<ol class="alphabeticList level-2" style="list-style-type: lower-alpha;">
<li class="alphabeticList level-2" value="1">LoadBalancer</li>
<li class="alphabeticList level-2">ClusterIP</li>
<li class="alphabeticList level-2">None—it’s the default for all services</li>
<li class="alphabeticList level-2">NodePort</li>
</ol>
</li>
</ol>
<p class="normal-one">Answer: d</p>
<ol>
<li class="numberedList" value="6">If you need to deploy an application on a Kubernetes cluster that requires known pod names and a controlled startup of each pod, which object would you create?<ol class="alphabeticList level-2" style="list-style-type: lower-alpha;">
<li class="alphabeticList level-2" value="1">StatefulSet</li>
<li class="alphabeticList level-2">Deployment</li>
<li class="alphabeticList level-2">ReplicaSet</li>
<li class="alphabeticList level-2">ReplicationController</li>
</ol>
</li>
</ol>
<p class="normal-one">Answer: a</p>
<h1 class="heading-1" id="_idParaDest-155">Join our book’s Discord space</h1>
<p class="normal">Join the book’s Discord workspace for a monthly <em class="italic">Ask Me Anything</em> session with the authors:</p>
<p class="normal"><a href="https://packt.link/K8EntGuide"><span class="url">https://packt.link/K8EntGuide</span></a></p>
<p class="normal"><img alt="" height="176" src="../Images/QR_Code965214276169525265.png" width="176"/></p>
</div>
</div></body></html>