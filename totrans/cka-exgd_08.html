<html><head></head><body>
<div id="sbo-rt-content"><div id="_idContainer174">
<h1 class="chapter-number" id="_idParaDest-168"><a id="_idTextAnchor293"/>8</h1>
<h1 id="_idParaDest-169"><a id="_idTextAnchor294"/>Monitoring and Logging Kubernetes Clusters and Applications</h1>
<p>This chapter describes how to monitor Kubernetes cluster components and applications and get infrastructure-level, system-level, and application-level logs to serve as a source for log analytics or further troubleshooting. Together with the next two chapters about troubleshooting cluster components and applications and troubleshooting Kubernetes security and networking, it covers 30% of the CKA exam content.</p>
<p>In this chapter, weâ€™re going to cover the following topics: </p>
<ul>
<li>Monitoring on a cluster node </li>
<li>Monitoring applications on a Kubernetes cluster</li>
<li>Managing logs at the cluster node and pod levels</li>
<li>Managing container <strong class="source-inline">stdout</strong> and <strong class="source-inline">stderr</strong> logs</li>
</ul>
<h1 id="_idParaDest-170"><a id="_idTextAnchor295"/>Technical requirements </h1>
<p>To get started, you need to make sure your local machine meets the following technical requirements: </p>
<ul>
<li>A compatible Linux host. We recommend a Debian-based Linux distribution such as Ubuntu 18.04 or later.</li>
<li>Make sure your host machine has at least 2 GB of RAM, 2 CPU cores, and about 20 GB of free disk space.</li>
</ul>
<h1 id="_idParaDest-171"><a id="_idTextAnchor296"/>Monitoring on a cluster node</h1>
<p><a id="_idTextAnchor297"/>Monitoring is essential for Kubernetes<a id="_idIndexMarker634"/> administrators when it comes to getting a clear understanding of whatâ€™s going on in your Kubernetes cluster. You need to know all of the different metrics to help you get on track in terms of the health of your Kubernetes<a id="_idIndexMarker635"/> cluster components. You also need to make sure that your components are operating as expected and that all workloads that are deployed on your worker nodes are functional and have enough resources, such as CPU, memory, and storage. Moreover, you should also check whether any worker nodes are available and have sufficient resources to scale or schedule more workloads.<a id="_idTextAnchor298"/> </p>
<p>In Kubernetes, Metrics Server collects CPU/memory metrics and to some extent adjusts the resources needed by containers automatically. Metrics Server collects those metrics every 15 seconds from the kubelet agent and then exposes them in the API server of the Kubernetes master via the Metrics API. This process<a id="_idIndexMarker636"/> is described in the following figure: </p>
<div>
<div class="IMG---Figure" id="_idContainer162">
<img alt="Figure 8.1 â€“ How Metrics Server works in a Kubernetes cluster " height="1040" src="image/Figure_8.01_B18201.jpg" width="1129"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.1 â€“ How Metrics Server works in a Kubernetes cluste<a id="_idTextAnchor299"/>r</p>
<p>Users can use the <strong class="source-inline">kubectl top</strong> command to access metrics collected by Metrics Server. At the time of writing this chapter, Metrics Server<a id="_idIndexMarker637"/> supports scaling up to 5,000 Kubernetes worker nodes, which is the maximum number of nodes that Kubernetes currently supports (Kubernetes v1.24 supports clusters with up to 5,000 nodes). For more details about<a id="_idIndexMarker638"/> large Kubernetes clusters, check out this official article: <a href="https://kubernetes.io/docs/setup/best-practices/cluster-large/">https://kubernetes.io/docs/setup/best-practices/cluster-larg<span id="_idTextAnchor300"/>e/</a>.</p>
<h2 id="_idParaDest-172"><a id="_idTextAnchor301"/>Checking whether Metrics Server is installed</h2>
<p>From your Kubernetes cluster, you <a id="_idIndexMarker639"/>can take the following steps<a id="_idIndexMarker640"/> to check whether you have Metrics Server available in your current cluster. You can start by setting up an alias for kubectl using the <strong class="source-inline">alias k=kubectl</strong> command and then use the <strong class="source-inline">k get</strong> command, as follows, to check out the worker nodes that are currently available: </p>
<p class="source-code">Â Â Â Â alias k=kubectl</p>
<p class="source-code">Â Â Â Â k get nodes</p>
<p>The preceding command will show the available worker nodes of your current cluster. The output is similar to the following: </p>
<p class="source-code">NAMEÂ Â Â Â Â Â Â STATUSÂ Â Â ROLESÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â AGEÂ Â Â VERSION</p>
<p class="source-code">minikubeÂ Â Â ReadyÂ Â Â Â control-plane,masterÂ Â Â 5dÂ Â Â v1.23.3</p>
<p>You can use the <strong class="source-inline">k top node</strong> command to check the metrics for the worker node called <strong class="source-inline">minikube</strong>, as follows: </p>
<p class="source-code">k top node minikube</p>
<p>The output of the preceding command will show the resource usage of the <strong class="source-inline">minikube</strong> node if you have Metrics Server installed. Alternatively, you will see the following, which only appears when Metrics Server is not available in your current Kubernetes cluster, which means you need to install Metrics Server:</p>
<p class="source-code">error: Metrics API not available</p>
<p>Alternatively, you can use the following command directly to see whether there will be any output:</p>
<p class="source-code">kubectl get pods -n kube-system | grep metrics-server</p>
<p>The CKA exam will usually<a id="_idIndexMarker641"/> have Metrics Server pre-installed, so<a id="_idIndexMarker642"/> you could jump to <em class="italic">step 3</em> to check out the use cases for the <strong class="source-inline">kubectl top</strong> c<a id="_idTextAnchor302"/>ommand.</p>
<h2 id="_idParaDest-173"><a id="_idTextAnchor303"/>Installing Metrics Server in your current Kubernetes cluster </h2>
<p>If youâ€™re on a vanilla Kubernetes<a id="_idIndexMarker643"/> cluster, you can install Metrics Server<a id="_idIndexMarker644"/> by deploying a YAML definition or through Helm charts; the latter will require Helm to be installed. To get the latest release and instructions, you can go to their GitHub repo: <a href="https://github.com/kubernetes-sigs/metrics-server">https://github.com/kubernetes-sigs/metric<span id="_idTextAnchor304"/>s-server</a>.</p>
<h3>Using a YAML manifest file</h3>
<p>You can use the <strong class="source-inline">kubectl apply -f</strong> command to deploy <a id="_idIndexMarker645"/>Metrics Server using the official YAML manifest file as follows: </p>
<p class="source-code">kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml</p>
<p>Starting from the end of February 2022, thereâ€™s also a <strong class="bold">high-availability</strong> (<strong class="bold">HA</strong>) version that bumps up the replica count from one to two for Metrics Server. If youâ€™re on a cluster with at least two nodes, you can use the following file: </p>
<p class="source-code">kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/high-availability.yaml</p>
<p>You can get more information about Metrics Server here: <a href="https://github.com/kubernetes-sigs/metrics-server/releases">https://github.com/kubernetes-sigs/metrics-server<span id="_idTextAnchor305"/>/releases</a></p>
<h3>Using Helm charts</h3>
<p>To install Metrics Server<a id="_idIndexMarker646"/> using Helm charts, you can go to Artifact Hub and then find the<a id="_idIndexMarker647"/> Metrics Server Helm charts at <a href="https://artifacthub.io/packages/helm/metrics-server/metrics-server">https://artifacthub.io/packages/helm/metrics-server/metrics-server</a></p>
<p>Since Helm 3 is widely used nowadays, you will need to add the Metrics Server Helm charts repo to Helm: </p>
<p class="source-code">helm repo add metrics-server https://kubernetes-sigs.github.io/metrics-server/</p>
<p>It will show the following to confirm that the repo has been added successfully: </p>
<pre class="source-code">
"metrics-server" has been added to your repositories</pre>
<p>After adding the repo, you can install the Helm charts through the following command: </p>
<p class="source-code">helm upgrade --install metrics-server metrics-server/metrics-server</p>
<p>The output of the preceding <a id="_idIndexMarker648"/>command will show you whether itâ€™s been installed s<a id="_idTextAnchor306"/>uccessfully. </p>
<h3>Using mini<a id="_idTextAnchor307"/>kube add-ons </h3>
<p>If youâ€™re using a minikube cluster, Metrics Server<a id="_idIndexMarker649"/> comes in the form of a built-in add-on that can be enabled and disabled via the <strong class="source-inline">minikube addons</strong> command. You can use the following to list the currently supported add-ons:</p>
<p class="source-code">Â Â Â miniku<a id="_idTextAnchor308"/><a id="_idTextAnchor309"/>be addons list</p>
<p>The output is similar to what is shown in the following<a id="_idTextAnchor310"/> screenshot: </p>
<div>
<div class="IMG---Figure" id="_idContainer163">
<img alt="Figure 8.2 â€“ minikube add-ons list  " height="1014" src="image/Figure_8.02_B18201.jpg" width="1282"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.2 â€“ minikube add-ons list </p>
<p>From the preceding screenshot, we can see the <strong class="source-inline">metrics-server</strong> add-on is <strong class="source-inline">disabled</strong>. You canalso use the following command to get a clearer view:</p>
<p class="source-code">Â Â Â minikube addons list | grep metrics-server</p>
<p>The following output<a id="_idIndexMarker650"/> shows that currently, the minikube add-on is <strong class="source-inline">disabled</strong>:</p>
<p class="source-code">| metrics-serverÂ Â Â Â Â Â Â Â Â Â Â Â Â Â | minikube | disabledÂ Â Â Â Â | kubernetes</p>
<p>You can use the <strong class="source-inline">minikube addon enable</strong> command to enable Metrics Server: </p>
<p class="source-code">Â Â Â minikube addons enable metrics-server</p>
<p>The following output<a id="_idIndexMarker651"/> shows that the Metrics Server add-on was successfully enabled: </p>
<p class="source-code">Â Â Â â–ª Using image k8s.gcr.io/metrics-server/metrics-server:v0.4.2</p>
<p class="source-code">ðŸŒŸÂ Â The 'metrics-server' addon is enabled</p>
<p>Now if you use the <strong class="source-inline">kubectl get</strong> command, youâ€™ll see that the Pods and Services related to Metrics Server are up and running in the <strong class="source-inline">kube-system</strong> namespace: </p>
<p class="source-code">Â Â Â kubectl get pod,svc -n kube-system </p>
<p>The output should look like the following: </p>
<div>
<div class="IMG---Figure" id="_idContainer164">
<img alt="Figure 8.3 â€“ Metrics Server Pods and Services in the kube-system namespace  " height="394" src="image/Figure_8.03_B18201.jpg" width="1348"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.3 â€“ Metrics Server Pods and Services in the kube-system namespace </p>
<p>Another command you can use is the following: </p>
<p class="source-code">Â Â kubectl get pods -n kube-system | grep metrics-server</p>
<p>The output should look like the following:</p>
<p class="source-code">metrics-server-6b76bd68b6-rwlb9Â Â Â Â 1/1Â Â Â Â Â RunningÂ Â Â 0Â Â Â Â Â Â Â Â Â 17h</p>
<p>As you can see from the output, the Metrics Server pod<a id="_idIndexMarker652"/> is up and running, which means you can now use the <strong class="source-inline">kubectl top</strong> command. Letâ€™s now take a look at <a id="_idTextAnchor311"/>what it does. </p>
<h2 id="_idParaDest-174"><a id="_idTextAnchor312"/>Checking out CPU/memory metrics </h2>
<p>You can use the <strong class="source-inline">kubectl top</strong> command<a id="_idIndexMarker653"/> to top the worker node that you want to get metrics details from. The following is an example where we top a worker node called <strong class="source-inline">minikube</strong>: </p>
<p class="source-code">k top node minikube</p>
<p>The output is as follows, where we can see the number of CPU cores and the amount of memory used: </p>
<p class="source-code">NAMEÂ Â Â Â Â Â Â CPU(cores)Â Â Â CPU%Â Â Â MEMORY(bytes)Â Â Â MEMORY%Â Â Â </p>
<p class="source-code">minikube 232m 11% 961Mi 24%Â Â </p>
<p>This also applies to the use case where your Kubernetes cluster has multiple worker nodes. Using the <strong class="source-inline">kubectl top node</strong> <strong class="source-inline">&lt;node name&gt;</strong> command will help you see the resource usage of that<a id="_idTextAnchor313"/> specific node.</p>
<h1 id="_idParaDest-175"><a id="_idTextAnchor314"/>Monitoring applications on a Kubernetes cluster</h1>
<p>A standard end-to-end monitoring<a id="_idIndexMarker654"/> solution covers infrastructure monitoring<a id="_idIndexMarker655"/> and application monitoring. In Kubernetes, Metrics Server is not only used to monitor the Kubernetes worker nodes but also Kubernetes Pods and containers. </p>
<p>We can test out application monitoring by deploying a new pod in the default namespace as follows:</p>
<p class="source-code">kubectl run nginx --image=nginx</p>
<p>After executing the preceding command, make sure that your <strong class="source-inline">nginx</strong> pod is up and running before going to the next section. To check out the status of the pod, you can use the <strong class="source-inline">kubectl get po<a id="_idTextAnchor315"/>d nginx</strong> command. </p>
<h2 id="_idParaDest-176"><a id="_idTextAnchor316"/>Monitoring the resource usage of an application</h2>
<p>You can use the <strong class="source-inline">kubectl top pod &lt;podname&gt;</strong> command<a id="_idIndexMarker656"/> to check out the metrics collected for that pod, including the resource consumption of the pod: </p>
<p class="source-code">kubectl top pod nginx</p>
<p>The output should look as follows, where you can see the CPU and memory usage of the pod: </p>
<p class="source-code">NAMEÂ Â Â Â CPU(cores)Â Â Â MEMORY(bytes)</p>
<p class="source-code">nginx 0m 9Mi</p>
<p>In our case, we deployed<a id="_idIndexMarker657"/> a single-container pod, but itâ€™s important to know that we could also check out the CPU and memory usage for a multi-container pod by using the following command: </p>
<p class="source-code">k top pod &lt; pod name &gt; --containers</p>
<p>Letâ€™s use the same <strong class="source-inline">kubectl top</strong> command to show the metrics for the <strong class="source-inline">nginx</strong> pod and all its containers:</p>
<p class="source-code">k top pod nginx --containers</p>
<p>The output should look like the following as itâ€™s a single-container pod: </p>
<p class="source-code">PODÂ Â Â Â Â NAMEÂ Â Â Â CPU(cores)Â Â Â MEMORY(bytes)</p>
<p class="source-code">nginx nginx 0m 9Mi</p>
<p>If there are multiple containers, it will list the name of the containers in that pod and show their CPU and memory usage respectively. </p>
<p>With that in mind, we could use <strong class="source-inline">kubectl top pod</strong>, adding the <strong class="source-inline">-A</strong> flag or <strong class="source-inline">â€“all-namespaces</strong>, to show all the metrics of all the Pods across different namespaces. The following command is used in this case:</p>
<p class="source-code">k top pod -A </p>
<p>Alternatively, you can also use the full flag as follows: </p>
<p class="source-code">k top pod --all-namespaces</p>
<p>The output should look like the following, where you have all the Pods listed along with their CPU and memory usage respectively: </p>
<pre class="source-code">
NAMESPACEÂ Â Â Â Â NAMEÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â CPU(cores)Â Â Â 
MEMORY(bytes)
defaultÂ Â Â Â Â Â Â nginxÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0mÂ Â Â Â Â Â Â Â Â Â Â 
9Mi
kube-systemÂ Â Â kube-proxy-64jzvÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1mÂ Â Â Â Â Â Â Â Â Â 
32Mi
kube-systemÂ Â Â kube-proxy-hplp5Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1mÂ Â Â Â Â Â Â Â Â Â 
28Mi
kube-systemÂ Â Â kube-proxy-kvb96Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 2mÂ Â Â Â Â Â Â Â Â Â 
31Mi
kube-systemÂ Â Â kube-proxy-kvjwhÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1mÂ Â Â Â Â Â Â Â Â Â 
28Mi
kube-systemÂ Â Â kube-proxy-rmw2rÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1mÂ Â Â Â Â Â Â Â Â Â 
31Mi
kube-systemÂ Â Â kube-proxy-tcz5mÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1mÂ Â Â Â Â Â Â Â Â Â 
26Mi
kube-systemÂ Â Â metrics-server-6576d9ccf8-z8mlgÂ Â Â Â Â Â Â 6mÂ Â Â Â Â Â Â Â Â Â Â 
37M</pre>
<p>Thereâ€™s a good chance<a id="_idIndexMarker658"/> that the CKA exam will ask you what pod consumes the most compute resources in a list of pods, or any other task of this nature â€“ thatâ€™s where the <strong class="source-inline">â€“sort-by</strong> flag comes into play. The <strong class="source-inline">--sort-by</strong> flag accepts either <strong class="source-inline">cpu</strong> or <strong class="source-inline">memory</strong> as a value, and as a result it will return the result <strong class="source-inline">asc</strong> or <strong class="source-inline">desc</strong>. The command looks as in the following examples: </p>
<p class="source-code">kubectl top pod <strong class="bold">--sort-by</strong>=cpu</p>
<p class="source-code">kubectl top pod <strong class="bold">â€“-sort-by</strong>=memory</p>
<p>It makes more sense when we have a large list of pods and you have requested to sort them by the memory or CPU resources consumed, from most to least. We can use the following command to do this: </p>
<p class="source-code">kubectl top pod -A --sort-by=memory</p>
<p>The output should look as follows, with all the pods across all the namespaces in your current Kubernetes cluster listed according to resource usage: </p>
<pre class="source-code">
kube-systemÂ Â Â metrics-server-6576d9ccf8-z8mlgÂ Â Â Â Â Â Â 7mÂ Â Â Â Â Â Â Â Â Â 
37Mi
kube-systemÂ Â Â kube-proxy-64jzvÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1mÂ Â Â Â Â Â Â Â Â Â 
32Mi
kube-systemÂ Â Â kube-proxy-rmw2rÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1mÂ Â Â Â Â Â Â Â Â Â 
31Mi
kube-systemÂ Â Â kube-proxy-kvb96Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1mÂ Â Â Â Â Â Â Â Â Â 
31Mi
kube-systemÂ Â Â kube-proxy-kvjwhÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1mÂ Â Â Â Â Â Â Â Â Â 
28Mi
kube-systemÂ Â Â kube-proxy-hplp5Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1mÂ Â Â Â Â Â Â Â Â Â 
28Mi
kube-systemÂ Â Â kube-proxy-tcz5mÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 1mÂ Â Â Â Â Â Â Â Â Â 
25Mi
defaultÂ Â Â Â Â Â Â nginxÂ Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â 0mÂ Â Â Â Â Â Â Â Â Â Â 
9Mi</pre>
<p>This command<a id="_idIndexMarker659"/> works in a similar way when using <strong class="source-inline">â€“sort-by cpu</strong> flag. The output lists the pods in the order of most CP<a id="_idTextAnchor317"/>U consumed to least. </p>
<h2 id="_idParaDest-177"><a id="_idTextAnchor318"/>Checking application details</h2>
<p>You can use the <strong class="source-inline">kubectl describe pod &lt;podname&gt;</strong> command to find out status information regarding<a id="_idIndexMarker660"/> the allocated CPUs and memory usage and some other information, such as runtime versions, system information, capacity, labels, and annotations:</p>
<p class="source-code">kubectl describe pod nginx</p>
<p>The output should look like the following: </p>
<div>
<div class="IMG---Figure" id="_idContainer165">
<img alt="Figure 8.4 â€“ kubectl describe pod nginx " height="855" src="image/Figure_8.04_B18201.jpg" width="818"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.4 â€“ kubectl describe pod nginx</p>
<p>Note that thereâ€™s an <strong class="source-inline">Events</strong> section at the bottom of the preceding screenshot that shows a log of recent events<a id="_idIndexMarker661"/> related to this pod. Weâ€™ll take a closer look at the <strong class="source-inline">Events</strong> section: </p>
<div>
<div class="IMG---Figure" id="_idContainer166">
<img alt="Figure 8.5 â€“ Events of the nginx pod " height="188" src="image/Figure_8.05_B18201.jpg" width="768"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.5 â€“ Events of the nginx pod</p>
<p>The events here include a series of events in Kubernetes, such as these:</p>
<ol>
<li>The pod gets scheduled to the worker node called <strong class="source-inline">minikube</strong>.</li>
<li>The container image is pulled from the container registry.</li>
<li>The kubelet agent provisions the pod containing an <strong class="source-inline">nginx</strong> container.</li>
<li>Kubelet starts the pod and the <strong class="source-inline">nginx</strong> container starts to accept traffic.</li>
</ol>
<p>Analyzing those events helps us to understand whatâ€™s going on during the pod provisioning process, and it could give us clues as to whether any exceptions happened and why, allowing us to come up with potential solutions. Weâ€™ll take a closer look at the events in the next section of this chapter. </p>
<p>If a pod is in a namespace other than the default namespace, you can specify the <strong class="source-inline">-n</strong> flag in the <strong class="source-inline">kubectl describe</strong> command to add the namespace. The following is an example using this command to describe a pod named <strong class="source-inline">coredns-64897985d-brqfl</strong> in the <strong class="source-inline">kube-system</strong> namespace: </p>
<p class="source-code"><strong class="bold">kubectl describe pod</strong> coredns-64897985d-brqfl <strong class="bold">-n</strong> kube-system</p>
<p>The output should look like the following: </p>
<div>
<div class="IMG---Figure" id="_idContainer167">
<img alt="Figure 8.6 â€“ kubectl describe coredns pod in the kube-system namespace  " height="898" src="image/Figure_8.06_B18201.jpg" width="984"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.6 â€“ kubectl describe coredns pod in the kube-system namespace </p>
<p>Even though the preceding<a id="_idIndexMarker662"/> screenshots contain similar chunks of information, the details differ from pod to pod. You could add <strong class="source-inline">&gt; mypod.yaml</strong> to the end of the command to export the pod information for further analysis: </p>
<p class="source-code">kubectl describe pod nginx &gt; mypod.yaml</p>
<p>You will get<a id="_idIndexMarker663"/> a YAML file called <strong class="source-inline">mypod.yaml</strong> containing crit<a id="_idTextAnchor319"/>ical pod information. </p>
<h2 id="_idParaDest-178"><a id="_idTextAnchor320"/>Monitoring cluster events </h2>
<p>We can get Kubernetes<a id="_idIndexMarker664"/> events by using the following command: </p>
<p class="source-code">kubectl get events</p>
<p>We can get events logged in the current cluster, which includes events logged previously in the <strong class="source-inline">Events</strong> section, when we use the <strong class="source-inline">kubectl describe pod</strong> command. The following is a sample output after running the <strong class="source-inline">kubect<a id="_idTextAnchor321"/>l get events</strong> command: </p>
<div>
<div class="IMG---Figure" id="_idContainer168">
<img alt="Figure 8.7 â€“ kubectl get events " height="789" src="image/Figure_8.07_B18201.jpg" width="1156"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.7 â€“ kubectl get events</p>
<p>You can use the following command to list the events sorted by timestamp: </p>
<p class="source-code">kubectl get events --sort-by=.metadata.creationTimestamp</p>
<p>If you want to collect the events during a deployment, you can run the following command on the side: </p>
<p class="source-code">kubectl get events --watch</p>
<p>The commands will give you a good<a id="_idIndexMarker665"/> idea of whatâ€™s going on during the deployment process if youâ€™re not using Kubernetes Dashboard or any third-party monitoring frameworks such as Prometheus with Grafana Dashboard. Knowing about what happens at the application level by monitoring sometimes comes in handy, especially when it comes to troubleshooting. Often we get a better understanding by analyzing logs and tracking exceptions. Letâ€™s take a look at how to manage logs at the cluste<a id="_idTextAnchor322"/>r node and pod levels. </p>
<h1 id="_idParaDest-179"><a id="_idTextAnchor323"/>Managing logs at the cluster node and Pod levels</h1>
<p>Logs are very handy when it comes<a id="_idIndexMarker666"/> to troubleshooting issues. The information<a id="_idIndexMarker667"/> collected in a log is usually helpful<a id="_idIndexMarker668"/> in understanding what has happened, figuring<a id="_idIndexMarker669"/> out why certain issues happened, and finding remediations to prevent them from<a id="_idTextAnchor324"/> happening again later on. </p>
<h2 id="_idParaDest-180"><a id="_idTextAnchor325"/>Cluster-level logging</h2>
<p>In Kubernetes, the notion<a id="_idIndexMarker670"/> of cluster-level logging is widely recognized. This means logs are meant to be stored in a separate backend, so the lifecycles of those logs are independent of whatâ€™s been logged down to the worker node, pod, or even container level. </p>
<p>Kubernetes itself does not provide a comprehensive native logging framework, but it can be integrated with lots of third-party open source logging solutions in the community, such as Grafana Loki or the EFK stack, which includes Elasticsearch, Fluentd, and Kibana for log searching, querying, and tracing. </p>
<p>Logging in Kubernetes involves a set of patterns that are implemented by the community with different open source solutions. There are the following three patterns: </p>
<ul>
<li><strong class="bold">Using a node-level logging agent that runs on every node</strong>: The agent is often in a DaemonSet so<a id="_idIndexMarker671"/> it will be evenly distributed on each node, and this agent pushes the logs to a backend. In this case, there are no code changes for the application. </li>
<li><strong class="bold">Using a dedicated sidecar container to log information from the application in the same Pod</strong>: This case can be in conjunction with a logging agent running on the node or streaming the logs out, and it is usually recommended to write log entries with the same formats to the same log stream for convenient processing. </li>
<li><strong class="bold">Directly streaming the logs from the application to an external backend</strong>: This can work with external object storage, as such storage supports lifecycle policies, which allows the setup of data retention policies and the archiving of old logs based on the policy. Most object storage also works with a search framework, where logs are indexed and so are easy to search and query. </li>
</ul>
<p>To learn more about<a id="_idIndexMarker672"/> the Kubernetes logging architecture, check this article out: <a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/">https://kubernetes.io/docs/concepts/cl<span id="_idTextAnchor326"/>uster-administration/logging/</a></p>
<h2 id="_idParaDest-181"><a id="_idTextAnchor327"/>Checking out the node details</h2>
<p>With native Kubernetes, you can use the <strong class="source-inline">kubectl describe node &lt;nodename&gt;</strong> command to find<a id="_idIndexMarker673"/> out the status information regarding the allocated CPUs and memory usage as well as some other information, such as runtime versions, system information, capacity, labels, and annotations. We can use the following command to describe a worker node named <strong class="source-inline">minikube</strong>: </p>
<p class="source-code">kubectl describe node minikube</p>
<p>The output is similar to the following: </p>
<div>
<div class="IMG---Figure" id="_idContainer169">
<img alt="Figure 8.8 â€“ kubectl describe node minikube " height="1264" src="image/Figure_8.08_B18201.jpg" width="1150"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.8 â€“ kubectl describe node minikube</p>
<p>Gettting to know the node specification<a id="_idIndexMarker674"/> will give you an understanding of how your node was previously configured. Letâ€™s now take a look at how to get some quick but handy information using the <a id="_idTextAnchor328"/><strong class="source-inline">kubectl describe node</strong> command. </p>
<h2 id="_idParaDest-182"><a id="_idTextAnchor329"/>Checking the node status </h2>
<p>With the <strong class="source-inline">kubectl describe</strong> command, we get some<a id="_idIndexMarker675"/> general information about a node. Notice that it also contains an <strong class="source-inline">events</strong> section that usually logs node events. To get more status information from a node, we usually use the following command, taking a node named <strong class="source-inline">minikube</strong> as an example: </p>
<p class="source-code">kubectl get node minikube -o wide</p>
<p>The output is similar to the following: </p>
<div>
<div class="IMG---Figure" id="_idContainer170">
<img alt="Figure 8.9 â€“ kubectl get node output " height="88" src="image/Figure_8.09_B18201.jpg" width="1030"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.9 â€“ kubectl get node output</p>
<p>From the preceding screenshot, if you compare the <strong class="source-inline">kubectl get node</strong> command with the one with the <strong class="source-inline">-o wide</strong> flag, youâ€™ll see that it gives extra information about the image and kernel version as well as the container runtime, which is quite handy when we need<a id="_idTextAnchor330"/> to get information quickly. </p>
<h1 id="_idParaDest-183"><a id="_idTextAnchor331"/>Managing container stdout and stderr logs</h1>
<p>In the Unix<a id="_idIndexMarker676"/> and Linux OSs, there<a id="_idIndexMarker677"/> are three I/O streams, called <strong class="source-inline">STDIN</strong>, <strong class="source-inline">STDOUT</strong>, and <strong class="source-inline">STDERR</strong>. Here, weâ€™ll talk about <strong class="source-inline">STDOUT</strong> and <strong class="source-inline">STERR</strong> in Linux containers, which are typically what the <strong class="source-inline">kubectl logs</strong> command shows to us. </p>
<p><strong class="source-inline">STDOUT</strong> is usually a commandâ€™s normal output, and <strong class="source-inline">STDERR</strong> is typically used to output error messages. Kubernetes uses the <strong class="source-inline">kubectl logs &lt;podname&gt;</strong> command to log <strong class="source-inline">STDOUT</strong> and <strong class="source-inline">STDERR</strong>. It looks like the following when we use the command to log the <strong class="source-inline">nginx</strong> pod that we deployed in this chapter: </p>
<p class="source-code">kubectl logs nginx</p>
<p>The output should look like the following: </p>
<div>
<div class="IMG---Figure" id="_idContainer171">
<img alt="Figure 8.10 â€“ kubectl logs nginx pod " height="239" src="image/Figure_8.10_B18201.jpg" width="727"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.10 â€“ kubectl logs nginx pod</p>
<p>Now, weâ€™ll use a container<a id="_idIndexMarker678"/> to write text to the standard output stream with a frequency<a id="_idIndexMarker679"/> of once per second. We can do this by deploying a new pod. The following is an example of a YAML manifest for this pod: </p>
<pre class="source-code">
apiVersion: v1
kind: Pod
metadata:
Â Â name: logger
spec:
Â Â containers:
Â Â - name: packs
Â Â Â Â image: busybox:1.28
Â Â Â Â args: [/bin/sh, -c,
Â Â Â Â Â Â Â Â Â Â Â Â 'i=0; while true; do echo "$i: $(date)"; i=$((i+1)); sleep 1; done']</pre>
<p>You can use the <strong class="source-inline">kubectl logs</strong> command to retrieve the logs from the <strong class="source-inline">logger</strong> Pod as follows: </p>
<p class="source-code">k logs logger</p>
<p>The log would look as follows: </p>
<pre class="source-code">
0: Thu May 12 04:34:40 UTC 2022
1: Thu May 12 04:34:41 UTC 2022
2: Thu May 12 04:34:42 UTC 2022
3: Thu May 12 04:34:43 UTC 2022</pre>
<p>We can get into the pod<a id="_idIndexMarker680"/> to retrieve the specific container log by using the <strong class="source-inline">-c</strong> flag. Letâ€™s check<a id="_idIndexMarker681"/> out the log for a container called <strong class="source-inline">packt</strong> in the <strong class="source-inline">logger</strong> pod using the following command: </p>
<p class="source-code">k logs logger -c packt</p>
<p>The following output is the logs retrieved from the <strong class="source-inline">packt</strong> container: </p>
<div>
<div class="IMG---Figure" id="_idContainer172">
<img alt="Figure 8.11 â€“ Logs from the packt container " height="252" src="image/Figure_8.11_B18201.jpg" width="423"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.11 â€“ Logs from the packt container</p>
<p>If you want to stream the logs, you can use the <strong class="source-inline">kubectl logs -f</strong> command, as follows: </p>
<p class="source-code">kubectl logs -f logger</p>
<p>You should be able to see an output like the following:</p>
<div>
<div class="IMG---Figure" id="_idContainer173">
<img alt="" height="508" src="image/Figure_8.12_B18201.jpg" width="347"/>
</div>
</div>
<p class="IMG---Caption" xml:lang="en-US">Figure 8.12 â€“ kubectl logs for the nginx pod</p>
<p>Use the following command<a id="_idIndexMarker682"/> if you want to return logs newer than a certain duration, such<a id="_idIndexMarker683"/> as within 1 hour: </p>
<p class="source-code">kubectl logs --since=1h </p>
<p>You can modify the value after the <strong class="source-inline">â€“s<a id="_idTextAnchor332"/>ince</strong> flag as per your requirements. </p>
<h1 id="_idParaDest-184"><a id="_idTextAnchor333"/>Summary</h1>
<p>This chapter covered monitoring and logging for Kubernetes on three levels â€“ cluster, node, and pod. This chapter laid the groundwork for the next two chapters, where we will focus on troubleshooting cluster components and application failures, as well as exploring some other challenges around Kubernetes security restrictions and container networking by providing more specific troubleshooting use cases and end-to-end tr<a id="_idTextAnchor334"/>oubleshooting scenarios. Stay tuned!</p>
<h1 id="_idParaDest-185"><a id="_idTextAnchor335"/>Mock CKA scenario-based practice test </h1>
<p>You have two virtual machines, <strong class="source-inline">master-0</strong> and <strong class="source-inline">worker-0</strong>: please com<a id="_idTextAnchor336"/>plete the following mock scenarios. </p>
<h2 id="_idParaDest-186"><a id="_idTextAnchor337"/>Scenario 1 </h2>
<p>List all the available Pods in your current cluster, identify the ones with the highest CPU consumption, and write their names to a <strong class="source-inline">max-cpu.txt</strong> file. </p>
<p>You can find all the scenario res<a id="_idTextAnchor338"/>olutions in <a href="B18201_Appendix_A.xhtml#_idTextAnchor386"><em class="italic">Appendix</em></a><em class="italic"> - Mock CKA scenario-based practice test resolutions</em> of this book.</p>
<h1 id="_idParaDest-187"><a id="_idTextAnchor339"/>FAQs</h1>
<ul>
<li><em class="italic">Where can I find out about the latest updates on Kubernetes Metrics Server? </em></li>
</ul>
<p>Kubernetes Metrics Server has a GitHub repository at <a href="https://github.com/kubernetes-sigs/metrics-server">https://github.com/kubernetes-sigs/metrics-server</a>.</p>
<ul>
<li><em class="italic">Where can I find the latest information on Kubernetes cluster logging architecture? </em></li>
</ul>
<p>Go to the official Kubernetes documentation at <a href="https://kubernetes.io/docs/concepts/cluster-administration/logging/">https://kubernetes.io/docs/concepts/cluster-administration/logging/</a>.</p>
<ul>
<li><em class="italic">Where can I find the metrics for Kubernetes system components?</em></li>
</ul>
<p>You can bookmark this page to get more information: <a href="https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/">https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/</a>.</p>
<p> </p>
</div>
</div></body></html>