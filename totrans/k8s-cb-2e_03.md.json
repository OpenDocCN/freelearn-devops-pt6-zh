["```\n# cat 3-1-1_deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-nginx\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      service : nginx\n  template:\n    metadata:\n      labels:\n        service : nginx\n    spec:\n      containers:\n        - name: my-container\n          image: nginx\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-nginx\nspec:\n  ports:\n    - protocol: TCP\n      port: 80\n      nodePort: 30080\n  type: NodePort\n  selector:\n    service: nginx\n```", "```\n// create deployment and service\n# kubectl create -f 3-1-1_deployment.yaml\ndeployment \"my-nginx\" created\nservice \"my-nginx\" created\n```", "```\n# kubectl get pods\nNAME READY STATUS RESTARTS AGE\nmy-nginx-6484b5fc4c-9v7dc 1/1 Running 0 7s\nmy-nginx-6484b5fc4c-krd7p 1/1 Running 0 7s\n```", "```\n# kubectl get services\nNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE\nkubernetes ClusterIP 10.96.0.1 <none> 443/TCP 20d\nmy-nginx NodePort 10.105.9.153 <none> 80:30080/TCP 59s\n```", "```\n// kubectl scale --replicas=<expected_replica_num> deployment <deployment_name>\n# kubectl scale --replicas=4 deployment my-nginx\ndeployment \"my-nginx\" scaled\n```", "```\n# kubectl get pods\nNAME READY STATUS RESTARTS AGE\nmy-nginx-6484b5fc4c-9v7dc 1/1 Running 0 1m\nmy-nginx-6484b5fc4c-krd7p 1/1 Running 0 1m\nmy-nginx-6484b5fc4c-nsvzt 0/1 ContainerCreating 0 2s\nmy-nginx-6484b5fc4c-v68dr 1/1 Running 0 2s\n```", "```\n// kubectl scale –replicas=<expected_replica_num> deployment <deployment_name>\n# kubectl scale --replicas=2 deployment my-nginx\ndeployment \"my-nginx\" scaled\n```", "```\n# kubectl get pods\nNAME READY STATUS RESTARTS AGE\nmy-nginx-6484b5fc4c-9v7dc 1/1 Running 0 1m\nmy-nginx-6484b5fc4c-krd7p 1/1 Running 0 1m\nmy-nginx-6484b5fc4c-nsvzt 0/1 Terminating 0 23s\nmy-nginx-6484b5fc4c-v68dr 0/1 Terminating 0 23s\n```", "```\n// adding –-current-replicas to precheck the condistion for scaling.\n# kubectl scale --current-replicas=3 --replicas=4 deployment my-nginx\nerror: Expected replicas to be 3, was 2\n```", "```\n// at the time we're writing this book, the latest configuration file of heapster in kops is 1.7.0\\. Check out https://github.com/kubernetes/kops/tree/master/addons/monitoring-standalone for the latest version when you use it. \n# kubectl create -f https://raw.githubusercontent.com/kubernetes/kops/master/addons/monitoring-standalone/v1.7.0.yaml\ndeployment \"heapster\" created\nservice \"heapster\" created\nserviceaccount \"heapster\" created\nclusterrolebinding \"heapster\" created\nrolebinding \"heapster-binding\" created\n```", "```\n# kubectl get pods --all-namespaces | grep heapster\nkube-system heapster-56d577b559-dnjvn 2/2 Running 0 26m\nkube-system heapster-v1.4.3-6947497b4-jrczl 3/3 Running 0 5d\n```", "```\n# kubectl get pods\nNAME READY STATUS RESTARTS AGE\nmy-nginx-6484b5fc4c-9v7dc 1/1 Running 0 40m\nmy-nginx-6484b5fc4c-krd7p 1/1 Running 0 40m\n```", "```\n# kubectl autoscale deployment my-nginx --cpu-percent=50 --min=2 --max=5 \ndeployment \"my-nginx\" autoscaled \n# cat 3-1-2_hpa.yaml\napiVersion: autoscaling/v1\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: my-nginx\nspec:\n  scaleTargetRef:\n    kind: Deployment\n    name: my-nginx\n  minReplicas: 2\n  maxReplicas: 5\n  targetCPUUtilizationPercentage: 50\n```", "```\n// check horizontal pod autoscaler (HPA)\n# kubectl get hpa\nNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE\nmy-nginx Deployment/my-nginx <unknown> / 50% 2 5 0 3s\n```", "```\n# kubectl get hpa\nNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE\nmy-nginx Deployment/my-nginx 0% / 50% 2 5 2 48m\n\n// check details of a hpa\n# kubectl describe hpa my-nginx\nName: my-nginx\nNamespace: default\nLabels: <none>\nAnnotations: <none>\nCreationTimestamp: Mon, 15 Jan 2018 22:48:28 -0500\nReference: Deployment/my-nginx\nMetrics: ( current / target )\n  resource cpu on pods (as a percentage of request): 0% (0) / 50%\nMin replicas: 2\nMax replicas: 5\n```", "```\n// generate the load\n# kubectl run -it --rm --restart=Never <pod_name> --image=busybox -- sh -c \"while true; do wget -O - -q http://my-nginx; done\"\n```", "```\n// check current value – it's 43% now. not exceeding scaling condition yet.\n# kubectl get hpa\nNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE\nmy-nginx Deployment/my-nginx 43% / 50% 2 5 2 56m\n```", "```\n# kubectl get hpa\nNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE\nmy-nginx Deployment/my-nginx 73% / 50% 2 5 3 1h\n\n# kubectl get hpa\nNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE\nmy-nginx Deployment/my-nginx 87% / 50% 2 5 4 15m\nKeeping observing it and deleting some busybox we deployed. It will eventually cool down and scale down without manual operation involved.\n# kubectl get hpa\nNAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE\nmy-nginx Deployment/my-nginx 40% / 50% 2 5 2 27m\n```", "```\n// check components\n$ kubectl get cs\n// check nodes\n$ kubectl get node\n```", "```\n// create a simple nginx Deployment with specified labels\n$ kubectl run simple-nginx --image=nginx --port=80 --replicas=5 --labels=\"project=My-Happy-Web,role=frontend,env=test\"\ndeployment.apps \"simple-nginx\" created\n```", "```\n// expose the Deployment, and named the service \"nginx-service\"\n$ kubectl expose deployment simple-nginx --port=8080 --target-port=80 --name=\"nginx-service\"\nservice \"nginx-service\" exposed\n// For minikube environment only, since Kubernetes is installed in a VM, add Service type as NodePort for accessing outside the VM.\n$ kubectl expose deployment simple-nginx --port=8080 --target-port=80 --name=\"nginx-service\" --type=NodePort service \"nginx-service\" exposed\n```", "```\n$ kubectl describe deployment simple-nginx\nName:                   simple-nginx\nNamespace:              default\nCreationTimestamp:      Fri, 04 May 2018 12:14:21 -0400\nLabels:                 env=test\n                        project=My-Happy-Web\n                        role=frontend\nAnnotations:            deployment.kubernetes.io/revision=1\nSelector:               env=test,project=My-Happy-Web,role=frontend\nReplicas:               5 desired | 5 updated | 5 total | 5 available | 0 unavailable\nStrategyType:           RollingUpdate MinReadySeconds:        0\nRollingUpdateStrategy:  1 max unavailable, 1 max surge\nPod Template:\n  Labels:  env=test\n           project=My-Happy-Web\n           role=frontend\n  Containers:\n   simple-nginx:\n    Image:        nginx\n    Port:         80/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nConditions:\n  Type           Status  Reason\n  ----           ------  ------\n  Available      True    MinimumReplicasAvailable\n  Progressing    True    NewReplicaSetAvailable\nOldReplicaSets:  <none>\nNewReplicaSet:   simple-nginx-585f6cddcd (5/5 replicas created)\nEvents:\n  Type    Reason             Age   From                   Message\n  ----    ------             ----  ----                   -------\n  Normal  ScalingReplicaSet  1h    deployment-controller  Scaled up replica set simple-nginx-585f6cddcd to 5\n// rs is the abbreviated resource key of replicaset\n$ kubectl get rs\nNAME                      DESIRED   CURRENT   READY     AGE\nsimple-nginx-585f6cddcd   5         5         5         1h\n```", "```\n// record the cluster IP of Service \"nginx-service\"\n$ export SERVICE_URL=$(kubectl get svc | grep nginx-service | awk '{print $3}'):8080\n\n// For minikube environment only, record the VM host IP and port for the service\n$ export SERVICE_URL=$(minikube service nginx-service --url)\n$ curl $SERVICE_URL | grep \"title\"\n<title>Welcome to nginx!</title>\n```", "```\n// get into editor mode with the command below\n// the flag \"--record\" is for recording the update\n// add the command argument as below and save the change\n$ kubectl edit deployment simple-nginx --record\nspec:\n  replicas: 5\n  ...\n  template:\n    ...\n    spec:\n      containers:\n      - image: nginx\n command:         - sh\n - -c - echo \"Happy Programming with Kubernetes!\" > /usr/share/nginx/html/index.html && service nginx stop && nginx -g \"daemon off;\"\n        imagePullPolicy: Always\n        ...\ndeployment.extensions \"simple-nginx\" edited\n```", "```\n// you may see different output on your screen, but definitely has the last line showing update successfully\n$ kubectl rollout status deployment simple-nginx\nWaiting for rollout to finish: 4 out of 5 new replicas have been updated...\nWaiting for rollout to finish: 4 out of 5 new replicas have been updated...\nWaiting for rollout to finish: 4 out of 5 new replicas have been updated...\nWaiting for rollout to finish: 4 out of 5 new replicas have been updated...\nWaiting for rollout to finish: 1 old replicas are pending termination...\nWaiting for rollout to finish: 1 old replicas are pending termination...\nWaiting for rollout to finish: 1 old replicas are pending termination...\nWaiting for rollout to finish: 4 of 5 updated replicas are available...\ndeployment \"simple-nginx\" successfully rolled out\n```", "```\n// describe the Deployment again\n$ kubectl describe deployment simple-nginx\nName:                   simple-nginx\n...\nEvents:\n  Type    Reason             Age   From                   Message\n  ----    ------             ----  ----                   -------\n  Normal  ScalingReplicaSet  1h    deployment-controller  Scaled up replica set simple-nginx-585f6cddcd to 5\n  Normal  ScalingReplicaSet  1h    deployment-controller  Scaled up replica set simple-nginx-694f94f77d to 1\n  Normal  ScalingReplicaSet  1h    deployment-controller  Scaled down replica set simple-nginx-585f6cddcd to 4\n  Normal  ScalingReplicaSet  1h    deployment-controller  Scaled up replica set simple-nginx-694f94f77d to 2\n  Normal  ScalingReplicaSet  1h    deployment-controller  Scaled down replica set simple-nginx-585f6cddcd to 3\n  Normal  ScalingReplicaSet  1h    deployment-controller  Scaled up replica set simple-nginx-694f94f77d to 3\n  Normal  ScalingReplicaSet  1h    deployment-controller  Scaled down replica set simple-nginx-585f6cddcd to 2\n  Normal  ScalingReplicaSet  1h    deployment-controller  Scaled up replica set simple-nginx-694f94f77d to 4\n  Normal  ScalingReplicaSet  1h    deployment-controller  Scaled down replica set simple-nginx-585f6cddcd to \n  Normal  ScalingReplicaSet  1h    deployment-controller  Scaled up replica set simple-nginx-694f94f77d to 5\n  Normal  ScalingReplicaSet  1h    deployment-controller  (combined from similar events): Scaled down replica set simple-nginx-585f6cddcd to 0\n```", "```\n// look at the new ReplicaSet in detail, you will find it copied the labels of the old one\n$ kubectl describe rs simple-nginx-694f94f77d\nName:           simple-nginx-694f94f77d\nNamespace:      default\nSelector:       env=test,pod-template-hash=2509509338,project=My-Happy-Web,role=frontend Labels:         env=test\n                pod-template-hash=2509509338\n                project=My-Happy-Web\n                role=frontend\n...\n// send request to the same endpoint of Service.\n$ curl $SERVICE_URL\nHappy Programming with Kubernetes!\n```", "```\n// change the image version with the subcommand \"set\"\n// when describing the deployment, we can know that the container name is the same as the name of the Deployment\n// record this change as well\n$ kubectl set image deployment simple-nginx simple-nginx=nginx:stable --record\ndeployment.apps \"simple-nginx\" image updated\n```", "```\n// check update status by rollout\n$ kubectl rollout status deployment simple-nginx\n...                                            \ndeployment \"simple-nginx\" successfully rolled out\n// check the image of Pod in simple-nginx\n$ kubectl describe deployment simple-nginx\nName:                   simple-nginx\n...\nPod Template:\n  Labels:  env=test\n           project=My-Happy-Web\n           role=frontend\n  Containers:\n   simple-nginx:\n    Image:  nginx:stable\n    Port:   80/TCP\n    Host Port:  0/TCP\n...\n```", "```\n$ kubectl get rs\nNAME                      DESIRED   CURRENT   READY     AGE\nsimple-nginx-585f6cddcd   0         0         0         1h\nsimple-nginx-694f94f77d   0         0         0         1h\nsimple-nginx-b549cc75c    5         5         5         1h\n```", "```\n// check the rollout history\n$ kubectl rollout history deployment simple-nginx\ndeployments \"simple-nginx\"\nREVISION  CHANGE-CAUSE\n1         <none>\n2         kubectl edit deployment simple-nginx --record=true\n3         kubectl set image deployment simple-nginx simple-nginx=nginx:stable --record=true\n```", "```\n// let's jump back to initial Deployment!\n// with flag --to-revision, we can specify which revision for rollback processing\n$ kubectl rollout undo deployment simple-nginx --to-revision=1\ndeployment.apps \"simple-nginx\"\n// check if the rollback update is finished\n$ kubectl rollout status deployment simple-nginx\n...                                             \ndeployment \"simple-nginx\" successfully rolled out\n// take a look at ReplicaSets, you will find that the old ReplicaSet takes charge of the business now\n$ kubectl get rs\nNAME                      DESIRED   CURRENT   READY     AGE\nsimple-nginx-585f6cddcd   5         5         5         4h\nsimple-nginx-694f94f77d   0         0         0         4h\nsimple-nginx-b549cc75c    0         0         0         3h\n// go ahead and check the nginx webpage or the details of Deployment\n$ curl $SERVICE_URL\n$ kubectl describe deployment simple-nginx\n```", "```\n// just go back to previous status\n$ kubectl rollout undo deployment simple-nginx\ndeployment.apps \"simple-nginx\"\n// look at the ReplicaSets agin, now the latest one takes the job again\n$ kubectl get rs\nNAME                      DESIRED   CURRENT   READY     AGE\nsimple-nginx-585f6cddcd   0         0         0         4h\nsimple-nginx-694f94f77d   0         0         0         4h\nsimple-nginx-b549cc75c    5         5         5         4h\n```", "```\n// create a new Deployment, and override the update strategy.\n$ kubectl run recreate-nginx --image=nginx --port=80 --replicas=5 --overrides='{\"apiVersion\": \"apps/v1\", \"spec\": {\"strategy\": {\"type\": \"Recreate\"}}}'\ndeployment.apps \"recreate-nginx\" created\n// verify our new Deployment\n$ kubectl describe deployment recreate-nginx\nName:               recreate-nginx\nNamespace:          default\nCreationTimestamp:  Sat, 05 May 2018 18:17:07 -0400\nLabels:             run=recreate-nginx\nAnnotations:        deployment.kubernetes.io/revision=1\nSelector:           run=recreate-nginx\nReplicas:           5 desired | 5 updated | 5 total | 0 available | 5 unavailable\nStrategyType:       Recreate ...\n```", "```\n// try to update recreate-strategy Deployment\n$ kubectl set image deployment recreate-nginx recreate-nginx=nginx:stable\ndeployment.apps \"recreate-nginx\" image updated\n// check both the rollout status and the events of Deployment\n$ kubectl rollout status deployment recreate-nginx\n$ kubectl describe deployment recreate-nginx\n...\nEvents:\n  Type    Reason             Age   From                   Message\n  ----    ------             ----  ----                   -------\n  Normal  ScalingReplicaSet  3h    deployment-controller  Scaled up replica set recreate-nginx-9d5b69986 to 5\n  Normal  ScalingReplicaSet  2h    deployment-controller  Scaled down replica set recreate-nginx-9d5b69986 to 0\n  Normal  ScalingReplicaSet  2h    deployment-controller  Scaled up replica set recreate-nginx-674d7f9c7f to 5\n```", "```\n// A simple nginx Kubernetes configuration file\n$ cat my-update-nginx.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: my-update-nginx\nspec:\n  replicas: 5\n  selector:\n    matchLabels:\n      run: simple-nginx\n  template:\n    metadata:\n      labels:\n        run: simple-nginx\n    spec:\n      containers:\n      - name: simple-nginx\n        image: nginx\n        ports:\n        - containerPort: 80\n\n// create the Deployment by file and recording the command in the revision tag\n$ kubectl create -f my-update-nginx.yaml --record\ndeployment.apps \"my-update-nginx\" created\n```", "```\n$ kubectl apply -f my-update-nginx-updated.yaml --record\nWarning: kubectl apply should be used on resource created by either kubectl create --save-config or kubectl apply\ndeployment.apps \"my-update-nginx\" configured\n// check the update revisions and status\n$ kubectl rollout history deployment my-update-nginx\ndeployments \"my-update-nginx\"\nREVISION  CHANGE-CAUSE\n1         kubectl create --filename=my-update-nginx.yaml --record=true\n2         kubectl apply --filename=my-update-nginx-updated.yaml --record=true\n$ kubectl rollout status deployment my-update-nginx\ndeployment \"my-update-nginx\" successfully rolled out\n```", "```\n// configuration file of creating two containers within a pod\n$ cat two-container-pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: two-container\nspec:\n  containers:\n    - name: web\n      image: nginx\n      ports:\n        - containerPort: 80\n          hostPort: 80\n    - name: centos\n      image: centos\n      command: [\"/bin/sh\", \"-c\", \"while : ;do curl http://localhost:80/; sleep 30; done\"]\n\n// create the pod\n$ kubectl create -f two-container-pod.yaml\npod \"two-container\" created\n// check the status of the newly-created Pod\n$ kubectl get pod two-container\nNAME            READY     STATUS    RESTARTS   AGE\ntwo-container   2/2       Running   0          5s\n```", "```\n$ kubectl describe pod two-container\nName:         two-container\nNamespace:    default\nNode:         ubuntu02/192.168.122.102\nStart Time:   Sat, 05 May 2018 18:28:22 -0400\nLabels:       <none>\nAnnotations:  <none>\nStatus:       Running\nIP:           192.168.79.198 Containers:\n  web:\n    Container ID:   docker://e832d294f176f643d604445096439d485d94780faf60eab7ae5d3849cbf15d75\n...\n  centos:\n    Container ID:  docker://9e35275934c1acdcfac4017963dc046f9517a8c1fc972df56ca37e69d7389a72\n...\n```", "```\n$ kubectl logs two-container centos | grep \"title\"\n<title>Welcome to nginx!</title>\n...\n```", "```\n// list containers of the Pod\n$ docker ps | grep \"two-container\"\n9e35275934c1        centos                                      \"/bin/sh -c 'while...\"   11 hours ago        Up 11 hours                             k8s_centos_two-container_default_113e727f-f440-11e7-ac3f-525400a9d353_0\ne832d294f176        nginx                                       \"nginx -g 'daemon ...\"   11 hours ago        Up 11 hours                             k8s_web_two-container_default_113e727f-f440-11e7-ac3f-525400a9d353_0\n9b3e9caf5149        gcr.io/google_containers/pause-amd64:3.1    \"/pause\"                 11 hours ago        Up 11 hours                             k8s_POD_two-container_default_113e727f-f440-11e7-ac3f-525400a9d353_0\n```", "```\n// inspect the nginx container, and use jq to parse it\n$ docker inspect e832d294f176 | jq '.[]| {NetworkMode: .HostConfig.NetworkMode, NetworkSettings: .NetworkSettings}'\n{\n  \"NetworkMode\": \"container:9b3e9caf5149ffb0ec14c1ffc36f94b2dd55b223d0d20e4d48c4e33228103723\",\n  \"NetworkSettings\": {\n    \"Bridge\": \"\",\n    \"SandboxID\": \"\",\n    \"HairpinMode\": false,\n    \"LinkLocalIPv6Address\": \"\",\n    \"LinkLocalIPv6PrefixLen\": 0,\n    \"Ports\": {},\n    \"SandboxKey\": \"\",\n    \"SecondaryIPAddresses\": null,\n    \"SecondaryIPv6Addresses\": null,\n    \"EndpointID\": \"\",\n    \"Gateway\": \"\",\n    \"GlobalIPv6Address\": \"\",\n    \"GlobalIPv6PrefixLen\": 0,\n    \"IPAddress\": \"\",\n    \"IPPrefixLen\": 0,\n    \"IPv6Gateway\": \"\",\n    \"MacAddress\": \"\",\n    \"Networks\": {}\n  }\n}\n// then inspect the centos one\n$ docker inspect 9e35275934c1 | jq '.[]| {NetworkMode: .HostConfig.NetworkMode, NetworkSettings: .NetworkSettings}'\n{\n  \"NetworkMode\": \"container:9b3e9caf5149ffb0ec14c1ffc36f94b2dd55b223d0d20e4d48c4e33228103723\",\n...\n```", "```\n// start a pod of our favourite example, nginx\n$ kubectl run nginx-pod --image=nginx --port=80 --restart=Never\npod \"nginx-pod\" created\n//expose the pod as a service listening on port 8080\n$ kubectl expose pod nginx-pod --port=8080 --target-port=80\nservice \"nginx-pod\" exposed\n// check the service IP\n$ kubectl get svc\nNAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE\nkubernetes   ClusterIP   10.96.0.1        <none>        443/TCP    1h\nnginx-pod    ClusterIP   10.102.153.182   <none>        8080/TCP   1m\n```", "```\n// check the accessibility of the service\n// create busybox and open standard input and independent terminal by flag \"i\" and \"t\", similar to docker command\n$ kubectl run busybox -it --image=busybox /bin/sh\nIf you don't see a command prompt, try pressing enter.\n/ # wget --spider 10.102.153.182:8080\nConnecting to 10.102.153.182:8080 (10.102.153.182:8080)\n```", "```\n// a configuration file defining NetworkPolicy of pod nginx-pod\n$ cat networkpolicy.yaml\nkind: NetworkPolicy\napiVersion: networking.k8s.io/v1\nmetadata:\n  name: nginx-networkpolicy\nspec:\n  podSelector:\n    matchLabels:\n      run: nginx-pod\n  ingress:\n    - from:\n      - podSelector:\n          matchLabels:\n            test: inbound\n```", "```\n// create the NetworkPolicy\n$ kubectl create -f networkpolicy.yaml\nnetworkpolicy.networking.k8s.io \"nginx-networkpolicy\" created\n// check the details of NetworkPolicy\n$ kubectl describe networkpolicy nginx-networkpolicy\nName:         nginx-networkpolicy\nNamespace:    default\nCreated on:   2018-05-05 18:36:56 -0400 EDT\nLabels:       <none>\nAnnotations:  <none>\nSpec:\n  PodSelector:     run=nginx-pod\n  Allowing ingress traffic:\n    To Port: <any> (traffic allowed to all ports)\n    From PodSelector: test=inbound\n  Allowing egress traffic:\n    <none> (Selected pods are isolated for egress connectivity)\n  Policy Types: Ingress\n```", "```\n// if you turned off the terminal, resume it with the subcommand attach\n$ kubectl attach busybox-598b87455b-s2mfq -c busybox -i -t\n// we add flag to specify timeout interval, otherwise it will just keep hanging on wget\n/ # wget --spider 10.102.153.182:8080 --timeout=3\nwget: download timed out\n```", "```\n// verify the connection by yourself with new busybox\n$ kubectl run busybox-labelled --labels=\"test=inbound\" -it --image=busybox /bin/sh\n```", "```\n$ cat nodeport-deployment.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: nodeport-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: nginx\n  template:\n    metadata:\n      labels:\n        app: nginx\n    spec:\n      containers:\n      - name: my-nginx\n        image: nginx\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: nodeport-svc\nspec:\n  type: NodePort\n  selector:\n    app: nginx\n  ports:\n    - protocol: TCP\n      port: 8080\n      targetPort: 80\n$ kubectl create -f nodeport-deployment.yaml\ndeployment.apps \"nodeport-deploy\" created\nservice \"nodeport-svc\" created\n```", "```\n$ kubectl describe service nodeport-svc\nName:                     nodeport-svc\nNamespace:                default\nLabels:                   <none>\nAnnotations:              <none>\nSelector:                 app=nginx\nType:                     NodePort\nIP:                       10.101.160.245\nPort:                     <unset>  8080/TCP\nTargetPort:               80/TCP\nNodePort:                 <unset>  30615/TCP\nEndpoints:                192.168.80.5:80,192.168.80.6:80\nSession Affinity:         None\nExternal Traffic Policy:  Cluster\nEvents:                   <none>\n```", "```\n// Take a look at following marked \"Chain\"\n$ sudo iptables -t nat -nL\n...\nChain KUBE-NODEPORTS (1 references)\ntarget     prot opt source               destination\nKUBE-MARK-MASQ  tcp  --  0.0.0.0/0            0.0.0.0/0            /* default/nodeport-svc: */ tcp dpt:30615\nKUBE-SVC-GFPAJ7EGCNM4QF4H  tcp  --  0.0.0.0/0            0.0.0.0/0            /* default/nodeport-svc: */ tcp dpt:30615\n...\nChain KUBE-SEP-DIS6NYZTQKZ5ALQS (1 references)\ntarget     prot opt source               destination\nKUBE-MARK-MASQ  all  --  192.168.80.6         0.0.0.0/0            /* default/nodeport-svc: */\nDNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            /* default/nodeport-svc: */ tcp to:192.168.80.6:80\n...\nChain KUBE-SEP-TC6HXYYMMLGUSFNZ (1 references)\ntarget     prot opt source               destination\nKUBE-MARK-MASQ  all  --  192.168.80.5         0.0.0.0/0            /* default/nodeport-svc: */\nDNAT       tcp  --  0.0.0.0/0            0.0.0.0/0            /* default/nodeport-svc: */ tcp to:192.168.80.5:80\nChain KUBE-SERVICES (2 references)\ntarget     prot opt source               destination\n...\nKUBE-SVC-GFPAJ7EGCNM4QF4H  tcp  --  0.0.0.0/0            10.101.160.245       /* default/nodeport-svc: cluster IP */ tcp dpt:8080\n...\nKUBE-NODEPORTS  all  --  0.0.0.0/0            0.0.0.0/0            /* kubernetes service nodeports; NOTE: this must be the last rule in this chain */ ADDRTYPE match dst-type LOCAL\n...\nChain KUBE-SVC-GFPAJ7EGCNM4QF4H (2 references)\ntarget     prot opt source               destination\nKUBE-SEP-TC6HXYYMMLGUSFNZ  all  --  0.0.0.0/0            0.0.0.0/0            /* default/nodeport-svc: */ statistic mode random probability 0.50000000000\nKUBE-SEP-DIS6NYZTQKZ5ALQS  all  --  0.0.0.0/0            0.0.0.0/0            /* default/nodeport-svc: */\n...\n```", "```\n// add a dummy hostname in local host file\n$ sudo sh -c \"echo `minikube ip` happy.k8s.io >> /etc/hosts\"\n```", "```\n$ cat echoserver.yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: echoserver-deploy\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: echo\n  template:\n    metadata:\n      labels:\n        app: echo\n    spec:\n      containers:\n        - name: my-echo\n          image: gcr.io/google_containers/echoserver:1.8\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: echoserver-svc\nspec:\n  selector:\n    app: echo\n  ports:\n    - protocol: TCP\n      port: 8080\n      targetPort: 8080\n```", "```\n$ kubectl create -f echoserver.yaml\ndeployment.apps \"echoserver-deploy\" created\nservice \"echoserver-svc\" created\n$ kubectl create -f nodeport-deployment.yaml\ndeployment.apps \"nodeport-deploy\" created\nservice \"nodeport-svc\" created\n```", "```\n$ cat ingress.yaml\napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: happy-ingress\n  annotations:\n nginx.ingress.kubernetes.io/rewrite-target: spec:\n  rules:\n    - host: happy.k8s.io\n      http:\n        paths:\n          - path: /nginx\n            backend:\n              serviceName: nodeport-svc\n              servicePort: 8080\n          - path: /echoserver\n            backend:\n              serviceName: echoserver-svc\n              servicePort: 8080\n```", "```\n$ kubectl create -f ingress.yaml\ningress.extensions \"happy-ingress\" created\n// \"ing\" is the abbreviation of \"ingress\"\n$ kubectl describe ing happy-ingress\nName:             happy-ingress\nNamespace:        default\nAddress:\nDefault backend:  default-http-backend:80 (172.17.0.3:8080)\nRules:\n  Host          Path  Backends\n  ----          ----  --------\n  happy.k8s.io\n                /nginx        nodeport-svc:8080 (<none>)\n                /echoserver   echoserver-svc:8080 (<none>)\nAnnotations:\n  nginx.ingress.kubernetes.io/rewrite-target\nEvents:\n  Type    Reason  Age   From                Message\n  ----    ------  ----  ----                -------\n  Normal  CREATE  14s   ingress-controller  Ingress default/happy-ingress\n```", "```\n// verify the URL set in ingress rules\n$ curl http://happy.k8s.io/nginx\n...\n<title>Welcome to nginx!</title>\n...\n$ curl http://happy.k8s.io/echoserver\nHostname: echoserver-deploy-5598f5796f-d8cr4\nPod Information:\n     -no pod information available-\nServer values:\n     server_version=nginx: 1.13.3 - lua: 10008\n...\n// the IP address would be added after connection\n$ kubectl get ing\nNAME            HOSTS          ADDRESS        PORTS     AGE\nhappy-ingress   happy.k8s.io   192.168.64.4   80        1m\n```", "```\n//this result indicates you have 2 nodes\n$ kubectl get nodes\nNAME          STATUS    ROLES         AGE       VERSION\nnode1         Ready     master,node   6h        v1.10.2\nnode2         Ready     node          6h        v1.10.2\n```", "```\n//in Google Kubernetes Engine Environment\n$ kubectl get sc\nNAME                 PROVISIONER\nstandard (default)   kubernetes.io/gce-pd\n```", "```\n$ cat daemonset-free.yaml\napiVersion: apps/v1\nkind: DaemonSet\nmetadata:\n  name: ram-check\nspec:\n  selector:\n    matchLabels:\n      name: checkRam\n  template:\n    metadata:\n      labels:\n        name: checkRam\n    spec:\n      containers:\n      - name: ubuntu-free\n        image: ubuntu\n        command: [\"/bin/bash\",\"-c\",\"while true; do free; sleep 30; done\"]\n      restartPolicy: Always\n```", "```\n$ kubectl create -f daemonset-free.yaml\ndaemonset.apps \"ram-check\" created\n\n$ kubectl get ds\nNAME        DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE\nram-check   2         2         2         2            2           <none>          5m\n```", "```\n$ kubectl get pods -o wide\nNAME              READY     STATUS    RESTARTS   AGE       IP               NODE\nram-check-6ldng   1/1       Running   0          9m        10.233.102.130   node1\nram-check-ddpdb   1/1       Running   0          9m        10.233.75.4      node2\n```", "```\n$ kubectl logs ram-check-6ldng\n              total        used        free      shared  buff/cache   available\nMem:        3623848      790144      329076        9128     2504628     2416976\nSwap:             0           0           0\n              total        used        free      shared  buff/cache   available\nMem:        3623848      786304      328028        9160     2509516     2420524\nSwap:             0           0           0\n              total        used        free      shared  buff/cache   available\nMem:        3623848      786344      323332        9160     2514172     2415944\nSwap:             0           0           0\n.\n.\n```", "```\n$ kubectl get ds\nNAME        DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE\nram-check   2         2         2         2            2           <none>          14m\n\n$ kubectl get nodes\nNAME          STATUS    ROLES         AGE       VERSION\nnode1         Ready     master,node   6h        v1.10.2\nnode2         Ready     node          6h        v1.10.2\n```", "```\n$ kubectl get nodes\nNAME          STATUS    ROLES         AGE       VERSION\nnode1         Ready     master,node   6h        v1.10.2\nnode2         Ready     node          6h        v1.10.2\nnode3         Ready     node          3m        v1.10.2\n```", "```\n$ kubectl get ds\nNAME        DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE\nram-check   3         3         3         3            3           <none>          18m\n\n$ kubectl get pods -o wide\nNAME              READY     STATUS    RESTARTS   AGE       IP               NODE\nram-check-6ldng   1/1       Running   0          18m       10.233.102.130   node1\nram-check-ddpdb   1/1       Running   0          18m       10.233.75.4      node2\nram-check-dpdmt   1/1       Running   0          3m        10.233.71.0      node3\n```", "```\n$ kubectl run apache2 --image=httpd --replicas=3\ndeployment \"apache2\" created\n\n//one of Pod has an IP address as 10.52.1.8\n$ kubectl get pods -o wide\nNAME                       READY     STATUS    RESTARTS   AGE       IP          NODE\napache2-55c684c66b-7m5zq   1/1       Running   0          5s        10.52.1.8   gke-chap7-default-pool-64212da9-z96q\napache2-55c684c66b-cjkcz   1/1       Running   0          1m        10.52.0.7   gke-chap7-default-pool-64212da9-8gzm\napache2-55c684c66b-v78tq   1/1       Running   0          1m        10.52.2.5   gke-chap7-default-pool-64212da9-bbs6\n\n//another Pod can reach to 10-52-1-8.default.pod.cluster.local $ kubectl exec apache2-55c684c66b-cjkcz -- ping -c 2 10-52-1-8.default.pod.cluster.local\nPING 10-52-1-8.default.pod.cluster.local (10.52.1.8): 56 data bytes\n64 bytes from 10.52.1.8: icmp_seq=0 ttl=62 time=1.642 ms\n64 bytes from 10.52.1.8: icmp_seq=1 ttl=62 time=0.322 ms\n--- 10-52-1-8.default.pod.cluster.local ping statistics ---\n2 packets transmitted, 2 packets received, 0% packet loss\nround-trip min/avg/max/stddev = 0.322/0.982/1.642/0.660 ms \n```", "```\n$ kubectl delete pod apache2-55c684c66b-7m5zq\npod \"apache2-55c684c66b-7m5zq\" deleted\n\n//Pod IP address has been changed to 10.52.0.7\n$ kubectl get pods -o wide\nNAME                       READY     STATUS        RESTARTS   AGE       IP          NODE\napache2-55c684c66b-7m5zq   0/1       Terminating   0          1m        <none>      gke-chap7-default-pool-64212da9-z96q\napache2-55c684c66b-cjkcz   1/1       Running       0          2m        10.52.0.7   gke-chap7-default-pool-64212da9-8gzm\napache2-55c684c66b-l9vqt   1/1       Running       0          7s        10.52.1.9   gke-chap7-default-pool-64212da9-z96q\napache2-55c684c66b-v78tq   1/1       Running       0          2m        10.52.2.5   gke-chap7-default-pool-64212da9-bbs6\n\n//DNS entry also changed\n$ kubectl exec apache2-55c684c66b-cjkcz -- ping -c 2 10-52-1-8.default.pod.cluster.local\nPING 10-52-1-8.default.pod.cluster.local (10.52.1.8): 56 data bytes\n92 bytes from gke-chap7-default-pool-64212da9-z96q.c.kubernetes-cookbook.internal (192.168.2.4): Destination Host Unreachable\n92 bytes from gke-chap7-default-pool-64212da9-z96q.c.kubernetes-cookbook.internal (192.168.2.4): Destination Host Unreachable\n--- 10-52-1-8.default.pod.cluster.local ping statistics ---\n2 packets transmitted, 0 packets received, 100% packet loss\n```", "```\n//create NameNode\n$ kubectl create -f https://raw.githubusercontent.com/kubernetes-cookbook/second-edition/master/chapter3/3-4/namenode.yaml \nservice \"hdfs-namenode-svc\" created\nstatefulset \"hdfs-namenode\" created\n\n$ kubectl get statefulset\nNAME            DESIRED   CURRENT   AGE\nhdfs-namenode   1         1         19s\n\n$ kubectl get pods\nNAME              READY     STATUS    RESTARTS   AGE\nhdfs-namenode-0   1/1       Running   0          26s\n\n//create DataNodes\n$ kubectl create -f https://raw.githubusercontent.com/kubernetes-cookbook/second-edition/master/chapter3/3-4/datanode.yaml \nstatefulset \"hdfs-datanode\" created\n\n$ kubectl get statefulset\nNAME            DESIRED   CURRENT   AGE\nhdfs-datanode   3         3         50s\nhdfs-namenode   1         1         5m\n\n$ kubectl get pods\nNAME              READY     STATUS    RESTARTS   AGE\nhdfs-datanode-0   1/1       Running   0          9m\nhdfs-datanode-1   1/1       Running   0          9m\nhdfs-datanode-2   1/1       Running   0          9m\nhdfs-namenode-0   1/1       Running   0          9m\n```", "```\n//Pod hdfs-namenode-0 has an IP address as 10.52.2.8\n$ kubectl get pods hdfs-namenode-0 -o wide\nNAME              READY     STATUS    RESTARTS   AGE       IP          NODE\nhdfs-namenode-0   1/1       Running   0          9m        10.52.2.8   gke-chapter3-default-pool-97d2e17c-0dr5\n\n```", "```\n$ kubectl exec hdfs-datanode-1 -it -- /bin/bash\nroot@hdfs-datanode-1:/#\nroot@hdfs-datanode-1:/# ping -c 1 hdfs-namenode-0.hdfs-namenode-svc.default.svc.cluster.local\nPING hdfs-namenode-0.hdfs-namenode-svc.default.svc.cluster.local (10.52.2.8): 56 data bytes\n...\n...\n```", "```\n//check the status by HDFS web console\n$ kubectl port-forward hdfs-namenode-0 :50070\nForwarding from 127.0.0.1:60107 -> 50070\n```", "```\n$ kubectl delete pod ram-check-6ldng\npod \"ram-check-6ldng\" deleted\n\n$ kubectl get pods -o wide\nNAME              READY     STATUS        RESTARTS   AGE       IP               NODE\nram-check-6ldng   1/1       Terminating 0          29m       10.233.102.132   node1\nram-check-ddpdb   1/1       Running       0          29m       10.233.75.5      node2\nram-check-dpdmt   1/1       Running       0          13m       10.233.71.0      node3\n\n$ kubectl get pods -o wide\nNAME              READY     STATUS    RESTARTS   AGE       IP               NODE\nram-check-ddpdb   1/1       Running   0          30m       10.233.75.5      node2\nram-check-dh5hq   1/1       Running   0          24s       10.233.102.135   node1 ram-check-dpdmt   1/1       Running   0          14m       10.233.71.0      node3\n```", "```\n$ kubectl get pods\nNAME              READY     STATUS    RESTARTS   AGE\nhdfs-datanode-0   1/1       Running   0          3m\nhdfs-datanode-1   1/1       Running   0          2m\nhdfs-datanode-2   1/1       Running   0          2m\nhdfs-namenode-0   1/1       Running   0          23m\n\n//delete DataNode-1\n$ kubectl delete pod hdfs-datanode-1\npod \"hdfs-datanode-1\" deleted\n\n//DataNode-1 is Terminating\n$ kubectl get pods\nNAME              READY     STATUS        RESTARTS   AGE\nhdfs-datanode-0   1/1       Running       0          3m\nhdfs-datanode-1   1/1       Terminating   0          3m\nhdfs-datanode-2   1/1       Running       0          2m\nhdfs-namenode-0   1/1       Running       0          23m\n\n//DataNode-1 is recreating automatically by statefulset \n$ kubectl get pods\nNAME              READY     STATUS              RESTARTS   AGE\nhdfs-datanode-0   1/1       Running             0          4m\nhdfs-datanode-1   0/1       ContainerCreating   0          16s\nhdfs-datanode-2   1/1       Running             0          3m\nhdfs-namenode-0   1/1       Running             0          24m\n\n//DataNode-1 is recovered\n$ kubectl get pods\nNAME              READY     STATUS    RESTARTS   AGE\nhdfs-datanode-0   1/1       Running   0          4m\nhdfs-datanode-1   1/1       Running   0          22s\nhdfs-datanode-2   1/1       Running   0          3m\nhdfs-namenode-0   1/1       Running   0          24m\n```", "```\n$ curl https://raw.githubusercontent.com/kubernetes-cookbook/second-edition/master/chapter3/3-4/datanode-pv.yaml\n...\n  volumeClaimTemplates:\n  - metadata:\n      name: hdfs-data\n    spec:\n      accessModes: [ \"ReadWriteOnce\" ]\n      resources:\n        requests:\n          storage: 10Gi\n```", "```\n$ curl https://raw.githubusercontent.com/kubernetes-cookbook/second-edition/master/chapter3/3-4/datanode-pv.yaml\n...\n          volumeMounts:\n          - mountPath: /hadoop/dfs/data\n            name: hdfs-data\n```", "```\n//delete DataNodes\n$ kubectl delete -f https://raw.githubusercontent.com/kubernetes-cookbook/second-edition/master/chapter3/3-4/datanode.yaml\nservice \"hdfs-datanode-svc\" deleted\nstatefulset \"hdfs-datanode\" deleted\n\n//delete NameNode\n$ kubectl delete -f https://raw.githubusercontent.com/kubernetes-cookbook/second-edition/master/chapter3/3-4/namenode.yaml \nservice \"hdfs-namenode-svc\" deleted\nstatefulset \"hdfs-namenode\" deleted\n\n//create NameNode again\n$ kubectl create -f https://raw.githubusercontent.com/kubernetes-cookbook/second-edition/master/chapter3/3-4/namenode.yaml\nservice \"hdfs-namenode-svc\" created\nstatefulset \"hdfs-namenode\" created\n\n//create DataNode which uses Persistent Volume (datanode-pv.yaml)\n$ kubectl create -f https://raw.githubusercontent.com/kubernetes-cookbook/second-edition/master/chapter3/3-4/datanode-pv.yaml\nservice \"hdfs-datanode-svc\" created\nstatefulset \"hdfs-datanode\" created\n\n//3 PVC has been created automatically\n$ kubectl get pvc\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\nhdfs-data-hdfs-datanode-0 Bound pvc-bc79975d-f5bd-11e7-ac7a-42010a8a00ef 10Gi RWO standard 53s\nhdfs-data-hdfs-datanode-1 Bound pvc-c753a336-f5bd-11e7-ac7a-42010a8a00ef 10Gi RWO standard 35s\nhdfs-data-hdfs-datanode-2 Bound pvc-d1e10587-f5bd-11e7-ac7a-42010a8a00ef 10Gi RWO standard 17s\n\n```", "```\n$ kubectl exec -it hdfs-namenode-0 -- /bin/bash\nroot@hdfs-namenode-0:/# hadoop fs -put /lib/x86_64-linux-gnu/* /\nroot@hdfs-namenode-0:/# exit\ncommand terminated with exit code 255\n\n//delete DataNode-1\n$ kubectl delete pod hdfs-datanode-1\npod \"hdfs-datanode-1\" deleted\n```", "```\n$ kubectl exec -it hdfs-namenode-0 -- /bin/bash\nroot@hdfs-namenode-0:/# hdfs fsck /\nConnecting to namenode via http://hdfs-namenode-0.hdfs-namenode-svc.default.svc.cluster.local:50070/fsck?ugi=root&path=%2F\nFSCK started by root (auth:SIMPLE) from /10.52.1.13 for path / at Wed Jan 10 04:32:30 UTC 2018\n....................................................................................................\n.................................................................Status: HEALTHY\n Total size: 22045160 B\n Total dirs: 2\n Total files: 165\n Total symlinks: 0\n Total blocks (validated): 165 (avg. block size 133607 B)\n Minimally replicated blocks: 165 (100.0 %)\n Over-replicated blocks: 0 (0.0 %)\n Under-replicated blocks: 0 (0.0 %)\n Mis-replicated blocks: 0 (0.0 %)\n Default replication factor: 3\n Average block replication: 3.0\n Corrupt blocks: 0\n Missing replicas: 0 (0.0 %)\n Number of data-nodes: 3\n Number of racks: 1\nFSCK ended at Wed Jan 10 04:32:30 UTC 2018 in 85 milliseconds\n\nThe filesystem under path '/' is HEALTHY\n```", "```\n//make double size of HDFS DataNodes\n$ kubectl scale statefulset hdfs-datanode --replicas=6\nstatefulset \"hdfs-datanode\" scaled\n\n$ kubectl get pods\nNAME READY STATUS RESTARTS AGE\nhdfs-datanode-0 1/1 Running 0 20m\nhdfs-datanode-1 1/1 Running 0 13m\nhdfs-datanode-2 1/1 Running 0 20m\nhdfs-datanode-3 1/1 Running 0 56s\nhdfs-datanode-4 1/1 Running 0 38s\nhdfs-datanode-5 1/1 Running 0 21s\nhdfs-namenode-0 1/1 Running 0 21m\n\n$ kubectl get pvc\nNAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE\nhdfs-data-hdfs-datanode-0 Bound pvc-bc79975d-f5bd-11e7-ac7a-42010a8a00ef 10Gi RWO standard 21m\nhdfs-data-hdfs-datanode-1 Bound pvc-c753a336-f5bd-11e7-ac7a-42010a8a00ef 10Gi RWO standard 21m\nhdfs-data-hdfs-datanode-2 Bound pvc-d1e10587-f5bd-11e7-ac7a-42010a8a00ef 10Gi RWO standard 21m\nhdfs-data-hdfs-datanode-3 Bound pvc-888b6e0d-f5c0-11e7-ac7a-42010a8a00ef 10Gi RWO standard 1m\nhdfs-data-hdfs-datanode-4 Bound pvc-932e6148-f5c0-11e7-ac7a-42010a8a00ef 10Gi RWO standard 1m\nhdfs-data-hdfs-datanode-5 Bound pvc-9dd71bf5-f5c0-11e7-ac7a-42010a8a00ef 10Gi RWO standard 1m\n```", "```\n$ cat job-dpkg.yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: package-check\nspec:\n  template:\n    spec:\n      containers:\n      - name: package-check\n        image: ubuntu\n        command: [\"dpkg-query\", \"-l\"]\n      restartPolicy: Never\n```", "```\n$ kubectl create -f job-dpkg.yaml\njob.batch \"package-check\" created\n```", "```\n$ kubectl get jobs\nNAME            DESIRED   SUCCESSFUL   AGE\npackage-check   1         1            26s\n```", "```\n$ kubectl get pods\nNo resources found, use --show-all to see completed objects.\n```", "```\n$ kubectl get pods --show-all\nNAME                  READY     STATUS      RESTARTS   AGE\npackage-check-hmjxj   0/1       Completed   0          3m\n```", "```\n$ kubectl logs package-check-hmjxj\nDesired=Unknown/Install/Remove/Purge/Hold\n| Status=Not/Inst/Conf-files/Unpacked/halF-conf/Half-inst/trig-aWait/Trig-pend\n|/ Err?=(none)/Reinst-required (Status,Err: uppercase=bad)\n||/ Name                     Version                       Architecture Description\n+++-========================-=============================-============-======================================================================\nii  adduser                  3.113+nmu3ubuntu4             all          add and remove users and groups\nii  apt                      1.2.24                        amd64        commandline package manager\nii  base-files               9.4ubuntu4.5                  amd64        Debian base system miscellaneous files\nii  base-passwd              3.5.39                        amd64        Debian base system master password and group files\nii  bash                     4.3-14ubuntu1.2               amd64        GNU Bourne Again SHell\n.\n.\n.\n```", "```\n$ kubectl describe job package-check\nName:           package-check\nNamespace:      default\nSelector:       controller-uid=9dfd1857-f5d1-11e7-8233-ae782244bd54\nLabels:         controller-uid=9dfd1857-f5d1-11e7-8233-ae782244bd54\n                job-name=package-check\nAnnotations:    <none>\nParallelism:    1\nCompletions:    1\nStart Time:     Tue, 09 Jan 2018 22:43:50 -0800\nPods Statuses:  0 Running / 1 Succeeded / 0 Failed\n.\n.\n.\n```", "```\n$ kubectl delete jobs package-check\njob.batch \"package-check\" deleted\n\n$ kubectl get pods --show-all\nNo resources found.\n```", "```\n$ cat job-dpkg-repeat.yaml\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: package-check\nspec:\n  completions: 3\n  template:\n    spec:\n      containers:\n      - name: package-check\n        image: ubuntu\n        command: [\"dpkg-query\", \"-l\"]\n      restartPolicy: Never\n```", "```\n$ kubectl create -f job-dpkg-repeat.yaml \njob.batch \"package-check\" created\n\n$ kubectl describe jobs package-check\nName:           package-check\nNamespace:      default\n...\n...\nAnnotations:    <none>\nParallelism:    1\nCompletions:    3\nStart Time:     Tue, 09 Jan 2018 22:58:09 -0800\nPods Statuses:  0 Running / 3 Succeeded / 0 Failed\n...\n...\nEvents:\n  Type    Reason            Age   From            Message\n  ----    ------            ----  ----            -------\n  Normal  SuccessfulCreate  42s   job-controller  Created pod: package-check-f72wk\n  Normal  SuccessfulCreate  32s   job-controller  Created pod: package-check-2mnw8\n  Normal  SuccessfulCreate  27s   job-controller  Created pod: package-check-whbr6\n```", "```\n$ cat job-dpkg-parallel.yaml \napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: package-check\nspec:\n  parallelism: 3\n  template:\n    spec:\n      containers:\n      - name: package-check\n        image: ubuntu\n        command: [\"dpkg-query\", \"-l\"]\n      restartPolicy: Never\n```", "```\n$ kubectl get pods --show-all\nNAME                  READY     STATUS      RESTARTS   AGE\npackage-check-5jhr8   0/1       Completed   0          1m\npackage-check-5zlmx   0/1       Completed   0          1m\npackage-check-glkpc   0/1       Completed   0          1m\n```", "```\n$ kubectl describe jobs package-check\nName:           package-check\nNamespace:      default\nSelector:       controller-uid=de41164e-f5d6-11e7-8233-ae782244bd54\nLabels:         controller-uid=de41164e-f5d6-11e7-8233-ae782244bd54\n                job-name=package-check\nAnnotations:    <none>\nParallelism:    3\nCompletions:    <unset>\n…\nEvents:\n  Type    Reason            Age   From            Message\n  ----    ------            ----  ----            -------\n  Normal  SuccessfulCreate  24s   job-controller  Created pod: package-check-5jhr8\n  Normal  SuccessfulCreate  24s   job-controller  Created pod: package-check-glkpc\n  Normal  SuccessfulCreate  24s   job-controller  Created pod: package-check-5zlmx\n```", "```\n$ cat cron-job.yaml \napiVersion: batch/v1beta1\nkind: CronJob\nmetadata:\n  name: package-check\nspec:\n  schedule: \"*/5 * * * *\"\n  concurrencyPolicy: \"Forbid\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: package-check\n            image: ubuntu\n            command: [\"dpkg-query\", \"-l\"]\n          restartPolicy: Never\n\n//create CronJob\n$ kubectl create -f cron-job.yaml \ncronjob.batch \"package-check\" created\n\n$ kubectl get cronjob\nNAME            SCHEDULE      SUSPEND   ACTIVE    LAST SCHEDULE   AGE\npackage-check   */5 * * * *   False     0         <none>\n```", "```\n//around 9 minutes later, 2 jobs have been submitted already\n$ kubectl get jobs\nNAME                       DESIRED   SUCCESSFUL   AGE\npackage-check-1515571800   1         1            7m\npackage-check-1515572100   1         1            2m\n\n//correspond Pod are remain and find by -a option\n$ kubectl get pods -a\nNAME                             READY     STATUS      RESTARTS   AGE\npackage-check-1515571800-jbzbr   0/1       Completed   0          7m\npackage-check-1515572100-bp5fz   0/1       Completed   0          2m\n```", "```\n$ cat nginx-pod.yaml\napiVersion: v1\nkind: Pod\nmetadata:\n  name: my-nginx\n  labels:\n    env: dev\nspec:\n  containers:\n  - name: my-nginx\n    image: nginx\n    ports:\n    - containerPort: 80\n```", "```\n$ cat nginx-pod.json\n{\n  \"apiVersion\": \"v1\",\n  \"kind\": \"Pod\",\n  \"metadata\": {\n       \"name\": \"my-nginx\",\n       \"labels\": {\n              \"env\": \"dev\"\n       }\n  },\n  \"spec\": {\n    \"containers\": [\n      {\n        \"name\": \"my-nginx\",\n        \"image\": \"nginx\",\n        \"ports\": [\n          {\n            \"containerPort\": 80    \n          }\n        ]\n      } \n    ]\n  }\n}\n```", "```\n// create the resource by either YAML or JSON file introduced before\n$ kubectl create -f nginx-pod.yaml\n// or\n$ kubectl create -f nginx-pod.json\n// as an example of v1.10.0, the content of schema directory may look like following\n// you would have different endpoint of server\nll ~/.kube/cache/discovery/192.168.99.100_8443/\ntotal 76\ndrwxr-xr-x 18 nosus nosus 4096 May 6 10:10 ./\ndrwxr-xr-x 4 nosus nosus 4096 May 6 10:00 ../\ndrwxr-xr-x 3 nosus nosus 4096 May 6 10:00 admissionregistration.k8s.io/\ndrwxr-xr-x 3 nosus nosus 4096 May 6 10:00 apiextensions.k8s.io/\ndrwxr-xr-x 4 nosus nosus 4096 May 6 10:00 apiregistration.k8s.io/\ndrwxr-xr-x 5 nosus nosus 4096 May 6 10:00 apps/\ndrwxr-xr-x 4 nosus nosus 4096 May 6 10:00 authentication.k8s.io/\ndrwxr-xr-x 4 nosus nosus 4096 May 6 10:00 authorization.k8s.io/\ndrwxr-xr-x 4 nosus nosus 4096 May 6 10:00 autoscaling/\ndrwxr-xr-x 4 nosus nosus 4096 May 6 10:00 batch/\ndrwxr-xr-x 3 nosus nosus 4096 May 6 10:00 certificates.k8s.io/\ndrwxr-xr-x 3 nosus nosus 4096 May 6 10:00 events.k8s.io/\ndrwxr-xr-x 3 nosus nosus 4096 May 6 10:00 extensions/\ndrwxr-xr-x 3 nosus nosus 4096 May 6 10:00 networking.k8s.io/\ndrwxr-xr-x 3 nosus nosus 4096 May 6 10:00 policy/\ndrwxr-xr-x 4 nosus nosus 4096 May 6 10:00 rbac.authorization.k8s.io/\n-rwxr-xr-x 1 nosus nosus 3898 May 6 10:10 servergroups.json*\ndrwxr-xr-x 4 nosus nosus 4096 May 6 10:00 storage.k8s.io/\ndrwxr-xr-x 2 nosus nosus 4096 May 6 10:10 v1/\n```"]