- en: Logging and Monitoring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This chapter will cover the following recipes:'
  prefs: []
  type: TYPE_NORMAL
- en: Working with EFK
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with Google Stackdriver
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring master and node
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Logging and monitoring are two of the most important tasks in Kubernetes. However,
    there are many ways to achieve logging and monitoring in Kubernetes, because there
    are a lot of logging and monitoring open source applications, as well as many
    public cloud services.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes has a best practice for setting up a logging and monitoring infrastructure
    that most Kubernetes provisioning tools support as an add-on. In addition, managed
    Kubernetes services, such as Google Kubernetes Engine, integrate GCP log and a
    monitoring service out of the box.
  prefs: []
  type: TYPE_NORMAL
- en: Let's set up a logging and monitoring service on your Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Working with EFK
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the Container world, log management always faces a technical difficulty,
    because Container has its own filesystem, and when Container is dead or evicted,
    the log files are gone. In addition, Kubernetes can easily scale out and scale
    down the Pods, so we need to care about a centralized log persistent mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes has an add-on for setting up centralized log management, which is
    called EFK. EFK stands for **Elasticsearch**, **Fluentd**, and **Kibana**. These
    applications' stack bring you a full function of log collection, indexing, and
    UI.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 1](4dd5324f-b753-4c80-b891-bd8e6013b2c1.xhtml), *Building Your Own
    Kubernetes Cluster*, we set up our Kubernetes cluster with several different provisioning
    tools. Based on your Kubernetes provisioning tool, there is an easy way to set
    up EFK stack. Note that Elasticsearch and Kibana are heavy-duty Java applications.
    They require at least 2 GB of memory each.
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, if you use minikube, your machine should have at least 8 GB of memory
    (16 GB is recommended). If you use kubespray or kops to set up Kubernetes cluster,
    Kubernetes node should have at least 4 core CPUs and 16 GB of memory in total
    (in other words, if you have 2 nodes, each node should have a minimum of 2 core
    CPUs and 8GB of memory).
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, in order to demonstrate how to gather the application logs efficiently,
    we create one additional namespace. It will help you to search your application
    log easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this recipe, we will use the following Kubernetes provisioning tools to
    set up EFK stack. Based on your Kubernetes cluster, please read the appropriate
    section of this recipe:'
  prefs: []
  type: TYPE_NORMAL
- en: minikube
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: kubespray (ansible)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: kops
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note that for GKE on the Google Cloud Platform, we will introduce another way
    to set up logging infrastructure in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up EFK with minikube
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: minikube provides an add-on feature for EFK out of the box, but it is disabled
    by default. So, you need to enable EFK on your minikube manually. EFK consumes
    a large amount of heap memory but minikube allocates only 2 GB by default, which
    is absolutely not sufficient to run the EFK stack in minikube. Therefore, we'll
    need to enlarge minikube's memory size explicitly.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, you should use the latest version of minikube, due to several
    bug fixes made for EFK while writing this cookbook. So, we are using minikube
    version 0.25.2\. Let''s configure minikube to enable EFK using the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you are already running `minikube`, stop `minikube` first:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Update to the latest version of minikube:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Since EFK consumes a large amount of heap memory, start `minikube` with 5 GB
    of memory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure, all Pods in the kube-system Namespace are up, because EFK relies
    on `kube-addon-manager-minikube`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Enable the `efk` add-on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait for a while; Elasticsearch, fluentd and kibana Pod have been deployed
    in the kube-system namespace automatically. Wait for the `STATUS `to become `Running`.
    It should take at least 10 minutes to complete:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'Use `kubectl logs` to watch a kibana that waits for the state to become `green`.
    This also takes an additional five minutes:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Access the kibana service using the `minikube service` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, you have access to the Kibana UI from your machine. You just need to set
    up an index. Since Fluentd keeps sending a log with the index name as `logstash-yyyy.mm.dd`,
    the index pattern is `logstash-*` by default. Click the Create button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/6221d481-761c-45c3-a8ad-82c7f7249adb.png)'
  prefs: []
  type: TYPE_IMG
- en: Setting up EFK with kubespray
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'kubespray has a configuration concerning whether or not to enable EFK. By default,
    it is disabled, so you need to enable it with the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: Open `<kubespray dir>/inventory/mycluster/group_vars/k8s-cluster.yaml`.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Around line number 152 in the `k8s-cluster.yml` file, change the value of  `efk_enabled` to
    `true`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Run the `ansible-playbook` command to update your Kubernetes cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Check to see if Elasticsearch, Fluentd, and Kibana Pod''s STATUS became Running
    or not; if you see the Pending state for more than 10 minutes, check `kubectl
    describe pod <Pod name>` to see the status. In most cases, you will get an error
    saying insufficient memory. If so, you need to add more Nodes or increase the
    available RAM:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'Check the kibana log to see if the status has become `green`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'Run `kubectl cluster-info`, confirm Kibana is running, and capture the URL
    of Kibana:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'In order to access the Kibana WebUI from your machine remotely, it is easier
    to use ssh port forwarding from your machine to the Kubernetes master:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Access the Kibana WebUI from your machine using the following URL: `http://localhost:8080/api/v1/namespaces/kube-system/services/kibana-logging/proxy`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Now you can access Kibana from your machine. You also need to configure the
    index. Just make sure the index name has `logstash-*` as the default value. Then,
    click the Create button:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/280efe0d-f605-4867-9a01-356809c8b4d0.png)'
  prefs: []
  type: TYPE_IMG
- en: Setting up EFK with kops
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'kops also has an add-on for setting up the EFK stack on your Kubernetes cluster
    easily. Proceed through the following steps to run EFK stack on your Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Run `kubectl create` to specify the kops EFK add-on:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'Wait for the `STATUS `of all Pods to become `Running`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Check Kibana''s log and wait until the state becomes `green`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'Run `kubetl cluster-info` to capture the Kibana URL:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Use `kubectl proxy` to forward your machine to the Kubernetes API server:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Access the Kibana WebUI from your machine using the following URL: `http://127.0.0.1:8080/api/v1/namespaces/kube-system/services/kibana-logging/proxy.
    Note that the IP address is 127.0.0.1, which is correct because we are using a
    kubectl proxy`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Now, you can start to use Kibana. Configure an index as described in the preceding
    minikube and kubespray sections.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As you can see, the installed Kibana versions are different based on the Kubernetes
    provisioning tool. But this cookbook explores the basic functions of Kibana. Therefore,
    there are no version-specific operations to worry about.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let''s launch a sample application and then learn how to monitor your application
    log using Kibana:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Prepare a sample application that keeps printing a `DateTime` and hello message
    to the `stdout`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'Create a sample application in the `chap9` namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Access the Kibana WebUI, then click the Discover tab:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Make sure the time range is `Last 15 minutes`, then type `kubernetes.namespace_name:
    chap9` in the search box and hit the *Enter* key:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/605953dd-4b60-4118-b5e1-8b43fd12b726.png)'
  prefs: []
  type: TYPE_IMG
- en: Searching the chap9 namespace log in 15 minutes
  prefs: []
  type: TYPE_NORMAL
- en: 'You can see all of the logs in the `chap9` namespaces as follows. The screenshot
    shows much more information than you might have expected. By clicking the add
    button for `kubernetes.host`, `kubernetes.pod_name`, and `log `will display only
    the fields necessary for this purpose:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/43d5f71f-eda4-47ca-a253-91abc698340c.png)'
  prefs: []
  type: TYPE_IMG
- en: Choosing log columns
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you can see a more simple log view for this application:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/640154f0-7bbe-4370-9d5c-617ca4a18e9a.png)'
  prefs: []
  type: TYPE_IMG
- en: Showing the final state of a customized Kibana view
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You now have have a centralized log management system in your
    Kubernetes cluster. You can observe the deployment of some Pods to see how you
    can see the application log.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The preceding EFK stack collects Pods' logs only, because Fluentd is monitoring
    `/var/log/containers/*` in the Kubernetes node host. It is good enough to monitor
    an application's behavior, but, as a Kubernetes administrator, you also need some
    Kubernetes system logs such as master and node logs.
  prefs: []
  type: TYPE_NORMAL
- en: There is an easy way to achieve Kubernetes system log management that integrates
    with the EFK stack; add a Kubernetes Event Exporter, which keeps monitoring a
    Kubernetes event. When the new event has occurred, send a log to Elasticsearch.
    So, you can monitor a Kubernetes event with Kibana as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have prepared an Eventer (Event Exporter) add-on ([https://raw.githubusercontent.com/kubernetes-cookbook/second-edition/master/chapter9/9-1/eventer.yml](https://raw.githubusercontent.com/kubernetes-cookbook/second-edition/master/chapter9/9-1/eventer.yml)).
    It is Heapster ([https://github.com/kubernetes/heapster](https://github.com/kubernetes/heapster)),
    based and expected to run on top of EFK add-ons. We can use this Eventer to monitor
    Kubernetes events through EFK:'
  prefs: []
  type: TYPE_NORMAL
- en: Details of Heapster will be described in the next section—*Monitoring master
    and nodes*.
  prefs: []
  type: TYPE_NORMAL
- en: 'Add eventer to your existing Kubernetes cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure Eventer Pod''s `STATUS` is `Running`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Use `kubectl logs` to keep observing Heapster and whether it can capture the
    event:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'For testing purposes, open another terminal, and then create a `nginx` Pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'Observe Heapster''s log; some new events have been captured:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Open Kibana and navigate to Settings | Indices| Add New. This will add a new
    index.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Put the Index name as `heapster-*`, set the time-field name as `Metadata.creationTimestamp`,
    and then click Create:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/bcc5beb4-06a2-4c0a-82e5-ba0fb8277743.png)'
  prefs: []
  type: TYPE_IMG
- en: Configurring a Heapster index
  prefs: []
  type: TYPE_NORMAL
- en: Go back to the Discover page, and then choose the `heapster-*` index from the
    left-hand panel.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select (click the Add button) Message, Source.component, and Source.host:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/339ef52f-785f-4797-a212-6dd019737602.png)'
  prefs: []
  type: TYPE_IMG
- en: Choosing the necessary columns
  prefs: []
  type: TYPE_NORMAL
- en: 'Now you can see the Kubernetes system log, which shows the `nginx` Pod creation
    event as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4de710de-182a-4d4f-bf5f-8a0a58b488ec.png)'
  prefs: []
  type: TYPE_IMG
- en: Showing the final state of the system log view in Kibana
  prefs: []
  type: TYPE_NORMAL
- en: Now you can monitor not only the application log, but also the Kubernetes system
    log in the EFK stack. Through switching indexes between either `logstash-*` (application
    log) or `heapster-*` (system log), you have a flexible log management environment.
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this cookbook, we learned how to enable the EFK stack for your Kubernetes
    cluster. Kibana is a powerful tool that you can use to create your own dashboard
    and keep checking the logs more efficiently. Please visit Kibana''s online documentation
    to understand how to use it:'
  prefs: []
  type: TYPE_NORMAL
- en: Kibana User Guide Reference: [https://www.elastic.co/guide/en/kibana/index.html](https://www.elastic.co/guide/en/kibana/current/index.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Working with Google Stackdriver
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In [Chapter 7](dfc46490-f109-4f07-ba76-1a381b006d76.xhtml), *Building Kubernetes
    on GCP*, we introduced GKE. It has an integrated logging mechanism, which is called
    Google Stackdriver. In this section, we will explore the integration between GKE
    and Stackdriver.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To use a Stackdriver, you just need a GCP account. If you have never used GCP,
    please go back and read [Chapter 7](dfc46490-f109-4f07-ba76-1a381b006d76.xhtml),
    *Building Kubernetes on GCP*, to set up a GCP account and the `gcloud` command-line
    interface.
  prefs: []
  type: TYPE_NORMAL
- en: 'To use Stackdriver on GKE, no action is needed, because GKE uses Stackdriver
    as a logging platform by default. But if you want to explicitly enable Stackdriver,
    specify `--enable-cloud-logging` while launching your Kubernetes by using the `gcloud`
    command, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'If, for some reason, you have a GKE that doesn''t enable Stackdriver, you can
    use the `gcloud` command to enable it afterwards:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In order to demonstrate Stackdriver with GKE, we will create one namespace
    on Kubernetes, then launch a sample Pod to see some logs on the Stackdriver, as
    shown in the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `chap9` namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: 'Prepare a sample application Pod:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Create the Pod on the `chap9` namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Access the GCP Web Console and navigate to Logging | Logs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Select Audited Resources | GKE Container | Your GKE cluster name (ex: my-gke)
    | chap9 namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/56cce8ab-6c3c-4e16-a08e-064c7457fe23.png)'
  prefs: []
  type: TYPE_IMG
- en: Selecting the chap9 namespace Pod log
  prefs: []
  type: TYPE_NORMAL
- en: 'As an alternative way of accessing the `chap9` namespace log, you can select
    an advanced filter. Then, type the following criteria to the text field and click
    the Submit Filter button:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/4e824b79-9f07-4735-8829-7a16e421fa31.png)'
  prefs: []
  type: TYPE_IMG
- en: Using an advanced filter
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/6443a266-ce69-4ce2-b263-14d382b44278.png)'
  prefs: []
  type: TYPE_IMG
- en: Input an advanced filter criterion
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, you can see the `myapp` log on Stackdriver:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/d7882e0f-0411-4fa5-ba69-a38cce0bc95f.png)'
  prefs: []
  type: TYPE_IMG
- en: Showing the chap9 Pod log in Stackdriver
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Stackdriver has a basic functionality for narrowing down a date, severity,
    and keyword search. It helps to monitor an application''s behavior. How about
    system-level behavior, such as master and node activities? Stackdriver also supports
    searching of the system-level log. Actually, `fluentd` captures not only the application
    log, but the system log as well. By performing the following steps, you can see
    the system log in Stackdriver:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Select GKE Cluster Operations | Your GKE name (for example, my-gke) | All location:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You should select All location instead of a particular location, because some
    Kubernetes operation logs do not contain location values.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/9c02d2bc-23bf-4707-be44-f29c62780a8c.png)'
  prefs: []
  type: TYPE_IMG
- en: Choosing a GKE system log in Stackdriver
  prefs: []
  type: TYPE_NORMAL
- en: 'As an alternative, input an advanced filter as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '![](img/2807ea60-99cc-4078-accf-f993e14c1c46.png)'
  prefs: []
  type: TYPE_IMG
- en: Showing a GKE system log in Stackdriver
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this recipe, we introduced Google Stackdriver. It is a built-in function
    of Google Kubernetes Engine. Stackdriver is a simple but powerful log management
    tool. In addition, Stackdriver is capable of monitoring the system status. You
    can make built-in or custom metrics to monitor and provide alerts regarding events
    as well. This will be described in the next recipe.
  prefs: []
  type: TYPE_NORMAL
- en: 'In addition, please read the following chapter to recap the basics of GCP and
    GKE:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Chapter 7](dfc46490-f109-4f07-ba76-1a381b006d76.xhtml), *Building Kubernetes
    on GCP*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Monitoring master and node
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: During the journey of the previous recipes, you learned how to build your own
    cluster, run various resources, enjoy different usage scenarios, and even enhance
    cluster administration. Now, here comes a new level of perspective for your Kubernetes
    cluster. In this recipe, we are going to talk about monitoring. Through the monitoring
    tool, users will not only learn about the resource consumption of nodes, but also
    the Pods. This will help us to have greater efficiency as regards resource utilization.
  prefs: []
  type: TYPE_NORMAL
- en: Getting ready
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'As with earlier recipes, all you have to prepare is a healthy Kubernetes cluster.
    The following command, along with `kubectl`, will help you to verify the status
    of your Kubernetes system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: For demonstration later, we will deploy the monitoring system on a `minikube-booted`
    cluster. However, it works for any kind of well-installed clusters.
  prefs: []
  type: TYPE_NORMAL
- en: How to do it...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this section, we will work on installing a monitoring system and introducing
    its dashboard. This monitoring system is based on *Heapster* ([https://github.com/kubernetes/heapster](https://github.com/kubernetes/heapster)),
    a resource usage collecting and analyzing tool. Heapster communicates with kubelet
    to get the resource usage of both machine and container. Along with Heapster,
    we have influxDB ([https://influxdata.com](https://influxdata.com)) for storage
    and Grafana ([http://grafana.org](http://grafana.org)) as the frontend dashboard,
    which visualizes the status of resources in several user-friendly plots:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/7e703755-eaf8-442f-a2b2-881dcecd6c4c.png)'
  prefs: []
  type: TYPE_IMG
- en: The interaction of monitoring components
  prefs: []
  type: TYPE_NORMAL
- en: 'Heapster gathers information from **kubelet** on each node and provides data
    for other platforms. In our case, an influxDB is a sink for saving historical
    data. It is available for users to do further data analysis, such as the prediction
    of peak workload, and then make corresponding resource adjustments. We have Grafana
    working as an affable web console; users can manage monitoring status through
    the browser. Moreover, `kubectl` has the subcommand `top`, which provides the
    ability to grep cluster-wide information through Heapster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: This command turns out an error message.
  prefs: []
  type: TYPE_NORMAL
- en: 'Installing a monitoring system could be much easier than anticipated. By applying
    configuration files from the open-source communities and companies, we can set
    up component monitoring on Kubernetes simply with the aid of a few commands:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: You could find that applying an online source is also feasible for creating
    Kubernetes applications.
  prefs: []
  type: TYPE_NORMAL
- en: How it works...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'After you have installed influxDB, Heapster, and Grafana, let''s learn how
    to get the status of the resource. First, you may use `kubectl top` now. Check
    the utilization of nodes and Pods, as well as verifying the functionality of monitoring:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Currently, `kubectl top` only covers nodes and Pods, and just shows their CPU
    and RAM usage.
  prefs: []
  type: TYPE_NORMAL
- en: According to the output of `kubectl top`, what does the **m** mean in terms
    of the quantity of CPU usage? It means "milli", as in millisecond and millimeter.
    Millicpu is regarded as 10^(-3) CPU. For example, if the Heapster Pod uses 1 m
    CPU, it only takes 0.1% CPU computation power at this moment.
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the Grafana dashboard
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, let''s take a look at the Grafana dashboard. In our case, for the minikube-booted
    cluster, we should open a proxy to enable accessibility from the localhost to
    the Kubernetes cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: 'You may access Grafana through this URL: `http://localhost:8001/api/v1/namespaces/kube-system/services/monitoring-grafana/proxy/`.
    The magic that enables us to see the web page is made by the Kubernetes DNS server
    and proxy:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Accessing the Grafana dashboard in an anti-minikube Kubernetes**'
  prefs: []
  type: TYPE_NORMAL
- en: 'To access Grafana through a browser, it depends on the network configuration
    of nodes and the Kubernetes service of Grafana. Follow these points for forwarding
    the web page to your client:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Upgrade Grafana''s service type**: The configuration file we applied creates
    Grafana with a ClusterIP service. You should change it to `NodePort` or `LoadBalancer`
    for exposing Grafana to the outside world.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Check firewalls**: Make sure your clients or load balancer are able to access
    your node of the cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dashboard access through the target port**: Instead of using a detailed URL,
    like we did on the minikube cluster, you can access Grafana with simple ones such
    as `NODE_ENTRYPOINT:3000` (Grafana requests port 3000 in the configuration file
    by default) or the entry point of the load balancer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/9b62104d-22b6-43df-839f-f3dcf61859f6.png)'
  prefs: []
  type: TYPE_IMG
- en: The home page of Grafana
  prefs: []
  type: TYPE_NORMAL
- en: 'In the default settings of Grafana, we have two dashboards, **Cluster** and
    **Pods**. The **Cluster** board covers the nodes'' resource utilization, such
    as CPU, memory, network transaction, and storage. The **Pods** dashboard has similar
    plots for each Pod and you can check each container in a Pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/e1bda91b-4fb6-4da5-804f-a586ce2eaf50.png)'
  prefs: []
  type: TYPE_IMG
- en: Viewing the Pod kube-dns by Pod dashboard
  prefs: []
  type: TYPE_NORMAL
- en: As the preceding screenshot show, for example, we can observe the CPU utilization
    of individual containers in the Pod `kube-dns` in the namespace `kube-system`,
    which is the cluster of the DNS server. You can find that there are three containers
    in this Pod, `kubedns`, `dnsmasq`, and `sidecar`, and the lines in the plot express
    the limit, request, and real usage of CPU for containers respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a new metric to monitor Pod
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For a running application, metrics are the data we can collect and use to analyze
    its behavior and performance. Metrics can come from the system side, such as the
    usage of CPU, or be based on the functionality of an application, such as the
    request frequency of certain functions. There are several metrics for monitoring
    offered by Heapster ([https://github.com/kubernetes/heapster/blob/master/docs/storage-schema.md](https://github.com/kubernetes/heapster/blob/master/docs/storage-schema.md)).
    We are going to show you how to create a customized panel by yourself. Please
    take the following steps as a reference:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Go to the dashboard of Pod, and drag the web page to the bottom. There is a
    button called ADD ROW; click it to add a metric. Then, choose the first category
    Graph as a new panel for expressing this metric:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/988cdb9a-61da-4fb4-993c-1dfbbd44ff19.png)'
  prefs: []
  type: TYPE_IMG
- en: Adding a new metric with graph expression
  prefs: []
  type: TYPE_NORMAL
- en: 'An empty panel block appears. Go ahead and click on it for further configuration.
    Just choose Edit when the editing block shows up right after you pick the panel:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/261dae87-d0cc-437e-822d-5dc45d76c76b.png)'
  prefs: []
  type: TYPE_IMG
- en: Starting to edit a panel
  prefs: []
  type: TYPE_NORMAL
- en: 'First, give your panel a name. For example, `CPU Rate`. We would like to create
    one showing the rate of CPU utilization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/5d8b175c-f7cb-4d2f-b640-6e133b8f8ddd.png)'
  prefs: []
  type: TYPE_IMG
- en: Giving the panel a title on the "General" page
  prefs: []
  type: TYPE_NORMAL
- en: 'Set up the following parameters for specific data querying. Take the following
    screenshot as reference:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'FROM: `cpu/usage_rate`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'WHERE: `type = pod_container`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AND: `namespace_name=$namespace, pod_name=$podname value`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GROUP BY: `tag(container_name)`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ALIAS BY: `$tag_container_name`'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](img/fef0d5dc-9c4c-4942-b895-c4a5a663f7fa.png)'
  prefs: []
  type: TYPE_IMG
- en: Parameters of data querying for CPU-rate metric
  prefs: []
  type: TYPE_NORMAL
- en: 'Does any line of status show up? If not, modifying the configuration in the
    display page will help you build the best looking graph for you. Make the Null
    value connected and you will find lines showing out:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![](img/f3a38ac6-cf33-48ea-b24d-63f864e5b62a.png)'
  prefs: []
  type: TYPE_IMG
- en: Editing the look of your metric. Checking the null value to be "connected" for
    showing the lines
  prefs: []
  type: TYPE_NORMAL
- en: Here you go! Feel free to close the edit mode. You now have a new metric for
    every Pod.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Just try to discover more functionality of the Grafana dashboard and the Heapster
    monitoring tool. You will obtain further details about your system, services,
    and containers through the information from the monitoring system.
  prefs: []
  type: TYPE_NORMAL
- en: There's more...
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: We built up a monitoring system based on Heapster, which is maintained by the
    Kubernetes group. Yet, several tools and platforms focusing on container cluster
    have sprung up to support the community, such as Prometheus ([https://prometheus.io](https://prometheus.io)).
    On the other hand, public clouds may have run daemons on VM for grabbing the metrics
    by default, and provided services for corresponding actions. We don't have to
    build one within the cluster. Next, we are going to introduce the monitoring method
    on AWS and GCP. You may wish to check [C*hapter 6*](b7e1d803-52d0-493b-9123-5848da3fa9ec.xhtml),
    *Building Kubernetes on AWS*, and [C*hapter 7*](dfc46490-f109-4f07-ba76-1a381b006d76.xhtml),
    *Building Kubernetes on GCP*, to build a cluster and learn more concepts.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring your Kubernetes cluster on AWS
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'While working on AWS, we usually rely on AWS CloudWatch([https://aws.amazon.com/cloudwatch/](https://aws.amazon.com/cloudwatch/))
    for monitoring. You can create a dashboard, and pick up any basic metrics you
    want. CloudWatch already collects a bunch of metrics for you:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/74f9230e-9818-4dc3-95e8-453cf4ea2bad.png)'
  prefs: []
  type: TYPE_IMG
- en: Create a new metric with AWS CloudWatch
  prefs: []
  type: TYPE_NORMAL
- en: But, for the resource of Kubernetes, such as Pods, customized metrics for them
    need to be sent out to CloudWatch with manual configuration. With a kops installation,
    it is recommended that you build your monitoring system with Heapster or Prometheus.
  prefs: []
  type: TYPE_NORMAL
- en: AWS has its own container cluster service, Amazon ECS. This may be the reason
    why AWS didn't support Kubernetes deeply and we have to build clusters through
    kops and terraform, along with other add-on services. Nevertheless, according
    to recent news, there will be a new service called **Amazon Elastic Container
    Service for Kubernetes** (**Amazon EKS**). We can look forward to the integration
    of Kubernetes and other AWS services.
  prefs: []
  type: TYPE_NORMAL
- en: Monitoring your Kubernetes cluster on GCP
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Before we look at the monitoring platform of GCP, the nodes of GKE cluster
    should admit being scanned for any applied status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: '*Google Stackdriver* provides system monitoring in a hybrid cloud environment.
    Besides its own GCP, it can also cover your computing resources on AWS. To access
    its web console, you can find its section under the menu on the left-hand side.
    There are multiple service categories in Stackdriver. Select Monitoring to check
    related functionality.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As a new user, you will get a 30-day free trial. The initial configuration
    is simple; just enable an account and bind your project. You may avoid the agent
    installation and AWS account setup since we simply want to check the GKE cluster.
    Once you log in to Stackdriver successfully, click Resources on the left-side
    panel and choose Kubernetes Engine under infrastructure type:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/4f113195-bb4d-4420-976a-93ac659c547a.png)'
  prefs: []
  type: TYPE_IMG
- en: Main page for GKE on Strackdriver monitoring
  prefs: []
  type: TYPE_NORMAL
- en: 'There are several metrics set up already for computing resources from node
    to container. Take your time exploring and check the official introduction for
    more features: [https://cloud.google.com/kubernetes-engine/docs/how-to/monitoring](https://cloud.google.com/kubernetes-engine/docs/how-to/monitoring).'
  prefs: []
  type: TYPE_NORMAL
- en: See also
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'This recipe showed you how to monitor your machines in the Kubernetes system.
    However, it is wise to study the recipes of the main components and daemons. You
    can get more ideas about working processes and resource usage. Moreover, since
    we have worked with several services to build our monitoring system, reviewing
    recipes about the Kubernetes services again will give you a clear idea about how
    you can build up this monitoring system:'
  prefs: []
  type: TYPE_NORMAL
- en: The *Exploring Architecture* recipe in [Chapter 1](1a0d884d-59d3-4f67-adee-2d2e37030132.xhtml),
    *Building Your Own Kubernetes Cluster*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The *Working with Services* recipe in [Chapter 2](e9a51674-078b-4ffc-a76c-98774150bfa3.xhtml),
    *Walking through Kubernetes Concepts*
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kubernetes is a project that keeps moving forward and upgrading apace. The
    recommended way to catch up is to check out new features on its official website:
    [http://kubernetes.io](http://kubernetes.io). Also, you can always get new Kubernetes
    versions on GitHub at [https://github.com/kubernetes/kubernetes/releases](https://github.com/kubernetes/kubernetes/releases).
    Keeping your Kubernetes system up to date, and learning new features practically,
    is the best method for accessing Kubernetes technology continuously.'
  prefs: []
  type: TYPE_NORMAL
