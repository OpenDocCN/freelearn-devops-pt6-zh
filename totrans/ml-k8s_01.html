<html><head></head><body>
		<div id="_idContainer058">
			<h1 id="_idParaDest-41"><em class="italic"><a id="_idTextAnchor040"/>Chapter 3</em>: Exploring Kubernetes</h1>
			<p>Now that you have seen that Kubernetes will form the basis of your <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) platform, it's logical to refresh your knowledge of the underlying bedrock of our solution. Though there are many resources available on the internet on this topic of Kubernetes, we will briefly discuss the role of Kubernetes in the cloud era and the flexibility it provides for building solutions. You will also learn about Operators in Kubernetes and how they help simplify the installation and operation of Kubernetes workloads. By the end of this chapter, you will have built a running <strong class="source-inline">minikube</strong> instance either in your local machine or in the cloud. This is a single-node Kubernetes cluster that you will use as the base infrastructure to build and run the ML platform.</p>
			<p>In this particular order, we will cover the following topics:</p>
			<ul>
				<li>Exploring Kubernetes major components</li>
				<li>Becoming cloud-agnostic through Kubernetes</li>
				<li>Understanding Operators</li>
				<li>Setting up your local Kubernetes environment</li>
				<li>(Optional) Provisioning a <strong class="bold">virtual machine</strong> (<strong class="bold">VM</strong>) on <strong class="bold">google cloud platform</strong> (<strong class="bold">GCP</strong>)</li>
			</ul>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor041"/>Technical requirements</h1>
			<p>This chapter includes some hands-on setup. You will be setting up a Kubernetes cluster, and for this, you will need a machine with the following hardware specifications:</p>
			<ul>
				<li>A <strong class="bold">central processing unit</strong> (<strong class="bold">CPU</strong>) with at least four cores; eight are recommended</li>
				<li>Memory of at least 16 <strong class="bold">gigabytes</strong> (<strong class="bold">GB</strong>); 32 GB is recommended</li>
				<li>Disk with available space of at least 60 GB</li>
			</ul>
			<p>This can be a physical machine such as a laptop, a server, or a VM running in the cloud that supports nested virtualization.</p>
			<h1 id="_idParaDest-43"><a id="_idTextAnchor042"/>Exploring Kubernetes major components</h1>
			<p>There are many definitions of Kubernetes available on the web. We assume that, as a Kubernetes <a id="_idIndexMarker140"/>user, you already have a favorite pick. Therefore, in this section, you will see some basic concepts to refresh your Kubernetes knowledge. This section is by no means a reference or tutorial for the Kubernetes system.</p>
			<p>From <a href="B18332_02_ePub.xhtml#_idTextAnchor027"><em class="italic">Chapter 2</em></a>, <em class="italic">Understanding MLOps</em>, you have seen that Kubernetes provides the means for your ML platform to perform the following capabilities:</p>
			<ul>
				<li><strong class="bold">Provide a declarative style of running software components</strong>: This capability will help your teams to be autonomous.</li>
				<li><strong class="bold">Provide an abstraction layer for hardware resources</strong>: Through this capability, you can run your ML platform on a variety of hardware and provide on-demand resource scheduling.</li>
				<li><strong class="bold">Provide an application programming interface (API) to interact with it</strong>: This will enable you to bring the automation for running different components onto your ML platform.</li>
			</ul>
			<p>Let's start by defining the major components of the Kubernetes platform: the control plane and the worker nodes.</p>
			<h2 id="_idParaDest-44"><a id="_idTextAnchor043"/>Control plane</h2>
			<p>The <strong class="bold">control plane</strong> is a set <a id="_idIndexMarker141"/>of components that form the <em class="italic">brains</em> of the Kubernetes. It <a id="_idIndexMarker142"/>consists of an API server, a key-value database, a scheduler, and a set of controllers. Let's define each of these components, as follows:</p>
			<ul>
				<li><strong class="bold">API server</strong>: This <a id="_idIndexMarker143"/>component provides a set of <strong class="bold">REpresentational State Transfer</strong> (<strong class="bold">REST</strong>) APIs <a id="_idIndexMarker144"/>to interact with the Kubernetes system. Everyone interacts with Kubernetes through this API. As a developer or operations engineer, you use the API, and internal Kubernetes components talk to the API server to perform different activities.</li>
				<li><strong class="bold">Key-value database</strong>: The API server is stateless; it needs to have a persistent store where <a id="_idIndexMarker145"/>it can store different objects. The key-value database is fulfilled by a component called <strong class="source-inline">etcd</strong>. No other component of the Kubernetes system talks to this value store directly—this is only accessible by the API server.</li>
				<li><strong class="bold">Scheduler</strong>: The scheduler <a id="_idIndexMarker146"/>component dictates where an application instance would be running. The scheduler selects the most suitable worker node based on the policy defined by the Kubernetes administrator.</li>
				<li><strong class="bold">Controllers</strong>: There are <a id="_idIndexMarker147"/>multiple controllers running in the control plane. Each controller has a set task; for example, a node controller is responsible for monitoring the state of the nodes.</li>
			</ul>
			<p>The following <a id="_idIndexMarker148"/>diagram shows the interaction between multiple <a id="_idIndexMarker149"/>control-plane components:</p>
			<div>
				<div id="_idContainer020" class="IMG---Figure">
					<img src="image/B18332_03_001.jpg" alt="Figure 3.1 – Kubernetes control-plane components&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.1 – Kubernetes control-plane components</p>
			<p>The control plane orchestrates the creation, update, and deletion of objects. It monitors and maintains the healthy state of the Kubernetes cluster. The control plane runs workloads that keep the cluster running. But what about the application workloads?</p>
			<h2 id="_idParaDest-45"><a id="_idTextAnchor044"/>Worker nodes</h2>
			<p>As the name suggests, workers are a set of nodes that host the application software. For example, all ML platform <a id="_idIndexMarker150"/>components will be executed on the worker nodes. However, worker nodes also run a couple of Kubernetes components that make <a id="_idIndexMarker151"/>the communication channel between the control plane and the worker and manage running applications on the worker node. These are the key components running on the worker nodes besides the applications:</p>
			<ul>
				<li><strong class="bold">Kube proxy</strong>: Its primary <a id="_idIndexMarker152"/>role is to manage network communications rules for your applications running on the node. </li>
				<li><strong class="bold">Kubelet</strong>: Think of <a id="_idIndexMarker153"/>the Kubelet software component as an agent running on each node. The primary role of this agent is to talk to the control-plane API server and manage applications running on the node. The agent also captures and sends the status of the node and the applications back to the control plane via the API.</li>
				<li><strong class="bold">Container runtime</strong>: The <a id="_idIndexMarker154"/>container runtime component is responsible for running containers that host applications, as directed by the Kubelet. <em class="italic">Docker</em> is one such example; however, Kubernetes has <a id="_idIndexMarker155"/>defined a <strong class="bold">container runtime interface</strong> (<strong class="bold">CRI</strong>). CRI defines interfaces that Kubernetes uses and the Kubernetes administrator can choose any container runtime that is compatible with the CRI.</li>
			</ul>
			<p>The following diagram shows the interaction between multiple worker-node components:</p>
			<div>
				<div id="_idContainer021" class="IMG---Figure">
					<img src="image/B18332_03_002.jpg" alt="Figure 3.2 – Kubernetes worker components&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.2 – Kubernetes worker components</p>
			<p>Worker <a id="_idIndexMarker156"/>nodes, also <a id="_idIndexMarker157"/>known as compute nodes, do the actual work of running the application workloads in the cluster. Running <a id="_idIndexMarker158"/>application workloads requires you to interact with the control plane using Kubernetes objects or resources. </p>
			<h2 id="_idParaDest-46"><a id="_idTextAnchor045"/>Kubernetes objects required to run an application</h2>
			<p>Now, let's define a set of Kubernetes <strong class="bold">objects</strong> that are commonly required to run an application <a id="_idIndexMarker159"/>on the Kubernetes system. When you build the components for your ML platform, you <a id="_idIndexMarker160"/>will be using these Kubernetes objects to run applications on top of Kubernetes. The objects are listed here:</p>
			<ul>
				<li><strong class="bold">Namespace</strong>: One Kubernetes cluster is shared by multiple teams and projects. Namespaces <a id="_idIndexMarker161"/>provide a way to isolate Kubernetes resources. This isolation allows different teams, different environments, or even different applications to share the same cluster while keeping different configurations, network policies, resource quotas, and access control. It is like having a logical sub-cluster within the same Kubernetes cluster.</li>
				<li><strong class="bold">Container image</strong>: When <a id="_idIndexMarker162"/>you want to run an application on Kubernetes, you need to package the application in a standard format. This packaged format, which consists of your application and all its dependencies, is called a container image, and the running instance of this image is <a id="_idIndexMarker163"/>called a <strong class="bold">container</strong>. It contains your application and all the dependencies, including the operating system resources and your application needs, in one common bundle.</li>
				<li><strong class="bold">Deployment</strong>: This <a id="_idIndexMarker164"/>Kubernetes object represents an application's desired state on the cluster. A Deployment object contains information such as which container image you want to run and how many instances or <em class="italic">replicas</em> of containers you require. Kubernetes is periodically comparing the current cluster state to the desired state defined in the Deployment object. When Kubernetes finds that the current state is different from the desired state, it will then apply the necessary updates to the cluster to achieve the desired state. These updates include spinning up new containers with the container image defined in the Deployment object, stopping containers, and configuring network and other resources required by the Deployment object.</li>
				<li><strong class="bold">Pods</strong>: A Pod is <a id="_idIndexMarker165"/>a fundamental unit of running <a id="_idIndexMarker166"/>applications in Kubernetes. It is also the smallest schedulable unit of deployment. It can contain one or more containers. Containers inside the pod share networking and disk resources. Containers running in a single pod are scheduled together on the same node while also having local communication with each other.</li>
				<li><strong class="bold">Services</strong>: How <a id="_idIndexMarker167"/>do pods communicate with each other? Pods communicate through the cluster network, and each pod has its <a id="_idIndexMarker168"/>own <strong class="bold">Internet Protocol</strong> (<strong class="bold">IP</strong>) address. However, pods may come and go. Kubernetes may restart a pod due to node health or scheduling changes, and when this happens, the pod's IP address will change. Furthermore, if the Deployment object is configured to run multiple replicas of the same pods, this means each replica will have its own IP address.</li>
			</ul>
			<p>A service, in Kubernetes, exposes a set of pods as a single abstracted network service. It provides <a id="_idIndexMarker169"/>a single consistent IP address and <strong class="bold">Domain Name System</strong> (<strong class="bold">DNS</strong>) name that can route traffic and perform load balancing on pods. Think of a service as a load-balanced reverse proxy to your running pods.</p>
			<ul>
				<li><strong class="bold">ConfigMaps and Secrets</strong>: We have our application packaged as a container image <a id="_idIndexMarker170"/>and running as a pod. The same pod will get deployed in multiple environments such as Dev, Test, and Production. However, each environment will have a different configuration, such as the database location or others. Hardcoding such a configuration into a container image is not the right approach. One reason is that the container image may be deployed in multiple environments with different environment settings. There must be a way to define configuration outside of the container image and inject this configuration onto our container at runtime!</li>
			</ul>
			<p>ConfigMaps and Secrets provide a way to store configuration data in Kubernetes. Once you have these objects defined, they can be injected into your running pods either as a file within the pod's filesystem or as a set of environment variables. </p>
			<p>A ConfigMap is <a id="_idIndexMarker171"/>used to store and access configuration data. However, for sensitive configurations such as passwords and private keys, Kubernetes provides a special object for this purpose, known as a Secret. Just as with ConfigMaps, Secrets can be mounted either as files or as environment variables into pods.</p>
			<p>The following diagram shows a logical relationship between Deployments, pods, ConfigMaps, and Services. A Deployment object provides an abstraction of a containerized application. This hides <a id="_idIndexMarker172"/>the complexity behind running <strong class="bold">replication controllers</strong> and pods. Deployments help you in running your application as a pod or group of pods, ConfigMaps provide an environment-specific configuration for your pods, and Services expose the pods in your deployment as a single network service:</p>
			<div>
				<div id="_idContainer022" class="IMG---Figure">
					<img src="image/B18332_03_003.jpg" alt="Figure 3.3 – Storage provisioning in Kubernetes&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.3 – Storage provisioning in Kubernetes</p>
			<ul>
				<li><strong class="bold">Storage (PersistentVolume and PersistentVolumeClaim (PV and PVC))</strong>: Pods are <a id="_idIndexMarker173"/>ephemeral. Once they are destroyed, all the local resources of the pod are gone. More often, applications <a id="_idIndexMarker174"/>deployed as pods may need access to storage <a id="_idIndexMarker175"/>to read and write persistent data that can outlive pods.</li>
			</ul>
			<p>Kubernetes promises to be the infrastructure abstraction layer on top of many hardware vendors and cloud providers. However, the way to request storage resources or provision disks is different with the various cloud providers and on-premises systems. This calls for a need to request storage resources in a consistent manner across different hardware vendors and cloud providers.</p>
			<p>Kubernetes solution to this is to split storage resources into two Kubernetes objects. A PV is an object that defines a physical storage volume. It contains the details of the underlying storage infrastructure. A PVC, on the other hand, is an abstracted pointer to a PV. A PVC indicates that the owner has a claim on a specific PV. Pods storage resources are associated with PVCs and never directly with the PV; this way, the underlying storage definition is abstracted from the application.</p>
			<p>The following <a id="_idIndexMarker176"/>diagram shows the relation between pods, PVCs, and PVs. The pod mounts a PVC as a volume; the PVC works as an abstraction layer for the pod to request a physical volume to be associated with the pod; the PVC is bound to a PV that provides specifics of the disks:</p>
			<div>
				<div id="_idContainer023" class="IMG---Figure">
					<img src="image/B18332_03_004.jpg" alt="Figure 3.4 – Storage provisioning in Kubernetes (continued)&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.4 – Storage provisioning in Kubernetes (continued)</p>
			<ul>
				<li><strong class="bold">Ingress</strong>: Services <a id="_idIndexMarker177"/>enable access to pods within the Kubernetes cluster. For scenarios in which you need access to a pod from outside the Kubernetes cluster, Ingress is the answer. Ingress provides a way for you to expose a particular service to be accessible from outside the cluster. This <a id="_idIndexMarker178"/>enables you to map a <strong class="bold">HyperText Transfer Protocol</strong> (<strong class="bold">HTTP</strong>)-based <strong class="bold">Uniform Resource Locator</strong> (<strong class="bold">URL</strong>) that <a id="_idIndexMarker179"/>points to a service. Ingress may <a id="_idIndexMarker180"/>also use <strong class="bold">Secure Sockets Layer</strong> (<strong class="bold">SSL</strong>) on the exposed URL and can be configured to terminate SSL for traffic within the cluster. This way, the transport layer will be encrypted all the way up to the Ingress, while forwarding the traffic to the pod in plain HTTP. It is also worth noting that <a id="_idIndexMarker181"/>Kubernetes allows traffic to be encrypted all the way to the pod if needed.</li>
			</ul>
			<p>The following diagram shows how Ingress enables pods to be accessible from outside the Kubernetes cluster:</p>
			<div>
				<div id="_idContainer024" class="IMG---Figure">
					<img src="image/B18332_03_005.jpg" alt="Figure 3.5 – The Ingress object in the Kubernetes cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.5 – The Ingress object in the Kubernetes cluster</p>
			<p>Now that you have refreshed your understanding of Kubernetes, let's see how Kubernetes allows you to run your platform anywhere.</p>
			<h1 id="_idParaDest-47"><a id="_idTextAnchor046"/>Becoming cloud-agnostic through Kubernetes</h1>
			<p>One of the key aspects of the ML platform we are building is that it enables the organization <a id="_idIndexMarker182"/>to run on any cloud or data center. However, each cloud has its own proprietary APIs to manage resources and deploy applications. For <a id="_idIndexMarker183"/>example, the <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>) API <a id="_idIndexMarker184"/>uses an <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>) instance (a server) when <a id="_idIndexMarker185"/>provisioning a server, while Google Cloud's API uses a <strong class="bold">Google</strong> <strong class="bold">Compute Engine</strong> (<strong class="bold">GCE</strong>) VM (a server). Even the names of the resources are different! This is where Kubernetes plays a key role.</p>
			<p>The wide adoption of Kubernetes has forced major cloud vendors to come up with tight integration solutions with Kubernetes. This allows anyone to spin up a Kubernetes cluster in AWS, GCP, or Azure in a matter of minutes.</p>
			<p>The Kubernetes API enables you to manage cloud resources. Using the standard Kubernetes API, you can deploy applications on any major cloud provider without needing to learn about the cloud provider's API. The Kubernetes API has become the abstraction layer to manage workloads in the cloud. The ML platform you will build in this book will exclusively use Kubernetes APIs to deploy and run applications. This includes the software components that make up the ML platform.</p>
			<p>The following diagram shows how Kubernetes allows you to become cloud-agnostic. You interact with Kubernetes through the Kubernetes API, which eliminates or reduces the need to interact directly with the cloud vendor's API. In other words, Kubernetes provides a consistent way of interacting with your environment regardless of which cloud or data center it is running on:</p>
			<div>
				<div id="_idContainer025" class="IMG---Figure">
					<img src="image/B18332_03_006.jpg" alt="Figure 3.6 – Kubernetes acting as a shim to cloud providers APIs &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.6 – Kubernetes acting as a shim to cloud providers APIs </p>
			<p>Another important <a id="_idIndexMarker186"/>thing that came out of the Kubernetes community is <strong class="bold">Operators</strong>. You will be using Kubernetes Operators to deploy most of the components of the ML platform. Let's dig in.</p>
			<h1 id="_idParaDest-48"><a id="_idTextAnchor047"/>Understanding Operators</h1>
			<p>In traditional <strong class="bold">information technology</strong> (<strong class="bold">IT</strong>) organizations, specialized and dedicated teams <a id="_idIndexMarker187"/>were required to maintain applications and other software components such as databases, caches, and messaging components. Those teams were continuously observing the software ecosystem and doing specific things such as taking backups for databases, upgrading and patching newer versions of software components, and more.</p>
			<p><strong class="bold">Operators</strong> are like <a id="_idIndexMarker188"/>system administrators or engineers, continuously monitoring applications running on the Kubernetes environment and performing operational tasks associated with the specific component. In other words, an Operator is an automated software manager that manages the installation and life cycle of applications on Kubernetes.</p>
			<p>Put simply, instead of you creating and updating Kubernetes Objects (Deployment, Ingress, and so on), the Operator takes this responsibility based on the configuration you provide. The configuration that directs the Operator to perform certain tasks is called a <strong class="bold">custom resource</strong> (<strong class="bold">CR</strong>), and the <a id="_idIndexMarker189"/>structure or schema for a CR is defined <a id="_idIndexMarker190"/>by an object called a <strong class="bold">CR definition</strong> (<strong class="bold">CRD</strong>).</p>
			<p>The following diagram shows how an Operator automates application operations activities. In the traditional approach, the developer builds and develops the application, and then an application operations team provides support to run the application. One of the Kubernetes Operator's aims is to automate activities that operations people perform:</p>
			<div>
				<div id="_idContainer026" class="IMG---Figure">
					<img src="image/B18332_03_007.jpg" alt="Figure 3.7 – An Operator is a software that automates tasks of the operations team&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.7 – An Operator is a software that automates tasks of the operations team</p>
			<p>Kubernetes Operators <a id="_idIndexMarker191"/>can be complex. There are Operators that manage instances of databases, while some manage clusters of pods that work together. Some <a id="_idIndexMarker192"/>Operators own just 1 or 2 CRDs, while others could own more than 10 CRDs. The <strong class="bold">Operator Lifecycle Manager</strong> (<strong class="bold">OLM</strong>) simplifies the installation and management of Kubernetes Operators. Let's dig a little bit deeper into this.</p>
			<p>In OLM, there are multiple stages required to install an Operator: creating a Deployment object for the Operator, configuring the required permissions to run an Operator (because it needs to observe changes in the Kubernetes cluster), and creating a CRD. To reduce the complexity of installing an Operator, a management layer may come in handy. OLM fulfills this role.</p>
			<p>OLM standardizes interactions with Operators. It requires that all interactions with the Operator be done through the Kubernetes API. OLM makes it easy to manage the life cycle of multiple Operators through a single standard interface—the Kubernetes API. Our ML platform will make use of a few Operators, and therefore it is useful to understand OLM and objects related to it. Let's look at them in more detail here:</p>
			<ul>
				<li><strong class="source-inline">ClusterServiceVersion</strong>: This object defines metadata about an Operator. It <a id="_idIndexMarker193"/>includes the name and version of the Operator, along with the installation information and required permissions. It also describes the CRD owned and required by the Operator.</li>
				<li><strong class="source-inline">Subscription</strong>: The <strong class="source-inline">Subscription</strong> object allows the user to install and update <a id="_idIndexMarker194"/>the Operator. OLM uses this object to install and configure Operators, CRDs, and related access-control objects.</li>
				<li><strong class="source-inline">OperatorGroup</strong>: <strong class="source-inline">OperatorGroup</strong> provides a way to associate your Operator <a id="_idIndexMarker195"/>with a specific set of namespaces. <strong class="source-inline">OperatorGroup</strong> defines a set of namespaces to which the associated Operator will react. If we do not define a set of namespaces in the <strong class="source-inline">OperatorGroup</strong> definition, then the Operator will run globally across all namespaces.</li>
			</ul>
			<p>In the next section, you will get to install and configure your local Kubernetes environment and install OLM on the Kubernetes cluster.</p>
			<h1 id="_idParaDest-49"><a id="_idTextAnchor048"/>Setting up your local Kubernetes environment</h1>
			<p>Now that <a id="_idIndexMarker196"/>we have refreshed some basic Kubernetes concepts, it's time for the rubber to hit the road. In this section, we will prepare and validate our local Kubernetes clusters. The cluster we set up here will be used to host the ML platform in later chapters.</p>
			<h2 id="_idParaDest-50"><a id="_idTextAnchor049"/>Installing kubectl</h2>
			<p><strong class="source-inline">kubectl</strong> is a <a id="_idIndexMarker197"/>command-line tool that assists in running commands against <a id="_idIndexMarker198"/>a Kubernetes cluster. You can <a id="_idIndexMarker199"/>create Kubernetes objects, view logs, and monitor the progress of your actions through this utility. The following steps will install <strong class="source-inline">kubectl</strong> on your machine.</p>
			<h3>Installing kubectl on Linux</h3>
			<p>First, let's see <a id="_idIndexMarker200"/>the process for installing <strong class="source-inline">kubectl</strong> on a machine <a id="_idIndexMarker201"/>running Linux. Follow these next steps:</p>
			<ol>
				<li value="1">Create or <strong class="bold">Secure Shell</strong> (<strong class="bold">SSH</strong>) to a Terminal session on your Linux computer.</li>
				<li>Download the <strong class="source-inline">kubectl</strong>. Kubernetes <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>). We will be using version <strong class="source-inline">1.22.4</strong> throughout the book. The following two lines of code are one command:<p class="source-code"><strong class="bold">curl -LO https://dl.k8s.io/release/v1.22.4/bin/linux/amd64/kubectl</strong></p></li>
				<li>Install the <strong class="source-inline">kubectl</strong> CLI by running the following command:<p class="source-code"><strong class="bold">sudo install kubectl /usr/local/bin/kubectl</strong></p></li>
				<li>Validate that it is installed by running the following command:<p class="source-code"><strong class="bold">kubectl version --client</strong></p></li>
			</ol>
			<p>You should see the following response to the <strong class="source-inline">version</strong> command:</p>
			<div>
				<div id="_idContainer027" class="IMG---Figure">
					<img src="image/B18332_03_008.jpg" alt="Figure 3.8 – Output of the kubectl version command in Linux&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.8 – Output of the kubectl version command in Linux</p>
			<p>You should now have <strong class="source-inline">kubectl</strong> running on your Linux machine.</p>
			<h3>Installing kubectl on macOS</h3>
			<p>First, let's <a id="_idIndexMarker202"/>see the process for installing <strong class="source-inline">kubectl</strong> on a <a id="_idIndexMarker203"/>machine running macOS. Follow these steps:</p>
			<ol>
				<li value="1">Create or <strong class="source-inline">SSH</strong> to a Terminal session on your Mac computer.</li>
				<li>Download the <strong class="source-inline">kubectl</strong> Kubernetes CLI. We will be using version <em class="italic">1.22.4</em> throughout the book.</li>
			</ol>
			<p>For Intel Macs, run the following command:</p>
			<p class="source-code"><strong class="bold">curl -LO https://dl.k8s.io/release/v1.22.4/bin/darwin/amd64/kubectl</strong></p>
			<p>For <a id="_idIndexMarker204"/>Apple M1 Macs, run the following command:</p>
			<p class="source-code"><strong class="bold">curl -LO https://dl.k8s.io/release/v1.22.4/bin/darwin/aa64/kubectl</strong></p>
			<ol>
				<li value="3">Install the <strong class="source-inline">kubectl</strong> CLI by running the following command:<p class="source-code"><strong class="bold">sudo install kubectl /usr/local/bin/kubectl</strong></p></li>
				<li>Validate <a id="_idIndexMarker205"/>that it is installed by running the following command:<p class="source-code"><strong class="bold">kubectl version --client</strong></p></li>
			</ol>
			<p>You should see the following response to the <strong class="source-inline">version</strong> command:</p>
			<div>
				<div id="_idContainer028" class="IMG---Figure">
					<img src="image/B18332_03_009.jpg" alt="Figure 3.9 – Output of the kubectl version command in macOS&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.9 – Output of the kubectl version command in macOS</p>
			<p>You should now have <strong class="source-inline">kubectl</strong> running on macOS.</p>
			<h4>Installing kubectl on Windows</h4>
			<p>Now, let's <a id="_idIndexMarker206"/>go through <a id="_idIndexMarker207"/>the steps for Windows, as follows:</p>
			<ol>
				<li value="1">Run <strong class="bold">PowerShell</strong> as <strong class="bold">Administrator</strong>.</li>
				<li>Download the <strong class="source-inline">kubectl</strong> Kubernetes CLI binary by running the following command. We will be using version <em class="italic">1.22.4</em> throughout the book:<p class="source-code"><strong class="bold">curl.exe -LO https://dl.k8s.io/release/v1.22.4/bin/windows/amd64/kubectl.exe</strong></p></li>
				<li>Copy the <strong class="source-inline">kubectl.exe</strong> file to <strong class="source-inline">c:\kubectl</strong> by running the following commands:<p class="source-code"><strong class="bold">mkdir c:\kubectl </strong></p><p class="source-code"><strong class="bold">copy kubectl.exe c:\kubectl</strong></p></li>
				<li>Add <strong class="source-inline">c:\kubectl</strong> to the <strong class="source-inline">PATH</strong> environment variable by running the following command <a id="_idIndexMarker208"/>and then restart your PowerShell Terminal:<p class="source-code"><strong class="bold">setx $ENV:PATH "$ENV:PATH;C:\kubectl" /M</strong></p></li>
				<li>Validate <a id="_idIndexMarker209"/>that it is installed by running the following command:<p class="source-code"><strong class="bold">kubectl version –client</strong></p></li>
			</ol>
			<p>You should see the following response to the <strong class="source-inline">version</strong> command:</p>
			<div>
				<div id="_idContainer029" class="IMG---Figure">
					<img src="image/B18332_03_010.jpg" alt="Figure 3.10 – Output of kubectl version command in Windows&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.10 – Output of kubectl version command in Windows</p>
			<p>You have just installed the <strong class="source-inline">kubectl</strong> Kubernetes CLI. The next step is to install <strong class="source-inline">minikube</strong>, a local, single-node Kubernetes cluster.</p>
			<h2 id="_idParaDest-51"><a id="_idTextAnchor050"/>Installing minikube</h2>
			<p><strong class="source-inline">minikube</strong> provides <a id="_idIndexMarker210"/>a way to run a local <a id="_idIndexMarker211"/>Kubernetes cluster with ease. This is a minimal cluster, and it is intended to be only used for local development or experimentation. Running Kubernetes in production environments is beyond the scope of this book.</p>
			<p>As with <strong class="source-inline">kubectl</strong>, let's go through the installation for different types of operating systems.</p>
			<h3>Installing minikube on Linux</h3>
			<p>Follow <a id="_idIndexMarker212"/>these steps to install <strong class="source-inline">minikube</strong> on Linux:</p>
			<ol>
				<li value="1">Create <a id="_idIndexMarker213"/>a Terminal session or <strong class="source-inline">SSH</strong> to your Linux computer.</li>
				<li>Install <strong class="source-inline">podman</strong> for <strong class="source-inline">minikube</strong> using the following code:<p class="source-code"><strong class="bold">sudo dnf install podman -y</strong></p></li>
				<li>Download <strong class="source-inline">minikube</strong> from this location. We are using version <strong class="source-inline">1.24.0</strong> of <strong class="source-inline">minikube</strong>:<p class="source-code"><strong class="bold">curl -LO https://storage.googleapis.com/minikube/releases/v1.24.0/minikube-linux-amd64</strong></p></li>
				<li>Install the <strong class="source-inline">minikube</strong> utility, as follows:<p class="source-code"><strong class="bold">sudo install minikube-linux-amd64 /usr/local/bin/minikube</strong></p></li>
				<li>Validate the <strong class="source-inline">minikube</strong> version, like this:<p class="source-code"><strong class="bold">minikube version</strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer030" class="IMG---Figure">
					<img src="image/B18332_03_011.jpg" alt="Figure 3.11 – Output of the minikube version command on Linux&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.11 – Output of the minikube version command on Linux</p>
			<p>You have just installed <strong class="source-inline">kubectl</strong> and <strong class="source-inline">minikube</strong> on Linux. These two command-line tools will help you to set up a local Kubernetes cluster.</p>
			<h3>Installing minikube on macOS</h3>
			<p>Although <a id="_idIndexMarker214"/>our preferred operating system is Linux <a id="_idIndexMarker215"/>for this book, we are providing steps to install <strong class="source-inline">minikube</strong> on macOS too. A lot of developers use the macOS system, and it would be beneficial to provide details for the operating system from Apple. Follow these next steps:</p>
			<ol>
				<li value="1">Download and install Docker Desktop from the Docker website or by accessing the following web page: <a href="https://www.docker.com/products/docker-desktop">https://www.docker.com/products/docker-desktop</a>.</li>
				<li>Once Docker is available, make sure that it is installed correctly by running the following command. Make sure that Docker is running before running this command:<p class="source-code"><strong class="bold">docker version</strong></p></li>
			</ol>
			<p>You should see the following response. If you get an error, please make sure that Docker is running:</p>
			<div>
				<div id="_idContainer031" class="IMG---Figure">
					<img src="image/B18332_03_012.jpg" alt="Figure 3.12 – Output of the docker version command on macOS&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.12 – Output of the docker version command on macOS</p>
			<ol>
				<li value="3">Open <a id="_idIndexMarker216"/>a Terminal on your macOS computer.</li>
				<li>Download <strong class="source-inline">minikube</strong> by running one of the following commands. You will be using <a id="_idIndexMarker217"/>version 1.24.0 of Minikube:<ul><li>If you have an Intel Mac, run the following command:<p class="source-code"><strong class="bold">curl -Lo minikube </strong>https://storage.googleapis.com/minikube/releases/v1.24.0/minikube-darwin-<strong class="bold">amd64</strong></p></li><li>If you have an M1 Mac (Apple silicon), run this command instead:<p class="source-code"><strong class="bold">curl -Lo minikube </strong>https://storage.googleapis.com/minikube/releases/v1.24.0/minikube-darwin-<strong class="bold">arm64</strong></p></li></ul></li>
				<li>Move the downloaded file to the <strong class="source-inline">/usr/local/bin</strong> folder and make the downloaded file an executable by using the following commands:<p class="source-code"><strong class="bold">sudo mv minikube /usr/local/bin</strong></p><p class="source-code"><strong class="bold">sudo chmod +x /usr/local/bin/minikube</strong></p></li>
				<li>Validate the <strong class="source-inline">minikube</strong> version, as follows:<p class="source-code"><strong class="bold">minikube version</strong></p></li>
			</ol>
			<p>You <a id="_idIndexMarker218"/>should see the following response:</p>
			<div>
				<div id="_idContainer032" class="IMG---Figure">
					<img src="image/B18332_03_013.jpg" alt="Figure 3.13 – Output of the minikube version command&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.13 – Output of the minikube version command</p>
			<p>You have <a id="_idIndexMarker219"/>just installed <strong class="source-inline">kubectl</strong> and <strong class="source-inline">minikube</strong> on macOS. These two command-line tools will help you set up a local Kubernetes cluster.</p>
			<h3>Installing minikube on Windows</h3>
			<p>As with <a id="_idIndexMarker220"/>macOS, a substantial number of developers <a id="_idIndexMarker221"/>use Windows. It would be fair to provide steps on how to run the exercises on the operating system from Microsoft, the mighty Windows. Let's dig in on how to run <strong class="source-inline">minikube</strong> on Windows using <strong class="source-inline">Hyper-V</strong>, the Microsoft virtualization layer. Please note that <strong class="source-inline">Hyper-V</strong> is available on all Windows except Windows Home. Follow these steps:</p>
			<ol>
				<li value="1">Run <strong class="bold">PowerShell</strong> as <strong class="bold">Administrator</strong>.</li>
				<li>In the PowerShell console, run the following command to enable <strong class="source-inline">Hyper-V</strong>:<p class="source-code"><strong class="bold">Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V --All</strong></p></li>
			</ol>
			<p>You should <a id="_idIndexMarker222"/>see the following response if <strong class="source-inline">Hyper-V</strong> is not <a id="_idIndexMarker223"/>enabled. If it is enabled already, the command will just print the status. Press <em class="italic">Y</em> to continue:</p>
			<div>
				<div id="_idContainer033" class="IMG---Figure">
					<img src="image/B18332_03_014.jpg" alt="Figure 3.14 – Output of the command for enabling Hyper-V on Windows&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.14 – Output of the command for enabling Hyper-V on Windows</p>
			<p>Restart the computer, if needed.</p>
			<ol>
				<li value="3">Download the <strong class="source-inline">minikube</strong> installer by opening the following link in the browser: <a href="https://github.com/kubernetes/minikube/releases/download/v1.24.0/minikube-installer.exe">https://github.com/kubernetes/minikube/releases/download/v1.24.0/minikube-installer.exe</a>.</li>
				<li>Run the downloaded installer. You should see the language setup screen, as shown in the following screenshot. Click <strong class="bold">OK</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer034" class="IMG---Figure">
					<img src="image/B18332_03_015.jpg" alt="Figure 3.15 – Language selection dialog of the minikube installer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.15 – Language selection dialog of the minikube installer</p>
			<ol>
				<li value="5">The installer will present the following welcome screen. Click <strong class="bold">Next &gt;</strong>, as illustrated in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer035" class="IMG---Figure">
					<img src="image/B18332_03_016.jpg" alt="Figure 3.16 – The minikube installer wizard&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.16 – The minikube installer wizard</p>
			<ol>
				<li value="6">The installer <a id="_idIndexMarker224"/>will present <a id="_idIndexMarker225"/>the following <strong class="bold">License Agreement</strong> screen. Click <strong class="bold">I Agree</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer036" class="IMG---Figure">
					<img src="image/B18332_03_017.jpg" alt="Figure 3.17 – License Agreement screen of the minikube installer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.17 – License Agreement screen of the minikube installer</p>
			<ol>
				<li value="7">On this <a id="_idIndexMarker226"/>screen, select the location where <a id="_idIndexMarker227"/>you want to install <strong class="source-inline">minikube</strong> and then click <strong class="bold">Install</strong>, as illustrated in the following screenshot:</li>
			</ol>
			<div>
				<div id="_idContainer037" class="IMG---Figure">
					<img src="image/B18332_03_018.jpg" alt="Figure 3.18 – Install location screen of the minikube installer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.18 – Install location screen of the minikube installer</p>
			<ol>
				<li value="8">The <a id="_idIndexMarker228"/>installation may take a few minutes. Once the <a id="_idIndexMarker229"/>installation is successful, you should see the following screen. Click <strong class="bold">Next &gt;</strong>:</li>
			</ol>
			<div>
				<div id="_idContainer038" class="IMG---Figure">
					<img src="image/B18332_03_019.jpg" alt="Figure 3.19 – Successful installation screen of the minikube installer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.19 – Successful installation screen of the minikube installer</p>
			<ol>
				<li value="9">This is <a id="_idIndexMarker230"/>the last screen in your <strong class="source-inline">minikube</strong> setup <a id="_idIndexMarker231"/>process. Click <strong class="bold">Finish</strong> to complete it:</li>
			</ol>
			<div>
				<div id="_idContainer039" class="IMG---Figure">
					<img src="image/B18332_03_020.jpg" alt="Figure 3.20 – Final screen of the minikube installer&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.20 – Final screen of the minikube installer</p>
			<ol>
				<li value="10">Finally, in <a id="_idIndexMarker232"/>the PowerShell console, set the v<a id="_idIndexMarker233"/>irtualization driver for <strong class="source-inline">minikube</strong> to <strong class="source-inline">hyperv</strong>. You can do this by running the following command:<p class="source-code"><strong class="bold">minikube config set driver hyperv</strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer040" class="IMG---Figure">
					<img src="image/B18332_03_021.jpg" alt="Figure 3.21 – Output of the minikube config command&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.21 – Output of the minikube config command</p>
			<p>Congratulations—you have set up the <strong class="source-inline">minikube</strong> program on your Windows machine!</p>
			<p>Over the preceding sections, you have installed the <strong class="source-inline">kubectl</strong> and <strong class="source-inline">minikube</strong> tools to set up your Kubernetes cluster. In the next section, you will set up a Kubernetes cluster.</p>
			<h3>Setting up a local Kubernetes cluster</h3>
			<p>Now, we will <a id="_idIndexMarker234"/>set up a Kubernetes cluster on your local machine. As mentioned in the technical requirements, we will need a minimum of 4 CPU cores <a id="_idIndexMarker235"/>or <strong class="bold">virtual CPUs</strong> (<strong class="bold">vCPUs</strong>), 60 GB of available disk, and at least 16 GB of memory to be allocated to the Kubernetes cluster. Our recommended configuration is 8 CPUs and 64 GB of memory with 60 GB of disk space. If you do not have these resources available locally, you can provision a Linux host in the cloud. We will describe in the next section how to provision a host on Google Cloud. Proceed as follows:</p>
			<ol>
				<li value="1">Set up the <strong class="source-inline">minikube</strong> configuration for CPU, disk, and memory through the following commands:<p class="source-code"><strong class="bold">minikube config set cpus 8</strong></p><p class="source-code"><strong class="bold">minikube config set memory 32GB</strong></p><p class="source-code"><strong class="bold">minikube config set disk-size 60GB</strong></p></li>
				<li>Validate if the configuration is set correctly via the following command:<p class="source-code"><strong class="bold">minikube config view</strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer041" class="IMG---Figure">
					<img src="image/B18332_03_022.jpg" alt="Figure 3.22 – Output of the minikube config command&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.22 – Output of the minikube config command</p>
			<ol>
				<li value="3">Now, start the Kubernetes cluster by running the following command:<p class="source-code"><strong class="bold">minikube start --kubernetes-version=1.22.4</strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer042" class="IMG---Figure">
					<img src="image/B18332_03_023.jpg" alt="Figure 3.23 – Partial output of the minikube start command&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.23 – Partial output of the minikube start command</p>
			<p>Once the start process is completed, you should see a successful message like this after the Kubernetes platform is available: </p>
			<div>
				<div id="_idContainer043" class="IMG---Figure">
					<img src="image/B18332_03_024.jpg" alt="Figure 3.24 – Output after the successful start of minikube&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.24 – Output after the successful start of minikube</p>
			<ol>
				<li value="4">Validate <a id="_idIndexMarker236"/>that all the pods are in the <strong class="bold">Running</strong> state through the following command on Linux or macOS. Note that it may take a few minutes for the pods to be in the <em class="italic">Running</em> state:<p class="source-code"><strong class="bold">watch kubectl get pods --all-namespaces</strong></p></li>
			</ol>
			<p>Or, run this command in Windows PowerShell:</p>
			<p class="source-code"><strong class="bold">while (1) {kubectl get pods --all-namespaces; sleep 5}</strong></p>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer044" class="IMG---Figure">
					<img src="image/B18332_03_025.jpg" alt="Figure 3.25 – Validating the Kubernetes pods have started successfully&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.25 – Validating the Kubernetes pods have started successfully</p>
			<p>Congratulations! You just installed and validated your new Kubernetes cluster. The next step is to install components that will allow you to run Operators on your new Kubernetes cluster.</p>
			<h2 id="_idParaDest-52"><a id="_idTextAnchor051"/>Installing OLM</h2>
			<p>After you <a id="_idIndexMarker237"/>have validated that all pods are running for <a id="_idIndexMarker238"/>the local Kubernetes cluster, you will now install <strong class="bold">OLM</strong>. The process for installing OLM or any other applications inside Kubernetes is the same for all operating systems types. Proceed as follows:</p>
			<ol>
				<li value="1">Run the following command to install the CRD for the OLM:<p class="source-code"><strong class="bold">kubectl apply -f </strong>https://github.com/operator-framework/operator-lifecycle-manager/releases/download/v0.19.1/crds.yaml</p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer045" class="IMG---Figure">
					<img src="image/B18332_03_026.jpg" alt="Figure 3.26 – Validating OLM CRs have been created successfully&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.26 – Validating OLM CRs have been created successfully</p>
			<ol>
				<li value="2">Run the following command to install OLM on Kubernetes:<p class="source-code"><strong class="bold">kubectl apply -f </strong>https://github.com/operator-framework/operator-lifecycle-manager/releases/download/v0.19.1/olm.yaml</p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer046" class="IMG---Figure">
					<img src="image/B18332_03_027.jpg" alt="Figure 3.27 – Creating OLM objects in Kubernetes &#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.27 – Creating OLM objects in Kubernetes </p>
			<ol>
				<li value="3">Validate <a id="_idIndexMarker239"/>if all OLM pods are in the <em class="italic">Running</em> state by running this command on Linux or macOS:<p class="source-code"><strong class="bold">watch kubectl get pods -n olm</strong></p></li>
			</ol>
			<p>Or, run this <a id="_idIndexMarker240"/>command in Windows PowerShell:</p>
			<p class="source-code"><strong class="bold">while (1) {kubectl get pods -n olm; sleep 5}</strong></p>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer047" class="IMG---Figure">
					<img src="image/B18332_03_028.jpg" alt="Figure 3.28 – Validating resources for OLM have been created successfully&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.28 – Validating resources for OLM have been created successfully</p>
			<ol>
				<li value="4">Validate that <strong class="source-inline">catalogsource</strong> is available by issuing the following command:<p class="source-code"><strong class="bold">kubectl get catalogsource -n olm</strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer048" class="IMG---Figure">
					<img src="image/B18332_03_029.jpg" alt="Figure 3.29 – Validating Operator catalog has been installed&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.29 – Validating Operator catalog has been installed</p>
			<p>Congratulations! You now have a local version of the Kubernetes cluster running and you have installed OLM on it. Your cluster is now ready to install Kubernetes Operators. Some of <a id="_idIndexMarker241"/>you may not have an access to a machine <a id="_idIndexMarker242"/>with the required minimum hardware requirements to run the ML platform, but don't worry—we've got you covered. The following section will help you provision the VM that you need in Google Cloud.</p>
			<h1 id="_idParaDest-53"><a id="_idTextAnchor052"/>Provisioning a VM on GCP</h1>
			<p>It is always preferable to have a local environment that you can use to work on the exercises <a id="_idIndexMarker243"/>in this book. However, we understand that not everyone has the required compute resources <a id="_idIndexMarker244"/>available in their local machines. So, let's go to the cloud! You can provision just the right machine that you need for the exercises, in the cloud, and for free. For instance, Google Cloud gives <strong class="bold">United States dollars</strong> (<strong class="bold">USD</strong>) $300 worth of credit to new accounts. Other cloud providers such as AWS and Azure also give a similar free tier account, and it is up to you to select the cloud provider of your choice. For provisioning the VM we need for this book, however, we will use Google Cloud.</p>
			<p>Once you have the account details sorted, use the following steps to provision a VM in your account. Just do not forget to stop the VM instance after you have completed a session to avoid getting billed for the hours that you are not using your machine.</p>
			<p>The following instruction will guide you through the process of provisioning a VM in Google Cloud:</p>
			<ol>
				<li value="1">First, register for a new account at <a href="https://cloud.google.com">https://cloud.google.com</a>.</li>
				<li>Install the <strong class="source-inline">gcloud</strong> <strong class="bold">software development kit</strong> (<strong class="bold">SDK</strong>) by following the steps at <a href="https://cloud.google.com/sdk/docs/install">https://cloud.google.com/sdk/docs/install</a>.</li>
				<li>Log in to Google Cloud using the following command. This command will open a browser instance where you provide login credentials for your Google Cloud account:<p class="source-code"><strong class="bold">gcloud auth login</strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer049" class="IMG---Figure">
					<img src="image/B18332_03_030.jpg" alt="Figure 3.30 – Output for the login command&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.30 – Output for the login command</p>
			<ol>
				<li value="4">Then, it <a id="_idIndexMarker245"/>will take you to the browser where you will authenticate. Once the browser <a id="_idIndexMarker246"/>completes the authentication steps, you will see the following output in the command line:</li>
			</ol>
			<div>
				<div id="_idContainer050" class="IMG---Figure">
					<img src="image/B18332_03_031.jpg" alt="Figure 3.31 – Output of a successful login to the gcloud account&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.31 – Output of a successful login to the gcloud account</p>
			<ol>
				<li value="5">Create a new project in Google Cloud, as follows. Your VM will belong to this project. Note that the project name must be globally unique in GCP, so please change it as per your preference:<p class="source-code"><strong class="bold">gcloud projects create mlops-kube --name="MLOps on Kubernetes"</strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer051" class="IMG---Figure">
					<img src="image/B18332_03_032.jpg" alt="Figure 3.32 – Output of the create project command in Google Cloud&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.32 – Output of the create project command in Google Cloud</p>
			<p class="callout-heading">Projects in GCP</p>
			<p class="callout">Project <strong class="bold">identifiers</strong> (<strong class="bold">IDs</strong>) or project <a id="_idIndexMarker247"/>names must be globally unique across Google Cloud. Only the first person will be able to create a project with the name <strong class="source-inline">mlops-kube</strong>. Choose a different project name of your choice for this command to work. You also need to use the chosen project name for subsequent commands where the <strong class="source-inline">mlops-kube</strong> project name is specified. </p>
			<ol>
				<li value="6">Make <a id="_idIndexMarker248"/>sure you are in the right project by issuing the following command:<p class="source-code"><strong class="bold">gcloud config set project mlops-kube</strong></p></li>
			</ol>
			<p>You <a id="_idIndexMarker249"/>should see the following response:</p>
			<div>
				<div id="_idContainer052" class="IMG---Figure">
					<img src="image/B18332_03_033.jpg" alt="Figure 3.33 – Output of the command for setting the current project context&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.33 – Output of the command for setting the current project context</p>
			<ol>
				<li value="7">Set the right region and zone as per your location. You can get a list of all zones via the <strong class="source-inline">gcloud compute zones list</strong> command, as shown here:<p class="source-code"><strong class="bold">gcloud config set compute/region australia-southeast1</strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer053" class="IMG---Figure">
					<img src="image/B18332_03_034.jpg" alt="Figure 3.34 – Output after setting up the gcloud region&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.34 – Output after setting up the gcloud region</p>
			<p>Run the following command:</p>
			<p class="source-code"><strong class="bold">gcloud config set compute/zone australia-southeast1-a</strong></p>
			<p>You should then see the following response:</p>
			<div>
				<div id="_idContainer054" class="IMG---Figure">
					<img src="image/B18332_03_035.jpg" alt="Figure 3.35 – Output after setting up the gcloud zone&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.35 – Output after setting up the gcloud zone</p>
			<ol>
				<li value="8">Enable <a id="_idIndexMarker250"/>the Compute Engine API, as follows. This step is required to provision the Linux VM via APIs: <p class="source-code"><strong class="bold">gcloud services enable compute.googleapis.com</strong></p></li>
				<li>Disable <strong class="bold">OS Login</strong> because you only connect via SSH, as follows:<p class="source-code"><strong class="bold">gcloud compute project-info add-metadata --metadata enable-oslogin=FALSE</strong></p></li>
				<li>Now, create <a id="_idIndexMarker251"/>a VM within this project by running the following command:<p class="source-code"><strong class="bold">gcloud compute instances create mlopskube-cluster --project=mlops-kube --zone=australia-southeast1-a --machine-type=c2-standard-8 --network-interface=network-tier=PREMIUM,subnet=default --maintenance-policy=MIGRATE --service-account=702800110954-compute@developer.gserviceaccount.com --scopes=https://www.googleapis.com/auth/devstorage.read_only,https://www.googleapis.com/auth/logging.write,https://www.googleapis.com/auth/monitoring.write,https://www.googleapis.com/auth/servicecontrol,https://www.googleapis.com/auth/service.management.readonly,https://www.googleapis.com/auth/trace.append --create-disk=auto-delete=yes,boot=yes,device-name=instance-1,image=projects/centos-cloud/global/images/centos-8-v20211105,mode=rw,size=80,type=projects/mlops-kube/zones/australia-southeast1-b/diskTypes/pd-balanced --no-shielded-secure-boot --shielded-vtpm --shielded-integrity-monitoring --reservation-affinity=any</strong></p></li>
			</ol>
			<p>The output of the command should display the machine details, as illustrated here:</p>
			<div>
				<div id="_idContainer055" class="IMG---Figure">
					<img src="image/B18332_03_036.jpg" alt="Figure 3.36 – Output of the create VM command on Google Cloud&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.36 – Output of the create VM command on Google Cloud</p>
			<ol>
				<li value="11">Add a <a id="_idIndexMarker252"/>firewall rule to allow access to the instance via port <strong class="source-inline">22</strong> for SSH, as follows. This is a <a id="_idIndexMarker253"/>lenient rule and should <em class="italic">NOT</em> be used in production:<p class="source-code"><strong class="bold">gcloud compute --project=mlops-kube firewall-rules create allow22 --direction=INGRESS --priority=1000 --network=default --action=ALLOW --rules=tcp:22 --source-ranges=0.0.0.0/0</strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer056" class="IMG---Figure">
					<img src="image/B18332_03_037.jpg" alt="Figure 3.37 – Output of the firewall rule command&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.37 – Output of the firewall rule command</p>
			<ol>
				<li value="12">SSH to the machine using the <strong class="source-inline">gcloud</strong> SSH capability, as follows. This will give the command line, and you can call the Kubernetes command mentioned in the preceding section:<p class="source-code"><strong class="bold">gcloud beta compute ssh --zone "australia-southeast1-a" "mlopskube-cluster"  --project "mlops-kube"</strong></p></li>
				<li>Delete the instance after you have completed the session, as follows: <p class="source-code"><strong class="bold">gcloud  compute instances delete --zone "australia-southeast1-a" "mlopskube-cluster"  --project "mlops-kube"</strong></p></li>
			</ol>
			<p>You should see the following response:</p>
			<div>
				<div id="_idContainer057" class="IMG---Figure">
					<img src="image/B18332_03_038.jpg" alt="Figure 3.38 – Deleting the machine on Google Cloud&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">Figure 3.38 – Deleting the machine on Google Cloud</p>
			<p>At this <a id="_idIndexMarker254"/>point, you can <a id="_idIndexMarker255"/>use this <strong class="source-inline">gcloud</strong> VM as the host machine for your Kubernetes cluster. Following the previous sections, you should now know how to install <strong class="source-inline">kubectl</strong> and <strong class="source-inline">minikube</strong> and how to set up a local Kubernetes cluster in this VM.</p>
			<h1 id="_idParaDest-54"><a id="_idTextAnchor053"/>Summary</h1>
			<p>In this chapter, you have reviewed some basic Kubernetes concepts and gone through the Operator ecosystem in the Kubernetes universe. If you want to learn more about Kubernetes, <em class="italic">The Kubernetes Workshop</em> by Packt is a good place to start. </p>
			<p>You have installed the tooling required to set up a local Kubernetes cluster. You have seen the instructions to do it in other environments such as Linux, macOS, and Windows. You have set up a VM on Google Cloud in case you do not want to use your local computer for the exercises. You have configured OLM to manage Operators on your Kubernetes cluster. These technologies will form the infrastructure foundation of our ML platform, which you will start to shape up in the next chapter.</p>
		</div>
	</body></html>