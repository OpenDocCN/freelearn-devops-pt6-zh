- en: '14'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Backing Up Workloads
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Backup products for Kubernetes are vital components of our ever-evolving journey
    into the world of container orchestration and cloud-native computing. In this
    chapter, we will explore using Velero’s capabilities and how it can help you ensure
    resilience and reliability for your workloads. Velero, meaning “safety” or “protection”
    in Italian, is a great name since it provides a safety net for your applications,
    allowing you to confidently run them in a dynamic, ever-changing environment.
  prefs: []
  type: TYPE_NORMAL
- en: As you dive deeper into Kubernetes and microservices, you will quickly realize
    the advantages of backing up, restoring, and migrating applications. While Kubernetes
    is a remarkable system for deploying and managing containerized applications,
    it doesn’t inherently provide tools for data protection and disaster recovery.
    This gap is filled by **Velero**, which presents a complete solution for safeguarding
    your Kubernetes workloads and the data connected with them.
  prefs: []
  type: TYPE_NORMAL
- en: Velero was originally known as Heptio Ark. Heptio was a company co-founded by
    two of Kubernetes’ original creators, Joe Beda and Craig McLuckie. Since then,
    it has become part of the VMware Tanzu portfolio, demonstrating its importance
    to the Kubernetes ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we will explore the key features and use cases of Kubernetes
    and Velero, from basic backup and restore operations to more advanced scenarios
    like cross-cluster migrations. Whether you are just beginning your Kubernetes
    journey or are a seasoned Kubernetes operator, Velero is a tool worth learning.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Kubernetes backups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Performing an `etcd` backup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introducing and setting up VMware’s Velero
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using Velero to back up workloads and PVCs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing Velero using the CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restoring from a backup
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To carry out the hands-on experiments in this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: An Ubuntu 22.04+ server running Docker with a minimum of 8 GB of RAM.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A KinD cluster built to the specifications in *Chapter 2*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Scripts from the `chapter14` folder from the repo, which you can access by
    going to this book’s GitHub repository: [https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Kubernetes backups
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Backing up a Kubernetes cluster requires backing up not only the workloads running
    on the cluster. You need to consider any persistent data and the cluster itself.
    Remember that the cluster state is maintained in an `etcd` database, making it
    a very important component that you need to back up in order to recover from any
    disasters.
  prefs: []
  type: TYPE_NORMAL
- en: 'Creating a backup of the cluster and the running workloads allows you to do
    the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Migrate clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a development cluster from a production cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recover a cluster from a disaster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Recover data from persistent volumes.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Namespace and deployment recovery.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In this chapter, we will provide the details and tools to back up your `etcd`
    database, your namespace, the objects in them, and any persistent data you have
    attached to your workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Recovering a cluster from a complete disaster in an enterprise usually involves
    backing up custom SSL certificates for various components, such as Ingress controllers,
    load balancers, and the API server. Since the process of backing up all custom
    components is different in many environments, we will focus on the procedures
    that are common among most Kubernetes distributions.
  prefs: []
  type: TYPE_NORMAL
- en: As you know, the cluster state is maintained in `etcd`, and if you lose all
    of your `etcd` instances, you will lose your cluster. In a multi-node control
    plane, you should have a minimum of three `etcd` instances, providing redundancy
    for the cluster. If you lose a single node, the cluster will remain running, and
    you can replace the failed node with a new node. Once the new instance has been
    added, it will receive a copy of the `etcd` database and your cluster will be
    back to full redundancy.
  prefs: []
  type: TYPE_NORMAL
- en: In the event that you lose all of your `etcd` servers without any backup of
    the database, you would lose the cluster, including the cluster state and all
    of the workloads. Since `etcd` is so important, the `etcdctl` utility includes
    a built-in backup function. In the next section, we will show you how to take
    an `etcd` backup using the `etcdctl` utility.
  prefs: []
  type: TYPE_NORMAL
- en: Performing an etcd backup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Since we are using KinD for our Kubernetes cluster, we can create a backup of
    the `etcd` database, but we will not be able to restore it.
  prefs: []
  type: TYPE_NORMAL
- en: Our `etcd` server is running in a pod on the cluster called `etcd-cluster01-control-plane`,
    located in the `kube-system` namespace. During the creation of the KinD cluster,
    we added an extra port mapping for the control plane node, exposing port `2379`,
    which is used to access `etcd`. In your own production environment, you may not
    have the `etcd` port exposed for external requests, but the process of backing
    up the database will still be similar to the steps explained in this section.
  prefs: []
  type: TYPE_NORMAL
- en: Backing up the required certificates
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most Kubernetes installations store certificates in `/etc/kubernetes/pki`. In
    this respect, KinD is no different, so we can back up our certificates using the
    `docker cp` command.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have said it a few times: `etcd` is very important! So, it stands to reason
    that accessing the database directly probably has some security around it. Well,
    it does, and to access it, you need to provide the correct certificates when you
    execute a command against the database. In an enterprise, you should store these
    keys in a secure location. For our example, we will pull the certificates from
    the KinD nodes.'
  prefs: []
  type: TYPE_NORMAL
- en: We have included a script in the `chapter14/etcd` directory called `install-etcd-tools.sh`
    that will execute the steps to download and execute the backup of the `etcd` database.
    To execute the script, change to the `chapter14/etcd` directory and execute the
    installation script.
  prefs: []
  type: TYPE_NORMAL
- en: 'Running the script will download the `etcd` tools, extract them, and move them
    to `usr/bin` so we can execute them easily. It will then create a directory for
    the certificates and copy them into the newly created directory, `/etcd/certs`.
    The certificates that we will use for backing up `etcd` are:'
  prefs: []
  type: TYPE_NORMAL
- en: '`ca.crt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`healthcheck-client.crt`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`healthcheck-client.key`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When you execute commands using the `etcdctl` utility, you will need to provide
    the keys or your actions will be denied.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have the certificates required to access `etcd`, the next step is
    to create a backup of the database.
  prefs: []
  type: TYPE_NORMAL
- en: Backing up the etcd database
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The creators of `etcd` created a utility that backs up and restores the `etcd`
    database, called `etcdctl`. For our purposes, we will only use the backup operation;
    however, since `etcd` is not exclusive to Kubernetes, the utility has a number
    of options that you will not use as a Kubernetes operator or developer. If you
    want to read more about this utility, you can visit the `etcd-io` Git repository
    at [https://github.com/etcd-io/etcd](https://github.com/etcd-io/etcd).
  prefs: []
  type: TYPE_NORMAL
- en: To back up a database, you will need the `etcdctl` utility and the certificates
    required to access the database, which we copied from the control plane server.
  prefs: []
  type: TYPE_NORMAL
- en: The script that we executed in the last section downloaded `etcctl`, and we
    moved it into `usr/bin`. To create a backup of the database, make sure you are
    in the `chapter14/etcd` directory and that the `certs` directory exists with the
    downloaded certificates.
  prefs: []
  type: TYPE_NORMAL
- en: 'To back up `etcd`, we execute the `etcd snapshot save` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Older versions of `etcdctl` required you to set the API version to 3 using `ETCDCTL_API=3`
    since they default to the version 2 API. `etcd 3.4` changed the default API to
    3, so we do not need to set that variable before using `etcdctl` commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'It shouldn’t take too long for the database to be copied over. If it takes
    more than a few seconds, you should try the same command with the `--debug=true`
    flag. Adding the debug flag will provide more output during the execution of the
    snapshot. The most common reason for the snapshot failing is an incorrect certificate.
    Below is an example of the verbose output from a snapshot command that had an
    incorrect certificate:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: Notice the `x509` error. This is likely caused by an incorrect certificate in
    your `etcdctl` command. Check that you have the correct certificates, and re-run
    the command.
  prefs: []
  type: TYPE_NORMAL
- en: 'If the command is successful, you will receive output similar to this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Next, we can verify that the database was copied over successfully by trying
    a simple `etcdctl` command that will provide a summary of the backup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'This will output an overview of the backup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: For this example, we only backed up the `etcd` database once. In a real-life
    scenario, you should create a scheduled process that executes a snapshot of `etcd`
    at regular intervals and stores the backup file in a safe, secure location.
  prefs: []
  type: TYPE_NORMAL
- en: Due to how KinD runs the control plane, we cannot use the restore procedures
    in this section. We are providing only the backup steps in this section so that
    you know how to back up an `etcd` database in an enterprise environment.
  prefs: []
  type: TYPE_NORMAL
- en: So far, you have learned about the critical importance of backing up both workloads
    and persistent data in Kubernetes, including the `etcd` database. Having a good
    backup strategy allows you to facilitate cluster migrations, create new development
    clusters from production clusters, and recover from disasters. By knowing these
    strategies, you can ensure improved disaster recovery preparedness, enhanced operational
    efficiency, and data security. Mastering these techniques will equip you to manage
    and recover Kubernetes clusters more effectively, ensuring a resilient and reliable
    environment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s move on and introduce the tool we will use to demonstrate Kubernetes
    backups: Velero.'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing and setting up VMware’s Velero
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Velero** is an open-source backup solution for Kubernetes that was originally
    developed by a company called Heptio. As VMware has enhanced its support for Kubernetes,
    it has purchased multiple companies, and Heptio is one of its acquisitions, bringing
    Velero into the VMware portfolio.'
  prefs: []
  type: TYPE_NORMAL
- en: VMware has moved most of its offerings around Kubernetes under the Tanzu umbrella.
    This can be a little confusing for some people since the original iteration of
    Tanzu was a deployment of multiple components that added Kubernetes support to
    vSphere clusters. Since the initial incarnation of Tanzu, it has come to include
    components such as Velero, Harbor, and the **Tanzu Application Platform** (**TAP**),
    none of which require vSphere to function; they will run natively in any standard
    Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Even with all of the ownership and branding changes, the base functions of Velero
    have remained. It offers many features that are only available in commercial products,
    including scheduling, backup hooks, and granular backup controls – all for no
    charge.
  prefs: []
  type: TYPE_NORMAL
- en: While Velero is free, it has a learning curve since it does not include an easy-to-use
    GUI like most commercial products. All operations in Velero are carried out using
    their command-line utility, an executable called `velero`. This single executable
    allows you to install the Velero server, create backups, check the status of backups,
    restore backups, and more. Since every operation for management can be done with
    one file, restoring a cluster’s workloads is a very easy process. In this chapter,
    we will create a second KinD cluster and populate it with a backup from an existing
    cluster.
  prefs: []
  type: TYPE_NORMAL
- en: But before that, we need to take care of a few requirements.
  prefs: []
  type: TYPE_NORMAL
- en: Velero requirements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Velero consists of a few components with which you create a backup system:'
  prefs: []
  type: TYPE_NORMAL
- en: '**The Velero CLI**: This provides the installation of Velero components. It
    is used for all backup and restore functions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The Velero server**: This is responsible for executing backup and restore
    procedures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage provider plug-ins**: These are used for backing up and restoring
    to specific storage systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outside of the base Velero components, you will also need to provide an object
    storage location that will be used to store your backups. If you do not have an
    object storage solution, you can deploy MinIO, which is an open-source project
    that provides an S3-compatible object store. We will deploy MinIO in our KinD
    cluster to demonstrate the backup and restore features provided by Velero.
  prefs: []
  type: TYPE_NORMAL
- en: Installing the Velero CLI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first step of deploying Velero is to download the latest Velero CLI binary.
    We have included a script to install the Velero binary in the `chapter14` directory
    called `install-velero-binary.sh`, which will download the Velero binary, move
    it to `/usr/bin`, and then output the version of Velero to verify that the binary
    has been installed correctly. As of the writing of this chapter, the latest version
    of Velero is 1.12.1.
  prefs: []
  type: TYPE_NORMAL
- en: You can safely ignore the last line, which shows an error in finding the Velero
    server. Right now, all we have installed is the Velero executable, and it can’t
    find the server yet. In the next section, we will install the server to complete
    the installation.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Velero
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Velero has minimal system requirements, most of which are easily met:'
  prefs: []
  type: TYPE_NORMAL
- en: A Kubernetes cluster running version 1.16 or higher
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Velero executable
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Images for the system components
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A compatible storage location
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A volume snapshot plugin (optional)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Depending on your infrastructure, you may not have a compatible location for
    the backups or snapshotting volumes. Fortunately, if you do not have a compatible
    storage system, there are open-source options that you can add to your cluster
    to meet the requirements.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explain the natively supported storage options
    and since our example will use a KinD cluster, we will install open-source options
    to add compatible storage to use as a backup location.
  prefs: []
  type: TYPE_NORMAL
- en: Backup storage location
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Velero requires an S3-compatible bucket to store backups. There are a number
    of officially supported systems, including all object store offerings from AWS,
    Azure, and Google.
  prefs: []
  type: TYPE_NORMAL
- en: In the following table, the **Support** column means that the plugin provides
    a compatible location for storing Velero backups. The **Volume Snapshot Support**
    column means that the plugin supports backing up persistent volumes using snapshots.
    If the CSI in use does not provide snapshot support, data will be backed up using
    a standard file system backup via Restic or Kopia. Snapshots offer several advantages,
    with the most significant being their ability to maintain application consistency.
    Velero ensures that snapshots are captured in a manner that maintains the state
    of the application, minimizing the likelihood of data corruption.
  prefs: []
  type: TYPE_NORMAL
- en: 'Along with the officially supported providers, there are a number of community-
    and vendor-supported providers from companies such as DigitalOcean, Hewlett-Packard,
    and Portworx. The following table lists all of the current providers:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Vendor** | **Object Store** | **Volume Snapshot Support** | **Support**
    |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon | AWS S3 | AWS EBS | Official |'
  prefs: []
  type: TYPE_TB
- en: '| Google | Google Cloud Storage | GCE Disks | Official |'
  prefs: []
  type: TYPE_TB
- en: '| Microsoft | Azure Blob Storage | Azure Managed Disks | Official |'
  prefs: []
  type: TYPE_TB
- en: '| VMware | Not Supported | vSphere Volumes | Official |'
  prefs: []
  type: TYPE_TB
- en: '| Kubernetes CSI | Not Supported | CSI Volumes | Official |'
  prefs: []
  type: TYPE_TB
- en: '| Alibaba Cloud | Alibaba Cloud OSS | Alibaba Cloud | Community |'
  prefs: []
  type: TYPE_TB
- en: '| DigitalOcean | DigitalOcean Object Storage | DigitalOcean Volumes Block Storage
    | Community |'
  prefs: []
  type: TYPE_TB
- en: '| HP | Not Supported | HPE Storage | Community |'
  prefs: []
  type: TYPE_TB
- en: '| OpenEBS | Not Supported | OpenEBS cStor Volumes | Community |'
  prefs: []
  type: TYPE_TB
- en: '| Portworx | Not Supported | Portworx Volumes | Community |'
  prefs: []
  type: TYPE_TB
- en: '| Storj | Storj Object Storage | Not Supported | Community |'
  prefs: []
  type: TYPE_TB
- en: 'Table 14.1: Velero storage options'
  prefs: []
  type: TYPE_NORMAL
- en: If you do not have an object storage solution, you can deploy the open-source
    S3 provider MinIO, which is what we will use for our S3 target in this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Now that the Velero executable has been installed and our KinD cluster has persistent
    storage, thanks to the auto-provisioner from Rancher, we can move on to the first
    requirement – adding an S3-compatible backup location for Velero.
  prefs: []
  type: TYPE_NORMAL
- en: Deploying MinIO
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**MinIO** is an open-source object storage solution that is compatible with
    Amazon’s S3 cloud services API. You can read more about MinIO in its GitHub repository
    at [https://github.com/minio/minio](https://github.com/minio/minio).'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you install MinIO using a manifest from the internet, be sure to verify
    what volumes are declared in the deployment before trying to use it as a backup
    location. Many of the examples on the internet use `emptyDir: {}`, which is not
    persistent.'
  prefs: []
  type: TYPE_NORMAL
- en: We have included a modified MinIO deployment from the Velero GitHub repository
    in the `chapter14` folder. Since we have persistent storage on our cluster, we
    edited the volumes in the deployment to use **Persistent Volume Claims** (**PVCs**),
    which will use the auto-provisioner for Velero’s data and configuration.
  prefs: []
  type: TYPE_NORMAL
- en: 'To deploy the MinIO server, change directories to `chapter14` and execute `kubectl
    create`. The deployment will create a Velero namespace, PVCs, and MinIO on your
    KinD cluster. It may take some time for the deployment to complete. We have seen
    the deployment take anything from a minute to a few minutes, depending on the
    host system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This will deploy the MinIO server and expose it as `minio` on port `9000/TCP`,
    with the `console` on port `9001/TCP`, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The MinIO server can be targeted by any pod in the cluster, with correct access
    keys, using `minio.velero.svc` on port `9000`.
  prefs: []
  type: TYPE_NORMAL
- en: With MinIO deployed, we need to expose the console using an Ingress rule so
    we can log in to look at buckets and verify that backups are working as expected.
  prefs: []
  type: TYPE_NORMAL
- en: Exposing MinIO and the console
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By default, your MinIO storage will only be available inside the cluster it
    has been deployed in. Since we will demonstrate restoring to a different cluster
    at the end of the chapter, we need to expose MinIO using an Ingress rule. MinIO
    also includes a dashboard that allows you to browse the contents of the S3 buckets
    on the server. To allow access to the dashboard, you can deploy an Ingress rule
    that exposes the MinIO console.
  prefs: []
  type: TYPE_NORMAL
- en: We have included a script in the `chapter14` folder called `create-minio-ingress.sh`
    that will create an Ingress rule using the `nip.io` syntax of `minio-console.w.x.y.z.nip.ip`
    and `minio.w.x.y.z.nip.ip`, with your host IP.
  prefs: []
  type: TYPE_NORMAL
- en: You will need the `console` Ingress rule when you install Velero in your cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once deployed, you can use a browser on any machine and open the URL you used
    for the Ingress rule. On our cluster, the host IP is `10.2.1.161`, so our URL
    is `minio-console.10.2.1.161.nip.io`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21165_14_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.1: MinIO dashboard'
  prefs: []
  type: TYPE_NORMAL
- en: To access the dashboard, supply the access key and secret key from the MinIO
    deployment. If you used the MinIO installer from the GitHub repository, the username
    and password have been defined in the manifest. They are `packt/packt123`.
  prefs: []
  type: TYPE_NORMAL
- en: Once logged in, you will see a list of buckets and any items that are stored
    in them. You should see a bucket named **velero**, which is the bucket we will
    use to back up our cluster. This bucket was created during the initial MinIO deployment
    – we added a line to the deployment that creates the **velero** bucket and the
    required permissions for the packt user.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21165_14_02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.2: MinIO browser'
  prefs: []
  type: TYPE_NORMAL
- en: If you are new to object storage, it is important to note that while this deploys
    a storage solution in your cluster, it **will not** create a `StorageClass` or
    integrate with Kubernetes in any way. All pod access to the S3 bucket is done
    using the URL that we will provide in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Now that you have an S3-compatible object store running, you need to create
    a configuration file that Velero will use to target your MinIO server.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Velero
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To deploy Velero in your cluster, you can use the Velero binary or a Helm chart.
    We have chosen to install Velero using the binary.
  prefs: []
  type: TYPE_NORMAL
- en: Before we start the installation, we need to create a credentials file that
    will contain the `access_key` and `secret_access_key` for the S3 target on MinIO.
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new credential file in the `chapter14` folder called `credentials-velero`
    with the following content:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: Next, we can deploy Velero using the Velero executable and the `install` option
    to deploy Velero with the option to back up persistent volumes.
  prefs: []
  type: TYPE_NORMAL
- en: Execute the Velero installation using the following command from inside the
    `chapter14` folder to deploy Velero. Please note that you need to provide your
    `nip.io` ingress name for MinIO. We exposed both MinIO and the console when we
    created the Ingress rule earlier. Be careful to use the ingress name that contains
    `minio.w.x.y.z.nip.io`; do not use the `minio-console` ingress or Velero will
    fail to find the S3 bucket.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s explain the installation options and what the values mean:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Option** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `--provider` | Configures Velero to use a storage provider. Since we are
    using MinIO, which is S3-compatible, we are passing `aws` as our provider. |'
  prefs: []
  type: TYPE_TB
- en: '| `--plugins` | Tells Velero the backup plugin to use. For our cluster, since
    we are using MinIO for object storage, we selected the AWS plugin. |'
  prefs: []
  type: TYPE_TB
- en: '| `--bucket` | The name of the S3 bucket that you want to target. |'
  prefs: []
  type: TYPE_TB
- en: '| `--secret-file` | Points to the file that contains the credentials to authenticate
    with the S3 bucket. |'
  prefs: []
  type: TYPE_TB
- en: '| `--use-volume-snapshots` | Will enable or disable volume snapshots for providers
    that support snapshots. Currently, Velero only supports object storage with snapshots;
    if snapshots are not supported, this should be set to `false`. Since we are not
    interested in snapshots for our examples, we set this to `false`. |'
  prefs: []
  type: TYPE_TB
- en: '| `--backup-location-config` | The S3 target location where Velero will store
    backups. Since MinIO is running in the same cluster as Velero, we can target S3
    using the name `minio.velero.svc:9000`. In a production environment, you would
    use MinIO in the same cluster – you will likely have an external S3 target to
    store your backups. Using the Kubernetes service name will cause Velero `describe`
    commands to have some errors since it tries to query the cluster using the name
    provided, and you cannot access `minio.velero.svc` from outside of the cluster.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `--use-node-agent` | Add this flag if you want to back up persistent volumes
    using Velero’s node agent. |'
  prefs: []
  type: TYPE_TB
- en: '| `--default-volumes-to-fs-backup` | Configures Velero to support opting out
    of backing up persistent volumes. If this isn’t added during deployment, you can
    still use the option during a Velero backup to back up volumes. This will be explained
    more in the *Backing up PVCs* section of this chapter. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 14.2: Velero install options'
  prefs: []
  type: TYPE_NORMAL
- en: When you execute the install, you will see a number of objects being created,
    including a number of **CustomResourceDefinitions** (**CRDs**) and other objects
    that Velero uses to handle backup and restore operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you run into issues with your Velero server starting up correctly, there
    are a few CRDs and Secrets that you can look at that may have incorrect information.
    In the following table, we explain some of the common objects that you may need
    to interact with when using Velero:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **CustomResourceDefinition** | **Name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `backups.velero.io` | `Backup` | Each backup that is created will create
    an object called `backup`, which includes the settings for each backup job. |'
  prefs: []
  type: TYPE_TB
- en: '| `backupstoragelocations.velero.io` | `BackupStorageLocation` | Each backup
    storage location creates a `BackupStorageLocation` object that contains the configuration
    to connect to the storage provider. |'
  prefs: []
  type: TYPE_TB
- en: '| `schedules.velero.io` | `Schedule` | Each scheduled backup creates a `Schedule`
    object that contains the schedule for a backup. |'
  prefs: []
  type: TYPE_TB
- en: '| `volumesnapshotlocations.velero.io` | `VolumeSnapshotLocation` | If enabled,
    the `VolumeSnapshotLocation` object contains the information for the storage used
    for volume snapshots. |'
  prefs: []
  type: TYPE_TB
- en: '| **Secret Name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `cloud-credentials` | Contains the credentials to connect to the storage
    provider in Base64 format. If your Velero pod fails to start up, you may have
    an incorrect value in the `data.cloud` spec. |'
  prefs: []
  type: TYPE_TB
- en: '| `velero-repo-credentials` | If you are using the Restic plugin, this will
    contain your repository password, similar to `cloud-credentials`. If you experience
    issues connecting to the volume snapshot provider, verify that the repository
    password is correct. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 14.3: Velero’s CRDs and Secrets'
  prefs: []
  type: TYPE_NORMAL
- en: While most of your interaction with these objects will be through the Velero
    executable, it is always a good practice to understand how utilities interact
    with the API server. Understanding the objects and what their functions are is
    helpful if you do not have access to the Velero executable but you need to view,
    or potentially change, an object value to address an issue quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have Velero installed and a high-level understanding of Velero objects,
    we can move on to creating different backup jobs for a cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Using Velero to back up workloads and PVCs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Velero supports running a one-time backup with a single command or on a recurring
    schedule. Whether you choose to run a single backup or a recurring backup, you
    can back up all objects or only certain objects using `include` and `exclude`
    flags.
  prefs: []
  type: TYPE_NORMAL
- en: Backing up PVCs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since data is becoming increasingly common on Kubernetes clusters, we will back
    up all of the cluster workloads, including any PVCs that are in the cluster. When
    we installed Velero, we added the `--use-node-agent` option, which created a **DaemonSet**
    that creates a node agent on each cluster node. The DaemonSet deploys a pod containing
    modules that can perform file system backups, including a data mover, which may
    be **Restic** or **Kopia** (*default*) on each node, and a new secret is created
    in the `velero` namespace called `velero-repo-credentials`. This secret contains
    a `repository-password` that will be used for your backups. This is a generated
    password, and you can change it to anything you want – however, if you plan to
    change the password, do it before creating any backups. If this password is changed
    after you have created any backups, Velero will not be able to read the old backups.
  prefs: []
  type: TYPE_NORMAL
- en: The default `ServiceAccount` token, `Secrets`, and `ConfigMaps` can be mapped
    to volumes. These are not volumes that contain data and will not be backed up
    using the node agent. Like any other base Kubernetes objects, they will be backed
    up when Velero backs up the other namespace objects.
  prefs: []
  type: TYPE_NORMAL
- en: The data movers are responsible for copying the data from the volumes. Previous
    Velero releases used Restic as the data mover, but it has been enhanced to include
    both Restic and Kopia in the node DaemonSet. By default, Kopia will be used as
    the data mover, but if you want to use Restic, you can change the default by adding
    the option `--data-mover restic` to your Velero backup create command. There is
    some debate around which data mover to use and Kopia has become the leader, so
    it has become the default.
  prefs: []
  type: TYPE_NORMAL
- en: 'Velero can be configured to back up PVCs via two different approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Opt-out**: Velero will back up all PVCs, unless a workload is annotated with
    the volume name(s) to ignore.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Opt-in**: Only workloads that have an annotation with the volume’s name will
    be backed up. This is Velero’s default configuration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s take a closer look at these two approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Using the opt-out approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is the approach we will use for the exercises. When using this approach,
    all PVCs will be backed up unless you specify an annotation in the pod, adding
    `backup.velero.io/backup-volumes-excludes`. For example, if you had 3 PVCs named
    `volume1`, `volume2`, and `volume3` in a namespace and you wanted to exclude `volume2`
    and `volume3` from being backed up, you would need to add the following annotation
    to the pod spec in your deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Since we added only `volume2` and `volume3` to the exclusion, Velero will ignore
    those volumes from the backup, but it will back up the PVC named `volume1` since
    it was not included in the list.
  prefs: []
  type: TYPE_NORMAL
- en: During the installation of Velero, we set `--default-volumes-to-fs-backup`,
    which tells Velero to back up all persistent data, unless a volume has an annotation
    to exclude it from being backed up. If you didn’t set that option during your
    Velero deployment, you can tell Velero to use the opt-out approach for a single
    backup by adding the same option, `--default-volumes-to-fs-backup`, to the `backup`
    command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: When a backup is created using this option, Velero will back up every persistent
    volume that is attached to pods, unless it has been excluded in the `excludes`
    annotation.
  prefs: []
  type: TYPE_NORMAL
- en: Using the opt-in approach
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you deployed Velero without the `--default-volumes-to-fs-backup` option,
    persistent volumes will not be backed up unless you add an annotation to tell
    Velero to back up the required volumes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly to how you opted out in the previous example, you can add an annotation
    to your deployment to instruct Velero to back up your volume or volumes. The annotation
    that you need to add is `backup.velero.io/backup-volumes`, and the following example
    tells Velero to back up two volumes, one called volume1 and the other called `volume2`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: When you run your next backup, Velero will see the annotation and will add the
    two persistent volumes to the backup job.
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of backing up data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Velero cannot back up a volume that is using `hostPath` for the persistent
    data. The `local-path-provisioner` maps persistent disks to a `hostPath` by default,
    meaning that Velero will not be able to back up or restore the data. Luckily,
    there is an option to change the type from `hostPath` to `local`, which will work
    with Velero. When you create a new PVC, you can add an annotation of `volumeType:
    local`. The example below shows a PVC manifest that would be created as a local
    type, rather than `hostPath`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This change is not needed in many cases, but since it’s required when using
    the local-path-provisioner, we will need to add the annotation to any PVCs that
    we want to test with Velero.
  prefs: []
  type: TYPE_NORMAL
- en: With Velero deployed with the ability to back up our persistent data, let’s
    jump into creating a one-time backup of our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Running a one-time cluster backup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create an initial backup, you can run a single Velero command that will back
    up all of the namespaces in the cluster and if there are any PVCs that have not
    been annotated to be ignored, they will also be backed up.
  prefs: []
  type: TYPE_NORMAL
- en: Executing a backup without any flags to include or exclude any cluster objects
    will back up every namespace and all of the objects in the namespace.
  prefs: []
  type: TYPE_NORMAL
- en: We will use what we learn in this section to perform a restore to show Velero
    in action. For our backup, we will back up the entire cluster, including the PVCs.
  prefs: []
  type: TYPE_NORMAL
- en: Before we start a backup, we are going to add a deployment with a PVC, where
    we will add a few empty files to verify that restoring data works as expected.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `chapter14/pvc-example` directory, there is a manifest called `busybox-pvc.yaml`.
    To deploy the example, you should execute the command from within the `chapter14/pvc-example`
    directory:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: The script will create a new namespace called `demo` with the `busybox-pvc`
    pod deployed using a PVC named `test-claim`, mounted in the `/mnt` directory of
    the container.
  prefs: []
  type: TYPE_NORMAL
- en: 'Right now, the PVC has one file, `original-data`, in it. We need to add a few
    other files to test a restore a little later. First, let’s verify the current
    contents of the PVC using `kubectl` `exec` to list the directory contents. If
    you are following along on your own cluster, you will need to change the `busybox-pvc`
    pod name to whatever is in use on your cluster. You can get the pod name using
    `kubectl get pods -n demo`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'This will list the `busybox` pod information. You will need the pod name to
    execute the exec command to create the files in the PVC:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now, let’s add two additional files called `newdata1` and `newdata2` to the
    pod. To do this, we will use another `kubectl exec` command that will touch files
    in the `/mnt` directory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Again, to verify the data has been written successfully, we can list the contents
    using `kubectl exec`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: Great! We can see that the two new files have been created. Now that we have
    new data in the pod, we can move on to backing up our cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a one-time backup, execute the `velero` command with the `backup
    create <backup name>` option. In our example, we have named the backup `initial-backup`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'The only confirmation you will receive from this is that the backup request
    was submitted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Fortunately, Velero also tells you the command to check the backup status and
    logs. The last line of the output tells us that we can use the `velero` command
    with the `backup` option and either `describe` or `logs` to check the status of
    the backup operation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The `describe` option will show all of the details of the job. An example is
    shown below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: Notice the last section. This section tells us that Velero backed up 4 PVCs
    using the Kopia data mover. We will show this more when we perform a backup.
  prefs: []
  type: TYPE_NORMAL
- en: To reinforce the previous section, where we mentioned some of the CRDs that
    Velero uses, we also want to explain where the Velero utility retrieves this information
    from.
  prefs: []
  type: TYPE_NORMAL
- en: Each backup that is created will create a backup object in the Velero namespace.
    For our initial backup, a new backup object named `initial-backup` was created.
    Using `kubectl`, we can describe the object to see similar information that the
    Velero executable will provide.
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding output, the `describe` option shows you all of the
    settings for the backup job. Since we didn’t pass any options to the backup request,
    the job contains all the namespaces and objects. Some of the most important details
    to verify are the phase, the total items to be backed up, and the items backed
    up.
  prefs: []
  type: TYPE_NORMAL
- en: If the status of the phase is anything other than `success`, you may not have
    all the items that you want in your backup. It’s also a good idea to check the
    backed-up items; if the number of items backed up is less than the items to be
    backed up, our backup did not back up all of the items.
  prefs: []
  type: TYPE_NORMAL
- en: 'You may need to check the status of a backup, but you may not have the Velero
    executable installed. Since this information is in a CR, we can describe the CR
    to retrieve the backup details. Running `kubectl describe` on the backup object
    will show the status of the backup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'If we jump to the bottom of the output from the `describe` command, you will
    see the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: In the output, you can see that the phase is completed, the start and completion
    times, and the number of objects that were backed up and included in the backup.
  prefs: []
  type: TYPE_NORMAL
- en: It’s good practice to use a cluster add-on that can generate alerts based on
    information in log files or the status of an object, such as **AlertManager**.
  prefs: []
  type: TYPE_NORMAL
- en: You always want a successful backup, and if a backup fails, you should look
    into the failure immediately.
  prefs: []
  type: TYPE_NORMAL
- en: To verify that the backup is correctly stored in our S3 target, go back to the
    MinIO console, and if you are not already in the **Bucket** view, click **Buckets**
    on the left-hand side. If you are already on the **Bucket** screen, press *F5*
    to refresh your browser to update the view. Once the view has been refreshed,
    you should see that the **velero** bucket has objects stored in it. Clicking on
    the bucket will show you another screen, where you will see two folders, one for
    backup and one for Kopia. Velero will split the data from the Kubernetes objects
    by storing data in the **kopia** (or restic, if that was used as the data mover)
    folder. All Kubernetes objects will be stored in the **backups** folder.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21165_14_03.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.3: Bucket details'
  prefs: []
  type: TYPE_NORMAL
- en: Since the overview of the **velero** bucket shows storage usage and a number
    of objects, and we see the **backups** and **kopia** folders, we can safely assume
    that the initial backup was successful. We will use this backup to restore a deleted
    namespace in the *Restoring from a backup* section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: A one-off backup is not something you will likely run often. You should back
    up your cluster on a regular, scheduled basis. In the next section, we will explain
    how to create a scheduled backup.
  prefs: []
  type: TYPE_NORMAL
- en: Scheduling a cluster backup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating a one-time backup is useful if you have a cluster operation scheduled
    or if there is a major software upgrade in a namespace. Since these events will
    be rare, you will want to schedule backing up the cluster at regular intervals,
    rather than random one-time backups.
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a scheduled backup, you use the `schedule` option and create a tag
    with the Velero executable. Along with the `schedule` and creating the tag, you
    need to provide a name for the job and the `schedule` flag, which accepts `cron`-based
    expressions. The following schedule tells Velero to back up at 1 A.M. every day:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.7 – Cron scheduling expression ](img/B21165_14_04.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.4: Cron scheduling expression'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the information in *Figure 14.4*, we can create a backup that will run
    at 1 A.M., using the following `velero schedule create` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Velero will reply that a schedule has been successfully created:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: If you are not familiar with `cron` and the options that are available, you
    should read the `cron` package documentation at [https://godoc.org/github.com/robfig/cron](https://godoc.org/github.com/robfig/cron).
  prefs: []
  type: TYPE_NORMAL
- en: '`cron` will also accept some shorthand expressions, which may be easier than
    using the standard `cron` expressions. The following table contains the shorthand
    for predefined schedules:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Shorthand value** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `@yearly` | Executes once a year at midnight on January 1^(st) |'
  prefs: []
  type: TYPE_TB
- en: '| `@monthly` | Executes once a month, on the first day of the month, at midnight
    |'
  prefs: []
  type: TYPE_TB
- en: '| `@weekly` | Executes once a week, on Sunday morning at midnight |'
  prefs: []
  type: TYPE_TB
- en: '| `@daily` | Executes daily at midnight |'
  prefs: []
  type: TYPE_TB
- en: '| `@hourly` | Executes at the beginning of each hour |'
  prefs: []
  type: TYPE_TB
- en: 'Table 14.4: cron shorthand scheduling'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the values from the shorthand table to schedule a backup job that executes
    daily at midnight, we use the following Velero command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: 'This will create a backup job that backs the cluster up at midnight, each night.
    You can verify that the job was created and the last time it ran by looking at
    the `schedules` object, using `kubectl get schedules -n velero`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: Scheduled jobs will create a backup object when the job is executed. The backup
    name will contain the name of the schedule, with a dash and the date and time
    of the backup. Backup names follow the standard naming of YYYYMMDDhhmmss. Using
    the name from the preceding example, our initial backup was created with the name
    `cluster-daily-20231206200028`. Here, `20231206200028` is the date the backup
    ran, and `200028` is the time the backup ran in UTC time. This is the equivalent
    of `2021-09-30 20:00:28 +0000 UTC`.
  prefs: []
  type: TYPE_NORMAL
- en: All of our examples so far have been configured to back up all of the namespaces
    and objects in the cluster. You may need to create different schedules or exclude/include
    certain objects based on your specific clusters.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explain how to create a custom backup that will
    allow you to use specific tags to include and exclude namespaces and objects.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a custom backup
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you create any backup job, you can provide flags to customize what objects
    will be included in or excluded from the backup job. Some of the most common flags
    are detailed here:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Flag** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `--exclude-namespaces` | Comma-separated list of namespaces to exclude from
    the backup job.*Example*: `--exclude-namespaces web-dev1,web-dev2`. |'
  prefs: []
  type: TYPE_TB
- en: '| `--exclude-resources` | Comma-separated list of resources to exclude, formatted
    as `resource.group`.*Example*: `--exclude-resources storageclasses.storage.k8s.io`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `--include-namespaces` | Comma-separated list of namespaces to include in
    the backup job.*Example*: `--include-namespaces web-dev1,web-dev2`. |'
  prefs: []
  type: TYPE_TB
- en: '| `--selector` | Configures the backup to include only objects that match a
    label selector. Accepts a single value only.*Example*: `--selector app.kubernetes.io/name=ingress-nginx`.
    |'
  prefs: []
  type: TYPE_TB
- en: '| `--ttl` | Configures how long to keep the backup in hours, minutes, and seconds.
    By default, the value is set for 30 days or `720h0m0s`.*Example*: `--ttl 24h0m0s`.This
    will delete the backup after 24 hours. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 14.5: Velero backup flags'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a scheduled backup that will run daily and include only Kubernetes
    system namespaces, we would create a scheduled job using the `--include-namespaces`
    flag:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: Since Velero commands use a CLI for all operations, we should start by explaining
    the common commands you will use to manage backup and restore operations.
  prefs: []
  type: TYPE_NORMAL
- en: Managing Velero using the CLI
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All Velero operations must be done using the Velero executable. Velero does
    not include a UI for managing backups and restores. Managing a backup system without
    a GUI can be a challenge at first, but once you get comfortable with the Velero
    management commands, it becomes easy to perform operations.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Velero executable accepts two options:'
  prefs: []
  type: TYPE_NORMAL
- en: Commands
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flags
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **command** is an operation such as `backup`, `restore`, `install`, and `get`.
    Most initial commands require a second command to make a complete operation. For
    example, a `backup` command requires another command, such as `create` or `delete`,
    to form a complete operation.
  prefs: []
  type: TYPE_NORMAL
- en: There are two types of flags – command flags and global flags. **Global flags**
    are flags that can be set for any command, while **command flags** are specific
    to the command being executed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like many CLI tools, Velero includes built-in help for every command. If you
    forget some syntax or want to know what flags can be used with a command, you
    can use the `-h` flag to get help:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The following is the abbreviated help output for the `backup create` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: We find Velero’s help system to be very helpful; once you get comfortable with
    Velero’s basics, you will find that the built-in help provides enough information
    for most commands.
  prefs: []
  type: TYPE_NORMAL
- en: Using common Velero commands
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since many readers may be new to Velero, we want to provide a quick overview
    of the most commonly used commands to get you comfortable with using Velero.
  prefs: []
  type: TYPE_NORMAL
- en: Listing Velero objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we have mentioned, Velero management is driven by using the CLI. You can
    imagine that as you create additional backup jobs, it may become difficult to
    remember what has been created. This is where the `get` command comes in handy.
  prefs: []
  type: TYPE_NORMAL
- en: 'The CLI can retrieve, or get, a list of the following Velero objects:'
  prefs: []
  type: TYPE_NORMAL
- en: Backup locations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backups
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plugins
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restores
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schedules
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snapshot locations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As you may expect, executing `velero get <object>` will return a list of the
    objects managed by Velero:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Each `get` command will produce a similar output, containing the names of each
    object and any unique values for the objects. This command is useful for getting
    a quick look at what objects exist, but it’s usually used before executing the
    next command, `describe`.
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving details for a Velero object
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After you get the name of the object that you want the details of, you can
    use the `describe` command to get the details of the object. Using the output
    from the `get` command in the previous section, we want to view the details of
    the `initial-backup` job:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: The output of the command provides all the details for the requested object.
    You will find yourself using the `describe` command to troubleshoot issues such
    as backup failures.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and deleting objects
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since we have already used the `create` command a few times, we will focus on
    the `delete` command in this section.
  prefs: []
  type: TYPE_NORMAL
- en: To recap, the `create` command allows you to create objects that will be managed
    by Velero, including backups, schedules, restores, and locations for backups and
    snapshots. We have created a backup and a schedule, and in the next section, we
    will create a restore.
  prefs: []
  type: TYPE_NORMAL
- en: Once an object is created, you may discover that you need to delete it. To delete
    objects in Velero, you use the `delete` command, along with the object and name
    you want to delete.
  prefs: []
  type: TYPE_NORMAL
- en: Since we do not have a backup called `sales` on our KinD cluster, the example
    command will not find a backup called `sales`.
  prefs: []
  type: TYPE_NORMAL
- en: 'In our `get backups` output example, we had a backup called `sales`. To delete
    that backup, we would execute the following `delete` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 'Since a delete is a one-way operation, you will need to confirm that you want
    to delete the object. Once you have confirmed the deletion, it may take a few
    minutes for the object to be removed from Velero since it waits until all associated
    data is removed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: As you can see in the output, when we delete a backup, Velero will delete all
    of the objects for the backup, including the snapshot’s backup files and restores.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are additional commands that you can use, but the commands covered in
    this section are what you really need to get comfortable with Velero. For reference,
    the list below shows common Velero commands and a brief description of what each
    command does:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Installing and uninstalling Velero**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`velero install`: Installs Velero server components into the Kubernetes cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing backups**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`velero backup create <NAME>`: Creates a backup with the specified name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup describe <NAME>`: Describes the details of a specific backup.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup delete <NAME>`: Deletes a specified backup.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup logs <NAME>`: Displays logs for a specific backup.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup download <NAME>`: Downloads the backup logs for troubleshooting
    purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup get`: Lists all backups.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing restores**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`velero restore create --from-backup <BACKUP_NAME>`: Creates a restore from
    a specified backup.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restore describe <NAME>`: Describes the details of a specific restore.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restore delete <NAME>`: Deletes a specified restore.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restore logs <NAME>`: Displays logs for a specific restore.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restore get`: Lists all restores.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scheduling backups**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`velero schedule create <NAME> --schedule <CRON_SCHEDULE>`: Creates a scheduled
    backup using `cron` syntax.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero schedule describe <NAME>`: Describes the details of a specific schedule.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero schedule delete <NAME>`: Deletes a specified schedule.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero schedule get`: Lists all schedules.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing plugins**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`velero plugin add <PLUGIN_IMAGE>`: Adds a plugin to the Velero server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero plugin get`: Lists all plugins.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Snapshot locations**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`velero snapshot-location create <NAME>`: Creates a new snapshot location with
    the specified name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero snapshot-location get`: Lists all snapshot locations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero snapshot-location describe <NAME>`: Describes the details of a specific
    snapshot location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero snapshot-location delete <NAME>`: Deletes a specified snapshot location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backup locations**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`velero backup-location create <NAME>`: Establishes a new backup location with
    the specified name.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup-location get`: Lists all backup locations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup-location describe <NAME>`: Describes the details of a specific
    backup location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup-location delete <NAME>`: Removes a specified backup location.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing restic repositories**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`velero restic repo get`: Lists all `restic` repositories.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restic repo describe <NAME>`: Describes the details of a specific restic
    repository.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restic repo forget <NAME>`: Manually removes restic backup snapshots.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restic repo prune <NAME>`: Removes unused data from a restic repository
    to free up space.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restic repo garbage-collect <NAME>`: Runs a garbage collection operation
    on the specified repository.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Utility commands**:'
  prefs: []
  type: TYPE_NORMAL
- en: '`velero version`: Displays the current version of Velero.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero client config set`: Configures the default settings for the Velero
    client.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero client config get`: Displays the current client configuration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero completion <SHELL>`: Generates a shell completion script for the specified
    shell, enhancing CLI usability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you can create and schedule backups and know how to use the help system
    in Velero, we can move on to using a backup to restore objects.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring from a backup
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explain the process of restoring from a backup using
    Velero. Having a backup is akin to having car insurance or homeowner’s insurance—it’s
    essential to have, yet you hope you never need to use it. When the unexpected
    happens, you’ll be grateful it’s there. In the realm of data backups, finding
    yourself needing to restore data without a backup is a scenario we often refer
    to as a “resume-building event.” To run a restore from a backup, you use the `create
    restore` command with the `--from-backup <backup name>` tag.
  prefs: []
  type: TYPE_NORMAL
- en: 'Earlier in the chapter, we created a single, one-time backup, called `initial-backup`,
    which includes every namespace and object in the cluster. If we decided that we
    needed to restore that backup, we would execute a restore using the Velero CLI:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: 'The output from the `restore` command may seem odd:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: At first, it may seem like a backup request was made since Velero replies with
    `"initial-backup-20231207163306" submitted successfully`, but you may be wondering
    why the restore isn’t called `initial-backup`. Velero uses the backup name to
    create a restore request, and since we named our backup `initial-backup`, the
    restore job name will use that name and append the date and time of the restore
    request.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can view the status of the restore using the `describe` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: Depending on the size of the restore, it may take some time to restore the entire
    backup. During the restore phase, the status of the backup will be `InProgress`.
    Once the restore is complete, the status will change to `Completed`.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring in action
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With all of the theory behind us, let’s use two examples to see Velero restores
    in action. For the examples, we will start with a simple deployment with a persistent
    volume that we will delete and restore on the same cluster. The second example
    will be more complex; we will back up a few namespaces in our main KinD cluster
    and restore them to a new KinD cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a deployment from a backup
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the backup section of this chapter, we created a backup of the cluster after
    we created a **busybox** deployment with a PVC attached. We added data to the
    PVC before we backed it up, and now we want to make sure that the backup is complete
    and that restoring a namespace is successful.
  prefs: []
  type: TYPE_NORMAL
- en: To test the restore, we will simulate a failure by deleting the `demo` namespace
    and then use our backup to restore the entire namespace, including the PVC data.
  prefs: []
  type: TYPE_NORMAL
- en: Simulating a failure
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To simulate an event that would require a backup of our namespace, we will
    delete the entire namespace using `kubectl`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: It may take a minute to delete the objects in the namespace. Once you have returned
    to a prompt, the deletion should be complete.
  prefs: []
  type: TYPE_NORMAL
- en: Verify that the namespace has been deleted before moving on. Run a `kubectl
    get ns` and verify that the `demo` namespace is no longer listed.
  prefs: []
  type: TYPE_NORMAL
- en: With the confirmation that the `demo` namespace has been deleted, we will demonstrate
    how to restore the entire namespace and objects from the backup.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a namespace
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine this is a real-life scenario. You receive a phone call that a developer
    has accidentally deleted every object in their namespace and they do not have
    the source files.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you are prepared for this type of event. You have several backup
    jobs running in your cluster, and you tell the developer that you can restore
    it to the state it was in last night from a backup.
  prefs: []
  type: TYPE_NORMAL
- en: We want to restore just the one namespace, `demo`, rather than the entire cluster.
    We know our backup name is `initial-backup`, so we will need to use that as our
    backup file when we execute a restore. To limit the restore to just a namespace,
    we will add the `--include-namespaces demo` flag to our command.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: This will start a restore from the `initial-backup`. It shouldn’t take too long
    to restore since it’s a single namespace and the PVC only has a few empty files
    to restore.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, check to make sure that the namespace has been recreated. If you execute
    `kubectl get ns demo`, you should see the `demo` namespace in the list:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 'Great! That’s the first step. Now, let’s make sure the pods were restored.
    We will need the name to look at the PVC contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: 'Looking good so far. Finally, let’s use `kubectl exec` to look at the `/mnt`
    directory in the pod. We are hoping to see the new files we created before the
    backup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: As we can see from the output of the `ls` command, the two files we added before
    executing the backup, `newfile1` and `newfile2`, are in the pod, proving that
    the backup works for restoring the namespace, including any persistent data.
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You just saved the developer a lot of work because you had
    a backup of the namespace!
  prefs: []
  type: TYPE_NORMAL
- en: Restoring objects like the previous example is a common exercise, and backing
    up and restoring in the same cluster is the only thing some operators may think
    backups are good for. While that may be the most common use case for backups,
    they can also be used for a number of other activities, like using a backup from
    one cluster into another, different cluster.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will use a backup from one cluster and restore the data
    to a different cluster. This is beneficial for a few scenarios, including migrating
    an application from one cluster to another or restoring the application and data
    to a development cluster to perform upgrade tests.
  prefs: []
  type: TYPE_NORMAL
- en: Using a backup to create workloads in a new cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Restoring objects in a cluster is just one use case for Velero. While it is
    the main use case for most users, you can also use your backup files to restore
    a workload or all workloads on another cluster. This is a useful option if you
    need to create a new development or disaster recovery cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that Velero backup jobs are only the namespaces and objects in the
    namespaces. To restore a backup to a new cluster, you must have a running cluster
    running Velero before you can restore any workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Backing up the cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By this point in the chapter, we assume that you have seen this process a few
    times and that you know how to use the Velero CLI. If you need a refresher, you
    can go back a few pages in the chapter for reference, or use the CLI help function.
  prefs: []
  type: TYPE_NORMAL
- en: For this example, we will not work with any data. Instead, we just want to demonstrate
    restoring a backup from one cluster to a different cluster.
  prefs: []
  type: TYPE_NORMAL
- en: First, we should create a few namespaces and add some deployments to each one
    to make it more interesting. We have included a script in the `chapter14` folder
    called `create-backup-objects.yaml` that will create the namespaces and the objects
    for you. Run that script to create the namespaces and deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the namespaces and deployment have been created, let’s create a new backup
    called `namespace-demo` that will back up only the four new namespaces that we
    created with the script:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: 'Before moving on, verify that the backup has been completed successfully. You
    can verify the backup by executing the `describe` command against the `namespace-demo`
    backup:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: In the output, you will see that the backup includes the four namespaces and
    there are 40 objects in the backup. An abbreviated output is shown below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: You now have a new backup that contains the four new namespaces and their objects.
    Now, using this backup, we will restore the four namespaces to a new cluster.
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to deploy a new KinD cluster thar, which will use to restore
    our `demo1`, `demo2`, `demo3`, and `demo4` namespaces.
  prefs: []
  type: TYPE_NORMAL
- en: Building a new cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since we are only demonstrating how Velero can be used to create workloads on
    a new cluster from a backup, we will create a simple single-node KinD cluster
    as our restore point.
  prefs: []
  type: TYPE_NORMAL
- en: This section gets a little complex since you will have two clusters in your
    `kubeconfig` file. Follow the steps carefully if you’re new to switching config
    contexts.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have completed this exercise, we will delete the second cluster since
    we will not need to have two clusters. This exercise will be interactive. You
    will need to execute each step:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new KinD cluster called `velero-restore`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will create a new single-node cluster that contains both the control plane
    and worker node, and it will set your cluster context to the new cluster.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the cluster has deployed, verify that your context has been switched to
    the `velero-restore` cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: Verify that the current context is set to the `kind-velero-restore` cluster.
    You will see an `*` in the current field of the cluster that is being used.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, verify the namespaces in the cluster using `kubectl`. You should only
    see the default namespaces that are included with a new cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have created a new cluster, we can start the process of restoring
    the workloads. The first step is to install Velero on the new cluster, pointing
    to the existing S3 bucket as the backup location.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a backup to the new cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With our new KinD cluster up and running, we need to install Velero to restore
    our backup. We can use most of the same manifests and settings that we used in
    the original cluster, but since we are in a different cluster, we need to change
    the S3 target to the external URL we used to expose MinIO.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Velero in the new cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We already have the `credentials-velero` file in the `chapter14` folder, so
    we can jump right into installing Velero using the `velero install` command. To
    follow these steps, you should be in the `chapter14` directory:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Be sure to change the `s3Url` to your MinIO Ingress rule for your original
    KinD cluster that was created earlier in the chapter. If you forgot the ingress
    name, change your context to `kind-cluster01` and use `kubectl` to look at the
    rules in the `velero` namespace, `kubectl get ingress -n velero`. This will show
    you the full `nip.io` for MinIO (remember, don’t use the `minio-console` rule):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The install will take a few minutes, but once the pod is up and running, view
    the log files to verify that the Velero server is up and running and connected
    to the S3 target:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If all of your settings were correct, the Velero log will have an entry saying
    that it has found backups in the backup location that need to be synced with the
    new Velero server (the number of backups may be different for your KinD cluster):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'After confirming the installation, verify that Velero can see the existing
    backup files using `velero get backups`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Your backup list will differ from ours, but you should see the same list that
    you had in the original cluster.
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we can use any of the backup files to create a restore job in
    the new cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a backup in a new cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will use the backup that was created in the previous section
    and restore the workloads to a brand new KinD cluster to simulate a workload migration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The backup that was created of the original cluster, after we added the namespaces
    and deployment, was called `namespace-demo`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using that backup name, we can restore the namespaces and objects by running
    the `velero create restore` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Wait for the restore to complete before moving on to the next step. To verify
    that the restore was successful, use the `velero describe restore` command with
    the name of the restore job that was created when you executed the `create restore`
    command. In our cluster, the restore job was assigned the name `namespace-demo-20211001235926`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once the phase has changed from `InProgress` to `Completed`, verify that your
    new cluster has the additional demo namespaces using `kubectl get ns`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will see that the new namespaces were created, and if you look at the pods
    in each namespace, you will see that each has a pod called `nginx`. You can verify
    that the pods were created using `kubectl get pods`. For example, to verify the
    pods in the `demo1` namespace, enter the following: `kubectl get pods -n demo1`.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: Congratulations! You have successfully restored objects from one cluster into
    a new cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting the new cluster
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since we do not need two clusters, let’s delete the new KinD cluster that we
    restored the backup to:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To delete the cluster, execute the `kind delete cluster` command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Set your current context to the original KinD cluster, `kind-cluster01`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now that we have cleaned up the temporary second cluster, we have completed
    the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Backing up clusters and workloads is a requirement for any enterprise cluster.
    Having a backup solution allows you to recover from a disaster or human error.
    A typical backup solution allows you to restore any Kubernetes object, including
    namespaces, persistent volumes, RBAC, services, and service accounts. You can
    also take all of the workloads from one cluster and restore them on a completely
    different cluster for testing or troubleshooting.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we reviewed how to back up the `etcd` cluster database using
    `etcdctl` and the snapshot feature. We also went into detail on how to install
    Velero in a cluster to back up and restore workloads. We closed out the chapter
    by copying workloads from an existing backup by restoring an existing backup on
    a new cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Coming up in the next chapter, we will introduce you to monitoring your clusters
    and workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: True or false – Velero can only use an S3 target to store backup jobs.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: If you do not have an object storage solution, how can you provide an S3 target
    using a backend storage solution such as NFS?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can’t – there is no way to add anything in front of NFS to present S3.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Kubernetes can do this using native CSI features.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Install MinIO and use the NFS volumes as persistent disks in the deployment.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You don’t need to use an object store; you can use NFS directly with Velero.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: True or false – Velero backups can only be restored on the same cluster where
    the backup was originally created.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What utility can you use to create an `etcd` backup?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Velero.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: MinIO.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: There is no reason to back up the `etcd` database.
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`etcdctl`.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which command will create a scheduled backup that runs every day at 3 A.M.?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`velero create backup daily-backup`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`velero create @daily backup daily-backup`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`velero create backup daily-backup –schedule="@daily3am"`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`velero create schedule daily-backup --schedule="0 3 * * *"`'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: a
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
