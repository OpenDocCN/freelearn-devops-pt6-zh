- en: '14'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '14'
- en: Backing Up Workloads
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 备份工作负载
- en: Backup products for Kubernetes are vital components of our ever-evolving journey
    into the world of container orchestration and cloud-native computing. In this
    chapter, we will explore using Velero’s capabilities and how it can help you ensure
    resilience and reliability for your workloads. Velero, meaning “safety” or “protection”
    in Italian, is a great name since it provides a safety net for your applications,
    allowing you to confidently run them in a dynamic, ever-changing environment.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 的备份产品是我们不断进化的容器编排和云原生计算世界中的重要组成部分。在本章中，我们将探讨如何使用 Velero 的功能，以及它如何帮助你确保工作负载的韧性和可靠性。Velero
    在意大利语中的意思是“安全”或“保护”，这个名字非常贴切，因为它为你的应用程序提供了安全网，使你能够在动态且不断变化的环境中自信地运行它们。
- en: As you dive deeper into Kubernetes and microservices, you will quickly realize
    the advantages of backing up, restoring, and migrating applications. While Kubernetes
    is a remarkable system for deploying and managing containerized applications,
    it doesn’t inherently provide tools for data protection and disaster recovery.
    This gap is filled by **Velero**, which presents a complete solution for safeguarding
    your Kubernetes workloads and the data connected with them.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 随着你深入了解 Kubernetes 和微服务，你会迅速意识到备份、恢复和迁移应用程序的优势。虽然 Kubernetes 是一个出色的容器化应用程序部署和管理系统，但它本身并没有提供数据保护和灾难恢复的工具。这一空白由**Velero**填补，它为保护你的
    Kubernetes 工作负载及其相关数据提供了完整的解决方案。
- en: Velero was originally known as Heptio Ark. Heptio was a company co-founded by
    two of Kubernetes’ original creators, Joe Beda and Craig McLuckie. Since then,
    it has become part of the VMware Tanzu portfolio, demonstrating its importance
    to the Kubernetes ecosystem.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Velero 最初名为 Heptio Ark。Heptio 是由 Kubernetes 的两位原始创建者 Joe Beda 和 Craig McLuckie
    共同创办的公司。从那时起，它成为了 VMware Tanzu 产品组合的一部分，展示了它在 Kubernetes 生态系统中的重要性。
- en: In this chapter, we will explore the key features and use cases of Kubernetes
    and Velero, from basic backup and restore operations to more advanced scenarios
    like cross-cluster migrations. Whether you are just beginning your Kubernetes
    journey or are a seasoned Kubernetes operator, Velero is a tool worth learning.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将探索 Kubernetes 和 Velero 的关键功能和使用场景，从基本的备份和恢复操作到更高级的场景，如跨集群迁移。无论你是刚开始接触
    Kubernetes，还是一位经验丰富的 Kubernetes 运维人员，Velero 都是一个值得学习的工具。
- en: 'In this chapter, we will cover the following topics:'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主题：
- en: Understanding Kubernetes backups
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 备份
- en: Performing an `etcd` backup
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行 `etcd` 备份
- en: Introducing and setting up VMware’s Velero
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍和设置 VMware 的 Velero
- en: Using Velero to back up workloads and PVCs
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Velero 备份工作负载和 PVC
- en: Managing Velero using the CLI
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 CLI 管理 Velero
- en: Restoring from a backup
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从备份恢复
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'To carry out the hands-on experiments in this chapter, you will need the following:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行本章的实践实验，你需要以下内容：
- en: An Ubuntu 22.04+ server running Docker with a minimum of 8 GB of RAM.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 运行 Docker 的 Ubuntu 22.04+ 服务器，至少 8 GB 内存。
- en: A KinD cluster built to the specifications in *Chapter 2*.
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根据*第 2 章*中的规格构建的 KinD 集群。
- en: 'Scripts from the `chapter14` folder from the repo, which you can access by
    going to this book’s GitHub repository: [https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition)'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从仓库中的 `chapter14` 文件夹获取脚本，你可以通过访问本书的 GitHub 仓库来找到：[https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition)
- en: Understanding Kubernetes backups
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 备份
- en: Backing up a Kubernetes cluster requires backing up not only the workloads running
    on the cluster. You need to consider any persistent data and the cluster itself.
    Remember that the cluster state is maintained in an `etcd` database, making it
    a very important component that you need to back up in order to recover from any
    disasters.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 备份 Kubernetes 集群不仅仅是备份集群上运行的工作负载。你需要考虑任何持久化数据以及集群本身。记住，集群状态是保存在 `etcd` 数据库中的，因此它是一个非常重要的组件，必须进行备份，以便在灾难发生时进行恢复。
- en: 'Creating a backup of the cluster and the running workloads allows you to do
    the following:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 创建集群和运行工作负载的备份使你能够执行以下操作：
- en: Migrate clusters.
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 迁移集群。
- en: Create a development cluster from a production cluster.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从生产集群创建开发集群。
- en: Recover a cluster from a disaster.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从灾难中恢复集群。
- en: Recover data from persistent volumes.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从持久卷中恢复数据。
- en: Namespace and deployment recovery.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 命名空间和部署恢复。
- en: In this chapter, we will provide the details and tools to back up your `etcd`
    database, your namespace, the objects in them, and any persistent data you have
    attached to your workloads.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将提供详细信息和工具来备份您的 `etcd` 数据库、命名空间、其中的对象以及您附加到工作负载的任何持久数据。
- en: Recovering a cluster from a complete disaster in an enterprise usually involves
    backing up custom SSL certificates for various components, such as Ingress controllers,
    load balancers, and the API server. Since the process of backing up all custom
    components is different in many environments, we will focus on the procedures
    that are common among most Kubernetes distributions.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在企业中从完全灾难中恢复集群通常涉及备份各种组件的自定义 SSL 证书，如 Ingress 控制器、负载均衡器和 API 服务器。由于在许多环境中备份所有自定义组件的过程不同，我们将专注于大多数
    Kubernetes 发行版中通用的流程。
- en: As you know, the cluster state is maintained in `etcd`, and if you lose all
    of your `etcd` instances, you will lose your cluster. In a multi-node control
    plane, you should have a minimum of three `etcd` instances, providing redundancy
    for the cluster. If you lose a single node, the cluster will remain running, and
    you can replace the failed node with a new node. Once the new instance has been
    added, it will receive a copy of the `etcd` database and your cluster will be
    back to full redundancy.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所知，集群状态由 `etcd` 维护，如果您丢失所有 `etcd` 实例，您将丢失您的集群。在多节点控制平面中，您应至少拥有三个 `etcd` 实例，为集群提供冗余。如果丢失一个节点，集群将继续运行，并且您可以用新节点替换失败的节点。一旦添加新实例，它将接收
    `etcd` 数据库的副本，您的集群将恢复到完全冗余状态。
- en: In the event that you lose all of your `etcd` servers without any backup of
    the database, you would lose the cluster, including the cluster state and all
    of the workloads. Since `etcd` is so important, the `etcdctl` utility includes
    a built-in backup function. In the next section, we will show you how to take
    an `etcd` backup using the `etcdctl` utility.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您丢失所有 `etcd` 服务器并且没有数据库备份，您将丢失集群，包括集群状态和所有工作负载。由于 `etcd` 非常重要，`etcdctl` 实用程序包含内置备份功能。在接下来的部分，我们将展示如何使用
    `etcdctl` 实用程序进行 `etcd` 备份。
- en: Performing an etcd backup
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 执行 etcd 备份
- en: Since we are using KinD for our Kubernetes cluster, we can create a backup of
    the `etcd` database, but we will not be able to restore it.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在 Kubernetes 集群中使用 KinD，我们可以创建 `etcd` 数据库的备份，但无法恢复它。
- en: Our `etcd` server is running in a pod on the cluster called `etcd-cluster01-control-plane`,
    located in the `kube-system` namespace. During the creation of the KinD cluster,
    we added an extra port mapping for the control plane node, exposing port `2379`,
    which is used to access `etcd`. In your own production environment, you may not
    have the `etcd` port exposed for external requests, but the process of backing
    up the database will still be similar to the steps explained in this section.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的 `etcd` 服务器在名为 `etcd-cluster01-control-plane` 的 Pod 中运行，位于 `kube-system`
    命名空间。在创建 KinD 集群时，我们为控制平面节点添加了额外的端口映射，暴露了端口 `2379`，用于访问 `etcd`。在您自己的生产环境中，可能不会将
    `etcd` 端口暴露给外部请求，但备份数据库的过程仍将与本节中解释的步骤类似。
- en: Backing up the required certificates
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 备份所需的证书
- en: Most Kubernetes installations store certificates in `/etc/kubernetes/pki`. In
    this respect, KinD is no different, so we can back up our certificates using the
    `docker cp` command.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 Kubernetes 安装将证书存储在 `/etc/kubernetes/pki` 中。在这方面，KinD 也不例外，因此我们可以使用 `docker
    cp` 命令备份我们的证书。
- en: 'We have said it a few times: `etcd` is very important! So, it stands to reason
    that accessing the database directly probably has some security around it. Well,
    it does, and to access it, you need to provide the correct certificates when you
    execute a command against the database. In an enterprise, you should store these
    keys in a secure location. For our example, we will pull the certificates from
    the KinD nodes.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经说了几次：`etcd` 非常重要！因此，直接访问数据库可能会有一些安全措施。确实如此，要访问它，您需要在执行针对数据库的命令时提供正确的证书。在企业中，您应将这些密钥存储在安全位置。在我们的示例中，我们将从
    KinD 节点提取证书。
- en: We have included a script in the `chapter14/etcd` directory called `install-etcd-tools.sh`
    that will execute the steps to download and execute the backup of the `etcd` database.
    To execute the script, change to the `chapter14/etcd` directory and execute the
    installation script.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 `chapter14/etcd` 目录中包含了一个名为 `install-etcd-tools.sh` 的脚本，该脚本将执行下载和执行 `etcd`
    数据库备份的步骤。要执行该脚本，请切换到 `chapter14/etcd` 目录并执行安装脚本。
- en: 'Running the script will download the `etcd` tools, extract them, and move them
    to `usr/bin` so we can execute them easily. It will then create a directory for
    the certificates and copy them into the newly created directory, `/etcd/certs`.
    The certificates that we will use for backing up `etcd` are:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 运行脚本将下载`etcd`工具，解压后将其移动到`usr/bin`目录，以便我们能够轻松地执行它们。然后它会为证书创建一个目录，并将证书复制到新创建的目录`/etcd/certs`中。我们用于备份`etcd`的证书如下：
- en: '`ca.crt`'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ca.crt`'
- en: '`healthcheck-client.crt`'
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`healthcheck-client.crt`'
- en: '`healthcheck-client.key`'
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`healthcheck-client.key`'
- en: When you execute commands using the `etcdctl` utility, you will need to provide
    the keys or your actions will be denied.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 当您使用`etcdctl`工具执行命令时，您需要提供密钥，否则您的操作将被拒绝。
- en: Now that we have the certificates required to access `etcd`, the next step is
    to create a backup of the database.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经拥有了访问`etcd`所需的证书，下一步是创建数据库的备份。
- en: Backing up the etcd database
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 备份`etcd`数据库
- en: The creators of `etcd` created a utility that backs up and restores the `etcd`
    database, called `etcdctl`. For our purposes, we will only use the backup operation;
    however, since `etcd` is not exclusive to Kubernetes, the utility has a number
    of options that you will not use as a Kubernetes operator or developer. If you
    want to read more about this utility, you can visit the `etcd-io` Git repository
    at [https://github.com/etcd-io/etcd](https://github.com/etcd-io/etcd).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`etcd`的创建者开发了一个用于备份和恢复`etcd`数据库的工具，叫做`etcdctl`。对于我们的用途，我们只会使用备份操作；然而，由于`etcd`不仅限于Kubernetes，因此该工具有许多选项，作为Kubernetes操作员或开发人员，您不会使用这些选项。如果您想了解更多关于此工具的信息，可以访问`etcd-io`的Git仓库：[https://github.com/etcd-io/etcd](https://github.com/etcd-io/etcd)。'
- en: To back up a database, you will need the `etcdctl` utility and the certificates
    required to access the database, which we copied from the control plane server.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 要备份数据库，您需要`etcdctl`工具以及访问数据库所需的证书，这些证书我们已经从控制平面服务器复制过来了。
- en: The script that we executed in the last section downloaded `etcctl`, and we
    moved it into `usr/bin`. To create a backup of the database, make sure you are
    in the `chapter14/etcd` directory and that the `certs` directory exists with the
    downloaded certificates.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在上一节中执行的脚本下载了`etcdctl`，并将其移入了`usr/bin`目录。要创建数据库的备份，请确保您位于`chapter14/etcd`目录，并且`certs`目录已存在，并且证书已下载到该目录中。
- en: 'To back up `etcd`, we execute the `etcd snapshot save` command:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 为了备份`etcd`，我们执行`etcd snapshot save`命令：
- en: '[PRE0]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Older versions of `etcdctl` required you to set the API version to 3 using `ETCDCTL_API=3`
    since they default to the version 2 API. `etcd 3.4` changed the default API to
    3, so we do not need to set that variable before using `etcdctl` commands.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 旧版本的`etcdctl`需要使用`ETCDCTL_API=3`来设置API版本为3，因为它们默认使用的是版本2的API。`etcd 3.4`更改了默认API为3，因此我们在使用`etcdctl`命令之前无需设置该变量。
- en: 'It shouldn’t take too long for the database to be copied over. If it takes
    more than a few seconds, you should try the same command with the `--debug=true`
    flag. Adding the debug flag will provide more output during the execution of the
    snapshot. The most common reason for the snapshot failing is an incorrect certificate.
    Below is an example of the verbose output from a snapshot command that had an
    incorrect certificate:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 数据库复制过来不应该花费太长时间。如果超过几秒钟仍未完成，您应该尝试在命令中添加`--debug=true`标志。添加调试标志会在执行快照时提供更多输出。快照失败的最常见原因是证书错误。下面是一个证书不正确导致快照命令输出的详细信息示例：
- en: '[PRE1]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Notice the `x509` error. This is likely caused by an incorrect certificate in
    your `etcdctl` command. Check that you have the correct certificates, and re-run
    the command.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意`x509`错误。这很可能是由于`etcdctl`命令中的证书不正确所导致的。请检查您是否使用了正确的证书，然后重新运行命令。
- en: 'If the command is successful, you will receive output similar to this:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果命令成功，您将收到类似以下的输出：
- en: '[PRE2]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Next, we can verify that the database was copied over successfully by trying
    a simple `etcdctl` command that will provide a summary of the backup:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以通过尝试一个简单的`etcdctl`命令来验证数据库是否成功复制，这个命令会提供备份的概述：
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'This will output an overview of the backup:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这将输出备份概述：
- en: '[PRE4]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: For this example, we only backed up the `etcd` database once. In a real-life
    scenario, you should create a scheduled process that executes a snapshot of `etcd`
    at regular intervals and stores the backup file in a safe, secure location.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们只备份了一次`etcd`数据库。在实际场景中，您应该创建一个定时任务，定期执行`etcd`的快照，并将备份文件存储在安全的位置。
- en: Due to how KinD runs the control plane, we cannot use the restore procedures
    in this section. We are providing only the backup steps in this section so that
    you know how to back up an `etcd` database in an enterprise environment.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 由于 KinD 运行控制平面的方式，我们无法使用本节中的恢复程序。本节仅提供备份步骤，以便您了解如何在企业环境中备份 `etcd` 数据库。
- en: So far, you have learned about the critical importance of backing up both workloads
    and persistent data in Kubernetes, including the `etcd` database. Having a good
    backup strategy allows you to facilitate cluster migrations, create new development
    clusters from production clusters, and recover from disasters. By knowing these
    strategies, you can ensure improved disaster recovery preparedness, enhanced operational
    efficiency, and data security. Mastering these techniques will equip you to manage
    and recover Kubernetes clusters more effectively, ensuring a resilient and reliable
    environment.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，您已经了解了在 Kubernetes 中备份工作负载和持久化数据（包括 `etcd` 数据库）的关键重要性。拥有一个良好的备份策略可以帮助您便捷地迁移集群，从生产集群创建新的开发集群，并从灾难中恢复。通过了解这些策略，您可以确保更好的灾难恢复准备、更高的操作效率以及数据安全。掌握这些技巧将帮助您更有效地管理和恢复
    Kubernetes 集群，确保环境的弹性和可靠性。
- en: 'Now, let’s move on and introduce the tool we will use to demonstrate Kubernetes
    backups: Velero.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们继续介绍我们将用于演示 Kubernetes 备份的工具：Velero。
- en: Introducing and setting up VMware’s Velero
  id: totrans-63
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍并设置 VMware 的 Velero
- en: '**Velero** is an open-source backup solution for Kubernetes that was originally
    developed by a company called Heptio. As VMware has enhanced its support for Kubernetes,
    it has purchased multiple companies, and Heptio is one of its acquisitions, bringing
    Velero into the VMware portfolio.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '**Velero** 是一个开源的 Kubernetes 备份解决方案，最初由一家名为 Heptio 的公司开发。随着 VMware 增强对 Kubernetes
    的支持，它收购了多家公司，其中 Heptio 是其收购之一，将 Velero 纳入 VMware 旗下。'
- en: VMware has moved most of its offerings around Kubernetes under the Tanzu umbrella.
    This can be a little confusing for some people since the original iteration of
    Tanzu was a deployment of multiple components that added Kubernetes support to
    vSphere clusters. Since the initial incarnation of Tanzu, it has come to include
    components such as Velero, Harbor, and the **Tanzu Application Platform** (**TAP**),
    none of which require vSphere to function; they will run natively in any standard
    Kubernetes cluster.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: VMware 已将其大多数 Kubernetes 相关产品纳入 Tanzu 体系下。对于一些人来说，这可能有些令人困惑，因为 Tanzu 的最初版本是将多个组件部署到
    vSphere 集群上以增加对 Kubernetes 的支持。自从 Tanzu 初期版本以来，它已经包含了如 Velero、Harbor 和 **Tanzu
    应用平台**（**TAP**）等组件，这些组件都不需要 vSphere 才能运行；它们可以在任何标准的 Kubernetes 集群中本地运行。
- en: Even with all of the ownership and branding changes, the base functions of Velero
    have remained. It offers many features that are only available in commercial products,
    including scheduling, backup hooks, and granular backup controls – all for no
    charge.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 即便经历了所有的所有权和品牌变更，Velero 的基本功能依然保留。它提供了许多仅在商业产品中才有的功能，包括调度、备份钩子和细粒度的备份控制——而且这些功能都是免费的。
- en: While Velero is free, it has a learning curve since it does not include an easy-to-use
    GUI like most commercial products. All operations in Velero are carried out using
    their command-line utility, an executable called `velero`. This single executable
    allows you to install the Velero server, create backups, check the status of backups,
    restore backups, and more. Since every operation for management can be done with
    one file, restoring a cluster’s workloads is a very easy process. In this chapter,
    we will create a second KinD cluster and populate it with a backup from an existing
    cluster.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Velero 是免费的，但它有一定的学习曲线，因为它不像大多数商业产品那样包括一个易于使用的图形用户界面。Velero 中的所有操作都通过命令行工具执行，这个工具是一个名为
    `velero` 的可执行文件。这个单一的可执行文件允许您安装 Velero 服务器、创建备份、检查备份状态、恢复备份等。由于管理的每个操作都可以通过一个文件完成，因此恢复集群的工作负载是一个非常简单的过程。在本章中，我们将创建一个第二个
    KinD 集群，并使用现有集群的备份来填充它。
- en: But before that, we need to take care of a few requirements.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 但是在此之前，我们需要处理一些要求。
- en: Velero requirements
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Velero 的要求
- en: 'Velero consists of a few components with which you create a backup system:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: Velero 由几个组件组成，您可以用这些组件创建备份系统。
- en: '**The Velero CLI**: This provides the installation of Velero components. It
    is used for all backup and restore functions.'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Velero CLI**：提供 Velero 组件的安装。用于所有备份和恢复功能。'
- en: '**The Velero server**: This is responsible for executing backup and restore
    procedures.'
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Velero 服务器**：负责执行备份和恢复操作。'
- en: '**Storage provider plug-ins**: These are used for backing up and restoring
    to specific storage systems.'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储提供商插件**：用于将备份和恢复到特定的存储系统。'
- en: Outside of the base Velero components, you will also need to provide an object
    storage location that will be used to store your backups. If you do not have an
    object storage solution, you can deploy MinIO, which is an open-source project
    that provides an S3-compatible object store. We will deploy MinIO in our KinD
    cluster to demonstrate the backup and restore features provided by Velero.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 除了基础的 Velero 组件，你还需要提供一个对象存储位置，用于存储你的备份。如果你没有对象存储解决方案，可以部署 MinIO，这是一个开源项目，提供兼容
    S3 的对象存储。我们将在 KinD 集群中部署 MinIO，演示 Velero 提供的备份和恢复功能。
- en: Installing the Velero CLI
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Velero CLI
- en: The first step of deploying Velero is to download the latest Velero CLI binary.
    We have included a script to install the Velero binary in the `chapter14` directory
    called `install-velero-binary.sh`, which will download the Velero binary, move
    it to `/usr/bin`, and then output the version of Velero to verify that the binary
    has been installed correctly. As of the writing of this chapter, the latest version
    of Velero is 1.12.1.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 部署 Velero 的第一步是下载最新的 Velero CLI 二进制文件。我们在 `chapter14` 目录中提供了一个名为 `install-velero-binary.sh`
    的脚本，它将下载 Velero 二进制文件，移动到 `/usr/bin` 目录，并输出 Velero 的版本以验证二进制文件是否正确安装。在本章编写时，Velero
    的最新版本是 1.12.1。
- en: You can safely ignore the last line, which shows an error in finding the Velero
    server. Right now, all we have installed is the Velero executable, and it can’t
    find the server yet. In the next section, we will install the server to complete
    the installation.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以安全地忽略最后一行，它显示的是找不到 Velero 服务器的错误。目前，我们仅安装了 Velero 可执行文件，因此它无法找到服务器。接下来的部分，我们将安装服务器以完成安装。
- en: Installing Velero
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装 Velero
- en: 'Velero has minimal system requirements, most of which are easily met:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: Velero 的系统要求非常少，大部分都很容易满足：
- en: A Kubernetes cluster running version 1.16 or higher
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个运行版本 1.16 或更高的 Kubernetes 集群
- en: The Velero executable
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Velero 可执行文件
- en: Images for the system components
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 系统组件的图像
- en: A compatible storage location
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个兼容的存储位置
- en: A volume snapshot plugin (optional)
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个卷快照插件（可选）
- en: Depending on your infrastructure, you may not have a compatible location for
    the backups or snapshotting volumes. Fortunately, if you do not have a compatible
    storage system, there are open-source options that you can add to your cluster
    to meet the requirements.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的基础设施，可能没有适合的备份位置或快照卷。幸运的是，如果没有兼容的存储系统，你可以添加开源选项到集群中以满足要求。
- en: In the next section, we will explain the natively supported storage options
    and since our example will use a KinD cluster, we will install open-source options
    to add compatible storage to use as a backup location.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分，我们将解释本地支持的存储选项，由于我们的示例将使用 KinD 集群，我们将安装开源选项以添加兼容存储作为备份位置。
- en: Backup storage location
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 备份存储位置
- en: Velero requires an S3-compatible bucket to store backups. There are a number
    of officially supported systems, including all object store offerings from AWS,
    Azure, and Google.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Velero 需要一个兼容 S3 的存储桶来存储备份。有许多官方支持的系统，包括 AWS、Azure 和 Google 的所有对象存储服务。
- en: In the following table, the **Support** column means that the plugin provides
    a compatible location for storing Velero backups. The **Volume Snapshot Support**
    column means that the plugin supports backing up persistent volumes using snapshots.
    If the CSI in use does not provide snapshot support, data will be backed up using
    a standard file system backup via Restic or Kopia. Snapshots offer several advantages,
    with the most significant being their ability to maintain application consistency.
    Velero ensures that snapshots are captured in a manner that maintains the state
    of the application, minimizing the likelihood of data corruption.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在下表中，**支持** 列表示该插件提供一个兼容的存储位置用于存储 Velero 备份。**卷快照支持** 列表示该插件支持使用快照备份持久卷。如果使用的
    CSI 不提供快照支持，数据将通过 Restic 或 Kopia 使用标准文件系统备份进行备份。快照有几个优势，其中最重要的是它们能够保持应用的一致性。Velero
    确保快照以一种能够保持应用状态的方式进行捕捉，从而最小化数据损坏的可能性。
- en: 'Along with the officially supported providers, there are a number of community-
    and vendor-supported providers from companies such as DigitalOcean, Hewlett-Packard,
    and Portworx. The following table lists all of the current providers:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 除了官方支持的提供商外，还有许多来自社区和供应商的提供商，来自如 DigitalOcean、惠普（Hewlett-Packard）和 Portworx
    等公司。下表列出了所有当前的提供商：
- en: '| **Vendor** | **Object Store** | **Volume Snapshot Support** | **Support**
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| **供应商** | **对象存储** | **卷快照支持** | **支持** |'
- en: '| Amazon | AWS S3 | AWS EBS | Official |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| Amazon | AWS S3 | AWS EBS | 官方 |'
- en: '| Google | Google Cloud Storage | GCE Disks | Official |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| Google | Google Cloud Storage | GCE 磁盘 | 官方 |'
- en: '| Microsoft | Azure Blob Storage | Azure Managed Disks | Official |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| Microsoft | Azure Blob 存储 | Azure 管理磁盘 | 官方 |'
- en: '| VMware | Not Supported | vSphere Volumes | Official |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| VMware | 不支持 | vSphere 卷 | 官方 |'
- en: '| Kubernetes CSI | Not Supported | CSI Volumes | Official |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| Kubernetes CSI | 不支持 | CSI 卷 | 官方 |'
- en: '| Alibaba Cloud | Alibaba Cloud OSS | Alibaba Cloud | Community |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| Alibaba Cloud | Alibaba Cloud OSS | Alibaba Cloud | 社区 |'
- en: '| DigitalOcean | DigitalOcean Object Storage | DigitalOcean Volumes Block Storage
    | Community |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| DigitalOcean | DigitalOcean 对象存储 | DigitalOcean 卷块存储 | 社区 |'
- en: '| HP | Not Supported | HPE Storage | Community |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| HP | 不支持 | HPE 存储 | 社区 |'
- en: '| OpenEBS | Not Supported | OpenEBS cStor Volumes | Community |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| OpenEBS | 不支持 | OpenEBS cStor 卷 | 社区 |'
- en: '| Portworx | Not Supported | Portworx Volumes | Community |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| Portworx | 不支持 | Portworx 卷 | 社区 |'
- en: '| Storj | Storj Object Storage | Not Supported | Community |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| Storj | Storj 对象存储 | 不支持 | 社区 |'
- en: 'Table 14.1: Velero storage options'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '表 14.1: Velero 存储选项'
- en: If you do not have an object storage solution, you can deploy the open-source
    S3 provider MinIO, which is what we will use for our S3 target in this chapter.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你没有对象存储解决方案，可以部署开源的 S3 提供商 MinIO，这就是我们在本章中用于 S3 目标的解决方案。
- en: Now that the Velero executable has been installed and our KinD cluster has persistent
    storage, thanks to the auto-provisioner from Rancher, we can move on to the first
    requirement – adding an S3-compatible backup location for Velero.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Velero 可执行文件已安装，并且我们的 KinD 集群有了持久存储，得益于 Rancher 的自动供应器，我们可以继续进行第一个要求——为 Velero
    添加一个 S3 兼容的备份位置。
- en: Deploying MinIO
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 部署 MinIO
- en: '**MinIO** is an open-source object storage solution that is compatible with
    Amazon’s S3 cloud services API. You can read more about MinIO in its GitHub repository
    at [https://github.com/minio/minio](https://github.com/minio/minio).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**MinIO** 是一个开源的对象存储解决方案，兼容 Amazon 的 S3 云服务 API。你可以在其 GitHub 仓库中阅读更多关于 MinIO
    的信息：[https://github.com/minio/minio](https://github.com/minio/minio)。'
- en: 'If you install MinIO using a manifest from the internet, be sure to verify
    what volumes are declared in the deployment before trying to use it as a backup
    location. Many of the examples on the internet use `emptyDir: {}`, which is not
    persistent.'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '如果你使用来自互联网的清单安装 MinIO，请务必在尝试将其用作备份位置之前，验证部署中声明的卷。互联网上许多示例使用了 `emptyDir: {}`，这不是持久存储。'
- en: We have included a modified MinIO deployment from the Velero GitHub repository
    in the `chapter14` folder. Since we have persistent storage on our cluster, we
    edited the volumes in the deployment to use **Persistent Volume Claims** (**PVCs**),
    which will use the auto-provisioner for Velero’s data and configuration.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 `chapter14` 文件夹中包含了来自 Velero GitHub 仓库的修改版 MinIO 部署。由于我们的集群具有持久存储，我们编辑了部署中的卷，使用了
    **持久卷声明** (**PVCs**)，这些 PVC 将使用自动供应器来为 Velero 的数据和配置提供支持。
- en: 'To deploy the MinIO server, change directories to `chapter14` and execute `kubectl
    create`. The deployment will create a Velero namespace, PVCs, and MinIO on your
    KinD cluster. It may take some time for the deployment to complete. We have seen
    the deployment take anything from a minute to a few minutes, depending on the
    host system:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 要部署 MinIO 服务器，切换到 `chapter14` 目录并执行 `kubectl create`。该部署将在你的 KinD 集群上创建 Velero
    命名空间、PVC 和 MinIO。部署可能需要一些时间完成。根据主机系统，部署的时间可能从一分钟到几分钟不等：
- en: '[PRE5]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'This will deploy the MinIO server and expose it as `minio` on port `9000/TCP`,
    with the `console` on port `9001/TCP`, as follows:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 这将部署 MinIO 服务器，并将其公开为 `minio`，监听端口 `9000/TCP`，控制台监听端口 `9001/TCP`，如下所示：
- en: '[PRE6]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The MinIO server can be targeted by any pod in the cluster, with correct access
    keys, using `minio.velero.svc` on port `9000`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: MinIO 服务器可以通过集群中的任何 Pod，使用正确的访问密钥，通过 `minio.velero.svc` 和端口 `9000` 进行访问。
- en: With MinIO deployed, we need to expose the console using an Ingress rule so
    we can log in to look at buckets and verify that backups are working as expected.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 部署 MinIO 后，我们需要通过 Ingress 规则公开控制台，这样我们就可以登录查看桶并验证备份是否按预期工作。
- en: Exposing MinIO and the console
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 暴露 MinIO 和控制台
- en: By default, your MinIO storage will only be available inside the cluster it
    has been deployed in. Since we will demonstrate restoring to a different cluster
    at the end of the chapter, we need to expose MinIO using an Ingress rule. MinIO
    also includes a dashboard that allows you to browse the contents of the S3 buckets
    on the server. To allow access to the dashboard, you can deploy an Ingress rule
    that exposes the MinIO console.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，你的 MinIO 存储只能在部署它的集群内使用。由于我们将在本章最后演示如何恢复到不同的集群，因此我们需要通过 Ingress 规则暴露 MinIO。MinIO
    还包括一个仪表盘，允许你浏览服务器上 S3 桶的内容。为了访问仪表盘，你可以部署一个暴露 MinIO 控制台的 Ingress 规则。
- en: We have included a script in the `chapter14` folder called `create-minio-ingress.sh`
    that will create an Ingress rule using the `nip.io` syntax of `minio-console.w.x.y.z.nip.ip`
    and `minio.w.x.y.z.nip.ip`, with your host IP.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 `chapter14` 文件夹中包含了一个名为 `create-minio-ingress.sh` 的脚本，它将使用 `nip.io` 语法（`minio-console.w.x.y.z.nip.ip`
    和 `minio.w.x.y.z.nip.ip`）并将你的主机 IP 创建一个 Ingress 规则。
- en: You will need the `console` Ingress rule when you install Velero in your cluster.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 当你在集群中安装 Velero 时，你将需要 `console` Ingress 规则。
- en: 'Once deployed, you can use a browser on any machine and open the URL you used
    for the Ingress rule. On our cluster, the host IP is `10.2.1.161`, so our URL
    is `minio-console.10.2.1.161.nip.io`:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 部署完成后，你可以在任何机器上使用浏览器，打开你为 Ingress 规则设置的 URL。在我们的集群中，主机 IP 是 `10.2.1.161`，所以我们的
    URL 是 `minio-console.10.2.1.161.nip.io`：
- en: '![](img/B21165_14_01.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21165_14_01.png)'
- en: 'Figure 14.1: MinIO dashboard'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.1：MinIO 仪表盘
- en: To access the dashboard, supply the access key and secret key from the MinIO
    deployment. If you used the MinIO installer from the GitHub repository, the username
    and password have been defined in the manifest. They are `packt/packt123`.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问仪表盘，请提供 MinIO 部署中的访问密钥和秘密密钥。如果你使用了 GitHub 仓库中的 MinIO 安装程序，用户名和密码已经在清单中定义，它们是
    `packt/packt123`。
- en: Once logged in, you will see a list of buckets and any items that are stored
    in them. You should see a bucket named **velero**, which is the bucket we will
    use to back up our cluster. This bucket was created during the initial MinIO deployment
    – we added a line to the deployment that creates the **velero** bucket and the
    required permissions for the packt user.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 登录后，你将看到一个桶列表以及存储在其中的任何项目。你应该看到一个名为 **velero** 的桶，这是我们用来备份集群的桶。这个桶是在初始 MinIO
    部署期间创建的——我们在部署中添加了一行，创建了 **velero** 桶并为 packt 用户设置了必要的权限。
- en: '![](img/B21165_14_02.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21165_14_02.png)'
- en: 'Figure 14.2: MinIO browser'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14.2：MinIO 浏览器
- en: If you are new to object storage, it is important to note that while this deploys
    a storage solution in your cluster, it **will not** create a `StorageClass` or
    integrate with Kubernetes in any way. All pod access to the S3 bucket is done
    using the URL that we will provide in the next section.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你是对象存储的新手，重要的是要注意，虽然这会在你的集群中部署一个存储解决方案，但它**不会**创建 `StorageClass`，也不会与 Kubernetes
    进行任何集成。所有对 S3 桶的访问将使用我们将在下一部分提供的 URL。
- en: Now that you have an S3-compatible object store running, you need to create
    a configuration file that Velero will use to target your MinIO server.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 既然你已经运行了一个与 S3 兼容的对象存储，你需要创建一个配置文件，Velero 将使用这个文件来定位你的 MinIO 服务器。
- en: Installing Velero
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 安装 Velero
- en: To deploy Velero in your cluster, you can use the Velero binary or a Helm chart.
    We have chosen to install Velero using the binary.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 要在你的集群中部署 Velero，你可以使用 Velero 二进制文件或 Helm 图表。我们选择使用二进制文件安装 Velero。
- en: Before we start the installation, we need to create a credentials file that
    will contain the `access_key` and `secret_access_key` for the S3 target on MinIO.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始安装之前，我们需要创建一个凭证文件，包含 MinIO 上 S3 目标的 `access_key` 和 `secret_access_key`。
- en: 'Create a new credential file in the `chapter14` folder called `credentials-velero`
    with the following content:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在 `chapter14` 文件夹中创建一个新的凭证文件，命名为 `credentials-velero`，并包含以下内容：
- en: '[PRE7]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Next, we can deploy Velero using the Velero executable and the `install` option
    to deploy Velero with the option to back up persistent volumes.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以使用 Velero 可执行文件和 `install` 选项来部署 Velero，并选择备份持久化卷的选项。
- en: Execute the Velero installation using the following command from inside the
    `chapter14` folder to deploy Velero. Please note that you need to provide your
    `nip.io` ingress name for MinIO. We exposed both MinIO and the console when we
    created the Ingress rule earlier. Be careful to use the ingress name that contains
    `minio.w.x.y.z.nip.io`; do not use the `minio-console` ingress or Velero will
    fail to find the S3 bucket.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令在`chapter14`文件夹内执行Velero安装，以部署Velero。请注意，您需要为MinIO提供`nip.io`的入口名称。当我们之前创建Ingress规则时，我们暴露了MinIO和控制台。请务必使用包含`minio.w.x.y.z.nip.io`的入口名称；不要使用`minio-console`入口，否则Velero将无法找到S3存储桶。
    |
- en: '[PRE8]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Let’s explain the installation options and what the values mean:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们解释一下安装选项及其含义：
- en: '| **Option** | **Description** |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| **选项** | **描述** |'
- en: '| `--provider` | Configures Velero to use a storage provider. Since we are
    using MinIO, which is S3-compatible, we are passing `aws` as our provider. |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| `--provider` | 配置Velero使用存储提供商。由于我们使用的是兼容S3的MinIO，我们将`aws`作为我们的提供商。 |'
- en: '| `--plugins` | Tells Velero the backup plugin to use. For our cluster, since
    we are using MinIO for object storage, we selected the AWS plugin. |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| `--plugins` | 告诉Velero使用哪个备份插件。对于我们的集群，由于我们使用MinIO作为对象存储，我们选择了AWS插件。 |'
- en: '| `--bucket` | The name of the S3 bucket that you want to target. |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| `--bucket` | 您希望目标的S3存储桶名称。 |'
- en: '| `--secret-file` | Points to the file that contains the credentials to authenticate
    with the S3 bucket. |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| `--secret-file` | 指向包含用于与S3存储桶进行身份验证的凭据文件。 |'
- en: '| `--use-volume-snapshots` | Will enable or disable volume snapshots for providers
    that support snapshots. Currently, Velero only supports object storage with snapshots;
    if snapshots are not supported, this should be set to `false`. Since we are not
    interested in snapshots for our examples, we set this to `false`. |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| `--use-volume-snapshots` | 启用或禁用支持快照的提供商的卷快照。目前，Velero只支持带有快照的对象存储；如果不支持快照，则应将此项设置为`false`。由于我们在示例中不使用快照，因此将此项设置为`false`。
    |'
- en: '| `--backup-location-config` | The S3 target location where Velero will store
    backups. Since MinIO is running in the same cluster as Velero, we can target S3
    using the name `minio.velero.svc:9000`. In a production environment, you would
    use MinIO in the same cluster – you will likely have an external S3 target to
    store your backups. Using the Kubernetes service name will cause Velero `describe`
    commands to have some errors since it tries to query the cluster using the name
    provided, and you cannot access `minio.velero.svc` from outside of the cluster.
    |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| `--backup-location-config` | Velero将备份存储到的S3目标位置。由于MinIO与Velero运行在同一个集群中，我们可以使用名称`minio.velero.svc:9000`来定位S3。在生产环境中，您可能会将MinIO与Velero放在同一个集群中，并使用外部的S3目标来存储备份。使用Kubernetes服务名称将导致Velero的`describe`命令出现一些错误，因为它尝试使用提供的名称查询集群，而您无法从集群外部访问`minio.velero.svc`。
    |'
- en: '| `--use-node-agent` | Add this flag if you want to back up persistent volumes
    using Velero’s node agent. |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| `--use-node-agent` | 如果您希望使用Velero的节点代理备份持久卷，请添加此标志。 |'
- en: '| `--default-volumes-to-fs-backup` | Configures Velero to support opting out
    of backing up persistent volumes. If this isn’t added during deployment, you can
    still use the option during a Velero backup to back up volumes. This will be explained
    more in the *Backing up PVCs* section of this chapter. |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| `--default-volumes-to-fs-backup` | 配置Velero支持选择不备份持久卷。如果在部署过程中未添加此选项，您仍然可以在Velero备份时选择备份卷。本节的*备份PVCs*部分将详细说明。
    |'
- en: 'Table 14.2: Velero install options'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 表14.2：Velero安装选项
- en: When you execute the install, you will see a number of objects being created,
    including a number of **CustomResourceDefinitions** (**CRDs**) and other objects
    that Velero uses to handle backup and restore operations.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在执行安装时，您将看到一系列对象被创建，包括多个**CustomResourceDefinitions**（**CRDs**）和Velero用于处理备份与恢复操作的其他对象。
    |
- en: 'If you run into issues with your Velero server starting up correctly, there
    are a few CRDs and Secrets that you can look at that may have incorrect information.
    In the following table, we explain some of the common objects that you may need
    to interact with when using Velero:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 如果在启动Velero服务器时遇到问题，您可以查看一些CRD和Secrets，它们可能包含错误信息。以下表格解释了您在使用Velero时可能需要交互的一些常见对象：
- en: '| **CustomResourceDefinition** | **Name** | **Description** |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| **CustomResourceDefinition** | **名称** | **描述** |'
- en: '| `backups.velero.io` | `Backup` | Each backup that is created will create
    an object called `backup`, which includes the settings for each backup job. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
- en: '| `backupstoragelocations.velero.io` | `BackupStorageLocation` | Each backup
    storage location creates a `BackupStorageLocation` object that contains the configuration
    to connect to the storage provider. |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
- en: '| `schedules.velero.io` | `Schedule` | Each scheduled backup creates a `Schedule`
    object that contains the schedule for a backup. |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
- en: '| `volumesnapshotlocations.velero.io` | `VolumeSnapshotLocation` | If enabled,
    the `VolumeSnapshotLocation` object contains the information for the storage used
    for volume snapshots. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
- en: '| **Secret Name** | **Description** |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
- en: '| `cloud-credentials` | Contains the credentials to connect to the storage
    provider in Base64 format. If your Velero pod fails to start up, you may have
    an incorrect value in the `data.cloud` spec. |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
- en: '| `velero-repo-credentials` | If you are using the Restic plugin, this will
    contain your repository password, similar to `cloud-credentials`. If you experience
    issues connecting to the volume snapshot provider, verify that the repository
    password is correct. |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
- en: 'Table 14.3: Velero’s CRDs and Secrets'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: While most of your interaction with these objects will be through the Velero
    executable, it is always a good practice to understand how utilities interact
    with the API server. Understanding the objects and what their functions are is
    helpful if you do not have access to the Velero executable but you need to view,
    or potentially change, an object value to address an issue quickly.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have Velero installed and a high-level understanding of Velero objects,
    we can move on to creating different backup jobs for a cluster.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: Using Velero to back up workloads and PVCs
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Velero supports running a one-time backup with a single command or on a recurring
    schedule. Whether you choose to run a single backup or a recurring backup, you
    can back up all objects or only certain objects using `include` and `exclude`
    flags.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Backing up PVCs
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since data is becoming increasingly common on Kubernetes clusters, we will back
    up all of the cluster workloads, including any PVCs that are in the cluster. When
    we installed Velero, we added the `--use-node-agent` option, which created a **DaemonSet**
    that creates a node agent on each cluster node. The DaemonSet deploys a pod containing
    modules that can perform file system backups, including a data mover, which may
    be **Restic** or **Kopia** (*default*) on each node, and a new secret is created
    in the `velero` namespace called `velero-repo-credentials`. This secret contains
    a `repository-password` that will be used for your backups. This is a generated
    password, and you can change it to anything you want – however, if you plan to
    change the password, do it before creating any backups. If this password is changed
    after you have created any backups, Velero will not be able to read the old backups.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: The default `ServiceAccount` token, `Secrets`, and `ConfigMaps` can be mapped
    to volumes. These are not volumes that contain data and will not be backed up
    using the node agent. Like any other base Kubernetes objects, they will be backed
    up when Velero backs up the other namespace objects.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: The data movers are responsible for copying the data from the volumes. Previous
    Velero releases used Restic as the data mover, but it has been enhanced to include
    both Restic and Kopia in the node DaemonSet. By default, Kopia will be used as
    the data mover, but if you want to use Restic, you can change the default by adding
    the option `--data-mover restic` to your Velero backup create command. There is
    some debate around which data mover to use and Kopia has become the leader, so
    it has become the default.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: 'Velero can be configured to back up PVCs via two different approaches:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '**Opt-out**: Velero will back up all PVCs, unless a workload is annotated with
    the volume name(s) to ignore.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Opt-in**: Only workloads that have an annotation with the volume’s name will
    be backed up. This is Velero’s default configuration.'
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s take a closer look at these two approaches.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: Using the opt-out approach
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This is the approach we will use for the exercises. When using this approach,
    all PVCs will be backed up unless you specify an annotation in the pod, adding
    `backup.velero.io/backup-volumes-excludes`. For example, if you had 3 PVCs named
    `volume1`, `volume2`, and `volume3` in a namespace and you wanted to exclude `volume2`
    and `volume3` from being backed up, you would need to add the following annotation
    to the pod spec in your deployment:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  id: totrans-173
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Since we added only `volume2` and `volume3` to the exclusion, Velero will ignore
    those volumes from the backup, but it will back up the PVC named `volume1` since
    it was not included in the list.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: During the installation of Velero, we set `--default-volumes-to-fs-backup`,
    which tells Velero to back up all persistent data, unless a volume has an annotation
    to exclude it from being backed up. If you didn’t set that option during your
    Velero deployment, you can tell Velero to use the opt-out approach for a single
    backup by adding the same option, `--default-volumes-to-fs-backup`, to the `backup`
    command.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  id: totrans-176
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: When a backup is created using this option, Velero will back up every persistent
    volume that is attached to pods, unless it has been excluded in the `excludes`
    annotation.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: Using the opt-in approach
  id: totrans-178
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you deployed Velero without the `--default-volumes-to-fs-backup` option,
    persistent volumes will not be backed up unless you add an annotation to tell
    Velero to back up the required volumes.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly to how you opted out in the previous example, you can add an annotation
    to your deployment to instruct Velero to back up your volume or volumes. The annotation
    that you need to add is `backup.velero.io/backup-volumes`, and the following example
    tells Velero to back up two volumes, one called volume1 and the other called `volume2`:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  id: totrans-181
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: When you run your next backup, Velero will see the annotation and will add the
    two persistent volumes to the backup job.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Limitations of backing up data
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Velero cannot back up a volume that is using `hostPath` for the persistent
    data. The `local-path-provisioner` maps persistent disks to a `hostPath` by default,
    meaning that Velero will not be able to back up or restore the data. Luckily,
    there is an option to change the type from `hostPath` to `local`, which will work
    with Velero. When you create a new PVC, you can add an annotation of `volumeType:
    local`. The example below shows a PVC manifest that would be created as a local
    type, rather than `hostPath`:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-185
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This change is not needed in many cases, but since it’s required when using
    the local-path-provisioner, we will need to add the annotation to any PVCs that
    we want to test with Velero.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: With Velero deployed with the ability to back up our persistent data, let’s
    jump into creating a one-time backup of our cluster.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: Running a one-time cluster backup
  id: totrans-188
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To create an initial backup, you can run a single Velero command that will back
    up all of the namespaces in the cluster and if there are any PVCs that have not
    been annotated to be ignored, they will also be backed up.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: Executing a backup without any flags to include or exclude any cluster objects
    will back up every namespace and all of the objects in the namespace.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: We will use what we learn in this section to perform a restore to show Velero
    in action. For our backup, we will back up the entire cluster, including the PVCs.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: Before we start a backup, we are going to add a deployment with a PVC, where
    we will add a few empty files to verify that restoring data works as expected.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: 'In the `chapter14/pvc-example` directory, there is a manifest called `busybox-pvc.yaml`.
    To deploy the example, you should execute the command from within the `chapter14/pvc-example`
    directory:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-194
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The script will create a new namespace called `demo` with the `busybox-pvc`
    pod deployed using a PVC named `test-claim`, mounted in the `/mnt` directory of
    the container.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: 'Right now, the PVC has one file, `original-data`, in it. We need to add a few
    other files to test a restore a little later. First, let’s verify the current
    contents of the PVC using `kubectl` `exec` to list the directory contents. If
    you are following along on your own cluster, you will need to change the `busybox-pvc`
    pod name to whatever is in use on your cluster. You can get the pod name using
    `kubectl get pods -n demo`:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  id: totrans-197
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'This will list the `busybox` pod information. You will need the pod name to
    execute the exec command to create the files in the PVC:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  id: totrans-199
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Now, let’s add two additional files called `newdata1` and `newdata2` to the
    pod. To do this, we will use another `kubectl exec` command that will touch files
    in the `/mnt` directory.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  id: totrans-201
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Again, to verify the data has been written successfully, we can list the contents
    using `kubectl exec`:'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  id: totrans-203
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Great! We can see that the two new files have been created. Now that we have
    new data in the pod, we can move on to backing up our cluster.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a one-time backup, execute the `velero` command with the `backup
    create <backup name>` option. In our example, we have named the backup `initial-backup`:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  id: totrans-206
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The only confirmation you will receive from this is that the backup request
    was submitted:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  id: totrans-208
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Fortunately, Velero also tells you the command to check the backup status and
    logs. The last line of the output tells us that we can use the `velero` command
    with the `backup` option and either `describe` or `logs` to check the status of
    the backup operation.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: 'The `describe` option will show all of the details of the job. An example is
    shown below:'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  id: totrans-211
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: Notice the last section. This section tells us that Velero backed up 4 PVCs
    using the Kopia data mover. We will show this more when we perform a backup.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: To reinforce the previous section, where we mentioned some of the CRDs that
    Velero uses, we also want to explain where the Velero utility retrieves this information
    from.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: Each backup that is created will create a backup object in the Velero namespace.
    For our initial backup, a new backup object named `initial-backup` was created.
    Using `kubectl`, we can describe the object to see similar information that the
    Velero executable will provide.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: As shown in the preceding output, the `describe` option shows you all of the
    settings for the backup job. Since we didn’t pass any options to the backup request,
    the job contains all the namespaces and objects. Some of the most important details
    to verify are the phase, the total items to be backed up, and the items backed
    up.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: If the status of the phase is anything other than `success`, you may not have
    all the items that you want in your backup. It’s also a good idea to check the
    backed-up items; if the number of items backed up is less than the items to be
    backed up, our backup did not back up all of the items.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: 'You may need to check the status of a backup, but you may not have the Velero
    executable installed. Since this information is in a CR, we can describe the CR
    to retrieve the backup details. Running `kubectl describe` on the backup object
    will show the status of the backup:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'If we jump to the bottom of the output from the `describe` command, you will
    see the following:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: In the output, you can see that the phase is completed, the start and completion
    times, and the number of objects that were backed up and included in the backup.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: It’s good practice to use a cluster add-on that can generate alerts based on
    information in log files or the status of an object, such as **AlertManager**.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: You always want a successful backup, and if a backup fails, you should look
    into the failure immediately.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: To verify that the backup is correctly stored in our S3 target, go back to the
    MinIO console, and if you are not already in the **Bucket** view, click **Buckets**
    on the left-hand side. If you are already on the **Bucket** screen, press *F5*
    to refresh your browser to update the view. Once the view has been refreshed,
    you should see that the **velero** bucket has objects stored in it. Clicking on
    the bucket will show you another screen, where you will see two folders, one for
    backup and one for Kopia. Velero will split the data from the Kubernetes objects
    by storing data in the **kopia** (or restic, if that was used as the data mover)
    folder. All Kubernetes objects will be stored in the **backups** folder.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B21165_14_03.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.3: Bucket details'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: Since the overview of the **velero** bucket shows storage usage and a number
    of objects, and we see the **backups** and **kopia** folders, we can safely assume
    that the initial backup was successful. We will use this backup to restore a deleted
    namespace in the *Restoring from a backup* section of this chapter.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: A one-off backup is not something you will likely run often. You should back
    up your cluster on a regular, scheduled basis. In the next section, we will explain
    how to create a scheduled backup.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: Scheduling a cluster backup
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Creating a one-time backup is useful if you have a cluster operation scheduled
    or if there is a major software upgrade in a namespace. Since these events will
    be rare, you will want to schedule backing up the cluster at regular intervals,
    rather than random one-time backups.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a scheduled backup, you use the `schedule` option and create a tag
    with the Velero executable. Along with the `schedule` and creating the tag, you
    need to provide a name for the job and the `schedule` flag, which accepts `cron`-based
    expressions. The following schedule tells Velero to back up at 1 A.M. every day:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 13.7 – Cron scheduling expression ](img/B21165_14_04.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.4: Cron scheduling expression'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the information in *Figure 14.4*, we can create a backup that will run
    at 1 A.M., using the following `velero schedule create` command:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  id: totrans-235
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'Velero will reply that a schedule has been successfully created:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  id: totrans-237
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: If you are not familiar with `cron` and the options that are available, you
    should read the `cron` package documentation at [https://godoc.org/github.com/robfig/cron](https://godoc.org/github.com/robfig/cron).
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '`cron` will also accept some shorthand expressions, which may be easier than
    using the standard `cron` expressions. The following table contains the shorthand
    for predefined schedules:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: '| **Shorthand value** | **Description** |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
- en: '| `@yearly` | Executes once a year at midnight on January 1^(st) |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
- en: '| `@monthly` | Executes once a month, on the first day of the month, at midnight
    |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
- en: '| `@weekly` | Executes once a week, on Sunday morning at midnight |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
- en: '| `@daily` | Executes daily at midnight |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
- en: '| `@hourly` | Executes at the beginning of each hour |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
- en: 'Table 14.4: cron shorthand scheduling'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the values from the shorthand table to schedule a backup job that executes
    daily at midnight, we use the following Velero command:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'This will create a backup job that backs the cluster up at midnight, each night.
    You can verify that the job was created and the last time it ran by looking at
    the `schedules` object, using `kubectl get schedules -n velero`:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Scheduled jobs will create a backup object when the job is executed. The backup
    name will contain the name of the schedule, with a dash and the date and time
    of the backup. Backup names follow the standard naming of YYYYMMDDhhmmss. Using
    the name from the preceding example, our initial backup was created with the name
    `cluster-daily-20231206200028`. Here, `20231206200028` is the date the backup
    ran, and `200028` is the time the backup ran in UTC time. This is the equivalent
    of `2021-09-30 20:00:28 +0000 UTC`.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: All of our examples so far have been configured to back up all of the namespaces
    and objects in the cluster. You may need to create different schedules or exclude/include
    certain objects based on your specific clusters.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explain how to create a custom backup that will
    allow you to use specific tags to include and exclude namespaces and objects.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: Creating a custom backup
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When you create any backup job, you can provide flags to customize what objects
    will be included in or excluded from the backup job. Some of the most common flags
    are detailed here:'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '| **Flag** | **Description** |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
- en: '| `--exclude-namespaces` | Comma-separated list of namespaces to exclude from
    the backup job.*Example*: `--exclude-namespaces web-dev1,web-dev2`. |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
- en: '| `--exclude-resources` | Comma-separated list of resources to exclude, formatted
    as `resource.group`.*Example*: `--exclude-resources storageclasses.storage.k8s.io`.
    |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
- en: '| `--include-namespaces` | Comma-separated list of namespaces to include in
    the backup job.*Example*: `--include-namespaces web-dev1,web-dev2`. |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
- en: '| `--selector` | Configures the backup to include only objects that match a
    label selector. Accepts a single value only.*Example*: `--selector app.kubernetes.io/name=ingress-nginx`.
    |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
- en: '| `--ttl` | Configures how long to keep the backup in hours, minutes, and seconds.
    By default, the value is set for 30 days or `720h0m0s`.*Example*: `--ttl 24h0m0s`.This
    will delete the backup after 24 hours. |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
- en: 'Table 14.5: Velero backup flags'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: 'To create a scheduled backup that will run daily and include only Kubernetes
    system namespaces, we would create a scheduled job using the `--include-namespaces`
    flag:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  id: totrans-264
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: Since Velero commands use a CLI for all operations, we should start by explaining
    the common commands you will use to manage backup and restore operations.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: Managing Velero using the CLI
  id: totrans-266
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All Velero operations must be done using the Velero executable. Velero does
    not include a UI for managing backups and restores. Managing a backup system without
    a GUI can be a challenge at first, but once you get comfortable with the Velero
    management commands, it becomes easy to perform operations.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: 'The Velero executable accepts two options:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: Commands
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flags
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A **command** is an operation such as `backup`, `restore`, `install`, and `get`.
    Most initial commands require a second command to make a complete operation. For
    example, a `backup` command requires another command, such as `create` or `delete`,
    to form a complete operation.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: There are two types of flags – command flags and global flags. **Global flags**
    are flags that can be set for any command, while **command flags** are specific
    to the command being executed.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: 'Like many CLI tools, Velero includes built-in help for every command. If you
    forget some syntax or want to know what flags can be used with a command, you
    can use the `-h` flag to get help:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  id: totrans-274
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'The following is the abbreviated help output for the `backup create` command:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: We find Velero’s help system to be very helpful; once you get comfortable with
    Velero’s basics, you will find that the built-in help provides enough information
    for most commands.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: Using common Velero commands
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since many readers may be new to Velero, we want to provide a quick overview
    of the most commonly used commands to get you comfortable with using Velero.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: Listing Velero objects
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As we have mentioned, Velero management is driven by using the CLI. You can
    imagine that as you create additional backup jobs, it may become difficult to
    remember what has been created. This is where the `get` command comes in handy.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: 'The CLI can retrieve, or get, a list of the following Velero objects:'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: Backup locations
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Backups
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plugins
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Restores
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schedules
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Snapshot locations
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'As you may expect, executing `velero get <object>` will return a list of the
    objects managed by Velero:'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  id: totrans-290
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Here is the output:'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  id: totrans-292
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Each `get` command will produce a similar output, containing the names of each
    object and any unique values for the objects. This command is useful for getting
    a quick look at what objects exist, but it’s usually used before executing the
    next command, `describe`.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: Retrieving details for a Velero object
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'After you get the name of the object that you want the details of, you can
    use the `describe` command to get the details of the object. Using the output
    from the `get` command in the previous section, we want to view the details of
    the `initial-backup` job:'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  id: totrans-296
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The output of the command provides all the details for the requested object.
    You will find yourself using the `describe` command to troubleshoot issues such
    as backup failures.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: Creating and deleting objects
  id: totrans-298
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since we have already used the `create` command a few times, we will focus on
    the `delete` command in this section.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: To recap, the `create` command allows you to create objects that will be managed
    by Velero, including backups, schedules, restores, and locations for backups and
    snapshots. We have created a backup and a schedule, and in the next section, we
    will create a restore.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: Once an object is created, you may discover that you need to delete it. To delete
    objects in Velero, you use the `delete` command, along with the object and name
    you want to delete.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: Since we do not have a backup called `sales` on our KinD cluster, the example
    command will not find a backup called `sales`.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: 'In our `get backups` output example, we had a backup called `sales`. To delete
    that backup, we would execute the following `delete` command:'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  id: totrans-304
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'Since a delete is a one-way operation, you will need to confirm that you want
    to delete the object. Once you have confirmed the deletion, it may take a few
    minutes for the object to be removed from Velero since it waits until all associated
    data is removed:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  id: totrans-306
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: As you can see in the output, when we delete a backup, Velero will delete all
    of the objects for the backup, including the snapshot’s backup files and restores.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: 'There are additional commands that you can use, but the commands covered in
    this section are what you really need to get comfortable with Velero. For reference,
    the list below shows common Velero commands and a brief description of what each
    command does:'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '**Installing and uninstalling Velero**:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '`velero install`: Installs Velero server components into the Kubernetes cluster.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing backups**:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: '`velero backup create <NAME>`: Creates a backup with the specified name.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup describe <NAME>`: Describes the details of a specific backup.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup delete <NAME>`: Deletes a specified backup.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup logs <NAME>`: Displays logs for a specific backup.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup download <NAME>`: Downloads the backup logs for troubleshooting
    purposes.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup get`: Lists all backups.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing restores**:'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: '`velero restore create --from-backup <BACKUP_NAME>`: Creates a restore from
    a specified backup.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restore describe <NAME>`: Describes the details of a specific restore.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restore delete <NAME>`: Deletes a specified restore.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restore logs <NAME>`: Displays logs for a specific restore.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restore get`: Lists all restores.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scheduling backups**:'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: '`velero schedule create <NAME> --schedule <CRON_SCHEDULE>`: Creates a scheduled
    backup using `cron` syntax.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero schedule describe <NAME>`: Describes the details of a specific schedule.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero schedule delete <NAME>`: Deletes a specified schedule.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero schedule get`: Lists all schedules.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing plugins**:'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: '`velero plugin add <PLUGIN_IMAGE>`: Adds a plugin to the Velero server.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero plugin get`: Lists all plugins.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Snapshot locations**:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '`velero snapshot-location create <NAME>`: Creates a new snapshot location with
    the specified name.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero snapshot-location get`: Lists all snapshot locations.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero snapshot-location describe <NAME>`: Describes the details of a specific
    snapshot location.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero snapshot-location delete <NAME>`: Deletes a specified snapshot location.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Backup locations**:'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: '`velero backup-location create <NAME>`: Establishes a new backup location with
    the specified name.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup-location get`: Lists all backup locations.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup-location describe <NAME>`: Describes the details of a specific
    backup location.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero backup-location delete <NAME>`: Removes a specified backup location.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Managing restic repositories**:'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: '`velero restic repo get`: Lists all `restic` repositories.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restic repo describe <NAME>`: Describes the details of a specific restic
    repository.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restic repo forget <NAME>`: Manually removes restic backup snapshots.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restic repo prune <NAME>`: Removes unused data from a restic repository
    to free up space.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero restic repo garbage-collect <NAME>`: Runs a garbage collection operation
    on the specified repository.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Utility commands**:'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: '`velero version`: Displays the current version of Velero.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero client config set`: Configures the default settings for the Velero
    client.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero client config get`: Displays the current client configuration.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`velero completion <SHELL>`: Generates a shell completion script for the specified
    shell, enhancing CLI usability.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that you can create and schedule backups and know how to use the help system
    in Velero, we can move on to using a backup to restore objects.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
- en: Restoring from a backup
  id: totrans-354
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will explain the process of restoring from a backup using
    Velero. Having a backup is akin to having car insurance or homeowner’s insurance—it’s
    essential to have, yet you hope you never need to use it. When the unexpected
    happens, you’ll be grateful it’s there. In the realm of data backups, finding
    yourself needing to restore data without a backup is a scenario we often refer
    to as a “resume-building event.” To run a restore from a backup, you use the `create
    restore` command with the `--from-backup <backup name>` tag.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: 'Earlier in the chapter, we created a single, one-time backup, called `initial-backup`,
    which includes every namespace and object in the cluster. If we decided that we
    needed to restore that backup, we would execute a restore using the Velero CLI:'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  id: totrans-357
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'The output from the `restore` command may seem odd:'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  id: totrans-359
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: At first, it may seem like a backup request was made since Velero replies with
    `"initial-backup-20231207163306" submitted successfully`, but you may be wondering
    why the restore isn’t called `initial-backup`. Velero uses the backup name to
    create a restore request, and since we named our backup `initial-backup`, the
    restore job name will use that name and append the date and time of the restore
    request.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: 'You can view the status of the restore using the `describe` command:'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  id: totrans-362
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: Depending on the size of the restore, it may take some time to restore the entire
    backup. During the restore phase, the status of the backup will be `InProgress`.
    Once the restore is complete, the status will change to `Completed`.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: Restoring in action
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With all of the theory behind us, let’s use two examples to see Velero restores
    in action. For the examples, we will start with a simple deployment with a persistent
    volume that we will delete and restore on the same cluster. The second example
    will be more complex; we will back up a few namespaces in our main KinD cluster
    and restore them to a new KinD cluster.
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a deployment from a backup
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the backup section of this chapter, we created a backup of the cluster after
    we created a **busybox** deployment with a PVC attached. We added data to the
    PVC before we backed it up, and now we want to make sure that the backup is complete
    and that restoring a namespace is successful.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
- en: To test the restore, we will simulate a failure by deleting the `demo` namespace
    and then use our backup to restore the entire namespace, including the PVC data.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: Simulating a failure
  id: totrans-369
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To simulate an event that would require a backup of our namespace, we will
    delete the entire namespace using `kubectl`:'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  id: totrans-371
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: It may take a minute to delete the objects in the namespace. Once you have returned
    to a prompt, the deletion should be complete.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: Verify that the namespace has been deleted before moving on. Run a `kubectl
    get ns` and verify that the `demo` namespace is no longer listed.
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: With the confirmation that the `demo` namespace has been deleted, we will demonstrate
    how to restore the entire namespace and objects from the backup.
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a namespace
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Imagine this is a real-life scenario. You receive a phone call that a developer
    has accidentally deleted every object in their namespace and they do not have
    the source files.
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: Of course, you are prepared for this type of event. You have several backup
    jobs running in your cluster, and you tell the developer that you can restore
    it to the state it was in last night from a backup.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: We want to restore just the one namespace, `demo`, rather than the entire cluster.
    We know our backup name is `initial-backup`, so we will need to use that as our
    backup file when we execute a restore. To limit the restore to just a namespace,
    we will add the `--include-namespaces demo` flag to our command.
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  id: totrans-379
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: This will start a restore from the `initial-backup`. It shouldn’t take too long
    to restore since it’s a single namespace and the PVC only has a few empty files
    to restore.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: 'First, check to make sure that the namespace has been recreated. If you execute
    `kubectl get ns demo`, you should see the `demo` namespace in the list:'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  id: totrans-382
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Great! That’s the first step. Now, let’s make sure the pods were restored.
    We will need the name to look at the PVC contents:'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  id: totrans-384
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'Looking good so far. Finally, let’s use `kubectl exec` to look at the `/mnt`
    directory in the pod. We are hoping to see the new files we created before the
    backup:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  id: totrans-386
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: As we can see from the output of the `ls` command, the two files we added before
    executing the backup, `newfile1` and `newfile2`, are in the pod, proving that
    the backup works for restoring the namespace, including any persistent data.
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: Congratulations! You just saved the developer a lot of work because you had
    a backup of the namespace!
  id: totrans-388
  prefs: []
  type: TYPE_NORMAL
- en: Restoring objects like the previous example is a common exercise, and backing
    up and restoring in the same cluster is the only thing some operators may think
    backups are good for. While that may be the most common use case for backups,
    they can also be used for a number of other activities, like using a backup from
    one cluster into another, different cluster.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will use a backup from one cluster and restore the data
    to a different cluster. This is beneficial for a few scenarios, including migrating
    an application from one cluster to another or restoring the application and data
    to a development cluster to perform upgrade tests.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: Using a backup to create workloads in a new cluster
  id: totrans-391
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Restoring objects in a cluster is just one use case for Velero. While it is
    the main use case for most users, you can also use your backup files to restore
    a workload or all workloads on another cluster. This is a useful option if you
    need to create a new development or disaster recovery cluster.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: Remember that Velero backup jobs are only the namespaces and objects in the
    namespaces. To restore a backup to a new cluster, you must have a running cluster
    running Velero before you can restore any workloads.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: Backing up the cluster
  id: totrans-394
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: By this point in the chapter, we assume that you have seen this process a few
    times and that you know how to use the Velero CLI. If you need a refresher, you
    can go back a few pages in the chapter for reference, or use the CLI help function.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: For this example, we will not work with any data. Instead, we just want to demonstrate
    restoring a backup from one cluster to a different cluster.
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
- en: First, we should create a few namespaces and add some deployments to each one
    to make it more interesting. We have included a script in the `chapter14` folder
    called `create-backup-objects.yaml` that will create the namespaces and the objects
    for you. Run that script to create the namespaces and deployment.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the namespaces and deployment have been created, let’s create a new backup
    called `namespace-demo` that will back up only the four new namespaces that we
    created with the script:'
  id: totrans-398
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  id: totrans-399
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Before moving on, verify that the backup has been completed successfully. You
    can verify the backup by executing the `describe` command against the `namespace-demo`
    backup:'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  id: totrans-401
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: In the output, you will see that the backup includes the four namespaces and
    there are 40 objects in the backup. An abbreviated output is shown below.
  id: totrans-402
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  id: totrans-403
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: You now have a new backup that contains the four new namespaces and their objects.
    Now, using this backup, we will restore the four namespaces to a new cluster.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: First, we need to deploy a new KinD cluster thar, which will use to restore
    our `demo1`, `demo2`, `demo3`, and `demo4` namespaces.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: Building a new cluster
  id: totrans-406
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Since we are only demonstrating how Velero can be used to create workloads on
    a new cluster from a backup, we will create a simple single-node KinD cluster
    as our restore point.
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: This section gets a little complex since you will have two clusters in your
    `kubeconfig` file. Follow the steps carefully if you’re new to switching config
    contexts.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we have completed this exercise, we will delete the second cluster since
    we will not need to have two clusters. This exercise will be interactive. You
    will need to execute each step:'
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
- en: 'Create a new KinD cluster called `velero-restore`:'
  id: totrans-410
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE46]'
  id: totrans-411
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE46]'
- en: This will create a new single-node cluster that contains both the control plane
    and worker node, and it will set your cluster context to the new cluster.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the cluster has deployed, verify that your context has been switched to
    the `velero-restore` cluster:'
  id: totrans-413
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE47]'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE47]'
- en: 'The output is as follows:'
  id: totrans-415
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  id: totrans-416
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: Verify that the current context is set to the `kind-velero-restore` cluster.
    You will see an `*` in the current field of the cluster that is being used.
  id: totrans-417
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Finally, verify the namespaces in the cluster using `kubectl`. You should only
    see the default namespaces that are included with a new cluster:'
  id: totrans-418
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE49]'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: Now that we have created a new cluster, we can start the process of restoring
    the workloads. The first step is to install Velero on the new cluster, pointing
    to the existing S3 bucket as the backup location.
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a backup to the new cluster
  id: totrans-421
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With our new KinD cluster up and running, we need to install Velero to restore
    our backup. We can use most of the same manifests and settings that we used in
    the original cluster, but since we are in a different cluster, we need to change
    the S3 target to the external URL we used to expose MinIO.
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: Installing Velero in the new cluster
  id: totrans-423
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We already have the `credentials-velero` file in the `chapter14` folder, so
    we can jump right into installing Velero using the `velero install` command. To
    follow these steps, you should be in the `chapter14` directory:'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: 'Be sure to change the `s3Url` to your MinIO Ingress rule for your original
    KinD cluster that was created earlier in the chapter. If you forgot the ingress
    name, change your context to `kind-cluster01` and use `kubectl` to look at the
    rules in the `velero` namespace, `kubectl get ingress -n velero`. This will show
    you the full `nip.io` for MinIO (remember, don’t use the `minio-console` rule):'
  id: totrans-425
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE50]'
  id: totrans-426
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE50]'
- en: 'The install will take a few minutes, but once the pod is up and running, view
    the log files to verify that the Velero server is up and running and connected
    to the S3 target:'
  id: totrans-427
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE51]'
  id: totrans-428
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: 'If all of your settings were correct, the Velero log will have an entry saying
    that it has found backups in the backup location that need to be synced with the
    new Velero server (the number of backups may be different for your KinD cluster):'
  id: totrans-429
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE52]'
  id: totrans-430
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE52]'
- en: 'After confirming the installation, verify that Velero can see the existing
    backup files using `velero get backups`:'
  id: totrans-431
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE53]'
  id: totrans-432
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE53]'
- en: Your backup list will differ from ours, but you should see the same list that
    you had in the original cluster.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: At this point, we can use any of the backup files to create a restore job in
    the new cluster.
  id: totrans-434
  prefs: []
  type: TYPE_NORMAL
- en: Restoring a backup in a new cluster
  id: totrans-435
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we will use the backup that was created in the previous section
    and restore the workloads to a brand new KinD cluster to simulate a workload migration.
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
- en: 'The backup that was created of the original cluster, after we added the namespaces
    and deployment, was called `namespace-demo`:'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
- en: 'Using that backup name, we can restore the namespaces and objects by running
    the `velero create restore` command:'
  id: totrans-438
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE54]'
  id: totrans-439
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Wait for the restore to complete before moving on to the next step. To verify
    that the restore was successful, use the `velero describe restore` command with
    the name of the restore job that was created when you executed the `create restore`
    command. In our cluster, the restore job was assigned the name `namespace-demo-20211001235926`:'
  id: totrans-440
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE55]'
  id: totrans-441
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'Once the phase has changed from `InProgress` to `Completed`, verify that your
    new cluster has the additional demo namespaces using `kubectl get ns`:'
  id: totrans-442
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE56]'
  id: totrans-443
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'You will see that the new namespaces were created, and if you look at the pods
    in each namespace, you will see that each has a pod called `nginx`. You can verify
    that the pods were created using `kubectl get pods`. For example, to verify the
    pods in the `demo1` namespace, enter the following: `kubectl get pods -n demo1`.'
  id: totrans-444
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'The output is as follows:'
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  id: totrans-446
  prefs: []
  type: TYPE_PRE
  zh: '[PRE57]'
- en: Congratulations! You have successfully restored objects from one cluster into
    a new cluster.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
- en: Deleting the new cluster
  id: totrans-448
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since we do not need two clusters, let’s delete the new KinD cluster that we
    restored the backup to:'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
- en: 'To delete the cluster, execute the `kind delete cluster` command:'
  id: totrans-450
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE58]'
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'Set your current context to the original KinD cluster, `kind-cluster01`:'
  id: totrans-452
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE59]'
  id: totrans-453
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: Now that we have cleaned up the temporary second cluster, we have completed
    the chapter.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-455
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Backing up clusters and workloads is a requirement for any enterprise cluster.
    Having a backup solution allows you to recover from a disaster or human error.
    A typical backup solution allows you to restore any Kubernetes object, including
    namespaces, persistent volumes, RBAC, services, and service accounts. You can
    also take all of the workloads from one cluster and restore them on a completely
    different cluster for testing or troubleshooting.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter, we reviewed how to back up the `etcd` cluster database using
    `etcdctl` and the snapshot feature. We also went into detail on how to install
    Velero in a cluster to back up and restore workloads. We closed out the chapter
    by copying workloads from an existing backup by restoring an existing backup on
    a new cluster.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: Coming up in the next chapter, we will introduce you to monitoring your clusters
    and workloads.
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-459
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: True or false – Velero can only use an S3 target to store backup jobs.
  id: totrans-460
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  id: totrans-461
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  id: totrans-462
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: If you do not have an object storage solution, how can you provide an S3 target
    using a backend storage solution such as NFS?
  id: totrans-463
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: You can’t – there is no way to add anything in front of NFS to present S3.
  id: totrans-464
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Kubernetes can do this using native CSI features.
  id: totrans-465
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Install MinIO and use the NFS volumes as persistent disks in the deployment.
  id: totrans-466
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You don’t need to use an object store; you can use NFS directly with Velero.
  id: totrans-467
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: True or false – Velero backups can only be restored on the same cluster where
    the backup was originally created.
  id: totrans-468
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  id: totrans-469
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  id: totrans-470
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: What utility can you use to create an `etcd` backup?
  id: totrans-471
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Velero.
  id: totrans-472
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: MinIO.
  id: totrans-473
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: There is no reason to back up the `etcd` database.
  id: totrans-474
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`etcdctl`.'
  id: totrans-475
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Which command will create a scheduled backup that runs every day at 3 A.M.?
  id: totrans-476
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '`velero create backup daily-backup`'
  id: totrans-477
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`velero create @daily backup daily-backup`'
  id: totrans-478
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`velero create backup daily-backup –schedule="@daily3am"`'
  id: totrans-479
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`velero create schedule daily-backup --schedule="0 3 * * *"`'
  id: totrans-480
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Answers
  id: totrans-481
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: a
  id: totrans-482
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: a
  id: totrans-483
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: b
  id: totrans-484
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: d
  id: totrans-485
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: d
  id: totrans-486
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
