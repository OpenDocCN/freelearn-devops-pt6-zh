["```\n$ gcloud init\n```", "```\n$ gcloud compute networks create my-auto-network --subnet-mode auto\n```", "```\n//create custom mode VPC which is named my-custom-network\n$ gcloud compute networks create my-custom-network --subnet-mode custom\n```", "```\n$ gcloud compute networks subnets create subnet-a --network=my-custom-network --range=10.0.1.0/24 --region=us-west1\n$ gcloud compute networks subnets create subnet-b --network=my-custom-network --range=172.16.1.0/24 --region=us-east1\n$ gcloud compute networks subnets create subnet-c --network=my-custom-network --range=192.168.1.0/24 --region=asia-northeast1\n```", "```\n//create ssh access for public host\n$ gcloud compute firewall-rules create public-ssh --network=my-custom-network --allow=\"tcp:22\" --source-ranges=\"0.0.0.0/0\" --target-tags=\"public\"  //create http access (80/tcp for public host)\n$ gcloud compute firewall-rules create public-http --network=my-custom-network --allow=\"tcp:80\" --source-ranges=\"0.0.0.0/0\" --target-tags=\"public\"  //create ssh access for private host (allow from host which has \"public\" tag)\n$ gcloud compute firewall-rules create private-ssh --network=my-custom-network --allow=\"tcp:22\" --source-tags=\"public\" --target-tags=\"private\"\n\n//create icmp access for internal each other (allow from host which has either \"public\" or \"private\")\n$ gcloud compute firewall-rules create internal-icmp --network=my-custom-network --allow=\"icmp\" --source-tags=\"public,private\"\n```", "```\n//this command create new ssh key pair\n$ gcloud compute config-ssh //key will be stored as ~/.ssh/google_compute_engine(.pub)\n$ cd ~/.ssh\n$ ls -l google_compute_engine*\n-rw-------  1 saito  admin  1766 Aug 23 22:58 google_compute_engine\n-rw-r--r--  1 saito  admin   417 Aug 23 22:58 google_compute_engine.pub\n```", "```\n//create public instance (\"public\" tag) on subnet-a\n$ gcloud compute instances create public-on-subnet-a --machine-type=f1-micro --network=my-custom-network --subnet=subnet-a --zone=us-west1-a --tags=public\n\n//create public instance (\"public\" tag) on subnet-b\n$ gcloud compute instances create public-on-subnet-b --machine-type=f1-micro --network=my-custom-network --subnet=subnet-b --zone=us-east1-c --tags=public\n\n//create private instance (\"private\" tag) on subnet-a with larger size (g1-small)\n$ gcloud compute instances create private-on-subnet-a --machine-type=g1-small --network=my-custom-network --subnet=subnet-a --zone=us-west1-a --tags=private\n\n//Overall, there are 3 VM instances has been created in this example as below\n$ gcloud compute instances list\nNAME                                           ZONE           MACHINE_TYPE  PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP      STATUS\npublic-on-subnet-b                             us-east1-c     f1-micro                   172.16.1.2   35.196.228.40    RUNNING\nprivate-on-subnet-a                            us-west1-a     g1-small                   10.0.1.2     104.199.121.234  RUNNING\npublic-on-subnet-a                             us-west1-a     f1-micro                   10.0.1.3     35.199.171.31    RUNNING\n```", "```\n$ ssh-add ~/.ssh/google_compute_engine\nEnter passphrase for /Users/saito/.ssh/google_compute_engine:\nIdentity added: /Users/saito/.ssh/google_compute_engine\n(/Users/saito/.ssh/google_compute_engine)\n```", "```\n//logout from VM instance, then back to your machine\n$ exit\n\n//install nginx from your machine via ssh\n$ ssh 35.196.228.40 \"sudo apt-get -y install nginx\"\n$ ssh 35.199.171.31 \"sudo apt-get -y install nginx\"  //check whether firewall rule (public-http) work or not\n$ curl -I http://35.196.228.40/\nHTTP/1.1 200 OK\nServer: nginx/1.10.3\nDate: Sun, 27 Aug 2017 07:07:01 GMT\nContent-Type: text/html\nContent-Length: 612\nLast-Modified: Fri, 25 Aug 2017 05:48:28 GMT\nConnection: keep-alive\nETag: \"599fba2c-264\"\nAccept-Ranges: bytes\n```", "```\n$ curl http://104.199.121.234:8080/examples/\ncurl: (7) Failed to connect to 104.199.121.234 port 8080: Operation timed out\n```", "```\n//create instance groups for HTTP instances and tomcat instance\n$ gcloud compute instance-groups unmanaged create http-ig-us-west --zone us-west1-a\n$ gcloud compute instance-groups unmanaged create http-ig-us-east --zone us-east1-c\n$ gcloud compute instance-groups unmanaged create tomcat-ig-us-west --zone us-west1-a\n\n//because tomcat uses 8080/tcp, create a new named port as tomcat:8080\n$ gcloud compute instance-groups unmanaged set-named-ports tomcat-ig-us-west --zone us-west1-a --named-ports tomcat:8080\n\n//register an existing VM instance to correspond instance group\n$ gcloud compute instance-groups unmanaged add-instances http-ig-us-west --instances public-on-subnet-a --zone us-west1-a\n$ gcloud compute instance-groups unmanaged add-instances http-ig-us-east --instances public-on-subnet-b --zone us-east1-c\n$ gcloud compute instance-groups unmanaged add-instances tomcat-ig-us-west --instances private-on-subnet-a --zone us-west1-a\n```", "```\n//create health check for http (80/tcp) for \"/\"\n$ gcloud compute health-checks create http my-http-health-check --check-interval 5 --healthy-threshold 2 --unhealthy-threshold 3 --timeout 5 --port 80 --request-path / \n//create health check for Tomcat (8080/tcp) for \"/examples/\"\n$ gcloud compute health-checks create http my-tomcat-health-check --check-interval 5 --healthy-threshold 2 --unhealthy-threshold 3 --timeout 5 --port 8080 --request-path /examples/\n```", "```\n//create backend service for http (default) and named port tomcat (8080/tcp)\n$ gcloud compute backend-services create my-http-backend-service --health-checks my-http-health-check --protocol HTTP --global\n$ gcloud compute backend-services create my-tomcat-backend-service --health-checks my-tomcat-health-check --protocol HTTP --port-name tomcat --global\n\n//add http instance groups (both us-west1 and us-east1) to http backend service\n$ gcloud compute backend-services add-backend my-http-backend-service --instance-group http-ig-us-west --instance-group-zone us-west1-a --balancing-mode UTILIZATION --max-utilization 0.8 --capacity-scaler 1 --global\n$ gcloud compute backend-services add-backend my-http-backend-service --instance-group http-ig-us-east --instance-group-zone us-east1-c --balancing-mode UTILIZATION --max-utilization 0.8 --capacity-scaler 1 --global\n\n//also add tomcat instance group to tomcat backend service\n$ gcloud compute backend-services add-backend my-tomcat-backend-service --instance-group tomcat-ig-us-west --instance-group-zone us-west1-a --balancing-mode UTILIZATION --max-utilization 0.8 --capacity-scaler 1 --global\n```", "```\n//create load balancer(url-map) to associate my-http-backend-service as default\n$ gcloud compute url-maps create my-loadbalancer --default-service my-http-backend-service\n\n//add /examples and /examples/* mapping to my-tomcat-backend-service\n$ gcloud compute url-maps add-path-matcher my-loadbalancer --default-service my-http-backend-service --path-matcher-name tomcat-map --path-rules /examples=my-tomcat-backend-service,/examples/*=my-tomcat-backend-service //create target-http-proxy that associate to load balancer(url-map)\n$ gcloud compute target-http-proxies create my-target-http-proxy --url-map=my-loadbalancer\n\n//allocate static global ip address and check assigned address\n$ gcloud compute addresses create my-loadbalancer-ip --global\n$ gcloud compute addresses describe my-loadbalancer-ip --global\naddress: 35.186.192.6\n\ncreationTimestamp: '2018-12-08T13:40:16.661-08:00' ...\n...\n//create forwarding rule that associate static IP to target-http-proxy\n$ gcloud compute forwarding-rules create my-frontend-rule --global --target-http-proxy my-target-http-proxy --address 35.186.192.6 --ports 80 \n```", "```\n//add one more Firewall Rule that allow Load Balancer to Tomcat (8080/tcp) \n$ gcloud compute firewall-rules create private-tomcat --network=my-custom-network --source-ranges 35.191.0.0/16,130.211.0.0/22 --target-tags private --allow tcp:8080\n```", "```\n$ gcloud compute instances list\nNAME                                           ZONE           MACHINE_TYPE  PREEMPTIBLE  INTERNAL_IP  EXTERNAL_IP      STATUS\npublic-on-subnet-b                             us-east1-c     f1-micro                   172.16.1.2   35.196.228.40    RUNNING\nprivate-on-subnet-a                            us-west1-a     g1-small                   10.0.1.2     104.199.121.234  RUNNING\npublic-on-subnet-a                             us-west1-a     f1-micro                   10.0.1.3     35.199.171.31    RUNNING\n```", "```\n//create 20GB PD on us-west1-a with standard type\n$ gcloud compute disks create my-disk-us-west1-a --zone us-west1-a --type pd-standard --size 20 //after a few seconds, check status, you can see existing boot disks as well\n$ gcloud compute disks list\nNAME                                           ZONE           SIZE_GB  TYPE         STATUS\npublic-on-subnet-b                             us-east1-c     10       pd-standard  READY\nmy-disk-us-west1-a                             us-west1-a     20       pd-standard  READY\nprivate-on-subnet-a                            us-west1-a     10       pd-standard  READY\npublic-on-subnet-a                             us-west1-a     10       pd-standard  READY  //attach PD(my-disk-us-west1-a) to the VM instance(public-on-subnet-a)\n$ gcloud compute instances attach-disk public-on-subnet-a --disk my-disk-us-west1-a --zone us-west1-a //login to public-on-subnet-a to see the status\n$ ssh 35.199.171.31\nLinux public-on-subnet-a 4.9.0-3-amd64 #1 SMP Debian 4.9.30-2+deb9u3 (2017-08-06) x86_64\n\nThe programs included with the Debian GNU/Linux system are free software;\nthe exact distribution terms for each program are described in the\nindividual files in /usr/share/doc/*/copyright.\n\nDebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent\npermitted by applicable law.\nLast login: Fri Aug 25 03:53:24 2017 from 107.196.102.199\nsaito@public-on-subnet-a:~$ sudo su\nroot@public-on-subnet-a:/home/saito# dmesg | tail\n[ 7377.421190] systemd[1]: apt-daily-upgrade.timer: Adding 25min 4.773609s random time.\n[ 7379.202172] systemd[1]: apt-daily-upgrade.timer: Adding 6min 37.770637s random time.\n[243070.866384] scsi 0:0:2:0: Direct-Access     Google   PersistentDisk   1    PQ: 0 ANSI: 6\n[243070.875665] sd 0:0:2:0: [sdb] 41943040 512-byte logical blocks: (21.5 GB/20.0 GiB)\n[243070.883461] sd 0:0:2:0: [sdb] 4096-byte physical blocks\n[243070.889914] sd 0:0:2:0: Attached scsi generic sg1 type 0\n[243070.900603] sd 0:0:2:0: [sdb] Write Protect is off\n[243070.905834] sd 0:0:2:0: [sdb] Mode Sense: 1f 00 00 08\n[243070.905938] sd 0:0:2:0: [sdb] Write cache: enabled, read cache: enabled, doesn't support DPO or FUA\n[243070.925713] sd 0:0:2:0: [sdb] Attached SCSI disk\n```", "```\n//install kubectl command\n$ gcloud components install kubectl\n```", "```\n$ gcloud container clusters create my-k8s-cluster --machine-type f1-micro --num-nodes 3 --network my-custom-network --subnetwork subnet-c --zone asia-northeast1-a --tags private  //after a few minutes, check node status\nNAME                                            STATUS    ROLES     AGE       VERSION\ngke-my-k8s-cluster-default-pool-bcae4a66-mlhw   Ready     <none>    2m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-bcae4a66-tn74   Ready     <none>    2m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-bcae4a66-w5l6   Ready     <none>    2m        v1.10.9-gke.5\n```", "```\n//run resize command to change number of nodes to 5\n$ gcloud container clusters resize my-k8s-cluster --size 5 --zone asia-northeast1-a \n//after a few minutes later, you may see additional nodes\n$ kubectl get nodes\nNAME                                            STATUS    ROLES     AGE       VERSION\ngke-my-k8s-cluster-default-pool-bcae4a66-j8zz   Ready     <none>    32s       v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-bcae4a66-jnnw   Ready     <none>    32s       v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-bcae4a66-mlhw   Ready     <none>    4m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-bcae4a66-tn74   Ready     <none>    4m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-bcae4a66-w5l6   Ready     <none>    4m        v1.10.9-gke.5 \n```", "```\n//create and add node pool which is named \"large-mem-pool\"\n\n$ gcloud container node-pools create large-mem-pool --cluster my-k8s-cluster --machine-type g1-small --num-nodes 2 --tags private --zone asia-northeast1-a  //after a few minustes, large-mem-pool instances has been added\n$ kubectl get nodes\nNAME                                              STATUS    ROLES     AGE       VERSION\ngke-my-k8s-cluster-default-pool-bcae4a66-j8zz     Ready     <none>    5m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-bcae4a66-jnnw     Ready     <none>    5m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-bcae4a66-mlhw     Ready     <none>    9m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-bcae4a66-tn74     Ready     <none>    9m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-bcae4a66-w5l6     Ready     <none>    9m        v1.10.9-gke.5\ngke-my-k8s-cluster-large-mem-pool-66e3a44a-jtdn   Ready     <none>    46s       v1.10.9-gke.5\ngke-my-k8s-cluster-large-mem-pool-66e3a44a-qpbr   Ready     <none>    44s       v1.10.9-gke.5\n```", "```\n//nodeSelector specifies f1-micro\n$ cat nginx-pod-selector.yml\napiVersion: v1\nkind: Pod\nmetadata:\n name: nginx\nspec:\n containers:\n - name: nginx\n   image: nginx\n nodeSelector:\n  beta.kubernetes.io/instance-type: f1-micro\n\n//deploy pod\n$ kubectl create -f nginx-pod-selector.yml\npod \"nginx\" created \n//it uses default pool\nNAME      READY     STATUS              RESTARTS   AGE       IP        NODE\nnginx     0/1       ContainerCreating   0          10s       <none>    gke-my-k8s-cluster-default-pool-bcae4a66-jnnw\n```", "```\n//list Node Pool\n$ gcloud container node-pools list --cluster my-k8s-cluster --zone asia-northeast1-a NAME            MACHINE_TYPE  DISK_SIZE_GB  NODE_VERSION\ndefault-pool    f1-micro      100           1.10.9-gke.5\nlarge-mem-pool  g1-small      100           1.10.9-gke.5  //delete default-pool\n$ gcloud container node-pools delete default-pool --cluster my-k8s-cluster --zone asia-northeast1-a \n//after a few minutes, default-pool nodes x 5 has been deleted\n$ kubectl get nodes\nNAME                                              STATUS    ROLES     AGE       VERSION\ngke-my-k8s-cluster-large-mem-pool-66e3a44a-jtdn   Ready     <none>    9m        v1.10.9-gke.5\ngke-my-k8s-cluster-large-mem-pool-66e3a44a-qpbr   Ready     <none>    9m        v1.10.9-gke.5\n```", "```\n//delete cluster first\n$ gcloud container clusters delete my-k8s-cluster --zone asia-northeast1-a\nThe following clusters will be deleted.\n - [my-k8s-cluster] in [asia-northeast1-a]\nDo you want to continue (Y/n)?  y ...\n...\n //create a new cluster with --node-locations option with 2 nodes per zones\n$ gcloud container clusters create my-k8s-cluster --machine-type f1-micro --num-nodes 2 --network my-custom-network --subnetwork subnet-c --tags private --zone asia-northeast1-a --node-locations asia-northeast1-a,asia-northeast1-b,asia-northeast1-c\n```", "```\n$ kubectl get nodes\nNAME                                            STATUS    ROLES     AGE       VERSION\ngke-my-k8s-cluster-default-pool-58e4e9a4-74hc   Ready     <none>    43s       v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-58e4e9a4-8jft   Ready     <none>    1m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-f7baf2e1-lk7j   Ready     <none>    1m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-f7baf2e1-zktg   Ready     <none>    1m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-fa5a04a5-bbj5   Ready     <none>    1m        v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-fa5a04a5-d35z   Ready     <none>    1m        v1.10.9-gke.5\n```", "```\n$ gcloud container get-server-config\nFetching server config for us-west1-b\n\ndefaultClusterVersion: 1.10.9-gke.5\ndefaultImageType: COS\nvalidImageTypes:\n- COS_CONTAINERD\n- COS\n- UBUNTU\nvalidMasterVersions:\n- 1.11.4-gke.8\n- 1.11.3-gke.18\n- 1.11.2-gke.20\n- 1.11.2-gke.18\n- 1.10.9-gke.7\n- 1.10.9-gke.5\n- 1.10.7-gke.13\n- 1.10.7-gke.11\n- 1.10.6-gke.13\n- 1.10.6-gke.11\n- 1.9.7-gke.11\nvalidNodeVersions:\n- 1.11.4-gke.8\n- 1.11.3-gke.18\n- 1.11.2-gke.20\n- 1.11.2-gke.18\n- 1.11.2-gke.15\n- 1.11.2-gke.9\n- 1.10.9-gke.7\n- 1.10.9-gke.5\n- 1.10.9-gke.3\n- 1.10.9-gke.0\n- 1.10.7-gke.13\n- 1.10.7-gke.11\n... \n```", "```\n//upgrade master using --master option\n$ gcloud container clusters upgrade my-k8s-cluster --zone asia-northeast1-a --cluster-version 1.11.4-gke.8 --master\n\nMaster of cluster [my-k8s-cluster] will be upgraded from version \n[1.10.9-gke.5] to version [1.11.4-gke.8]. This operation is \nlong-running and will block other operations on the cluster (including\n delete) until it has run to completion.\n\nDo you want to continue (Y/n)? y\n\nUpgrading my-k8s-cluster...done.\nUpdated [https://container.googleapis.com/v1/projects/devops-with-kubernetes/zones/asia-northeast1-a/clusters/my-k8s-cluster].\n```", "```\n//master upgrade has been successfully to done\n$ gcloud container clusters list --zone asia-northeast1-a\nNAME            LOCATION           MASTER_VERSION  MASTER_IP      MACHINE_TYPE  NODE_VERSION    NUM_NODES  STATUS\n\nmy-k8s-cluster  asia-northeast1-a  1.11.4-gke.8    35.243.78.166  f1-micro      1.10.9-gke.5 *  6          RUNNING\n```", "```\n//node upgrade (not specify --master)\n$ gcloud container clusters upgrade my-k8s-cluster --zone asia-northeast1-a --cluster-version 1.11.4-gke.8\nAll nodes (6 nodes) of cluster [my-k8s-cluster] will be upgraded from \nversion [1.10.9-gke.5] to version [1.11.4-gke.8]. This operation is \nlong-running and will block other operations on the cluster (including delete) until it has run to completion.\n\nDo you want to continue (Y/n)?  y\n```", "```\n$ kubectl get nodes\nNAME                                            STATUS                     ROLES     AGE       VERSION\ngke-my-k8s-cluster-default-pool-58e4e9a4-74hc   Ready                      <none>    18m       v1.11.4-gke.8\ngke-my-k8s-cluster-default-pool-58e4e9a4-8jft   Ready                      <none>    19m       v1.11.4-gke.8\ngke-my-k8s-cluster-default-pool-f7baf2e1-lk7j   Ready                      <none>    19m       v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-f7baf2e1-zktg   Ready                      <none>    19m       v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-fa5a04a5-bbj5   Ready,SchedulingDisabled   <none>    19m       v1.10.9-gke.5\ngke-my-k8s-cluster-default-pool-fa5a04a5-d35z   Ready                      <none>    19m       v1.10.9-gke.5  \n```", "```\n$ kubectl get storageclass\nNAME                 TYPE\nstandard (default)   kubernetes.io/gce-pd  $ kubectl describe storageclass standard\n\nName:                  standard\nIsDefaultClass:        Yes\nAnnotations:           storageclass.beta.kubernetes.io/is-default-class=true\nProvisioner:           kubernetes.io/gce-pd\nParameters:            type=pd-standard\nAllowVolumeExpansion:  <unset>\nMountOptions:          <none>\nReclaimPolicy:         Delete\nVolumeBindingMode:     Immediate\nEvents:                <none>\n```", "```\n$ cat pvc-gke.yml\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n    name: pvc-gke-1\nspec:\n  storageClassName: \"standard\"\n  accessModes:\n    - ReadWriteOnce\n  resources:\n    requests:\n      storage: 10Gi\n //create Persistent Volume Claim\n$ kubectl create -f pvc-gke.yml \npersistentvolumeclaim \"pvc-gke-1\" created \n\n//check Persistent Volume\n$ kubectl get pv\nNAME                                       CAPACITY   ACCESSMODES   RECLAIMPOLICY   STATUS    CLAIM               STORAGECLASS   REASON    AGE\npvc-bc04e717-8c82-11e7-968d-42010a920fc3   10Gi       RWO           Delete          Bound     default/pvc-gke-1   standard                 2s \n\n//check via gcloud command\n$ gcloud compute disks list \nNAME                                                             ZONE               SIZE_GB  TYPE         STATUS\ngke-my-k8s-cluster-d2e-pvc-bc04e717-8c82-11e7-968d-42010a920fc3  asia-northeast1-a  10       pd-standard  READY \n```", "```\n$ cat grafana.yml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: grafana\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      project: devops-with-kubernetes\n      app: grafana\n  template:\n    metadata:\n      labels:\n        project: devops-with-kubernetes\n        app: grafana\n    spec:\n     containers:\n       - image: grafana/grafana\n         name: grafana\n         ports:\n          - containerPort: 3000\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: grafana\nspec:\n  ports:\n    - port: 80\n      targetPort: 3000\n  type: LoadBalancer\n  selector:\n    project: devops-with-kubernetes\n    app: grafana \n\n//deploy grafana with Load Balancer service\n$ kubectl create -f grafana.yml \ndeployment.apps \"grafana\" created\nservice \"grafana\" created\n\n//check L4 Load balancer IP address\n$ kubectl get svc grafana NAME      TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)        AGE\ngrafana   LoadBalancer   10.59.244.97   35.243.118.88   80:31213/TCP   1m //can reach via GCP L4 Load Balancer $ curl -I 35.243.118.88\nHTTP/1.1 302 Found\nContent-Type: text/html; charset=utf-8\nLocation: /login\nSet-Cookie: grafana_sess=186d81bd66d150d5; Path=/; HttpOnly\nSet-Cookie: redirect_to=%252F; Path=/; HttpOnly\nDate: Sun, 09 Dec 2018 02:25:48 GMT\n```", "```\n$ cat nginx-tomcat-ingress.yaml \napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: nginx-tomcat-ingress\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /\n        backend:\n          serviceName: nginx\n          servicePort: 80\n      - path: /examples\n        backend:\n          serviceName: tomcat\n          servicePort: 8080\n      - path: /examples/*\n        backend:\n          serviceName: tomcat\n          servicePort: 8080 \n\n $ kubectl create -f nginx-tomcat-ingress.yaml \ningress \"nginx-tomcat-ingress\" created \n```", "```\n$ kubectl get ing\nNAME                   HOSTS     ADDRESS           PORTS     AGE\nnginx-tomcat-ingress   *         107.178.253.174   80        1m \n```", "```\n//allocate static IP as my-nginx-tomcat\n$ gcloud compute addresses create my-nginx-tomcat --global \n //check assigned IP address\n$ gcloud compute addresses list \nNAME             REGION  ADDRESS         STATUS\nmy-nginx-tomcat          35.186.227.252  IN_USE \n //add annotations definition\n$ cat nginx-tomcat-static-ip-ingress.yaml \napiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: nginx-tomcat-ingress\n  annotations:\n    kubernetes.io/ingress.global-static-ip-name: my-nginx- \ntomcat\nspec:\n  rules:\n  - http:\n      paths:\n      - path: /\n        backend:\n          serviceName: nginx\n          servicePort: 80\n      - path: /examples\n        backend:\n          serviceName: tomcat\n          servicePort: 8080\n      - path: /examples/*\n        backend:\n          serviceName: tomcat\n          servicePort: 8080 \n //apply command to update Ingress\n$ kubectl apply -f nginx-tomcat-static-ip-ingress.yaml \n //check Ingress address that associate to static IP\n$ kubectl get ing\nNAME                   HOSTS     ADDRESS          PORTS     AGE\nnginx-tomcat-ingress   *         35.186.227.252   80        48m \n```"]