<html><head></head><body>
  <div id="_idContainer331" class="Basic-Text-Frame">
    <h1 class="chapterNumber">18</h1>
    <h1 id="_idParaDest-882" class="chapterTitle">The Future of Kubernetes</h1>
    <p class="normal">In this chapter, we will look at the future of Kubernetes from multiple angles. We’ll start with the momentum of Kubernetes since its inception across dimensions such as community, ecosystem, and mindshare. Spoiler alert – Kubernetes won the container orchestration wars by a landslide. As Kubernetes grows and matures, the battle lines shift from beating competitors to fighting against its own complexity. Usability, tooling, and education will play a major role as container orchestration is still new, fast-moving, and not a well-understood domain. Then we will take a look at some very interesting patterns and trends, and finally, we will review my predictions from the second edition, and I will make some new predictions.</p>
    <p class="normal">The covered topics are as follows:</p>
    <ul>
      <li class="bulletList">The Kubernetes momentum</li>
      <li class="bulletList">The importance of CNCF</li>
      <li class="bulletList">Kubernetes extensibility</li>
      <li class="bulletList">Service mesh integration</li>
      <li class="bulletList">Serverless computing on Kubernetes</li>
      <li class="bulletList">Kubernetes and VMs</li>
      <li class="bulletList">Cluster autoscaling</li>
      <li class="bulletList">Ubiquitous operators</li>
      <li class="bulletList">Kubernetes for AI</li>
      <li class="bulletList">Kubernetes challenges</li>
    </ul>
    <h1 id="_idParaDest-883" class="heading-1">The Kubernetes momentum</h1>
    <p class="normal">Kubernetes is<a id="_idIndexMarker2050"/> undeniably a juggernaut. Not only did Kubernetes beat all the other container orchestrators, but it is also the de facto solution on public clouds, utilized in many private clouds, and even VMware – the virtual machine company – is focused on Kubernetes solutions and integrating its products with Kubernetes.</p>
    <p class="normal">Kubernetes works very well in multi-cloud and hybrid-cloud scenarios due to its extensible design.</p>
    <p class="normal">In addition, Kubernetes makes inroads on the edge, too, with custom distributions that expand its broad applicability even more.</p>
    <p class="normal">The Kubernetes project continues to release a new version every three months, like clockwork. The community just keeps growing.</p>
    <p class="normal">The Kubernetes GitHub repository has almost 100,000 stars. One of the major drivers of this phenomenal growth <a id="_idIndexMarker2051"/>is the <strong class="keyWord">CNCF</strong> (<strong class="keyWord">Cloud Native Computing Foundation</strong>).</p>
    <figure class="mediaobject"><img src="../Images/B18998_18_01.png" alt=""/></figure>
    <p class="packt_figref">Figure 18.1: Star History chart</p>
    <h2 id="_idParaDest-884" class="heading-2">The importance of the CNCF</h2>
    <p class="normal">The <a id="_idIndexMarker2052"/>CNCF has become a very important organization in the cloud computing scene. While it is not Kubernetes-specific, the dominance of Kubernetes is undeniable. Kubernetes is the first project to graduate, and most of the other projects lean heavily toward Kubernetes. In particular, the CNCF offers certification and training only for Kubernetes. The CNCF, among other roles, ensures that cloud technologies will not suffer from vendor lock-in. Check out this crazy diagram of the entire<a id="_idIndexMarker2053"/> CNCF landscape: <a href="https://landscape.cncf.io"><span class="url">https://landscape.cncf.io</span></a>.</p>
    <h3 id="_idParaDest-885" class="heading-3">Project curation</h3>
    <p class="normal">The CNCF assigns maturity levels<a id="_idIndexMarker2054"/> to projects: <strong class="keyWord">graduated</strong>, <strong class="keyWord">incubating</strong>, and <strong class="keyWord">sandbox</strong>:</p>
    <figure class="mediaobject"><img src="../Images/B18998_18_02.png" alt="CNCF maturity levels"/></figure>
    <p class="packt_figref">Figure 18.2: CNCF maturity levels</p>
    <p class="normal">Projects start at a certain level – sandbox or incubating – and over time, can graduate. That doesn’t mean that only graduated projects can be safely used. Many incubating and even sandbox projects are used heavily in production. For example, etcd is the persistent state store of Kubernetes itself, and it is just an incubating project. Obviously, it is a highly trusted component. Virtual Kubelet<a id="_idIndexMarker2055"/> is a sandbox project that powers AWS Fargate and Microsoft ACI. This is clearly enterprise-grade software.</p>
    <p class="normal">The main benefit of the <a id="_idIndexMarker2056"/>CNCF curation of projects is to help navigate the incredible ecosystem that grew around Kubernetes. When you look to extend your Kubernetes solution with additional technologies and tools, the CNCF projects are a good place to start.</p>
    <h3 id="_idParaDest-886" class="heading-3">Certification</h3>
    <p class="normal">When<a id="_idIndexMarker2057"/> technologies start to offer certification programs, you can tell they are here to stay. The CNCF offers several types of certifications:</p>
    <ul>
      <li class="bulletList">Certified Kubernetes for conforming Kubernetes distributions and installers (about 90).</li>
      <li class="bulletList"><strong class="keyWord">Kubernetes Certified Service Provider</strong> (<strong class="keyWord">KCSP</strong>) for <a id="_idIndexMarker2058"/>vetted service providers with deep Kubernetes experience (134 providers).</li>
      <li class="bulletList"><strong class="keyWord">Certified Kubernetes Administrator</strong> (<strong class="keyWord">CKA</strong>) for <a id="_idIndexMarker2059"/>administrators.</li>
      <li class="bulletList"><strong class="keyWord">Certified Kubernetes Application Developer</strong> (<strong class="keyWord">CKAD</strong>) for <a id="_idIndexMarker2060"/>developers.</li>
      <li class="bulletList"><strong class="keyWord">Certified Kubernetes Security Specialist</strong> (<strong class="keyWord">CKS</strong>) for security <a id="_idIndexMarker2061"/>experts.</li>
    </ul>
    <h3 id="_idParaDest-887" class="heading-3">Training</h3>
    <p class="normal">The <a id="_idIndexMarker2062"/>CNCF offers training too. There is a free introduction to Kubernetes course and several paid courses that align with the CKA and CKAD certification exams. In addition, the CNCF maintains a list of <a id="_idIndexMarker2063"/>Kubernetes training partners (<a href="https://landscape.cncf.io/card-mode?category=kubernetes-training-partner&amp;grouping=category"><span class="url">https://landscape.cncf.io/card-mode?category=kubernetes-training-partner&amp;grouping=category</span></a>).</p>
    <p class="normal">If you’re looking for free Kubernetes training, here are a couple of options:</p>
    <ul>
      <li class="bulletList">VMware Kubernetes academy</li>
      <li class="bulletList">Google Kubernetes Engine on Coursera</li>
    </ul>
    <h3 id="_idParaDest-888" class="heading-3">Community and education</h3>
    <p class="normal">The<a id="_idIndexMarker2064"/> CNCF also organizes conferences like KubeCon, CloudNativeCon, and meetups and maintains several communication avenues like Slack channels and mailing lists. It also publishes surveys and reports.</p>
    <p class="normal">The number of attendees and participants keeps growing year after year.</p>
    <h2 id="_idParaDest-889" class="heading-2">Tooling</h2>
    <p class="normal">The number of <a id="_idIndexMarker2065"/>tools to manage containers and clusters, the various add-ons, extensions, and plugins just keep growing. Here is a subset of the tools, projects, and companies that participate in the Kubernetes ecosystem:</p>
    <figure class="mediaobject"><img src="../Images/B18998_18_03.png" alt="Kubernetes Tooling"/></figure>
    <p class="packt_figref">Figure 18.3: Kubernetes tooling</p>
    <h1 id="_idParaDest-890" class="heading-1">The rise of managed Kubernetes platforms</h1>
    <p class="normal">Pretty much every cloud provider has a solid managed Kubernetes offering these days. Sometimes there are multiple flavors and ways of running Kubernetes on a given cloud provider.</p>
    <h2 id="_idParaDest-891" class="heading-2">Public cloud Kubernetes platforms</h2>
    <p class="normal">Here are <a id="_idIndexMarker2066"/>some of the prominent managed platforms:</p>
    <ul>
      <li class="bulletList">Google GKE</li>
      <li class="bulletList">Microsoft AKS</li>
      <li class="bulletList">Amazon EKS</li>
      <li class="bulletList">Digital Ocean</li>
      <li class="bulletList">Oracle Cloud</li>
      <li class="bulletList">IBM Cloud Kubernetes service</li>
      <li class="bulletList">Alibaba ACK</li>
      <li class="bulletList">Tencent TKE</li>
    </ul>
    <p class="normal">Of course, you<a id="_idIndexMarker2067"/> can always roll your own and use the public cloud providers just as infrastructure providers. This is a very common use case with Kubernetes.</p>
    <h2 id="_idParaDest-892" class="heading-2">Bare metal, private clouds, and Kubernetes on the edge</h2>
    <p class="normal">Here, you can find <a id="_idIndexMarker2068"/>Kubernetes distributions that are designed or configured to run in special environments, often in your own data centers as a private cloud or in more restricted environments like <a id="_idIndexMarker2069"/>edge computing on small devices:</p>
    <ul>
      <li class="bulletList">Google Anthos for GKE</li>
      <li class="bulletList">OpenStack</li>
      <li class="bulletList">Rancher k3S</li>
      <li class="bulletList">Kubernetes on Raspberry PI</li>
      <li class="bulletList">KubeEdge</li>
    </ul>
    <h2 id="_idParaDest-893" class="heading-2">Kubernetes PaaS (Platform as a Service)</h2>
    <p class="normal">This category of offerings aims to abstract some of the complexity of Kubernetes and put a simpler facade in front of it. There <a id="_idIndexMarker2070"/>are many varieties here. Some of them cater to the multi-cloud and hybrid-cloud scenarios, some expose a function-as-a-service interface, and some just focus on a better installation and support experience:</p>
    <ul>
      <li class="bulletList">Google Cloud Run</li>
      <li class="bulletList">VMware PKS</li>
      <li class="bulletList">Platform 9 PMK</li>
      <li class="bulletList">Giant Swarm</li>
      <li class="bulletList">OpenShift</li>
      <li class="bulletList">Rancher RKE</li>
    </ul>
    <h1 id="_idParaDest-894" class="heading-1">Upcoming trends</h1>
    <p class="normal">Let’s talk about some of the technological trends<a id="_idIndexMarker2071"/> in the Kubernetes world that will be important in the near future. </p>
    <h2 id="_idParaDest-895" class="heading-2">Security</h2>
    <p class="normal">Security is, of course, a paramount concern for large-scale systems. Kubernetes is primarily a platform for managing containerized workloads. Those containerized workloads are often run in a multi-tenant environment. The isolation between tenants is super important. Containers<a id="_idIndexMarker2072"/> are lightweight and efficient because they share an OS and maintain their isolation through various mechanisms like namespace isolation, filesystem isolation, and cgroup resource isolation. In theory, this should be enough. In practice, the surface area is large, and there were multiple breakouts out of container isolation.</p>
    <p class="normal">To address this risk, multiple lightweight VMs were designed to add a hypervisor (machine-level virtualization) as an additional isolation level between the container and the OS kernel. The big cloud providers already support these technologies, and the Kubernetes CRI interface provides a streamlined way to take advantage of these more secure runtimes.</p>
    <p class="normal">For example, FireCracker<a id="_idIndexMarker2073"/> is integrated with containerd via firecracker-containerd. Google gVisor<a id="_idIndexMarker2074"/> is another sandbox technology. It is a userspace kernel that implements most of the Linux system calls and provides a buffer between the application and the host OS. It is also available through containerd via gvisor-containerd-shim.</p>
    <h2 id="_idParaDest-896" class="heading-2">Networking</h2>
    <p class="normal">Networking<a id="_idIndexMarker2075"/> is another area <a id="_idIndexMarker2076"/>that is an ongoing source of innovation. The Kubernetes CNI allows any number of innovative networking solutions behind a simple interface. A major theme is the incorportation of eBPF – a relatively new Linux kernel technology – into Kubernetes.</p>
    <p class="normal"><strong class="keyWord">eBPF</strong> stands for <strong class="keyWord">extended Berkeley Packet Filter</strong>. The core of eBPF is a mini-VM in the Linux kernel that executes <a id="_idIndexMarker2077"/>special programs attached to kernel objects when certain events occur, such as a packet being transmitted or received. Originally, only sockets were supported, and the technology was called just BPF. Later, additional objects were added to the mix and that’s when the <em class="italic">e</em> for <em class="italic">extended</em> came along. eBPF’s claim to fame is its performance due to the fact it runs highly optimized compiled BPF programs in the kernel and doesn’t require extending the<a id="_idIndexMarker2078"/> kernel with <a id="_idIndexMarker2079"/>kernel modules.</p>
    <p class="normal">There are many applications for eBPF:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Dynamic network control</strong>: iptables-based approaches don’t scale very well in a dynamic environment like<a id="_idIndexMarker2080"/> a Kubernetes cluster where you have a constantly changing set of pods and services. Replacing iptables with BPF programs is both more performant and more manageable. Cilium is focused on routing and filtering traffic using eBPF.</li>
      <li class="bulletList"><strong class="keyWord">Monitoring connections</strong>: Creating an up-to-date map of TCP connections between containers is possible by attaching a BPF program kprobes that track socket-level events. WeaveScope utilizes this capability by running an agent on each node that collects this information and sends it to a server that provides a visual representation through a slick UI.</li>
      <li class="bulletList"><strong class="keyWord">Restricting syscalls</strong>: The Linux kernel provides more than 300 system calls. In a security-sensitive container environment, it is highly desirable. The original seccomp facility was pretty rudimentary. In Linux 3.5, seccomp was extended to support BPF for advanced custom filters.</li>
      <li class="bulletList"><strong class="keyWord">Raw performance</strong>: eBPF provides significant performance benefits, and projects like Calico<a id="_idIndexMarker2081"/> took advantage and implemented a faster data plane that uses fewer resources.</li>
    </ul>
    <h2 id="_idParaDest-897" class="heading-2">Custom hardware and devices</h2>
    <p class="normal">Kubernetes <a id="_idIndexMarker2082"/>manages nodes, networking, and storage at a relatively high level. But there are many benefits to integrating specific hardware at a fine-grained level. For example, GPUs, high-performance network cards, FPGAs, InfiniBand adapters, and other compute and networking and storage resources. This is where the device plugin framework<a id="_idIndexMarker2083"/> comes in, which can be found here: <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins"><span class="url">https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins</span></a>. It has been in GA since Kubernetes 1.26, and there is ongoing innovation in this area. For example, monitoring device plugin resources is also in beta since Kubernetes 1.15. It is very interesting to see what devices will be harnessed to Kubernetes. The <a id="_idIndexMarker2084"/>framework itself follows modern Kubernetes extensibility practices by utilizing gRPC.</p>
    <h2 id="_idParaDest-898" class="heading-2">Service mesh</h2>
    <p class="normal">The service mesh<a id="_idIndexMarker2085"/> is arguably the most important trend in networking over the last couple of years. We covered service meshes in depth in <em class="chapterRef">Chapter 14</em>, <em class="italic">Utilizing Service Meshes</em>. The adoption is impressive, and I predict that most Kubernetes distributions <a id="_idIndexMarker2086"/>will provide a default service mesh and allow easy integration with other service meshes. The benefits that service meshes provide are just too valuable. It makes sense to provide a default platform that includes Kubernetes with an integrated service mesh. That said, Kubernetes itself will not absorb some service mesh and expose it through its API. This goes against the grain of keeping the core of Kubernetes small.</p>
    <p class="normal">Google Anthos<a id="_idIndexMarker2087"/> is a good example where Kubernetes + Knative + Istio are combined to provide a unified platform that provides an opinionated best-practices bundle that would take an organization a lot of time and resources to build on top of vanilla Kubernetes.</p>
    <p class="normal">Another push in this direction is the<a id="_idIndexMarker2088"/> sidecar container KEP; information about it can be found here: <a href="https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/753-sidecar-containers/README.md"><span class="url">https://github.com/kubernetes/enhancements/blob/master/keps/sig-node/753-sidecar-containers/README.md</span></a>.</p>
    <p class="normal">The sidecar container pattern<a id="_idIndexMarker2089"/> has been a staple of Kubernetes from the get-go. After all, pods can contain multiple containers. But there was no notion of a main container or a sidecar container. All containers in the pod have the same status. Most service meshes use sidecar containers to intercept traffic and perform their jobs. Formalizing sidecar containers will help those efforts and push service meshes even further.</p>
    <p class="normal">It’s not clear at this stage if Kubernetes and the service mesh will be hidden behind a simpler abstraction on most platforms or if they will be front and center.</p>
    <h2 id="_idParaDest-899" class="heading-2">Serverless computing</h2>
    <p class="normal">Serverless<a id="_idIndexMarker2090"/> computing is another <a id="_idIndexMarker2091"/>trend that is here to stay. We discussed it at length in <em class="chapterRef">Chapter 12</em>, <em class="italic">Serverless Computing on Kubernetes</em>. Kubernetes and serverless can be combined on multiple levels. Kubernetes can utilize serverless cloud solutions like AWS Fargate <a id="_idIndexMarker2092"/>and <strong class="keyWord">AKS Azure Container Instances </strong>(<strong class="keyWord">ACI</strong>) to save the cluster administrator from managing nodes. This approach also caters to integrating lightweight VMs transparently with Kubernetes since the cloud platforms don’t use naked Linux containers for their container-as-a-service platforms.</p>
    <p class="normal">Another avenue is to reverse the roles and expose containers as a service powered by Kubernetes under the covers. This is exactly what Google Cloud Run is doing. The lines blur here as there are multiple products from Google to manage containers and/or Kubernetes ranging from just GKE, through Anthos GKE (bring your own cluster to the GKE environment for your private data center), Anthos (managed Kubernetes + service mesh), and Anthos Cloud Run.</p>
    <p class="normal">Finally, there are<a id="_idIndexMarker2093"/> functions-as-a-service and scale-to-zero projects <a id="_idIndexMarker2094"/>running inside your Kubernetes cluster. Knative may become the leader here, as it is already used by many frameworks, and is deployed heavily through various Google products.</p>
    <h2 id="_idParaDest-900" class="heading-2">Kubernetes on the edge</h2>
    <p class="normal">Kubernetes is the poster<a id="_idIndexMarker2095"/> boy of cloud-native computing, but with the <strong class="keyWord">Internet of Things </strong>(<strong class="keyWord">IoT</strong>) revolution, there is more need to<a id="_idIndexMarker2096"/> perform<a id="_idIndexMarker2097"/> computation at the edge of the network. Sending all data to the backend for processing suffers from several drawbacks:</p>
    <ul>
      <li class="bulletList">Latency</li>
      <li class="bulletList">Need for enough bandwidth</li>
      <li class="bulletList">Cost</li>
    </ul>
    <p class="normal">With edge locations collecting a lot of data via sensors, video cameras, etc., the amount of edge data grows, and it makes more sense to perform more and more sophisticated processing at the edge. Kubernetes grew out of Google’s Borg, which was definitely not designed to run at the edge of the network. But Kubernetes’ design proved to be flexible enough to accommodate it. I expect that we will see more and more Kubernetes deployments at the edge of the network, which will lead to very interesting systems that are composed of many Kubernetes clusters that will need to be managed centrally.</p>
    <p class="normal">KubeEdge<a id="_idIndexMarker2098"/> is an open-source framework that is built on top of Kubernetes and Mosquito – an open-source implementation of MQTT message broker – to provide a foundation for <a id="_idIndexMarker2099"/>networking, application deployment, and metadata synchronization between the cloud and the edge.</p>
    <h2 id="_idParaDest-901" class="heading-2">Native CI/CD</h2>
    <p class="normal">For developers, one of the most <a id="_idIndexMarker2100"/>important questions is the construction of a CI/CD pipeline. There are many options and choosing between them can be difficult. The CD<a id="_idIndexMarker2101"/> Foundation is an open source foundation that was formed to standardize concepts like pipelines and workflows, and define industry specifications that will allow different tools and communities to interoperate better. </p>
    <p class="normal">The current projects are:</p>
    <ul>
      <li class="bulletList">Jenkins</li>
      <li class="bulletList">Tekton</li>
      <li class="bulletList">Spinnaker</li>
      <li class="bulletList">Jenkins X</li>
      <li class="bulletList">Screwdriver.cd</li>
      <li class="bulletList">Ortelius</li>
      <li class="bulletList">CDEvents</li>
      <li class="bulletList">Pyrsia</li>
      <li class="bulletList">Shipwright</li>
    </ul>
    <p class="normal">Note that only Jenkins and Tekton are considered graduated projects. The rest are incubating projects (even Spinnaker).</p>
    <p class="normal">One of my favorite native CD projects, Argo CD, is not <a id="_idIndexMarker2102"/>part of the CD Foundation. I actually opened a GitHub issue asking to submit Argo CD to the CDF, but the Argo team has decided that CNCF is a better fit for their project.</p>
    <p class="normal">Another project to <a id="_idIndexMarker2103"/>watch is CNB – Cloud Native Buildpacks. The project takes the source and creates OCI (think Docker) images. It is important for FaaS frameworks and native in-cluster CI. It is also a CNCF sandbox project.</p>
    <h2 id="_idParaDest-902" class="heading-2">Operators</h2>
    <p class="normal">The <strong class="keyWord">Operator</strong> pattern<a id="_idIndexMarker2104"/> emerged in 2016 from CoreOS (acquired by RedHat, acquired by IBM) and<a id="_idIndexMarker2105"/> gained a lot of success in the community. An Operator is a combination of custom resources and a controller used to manage an application. At my current job, I write operators to manage various aspects of infrastructure, and it is a joy. It is already the established way to distribute non-trivial applications to Kubernetes clusters. Check out <a href="https://operatorhub.io/"><span class="url">https://operatorhub.io/</span></a> for a huge list of existing operators. I expect this trend to continue and intensify.</p>
    <h1 id="_idParaDest-903" class="heading-1">Kubernetes and AI</h1>
    <p class="normal">AI is the hottest trend right now. <strong class="keyWord">Large language models</strong> (<strong class="keyWord">LLMs</strong>) and <strong class="keyWord">Generative Pre-trained Transforms </strong>(<strong class="keyWord">GPT</strong>) surprised most <a id="_idIndexMarker2106"/>professionals with their capabilities. The <a id="_idIndexMarker2107"/>release of ChatGPT 3.5 by OpenAI was a watershed moment. AI suddenly excels in areas that were considered strongholds of human intelligence, such as creative writing, painting, understanding, answering nuanced questions, and, of course, coding. My perspective is that advanced AI is the solution to the big data problem. We learned to collect a lot of data, but analyzing and extracting insights from the data is a difficult and labor-intensive process. AI seems like the right technology to digest all the data and automatically understand, summarize, and organize it into a useful form to be used by humans and other systems (most likely AI-based systems).</p>
    <p class="normal">Let’s see why Kubernetes is such a great fit for AI workloads.</p>
    <h2 id="_idParaDest-904" class="heading-2">Kubernetes and AI synergy</h2>
    <p class="normal">Modern AI is all about <a id="_idIndexMarker2108"/>deep learning networks and huge models with billions of parameters trained on massive datasets, often using dedicated hardware. Kubernetes is a perfect fit for such workloads as it quickly adapts to the workload’s needs, takes advantage of new and improved hardware, and provides strong observability.</p>
    <p class="normal">The best evidence is the field. Kubernetes is at the core of the OpenAI pipeline, and additional companies are developing and deploying massive AI applications. Check out this article that shows how OpenAI pushes the envelope with Kubernetes and runs huge clusters with 7,500 nodes: <a href="https://openai.com/research/scaling-kubernetes-to-7500-nodes"><span class="url">https://openai.com/research/scaling-kubernetes-to-7500-nodes</span></a>.</p>
    <p class="normal">Let’s consider training AI models on Kubernetes.</p>
    <h2 id="_idParaDest-905" class="heading-2">Training AI models on Kubernetes</h2>
    <p class="normal">Training<a id="_idIndexMarker2109"/> large AI models is potentially slow and very expensive. Organizations<a id="_idIndexMarker2110"/> that partake in training AI models on Kubernetes benefit from many of its properties:</p>
    <ul>
      <li class="bulletList"><strong class="keyWord">Scalability</strong>: Kubernetes provides a highly scalable infrastructure for deploying and managing AI workloads. With Kubernetes, it is possible to quickly scale resources up or down based on demand, enabling organizations to train AI models quickly and efficiently.</li>
      <li class="bulletList"><strong class="keyWord">Resource utilization</strong>: Kubernetes allows for efficient resource utilization, enabling organizations to train AI models using the most cost-effective infrastructure. With Kubernetes, it is possible to automatically allocate and manage resources, ensuring that the right resources are available for the workload.</li>
      <li class="bulletList"><strong class="keyWord">Flexibility</strong>: Kubernetes provides a high degree of flexibility in terms of the infrastructure used for training AI models. Kubernetes supports a wide range of hardware, including GPUs, FPGAs, and TPUs, making it possible to use the most appropriate hardware for the workload.</li>
      <li class="bulletList"><strong class="keyWord">Portability</strong>: Kubernetes provides a highly portable infrastructure for deploying and managing AI workloads. Kubernetes supports a wide range of cloud providers and on-premises infrastructure, making it possible to train AI models in any environment.</li>
      <li class="bulletList"><strong class="keyWord">Ecosystem</strong>: Kubernetes has a vibrant ecosystem of open-source tools and frameworks that can be used for training AI models. For example, Kubeflow is a popular open-source framework for building and deploying machine learning<a id="_idIndexMarker2111"/> workflows <a id="_idIndexMarker2112"/>on Kubernetes.</li>
    </ul>
    <h2 id="_idParaDest-906" class="heading-2">Running AI-based systems on Kubernetes</h2>
    <p class="normal">Once you have trained <a id="_idIndexMarker2113"/>your models and built your application<a id="_idIndexMarker2114"/> on top of your models, you need to deploy and run it. Kubernetes is, of course, a great platform for deploying workloads in general. AI-based workloads are often designed for a reliable and quick super-human response. The high availability that Kubernetes offers and the ability to quickly scale up and down based on demand satisfy these requirements.</p>
    <p class="normal">In addition, if the<a id="_idIndexMarker2115"/> system is designed to keep learning (as opposed to fixed pre-trained systems like GPTs), then Kubernetes offers strong security<a id="_idIndexMarker2116"/> and control that support safe operation.</p>
    <p class="normal">Let’s look at the emerging field of AIOps.</p>
    <h2 id="_idParaDest-907" class="heading-2">Kubernetes and AIOps</h2>
    <p class="normal">AIOps is a<a id="_idIndexMarker2117"/> paradigm that leverages AI and machine learning to automate and optimize the management of infrastructure. AIOps can help organizations improve the reliability, performance, and security of their IT infrastructure while reducing the burden on human engineers.</p>
    <p class="normal">Kubernetes is a perfect target for practicing AIOps. It is fully accessible programmatically. It is often deployed with deep observability. Those two conditions are necessary and sufficient to enable AI to scrutinize the state of the system and take action when necessary.</p>
    <p class="normal">The future of Kubernetes seems bright, but it has some challenges too.</p>
    <h1 id="_idParaDest-908" class="heading-1">Kubernetes challenges</h1>
    <p class="normal">Is Kubernetes the <a id="_idIndexMarker2118"/>answer to everything to do with infrastructure? Not at all. Let’s look at some challenges, such as Kubernetes’ complexity, and some alternative solutions for the problem of developing, deploying, and managing large-scale systems.</p>
    <h2 id="_idParaDest-909" class="heading-2">Kubernetes complexity</h2>
    <p class="normal">Kubernetes is a large, powerful, and <a id="_idIndexMarker2119"/>extensible platform. It is mostly un-opinionated and very flexible. It has a huge surface area with a lot of resources and APIs. In addition, Kubernetes has a huge ecosystem. That translates to a system that is extremely difficult to learn and master. What does it say about Kubernetes’ future? One likely scenario is that most developers will not interact with Kubernetes directly. Simplified solutions built on top of Kubernetes will be the primary access point for most developers.</p>
    <p class="normal">If Kubernetes is fully abstracted, then it may become a threat to its future since Kubernetes, as the underlying implementation, might be replaced by the solution provider. The final users may not need to make any changes at all to their code or configuration.</p>
    <p class="normal">Another scenario is that more and more organizations negatively weigh the costs of building on top of Kubernetes compared to lightweight container orchestration platforms such as <a id="_idIndexMarker2120"/>Nomad. This could lead to an exodus from Kubernetes.</p>
    <p class="normal">Let’s look at some technologies that may compete with Kubernetes in different areas.</p>
    <h2 id="_idParaDest-910" class="heading-2">Serverless function platforms</h2>
    <p class="normal">Serverless <a id="_idIndexMarker2121"/>function platforms offer organizations and developers similar benefits to Kubernetes using a simpler (if less powerful) paradigm. Instead of modeling your system as a set of long-running applications and services, you just implement a set of functions that can be triggered on demand. You don’t need to manage clusters, node pools, and servers. Some solutions offer long-running services, too, either pre-packaged as containers or directly from source. We covered it thoroughly in <em class="chapterRef">Chapter 12</em>, <em class="italic">Serverless Computing on Kubernetes</em>. As the serverless platforms get better and Kubernetes become more complicated, more organizations may prefer to at least start using serverless solutions and possibly migrate to Kubernetes later.</p>
    <p class="normal">First and foremost, all cloud providers offer various serverless solutions. The pure cloud functions models<a id="_idIndexMarker2122"/> are:</p>
    <ul>
      <li class="bulletList">AWS Lambda</li>
      <li class="bulletList">Google Cloud Functions</li>
      <li class="bulletList">Azure Functions</li>
    </ul>
    <p class="normal">There are also multiple strong and easy-to-use solutions out there that are not associated with the big cloud <a id="_idIndexMarker2123"/>providers:</p>
    <ul>
      <li class="bulletList">Cloudflare Workers</li>
      <li class="bulletList">Fly.io</li>
      <li class="bulletList">Render</li>
      <li class="bulletList">Vercel</li>
    </ul>
    <p class="normal">That concludes our coverage of Kubernetes challenges. Let’s summarize the chapter.</p>
    <h1 id="_idParaDest-911" class="heading-1">Summary</h1>
    <p class="normal">In this chapter, we looked at the future of Kubernetes, and it looks great! The technical foundation, the community, the broad support, and the momentum are all very impressive. Kubernetes is still young, but the pace of innovation and stabilization is very encouraging. The modularization and extensibility principles of Kubernetes let it become the universal foundation for modern cloud-native applications. That said, there are some challenges to Kubernetes and it might not dominate each and every scenario. This is a good thing. Diversity, competition, and inspiration from other solutions will just make Kubernetes better.</p>
    <p class="normal">At this point, you should have a clear idea of where Kubernetes is right now and where it’s going from here. You should be confident that Kubernetes is not just here to stay, but that it will be the leading container orchestration platform for many years to come and integrate with any major offering and environment you can imagine, from planet-scale public cloud platforms, private clouds, data centers, edge locations and all the way down to your development laptop and Raspberry Pi.</p>
    <p class="normal">That’s it! This is the end of the book.</p>
    <p class="normal">Now it’s up to you to use what you’ve learned and build amazing things with Kubernetes!</p>
    <h1 id="_idParaDest-912" class="heading-1">Join us on Discord!</h1>
    <p class="normal">Read this book alongside other users, cloud experts, authors, and like-minded professionals.</p>
    <p class="normal">Ask questions, provide solutions to other readers, chat with the authors via. Ask Me Anything sessions and much more.</p>
    <p class="normal">Scan the QR code or visit the link to join the community now.</p>
    <p class="normal"><a href="https://packt.link/cloudanddevops"><span class="url">https://packt.link/cloudanddevops</span></a></p>
    <p class="normal"><img src="../Images/QR_Code844810820358034203.png" alt=""/></p>
  </div>
</body></html>