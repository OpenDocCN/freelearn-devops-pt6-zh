<html><head></head><body>
		<div id="_idContainer185">
			<h1 id="_idParaDest-242" class="chapter-number"><a id="_idTextAnchor254"/>14</h1>
			<h1 id="_idParaDest-243"><a id="_idTextAnchor255"/>Supporting DevOps Processes with Observability</h1>
			<p>This chapter will discuss the use of Grafana in two different aspects of the technology industry – <strong class="bold">software delivery</strong> and <span class="No-Break"><strong class="bold">platform operations</strong></span><span class="No-Break">.</span></p>
			<p>We will briefly introduce you to the <strong class="bold">DevOps life cycle</strong> as valuable foundational knowledge. Using this framework, we will <a id="_idIndexMarker1127"/>guide you through the value of Grafana in each phase to enrich the software development process in your organization. We encourage you to spend time understanding where bottlenecks are in this process and focus resources on the most appropriate phase for your team <span class="No-Break">or organization.</span></p>
			<p>Platform operations are typified by using third-party applications. This removes about half of the DevOps life cycle, as those stages are conducted by a third party. You will be introduced to the considerations you should make for using Grafana during the deployment and operation of several types of platforms. We will look at collecting data from data collection tools in an observability platform and consider best practices around disaster planning for the failure<a id="_idIndexMarker1128"/> of this business-critical system. We will look at the particular needs of the operators and users of platforms that provide <strong class="bold">continuous integration</strong> (<strong class="bold">CI</strong>) or <strong class="bold">continuous delivery/deployment</strong> (<strong class="bold">CD</strong>) capabilities to an organization, as monitoring these platforms can be challenging. We will discuss<a id="_idIndexMarker1129"/> resources available to monitor databases, in-memory data stores, message buses, and web servers, covering how to install them efficiently and how these common tools have publicly available dashboards in Grafana to use. Finally, we will have a quick look at how this same pattern of monitoring platforms is applicable for some <span class="No-Break">security tools.</span></p>
			<p>This chapter will handle technical concepts but there are no requirements to have experience with individual tools, and the chapter should be accessible to anyone, regardless <span class="No-Break">of background.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Introducing the DevOps <span class="No-Break">life cycle</span></li>
				<li>Using Grafana for fast feedback during the development <span class="No-Break">life cycle</span></li>
				<li>Using Grafana to monitor infrastructure <span class="No-Break">and platforms</span></li>
			</ul>
			<h1 id="_idParaDest-244"><a id="_idTextAnchor256"/>Introducing the DevOps life cycle</h1>
			<p>Before we explain what the DevOps life cycle<a id="_idIndexMarker1130"/> is, let’s consider the history of Agile, DevOps, DevSecOps, and platform engineering <span class="No-Break">a little.</span></p>
			<p>Iterative development practices were used as early as the late 1950s, but in the 1990s, several development methods<a id="_idIndexMarker1131"/> were introduced as a reaction<a id="_idIndexMarker1132"/> to development practices<a id="_idIndexMarker1133"/> that were seen<a id="_idIndexMarker1134"/> as heavyweight, micromanaged, highly regulated, and with a high risk of project failure. These new methods included <strong class="bold">rapid application development</strong> (<strong class="bold">RAD</strong>), <strong class="bold">Scrum</strong>, <strong class="bold">extreme programming</strong>, and <strong class="bold">feature-driven design</strong> (<strong class="bold">FDD</strong>). These all originated before the Agile Manifesto, but they are now known as agile practices. According to the Agile Manifesto, published in 2001, we prefer<a id="_idIndexMarker1135"/> <span class="No-Break">the following:</span></p>
			<ul>
				<li>Individuals and interactions over processes <span class="No-Break">and tools</span></li>
				<li>Working software over <span class="No-Break">comprehensive documentation</span></li>
				<li>Customer collaboration over <span class="No-Break">contract negotiation</span></li>
				<li>Responding to change over following <span class="No-Break">a plan</span></li>
			</ul>
			<p>This indicates that, while there is value in the items on the right, we value the items on the <span class="No-Break">left more.</span></p>
			<p>Agile practices evolved from development practices, and they are focused on development teams, although there are a lot of crossovers with operational practices. These manifesto notions drove a lot of interest in practices such as test-driven development, CI, CD, and <span class="No-Break">many others.</span></p>
			<p>In the early 2000s, concerns around the separation of development practices and operational practices were highlighted (although these concerns were also raised through the 1980s and 1990s). These concerns coalesced in 2009 with the first <em class="italic">DevOps Days</em> conference. DevOps does not articulate a central philosophy such as Agile, but it suggests practices and measures that are intended to speed the delivery of working software to customers. A lot of these practices<a id="_idIndexMarker1136"/> revolve around having developers, testers, and operators collaborate more closely, often by bringing them together in the same team. Similarly, development practices such as using version control systems (for example, Git) are adopted so operational concerns such as system configuration can become part of the shared understanding of a whole <span class="No-Break">software system.</span></p>
			<p>DevOps has several branches, extensions, and concepts. Here are some of them for those who are interested in reading further: <strong class="bold">ArchOps</strong>, <strong class="bold">site reliability engineering</strong> (<strong class="bold">SRE</strong>), <strong class="bold">DevSecOps</strong>, <strong class="bold">DataOps</strong>, <strong class="bold">12-factor apps</strong> or <strong class="bold">15-factor apps</strong>, <strong class="bold">infrastructure as code</strong> (<strong class="bold">IaC</strong>), <strong class="bold">configuration as code</strong> (<strong class="bold">CaC</strong>), <span class="No-Break">and </span><span class="No-Break"><strong class="bold">GitOps</strong></span><span class="No-Break">.</span></p>
			<p>A quote from Amazon CTO Werner Vogels back in 2006 became a bit of a rallying cry for the DevOps movement: “<em class="italic">You build it, you run it</em>.” This has a lot of merit. Having the team who designed and wrote a product also be responsible for its operation should mean that incidents are resolved quicker and customer feedback can be heard and responded to. Teams can be more agile! When managed well and in the right organization, this can be a very effective<a id="_idIndexMarker1137"/> way to operate. However, as the analysis by Matthew Skelton and Manuel Pais in <em class="italic">Team Topologies</em> (<a href="https://web.devopstopologies.com/index.html#anti-types">https://web.devopstopologies.com/index.html#anti-types</a>) shows, many anti-patterns can appear and lead to dysfunction in an organization. This approach can also lead to a significant cognitive load for development teams, which makes organizations less able to respond <span class="No-Break">to change.</span></p>
			<p>You might ask why we include this history when we are explaining what the DevOps life cycle is. The reason is to caution you that this life cycle is a tool and, in most organizations, a collection of processes; while they do have value, they should not be valued more than individuals and interactions. The way that teams tasked with managing a customer-facing software system will interact with an observability platform will differ significantly from a team tasked with managing the platform in support of the organization’s goals. With this caution given, let’s look at the DevOps life cycle as it gives us a good framework to discuss the many aspects of using an observability platform through the <span class="No-Break">life cycle:</span></p>
			<div>
				<div id="_idContainer183" class="IMG---Figure">
					<img src="image/B18277_14_1.jpg" alt="Figure 14.1 – The DevOps life cycle"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.1 – The DevOps life cycle</p>
			<p class="callout-heading">Important note</p>
			<p class="callout">There’s isn’t a clear definition of DevOps or DevSecOps. The DevOps life cyle itself covers development and operations while the security aspect wraps around all of that (and more), as shown in <span class="No-Break"><em class="italic">Figure 14</em></span><span class="No-Break"><em class="italic">.1</em></span><span class="No-Break">.</span></p>
			<p>Let’s walk through each phase<a id="_idIndexMarker1138"/> of this <span class="No-Break">life cycle:</span></p>
			<ul>
				<li><strong class="bold">Code</strong>: This is where new code is written in line with the specification given during the <span class="No-Break">planning phase</span></li>
				<li><strong class="bold">Build</strong>: This phase is where new code <span class="No-Break">is built</span></li>
				<li><strong class="bold">Test</strong>: New code is tested in various ways during <span class="No-Break">this phase</span></li>
				<li><strong class="bold">Release</strong>: The code is verified as ready to be deployed to production in this phase; any final checks or assurances will be <span class="No-Break">performed here</span></li>
				<li><strong class="bold">Deploy</strong>: The code is deployed to a <span class="No-Break">production environment</span></li>
				<li><strong class="bold">Operate</strong>: This phase is a continuous phase; the latest deployed release is run in a <span class="No-Break">production environment</span></li>
				<li><strong class="bold">Monitor</strong>: Any data collected from the release that is currently operating in production is gathered, as well as any feedback or user research, and is collated together to be used in the next <span class="No-Break">planning phase</span></li>
				<li><strong class="bold">Plan</strong>: During this phase, the team plans what future iterations of the product <span class="No-Break">will contain</span></li>
				<li><strong class="bold">Security</strong>: This is a continuous concern for the team<a id="_idIndexMarker1139"/> in a DevSecOps approach and is the responsibility of all members of <span class="No-Break">the team</span></li>
			</ul>
			<p>Now that we have seen the DevOps life cycle, let’s consider how we can use Grafana tools during each phase of <span class="No-Break">this cycle.</span></p>
			<h1 id="_idParaDest-245"><a id="_idTextAnchor257"/>Using Grafana for fast feedback during the development life cycle</h1>
			<p>In this section, we will consider<a id="_idIndexMarker1140"/> how to use Grafana tools through each stage of the DevOps life cycle. Developing software can be risky and expensive, and observability platforms can also be expensive. Therefore, using the data from an observability platform to reduce the risks and expense of developing software is a great investment. We’ll start with the <em class="italic">code</em> phase of the <span class="No-Break">life cycle.</span></p>
			<h2 id="_idParaDest-246"><a id="_idTextAnchor258"/>Code</h2>
			<p>To use Grafana in the DevOps<a id="_idIndexMarker1141"/> life cycle, the system must produce useful data that can be used to understand the state of the system. To that end, the first act during the <em class="italic">code</em> phase of the life cycle is to <em class="italic">instrument</em> the system. Depending on the type of system we are working on, the method of producing data may <span class="No-Break">look different:</span></p>
			<ul>
				<li>A <strong class="bold">software application</strong> would be instrumented by adding libraries or SDKs that produce data<a id="_idIndexMarker1142"/> in a format agreed with the team(s) who collects this data. In some situations, this can even be achieved by the injection of instrumentation into the application, which can happen during the <em class="italic">deploy</em> stage of the life cycle. Organizations<a id="_idIndexMarker1143"/> need to be clear on where this <span class="No-Break">responsibility lies.</span></li>
				<li>A <strong class="bold">cloud infrastructure</strong> or <strong class="bold">cloud platform</strong> component would be instrumented <a id="_idIndexMarker1144"/>by collecting data from <span class="No-Break">the vendor.</span></li>
				<li>A <strong class="bold">local infrastructure</strong> or <strong class="bold">local platform</strong> component would be instrumented by collecting data<a id="_idIndexMarker1145"/> in a format supported by the vendor of <span class="No-Break">the component.</span></li>
			</ul>
			<p>For a lot of systems, this may be all that is needed. However, there are times when an organization needs custom data from a system. Adding such instrumentation falls squarely in the <em class="italic">code</em> phase of the life cycle. However, when considering such activities, it is important to also ensure that the <em class="italic">plan</em> and <em class="italic">test</em> phases are considered. This can be achieved through activities such as agreeing on a data format and field definitions and implementing the code in a way that it can be tested in future iterations of the product (for example, <span class="No-Break">domain-orientated observability).</span></p>
			<p>The final area in which Grafana can help during the coding process is by being run directly against code as it is developed. Most, if not all developers, will run their code locally before it is committed to a version control repository. As Grafana is open source, it is very easy to implement a local development environment that produces and collects observability telemetry; we provided an example of this kind of environment when we explored live data in <em class="italic">Chapters 3</em>, <em class="italic">4</em>, <em class="italic">5,</em> and <em class="italic">6</em>. This wealth of information can feed directly back into the coding process as <span class="No-Break">it happens.</span></p>
			<p>The next phase of the life cycle<a id="_idIndexMarker1146"/> is the <em class="italic">build</em> phase. We will skip over this as we deal with monitoring builds in a lot more detail when we talk about monitoring CI/CD platforms in the next section of this chapter. Let’s talk about the <em class="italic">test</em> <span class="No-Break">phase next.</span></p>
			<h2 id="_idParaDest-247"><a id="_idTextAnchor259"/>Test</h2>
			<p>The <em class="italic">test</em> phase can cover a lot of different<a id="_idIndexMarker1147"/> test types. While tests are typically managed by the CI/CD platform, such as the use of a testing framework or static analysis tools, the most common form of feedback in Grafana is to monitor the CI/CD platform itself. An additional approach for organizations or teams who want to track more information is to output time series data from the CI/CD platform into a <strong class="bold">time series database</strong> (<strong class="bold">TSDB</strong>). These kinds of custom approaches can often become<a id="_idIndexMarker1148"/> like a complex Rube Goldberg machine, so we would caution you to be very mindful of what the value is to the organization, and we recommend that you research the market in case a more suitable product <span class="No-Break">is available.</span></p>
			<p>As the <em class="italic">test</em> phase moves into end-to-end tests, tools such as k6 really come into play (we discussed this in <a href="B18277_13.xhtml#_idTextAnchor239"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>). Writing great repeatable tests for tools in this space can also offer a very valuable ability to run them during the <em class="italic">deploy</em> phase of the life cycle to confirm that the new code has been <span class="No-Break">successfully deployed.</span></p>
			<p>The <em class="italic">release</em> phase encompasses everything between completing testing and releasing code to customers. This often covers activities such as gaining approvals for the deployment from stakeholders<a id="_idIndexMarker1149"/> or assurance teams. Let’s have a look at how Grafana <span class="No-Break">can help.</span></p>
			<h2 id="_idParaDest-248"><a id="_idTextAnchor260"/>Release</h2>
			<p>Let’s start discussing using Grafana<a id="_idIndexMarker1150"/> for the <em class="italic">release</em> phase with a brief warning: many tools on the market may offer a better fit for organizations and teams, so we recommend that organizations do some research if they are having problems with their <span class="No-Break">release processes.</span></p>
			<p>Perhaps the biggest feature<a id="_idIndexMarker1151"/> of Grafana that enables a smooth release step<a id="_idIndexMarker1152"/> is the ability to show whether a new iteration of a product complies with the <strong class="bold">service-level objectives</strong> (<strong class="bold">SLOs</strong>) and <strong class="bold">service-level agreements</strong> (<strong class="bold">SLAs</strong>) for the product. Showing these metrics from a new iteration, especially when the product has been put under load by a tool such as k6, is a very powerful way to say that the new iteration behaves <span class="No-Break">as expected.</span></p>
			<p>The other feature that may be of interest to some teams is the ability to automatically build dashboards that contain HTML widgets. This can be used to automatically assemble a release dashboard with links to various artifacts such as test reports, tickets for included features, <span class="No-Break">and similar.</span></p>
			<p>The operational phases of the life cycle are the most associated with Grafana. Let’s start looking at these with the <em class="italic">deploy</em> phase, in which code is deployed into a production environment ready for customers <span class="No-Break">to access.</span></p>
			<h2 id="_idParaDest-249"><a id="_idTextAnchor261"/>Deploy</h2>
			<p>The <em class="italic">deploy</em> phase will see a lot of changes<a id="_idIndexMarker1153"/> occur, and the details of using Grafana will differ depending on how the system <span class="No-Break">is deployed:</span></p>
			<ul>
				<li>Where an application is deployed to a Kubernetes cluster, Pods will be scheduled for termination, while new Pods using the newer version will be started. We might see Pods responsible for database updates scheduled, and various other aspects. When used as the repository for all telemetry from a Kubernetes cluster, Grafana can be used to visualize the deployment process in a way that suits the deployment team, from prebuilt dashboards to a custom dashboard specifically designed for a specific <span class="No-Break">application deployment.</span></li>
				<li>Where applications are deployed directly to an operating system rather than a containerized environment, Grafana still offers detailed monitoring, with prebuilt dashboards for operating systems, common languages, web servers, databases, in-memory data stores, and many <span class="No-Break">other tools.</span></li>
			</ul>
			<p>These approaches provide <strong class="bold">white box monitoring</strong> of a deployment; a lot of organizations will also implement <strong class="bold">black box monitoring</strong> of the application during a deployment. Grafana can help here as well. By using <strong class="bold">Grafana OnCall</strong> to receive messages from an availability<a id="_idIndexMarker1154"/> monitoring tool such<a id="_idIndexMarker1155"/> as the Prometheus blackbox<a id="_idIndexMarker1156"/> exporter, k6, or Pingdom, this stream of data can also be monitored during <span class="No-Break">a deployment.</span></p>
			<p>It is best practice to generate annotations when a deployment happens, which can be done via the API. Here is an example of an annotation added to a deployment of the OpenTelemetry Collector that caused <span class="No-Break">an incident:</span></p>
			<div>
				<div id="_idContainer184" class="IMG---Figure">
					<img src="image/B18277_14_2.jpg" alt="Figure 14.2 – Annotations in action"/>
				</div>
			</div>
			<p class="IMG---Caption" lang="en-US" xml:lang="en-US">Figure 14.2 – Annotations in action</p>
			<p>As the screenshot shows, Grafana will display contextual information about deployments on any visualization that has the option switched on. Annotations appear as a line on the chart and show information when hovered over; this contextual information can <span class="No-Break">be tagged.</span></p>
			<p>At their heart, CD platforms<a id="_idIndexMarker1157"/> are code execution platforms, which means that any action that can be coded can be performed by a CD platform. We just talked about monitoring a deployment visually using a dashboard. This approach is great when deployments happen infrequently. When deployments occur much more frequently, it can be valuable to invest time in writing stages of a deployment where the state of the application being deployed is monitored. Loki, Mimir, and Tempo all offer query endpoints, which can be used to run queries as part of the scripted CD job. Effectively, this offloads the need to watch a dashboard to the CD pipeline, and rollback steps can be defined if the deployment fails. Some common examples of this use are <span class="No-Break">as follows:</span></p>
			<ul>
				<li>Monitoring the error rate seen in the <span class="No-Break">application logs.</span></li>
				<li>Checking whether login actions are successful. This would usually be tied to a smoke test to ensure that login <span class="No-Break">events occur.</span></li>
				<li>Checking whether communication with downstream services <span class="No-Break">is affected.</span></li>
			</ul>
			<p>If these checks were to fail, the deployment could be quickly rolled back using automated procedures. This approach significantly reduces the <strong class="bold">mean time to recovery</strong> (<strong class="bold">MTTR</strong>) for such common issues and ensures that engineers<a id="_idIndexMarker1158"/> can be focused on more valuable tasks during <span class="No-Break">a deployment.</span></p>
			<p>The gold standard for leveraging the tools provided by Grafana is to also deploy any updates to the dashboards used for a service with Terraform during the same deployment window as the code deployment. Adopting this practice allows for an easily repeatable process, moving from local development work through testing and into a <span class="No-Break">production environment.</span></p>
			<p>While exciting, the <em class="italic">deploy</em> phase is not the phase<a id="_idIndexMarker1159"/> where code is in <em class="italic">normal</em> operation; that phase is the <em class="italic">operate</em> phase. Let’s look at this <span class="No-Break">phase next.</span></p>
			<h2 id="_idParaDest-250"><a id="_idTextAnchor262"/>Operate</h2>
			<p>The <em class="italic">operate</em> phase is where the product<a id="_idIndexMarker1160"/> is live in front of customers. The most important aspect of this phase is ensuring customers are getting a great service. This can be achieved by monitoring SLOs and SLAs, checking errors that may occur, responding to incidents, and helping customers in their use of the product. Grafana is primarily a tool that is used through the <em class="italic">operate</em> phase of the life cycle, so most<a id="_idIndexMarker1161"/> tools in Grafana are targeted toward this phase. Some key components<a id="_idIndexMarker1162"/> that will be used by all teams who use Grafana are <strong class="bold">dashboards</strong> and <strong class="bold">alerts</strong>. The ability to see how a user is interacting with a product is also very valuable to operational teams, such as customer experience or customer <span class="No-Break">support teams.</span></p>
			<p>We discussed in <a href="B18277_09.xhtml#_idTextAnchor183"><span class="No-Break"><em class="italic">Chapter 9</em></span></a> how <strong class="bold">Grafana Alerting</strong> and <strong class="bold">Grafana Incident</strong> can integrate with many systems. This capability<a id="_idIndexMarker1163"/> is very helpful in creating a detailed incident <a id="_idIndexMarker1164"/>response system – for example, by linking Grafana with ServiceNow so the creation, updating, and closing of incident tickets can be partially or fully automated, even with capabilities to collect chat communications to reduce the time needed to write up what happened during an incident <span class="No-Break">for reporting.</span></p>
			<p>We talked about using <strong class="bold">Grafana Frontend Observability</strong> in <a href="B18277_12.xhtml#_idTextAnchor231"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>; when correctly implemented with distributed<a id="_idIndexMarker1165"/> tracing, this tool allows customer-facing teams to reconstruct an individual user’s session. This allows these teams to work quickly with the customer to understand the frontend problem they are experiencing and translate that into a trace path through the system to identify the source of the issue and get it to the right team quickly, with easy-to-digest information<a id="_idIndexMarker1166"/> on <span class="No-Break">what happened.</span></p>
			<p>Let’s consider how to use Grafana to monitor <span class="No-Break">the system.</span></p>
			<h2 id="_idParaDest-251"><a id="_idTextAnchor263"/>Monitor</h2>
			<p>Like the <em class="italic">operate</em> phase. the <em class="italic">monitor</em> phase is the phase in which using<a id="_idIndexMarker1167"/> Grafana can really shine. The two biggest challenges are knowing what telemetry to use to answer a question about the product and whether the telemetry is being made available. While it would be impossible to list every potential question, here are some common questions, linked with the telemetry type that would be best suited to <span class="No-Break">answer them:</span></p>
			<ul>
				<li>How are my customers interacting with <span class="No-Break">my product?</span><p class="list-inset">This is best answered by using real user monitoring, which we discussed in <a href="B18277_12.xhtml#_idTextAnchor231"><span class="No-Break"><em class="italic">Chapter 12</em></span></a>. This question could cover many similar questions such as what the uptake of a new feature is, and whether there are unvisited pages or features in <span class="No-Break">the system.</span></p></li>
				<li>Are there particular functions that <span class="No-Break">are slow?</span><p class="list-inset">This can be answered by combining the timing information for requests from metrics with the detailed application information produced in logs. We discussed these in <em class="italic">Chapters 4</em> and <em class="italic">5</em>. For applications with downstream dependencies, this information can also be complemented with trace data, as discussed in <a href="B18277_06.xhtml#_idTextAnchor134"><span class="No-Break"><em class="italic">Chapter 6</em></span></a><span class="No-Break">.</span></p></li>
				<li>Why is a particular <span class="No-Break">function slow?</span><p class="list-inset">Often, this question will be answered through local testing, but this process may be significantly aided by using continuous profiling against a system with real or replayed requests. <a href="B18277_13.xhtml#_idTextAnchor239"><span class="No-Break"><em class="italic">Chapter 13</em></span></a> discussed continuous profiling in <span class="No-Break">more detail.</span></p></li>
				<li>Is my application behaving <span class="No-Break">as expected?</span><p class="list-inset">This is best addressed by establishing clear <strong class="bold">service-level indicators</strong> (<strong class="bold">SLIs</strong>) and SLOs for the application; we outlined<a id="_idIndexMarker1168"/> how to do this in <a href="B18277_09.xhtml#_idTextAnchor183"><span class="No-Break"><em class="italic">Chapter 9</em></span></a><span class="No-Break">.</span></p></li>
				<li>Is the service compliant with <span class="No-Break">the SLOs/SLAs?</span><p class="list-inset">This is typically answered by using metrics data. However, some indicators may be metrics derived from logs or tracing data – for example, creating a metric from logs of the number of <span class="No-Break">errors seen.</span></p></li>
				<li>Is my infrastructure <span class="No-Break">scaled correctly?</span><p class="list-inset">This would be answered by collecting data from the infrastructure. How that is done may differ depending on the type <span class="No-Break">of infrastructure:</span></p><ul><li>For cloud infrastructure, this is done via an integration that provides logs, metrics, and sometimes <span class="No-Break">tracing data</span></li><li>For on-premises infrastructure, the collection methods <span class="No-Break">will vary</span></li></ul><p class="list-inset">We discussed this topic in more detail in <a href="B18277_07.xhtml#_idTextAnchor147"><span class="No-Break"><em class="italic">Chapter 7</em></span></a><span class="No-Break">.</span></p></li>
				<li>What is the long-term trend <span class="No-Break">for something?</span><p class="list-inset">The best telemetry type for long-term trending is metrics as they provide a default 13-month retention period. This means the best practice for such analysis is to produce a metric from the data you wish <span class="No-Break">to track.</span></p><p class="list-inset">Another approach would be to load data from Grafana into some form of data warehouse, but this is outside the scope of <span class="No-Break">this book.</span></p></li>
			</ul>
			<p>The real difference between the <em class="italic">operate</em> phase <a id="_idIndexMarker1169"/>and the <em class="italic">monitor</em> phase is the aim of the use of Grafana. In the <em class="italic">operate</em> phase, the goal is to ensure that the system is functioning correctly for customers of the system. In the <em class="italic">monitor</em> phase, the goal is to understand and document how the system is functioning to feed into the <em class="italic">plan</em> phase to improve the system. Let’s finish discussing the DevOps life cycle with the <span class="No-Break"><em class="italic">plan</em></span><span class="No-Break"> phase.</span></p>
			<h2 id="_idParaDest-252"><a id="_idTextAnchor264"/>Plan</h2>
			<p>The <em class="italic">plan</em> phase takes input from many sources<a id="_idIndexMarker1170"/> to help a team decide what the next priority for work is. The questions asked in the <em class="italic">monitor</em> phase, and any incidents or SLO breaches from the <em class="italic">operate</em> phase, are some of those sources. To help prioritize, it is common to consider things such as <span class="No-Break">the following:</span></p>
			<ul>
				<li>How many customers are affected by a particular incident or <span class="No-Break">potential improvement?</span><p class="list-inset">The logs, metrics, and traces in Grafana can collect the data needed to answer this. This is true even for changes that have been sourced from other places such as <span class="No-Break">user feedback.</span></p></li>
				<li>How close to capacity is a component of the system, or how much time is there to address a bottleneck before it begins creating incidents or <span class="No-Break">performance degradation?</span></li>
			</ul>
			<p>Identifying bottlenecks before they become critical can be done by using k6 to load test the system with spike testing, stress testing, or even testing it <span class="No-Break">to breakpoint.</span></p>
			<p>The DevOps life cycle is very focused on teams who are developing software. It’s common for organizations to use software provided by third parties to provide internal platforms. There is a lot of crossover with the <em class="italic">deploy</em>, <em class="italic">operate</em>, and <em class="italic">monitor</em> phases, but let’s take a more detailed look at using observability with some of <span class="No-Break">these platforms.</span></p>
			<h1 id="_idParaDest-253"><a id="_idTextAnchor265"/>Using Grafana to monitor infrastructure and platforms</h1>
			<p>Teams who work with third-party infrastructure<a id="_idIndexMarker1171"/> and platforms are well supported<a id="_idIndexMarker1172"/> by the tools from Grafana and OpenTelemetry. We’ll consider a few major types of platforms; observability, CI, CD, infrastructure and resource, and finally, security platforms. The <em class="italic">deploy</em>, <em class="italic">operate</em>, <em class="italic">monitor</em>, and <em class="italic">plan</em> phases should all be understood for these platforms and the points made in the previous section for these phases are relevant to these kinds<a id="_idIndexMarker1173"/> of platform<a id="_idIndexMarker1174"/> products. Let’s start by considering <span class="No-Break">observability platforms.</span></p>
			<h2 id="_idParaDest-254"><a id="_idTextAnchor266"/>Observability platforms</h2>
			<p>Teams who manage observability platforms<a id="_idIndexMarker1175"/> have a responsibility to offer a platform that demonstrates best practices by having well-documented SLIs and SLOs, easy-to-find dashboards, and a dependable incident <span class="No-Break">management process.</span></p>
			<p>Helpfully, there are dashboards available through the Grafana Dashboards community portal that provide very detailed views of the OpenTelemetry Collector and the data flows as they pass through the Collector. Deciding what aspects of the Collector are most important to your organization and publishing them is a step that should be taken by any team that manages <span class="No-Break">observability collection.</span></p>
			<p>An important consideration for managing an observability platform is the disaster management process for the loss of the platform. While this scenario is unlikely, it is much better to have a tested plan than to try to come up with one when the platform is on fire – this is advised after a very painful experience. Usually, such a disaster plan can be simple – for instance, the ability to create a Prometheus instance or even a full Grafana stack in each cluster will give organizations<a id="_idIndexMarker1176"/> the capability to continue operating in the event of the <strong class="bold">software-as-a-service</strong> (<strong class="bold">SaaS</strong>) platform they use <span class="No-Break">being down.</span></p>
			<p>A related plan that should exist is how noisy data sources are controlled. Compartmentalization of production data from other sources is a best practice. Sometimes, the financial or capacity cost of a noisy data source could be a business interruption. These risks can be managed in several ways, such as revoking API keys, adding filtering to collectors, or even more extreme measures such as switching off the <span class="No-Break">data source.</span></p>
			<p>Let’s consider CI <span class="No-Break">platforms next.</span></p>
			<h2 id="_idParaDest-255"><a id="_idTextAnchor267"/>CI platforms</h2>
			<p>CI platforms cover a lot of different tools<a id="_idIndexMarker1177"/>, such as Github Actions, GitLab CI/CD, Jenkins, Azure DevOps, Google Cloud Build, and similar. We believe the most common question asked of CI platforms is “<em class="italic">Why did my build fail?</em>”. Giving engineers tools to debug their builds is very important for such a platform. Often, this feedback can be seen in the CI platform itself. However, for some types of failures, it may not be obvious, such as a runner that failed, a noisy neighbor, or some other issue. In these cases, having data collected from the CI platform itself can be <span class="No-Break">very useful.</span></p>
			<p>Due to the nature of the CI platform, data collection <a id="_idIndexMarker1178"/>usually needs to be tailored to <span class="No-Break">the platform:</span></p>
			<ul>
				<li>Platforms provided by cloud vendors would usually be instrumented by collecting the logs and metrics from the platform in the vendor’s own tooling (for example, AWS CloudWatch, GCP Operations Suite, or Azure Monitor) and then sending them on to a Grafana instance <span class="No-Break">if appropriate.</span></li>
				<li>Other platforms will probably need to have an agent installed. We discussed this process in <a href="B18277_13.xhtml#_idTextAnchor239"><span class="No-Break"><em class="italic">Chapter 13</em></span></a>. For reference, the OpenTelemetry Collector is provided via a Docker image, Alpine image (APK), Debian image (<strong class="source-inline">.deb</strong>), Enterprise Linux image (<strong class="source-inline">.rpm</strong>), and as a general image (<strong class="source-inline">.tar.gz</strong>), which includes executables for macOS (Intel and ARM) and Windows. The Grafana Agent is provided as a Docker image, Debian image (<strong class="source-inline">.deb</strong>), Enterprise Linux image (<strong class="source-inline">.rpm</strong>), SUSE image, macOS image (via Homebrew for Intel and ARM), and Windows <span class="No-Break">Installer (</span><span class="No-Break"><strong class="source-inline">.exe</strong></span><span class="No-Break">).</span></li>
			</ul>
			<p>Once an agent is installed, the configuration should be managed to give the best support for the nature of the integration work that is carried out on the platform. We recommend using one of the automation tools discussed in <a href="B18277_10.xhtml#_idTextAnchor204"><span class="No-Break"><em class="italic">Chapter 10</em></span></a> to <span class="No-Break">manage this.</span></p>
			<p>Logs and metrics are the prime data components to capture, as CI platforms do not typically need distributed tracing. One thing to consider as a team adds observability to a CI platform is whether the leadership team wishes to track higher-level business metrics – for example, lead time<a id="_idIndexMarker1179"/> for changes, defect counts, or similar. For those of you who want to look further into these ideas, we recommend looking at Google’s <strong class="bold">DevOps Research and Assessment</strong> (<strong class="bold">DORA</strong>) team reports (<a href="https://cloud.google.com/devops/state-of-devops/">https://cloud.google.com/devops/state-of-devops/</a>). These kinds of considerations would usually need to be agreed<a id="_idIndexMarker1180"/> upon across several teams, so having a clearly documented definition of how they are calculated and collected is vital. This kind of data collection may or may not be done in the observability tooling. It is best practice to separate the data from CI platforms from business-critical workloads. This can easily be achieved by dedicating a separate Grafana stack for CI workloads. There are publicly available dashboards for these systems <span class="No-Break">as well.</span></p>
			<p>Now that we’ve seen how to monitor a CI platform, let’s consider the <span class="No-Break">deployment platform.</span></p>
			<h2 id="_idParaDest-256"><a id="_idTextAnchor268"/>CD platforms</h2>
			<p>CD platforms often have crossover<a id="_idIndexMarker1181"/> with CI platforms; we’re considering them separate as they are different aspects of the overall system. These platforms use tools such as Jenkins, GitLab CI/CD, AWS CodeDeploy, ArgoCD, FluxCD, and similar. For infrastructure<a id="_idIndexMarker1182"/> deployment, they may also include tools such as Terraform <a id="_idIndexMarker1183"/>Cloud, Atlantis, or Spacelift. There are two main groups of CD tools: <strong class="bold">push systems</strong> and <strong class="bold">pull systems</strong>. We’ll discuss them separately in this way as the data collection processes differ. With either deployment method, a very important aspect of integrating with Grafana well is to record an annotation in Grafana. We discussed this in more detail when we talked about the <em class="italic">deploy</em> phase of the DevOps life cycle, but this contextual information can save huge amounts of time during troubleshooting, and ultimately, provide a better <span class="No-Break">customer experience.</span></p>
			<p>Pull systems in Kubernetes<a id="_idIndexMarker1184"/> also use the term <em class="italic">GitOps</em>; such systems typically use tools such as <strong class="bold">ArgoCD</strong> or <strong class="bold">FluxCD</strong>. As these tools are deployed into an existing Kubernetes cluster, the observability<a id="_idIndexMarker1185"/> stance is very simple, in that the service will have data collected by the existing collection infrastructure in the cluster. ArgoCD provides metrics in Prometheus format, and there are several dashboards publicly available. It’s also possible to extend the data collection via other tools in the Argo group of tools. FluxCD provides Prometheus metrics that can be extended with kube-state-metrics as well. The tool also provides logs and produces Kubernetes events<a id="_idIndexMarker1186"/> as well. There are other<a id="_idIndexMarker1187"/> pull systems outside of Kubernetes, such as <strong class="bold">Chef</strong> and <strong class="bold">ansible-pull</strong>, but due to the low prevalence of these tools, we’ll not discuss <span class="No-Break">them here.</span></p>
			<p>Push-based CD platforms have one or more central systems that connect to the deployment target and run the deployment process. Jenkins is perhaps the classic example here, but systems such as GitHub Actions and GitLab CI/CD also fall into this category. You may notice that these tools were also mentioned previously when we considered the CI platform. Unsurprisingly, these tools are monitored in the same way, whether they are used for integration tasks or delivery/deployment tasks. When the use of these tools has a mix of integration and delivery/deployment tasks, monitoring the actions of the platform is very important from a security perspective as these systems will often consume third-party libraries during the integration phase, which opens the system to supply chain attacks. Combining such an attack with high-level access to production on a single system is a very real threat <span class="No-Break">to organizations.</span></p>
			<p>We’ve now considered how to monitor<a id="_idIndexMarker1188"/> the platforms that build and deploy software. Let’s consider a wider group of systems next. We’ll consider data storage and message queue systems in this <span class="No-Break">next section.</span></p>
			<h2 id="_idParaDest-257"><a id="_idTextAnchor269"/>Resource platforms</h2>
			<p>We’re using the term <em class="italic">resource platform</em> to describe the types of backend <a id="_idIndexMarker1189"/>systems that an application may depend on. These might include databases, in-memory data stores, message buses, web servers, or similar. These platforms are an odd case, as the responsibility for the system can reside in many different areas of the organization. Commonly, either a software delivery team would be responsible, or sometimes a centralized team would be responsible. We will attempt to ignore this complexity by talking in general terms about how to ensure these tools <span class="No-Break">are observable.</span></p>
			<p>There are a few places to start looking at monitoring <span class="No-Break">these systems:</span></p>
			<ul>
				<li><strong class="bold">OpenTelemetry Collector contributed receivers</strong>: There are contributed receiver modules for a vast array<a id="_idIndexMarker1190"/> of resource platforms. Deploying these receivers is <span class="No-Break">very simple:</span><ul><li>In Kubernetes, the collector can be deployed as a sidecar to the service, or as a dedicated agent in the cluster or namespace that forwards telemetry on to a gateway. An example of a dedicated agent is shown in <em class="italic">Figure 11.5</em> in <a href="B18277_11.xhtml#_idTextAnchor218"><em class="italic">Chapter 11</em></a> where the agent is used to collect metrics from the <span class="No-Break">Kubernetes cluster.</span></li><li>In a virtual or bare metal installation, a dedicated OpenTelemetry Collector needs to be deployed, although this can often be done on the instance being monitored with no <span class="No-Break">performance degradation.</span></li></ul></li>
				<li><strong class="bold">Prometheus modules</strong>: These are modules that allow Prometheus<a id="_idIndexMarker1191"/> to scrape data from a lot of resource platforms. These can simply be deployed to a Prometheus instance and configured to connect to the platform that needs<a id="_idIndexMarker1192"/> to <span class="No-Break">be monitored.</span></li>
			</ul>
			<p>Once metrics are collected from these systems, Grafana offers a wide range of prebuilt public dashboards for them. The wide availability of these dashboards means the time to value is <span class="No-Break">very good.</span></p>
			<p>One thing to highlight to prevent confusion with these systems is that this type of data collection is not the same as using the system as a data source in Grafana. A lot of these systems, especially databases such as MySQL, PostgreSQL, and MongoDB, can be used as a Grafana data source. A data source connects to the system and allows users to query the data in the system. The tools we are discussing here connect to the system and query operational metrics from it. These metrics<a id="_idIndexMarker1193"/> can then be used to provide SLOs and transparency of the operation of the system to <span class="No-Break">other teams.</span></p>
			<h2 id="_idParaDest-258"><a id="_idTextAnchor270"/>Security platforms</h2>
			<p>We will not delve too deeply into <strong class="bold">security platforms</strong> as they could fill an entire book on their own. However, it’s worth<a id="_idIndexMarker1194"/> noting that several tools, such as <strong class="bold">Falco</strong>, <strong class="bold">Open Policy Agent</strong>, <strong class="bold">kube-bench</strong>, <strong class="bold">Trivy,</strong> and others, have methods of exposing metrics related to their operation, which can be consumed by Grafana in <span class="No-Break">some way.</span></p>
			<p>There is also a very big crossover of concerns of observability platforms with cyber security platforms. Both platforms consume log data, which can lead to the running of multiple agents to collect this data. A more cost-effective solution could be for these teams to work together on a shared pipeline of this data that supports both teams’ operations. Such a pipeline should be monitored closely as it could present a significant risk to <span class="No-Break">the organization.</span></p>
			<p>We’ve now considered using Grafana both in the software application life cycle and for the management of infrastructure <span class="No-Break">and platforms.</span></p>
			<h1 id="_idParaDest-259"><a id="_idTextAnchor271"/>Summary</h1>
			<p>In this chapter, we have considered how you can use Grafana through the DevOps life cycle. You learned about deploying Grafana in a local environment to speed up development time by getting instant feedback on the performance of the code. We looked at the testing phase, and you learned how using tools such as k6 can provide great repeatable tests that can even be used as an application is deployed. During the release phase, Grafana can be used to demonstrate various aspects of an application to the stakeholders who approve your releases. We saw how deployments can have their risks reduced by leveraging SLOs and black box monitoring. We also saw how using Grafana annotations can improve the visibility of deployments occurring. The <em class="italic">operate</em> and <em class="italic">monitor</em> phases use Grafana in very similar ways, which have been covered in this book. You were introduced to the difference in the aim of these two phases, with the <em class="italic">operate</em> phase being concerned with the correct functioning and the <em class="italic">monitor</em> phase being concerned with how to improve the customer experience. Finally, we talked about how Grafana can be used to have a data-driven discussion during the planning phase of a <span class="No-Break">software tool.</span></p>
			<p>We then considered how Grafana can also be used with various types of platforms. We introduced you to using Grafana to monitor your observability platform, effectively demonstrating the principle of using your own product or “<em class="italic">eating your own dog food</em>,” and acting as an example of best practice to an organization. You saw how to use Grafana with your CI/CD platforms, so engineers in an organization have a lot of data to understand how their builds and deployments are working. We then discussed how to get operational data from many systems used across the industry, such as databases, in-memory data stores, message buses, and web servers. You learned that the best approach is to look for available data collection tooling and publicly available dashboards. The final kind of platform we looked at was a security platform, where you saw that some tools also surface data in Prometheus or OpenTelemetry format, which can be consumed by Grafana. Where this is available, prebuilt Grafana dashboards are also available, which significantly reduces the time to value for using <span class="No-Break">these tools.</span></p>
			<p>We have nearly reached the end of the book. The next chapter will cover best practices and troubleshooting techniques. You will look at some specific items around data collection and the Grafana stack as well as general guidance on common pitfalls in observability. We will also discuss interesting <span class="No-Break">future trends.</span></p>
		</div>
	</body></html>