- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Setting Up MetalLB and Ingress for Load Balancing
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 设置 MetalLB 和 Ingress 进行负载均衡
- en: In the last chapter, we have looked at how Kubernetes network model works and
    learned how to use Calico, Cilium, and Flannel CNI plugins to network the cluster.
    We've also gone through some of the most important factors to consider when choosing
    a CNI provider.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一章中，我们已经了解了 Kubernetes 网络模型是如何工作的，并学会了如何使用 Calico、Cilium 和 Flannel CNI 插件来对集群进行网络配置。我们还讨论了选择
    CNI 提供商时需要考虑的一些最重要的因素。
- en: We should revisit the Kubernetes Service abstraction mechanism from the first
    chapter before diving into **MetalLB** load-balancer and Ingress concepts for
    load balancing. Kubernetes **Services**, in simple terms, connect a group of Pods
    to an abstracted Service name and IP address. Discovery and routing between Pods
    are provided by the Services. Services, for example, connect an application's
    frontend to its backend, which are both deployed in different cluster deployments.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨 **MetalLB** 负载均衡器和 Ingress 的负载均衡概念之前，我们应该回顾一下第一章中关于 Kubernetes 服务抽象机制的内容。简单来说，Kubernetes
    **服务**将一组 Pod 与抽象的服务名称和 IP 地址连接起来。服务提供了 Pod 之间的发现和路由。例如，服务将一个应用程序的前端连接到其后端，这些组件都部署在不同的集群部署中。
- en: 'The most common types of Services are listed here:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 这里列出了最常见的服务类型：
- en: '**ClusterIP**: This is the default type, which exposes the Service via the
    cluster''s internal IP address. These Services are only accessible within the
    cluster.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**ClusterIP**：这是默认类型，通过集群的内部 IP 地址暴露服务。这些服务仅在集群内部可访问。'
- en: '`NordPort` service, a `ClusterIP` Service is automatically created.'
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`NordPort` 服务，一个 `ClusterIP` 服务会自动创建。'
- en: '`LoadBalancer` type of service will create a load balancer and expose the Service
    externally. It will also automatically create `ClusterIP` and `NodePort` Services
    and route traffic accordingly.'
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`LoadBalancer` 类型的服务将创建一个负载均衡器并将服务暴露到外部。它还会自动创建 `ClusterIP` 和 `NodePort` 服务，并相应地路由流量。'
- en: '`externalName ex.sampleapp.test.com` field by returning a value for the **Canonical
    Name** (**CNAME**) record.'
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过返回 **规范名称**（**CNAME**）记录的值来配置 `externalName ex.sampleapp.test.com` 字段。
- en: 'The most common types of Services are depicted in the following diagram:'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的服务类型如下面的图示所示：
- en: '![Figure 7.1 – Common types of Services ](img/Figure_7.01_B18115.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.1 – 常见的服务类型](img/Figure_7.01_B18115.jpg)'
- en: Figure 7.1 – Common types of Services
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – 常见的服务类型
- en: 'Let''s get into the intricacies of MetalLB and Ingress configuration now that
    we''ve covered the basics. In this chapter, we''re going to cover the following
    main topics:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经覆盖了基础知识，接下来让我们深入探讨 MetalLB 和 Ingress 配置。在本章中，我们将涵盖以下主要主题：
- en: Overview of MetalLB and Ingress
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MetalLB 和 Ingress 概述
- en: Configuring MetalLB to load balance across the cluster
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置 MetalLB 在集群中进行负载均衡
- en: Configuring Ingress to expose Services outside the cluster
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 配置 Ingress 以将服务暴露到集群外部
- en: Guidelines on choosing the right load balancer for your applications
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 选择合适的负载均衡器以服务于你的应用程序的指南
- en: Overview of MetalLB and Ingress
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: MetalLB 和 Ingress 概述
- en: Despite its widespread adoption, Kubernetes does not offer a load balancer implementation.
    If your Kubernetes cluster is running on a cloud platform such as Azure, `Pending`
    status indefinitely.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Kubernetes 被广泛采用，但它并没有提供负载均衡器的实现。如果你的 Kubernetes 集群运行在云平台（如 Azure）上，`Pending`
    状态将无限期持续。
- en: The `NodePort` and `externalIPs` Services are the only options for bringing
    user traffic into bare-metal clusters. Both strategies have considerable drawbacks
    when it comes to output. MetalLB solves this problem by providing an implementation
    of a network load balancer that connects with conventional network equipment,
    allowing external Services on bare-metal clusters.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '`NodePort` 和 `externalIPs` 服务是将用户流量引入裸金属集群的唯一选项。这两种策略在输出方面都有相当大的缺陷。MetalLB
    通过提供一个网络负载均衡器的实现来解决这个问题，该负载均衡器与传统的网络设备连接，从而允许裸金属集群上的外部服务。'
- en: 'In a nutshell, MetalLB enables you to establish `LoadBalancer` Kubernetes Services
    in clusters that aren''t hosted on a cloud provider. Address allocation and external
    announcement are two characteristics that work together to deliver this Service.
    We will now see these in more detail, as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 简而言之，MetalLB 使你能够在没有云服务提供商的集群中建立 `LoadBalancer` Kubernetes 服务。地址分配和外部公告是共同作用来提供此服务的两个特点。接下来我们将详细了解这些内容，具体如下：
- en: '**Address allocation**: MetalLB cannot generate IP addresses on its own; instead,
    we must provide it with IP address pools from which it can draw. As Services come
    and go, MetalLB will take care of assigning and unassigning individual addresses,
    but it will only ever distribute IPs that are part of its preset pools. Setting
    up IP address pools is based on the environment we have; for example, if you''re
    running a bare-metal cluster in a colocation facility, your hosting provider may
    provide IP addresses for lease, or if you''re running on a private **local area
    network** (**LAN**), you could choose a range of IPs from one of the private addresses
    spaces.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**地址分配**：MetalLB 无法自行生成 IP 地址；相反，我们必须提供 IP 地址池供其选择。当 Services 创建和删除时，MetalLB
    会负责分配和取消分配个别地址，但它只会分发预设池中的 IP 地址。设置 IP 地址池的方式取决于我们的环境；例如，如果你在一个共置设施中运行裸金属集群，你的托管服务提供商可能会提供
    IP 地址供租用，或者如果你在一个私有**局域网**（**LAN**）中运行，你可以选择来自某个私有地址空间的 IP 地址范围。'
- en: '**External announcement**: After assigning an external IP address to a Service,
    MetalLB must notify the network outside the cluster that the IP address is residing
    in the cluster. MetalLB accomplishes this using conventional routing protocols
    such as **Address Resolution Protocol** (**ARP**), **Neighbor Discovery Protocol**
    (**NDP**), or **Border Gateway Protocol** (**BGP**). In a **Layer 2** (**L2**)
    mode such as ARP/NDP, one node in the cluster takes ownership of the Service and
    makes those IPs visible on the local network using standard address discovery
    protocols (ARP for IPv4; NDP for IPv6); whereas in the BGP mode, all nodes in
    the cluster create BGP peering sessions with adjacent routers that you control
    in BGP mode and inform those routers how to forward traffic to the Service IPs.
    BGP''s policy mechanisms enable genuine load balancing across several nodes as
    well as fine-grained traffic control.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部公告**：在为 Service 分配外部 IP 地址后，MetalLB 必须通知集群外部网络该 IP 地址已驻留在集群中。MetalLB 使用传统的路由协议来实现这一点，如**地址解析协议**（**ARP**）、**邻居发现协议**（**NDP**）或**边界网关协议**（**BGP**）。在**第二层**（**L2**）模式下，如
    ARP/NDP，集群中的一个节点会接管该 Service，并使用标准的地址发现协议（IPv4 的 ARP；IPv6 的 NDP）使这些 IP 在本地网络中可见；而在
    BGP 模式下，集群中的所有节点都会与你控制的相邻路由器创建 BGP 对等会话，并告知这些路由器如何将流量转发到 Service IP。BGP 的策略机制使得在多个节点之间实现真正的负载均衡，并提供精细化的流量控制。'
- en: Another option is to utilize **Ingress** (Kubernetes object) to expose your
    Service. Although it acts as the cluster's entrance point, Ingress is not a Service
    type.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是使用**Ingress**（Kubernetes 对象）来暴露你的 Service。尽管它充当集群的入口点，但 Ingress 并不是一种
    Service 类型。
- en: 'The workings of Ingress are depicted in the following diagram:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress 的工作原理如下图所示：
- en: '![Figure 7.2 – Workings of Ingress ](img/Figure_7.02_B18115.jpg)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.2 – Ingress 的工作原理](img/Figure_7.02_B18115.jpg)'
- en: Figure 7.2 – Workings of Ingress
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – Ingress 的工作原理
- en: The Ingress controller aids in the consolidation of various applications' routing
    rules into a single entity. With the help of `NodePort` or `LoadBalancer`, the
    Ingress controller is exposed to the outside world. It's more suited for internal
    load balancing of `nginx` or `HAProxy`. For `LoadBalancer` kind of service, and
    MetalLB comes to our rescue in such situations.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: Ingress 控制器帮助将不同应用程序的路由规则整合成一个实体。在 `NodePort` 或 `LoadBalancer` 的帮助下，Ingress
    控制器暴露给外部世界。它更适合 `nginx` 或 `HAProxy` 的内部负载均衡。对于 `LoadBalancer` 类型的服务，MetalLB 在这种情况下为我们提供了帮助。
- en: In the next section, we'll go over how to set up MetalLB as a load balancer
    for your cluster.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将讨论如何将 MetalLB 设置为集群的负载均衡器。
- en: Configuring MetalLB to load balance across the cluster
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置 MetalLB 以实现集群负载均衡
- en: 'Now that we are clear on MetalLB concepts, we will dive into the steps of configuring
    MetalLB to load balance across the cluster. The following diagram depicts our
    Raspberry Pi cluster setup:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经明确了 MetalLB 的概念，接下来我们将深入探讨如何配置 MetalLB 实现集群的负载均衡。下图展示了我们的 Raspberry Pi
    集群设置：
- en: '![Figure 7.3 – MicroK8s Raspberry Pi cluster ](img/Figure_7.03_B18115.jpg)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3 – MicroK8s Raspberry Pi 集群](img/Figure_7.03_B18115.jpg)'
- en: Figure 7.3 – MicroK8s Raspberry Pi cluster
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3 – MicroK8s Raspberry Pi 集群
- en: Now that we know what we want to do, let's look at the requirements.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了我们要做什么，接下来让我们看看要求。
- en: Requirements
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 要求
- en: 'Before you begin, here are the prerequisites that are needed for building a
    Raspberry Pi Kubernetes cluster and for the configuration of a MetalLB load balancer:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，以下是构建 Raspberry Pi Kubernetes 集群和配置 MetalLB 负载均衡器所需的先决条件：
- en: A microSD card (4 **gigabytes** (**GB**) minimum; 8 GB recommended)
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一张 microSD 卡（最小容量为 **4 GB**（**GB**），推荐使用 8 GB）
- en: A computer with a microSD card drive
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台带有 microSD 卡读卡器的计算机
- en: A Raspberry Pi 2, 3, or 4 (one or more)
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Raspberry Pi 2、3 或 4（一个或多个）
- en: A micro-USB power cable (USB-C for the Pi 4)
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一根 micro-USB 电源线（Pi 4 使用 USB-C）
- en: A Wi-Fi network or an Ethernet cable with an internet connection
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Wi-Fi 网络或带有互联网连接的以太网电缆
- en: (Optional) A monitor with a **High-Definition Multimedia Interface** (**HDMI**)
    interface
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （可选）带有 **High-Definition Multimedia Interface**（**HDMI**）接口的显示器
- en: (Optional) An HDMI cable for the Pi 2 and 3 and a micro-HDMI cable for the Pi
    4
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （可选）适用于 Pi 2 和 3 的 HDMI 线缆以及适用于 Pi 4 的 micro-HDMI 线缆
- en: (Optional) A **Universal Serial Bus** (**USB**) keyboard
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: （可选）一个 **Universal Serial Bus**（**USB**）键盘
- en: Now that we've established what the requirements are, we'll go on to the step-by-step
    instructions on how to complete the process.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经确定了所需的要求，接下来我们将逐步介绍如何完成此过程的说明。
- en: Step 1 – Creating a MicroK8s Raspberry Pi cluster
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 1 – 创建 MicroK8s Raspberry Pi 集群
- en: 'Please follow the steps that we covered in [*Chapter 5*](B18115_05.xhtml#_idTextAnchor070),
    *Creating and Implementing Updates on Multi-Node Raspberry Pi Kubernetes Clusters*,
    to create a MicroK8s Raspberry Pi cluster. Here''s a quick refresher:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 请按照我们在 [*第 5 章*](B18115_05.xhtml#_idTextAnchor070) 中介绍的步骤，*在多节点 Raspberry Pi
    Kubernetes 集群上创建和实施更新*，创建 MicroK8s Raspberry Pi 集群。以下是一个快速复习：
- en: 'Installing the **operating system** (**OS**) image to a **Secure Digital**
    (**SD**) card:'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 **操作系统**（**OS**）镜像安装到 **Secure Digital**（**SD**）卡：
- en: Configuring Wi-Fi access settings
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置 Wi-Fi 访问设置
- en: Configuring remote access settings
  id: totrans-49
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置远程访问设置
- en: Configuring control group settings
  id: totrans-50
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置控制组设置
- en: Configuring hostname
  id: totrans-51
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置主机名
- en: Installing and configuring MicroK8s
  id: totrans-52
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装和配置 MicroK8s
- en: Adding a worker node
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加工作节点
- en: 'A fully functional multi-node Kubernetes cluster should look like the one shown
    in the following screenshot. To summarize, we have installed MicroK8s on the Raspberry
    Pi boards and joined multiple deployments to form a cluster. We have also added
    nodes to the cluster:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 完全功能的多节点 Kubernetes 集群应如下截图所示。总结一下，我们已在 Raspberry Pi 板上安装了 MicroK8s，并加入了多个部署以形成集群。我们还向集群添加了节点：
- en: '![Figure 7.4 – Fully functional MicroK8s Raspberry Pi cluster ](img/Figure_5.22_B18115.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.4 – 完全功能的 MicroK8s Raspberry Pi 集群 ](img/Figure_5.22_B18115.jpg)'
- en: Figure 7.4 – Fully functional MicroK8s Raspberry Pi cluster
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4 – 完全功能的 MicroK8s Raspberry Pi 集群
- en: We can now go to the next step of enabling the MetalLB add-on, as we have a
    fully functional cluster.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以进入下一步，启用 MetalLB 插件，因为我们已经拥有了一个完全功能的集群。
- en: Step 2 – Enabling the MetalLB add-on
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 步骤 2 – 启用 MetalLB 插件
- en: MicroK8s supports a variety of add ons ([https://microk8s.io/docs/addons](https://microk8s.io/docs/addons))
    which are pre-packaged components that provide additional capabilities for your
    Kubernetes cluster.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: MicroK8s 支持各种插件 ([https://microk8s.io/docs/addons](https://microk8s.io/docs/addons))，这些是预打包的组件，为您的
    Kubernetes 集群提供额外的功能。
- en: 'These are easy to set up with the following command:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令轻松设置：
- en: '[PRE0]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Use the following command to enable the MetalLB load balancer:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令启用 MetalLB 负载均衡器：
- en: '[PRE1]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'The following command execution output indicates the MetalLB add-on has been
    enabled successfully:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的命令执行输出表示 MetalLB 插件已成功启用：
- en: '![Figure 7.5 – Enabling MetalLB add-on ](img/Figure_7.05_B18115.jpg)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.5 – 启用 MetalLB 插件 ](img/Figure_7.05_B18115.jpg)'
- en: Figure 7.5 – Enabling MetalLB add-on
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5 – 启用 MetalLB 插件
- en: 'We''ve instructed MetalLB to give out addresses in the `192.168.1.10` - `192.168.1.15`
    range with this command. To check a list of available and installed add-ons, use
    the `status` command, as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已指示 MetalLB 使用以下命令在 `192.168.1.10` - `192.168.1.15` 范围内分配地址。要检查可用和已安装的插件列表，请使用
    `status` 命令，如下所示：
- en: '[PRE2]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: 'Alternatively, you can use `192.168.2.1/24` subnet, and I opted to give MetalLB
    half of the IPs. IP numbers `192.168.2.1` to `192.168.2.126` make up the first
    part of the subnet. A /25 subnet can be used to represent this range: `192.168.2.1`/`25`.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，您可以使用 `192.168.2.1/24` 子网，并选择为 MetalLB 分配一半的 IP 地址。IP 数字 `192.168.2.1` 到
    `192.168.2.126` 组成了子网的第一部分。可以使用 /25 子网来表示这个范围：`192.168.2.1`/`25`。
- en: A /25 subnet can also be used to represent the second half of the network—for
    example, `192.168.2.128`/`25`. Each half has 126 IP addresses.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 /25 子网也可以用来表示网络的第二部分，例如，`192.168.2.128`/`25`。每半部分有 126 个 IP 地址。
- en: Make sure you choose subnets that are appropriate for your network and that
    your router and MetalLB are configured correctly.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 确保选择适合您网络的子网，并正确配置您的路由器和 MetalLB。
- en: 'The following command execution output indicates (refer to the highlighted
    portions) that the MetalLB add-on has been enabled:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出表明（请参阅高亮部分）MetalLB 插件已启用：
- en: '![Figure 7.6 – MicroK8s status ](img/Figure_7.06_B18115.jpg)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.6 – MicroK8s 状态](img/Figure_7.06_B18115.jpg)'
- en: Figure 7.6 – MicroK8s status
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6 – MicroK8s 状态
- en: 'For its components, MetalLB uses the `metallb-system` namespace. To verify
    all components are running, use the following command:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于其组件，MetalLB 使用 `metallb-system` 命名空间。要验证所有组件是否正在运行，请使用以下命令：
- en: '[PRE3]'
  id: totrans-77
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The following command execution output indicates that all components are in
    a `Running` state:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出表明所有组件处于 `Running` 状态：
- en: '![ Figure 7.7 – Components of MetalLB and their status ](img/Figure_7.07_B18115.jpg)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.7 – MetalLB 组件及其状态](img/Figure_7.07_B18115.jpg)'
- en: Figure 7.7 – Components of MetalLB and their status
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7 – MetalLB 组件及其状态
- en: 'The components that you can see in the preceding command execution output of
    MetalLB are outlined in more detail here:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在前述 MetalLB 命令执行输出中看到的组件将在此进行更详细的说明：
- en: '`metallb-system/controller` (deployment): This is the IP address assignment
    controller for the entire cluster.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metallb-system/controller`（部署）：这是整个集群的 IP 地址分配控制器。'
- en: '`metallb-system/speaker` (DaemonSet): This component communicates with Services
    using the protocol(s) of your choice.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metallb-system/speaker`（DaemonSet）：该组件使用您选择的协议与服务进行通信。'
- en: Now that we've activated the MetalLB add-on, the next step is to launch an example
    application and see whether it can load balance.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经激活了 MetalLB 插件，下一步是启动一个示例应用程序，查看它是否能够进行负载均衡。
- en: 'Add-ons that have been enabled can be disabled at any time by utilizing the
    `disable` command, as follows:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 已启用的插件可以随时通过使用 `disable` 命令禁用，如下所示：
- en: '[PRE4]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: At this point, you have a fully functional multi-node Kubernetes cluster with
    the MetalLB add-on enabled.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 此时，您已经拥有了一个完全功能的多节点 Kubernetes 集群，并启用了 MetalLB 插件。
- en: Note
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: Between nodes, port `7946` (TCP and UDP) must be permitted. Additionally, ensure
    that no other software is running on port `7946` on the nodes before installing
    MetalLB.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 节点之间，端口 `7946`（TCP 和 UDP）必须被允许。此外，在安装 MetalLB 之前，请确保没有其他软件在节点上的端口 `7946` 上运行。
- en: Step 3 – Deploying a sample containerized application
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第三步 – 部署示例容器化应用程序
- en: 'In this step, we will be deploying the following Apache web server deployment
    on our multi-node MicroJ8s cluster setup, as follows:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 在此步骤中，我们将会在多节点 MicroJ8s 集群设置中部署以下 Apache web 服务器，如下所示：
- en: '[PRE5]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Before we deploy the web server, let''s verify the cluster nodes are ready
    by using the following command:'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们部署 web 服务器之前，先使用以下命令验证集群节点是否已准备就绪：
- en: '[PRE6]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The following command execution output shows that all the nodes are in a `Ready`
    state. We are now ready to start:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出显示所有节点处于 `Ready` 状态。现在我们已准备好开始：
- en: '![Figure 7.8 – Checking whether nodes are in a Ready state ](img/Figure_7.08_B18115.jpg)'
  id: totrans-96
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.8 – 检查节点是否处于 Ready 状态](img/Figure_7.08_B18115.jpg)'
- en: Figure 7.8 – Checking whether nodes are in a Ready state
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.8 – 检查节点是否处于 Ready 状态
- en: 'The following command will deploy the web server application:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将部署 web 服务器应用程序：
- en: '[PRE7]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The following command execution output indicates that there is no error in
    the deployment, and in the next steps, we can verify the same using the `get deployments`
    command:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出表明部署没有错误，在接下来的步骤中，我们可以使用 `get deployments` 命令验证相同内容：
- en: '![Figure 7.9 – Deploying the web server ](img/Figure_7.09_B18115.jpg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.9 – 部署 web 服务器](img/Figure_7.09_B18115.jpg)'
- en: Figure 7.9 – Deploying the web server
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9 – 部署 web 服务器
- en: 'Check the status of the deployment to verify the application has been deployed
    and is running by using the following command:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令检查部署状态，以验证应用程序已成功部署并正在运行：
- en: '[PRE8]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The following command execution output confirms that the deployment is `Ready`:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出确认部署已 `Ready`：
- en: '![Figure 7.10 – Confirming that the deployment is ready ](img/Figure_7.10_B18115.jpg)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.10 – 确认部署已就绪](img/Figure_7.10_B18115.jpg)'
- en: Figure 7.10 – Confirming that the deployment is ready
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10 – 确认部署已就绪
- en: Now that we have the sample web server application ready, we can test the load-balancing
    mechanism in the next part.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已准备好示例 web 服务器应用程序，接下来可以测试负载均衡机制。
- en: Step 4 – Verifying the load balancer mechanism
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第四步 – 验证负载均衡机制
- en: To summarize, we've deployed a sample web server application. We'll now test
    the load-balancer mechanism in this section.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，我们已部署了一个示例 web 服务器应用程序。接下来我们将在本部分测试负载均衡机制。
- en: 'Use the following command to see whether your load balancer has been allocated
    an external IP and port:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令查看负载均衡器是否已分配外部 IP 和端口：
- en: '[PRE9]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The following command execution output (refer to the highlighted portions)
    shows that an external IP and port have been allocated:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出（参见高亮部分）显示外部 IP 和端口已分配：
- en: '![Figure 7.11 – Checking whether external IP and port have been allocated ](img/Figure_7.11_B18115.jpg)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.11 – 检查是否已分配外部 IP 和端口](img/Figure_7.11_B18115.jpg)'
- en: Figure 7.11 – Checking whether external IP and port have been allocated
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11 – 检查是否已分配外部 IP 和端口
- en: 'Now that an external IP has been allocated, we can access the application using
    the external IP address from any of the nodes or from the external network, as
    follows:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 现在已经分配了外部 IP，我们可以使用任意节点的外部 IP 地址或外部网络访问应用程序，如下所示：
- en: '[PRE10]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'If you have followed the preceding steps, you should be able to see the `<html><body><h1>It
    works!</h1></body></html>` Apache web server output, as in the following command
    execution output:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经按照前面的步骤操作，你应该能够看到 `<html><body><h1>It works!</h1></body></html>` Apache
    web 服务器输出，如以下命令执行输出所示：
- en: '![Figure 7.12 – Apache web server output ](img/Figure_7.12_B18115.jpg)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.12 – Apache web 服务器输出](img/Figure_7.12_B18115.jpg)'
- en: Figure 7.12 – Apache web server output
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12 – Apache web 服务器输出
- en: 'Let''s scale the deployment to see whether our load balancer is still working
    properly. To do so, run the `kubectl scale` command, as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们扩展部署，看看负载均衡器是否仍然正常工作。为此，请运行 `kubectl scale` 命令，如下所示：
- en: '[PRE11]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'The following command execution output confirms that there is no error in the
    deployment, and in the next steps, we can verify that the deployment has five
    Pods:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出确认部署没有错误，接下来的步骤中，我们可以验证部署中有五个 Pods：
- en: '![Figure 7.13 – Scaling the deployment ](img/Figure_7.13_B18115.jpg)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.13 – 扩展部署](img/Figure_7.13_B18115.jpg)'
- en: Figure 7.13 – Scaling the deployment
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13 – 扩展部署
- en: 'Use the following command to check the status of the deployment:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令检查部署状态：
- en: '[PRE12]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The following command output shows that the command was successfully run, and
    the deployment has been updated:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令输出显示命令已成功执行，且部署已更新：
- en: '![Figure 7.14 – Checking deployment state ](img/Figure_7.14_B18115.jpg)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.14 – 检查部署状态](img/Figure_7.14_B18115.jpg)'
- en: Figure 7.14 – Checking deployment state
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14 – 检查部署状态
- en: 'Now that the deployment has been updated, let''s check how the Pods are distributed
    across the nodes, using the following command:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 部署已更新后，让我们使用以下命令检查 Pods 如何在节点间分布：
- en: '[PRE13]'
  id: totrans-132
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The following command execution output indicates that three Pods are running
    on the `master` node, and two of them are running on `worker1`:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出显示，三个 Pods 正在 `master` 节点上运行，其中两个在 `worker1` 上运行：
- en: '![Figure 7.15 – How Pods are distributed across the nodes ](img/Figure_7.15_B18115.jpg)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.15 – Pods 如何在节点间分布](img/Figure_7.15_B18115.jpg)'
- en: Figure 7.15 – How Pods are distributed across the nodes
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.15 – Pods 如何在节点间分布
- en: 'Let''s check whether there is any change in the external IP and ports using
    the following command:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用以下命令检查外部 IP 和端口是否有任何变化：
- en: '[PRE14]'
  id: totrans-137
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'The following command execution output shows that there is no change in the
    allocated external IP and port:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出显示分配的外部 IP 和端口没有变化：
- en: '![Figure 7.17 – Apache web server output ](img/Figure_7.16_B18115.jpg)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.17 – Apache web 服务器输出](img/Figure_7.16_B18115.jpg)'
- en: Figure 7.16 – Rechecking for any change in external IP and port
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.16 – 重新检查外部 IP 和端口是否有变化
- en: 'Let''s use the same `curl` command to access the application and verify it''s
    working, as follows:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们使用相同的`curl`命令访问应用程序并验证其是否正常工作，如下所示：
- en: '![](img/Figure_7.17_B18115.jpg)'
  id: totrans-142
  prefs: []
  type: TYPE_IMG
  zh: '![](img/Figure_7.17_B18115.jpg)'
- en: Figure 7.17 – Apache web server output
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.17 – Apache web 服务器输出
- en: The command execution output confirms that the load balancer is working properly.
    Even though the Pods are spread throughout the nodes, our web server application
    is able to effectively serve user requests.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 命令执行输出确认负载均衡器正常工作。即使 Pods 分布在各个节点上，我们的 web 服务器应用程序仍然能够有效地处理用户请求。
- en: 'The following diagram depicts the MetalLB load-balancing functionality. MetalLB
    implements the `LoadBalancer` Kubernetes Service. When a `LoadBalancer` Service
    is requested externally, MetalLB assigns an IP address from the preset range to
    the client and informs the network that the IP is residing in the cluster:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了MetalLB的负载均衡功能。MetalLB实现了`LoadBalancer` Kubernetes服务。当外部请求`LoadBalancer`服务时，MetalLB会从预设范围内为客户端分配一个IP地址，并通知网络该IP地址在集群内：
- en: '![Figure 7.18 – MetalLB load-balancing functionality ](img/Figure_7.18_B18115.jpg)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.18 – MetalLB 负载均衡功能](img/Figure_7.18_B18115.jpg)'
- en: Figure 7.18 – MetalLB load-balancing functionality
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.18 – MetalLB 负载均衡功能
- en: 'MetalLB is configured in L2 mode by default in MicroK8s. The following command
    can be used to confirm this:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，MetalLB在MicroK8s中配置为L2模式。可以使用以下命令确认这一点：
- en: '[PRE15]'
  id: totrans-149
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'The following command execution output confirms that MetalLB is in L2 mode,
    and we can see the IP range as well:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出确认了MetalLB处于L2模式，并且我们还可以看到IP范围：
- en: '![Figure 7.19 – MetalLB ConfigMap ](img/Figure_7.19_B18115.jpg)'
  id: totrans-151
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.19 – MetalLB ConfigMap](img/Figure_7.19_B18115.jpg)'
- en: Figure 7.19 – MetalLB ConfigMap
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.19 – MetalLB ConfigMap
- en: To set the MetalLB in BGP mode, `ConfigMap config` needs to be reconfigured
    to set the operation mode as `BGP` and the external IP address range.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 要将MetalLB设置为BGP模式，需要重新配置`ConfigMap config`，将操作模式设置为`BGP`并配置外部IP地址范围。
- en: The speakers in BGP mode create a BGP peering with routers outside of the cluster
    and instruct those routers on how to redirect traffic to the Service IPs. BGP's
    policy mechanisms enable genuine load balancing across several nodes, as well
    as fine-grained traffic control.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在BGP模式下，speakers会与集群外的路由器建立BGP对等连接，并指示这些路由器如何将流量重定向到服务IP。BGP的策略机制使得跨多个节点实现真正的负载均衡，并且能够进行精细化的流量控制。
- en: You can utilize ordinary router hardware with BGP as a load-balancing method.
    It does, however, have some drawbacks. More information regarding these limits,
    as well as ways to overcome them, may be found on the MetalLB BGP documentation
    page ([https://metallb.universe.tf/configuration/#bgp-configuration](https://metallb.universe.tf/configuration/#bgp-configuration)).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用普通的路由器硬件配合BGP作为负载均衡方法。然而，它确实存在一些缺点。有关这些限制的更多信息，以及如何克服它们的方法，可以在MetalLB BGP文档页面找到（[https://metallb.universe.tf/configuration/#bgp-configuration](https://metallb.universe.tf/configuration/#bgp-configuration)）。
- en: 'To summarize, MetalLB enables you to establish Kubernetes `LoadBalancer` Services
    without requiring your cluster to be deployed on a cloud platform. MetalLB provides
    two modes of operation: a basic L2 mode that requires no external hardware or
    configuration, and a BGP mode that is more robust and production-ready but necessitates
    more network setup tasks. In the next section, we will look at how to use the
    `Ingress` method for load-balancing configuration.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，MetalLB使你能够在无需将集群部署在云平台上的情况下，建立Kubernetes `LoadBalancer`服务。MetalLB提供两种操作模式：一种是无需外部硬件或配置的基本L2模式，另一种是更为强大且适合生产环境的BGP模式，但需要更多的网络设置任务。在下一节中，我们将介绍如何使用`Ingress`方法进行负载均衡配置。
- en: Configuring Ingress to expose Services outside the cluster
  id: totrans-157
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 配置Ingress以将服务暴露到集群外部
- en: As we discussed in the *Overview of MetalLB and Ingress* section, Ingress offers
    HTTP and HTTPS routes to Services within the cluster from outside the cluster.
    Rules defined on Ingress control traffic routing. NGINX Ingress Controller is
    a common Kubernetes Ingress and the default Ingress controller for MicroK8s as
    well.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在*MetalLB和Ingress概述*部分中讨论的那样，Ingress提供了从集群外部到集群内服务的HTTP和HTTPS路由。Ingress上定义的规则控制流量的路由。NGINX
    Ingress Controller是常见的Kubernetes Ingress，也是MicroK8s的默认Ingress控制器。
- en: Another option is employing a load balancer such as MetalLB that can be deployed
    in the same Kubernetes cluster, and the Services can then be exposed to an external
    network.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种选择是使用负载均衡器，如MetalLB，它可以部署在同一个Kubernetes集群中，然后服务可以暴露到外部网络。
- en: 'A diagrammatic illustration of both approaches is shown here:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是两种方法的图示：
- en: '![Figure 7.20 – Ingress load-balancing functionality ](img/Figure_7.20_B18115.jpg)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.20 – Ingress 负载均衡功能](img/Figure_7.20_B18115.jpg)'
- en: Figure 7.20 – Ingress load-balancing functionality
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.20 – Ingress 负载均衡功能
- en: Both options are discussed in more depth in the following sections.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 以下选项将在后续部分中更详细地讨论。
- en: Option 1 – Using the Ingress NodePort method
  id: totrans-164
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选项1 – 使用Ingress NodePort方法
- en: For this option and the next, we'll use the same MicroK8s Raspberry Pi cluster
    that we built for the MetalLB setup.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 对于这一选项和下一个选项，我们将使用为MetalLB配置建立的相同MicroK8s Raspberry Pi集群。
- en: Step 1 – Enabling the Ingress add-on
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 1 步 – 启用 Ingress 插件
- en: 'The Ingress add-on can be enabled using the same command that we used to enable
    MetalLB, as illustrated here:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 可以使用与启用 MetalLB 时相同的命令启用 Ingress 插件，如此处所示：
- en: '[PRE16]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'The following command execution output indicates the Ingress add-on has been
    enabled successfully:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出表示 Ingress 插件已成功启用：
- en: '![Figure 7.21 – Enabling Ingress add-on ](img/Figure_7.21_B18115.jpg)'
  id: totrans-170
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.21 – 启用 Ingress 插件](img/Figure_7.21_B18115.jpg)'
- en: Figure 7.21 – Enabling Ingress add-on
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.21 – 启用 Ingress 插件
- en: Now that the Ingress add-on has been enabled, the next step is to deploy a sample
    application to test the load-balancing functionality.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 Ingress 插件已经启用，下一步是部署一个示例应用程序来测试负载均衡功能。
- en: Step 2 – Deploying a sample containerized application
  id: totrans-173
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 第 2 步 – 部署示例容器化应用程序
- en: 'We''ll apply the following `whoami` deployment on our multi-node MicroK8s cluster,
    which is a Tiny Go web server that prints OS information and HTTP requests to
    output:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在我们的多节点 MicroK8s 集群上应用以下 `whoami` 部署，这是一个 Tiny Go Web 服务器，能够输出操作系统信息和 HTTP
    请求：
- en: '[PRE17]'
  id: totrans-175
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'The following command will deploy the `whoami` application:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将部署 `whoami` 应用程序：
- en: '[PRE18]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'The following command execution output indicates that there is no error in
    the deployment, and in the next steps, we can verify this by using the `get deployments`
    command:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出表示部署没有错误，在接下来的步骤中，我们可以使用 `get deployments` 命令验证这一点：
- en: '![Figure 7.22 – Deploying the whoami application ](img/Figure_7.22_B18115.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.22 – 部署 whoami 应用程序](img/Figure_7.22_B18115.jpg)'
- en: Figure 7.22 – Deploying the whoami application
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.22 – 部署 whoami 应用程序
- en: 'Check the status of the deployment to verify the application has been deployed
    and is running by using the following command:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令检查部署状态，验证应用程序是否已部署并正在运行：
- en: '[PRE19]'
  id: totrans-182
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'The following command execution output indicates that the deployment is `Ready`:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出表示部署已 `Ready`：
- en: '![Figure 7.23 – Checking the deployment status ](img/Figure_7.23_B18115.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.23 – 检查部署状态](img/Figure_7.23_B18115.jpg)'
- en: Figure 7.23 – Checking the deployment status
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.23 – 检查部署状态
- en: 'Use the following command to check whether an Ingress object has been created:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令检查是否已创建 Ingress 对象：
- en: '[PRE20]'
  id: totrans-187
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'The output of the preceding command indicates that an Ingress object with the
    name `whoami-ingress` has been created:'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 前述命令的输出表示已创建一个名为 `whoami-ingress` 的 Ingress 对象：
- en: '![Figure 7.24 – Checking the Ingress object that we created ](img/Figure_7.24_B18115.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.24 – 检查我们创建的 Ingress 对象](img/Figure_7.24_B18115.jpg)'
- en: Figure 7.24 – Checking the Ingress object that we created
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.24 – 检查我们创建的 Ingress 对象
- en: 'Use the `describe` command to view detailed information about the Ingress object
    we just created:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 `describe` 命令查看我们刚创建的 Ingress 对象的详细信息：
- en: '![Figure 7.25 – Ingress describe command to check details on Ingress object
    created ](img/Figure_7.25_B18115.jpg)'
  id: totrans-192
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.25 – 使用 Ingress 描述命令检查已创建的 Ingress 对象的详细信息](img/Figure_7.25_B18115.jpg)'
- en: Figure 7.25 – Ingress describe command to check details on Ingress object created
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.25 – 使用 Ingress 描述命令检查已创建的 Ingress 对象的详细信息
- en: 'From the command execution output, here is what each field represents:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 从命令执行输出来看，以下是各个字段的表示：
- en: '`Host`: Because no host is mentioned in the previous output, the rule applies
    to all inbound HTTP traffic via the provided IP address. The rules apply to that
    site if a host (for example, `foo.com`) is supplied.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Host`：由于在之前的输出中没有提到主机，规则适用于通过提供的 IP 地址进入的所有 HTTP 流量。如果提供了主机（例如 `foo.com`），则规则适用于该站点。'
- en: '`Path`: List of routes (for example, `/whoami`) with a backend described by
    a `service.name` and a `service.port.name` or `service.port.number`. Before the
    load balancer distributes traffic to the specified Service, the host and path
    must match the content of an incoming request.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Path`：由 `service.name` 和 `service.port.name` 或 `service.port.number` 描述的后端的路由列表（例如
    `/whoami`）。在负载均衡器将流量分发到指定服务之前，主机和路径必须与传入请求的内容匹配。'
- en: '`Backends`: The Service describes a backend as a combination of Service and
    port names. The mentioned backend receives HTTP (and HTTPS) requests to the Ingress
    object that matches the rule''s host and path.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Backends`：该服务将后端描述为服务和端口名称的组合。所述后端接收与规则的主机和路径匹配的 HTTP（和 HTTPS）请求，传递给对应的 Ingress
    对象。'
- en: 'For more information on Ingress, please refer to the Ingress Kubernetes documentation
    at the following link: [https://kubernetes.io/docs/concepts/services-networking/ingress/](https://kubernetes.io/docs/concepts/services-networking/ingress/).'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 有关 Ingress 的更多信息，请参阅 Kubernetes 的官方文档：[https://kubernetes.io/docs/concepts/services-networking/ingress/](https://kubernetes.io/docs/concepts/services-networking/ingress/)。
- en: Step 3 – Verifying the load balancer mechanism
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 步骤 3 – 验证负载均衡器机制
- en: 'Use the `curl` command to check whether you can access the application, as
    illustrated here:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`curl`命令检查是否能够访问应用程序，如下所示：
- en: '![Figure 7.26 – Accessing the deployed application ](img/Figure_7.26_B18115.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.26 – 访问已部署的应用程序](img/Figure_7.26_B18115.jpg)'
- en: Figure 7.26 – Accessing the deployed application
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.26 – 访问已部署的应用程序
- en: 'Let''s scale the deployment to see whether our load balancer is working properly.
    To do so, run the `kubectl scale` command, as follows:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们扩展部署，看看负载均衡器是否正常工作。为此，请运行`kubectl scale`命令，如下所示：
- en: '[PRE21]'
  id: totrans-204
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'The following command execution output confirms that there is no error in the
    deployment, and in the next steps, let''s check how the Pods are distributed across
    the nodes:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出确认部署没有错误，接下来的步骤中让我们检查 Pods 如何在节点间分布：
- en: '![Figure 7.27 – Scaling the deployment ](img/Figure_7.27_B18115.jpg)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.27 – 扩展部署](img/Figure_7.27_B18115.jpg)'
- en: Figure 7.27 – Scaling the deployment
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.27 – 扩展部署
- en: 'The following command execution output indicates that two Pods are running
    on the `master` node, and three of them are running on `worker1`:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令执行输出表明，两个 Pods 正在 `master` 节点上运行，三个 Pods 正在 `worker1` 节点上运行：
- en: '![Figure 7.28 – Checking how the Pods are distributed across nodes ](img/Figure_7.28_B18115.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.28 – 检查 Pods 如何在节点之间分布](img/Figure_7.28_B18115.jpg)'
- en: Figure 7.28 – Checking how the Pods are distributed across nodes
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.28 – 检查 Pods 如何在节点之间分布
- en: 'Let''s use the same `curl` command to access the application and verify it''s
    working, as follows:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用相同的`curl`命令访问应用程序并验证其是否正常工作，如下所示：
- en: '![Figure 7.29 – Rechecking whether the load balancer is working properly ](img/Figure_7.29_B18115.jpg)'
  id: totrans-212
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.29 – 重新检查负载均衡器是否正常工作](img/Figure_7.29_B18115.jpg)'
- en: Figure 7.29 – Rechecking whether the load balancer is working properly
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.29 – 重新检查负载均衡器是否正常工作
- en: The command execution output confirms that the load balancer is working properly.
    Even though the Pods are spread throughout the nodes, our `whoami` application
    is able to effectively serve user requests.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 命令执行输出确认负载均衡器正常工作。尽管 Pods 分布在不同节点上，我们的 `whoami` 应用程序仍然能够有效地响应用户请求。
- en: Option 2 – Using Ingress and a load balancer
  id: totrans-215
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 选项 2 – 使用 Ingress 和负载均衡器
- en: In this method, we must have a load balancer for the Kubernetes cluster in order
    to proceed. Since we already have an installed MetalLB load balancer configured,
    we will be reusing it. However, we will have to define a simple load balancer
    Service for our sample `whoami` application to make sure it's acquiring the external
    IP and port.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在此方法中，我们必须为 Kubernetes 集群配置负载均衡器才能继续。由于我们已经安装并配置了 MetalLB 负载均衡器，因此将重用它。然而，我们仍然需要为我们的示例
    `whoami` 应用程序定义一个简单的负载均衡器服务，以确保它获得外部 IP 和端口。
- en: 'Here is the code for the simple load balancer Service deployment of the `whoami`
    application:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是简单负载均衡器服务部署 `whoami` 应用程序的代码：
- en: '[PRE22]'
  id: totrans-218
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The following command will deploy the preceding application:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令将部署前述应用程序：
- en: '[PRE23]'
  id: totrans-220
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following command output shows that the command was successfully run and
    a load balancer has been created. We will confirm the same in the next steps:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令输出表明命令已成功执行，并且已创建负载均衡器。我们将在接下来的步骤中确认这一点：
- en: '![Figure 7.30 – Created load-balancer Service ](img/Figure_7.30_B18115.jpg)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.30 – 创建的负载均衡器服务](img/Figure_7.30_B18115.jpg)'
- en: Figure 7.30 – Created load-balancer Service
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.30 – 创建的负载均衡器服务
- en: 'Use the following command to check whether a load balancer Service has been
    created and an external IP and port have been allocated. You won''t acquire an
    IP address for `EXTERNAL-IP` if a load balancer isn''t available. Instead, it''s
    marked as `<pending>`. In this situation, check the availability of your load
    balancer:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 使用以下命令检查是否已创建负载均衡器服务，并且外部 IP 和端口已分配。如果负载均衡器不可用，`EXTERNAL-IP` 不会获得 IP 地址，而是显示为
    `<pending>`。在这种情况下，请检查负载均衡器的可用性：
- en: '[PRE24]'
  id: totrans-225
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The following command output shows that an external IP and port have been allocated:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令输出显示已分配外部 IP 和端口：
- en: '![Figure 7.31 – Load balancer has allocated external IP and port ](img/Figure_7.31_B18115.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.31 – 负载均衡器已分配外部 IP 和端口](img/Figure_7.31_B18115.jpg)'
- en: Figure 7.31 – Load balancer has allocated external IP and port
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.31 – 负载均衡器已分配外部 IP 和端口
- en: 'Now that an external IP has been allocated, we can access the application from
    any of the nodes or from an external network, as follows:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 既然外部 IP 已经分配，我们可以通过任何节点或外部网络访问应用，如下所示：
- en: '[PRE25]'
  id: totrans-230
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'The following command output shows that the command was successfully run and
    the load balancer is working properly. Though the application is spread throughout
    the nodes, our `whoami` application is able to effectively serve user requests:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 以下命令输出显示命令已成功运行，且负载均衡器正常工作。尽管应用分布在各个节点上，我们的 `whoami` 应用仍然能够有效地处理用户请求：
- en: '![Figure 7.32 – Checking whether the load balancer is working properly ](img/Figure_7.32_B18115.jpg)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.32 – 检查负载均衡器是否正常工作](img/Figure_7.32_B18115.jpg)'
- en: Figure 7.32 – Checking whether the load balancer is working properly
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.32 – 检查负载均衡器是否正常工作
- en: To summarize, Kubernetes provides several ways to expose Services to the outside
    world. `LoadBalancer` and Ingress controllers are the most common choices. We
    have explored both options with examples in this chapter.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，Kubernetes 提供了几种将服务暴露到外部世界的方法。`LoadBalancer` 和 Ingress 控制器是最常见的选择。在本章中，我们通过示例探讨了这两种选项。
- en: Guidelines on how to choose the right load balancer for your applications
  id: totrans-235
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 选择合适的负载均衡器的指南
- en: Now that we've gone over choices, it would be useful to have a cheat sheet to
    rapidly compare some crucial features to assist us in deciding which one to utilize.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了不同的选择，拥有一份备忘单来快速比较一些关键特性将会非常有帮助，帮助我们决定使用哪个选项。
- en: 'In the following table, we will cover some of the important parameters in choosing
    the right option:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 在下表中，我们将介绍选择正确选项时需要考虑的一些重要参数：
- en: '![Table 7.1 – How to choose the right load balancer ](img/B18115_07_Table_7.1a.jpg)![Table
    7.1 – How to choose the right load balancer ](img/B18115_07_Table_7.1b.jpg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![表 7.1 – 如何选择合适的负载均衡器](img/B18115_07_Table_7.1a.jpg)![表 7.1 – 如何选择合适的负载均衡器](img/B18115_07_Table_7.1b.jpg)'
- en: Table 7.1 – How to choose the right load balancer
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7.1 – 如何选择合适的负载均衡器
- en: In conclusion, it all boils down to a few choices. When using `LoadBalancer`,
    especially on bare metal, it works great because the Service can choose which
    port it wishes to use. The disadvantage is that it can be costly, as each Service
    will have its own load balancer and external IP address, both of which cost money
    in the cloud environment. Ingress is becoming the most popular Service when connected
    with a MetalLB load balancer because it reduces the number of IPs used while still
    allowing each service to have its own name and/or **Uniform Resource Identifier**
    (**URI**) routing.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，最终选择可以归结为几个选项。当使用 `LoadBalancer`，特别是在裸机环境下，它表现非常好，因为服务可以选择其希望使用的端口。缺点是，它可能比较昂贵，因为每个服务都需要自己的负载均衡器和外部
    IP 地址，而这在云环境中都是需要付费的。Ingress 变成了最受欢迎的服务，尤其是当与 MetalLB 负载均衡器一起使用时，因为它减少了使用的 IP
    数量，同时仍然允许每个服务拥有自己的名称和/或 **统一资源标识符** (**URI**) 路由。
- en: Summary
  id: totrans-241
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we looked at techniques for exposing Services outside the cluster
    and we've seen how load balancers can expose applications to the outside network.
    Incoming requests are routed to your application using a load balancer's single
    IP address. MetalLB implements the `LoadBalancer` Kubernetes service. When a `LoadBalancer`
    Service is requested, MetalLB assigns an IP address from a preset range to the
    client and informs the network that the IP resides in the cluster.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们讨论了将服务暴露到集群外部的技术，并且我们已经看到负载均衡器如何将应用暴露到外部网络。传入的请求会通过负载均衡器的单一 IP 地址路由到你的应用。MetalLB
    实现了 `LoadBalancer` Kubernetes 服务。当请求 `LoadBalancer` 服务时，MetalLB 从预设的范围中为客户端分配一个
    IP 地址，并通知网络该 IP 地址位于集群内。
- en: We have also seen the NGINX Ingress Controller option, which is a common Kubernetes
    Ingress option. MetalLB, which can be deployed in the same Kubernetes cluster
    along with Ingress, can also be used as a load balancer. `NodePort` is another
    way to expose the Ingress controller to the outside world. Both options were discussed
    in this chapter, along with different examples.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还看到了 NGINX Ingress 控制器选项，这是一个常见的 Kubernetes Ingress 选项。MetalLB 可以与 Ingress
    一起部署在同一个 Kubernetes 集群中，也可以用作负载均衡器。`NodePort` 是另一种将 Ingress 控制器暴露到外部世界的方式。在本章中，我们讨论了这两种选项，并提供了不同的示例。
- en: In the next chapter, we will be covering how to monitor the health of infrastructure
    and applications using tools such as Prometheus, Grafana, Elastic, Fluentd, Kibana,
    and Jaeger. You will also learn how to configure and access the various dashboards/metrics.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将介绍如何使用像 Prometheus、Grafana、Elastic、Fluentd、Kibana 和 Jaeger 等工具来监控基础设施和应用程序的健康状况。你还将学习如何配置和访问各种仪表盘/指标。
