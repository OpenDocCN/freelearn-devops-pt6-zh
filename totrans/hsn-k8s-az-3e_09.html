<html><head></head><body>
		<div>
			<div id="_idContainer127" class="Content">
			</div>
		</div>
		<div id="_idContainer128" class="Content">
			<h1 id="_idParaDest-66">5. <a id="_idTextAnchor067"/>Handling common failures in AKS</h1>
		</div>
		<div id="_idContainer165" class="Content">
			<p>Kubernetes is a distributed system with many working parts. AKS abstracts most of it for you, but it is still your responsibility to know where to look and how to respond when bad things happen. Much of the failure handling is done automatically by Kubernetes; however, you will encounter situations where manual intervention is required.</p>
			<p>There are two areas where things can go wrong in an application that is deployed on top of AKS. Either the cluster itself has issues, or the application deployed on top of the cluster has issues. This chapter focuses specifically on cluster issues. There are several things that can go wrong with a cluster.</p>
			<p>The first thing that can go wrong is a node in the cluster can become unavailable. This can happen either due to an Azure infrastructure outage or due to an issue with the virtual machine itself, such as an operating system crash. Either way, Kubernetes monitors the cluster for node failures and will recover automatically. You will see this process in action in this chapter.</p>
			<p>A second common issue in a Kubernetes cluster is out-of-resource failures. This means that the workload you are trying to deploy requires more resources than are available on your cluster. You will learn how to monitor these signals and how you can solve them.</p>
			<p>Another common issue is problems with mounting storage, which happens when a node becomes unavailable. When a node in Kubernetes becomes unavailable, Kubernetes will not detach the disks attached to this failed node. This means that those disks cannot be used by workloads on other nodes. You will see a practical example of this and learn how to recover from this failure.</p>
			<p>We will look into the following topics in depth in this chapter:</p>
			<ul>
				<li>Handling node failures</li>
				<li>Solving out-of-resource failures</li>
				<li>Handling storage mount issues</li>
			</ul>
			<p>In this chapter, you will learn about common failure scenarios, as well as solutions to those scenarios. To start, we will introduce node failures.</p>
			<h4>Note:</h4>
			<p class="callout">Refer to Kubernetes the Hard Way (<a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">https://github.com/kelseyhightower/kubernetes-the-hard-way</a>), an excellent tutorial, to get an idea about the blocks on which Kubernetes is built. For the Azure version, refer to Kubernetes the Hard Way – Azure Translation (<a href="https://github.com/ivanfioravanti/kubernetes-the-hard-way-on-azure">https://github.com/ivanfioravanti/kubernetes-the-hard-way-on-azure</a>).</p>
			<h2 id="_idParaDest-67"><a id="_idTextAnchor068"/>Handling node failures</h2>
			<p>Intentionally (to save costs) or unintentionally, nodes can go down. When that happens, you don't want to get the proverbial 3 a.m. call that your system is down. Kubernetes can handle moving workloads on failed nodes automatically for you instead. In this exercise, you are going to deploy the guestbook application and bring a node down in your cluster to see what Kubernetes does in response:</p>
			<ol>
				<li>Ensure that your cluster has at least two nodes:<p class="snippet">kubectl get nodes</p><p>This should generate an output as shown in <em class="italics">Figure 5.1</em>:</p><div id="_idContainer129" class="IMG---Figure"><img src="image/B17338_05_01.jpg" alt="List of nodes in the created cluster"/></div><p class="figure">Figure 5.1: List of nodes in the cluster</p><p>If you don't have two nodes in your cluster, look for your cluster in the Azure portal, navigate to <span class="P---Screen-Text">Node pools</span>, select the pool you wish to scale, and click on <span class="P---Screen-Text">Scale</span>. You can then scale <span class="P---Screen-Text">Node count</span> to <span class="P---Screen-Text">2</span> nodes as shown in <em class="italics">Figure 5.2</em>:</p><div id="_idContainer130" class="IMG---Figure"><img src="image/B17338_05_02.jpg" alt="Scaling the cluster size to two nodes using the Azure portal"/></div><p class="figure">Figure 5.2: Scaling the cluster</p></li>
				<li>As an example application in this section, deploy the guestbook application. The YAML file to deploy this has been provided in the source code for this chapter (<strong class="inline">guestbook-all-in-one.yaml</strong>). To deploy the guestbook application, use the following command:<p class="snippet">kubectl create -f guestbook-all-in-one.yaml</p></li>
				<li>Watch the <strong class="inline">service</strong> object until the public IP becomes available. To do this, type the following:<p class="snippet">kubectl get service -w</p><h4>Note</h4><p class="callout">You can also get services in Kubernetes by using <strong class="inline">kubectl get svc</strong> rather than the full <strong class="inline">kubectl get service</strong>.</p></li>
				<li>This will take a couple of seconds to show you the updated external IP. <em class="italics">Figure 5.3</em> shows the service's public IP. Once you see the public IP appear (<span class="P---Screen-Text">20.72.244.113</span> in this case), you can exit the watch command by hitting <em class="italics">Ctrl</em> + <em class="italics">C</em>:<div id="_idContainer131" class="IMG---Figure"><img src="image/B17338_05_03.jpg" alt="Fetching the external IP of the Service object"/></div><p class="figure">Figure 5.3: The external IP of the frontend service changes from &lt;pending&gt; to an actual IP address</p></li>
				<li>Go to <strong class="inline">http://&lt;EXTERNAL-IP&gt;</strong> (<strong class="inline">http://20.72.244.113</strong> in this case) as shown in <em class="italics">Figure 5.4</em>:<div id="_idContainer132" class="IMG---Figure"><img src="image/B17338_05_04.jpg" alt="Browsing to the guestbook application using the external IP"/></div><p class="figure">Figure 5.4: Browsing to the guestbook application</p></li>
				<li>Let's see where the pods are currently running using the following command:<p class="snippet">kubectl get pods -o wide</p><p>This will generate an output as shown in <em class="italics">Figure 5.5</em>:</p><div id="_idContainer133" class="IMG---Figure"><img src="image/B17338_05_05.jpg" alt="List of pods running on nodes 0 and 2"/></div><p class="figure">Figure 5.5: The pods are spread between node 0 and node 2</p><p>This shows you that you should have the workload spread between node 0 and node 2.</p><h4>Note</h4><p class="callout">In the example shown in <em class="italics">Figure 5.5</em>, the workload is spread between nodes 0 and 2. You might notice that node 1 is missing here. If you followed the example in <em class="italics">Chapter 4,  Building scalable applications</em>, your cluster should be in a similar state. The reason for this is that as Azure removes old nodes and adds new nodes to a cluster (as you did in <em class="italics">Chapter 4, Building scalable applications</em>), it keeps incrementing the node counter. </p></li>
				<li>Before introducing the node failures, there are two optional steps you can take to verify whether your application can continue to run. You can run the following command to hit the guestbook front end every 5 seconds and get the HTML. It's recommended to open this in a new Cloud Shell window:<p class="snippet">while true; do </p><p class="snippet">  curl -m 1 http://&lt;EXTERNAl-IP&gt;/; </p><p class="snippet">  sleep 5;</p><p class="snippet">done</p><h4>Note</h4><p class="callout">The preceding command will keep calling your application till you press <em class="italics">Ctrl</em> + <em class="italics">C</em>. There might be intermittent times where you don't get a reply, which is to be expected as Kubernetes takes a couple of minutes to rebalance the system.</p><p>You can also add some guestbook entries to see what happens to them when you cause the node to shut down. This will display an output as shown in <em class="italics">Figure 5.6</em>:</p><div id="_idContainer134" class="IMG---Figure"><img src="image/B17338_05_06.jpg" alt="Adding a couple of entries in the guestbook application"/></div><p class="figure">Figure 5.6: Writing a couple of messages in the guestbook</p></li>
				<li>In this example, you are exploring how Kubernetes handles a node failure. To demonstrate this, shut down a node in the cluster. You can shut down either node, although for maximum impact it is recommended you shut down the node from <em class="italics">step 6</em> that hosted the most pods. In the case of the example shown, node 2 will be shut down.<p>To shut down this node, look for <strong class="bold">VMSS</strong> (<strong class="bold">virtual machine scale sets</strong>) in the Azure search bar, and select the scale set used by your cluster, as shown in <em class="italics">Figure 5.7</em>. If you have multiple scale sets in your subscription, select the one whose name corresponds to the node names shown in <em class="italics">Figure 5.5</em>:</p><div id="_idContainer135" class="IMG---Figure"><img src="image/B17338_05_07.jpg" alt="Searching for vmss in the azure search bar, and selecting the scale set used by your cluster"/></div><p class="figure">Figure 5.7: Looking for the scale set hosting your cluster</p><p>After navigating to the pane of the scale set, go to the <span class="P---Screen-Text">Instances</span> view, select the instance you want to shut down, and then hit the <span class="P---Screen-Text">Stop</span> button, as shown in <em class="italics">Figure 5.8</em>:</p><div id="_idContainer136" class="IMG---Figure"><img src="image/B17338_05_08.jpg" alt="Shutting down the desired node through the Instances pane of the scale set used by your cluster"/></div><p class="figure">Figure 5.8: Shutting down node 2</p><p>This will shut down the node. To see how Kubernetes will react with your pods, you can watch the pods in your cluster via the following command:</p><p class="snippet">kubectl get pods -o wide -w</p><p>After a while, you should notice additional output, showing you that the pods got rescheduled on the healthy host, as shown in <em class="italics">Figure 5.9</em>:</p><div id="_idContainer137" class="IMG---Figure"><img src="image/B17338_05_09.jpg" alt="Pods from the failed node getting rescheduled on healthy nodes"/></div><p class="figure">Figure 5.9: The pods from the failed node getting recreated on a healthy node</p><p>What you see here is the following:</p><ul><li>The Redis master pod running on <span class="P---Screen-Text">node 2</span> got terminated as the host became unhealthy.</li><li>A new Redis master pod got created, on host <span class="P---Screen-Text">0</span>. This went through the stages <span class="P---Screen-Text">Pending</span>, <span class="P---Screen-Text">ContainerCreating</span>, and then <span class="P---Screen-Text">Running</span>.</li></ul><h4>Note</h4><p class="callout">In the preceding example, Kubernetes picked up that the host was unhealthy before it rescheduled the pods. If you were to do <strong class="inline">kubectl get nodes</strong>, you would see node <span class="P---Screen-Text">2</span> is in a <span class="P---Screen-Text">NotReady</span> state. There is a configuration in Kubernetes called <strong class="inline">pod-eviction-timeout</strong> that defines how long the system will wait to reschedule pods on a healthy host. The default is 5 minutes.</p></li>
				<li>If you recorded a number of messages in the guestbook during <em class="italics">step 7</em>, browse back to the guestbook application on its public IP. What you can see is that all your precious messages are gone! This shows the importance of having <strong class="bold">PersistentVolumeClaims</strong> (<strong class="bold">PVCs</strong>) for any data that you want to survive in the case of a node failure, which is not the case in our application here. You will see an example of this in the last section of this chapter.</li>
			</ol>
			<p>In this section, you learned how Kubernetes automatically handles node failures by recreating pods on healthy nodes. In the next section, you will learn how you can diagnose and solve out-of-resource issues.</p>
			<h2 id="_idParaDest-68"><a id="_idTextAnchor069"/>Solving out-of-resource failures</h2>
			<p>Another common issue that can come up with Kubernetes clusters is the cluster running out of resources. When the cluster doesn't have enough CPU power or memory to schedule additional pods, pods will become stuck in a <strong class="inline">Pending</strong> state. You have seen this behavior in <em class="italics">Chapter 4, Building scalable applications</em>, as well.</p>
			<p>Kubernetes uses requests to calculate how much CPU power or memory a certain pod requires. The guestbook application has requests defined for all the deployments. If you open the <strong class="inline">guestbook-all-in-one.yaml</strong> file in the folder <strong class="inline">Chapter05</strong>, you'll see the following for the <strong class="inline">redis-replica</strong> deployment:</p>
			<p class="snippet">63  kind: Deployment</p>
			<p class="snippet">64  metadata:</p>
			<p class="snippet">65    name: redis-replica</p>
			<p class="snippet">...</p>
			<p class="snippet">83          resources:</p>
			<p class="snippet">84            requests:</p>
			<p class="snippet">85              cpu: 200m</p>
			<p class="snippet">86              memory: 100Mi</p>
			<p>This section explains that every pod for the <strong class="inline">redis-replica</strong> deployment requires <strong class="inline">200m</strong> of a CPU core (<strong class="inline">200</strong> milli or <strong class="inline">20%</strong>) and <strong class="inline">100MiB</strong> (Mebibyte) of memory. In your 2 CPU clusters (with node 1 shut down), scaling this to 10 pods will cause issues with the available resources. Let's look into this:</p>
			<h4>Note</h4>
			<p class="callout">In Kubernetes, you can use either the binary prefix notation or the base 10 notation to specify memory and storage. Binary prefix notation means using KiB (kibibyte) to represent 1,024 bytes, MiB (mebibyte) to represent 1,024 KiB, and Gib (gibibyte) to represent 1,024 MiB. Base 10 notation means using kB (kilobyte) to represent 1,000 bytes, MB (megabyte) to represent 1,000 kB, and GB (gigabyte) represents 1,000 MB.</p>
			<ol>
				<li value="1">Let's start by scaling the <strong class="inline">redis-replica</strong> deployment to 10 pods:<p class="snippet">kubectl scale deployment/redis-replica --replicas=10</p></li>
				<li>This will cause a couple of new pods to be created. We can check our pods using the following:<p class="snippet">kubectl get pods</p><p>This will generate an output as shown in <em class="italics">Figure 5.10</em>:</p><div id="_idContainer138" class="IMG---Figure"><img src="image/B17338_05_10.jpg" alt="The Redis replica pod in a Pending state due to a shortage of resources"/></div><p class="figure">Figure 5.10: Some pods are in the Pending state</p><p>Highlighted here is one of the pods that are in the <span class="P---Screen-Text">Pending</span> state. This occurs if the cluster is out of resources.</p></li>
				<li>We can get more information about these pending pods using the following command:<p class="snippet">kubectl describe pod redis-replica-&lt;pod-id&gt;</p><p>This will show you more details. At the bottom of the <strong class="inline">describe</strong> command, you should see something like what's shown in <em class="italics">Figure 5.11</em>:</p><div id="_idContainer139" class="IMG---Figure"><img src="image/B17338_05_11.jpg" alt="Fetching more details about the pending pod using the kubectl describe pod command"/></div><p class="figure">Figure 5.11: Kubernetes is unable to schedule this pod</p><p>It explains two things:</p><ul><li>One of the nodes is out of CPU resources.</li><li>One of the nodes has a taint (node.kubernetes.io/unreachable) that the pod didn't tolerate. This means that the node that is <strong class="inline">NotReady</strong> can't accept pods.</li></ul></li>
				<li>We can solve this capacity issue by starting up node <span class="P---Screen-Text">2</span> as shown in <em class="italics">Figure 5.12</em>. This can be done in a way similar to the shutdown process:<div id="_idContainer140" class="IMG---Figure"><img src="image/B17338_05_12.jpg" alt="Starting node 2 again from the Instances pane of the selected VMSS"/></div><p class="figure">Figure 5.12: Start node 2 again</p></li>
				<li>It will take a couple of minutes for the other node to become available again in Kubernetes. You can monitor the progress on the pods by executing the following command:<p class="snippet">kubectl get pods -w</p><p>This will show you an output after a couple of minutes similar to <em class="italics">Figure 5.13</em>:</p><div id="_idContainer141" class="IMG---Figure"><img src="image/B17338_05_13.jpg" alt="Monitoring the transition of the pods from the Pending state to the Running state"/></div><p class="figure">Figure 5.13: Pods move from a Pending state to ContainerCreating to Running</p><p>Here again, you see the container status change from <span class="P---Screen-Text">Pending</span>, to <span class="P---Screen-Text">ContainerCreating</span>, to finally <span class="P---Screen-Text">Running</span>. </p></li>
				<li>If you re-execute the <strong class="inline">describe</strong> command on the previous pod, you'll see an output like what's shown in <em class="italics">Figure 5.14</em>:</li>
			</ol>
			<div>
				<div id="_idContainer142" class="IMG---Figure">
					<img src="image/B17338_05_14.jpg" alt="Output showing that the Kubernetes scheduler assigned the redis replica pod to node 2"/>
				</div>
			</div>
			<p class="figure">Figure 5.14: When the node is available again, the Pending pods are assigned to that node</p>
			<p>This shows that after node 2 became available, Kubernetes scheduled the pod on that node, and then started the container.</p>
			<p>In this section, you learned how to diagnose out-of-resource errors. You were able to solve the error by adding another node to the cluster. Before moving on to the final failure mode, clean up the guestbook deployment.</p>
			<h4>Note</h4>
			<p class="callout">In <em class="italics">Chapter 4, Building scalable applications</em>, the <strong class="bold">cluster autoscaler</strong> was introduced. The cluster autoscaler will monitor out-of-resource errors and add new nodes to the cluster automatically.</p>
			<p>Let's clean up the guestbook deployment by running the following <strong class="inline">delete</strong> command:</p>
			<p class="snippet">kubectl delete -f guestbook-all-in-one.yaml</p>
			<p>It is now also safe to close the other Cloud Shell window you opened earlier.</p>
			<p>So far, you have learned how to recover from two failure modes for nodes in a Kubernetes cluster. First, you saw how Kubernetes handles a node going offline and how the system reschedules pods to a working node. After that, you saw how Kubernetes uses requests to manage the scheduling of pods on a node, and what happens when a cluster is out of resources. In the next section, you'll learn about another failure mode in Kubernetes, namely what happens when Kubernetes encounters storage mounting issues.</p>
			<h2 id="_idParaDest-69"><a id="_idTextAnchor070"/>Fixing storage mount issues</h2>
			<p>Earlier in this chapter, you noticed how the guestbook application lost data when the Redis master was moved to another node. This happened because that sample application didn't use any persistent storage. In this section, you'll see an example of how PVCs can be used to prevent data loss when Kubernetes moves a pod to another node. You will see a common error that occurs when Kubernetes moves pods with PVCs attached, and you'll learn how to fix this.</p>
			<p>For this, you will reuse the WordPress example from the previous chapter. Before starting, let's make sure that the cluster is in a clean state:</p>
			<p class="snippet">kubectl get all</p>
			<p>This should show you just the one Kubernetes service, as in <em class="italics">Figure 5.15</em>:</p>
			<div>
				<div id="_idContainer143" class="IMG---Figure">
					<img src="image/B17338_05_15.jpg" alt="Checking the status of the cluster using the kubectl get all command"/>
				</div>
			</div>
			<p class="figure">Figure 5.15: You should only have the one Kubernetes service running for now</p>
			<p>Let's also ensure that both nodes are running and <span class="P---Screen-Text">Ready</span>:</p>
			<p class="snippet">kubectl get nodes</p>
			<p>This should show us both nodes in a <span class="P---Screen-Text">Ready</span> state, as in <em class="italics">Figure 5.16</em>:</p>
			<div>
				<div id="_idContainer144" class="IMG---Figure">
					<img src="image/B17338_05_16.jpg" alt="Checking the status of both nodes using the kubectl get nodes command"/>
				</div>
			</div>
			<p class="figure">Figure 5.16: You should have two nodes available in your cluster</p>
			<p>In the previous example, under the <em class="italics">Handling node failures</em> section, you saw that the messages stored in <strong class="inline">redis-master</strong> are lost if the pod gets restarted. The reason for this is that <strong class="inline">redis-master</strong> stores all data in its container, and whenever it is restarted, it uses the clean image without the data. In order to survive reboots, the data has to be stored outside. Kubernetes uses PVCs to abstract the underlying storage provider to provide this external storage.</p>
			<p>To start this example, set up the WordPress installation.</p>
			<h3 id="_idParaDest-70"><a id="_idTextAnchor071"/>Starting the WordPress installation</h3>
			<p>Let's start by installing WordPress. We will demonstrate how it works and then verify that storage is still present after a reboot.</p>
			<p>If you have not done so yet in a previous chapter, add the Helm repository for Bitnami:</p>
			<p class="snippet">helm repo add bitnami https://charts.bitnami.com/bitnami</p>
			<p>Begin reinstallation by using the following command:</p>
			<p class="snippet">helm install wp bitnami/wordpress</p>
			<p>This will take a couple of minutes to process. You can follow the status of this installation by executing the following command:</p>
			<p class="snippet">kubectl get pods -w</p>
			<p>After a couple of minutes, this should show you two pods with a status of <span class="P---Screen-Text">Running</span> and with a ready status of <span class="P---Screen-Text">1/1</span> for both pods, as shown in <em class="italics">Figure 5.17</em>:</p>
			<div>
				<div id="_idContainer145" class="IMG---Figure">
					<img src="image/B17338_05_17.jpg" alt="Using kubectl get pods -w to follow the progress of WordPress installation"/>
				</div>
			</div>
			<p class="figure">Figure 5.17: All pods will have the status of Running after a couple of minutes</p>
			<p>You might notice that the <strong class="inline">wp-wordpress</strong> pod went through an Error status and was restarted afterward. This is because the <strong class="inline">wp-mariadb</strong> pod was not ready in time, and <strong class="inline">wp-wordpress</strong> went through a restart. You will learn more about readiness and how this can influence pod restarts in <em class="italics">Chapter 7, Monitoring the AKS cluster and the application</em>.</p>
			<p>In this section, you saw how to install WordPress. Now, you will see how to avoid data loss using persistent volumes.</p>
			<h3 id="_idParaDest-71"><a id="_idTextAnchor072"/>Using persistent volumes to avoid data loss</h3>
			<p>A <strong class="bold">persistent volume</strong> (<strong class="bold">PV</strong>) is the way to store persistent data in the cluster with Kubernetes. PVs were discussed in more detail in <em class="italics">Chapter 3, Application deployment on AKS</em>. Let's explore the PVs created for the WordPress deployment:</p>
			<ol>
				<li value="1">You can get the PersistentVolumeClaims using the following command:<p class="snippet">kubectl get pvc</p><p>This will generate an output as shown in <em class="italics">Figure 5.18</em>:</p><div id="_idContainer146" class="IMG---Figure"><img src="image/B17338_05_18.jpg" alt="Fetching the details of the PersistentVolumeClaims using the kubectl get pvc command"/></div><p class="figure">Figure 5.18: Two PVCs are created by the WordPress deployment</p><p>A PersistentVolumeClaim will result in the creation of a PersistentVolume. The PersistentVolume is the link to the physical resource created, which is an Azure disk in this case. The following command shows the actual PVs that are created:</p><p class="snippet">kubectl get pv</p><p>This will show you the two PersistentVolumes:</p><div id="_idContainer147" class="IMG---Figure"><img src="image/B17338_05_19.jpg" alt="Using the kubectl get pv command to check the created PersistentVolumes"/></div><p class="figure">Figure 5.19: Two PVs are created to store the data of the PVCs</p><p>You can get more details about the specific PersistentVolumes that were created. Copy the name of one of the PVs, and run the following command:</p><p class="snippet">kubectl describe pv &lt;pv name&gt;</p><p>This will show you the details of that volume, as in <em class="italics">Figure 5.20</em>:</p><div id="_idContainer148" class="IMG---Figure"><img src="image/B17338_05_20.jpg" alt="Using the kubectl describe pv&lt;pv name&gt; command to get details of specific PersistentVolumes"/></div><p class="figure">Figure 5.20: The details of one of the PVs</p><p>Here, you can see which PVC has claimed this volume and what the <span class="P---Screen-Text">DiskName</span> is in Azure.</p></li>
				<li>Verify that your site is working:<p class="snippet">kubectl get service</p><p>This will show us the public IP of our WordPress site, as seen in <em class="italics">Figure 5.21</em>:</p><div id="_idContainer149" class="IMG---Figure"><img src="image/B17338_05_21.jpg" alt="Obtaining the public IP of our WordPress site"/></div><p class="figure">Figure 5.21: Public IP of the WordPress site</p></li>
				<li>If you remember from <em class="italics">Chapter 3, Application deployment of AKS</em>, Helm showed you the commands you need to get the admin credentials for our WordPress site. Let's grab those commands and execute them to log on to the site as follows:<p class="snippet">helm status wp</p><p class="snippet">echo Username: user</p><p class="snippet">echo Password: $(kubectl get secret --namespace default wp-wordpress -o jsonpath="{.data.wordpress-password}" | base64 -d)</p><p>This will show you the <span class="P---Screen-Text">username</span> and <span class="P---Screen-Text">password</span>, as displayed in <em class="italics">Figure 5.22</em>:</p></li>
			</ol>
			<div>
				<div id="_idContainer150" class="IMG---Figure">
					<img src="image/B17338_05_22.jpg" alt="Using Helm commands to obtain a username and password to login to the WordPress site"/>
				</div>
			</div>
			<p class="figure">Figure 5.22: Getting the username and password for the WordPress application</p>
			<p>You can log in to our site via the following address: <strong class="inline">http://&lt;external-ip&gt;/admin</strong>. Log in here with the credentials from the previous step. Then you can go ahead and add a post to your website. Click the <span class="P---Screen-Text">Write your first blog post </span>button, and then create a short post, as shown in <em class="italics">Figure 5.23</em>:</p>
			<div>
				<div id="_idContainer151" class="IMG---Figure">
					<img src="image/B17338_05_23.jpg" alt="Writing your first blog post on the WordPress website"/>
				</div>
			</div>
			<p class="figure">Figure 5.23: Writing your first blog post</p>
			<p>Type some text now and hit the <span class="P---Screen-Text">Publish</span> button, as shown in <em class="italics">Figure 5.24</em>. The text itself isn't important; you are writing this to verify that data is indeed persisted to disk:</p>
			<div>
				<div id="_idContainer152" class="IMG---Figure">
					<img src="image/B17338_05_24.jpg" alt="Using the Publish button to publish a post with random text on the WordPress website"/>
				</div>
			</div>
			<p class="figure">Figure 5.24: Publishing a post with random text</p>
			<p>If you now head over to the main page of your website at <strong class="inline">http://&lt;external-ip&gt;</strong>, you'll see your test post as shown in <em class="italics">Figure 5.25</em>: </p>
			<div>
				<div id="_idContainer153" class="IMG---Figure">
					<img src="image/B17338_05_25.jpg" alt="Using the website’s external IP to navigate to the WordPress website and verify the published post"/>
				</div>
			</div>
			<p class="figure">Figure 5.25: The published blog post appears on the home page</p>
			<p>In this section, you deployed a WordPress site, you logged in to your WordPress site, and you created a post. You will verify whether this post survives a node failure in the next section.</p>
			<h3>Handling pod failure with PVC involvement</h3>
			<p>The first test you'll do with the PVCs is to kill the pods and verify whether the data has indeed persisted. To do this, let's do two things:</p>
			<ol>
				<li value="1"><strong class="bold">Watch the pods in your application</strong>: To do this, use the current Cloud Shell and execute the following command:<p class="snippet">kubectl get pods -w</p></li>
				<li><strong class="bold">Kill the two pods that have the PVC mounted</strong>: To do this, create a new Cloud Shell window by clicking on the icon shown in <em class="italics">Figure 5.26</em>:<div id="_idContainer154" class="IMG---Figure"><img src="image/B17338_05_26.jpg" alt="Opening a new Cloud Shell instance"/></div><p class="figure">Figure 5.26: Opening a new Cloud Shell instance</p><p>Once you open a new Cloud Shell, execute the following command:</p><p class="snippet">kubectl delete pod --all</p><p>In the original Cloud Shell, follow along with the <strong class="inline">watch</strong> command that you executed earlier. You should see an output like what's shown in <em class="italics">Figure 5.27</em>:</p><div id="_idContainer155" class="IMG---Figure"><img src="image/B17338_05_27.jpg" alt="Kubernetes creates new pods to recover from the pod outage caused due to the deletion of pods"/></div><p class="figure">Figure 5.27: After deleting the pods, Kubernetes will automatically recreate both pods</p><p>As you can see, the two original pods went into a <span class="P---Screen-Text">Terminating</span> state. Kubernetes quickly started creating new pods to recover from the pod outage. The pods went through a similar life cycle as the original ones, going from <span class="P---Screen-Text">Pending</span> to <span class="P---Screen-Text">ContainerCreating</span> to <span class="P---Screen-Text">Running</span>.</p></li>
				<li>If you head on over to your website, you should see that your demo post has been persisted. This is how PVCs can help you prevent data loss, as they persist data that would not have been persisted in the pod itself.</li>
			</ol>
			<p>In this section, you've learned how PVCs can help when pods get recreated on the same node. In the next section, you'll see how PVCs are used when a node has a failure.</p>
			<h3>Handling node failure with PVC involvement</h3>
			<p>In the previous example, you saw how Kubernetes can handle pod failures when those pods have a PV attached. In this example, you'll learn how Kubernetes handles node failures when a volume is attached:</p>
			<ol>
				<li value="1">Let's first check which node is hosting your application, using the following command:<p class="snippet">kubectl get pods -o wide</p><p>In the example shown in <em class="italics">Figure 5.28</em>, node <span class="P---Screen-Text">2</span> was hosting <span class="P---Screen-Text">MariaDB</span>, and node <span class="P---Screen-Text">0</span> was hosting the <span class="P---Screen-Text">WordPress</span> site:</p><div id="_idContainer156" class="IMG---Figure"><img src="image/B17338_05_28.jpg" alt="Checking the node that is hosting your application"/></div><p class="figure">Figure 5.28: Check which node hosts the WordPress site</p></li>
				<li>Introduce a failure and stop the node that is hosting the <span class="P---Screen-Text">WordPress</span> pod using the Azure portal. You can do this in the same way as in the earlier example. First, look for the scale set backing your cluster, as shown in <em class="italics">Figure 5.29</em>:<div id="_idContainer157" class="IMG---Figure"><img src="image/B17338_05_29.jpg" alt="Searching for vmss in the azure search bar, and selecting the scale set used by your cluster"/></div><p class="figure">Figure 5.29: Looking for the scale set hosting your cluster</p></li>
				<li>Then shut down the node, by clicking on <span class="P---Screen-Text">Instances</span> in the left-hand menu, then selecting the node you need to shut down and clicking the <span class="P---Screen-Text">Stop</span> button, as shown in <em class="italics">Figure 5.30</em>:<div id="_idContainer158" class="IMG---Figure"><img src="image/B17338_05_30.jpg" alt="Shutting down the desired node through the Instances pane of the scale set used by your cluster"/></div><p class="figure">Figure 5.30: Shutting down the node</p></li>
				<li>After this action, once again, watch the pods to see what is happening in the cluster:<p class="snippet">kubectl get pods -o wide -w</p><p>As in the previous example, it is going to take 5 minutes before Kubernetes will start taking action against the failed node. You can see that happening in <em class="italics">Figure 5.31</em>:</p><div id="_idContainer159" class="IMG---Figure"><img src="image/B17338_05_31.jpg" alt="The status of the pod indicates that it is stuck in a ContainerCreating state"/></div><p class="figure">Figure 5.31: A pod in a ContainerCreating state</p></li>
				<li>You are seeing a new issue here. The new pod is stuck in a <span class="P---Screen-Text">ContainerCreating</span> state. Let's figure out what is happening here. First, describe that pod:<p class="snippet">kubectl describe pods/wp-wordpress-&lt;pod-id&gt;</p><p>You will get an output as shown in <em class="italics">Figure 5.32</em>:</p><div id="_idContainer160" class="IMG---Figure"><img src="image/B17338_05_32.jpg" alt="Using the kubectl describe command to understand the issue with the pod stuck in theContainerCreating state"/></div><p class="figure">Figure 5.32: Output explaining why the pod is in a ContainerCreating state</p><p>This tells you that there is a problem with the volume. You see two errors related to that volume: the <strong class="inline">FailedAttachVolume</strong> error explains that the volume is already used by another pod, and <strong class="inline">FailedMount</strong> explains that the current pod cannot mount the volume. You can solve this by manually forcefully removing the old pod stuck in the <strong class="inline">Terminating</strong> state. </p><h4>Note</h4><p class="callout">The behavior of the pod stuck in the <strong class="inline">Terminating</strong> state is not a bug. This is default Kubernetes behavior. The Kubernetes documentation states the following: <em class="italics">"Kubernetes (versions 1.5 or newer) will not delete pods just because a Node is unreachable. The pods running on an unreachable Node enter the Terminating or Unknown state after a timeout. Pods may also enter these states when the user attempts the graceful deletion of a pod on an unreachable Node."</em> You can read more at <a href="https://kubernetes.io/docs/tasks/run-application/force-delete-stateful-set-pod/">https://kubernetes.io/docs/tasks/run-application/force-delete-stateful-set-pod/</a>.</p></li>
				<li>To forcefully remove the terminating pod from the cluster, get the full pod name using the following command:<p class="snippet">kubectl get pods</p><p>This will show you an output similar to <em class="italics">Figure 5.33</em>:</p><div id="_idContainer161" class="IMG---Figure"><img src="image/B17338_05_33.jpg" alt="Fetching the name of the pod stuck in the Terminating state"/></div><p class="figure">Figure 5.33: Getting the name of the pod stuck in the Terminating state</p></li>
				<li>Use the pod's name to force the deletion of this pod:<p class="snippet">kubectl delete pod wordpress-wp-&lt;pod-id&gt; --force</p></li>
				<li>After the pod has been deleted, it will take a couple of minutes for the other pod to enter a Running state. You can monitor the state of the pod using the following command:<p class="snippet">kubectl get pods -w</p><p>This will return an output similar to <em class="italics">Figure 5.34</em>:</p><div id="_idContainer162" class="IMG---Figure"><img src="image/B17338_05_34.jpg" alt="The new WordPress pod returning to a Running state"/></div><p class="figure">Figure 5.34: The new WordPress pod returning to a Running state</p></li>
				<li>As you can see, this brought the new pod to a healthy state. It did take a couple of minutes for the system to pick up the changes and then mount the volume to the new pod. Let's get the details of the pod again using the following command:<p class="snippet">kubectl describe pod wp-wordpress-&lt;pod-id&gt;</p><p>This will generate an output as follows:</p><div id="_idContainer163" class="IMG---Figure"><img src="image/B17338_05_35.jpg" alt="The new pod is now attaching the volume and pulling the container image"/></div><p class="figure">Figure 5.35: The new pod is now attaching the volume and pulling the container image</p></li>
				<li>This shows you that the new pod successfully got the volume attached and that the container image got pulled. This also made your WordPress website available again, which you can verify by browsing to the public IP. Before continuing to the next chapter, clean up the application using the following command:<p class="snippet">helm delete wp</p><p class="snippet">kubectl delete pvc --all</p><p class="snippet">kubectl delete pv --all</p></li>
				<li>Let's also start the node that was shut down: go back to the scale set pane in the Azure portal, click <span class="P---Screen-Text">Instances</span> in the left-hand menu, select the node you need to start, and click on the <span class="P---Screen-Text">Start</span> button, as shown in <em class="italics">Figure 5.36</em>:</li>
			</ol>
			<div>
				<div id="_idContainer164" class="IMG---Figure">
					<img src="image/B17338_05_36.jpg" alt="Using the Instances pane of the selected VMSS to start the node that was shut down"/>
				</div>
			</div>
			<p class="figure">Figure 5.36: Starting node 0 again</p>
			<p>In this section, you learned how you can recover from a node failure when PVCs aren't mounting to new pods. All you needed to do was forcefully delete the pod that was stuck in the <strong class="inline">Terminating</strong> state.</p>
			<h2 id="_idParaDest-72"><a id="_idTextAnchor073"/>Summary</h2>
			<p>In this chapter, you learned about common Kubernetes failure modes and how you can recover from them. This chapter started with an example of how Kubernetes automatically detects node failures and how it will start new pods to recover the workload. After that, you scaled out your workload and had your cluster run out of resources. You recovered from that situation by starting the failed node again to add new resources to the cluster.</p>
			<p>Next, you saw how PVs are useful to store data outside of a pod. You deleted all pods on the cluster and saw how the PV ensured that no data was lost in your application. In the final example in this chapter, you saw how you can recover from a node failure when PVs are attached. You were able to recover the workload by forcefully deleting the terminating pod. This brought your workload back to a healthy state.</p>
			<p>This chapter has explained common failure modes in Kubernetes. In the next chapter, we will introduce HTTPS support to our services and introduce authentication with Azure Active Directory.</p>
		</div>
	</body></html>