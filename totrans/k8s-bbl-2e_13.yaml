- en: '13'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DaemonSet – Maintaining Pod Singletons on Nodes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The previous chapters have explained and demonstrated how to use the most common
    Kubernetes controllers for managing Pods, such as ReplicaSet, Deployment, and
    StatefulSet. Generally, when running cloud application components that contain
    the actual *business logic*, you will need either Deployments or StatefulSets
    for controlling your Pods. In some cases, when you need to run batch workloads
    as part of your application, you will use Jobs and CronJobs.
  prefs: []
  type: TYPE_NORMAL
- en: However, in some cases, you will need to run components that have a supporting
    function and, for example, execute maintenance tasks or aggregate logs and metrics.
    More specifically, if you have any tasks that need to be executed for each Node
    in the cluster, they can be performed using a **DaemonSet**. The purpose of a
    DaemonSet is to ensure that *each* Node (unless specified otherwise) runs a *single*
    replica of a Pod. If you add a new Node to the cluster, it will automatically
    get a Pod replica scheduled. Similarly, if you remove a Node from the cluster,
    the Pod replica will be terminated – the DaemonSet will execute all the required
    actions.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will cover the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the DaemonSet object
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating and managing DaemonSets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Common use cases for DaemonSets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alternatives to DaemonSets
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'For this chapter, you will need the following:'
  prefs: []
  type: TYPE_NORMAL
- en: A Kubernetes cluster deployed. You can use either a local or cloud-based cluster,
    but in order to fully understand the concepts, we recommend using a *multi-node*
    Kubernetes cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Kubernetes CLI (`kubectl`) installed on your local machine and configured
    to manage your Kubernetes cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubernetes cluster deployment (local and cloud-based) and `kubectl` installation
    were covered in *Chapter 3*, *Installing Your First Kubernetes Cluster*.
  prefs: []
  type: TYPE_NORMAL
- en: 'You can download the latest code samples for this chapter from the official
    GitHub repository: [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter13](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter13).'
  prefs: []
  type: TYPE_NORMAL
- en: Introducing the DaemonSet object
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The term **daemon** in operating systems has a long history and, in short, is
    used to describe a program that runs as a background process, without interactive
    control from the user. In many cases, daemons are responsible for handling maintenance
    tasks, serving network requests, or monitoring hardware activities. These are
    often processes that you want to run reliably, all the time, in the background,
    from the time you boot the operating system to when you shut it down.
  prefs: []
  type: TYPE_NORMAL
- en: Daemons are associated in most cases with Unix-like operating systems. In Windows,
    you will more commonly encounter the term *Windows service*.
  prefs: []
  type: TYPE_NORMAL
- en: Imagine needing a program to run on every computer in your office, making sure
    everything stays in order. In Kubernetes, that’s where DaemonSets come in. They’re
    like special managers for Pods, ensuring a single copy of a Pod runs on each machine
    (called a Node) in your cluster. Also, in use cases like gRPC, this is crucial
    as gRPC may require a dedicated socket to be created on the node’s filesystem,
    which is easier to manage with one Pod per node.
  prefs: []
  type: TYPE_NORMAL
- en: 'These Pods handle crucial tasks for the entire cluster, like:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Monitoring**: Keeping an eye on the health of each Node'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logging**: Collecting information about what’s happening on each Node and
    the Pods running on them'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage management**: Handling requests for storage space for your applications'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network management**: Cluster components such as kube-proxy and **Container
    Network Interface** (**CNI**) (e.g., Calico) for connectivity'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As your cluster grows (adding more Nodes), DaemonSets automatically add more
    Pods to manage the new machines. The opposite happens when Nodes are removed –
    the Pods on those Nodes are cleaned up automatically. Think of it as a self-adjusting
    team, always making sure every Node has the help it needs.
  prefs: []
  type: TYPE_NORMAL
- en: The following diagram shows the high-level details of a DaemonSet object.
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22019_13_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13.1: DaemonSet in Kubernetes'
  prefs: []
  type: TYPE_NORMAL
- en: In simpler setups, one DaemonSet can handle everything for a particular task
    (like monitoring) across all Nodes. More complex situations might use multiple
    DaemonSets for the same task, but with different settings or resource needs depending
    on the type of Node (think high-powered machines vs. basic ones).
  prefs: []
  type: TYPE_NORMAL
- en: By using DaemonSets, you can ensure your Kubernetes cluster has the essential
    tools running on every Node, keeping things running smoothly and efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: All you have learned in the previous chapters about ReplicaSets, Deployments,
    and StatefulSets applies more or less to the DaemonSet. Its specification requires
    you to provide a Pod template, Pod label selectors, and, optionally, Node selectors
    if you want to schedule the Pods only on a subset of Nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on the case, you may not need to communicate with the DaemonSet from
    other Pods or an external network. For example, if the job of your DaemonSet is
    just to perform a periodic cleanup of the filesystem on the Node, it is unlikely
    you would like to communicate with such Pods. If your use case requires any ingress
    or egress communication with the DaemonSet Pods, then you have the following common
    patterns:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Mapping container ports to host ports**: Since the DaemonSet Pods are guaranteed
    to be singletons on cluster Nodes, it is possible to use mapped host ports. The
    clients must know the Node IP addresses.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pushing data to a different service**: In some cases, it may be enough that
    the DaemonSet is responsible for sending updates to other services without needing
    to allow ingress traffic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Headless service matching DaemonSet Pod label selectors**: This is a similar
    pattern to the case of StatefulSets, where you can use the cluster DNS to retrieve
    multiple `A records` for Pods using the DNS name of the headless service.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Normal service matching DaemonSet Pod label selectors**: Less commonly, you
    may need to reach *any* Pod in the DaemonSet. Using a normal Service object, for
    example, the `ClusterIP` type, will allow you to communicate with a random Pod
    in the DaemonSet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we discussed, DaemonSets ensures that the Pods for essential services will
    run on all or selected nodes. Let us explore in the next section how the scheduling
    works effectively for DaemonSets.
  prefs: []
  type: TYPE_NORMAL
- en: How DaemonSet Pods are scheduled
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: DaemonSets guarantee that a single Pod runs on every eligible node in your Kubernetes
    cluster. The DaemonSet controller creates Pods with node affinity rules targeting
    specific nodes. This ensures that Pods for the DaemonSet are only scheduled on
    specific nodes that meet the desired conditions, making it useful for targeting
    certain types of nodes in complex application setups. The default scheduler then
    binds the Pod to the intended node, potentially preempting existing Pods if resources
    are insufficient. While a custom scheduler can be specified, the DaemonSet controller
    ultimately ensures that the Pod placement aligns with the desired node affinity.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn how you can check the DaemonSet resources
    in the Kubernetes cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Checking DaemonSets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Once you deploy a Kubernetes cluster, you might already be using some of the
    DaemonSets deployed as part of the Kubernetes or cluster support components, such
    as the DNS service or CNI.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Once the cluster is created, verify the nodes in the cluster as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let us check if any DaemonSet is available in the freshly installed system:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: If you are following the same method to create a `minikube` cluster, you will
    see a similar output with `calico-node` and `kube-proxy`, which are deployed as
    DaemonSets. (You can also install Calico in your other Kubernetes clusters and
    follow the remaining steps here.) You might have already noticed that we have
    enabled Calico as the CNI plugin in the `minikube` cluster earlier. Calico, when
    used for Kubernetes networking, is typically deployed as a DaemonSet.
  prefs: []
  type: TYPE_NORMAL
- en: Ignore the `kube-proxy` DaemonSet for now as `minikube` runs kube-proxy as a
    DaemonSet. This guarantees that `kube-proxy`, which is responsible for managing
    network traffic within the cluster, is always up and running on every machine
    in your `minikube` environment.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let us check the Pods deployed by the `calico-node` DaemonSet.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'From this output, we can see that:'
  prefs: []
  type: TYPE_NORMAL
- en: Calico Pods are deployed across all `minikube` nodes. The Pods reside on different
    nodes, which correspond to your `minikube` virtual machines (`minikube`, `minikube-m02`,
    and `minikube-m03`). This suggests Calico is using a DaemonSet to ensure a Pod
    is running on each node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Pod `calico-kube-controllers-ddf655445-jx26x` is the controller of the Calico
    CNI.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Since the Calico DaemonSet is installed by `minikube` in this case, we will
    not explore much on that side. But in the next section, we will learn how to deploy
    a DaemonSet from scratch and explore it in detail.
  prefs: []
  type: TYPE_NORMAL
- en: Creating and managing DaemonSets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In order to demonstrate how DaemonSets work, we will use **Fluentd** Pods. Fluentd
    is a popular open-source log aggregator that centralizes log data from various
    sources. It efficiently collects, filters, and transforms log messages before
    forwarding them to different destinations for analysis and storage.
  prefs: []
  type: TYPE_NORMAL
- en: To access the DaemonSet endpoints, we will use a *headless* service, similar
    to what we did for StatefulSet in *Chapter 12*, *StatefulSet – Deploy Stateful
    Applications*. Most of the real use cases of DaemonSets are rather complex and
    involve mounting various system resources to the Pods. We will keep our DaemonSet
    example as simple as possible to show the principles.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you would like to work on another example of a DaemonSet, we have provided
    a working version of Prometheus `node-exporter` deployed as a DaemonSet behind
    a headless Service: `node-exporter.yaml`. When following the guide in this section,
    the only difference is that you need to use `node-exporter` as the Service name,
    use port `9100`, and append the `/metrics` path for requests sent using `wget`.
    This DaemonSet exposes Node metrics in *Prometheus data model* format on port
    `9100` under the `/metrics` path.'
  prefs: []
  type: TYPE_NORMAL
- en: We will now go through all the YAML manifests required to create our DaemonSet
    and apply them to the cluster.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a DaemonSet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As a best practice, let us use the declarative way to create the DaemonSet for
    our hands-on practice. First, let’s take a look at the DaemonSet YAML manifest
    file named `Fluentd-daemonset.yaml`.
  prefs: []
  type: TYPE_NORMAL
- en: The first part of the YAML is for creating a separate namespace for logging.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: After that, we have our DaemonSet declaration details as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'The first part of the preceding file contains the `metadata` and Pod label
    `selector` for the DaemonSet, quite similar to what you have seen in Deployments
    and StatefulSets. In the second part of the file, we present the Pod template
    that will be used by the DaemonSet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the structure of the DaemonSet spec is similar to what you
    know from Deployments and StatefulSets. The general idea is the same; you need
    to configure the Pod template and use a proper label selector to match the Pod
    labels. Note that you do *not* see the `replicas` field here, as the number of
    Pods running in the cluster will be dependent on the number of Nodes in the cluster.
    The DaemonSet specification has two main components:'
  prefs: []
  type: TYPE_NORMAL
- en: '`spec.selector`: A label selector, which defines how to identify Pods that
    the DaemonSet owns. This can include *set-based* and *equality-based* selectors.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`spec.template`: This defines the template for Pod creation. Labels used in
    `metadata` must match the `selector`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is also common to specify `.spec.template.spec.nodeSelector` or `.spec.template.spec.tolerations`
    in order to control the Nodes where the DaemonSet Pods are deployed. We will cover
    Pod scheduling in detail in *Chapter 19*, *Advanced Techniques for Scheduling
    Pods*. Additionally, you can specify `.spec.updateStrategy`, `.spec.revisionHistoryLimit`,
    and `.spec.minReadySeconds`, which are similar to what you have learned about
    Deployment objects.
  prefs: []
  type: TYPE_NORMAL
- en: If you run hybrid Linux-Windows Kubernetes clusters, one of the common use cases
    for Node selectors or Node affinity for DaemonSets is ensuring that the Pods are
    scheduled only on Linux Nodes or only on Windows Nodes. This makes sense as the
    container runtime and operating system are very different between such Nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Also, notice the volume mounting lines where the Fluentd pods will get access
    to the `/var/log` directory of the host (where the Pod is running) so that Fluentd
    can process the data and send it to the logging aggregator.
  prefs: []
  type: TYPE_NORMAL
- en: Please note that in actual Deployment, we need to provide the target Elasticsearch
    servers to the Fluentd Pods so that Fluentd can send the logs. In our demonstration,
    we are not covering the Elasticsearch setup and you may ignore this part for now.
  prefs: []
  type: TYPE_NORMAL
- en: It is possible to pass such parameters via environment variables to the containers
    as follows. (Refer to the `fluentd-daemonset.yaml` to learn more.)
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'We have all the required YAML manifest files for our demonstration and we can
    proceed with applying the manifests to the cluster. Please follow these steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `fluentd-elasticsearch` DaemonSet using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, you can use the `kubectl describe` command to observe the creation of
    the DaemonSet:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Alternatively, you can use `ds` as an abbreviation for `daemonset` when using
    the `kubectl` commands.
  prefs: []
  type: TYPE_NORMAL
- en: 'Use the `kubectl get pods` command with the `-w` option and you can see that
    there will be one Pod scheduled for each of the Nodes in the cluster, as shown
    below:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In our case, we have three Nodes in the cluster, so exactly three Pods have
    been created.
  prefs: []
  type: TYPE_NORMAL
- en: We have successfully deployed the DaemonSet and we can now verify that it works
    as expected. Ensure that the Fluentd Pods are able to access the Kubernetes node
    log files. To confirm that, log in to one of the Fluentd Pods and check the `/var/log`
    directory.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: This demonstrates the most important principles underlying how DaemonSet Pods
    are scheduled in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: It is best practice to use appropriate **taints** and **tolerations** for the
    nodes to implement DaemonSets. We will learn about taints and tolerations in *Chapter
    19*, *Advanced Techniques for Scheduling Pods*.
  prefs: []
  type: TYPE_NORMAL
- en: Let us learn about some advanced configurations for the DaemonSet in the next
    section.
  prefs: []
  type: TYPE_NORMAL
- en: Prioritizing critical DaemonSets in Kubernetes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When managing critical system components using DaemonSets in Kubernetes, ensuring
    their uninterrupted operation is crucial. Here’s how to leverage Pod priority
    and PriorityClasses to guarantee these essential Pods aren’t disrupted by lower-priority
    tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes assigns a priority level to each Pod, determining its relative importance
    within the cluster. Higher-priority Pods are considered more significant compared
    to lower-priority ones.
  prefs: []
  type: TYPE_NORMAL
- en: By assigning a higher `PriorityClass` to your DaemonSet, you elevate the importance
    of its Pods. This ensures these critical Pods are not preempted by the scheduler
    to make way for lower-priority Pods when resource constraints arise.
  prefs: []
  type: TYPE_NORMAL
- en: A PriorityClass defines a specific priority level for Pods. Values in this class
    can range from negative integers to a maximum of 1 billion. Higher values represent
    higher priority.
  prefs: []
  type: TYPE_NORMAL
- en: A sample YAML definition for the **PriorityClass** is given below.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Once you have created the PriorityClass, you can use the same in the DaemonSet
    configuration as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: For reference, system components like kube-proxy and cluster CNI (Calico) often
    utilize the built-in `system-node-critical` PriorityClass. This class possesses
    the highest priority, ensuring these vital Pods are never evicted under any circumstances.
  prefs: []
  type: TYPE_NORMAL
- en: We will now show how you can modify the DaemonSet to roll out a new version
    of a container image for the Pods.
  prefs: []
  type: TYPE_NORMAL
- en: Modifying a DaemonSet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Updating a DaemonSet can be done in a similar way as for Deployments. If you
    modify the *Pod template* of the DaemonSet, this will trigger a *rollout* of a
    new revision of DaemonSet according to its `updateStrategy`. There are two strategies
    available:'
  prefs: []
  type: TYPE_NORMAL
- en: '`RollingUpdate`: The default strategy, which allows you to roll out a new version
    of your daemon in a controlled way. It is similar to rolling updates in Deployments
    in that you can define `.spec.updateStrategy.rollingUpdate.maxUnavailable` to
    control how many Pods in the clusters are unavailable at most during the rollout
    (defaults to `1`) and `.spec.minReadySeconds` (defaults to `0`). It is guaranteed
    that, *at most, one* Pod of DaemonSet will be in a running state on each node
    in the cluster during the rollout process.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OnDelete`: This strategy implements the legacy behavior of StatefulSet updates
    prior to Kubernetes 1.6\. In this type of strategy, the DaemonSet will *not* automatically
    update the Pod by recreating them. You need to manually delete a Pod on a Node
    in order to get the new Pod template applied. This is useful in scenarios when
    you need to do additional manual actions or verifications before proceeding to
    the next Node.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The rollout of a new DaemonSet revision can be controlled in similar ways as
    for a Deployment object. You can use the `kubectl rollout status` command and
    perform *imperative* rollbacks using the `kubectl rollout undo` command. Let’s
    demonstrate how you can *declaratively* update the container image in a DaemonSet
    Pod to a newer version:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Modify the `fluentd-daemonset.yaml` YAML manifest file so that it uses the
    `quay.io/fluentd_elasticsearch/fluentd:v4.7.5` container image in the template:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Apply the manifest file to the cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Immediately after that, use the `kubectl rollout status` command to see the
    progress in real time:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Similarly, using the `kubectl describe` command, you can see events for the
    DaemonSet that exactly show what the order was of the Pod recreation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You can see that the Pods were replaced one by one.
  prefs: []
  type: TYPE_NORMAL
- en: You can change the DaemonSet container image *imperatively* using the `kubectl
    set image ds fluentd-elasticsearch fluentd-elasticsearch=quay.io/fluentd_elasticsearch/fluentd:v4.7.5
    -n logging` command. This approach is recommended only for non-production scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, the DaemonSet will automatically create Pods if a new Node joins
    the cluster (providing that it matches the selector and affinity parameters).
    If a Node is removed from the cluster, the Pod will also be terminated. The same
    will happen if you modify the labels or taints on a Node so that it matches the
    DaemonSet – a new Pod will be created for that Node. If you modify the labels
    or taints for a Node in a way that no longer matches the DaemonSet, the existing
    Pod will be terminated.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will learn how to roll back a DaemonSet update.
  prefs: []
  type: TYPE_NORMAL
- en: Rolling back the DaemonSet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As we learned in the previous chapters, it is also possible to roll back the
    DaemonSet using the `kubectl rollback` command as follows.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: However, it is highly recommended to update the YAML and apply configurations
    in a declarative method for the production environments.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will show how you can delete a DaemonSet.
  prefs: []
  type: TYPE_NORMAL
- en: Deleting a DaemonSet
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In order to delete a DaemonSet object, there are two possibilities:'
  prefs: []
  type: TYPE_NORMAL
- en: Delete the DaemonSet together with the Pods that it owns.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Delete the DaemonSet and leave the Pods unaffected.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To delete the DaemonSet together with Pods, you can use the regular `kubectl
    delete` command as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: You will see that the Pods will first get terminated and then the DaemonSet
    will be deleted.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, if you would like to delete just the DaemonSet, you need to use the `--cascade=orphan`
    option with `kubectl delete`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: After this command, if you inspect which Pods are in the cluster, you will still
    see all the Pods that were owned by the `fluentd-elasticsearch` DaemonSet.
  prefs: []
  type: TYPE_NORMAL
- en: If you are draining a node using the `kubectl drain` command and this node is
    running Pods owned by a DaemonSet, you need to pass the `--ignore-daemonsets`
    flag to drain the node completely.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s now take a look at the most common use cases for DaemonSets in Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Common use cases for DaemonSets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'At this point, you may wonder what is the actual use of the DaemonSet and what
    the real-life use cases are for this Kubernetes object. In general, DaemonSets
    are used either for very fundamental functions of the cluster, without which it
    is not usable, or for helper workloads performing maintenance or data collection.
    We have summarized the common and interesting use cases for DaemonSets in the
    following points:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Depending on your cluster Deployment, the `kube-proxy` core service may be
    deployed as a DaemonSet instead of a regular operating system service. For example,
    in the case of **Azure Kubernetes Service** (**AKS**), you can see the definition
    of this DaemonSet using the `kubectl describe ds -n kube-system kube-proxy` command.
    This is a perfect example of a backbone service that needs to run as a singleton
    on each Node in the cluster. You can also see an example YAML manifest for `kube-proxy`
    here: [https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/kube-proxy/kube-proxy-ds.yaml](https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/kube-proxy/kube-proxy-ds.yaml).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Another example of fundamental services running as DaemonSets is running an
    installation of **CNI** plugins and agents for maintaining the network in a Kubernetes
    cluster. We have already tested this with the Calico CNI DaemonSet in our `minikube`
    cluster at the beginning of this chapter. Another good example of such a DaemonSet
    is the Flannel agent ([https://github.com/flannel-io/flannel/blob/master/Documentation/kube-flannel.yml](https://github.com/flannel-io/flannel/blob/master/Documentation/kube-flannel.yml)),
    which runs on each Node and is responsible for allocating a subnet lease to each
    host out of a larger, preconfigured address space. This, of course, depends on
    what type of networking is installed on the cluster.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cluster storage daemons will often be deployed as DaemonSets. A good example
    of a commonly used daemon is the **Object Storage Daemon** (**OSD**) for **Ceph**,
    which is a distributed object, block, and file storage platform. OSD is responsible
    for storing objects on the local filesystem of each Node and providing access
    to them over the network. You can find an example manifest file here (as part
    of a Helm chart template): [https://github.com/ceph/ceph-container/blob/master/examples/helm/ceph/templates/osd/daemonset.yaml](https://github.com/ceph/ceph-container/blob/master/examples/helm/ceph/templates/osd/daemonset.yaml).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ingress controllers in Kubernetes are sometimes deployed as DaemonSets. We
    will take a closer look at Ingress in *Chapter 21*, *Advanced Kubernetes: Traffic
    Management, Multi-Cluster Strategies and More*. For example, when you deploy `nginx`
    as an Ingress controller in your cluster, you have an option to deploy it as a
    DaemonSet: [https://github.com/nginxinc/kubernetes-ingress/blob/master/deployments/daemon-set/nginx-ingress.yaml](https://github.com/nginxinc/kubernetes-ingress/blob/master/deployments/daemon-set/nginx-ingress.yaml).
    Deploying an Ingress controller as a DaemonSet is especially common if you do
    Kubernetes cluster deployments on bare-metal servers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Log gathering and aggregation agents are often deployed as DaemonSets. For
    example, `fluentd` can be deployed as a DaemonSet in a cluster. You can find multiple
    YAML manifest files with examples in the official repository: [https://github.com/fluent/fluentd-kubernetes-daemonset](https://github.com/fluent/fluentd-kubernetes-daemonset).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Agents for collecting Node metrics make a perfect use case for Deployment as
    DaemonSets. A well-known example of such an agent is Prometheus `node-exporter`:
    [https://github.com/prometheus-operator/kube-prometheus/blob/main/manifests/nodeExporter-daemonset.yaml](https://github.com/prometheus-operator/kube-prometheus/blob/main/manifests/nodeExporter-daemonset.yaml).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The list goes on – as you can see, a DaemonSet is another building block provided
    for engineers designing the workloads running on Kubernetes clusters. In many
    cases, DaemonSets are the hidden backbone of a cluster that makes it fully operational.
  prefs: []
  type: TYPE_NORMAL
- en: Let us now learn about the recommended best practices for DaemonSet implementations.
  prefs: []
  type: TYPE_NORMAL
- en: DaemonSet best practices
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'DaemonSets are powerful tools in Kubernetes for managing Pods that need to
    run on every node. But to ensure they work as expected, there are some key things
    to keep in mind:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Resource requests and limits**: Briefly mentioning the importance of setting
    appropriate resource requests and limits for DaemonSet Pods can help users manage
    resource allocation effectively. This can help prevent resource starvation for
    other Pods in the cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Clean and separate**: Organize your DaemonSets by placing each one in its
    own separate namespace. This keeps things tidy and simplifies managing resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scheduling smarts**: When creating a DaemonSet, it’s recommended to use `preferredDuringSchedulingIgnoredDuringExecution`
    instead of `requiredDuringSchedulingIgnoredDuringExecution`. The first option
    allows for more flexibility if there aren’t enough nodes available initially.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Wait for readiness** (optional): You can use the `minReadySeconds` setting
    in your Pod schema. This tells Kubernetes to wait a certain amount of time before
    creating new Pods during an update. This helps ensure all existing Pods are healthy
    before adding new ones.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Monitoring and logging**: A quick note about the importance of monitoring
    and logging for DaemonSet Pods can be helpful. This allows users to track the
    health and performance of their DaemonSets and identify any potential issues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Always running**: Make sure your DaemonSet Pods have a **Restart Policy**
    set to `Always` (or leave it unspecified). This guarantees that the Pods automatically
    restart if they ever crash.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**High priority**: Give your DaemonSet Pods a high priority (like `10000`)
    to ensure they get the resources they need and aren’t evicted by other Pods.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Matching labels**: Define a pod selector that matches the labels of your
    DaemonSet template. This ensures the Pods deployed by the DaemonSet are the ones
    you intended.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By following these best practices, you can configure your DaemonSets to run
    smoothly and keep your Kubernetes cluster functioning optimally.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s discuss what possible alternatives there are to using DaemonSets.
  prefs: []
  type: TYPE_NORMAL
- en: Alternatives to DaemonSets
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The reason for using DaemonSets is quite simple – you would like to have exactly
    one Pod with a particular function on each Node in the cluster. However, sometimes,
    you should consider different approaches that may fit your needs better:'
  prefs: []
  type: TYPE_NORMAL
- en: In log-gathering scenarios, you need to evaluate whether you want to design
    your log pipeline architecture based on DaemonSets or the *sidecar* container
    pattern. Both have their advantages and disadvantages, but in general, running
    sidecar containers may be easier to implement and more robust, even though it
    may require more system resources.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you just want to run periodic tasks, and you do not need to do it on each
    Node in the cluster, a better solution can be using **Kubernetes CronJobs**. Again,
    it is important to know what the actual use case is and whether running a separate
    Pod on each Node is a must-have requirement.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Operating system daemons (for example, provided by `systemd` in Ubuntu) can
    be used to do similar tasks as DaemonSets. The drawback of this approach is that
    you cannot manage these native daemons using the same tools as you manage Kubernetes
    clusters with, for example, `kubectl`. But at the same time, you do not have the
    dependency on any Kubernetes service, which may be a good thing in some cases.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Static Pods ([https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/](https://kubernetes.io/docs/tasks/configure-pod-container/static-pod/))
    can be used to achieve a similar result. This type of Pod is created based on
    a specific directory watched by `kubelet` for static manifest files. Static Pods
    cannot be managed using `kubectl` and they are most useful for cluster bootstrapping
    functions.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we can now summarize our knowledge about DaemonSets.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, you have learned how to work with DaemonSets in Kubernetes
    and how they are used to manage special types of workloads or processes that must
    run as a singleton on each Node in the cluster. You first created an example DaemonSet
    and learned what the most important parts of its specification are. Next, you
    practiced how to roll out a new revision of a DaemonSet to the cluster and saw
    how you can monitor the Deployment. Additionally, we discussed what the most common
    use cases are for this special type of Kubernetes object and what alternatives
    there are that you could consider.
  prefs: []
  type: TYPE_NORMAL
- en: This was the last type of Pod management controller that we discussed in this
    part of the book. In the next part of this book, we will examine some more advanced
    Kubernetes usage, starting with Helm charts and then Kubernetes operators.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'DaemonSet: [https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/](https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Network Policy: [https://minikube.sigs.k8s.io/docs/handbook/network_policy/](https://minikube.sigs.k8s.io/docs/handbook/network_policy/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Fluentd Deployment on Kubernetes: [https://docs.fluentd.org/container-deployment/kubernetes](https://docs.fluentd.org/container-deployment/kubernetes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: )
  prefs: []
  type: TYPE_NORMAL
- en: 'Perform a Rolling Update on a DaemonSet: https://kubernetes.io/docs/tasks/manage-daemon/update-daemon-set/'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code119001106479081656.png)'
  prefs: []
  type: TYPE_IMG
