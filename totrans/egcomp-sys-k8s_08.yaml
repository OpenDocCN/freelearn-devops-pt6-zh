- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Observability and Traffic Splitting Using Linkerd
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Linkerd进行可观察性和流量分流
- en: Observability is important when you develop microservices or applications using
    containers, as it provides insights into complex systems. Monitoring mechanisms,
    analytics, and observability give you an idea of how your applications will work
    in production as a system. In production, observability provides logging, metrics,
    and traces of how services interact with one another to provide functionality.
    Service meshes are often used to implement observability in your services. A **service
    mesh** is a powerful tool that helps you to implement observability and other
    functionalities such as retries or timeout management, without modifying your
    applications. This chapter discusses **golden metrics**, commonly used metrics
    for understanding systems, how to implement observability using Linkerd for an
    application with an ingress controller, and how to implement traffic routing using
    a sample application.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用容器开发微服务或应用程序时，可观察性非常重要，因为它提供了对复杂系统的洞察。监控机制、分析和可观察性可以让你了解应用程序在生产环境中作为一个系统如何运行。在生产环境中，可观察性提供日志、指标和追踪，以便了解服务如何相互交互以提供功能。服务网格通常用于在服务中实现可观察性。**服务网格**是一种强大的工具，它帮助你实现可观察性及其他功能，如重试或超时管理，而无需修改应用程序。本章讨论了**黄金指标**，即用于理解系统的常用指标，如何使用Linkerd为带有入口控制器的应用程序实现可观察性，以及如何使用示例应用程序实现流量路由。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: Observability, monitoring, and analytics
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 可观察性、监控和分析
- en: Introduction to service meshes and Linkerd
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格和Linkerd简介
- en: Implementing observability and traffic splitting with Linkerd
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Linkerd实现可观察性和流量分流
- en: Testing observability and traffic splitting with Linkerd
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用Linkerd测试可观察性和流量分流
- en: Uninstalling Linkerd
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卸载Linkerd
- en: Ideas to implement using service meshes
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用服务网格实现的思路
- en: Technical requirements
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, to implement observability with Linkerd, you will need the
    following:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，要实现Linkerd的可观察性，你需要以下内容：
- en: A single or multi-node K3s cluster using ARM devices with MetalLB installed
    and with the option to avoid Traefik being installed as the default ingress controller.
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用ARM设备的单节点或多节点K3s集群，安装了MetalLB，并且可以选择避免将Traefik作为默认的入口控制器进行安装。
- en: Kubectl configured to be used in your local machine to avoid using the `--kubeconfig`
    parameter.
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 已在本地机器上配置的Kubectl，以避免使用`--kubeconfig`参数。
- en: Helm command installed.
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 安装Helm命令。
- en: Clone the repository at [https://github.com/PacktPublishing/Edge-Computing-Systems-with-Kubernetes/tree/main/ch8](https://github.com/PacktPublishing/Edge-Computing-Systems-with-Kubernetes/tree/main/ch8)
    if you want to run the YAML configuration by using `kubectl apply` instead of
    copying the code from the book. Take a look at the `yaml` directory for the YAML
    examples, inside the `ch8` directory.
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如果你想通过使用`kubectl apply`来运行YAML配置，而不是从书中复制代码，请克隆[https://github.com/PacktPublishing/Edge-Computing-Systems-with-Kubernetes/tree/main/ch8](https://github.com/PacktPublishing/Edge-Computing-Systems-with-Kubernetes/tree/main/ch8)中的代码仓库。查看`ch8`目录中的`yaml`目录，获取YAML示例。
- en: We are going to install Linkerd to implement observability and traffic splitting
    on this cluster. So, let’s get started with the basic theory to understand the
    benefits of observability and how to implement it.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将安装Linkerd，以便在此集群上实现可观察性和流量分流。那么，让我们从基础理论开始，理解可观察性的好处以及如何实现它。
- en: Observability, monitoring, and analytics
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 可观察性、监控和分析
- en: To start, let’s get familiar with the observability concept. Peter Waterhouse
    mentioned, in his article in *The New Stack*, that "*observability is a measure
    of how well internal states of a system can be inferred from knowledge of its
    external outputs*." He also mentioned that observability is more of a property
    of a system and not something that you actually do.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们熟悉可观察性这一概念。Peter Waterhouse在他的*The New Stack*文章中提到，“*可观察性是衡量如何通过了解系统的外部输出，推断系统内部状态的能力*。”他还提到，可观察性更像是系统的一个属性，而不是你实际做的事情。
- en: 'There are two concepts that are close to each other in this context: monitoring
    and observability. In Steve Waterworth’s article, available at [dzone.com](http://dzone.com),
    he mentioned this relation with the phrase, "*If you are observable, I can monitor
    you*."'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个背景下，有两个概念是密切相关的：监控和可观察性。在Steve Waterworth的文章中（可在[dzone.com](http://dzone.com)查看），他通过一句话提到这种关系，“*如果你是可观察的，我就能监控你*。”
- en: What this means is that observability is achieved when data about systems is
    managed. Monitoring, on the other hand, it is the actual task of collecting and
    displaying this data. Finally, the analysis occurs after collecting data with
    a monitoring tool, and you perform it either manually or automatically.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着，当系统数据得到管理时，就实现了可观察性。另一方面，监控是收集和显示这些数据的实际任务。最后，分析发生在使用监控工具收集数据之后，且可以手动或自动进行。
- en: 'This relationship is represented by the Pyramid of Power:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这种关系通过权力金字塔表示：
- en: '![Figure 8.1 – Pyramid of Power'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.1 – 权力金字塔'
- en: '](img/B16945_08_01.jpg)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16945_08_01.jpg)'
- en: Figure 8.1 – Pyramid of Power
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.1 – 权力金字塔
- en: The Pyramid of Power represents how analysis and monitoring are the base to
    implement observability. Together, they can bring the property to know the state
    of your system; this is what we call observability. Service meshes give observability
    to the system by measuring metrics that reflect the state of the system. These
    metrics are called golden metrics. Let’s explore golden metrics in the next section.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 权力金字塔表示了分析和监控是实现可观察性的基础。它们共同作用，能提供了解系统状态的能力；这就是我们所说的可观察性。服务网格通过度量反映系统状态的指标来赋予系统可观察性。这些指标被称为黄金指标。让我们在接下来的部分中探讨黄金指标。
- en: Golden metrics
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 黄金指标
- en: Golden metrics were first introduced in the Google *Site Reliability Engineering*
    book and were defined as the minimum metrics required to monitor services. This
    is how the Pyramid of Power gets a place in the discussion about monitoring and
    observability. These metrics were also defined as a model, as a foundation for
    building monitoring around applications.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 黄金指标首次出现在谷歌的《*站点可靠性工程*》一书中，并被定义为监控服务所需的最小指标。这也是权力金字塔在监控和可观察性讨论中占据一席之地的原因。这些指标还被定义为一种模型，作为围绕应用程序构建监控的基础。
- en: According to the Linkerd service mesh glossary web page, golden metrics are
    also called **golden signals**; these are the core metrics of application health.
    These metrics are defined or based on latency, traffic volume, error rate, and
    saturation. With these metrics, you can figure out the health of your application
    to finally build the property of observability in your applications and system.
    Golden metrics are the base for monitoring services and building observable systems.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 Linkerd 服务网格词汇网页，黄金指标也叫**黄金信号**；这些是应用健康的核心指标。这些指标是基于延迟、流量量、错误率和饱和度来定义的。通过这些指标，您可以判断应用程序的健康状况，最终在您的应用程序和系统中建立可观察性的特性。黄金指标是监控服务和构建可观察系统的基础。
- en: Let’s explore, in the next section, how service meshes implement these golden
    metrics to bring observability to your system.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们在接下来的部分中探讨，服务网格是如何实现这些黄金指标，以便为您的系统带来可观察性。
- en: Introduction to service meshes and Linkerd
  id: totrans-30
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 服务网格简介与 Linkerd
- en: George Mirando, in his book, *The Service Mesh*, says that a service mesh "*is
    a dedicated infrastructure layer for handling service-to-service communication
    in order to make it visible, manageable, and controlled. The exact details of
    its architecture vary between implementations, but generally speaking, every service
    mesh is implemented as a series of interconnected network proxies designed to
    better manage service traffic*." In general, we can adopt the idea of a service
    mesh being built by this interconnected network of proxies that provides manageable,
    stable, and controlled service-to-service communication.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: George Mirando 在他的书《*服务网格*》中说，服务网格“*是一个专门的基础设施层，用于处理服务间通信，以便使其可见、可管理和可控制。它的架构的具体细节在不同的实现中有所不同，但一般来说，每个服务网格都实现为一系列互联的网络代理，旨在更好地管理服务流量*。”一般来说，我们可以采纳这样的观点，即服务网格是通过这些互联的网络代理构建的，提供可管理、稳定和受控的服务间通信。
- en: 'Now, let’s see how this is implemented, starting with the explanation given
    in the following diagram:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们看看如何实现这一点，首先从下面的图示开始解释：
- en: '![Figure 8.2 – Service mesh implementation with a sidecar container'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '![图8.2 – 带侧车容器的服务网格实现'
- en: '](img/B16945_08_02.jpg)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16945_08_02.jpg)'
- en: Figure 8.2 – Service mesh implementation with a sidecar container
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 图8.2 – 带侧车容器的服务网格实现
- en: 'Sidecar is a design pattern used on distributed systems that only have a single
    node. This pattern is commonly used in Kubernetes when deploying applications
    that use multiple containers. In this context, the sidecar pattern is made with
    two containers; the first container contains the application container (which
    is the core container), and the second sidecar container is a proxy that provides
    functionalities for a reliable network for your application, and both live inside
    a pod (which is an abstraction of a group of containers in Kubernetes for an application).
    This pod lives inside a data plane that contains all the services interconnected
    by proxies. To exemplify this, let’s look at the following diagram:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Sidecar 是一种在仅有单个节点的分布式系统中使用的设计模式。在 Kubernetes 中部署使用多个容器的应用程序时，通常会使用这种模式。在这个上下文中，sidecar
    模式由两个容器组成；第一个容器包含应用程序容器（即核心容器），第二个 sidecar 容器是一个代理，为您的应用程序提供可靠网络功能，且这两个容器都位于一个
    Pod 内（Pod 是 Kubernetes 中对一组容器的抽象）。这个 Pod 位于数据平面内，数据平面包含所有通过代理互联的服务。为了说明这一点，让我们看看以下图示：
- en: '![Figure 8.3 – Service mesh control plane and data plane'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.3 – 服务网格控制平面与数据平面'
- en: '](img/B16945_08_03.jpg)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16945_08_03.jpg)'
- en: Figure 8.3 – Service mesh control plane and data plane
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – 服务网格控制平面与数据平面
- en: These proxies ask the control plane what to do with the incoming traffic, for
    example, block or encrypt the traffic. The control plane also evaluates and decides
    the corrective action to run in the proxies, such as a retry or redirect if a
    timeout occurs. The control plane contains rules to be applied to each service
    connect across the mesh. Collecting data to provide golden metrics makes the services
    observable. Some service meshes also provide a basic UI to manage all these service
    mesh functionalities.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这些代理向控制平面询问如何处理传入的流量，例如，阻止或加密流量。控制平面还会评估并决定在代理中执行的纠正措施，例如在超时发生时进行重试或重定向。控制平面包含应用于每个服务的规则，这些规则会贯穿整个网格。收集数据以提供黄金指标使得服务具有可观察性。一些服务网格还提供一个基本的
    UI 来管理所有这些服务网格功能。
- en: 'The need for service meshes exists because of wrong assumptions regarding distributed
    systems, such as the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 服务网格的需求存在是因为对分布式系统的错误假设，例如以下内容：
- en: The network is reliable.
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络可靠。
- en: Latency is zero.
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 延迟为零。
- en: Bandwidth is infinite.
  id: totrans-44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 带宽是无限的。
- en: The network is secure.
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络是安全的。
- en: Topology doesn’t change.
  id: totrans-46
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拓扑结构不变。
- en: There is one administrator.
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 只有一个管理员。
- en: The transport cost is zero.
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 传输成本为零。
- en: The network is homogeneous.
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网络是同质的。
- en: Service meshes exist to address all the wrong assumptions, helping to manage
    distributed systems from the logic in your application code and creating a reliable
    network for your application. In general, service meshes provide this reliability
    by just injecting a proxy as a sidecar without modifying the code of your application.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 服务网格的存在是为了应对所有关于分布式系统的错误假设，帮助管理应用程序代码中的逻辑，并为应用程序创建可靠的网络。一般来说，服务网格通过仅仅注入代理作为
    sidecar，而不修改应用程序代码，来提供这种可靠性。
- en: Finally, the relationship between service meshes and observability is that these
    proxies can generate the golden metrics when the proxies intercept network traffic,
    providing a graphical dashboard to provide a way to visualize the state of your
    applications; in other words, creating the observability property for your system.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，服务网格与可观察性之间的关系在于，当代理拦截网络流量时，这些代理可以生成黄金指标，提供一个图形化仪表盘来可视化您的应用程序状态；换句话说，创建系统的可观察性属性。
- en: Linkerd service mesh
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Linkerd 服务网格
- en: 'Linkerd is a service designed to run on Kubernetes. It provides debugging,
    observability, reliability, and security to your applications deployed on Kubernetes
    without modifying your application’s source code. So, Linkerd not only provides
    observability but also provides more features, such as the following:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: Linkerd 是一个设计用于在 Kubernetes 上运行的服务。它为部署在 Kubernetes 上的应用程序提供调试、可观察性、可靠性和安全性，而无需修改应用程序的源代码。因此，Linkerd
    不仅提供可观察性，还提供更多功能，诸如：
- en: HTTP, HTTP/2, and gRPC proxying
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: HTTP、HTTP/2 和 gRPC 代理
- en: Retries and timeouts
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重试和超时
- en: Telemetry and monitoring
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遥测和监控
- en: Load balancing
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 负载均衡
- en: Authorization policy
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 授权策略
- en: Automatic proxy injection
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 自动代理注入
- en: Distributed tracing
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分布式追踪
- en: Fault injection
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 故障注入
- en: Traffic split
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流量拆分
- en: Service profiles
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务配置文件
- en: Multi-cluster communication
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多集群通信
- en: Linkerd is also a fully open source software, part of the graduated projects
    of the **Cloud Native Computing Foundation** (**CNCF**). Linkerd is built by Buoyant.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Linkerd 也是一款完全开源的软件，属于 **Cloud Native Computing Foundation**（**CNCF**）的毕业项目之一。Linkerd
    由 Buoyant 开发。
- en: As we explored in the introduction to service meshes, Linkerd works with a data
    plane and a control plane, and it has the Linkerd CLI to manage its installation.
    It also comes with a UI to explore the different graphics that show golden metrics
    for your injected services.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在服务网格介绍中探讨的那样，Linkerd 通过数据平面和控制平面工作，并且具有 Linkerd CLI 来管理其安装。它还配有一个 UI，用于查看展示注入服务的黄金指标的各种图形。
- en: In order to use Linkerd, first, you have to inject your application with the
    Linkerd proxy using the Linkerd CLI, and then Linkerd will be ready to start collecting
    metrics and enable your application to communicate with other inject services
    across the data plane; and, of course, Linkerd will be ready to configure your
    application with all its features such as traffic splitting.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了使用 Linkerd，首先，你需要通过 Linkerd CLI 将你的应用程序注入 Linkerd 代理中，然后 Linkerd 就可以开始收集指标并使你的应用程序能够通过数据平面与其他注入的服务进行通信；当然，Linkerd
    还将准备好使用所有功能来配置你的应用程序，例如流量分配。
- en: Linkerd was designed to be fast without consuming a lot of resources and to
    be easy to use compared to other service meshes such as **Istio**. Istio includes
    a full package of tools for implementing not only a service mesh functionality
    but also tracing and ingress controller functionalities, which could be too much
    for some solutions. Linkerd reduces the complexity, and it was built to work as
    a modular service mesh piece of software that can integrate with your current
    technology solution stack to add an observability layer to your system. Linkerd
    meets edge computing requirements supporting ARM architectures and low resource
    consumption and is simple to use. In this way, Linkerd could be an option to look
    at before considering another solution based on Envoy such as Istio.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: Linkerd 设计之初便注重速度和低资源消耗，相比于其他服务网格（如 **Istio**），其易用性更强。Istio 包括一整套工具，不仅实现了服务网格功能，还提供了追踪和入口控制器功能，这对于一些解决方案来说可能过于复杂。而
    Linkerd 简化了复杂性，旨在作为一个模块化的服务网格软件，可以与当前的技术解决方案栈集成，为系统添加可观测性层。Linkerd 满足边缘计算需求，支持
    ARM 架构、低资源消耗，并且易于使用。这样，在考虑基于 Envoy 的其他解决方案（如 Istio）之前，Linkerd 可能是一个值得关注的选项。
- en: It’s important to mention that, because service meshes work using proxies, some
    ingress controllers or cloud native proxies could match your needs before choosing
    a full service mesh solution such as Traefik, Emissary, and Contour. Some important
    features to consider while picking a service mesh or a cloud native proxy are
    security and rate limit implementations. You can explore some articles comparing
    these solutions in the *Further reading* section. But now, it’s time to understand
    how to implement observability and traffic splitting in the next section.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 需要特别提到的是，由于服务网格通过代理工作，一些入口控制器或云原生代理在选择完整的服务网格解决方案（如 Traefik、Emissary 和 Contour）之前，可能会更符合你的需求。在选择服务网格或云原生代理时，一些重要的考虑因素包括安全性和速率限制实现。你可以在
    *进一步阅读* 部分查找一些对比这些解决方案的文章。但现在，是时候理解如何在接下来的章节中实现可观测性和流量分配了。
- en: Implementing observability and traffic splitting with Linkerd
  id: totrans-70
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Linkerd 实现可观测性和流量分配
- en: 'To explain how we are going to use Linkerd for observability and traffic splitting,
    let’s explore the following diagram:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 为了说明我们如何使用 Linkerd 实现可观测性和流量分配，让我们来看看以下的图示：
- en: '![Figure 8.4 – Traffic splitting with Linkerd'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.4 – 使用 Linkerd 进行流量分配'
- en: '](img/B16945_08_04.jpg)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16945_08_04.jpg)'
- en: Figure 8.4 – Traffic splitting with Linkerd
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 使用 Linkerd 进行流量分配
- en: First of all, you have to install Linkerd in your Kubernetes cluster. For this
    small scenario, we are going to use two deployments. The first deployment is a
    simple API deployment that returns the message *Meshed application app1 with Linkerd*,
    and the second, a deployment that always returns error code `500`.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，你需要在 Kubernetes 集群中安装 Linkerd。对于这个小场景，我们将使用两个部署。第一个部署是一个简单的 API 部署，它返回消息
    *Meshed application app1 with Linkerd*，第二个部署始终返回错误代码 `500`。
- en: All the traffic will be sent by a client (in our case a loop that sends requests
    to the endpoint of the application) that is a load balancer created by your ingress
    controller service and used by an ingress definition. Every time the ingress object
    detects the traffic, the traffic will be split by 50% to the API deployment and
    50% to the faulty deployment. This is going to simulate an error rate of 50% in
    your requests and 50% for traffic without errors.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 所有流量将由客户端（在我们这个例子中，是一个向应用程序端点发送请求的循环）发送，客户端是由您的 ingress 控制器服务创建的负载均衡器，并由 ingress
    定义使用。每次 ingress 对象检测到流量时，流量将被 50% 分配到 API 部署，50% 分配到故障部署。这将模拟 50% 请求出错和 50% 流量没有错误的错误率。
- en: It’s necessary to inject the ingress, the application, and the faulty deployment
    that simulates errors. In this way, these services will communicate with each
    other using the Linkerd proxy injected on each deployment.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 必须注入 ingress、应用程序和模拟错误的故障部署。这样，这些服务将使用注入在每个部署中的 Linkerd 代理进行相互通信。
- en: While the traffic is moving across the services, it is generating the golden
    metrics that the Linkerd dashboard can visualize with Grafana and other reports
    that Linkerd implements in its UI.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 当流量在各服务之间传输时，它会生成 Linkerd 仪表板可以通过 Grafana 和 Linkerd 在其 UI 中实现的其他报告来可视化的黄金指标。
- en: Now, we are ready to start installing Linkerd in the next section.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好在下一节中开始安装 Linkerd。
- en: Installing Linkerd in your cluster
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在集群中安装 Linkerd
- en: 'So, let’s begin with the installation of Linkerd in your cluster. For this
    you have to follow the next steps:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，让我们从在集群中安装 Linkerd 开始。为此，您需要按照以下步骤进行：
- en: 'First, install the Linkerd CLI by running the following command:'
  id: totrans-82
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，通过运行以下命令安装 Linkerd CLI：
- en: '[PRE0]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'If you are using macOS, you can install the Linkerd CLI using the `brew` command:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您使用的是 macOS，可以通过 `brew` 命令安装 Linkerd CLI：
- en: '[PRE1]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Add the directory where Linkerd is installed to your path:'
  id: totrans-86
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将 Linkerd 安装目录添加到您的路径中：
- en: '[PRE2]'
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Run the following command to load the new path, instead of logging in again
    to load the new path:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 运行以下命令加载新路径，而不是重新登录以加载新路径：
- en: '[PRE3]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'To check whether the cluster fits the requirements to install Linkerd, run
    the following:'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要检查集群是否符合安装 Linkerd 的要求，请运行以下命令：
- en: '[PRE4]'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, install Linkerd by running the following command:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，运行以下命令安装 Linkerd：
- en: '[PRE5]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Now, install the Linkerd dashboard by running the following command:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，通过运行以下命令安装 Linkerd 仪表板：
- en: '[PRE6]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: This command is going to wait while Linkerd is being installed before installing
    the Linkerd dashboard.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 此命令将在安装 Linkerd 后，等待 Linkerd 仪表板的安装。
- en: 'To check whether the installation was successful, run the following:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要检查安装是否成功，请运行以下命令：
- en: '[PRE7]'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'To open the Linkerd dashboard once everything is running, run the following
    command:'
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一旦一切运行起来，要打开 Linkerd 仪表板，请运行以下命令：
- en: '[PRE8]'
  id: totrans-100
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The previous command will expose the Linkerd dashboard inside your device.
    To run this command, we are assuming that the command was run inside the devices,
    so you need to run the following line to resolve the URL `http://web.linkerd-viz.svc.cluster.local:50750`
    to point to your device:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 上述命令将会在您的设备中暴露 Linkerd 仪表板。要运行此命令，我们假设该命令是在设备内部运行的，因此您需要运行以下命令来解析 URL `http://web.linkerd-viz.svc.cluster.local:50750`，并将其指向您的设备：
- en: '[PRE9]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '`IP_CLUSTER` is the IP address of your cluster.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '`IP_CLUSTER` 是您的集群的 IP 地址。'
- en: 'Now, access the next URL to open the dashboard: `http://web.linkerd-viz.svc.cluster.local:50750`.'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，访问以下 URL 打开仪表板：`http://web.linkerd-viz.svc.cluster.local:50750`。
- en: Now, it’s time to install the NGINX ingress controller to be used in this implementation.
    Let’s explore this in the next section.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候安装 NGINX ingress 控制器，以便在此实现中使用。我们将在下一节中详细介绍。
- en: Installing and injecting the NGINX ingress controller
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 安装并注入 NGINX ingress 控制器
- en: 'In this scenario, we are going to use the NGINX ingress controller, using Helm
    to install it by following the given steps:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们将使用 NGINX ingress 控制器，通过 Helm 安装它，按照给定的步骤进行：
- en: 'Create the `nginx-ingress` namespace:'
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 `nginx-ingress` 命名空间：
- en: '[PRE10]'
  id: totrans-109
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Add the NGINX ingress controller Helm chart and update the repositories configured
    in Helm:'
  id: totrans-110
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 添加 NGINX ingress 控制器 Helm 图表并更新 Helm 中配置的仓库：
- en: '[PRE11]'
  id: totrans-111
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Install the NGINX ingress controller:'
  id: totrans-112
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 NGINX ingress 控制器：
- en: '[PRE12]'
  id: totrans-113
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Now, to inject the NGINX ingress controller pod, run the following command:'
  id: totrans-114
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，要注入 NGINX ingress 控制器 Pod，请运行以下命令：
- en: '[PRE13]'
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: Your ingress controller is now ready to be installed and injected. Let’s create
    the applications that we need in the next section.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 您的 ingress 控制器现在已经准备好安装并注入。让我们在下一节中创建所需的应用程序。
- en: Creating a demo application and faulty pods
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建演示应用程序和故障 Pod
- en: 'Now, let’s create our sample application and faulty pod to experiment with
    the traffic splitting feature and get some faulty traffic to simulate error requests.
    For this, follow the given steps:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们创建我们的示例应用程序和故障 Pod，以实验流量分流功能，并获取一些故障流量来模拟错误请求。为此，请按照以下步骤操作：
- en: 'Create the `myapps` namespace for your pods:'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为你的 Pods 创建 `myapps` 命名空间：
- en: '[PRE14]'
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Create the sample application, `app1`, by running the following command:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令创建示例应用程序 `app1`：
- en: '[PRE15]'
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Important Note
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'The `linkerd inject` command inserts the `linkerd.io/inject: enabled` label
    in the `annotations` sections of your deployment or pod. This label is used by
    Linkerd to inject the services with the Linkerd proxy. You can also add this label
    manually in your YAML definitions to have a better approach using declarative
    definitions for your pods and deployments. To customize the code of app1demo check
    the link [https://github.com/sergioarmgpl/containers/tree/main/app1demo](https://github.com/sergioarmgpl/containers/tree/main/app1demo).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`linkerd inject` 命令将在部署或 Pod 的 `annotations` 部分插入 `linkerd.io/inject: enabled`
    标签。Linkerd 使用此标签将服务与 Linkerd 代理进行注入。你也可以在 YAML 定义中手动添加此标签，以便更好地使用声明式定义来管理你的 Pods
    和部署。要自定义 app1demo 的代码，请查看链接 [https://github.com/sergioarmgpl/containers/tree/main/app1demo](https://github.com/sergioarmgpl/containers/tree/main/app1demo)。'
- en: 'To create our faulty pod, we are going to use NGINX as a web server and a custom
    configuration to return a request with a `500` code error in order for Linkerd
    to detect and count the request as an error. For this, let’s create the configuration
    by running the following command:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了创建我们故障的 Pod，我们将使用 NGINX 作为 Web 服务器，并通过自定义配置返回带有`500`代码错误的请求，以便 Linkerd 检测并将该请求计为错误。为此，让我们运行以下命令创建配置：
- en: '[PRE16]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Now, let’s create the deployment that returns a `500` error in port `5000`
    when accessing the pod in the `/` path:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们创建一个在访问 Pod 的 `/` 路径时返回 `500` 错误的部署，并监听 `5000` 端口：
- en: '[PRE17]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Now that our applications have been deployed, let’s configure the services
    for these applications. Let’s start with the `error-injector` service:'
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在我们的应用程序已经部署完成，让我们为这些应用程序配置服务。我们从 `error-injector` 服务开始：
- en: '[PRE18]'
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Now, create the service for your application by running the following command:'
  id: totrans-131
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，通过运行以下命令为你的应用程序创建服务：
- en: '[PRE19]'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Now, let’s use the `app1` service and the other half for `error-injector`,
    so we are going to expect a 50% success rate:'
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，让我们使用 `app1` 服务和另一个 `error-injector` 服务的一半流量，因此我们期望成功率为 50%：
- en: '[PRE20]'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Finally, let’s create our ingress rule to expose the endpoint to send traffic
    to this application using traffic splitting:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，让我们创建 ingress 规则，使用流量分流将流量发送到此应用程序：
- en: '[PRE21]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Important Note
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: Depending on which Kubernetes version you are using, you have to use the syntax
    for your ingress controller definition, *v1beta1* or *v1*. For more information,
    you can check [https://kubernetes.io/docs/concepts/services-networking/ingress](https://kubernetes.io/docs/concepts/services-networking/ingress),
    and change from different Kubernetes versions.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你使用的 Kubernetes 版本，你需要使用适合你 ingress 控制器定义的语法，*v1beta1* 或 *v1*。更多信息，请查看 [https://kubernetes.io/docs/concepts/services-networking/ingress](https://kubernetes.io/docs/concepts/services-networking/ingress)，并根据不同的
    Kubernetes 版本进行更改。
- en: Now, we are ready to test the observability and traffic splitting configured
    with Linkerd. Let’s explore this in the next section.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经准备好测试使用 Linkerd 配置的可观察性和流量分流。让我们在下一部分探索这一点。
- en: Testing observability and traffic splitting with Linkerd
  id: totrans-140
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Linkerd 测试可观察性和流量分流
- en: 'Now, it’s time to test the observability. To start exploring the dashboard
    and see the observability, follow the given steps:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，是时候测试可观察性了。要开始探索仪表盘并查看可观察性，请按照以下步骤进行：
- en: 'Open your dashboard by running the following command:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过运行以下命令打开仪表盘：
- en: '[PRE22]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: This will automatically open the dashboard to the URL `http://localhost:50750`.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 这将自动打开仪表盘，URL 为 `http://localhost:50750`。
- en: 'The dashboard will look as in the following screenshot:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 仪表盘将显示如下截图：
- en: '![Figure 8.5 – Linkerd dashboard'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.5 – Linkerd 仪表盘'
- en: '](img/B16945_08_05.jpg)'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16945_08_05.jpg)'
- en: Figure 8.5 – Linkerd dashboard
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – Linkerd 仪表盘
- en: To load the right information, select the **MYAPPS** namespace in the combo
    box in the left sidebar, and then click on the **Deployments** icon to load the
    **HTTP Metrics** and **TCP Metrics** information.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 为了加载正确的信息，在左侧边栏的组合框中选择 **MYAPPS** 命名空间，然后点击 **Deployments** 图标以加载 **HTTP Metrics**
    和 **TCP Metrics** 信息。
- en: 'To see similar information as the previous dashboard, execute the following
    command to start sending traffic to our deployment:'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 要查看与之前仪表盘类似的信息，请执行以下命令以开始将流量发送到我们的部署：
- en: '[PRE23]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The first command assigns the load balancer IP address that your NGINX ingress
    controller is using as the endpoint to expose services using ingress definitions.
    Then, while the command sends traffic, it also shows the result of each request,
    showing a similar message to the following:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令将负载均衡器的 IP 地址分配给您的 NGINX Ingress 控制器，它作为端点来暴露使用 Ingress 定义的服务。然后，在命令发送流量时，它还会显示每个请求的结果，显示类似以下的消息：
- en: '[PRE24]'
  id: totrans-153
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'Or, the following output error is displayed:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，显示以下输出错误：
- en: '[PRE25]'
  id: totrans-155
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: This is a frequency of 50% for the message and 50% for the error, on average.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个消息的频率为 50% 和错误的频率为 50%，平均而言。
- en: 'If you click on the orange Grafana icon (let’s say, for example, in the **HTTP
    Metrics** section), you will see a similar Grafana graph to the following:'
  id: totrans-157
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果您点击橙色的 Grafana 图标（例如，在 **HTTP 指标** 部分），您将看到类似以下的 Grafana 图表：
- en: '![Figure 8.6 – Grafana Linkerd HTTP Metrics graph'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.6 – Grafana Linkerd HTTP 指标图'
- en: '](img/B16945_08_06.jpg)'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16945_08_06.jpg)'
- en: Figure 8.6 – Grafana Linkerd HTTP Metrics graph
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – Grafana Linkerd HTTP 指标图
- en: In this graph, you can see the golden metrics and the success rate of the application
    for the `app1` deployment, the **requests per second** (**RPS**), and the latency
    of each request; these metrics represent the golden metrics for your application,
    which give you the basic observability feature for your system and your application.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个图表中，您可以看到应用程序 `app1` 部署的黄金指标和成功率，**每秒请求数**（**RPS**）以及每个请求的延迟；这些指标代表了您的应用程序的黄金指标，为您的系统和应用程序提供了基本的可观察性功能。
- en: 'If you click on **Traffic Splits** while the **myapps** namespace is selected,
    you will see a traffic splitting representation like this:'
  id: totrans-162
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果在选择 **myapps** 命名空间时点击 **流量拆分**，您将看到类似这样的流量拆分表示：
- en: '![Figure 8.7 – Linkerd traffic splitting dashboard'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 8.7 – Linkerd 流量拆分仪表盘'
- en: '](img/B16945_08_07.jpg)'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B16945_08_07.jpg)'
- en: Figure 8.7 – Linkerd traffic splitting dashboard
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.7 – Linkerd 流量拆分仪表盘
- en: In this dashboard, you will see, in real time, how the traffic splitting configuration
    sends 50% of the traffic to the `app1` Kubernetes services and 50% to the error
    injector. The red color represents failure requests (requests that return the
    `500` request error code), while the green color represents valid traffic from
    the `app1` service returning a `200` request code. This, in general, gives you
    the live state of your application, which is the goal of implementing observability.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 在此仪表盘中，您将实时看到流量拆分配置如何将 50% 的流量发送到 `app1` Kubernetes 服务，并将 50% 的流量发送到错误注入器。红色代表失败的请求（返回
    `500` 请求错误代码的请求），而绿色代表来自 `app1` 服务的有效流量，返回 `200` 请求代码。这通常会为您提供应用程序的实时状态，这是实现可观察性目标的一部分。
- en: This basic implementation simulates a failure request for an application using
    a service mesh. You can also use the same implementation to split your traffic
    between applications or implement advanced deployment strategies such as blue/green
    deployments. This was a simple use case to implement observability in your applications
    and the power of traffic management from a service mesh. Now, let’s explore some
    useful commands if you want to use Linkerd using the CLI.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 这个基本实现模拟了使用服务网格的应用程序故障请求。您还可以使用相同的实现将流量在应用程序之间拆分，或实施诸如蓝绿部署之类的高级部署策略。这是一个简单的用例，旨在在您的应用程序中实现可观察性，并展示服务网格的流量管理功能。现在，让我们来看看一些有用的命令，如果您希望使用
    CLI 来使用 Linkerd。
- en: Using Linkerd’s CLI
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Linkerd 的 CLI
- en: 'In some cases where no UI is available, maybe for security reasons, it could
    be useful to use the Linkerd CLI. So, let’s explore four basic command-line options:
    `routes`, `top`, `tap`, and `edges`:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，如果没有 UI 可用（可能出于安全原因），使用 Linkerd CLI 可能会很有用。因此，下面我们将探讨四个基本的命令行选项：`routes`、`top`、`tap`
    和 `edges`：
- en: '`routes` shows the current routes that other applications or clients are using
    to access your application. Using our previous scenario as an example, you can
    show the routes of `app1` in the `myapps` namespace with the following command:'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`routes` 显示当前其他应用程序或客户端用于访问您的应用程序的路由。以我们之前的场景为例，您可以使用以下命令显示 `myapps` 命名空间中
    `app1` 的路由：'
- en: '[PRE26]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: '`top` displays the traffic and path of your application. The following command
    is going to show how the ingress controller forwards the traffic to your applications,
    shows a counter to access the `/` path, and shows the success rate of the requests:'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`top` 显示你的应用程序的流量和路径。以下命令将显示入口控制器如何将流量转发到你的应用程序，显示访问`/`路径的计数器，并显示请求的成功率：'
- en: '[PRE27]'
  id: totrans-173
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '`tap` displays the information of the requests in real time for `app1`; for
    this, you have to run the following command:'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`tap` 实时显示 `app1` 请求的信息；为此，你需要运行以下命令：'
- en: '[PRE28]'
  id: totrans-175
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: '`edges` shows a table displaying how your application is connected with other
    injected applications in your cluster, and the source and destiny of each connection.
    For this, you have to run the following command for `app1`:'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`edges` 显示一个表格，展示你的应用程序如何与集群中其他注入的应用程序连接，以及每个连接的源和目的地。为此，你需要运行以下命令来查看 `app1`：'
- en: '[PRE29]'
  id: totrans-177
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: With this, you have an idea of how to use Linkerd with the CLI. Now, let’s move
    to the next section to learn how to uninstall Linkerd.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这个，你大致了解了如何使用 CLI 来操作 Linkerd。现在，让我们进入下一节，学习如何卸载 Linkerd。
- en: Uninstalling Linkerd
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 卸载 Linkerd
- en: 'If you are evaluating Linkerd or doing some management in your clusters, for
    example, it could be useful to uninstall Linkerd. For this, follow the next steps:'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你正在评估 Linkerd 或在集群中进行一些管理工作，例如，卸载 Linkerd 可能会很有用。为此，请按照下列步骤操作：
- en: 'Uninstall support for additional features of Linkerd (called **viz**) as follows:'
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卸载 Linkerd 的附加功能支持（称为**viz**）如下：
- en: '[PRE30]'
  id: totrans-182
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Uninstall the Linkerd control plane. This is going to uninstall the rest of
    the core Linkerd components. For this, run the following command:'
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卸载 Linkerd 控制平面。这将卸载其余的核心 Linkerd 组件。为此，运行以下命令：
- en: '[PRE31]'
  id: totrans-184
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Now, Linkerd is uninstalled from your cluster. To end this chapter, let’s move
    to the last section to explore some useful ideas of where you can use Linkerd.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，Linkerd 已从你的集群中卸载。为了结束这一章，让我们进入最后一节，探讨一些有关你可以使用 Linkerd 的有用想法。
- en: Ideas to implement when using service meshes
  id: totrans-186
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用服务网格时可以实施的想法
- en: 'To end this chapter, here are some ideas of how you can get the advantages
    of using service meshes at the edge. These ideas are not specific to the edge
    and could be used in a common infrastructure:'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 为了结束这一章，以下是一些关于如何在边缘使用服务网格的优势的想法。这些想法不仅限于边缘，也可以应用于常规基础设施：
- en: '**Implement rate limits**: You can use a service mesh to configure some rate
    limits in your applications, managing in this way how much input traffic is accepted.
    There are some awesome projects to implement this, including Linkerd and Envoy-based
    service meshes such as Istio and Ambassador.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**实施速率限制**：你可以使用服务网格在你的应用程序中配置速率限制，从而管理接受多少输入流量。实现这一功能有一些很棒的项目，包括 Linkerd 和基于
    Envoy 的服务网格，如 Istio 和 Ambassador。'
- en: '**Traffic splitting**: You can use this feature of service meshes to implement
    blue/green deployments and canary deployments; an example of this is the implementation
    of Argo Rollouts, which can use Linkerd to implement this kind of deployment strategy.
    You can also implement some chaos engineering tests using service meshes.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**流量拆分**：你可以使用服务网格的这一功能来实现蓝绿部署和金丝雀部署；例如，Argo Rollouts 的实现可以使用 Linkerd 来执行这种部署策略。你还可以使用服务网格进行一些混沌工程测试。'
- en: '**Security policies**: You can use service meshes to restrict traffic and encrypt
    end-to-end traffic. This could be useful to increase the security of your services.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全策略**：你可以使用服务网格来限制流量并加密端到端流量。这对于增强服务的安全性可能非常有用。'
- en: '**Multi-cluster connection**: With a service mesh, you can connect your clusters
    without complex configurations. **Kuma** is a control plane for microservices
    and service meshes that can help you to connect multiple clusters; it was built
    on top of Envoy. You can also do the same using Linkerd and other Envoy-based
    service meshes.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**多集群连接**：使用服务网格，你可以在无需复杂配置的情况下连接多个集群。**Kuma** 是一个面向微服务和服务网格的控制平面，能够帮助你连接多个集群，它建立在
    Envoy 之上。你也可以使用 Linkerd 和其他基于 Envoy 的服务网格来实现同样的功能。'
- en: '**Scaling based on networking**: You can use Prometheus metrics generated by
    service meshes to generate alerts or scale your services. You can also implement
    machine learning models to implement some intelligent scaling. You can use them
    with projects such as **Kubernetes-based Event-Driven Autoscaling** (**KEDA**),
    which reads information from an API to scale your services.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**基于网络的扩展**：你可以使用服务网格生成的 Prometheus 指标来生成警报或扩展你的服务。你还可以实现机器学习模型来进行一些智能扩展。你可以将它们与像
    **基于 Kubernetes 的事件驱动自动扩展**（**KEDA**）这样的项目结合使用，KEDA 从 API 中读取信息来扩展你的服务。'
- en: These are some ideas that you can explore when using service meshes. Now, it’s
    time to finish the chapter.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是你在使用服务网格时可以探索的一些思路。现在，是时候结束本章了。
- en: Summary
  id: totrans-194
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we learned how to implement observability and how to use a
    service mesh to set up traffic splitting. We focused on implementing this scenario
    using Linkerd, running a sample application that shows a message, and using traffic
    splitting. When the application receives the traffic, we showed how to explore
    the different graphics that can be used to get the real-time state of your system.
    We also learned how to use Linkerd with the CLI uninstalled. The chapter ended
    with some implementation ideas to explore when using service meshes and how this
    can impact your system. All of this forms the base to implement observability
    and basic traffic splitting in systems using a Linkerd service mesh. In the next
    chapter, we are going to learn how to implement serverless functions and simple
    event-driven pipelines using Knative.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了如何实现可观察性，以及如何使用服务网格来设置流量拆分。我们专注于使用 Linkerd 实现这一场景，运行一个显示消息的示例应用程序，并使用流量拆分。当应用程序接收到流量时，我们展示了如何探索可以用来获取系统实时状态的不同图形。我们还学习了如何在未安装
    CLI 的情况下使用 Linkerd。本章以一些实施思路作为结束，探讨了使用服务网格时可以探索的内容以及这将如何影响你的系统。所有这些内容构成了使用 Linkerd
    服务网格在系统中实现可观察性和基本流量拆分的基础。在下一章中，我们将学习如何使用 Knative 实现无服务器函数和简单的事件驱动管道。
- en: Questions
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: 'Here are a few questions to validate your new knowledge:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个问题可以验证你新获得的知识：
- en: How do service meshes help you to implement observability?
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格如何帮助你实现可观察性？
- en: What are the features that service meshes provide to systems?
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格为系统提供了哪些功能？
- en: How do service meshes work internally?
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格是如何在内部工作的？
- en: What does Linkerd provide for users implementing observability?
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linkerd 为实施可观察性的用户提供了什么？
- en: How can Linkerd be compared to other service meshes?
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linkerd 如何与其他服务网格进行比较？
- en: What are the common use cases for service meshes?
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格的常见使用案例有哪些？
- en: Further reading
  id: totrans-204
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: 'You can refer to the following resources for more information on the topics
    covered in this chapter:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以参考以下资源，获取本章所涵盖主题的更多信息：
- en: '*Design distributed systems* book, by *Brendan Burns*: [https://learning.oreilly.com/library/view/designing-distributed-systems/9781491983638](https://learning.oreilly.com/library/view/designing-distributed-systems/9781491983638)'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*设计分布式系统* 书籍，*Brendan Burns* 编著：[https://learning.oreilly.com/library/view/designing-distributed-systems/9781491983638](https://learning.oreilly.com/library/view/designing-distributed-systems/9781491983638)'
- en: 'Service mesh pattern: [https://philcalcado.com/2017/08/03/pattern_service_mesh.html](https://philcalcado.com/2017/08/03/pattern_service_mesh.html)'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格模式：[https://philcalcado.com/2017/08/03/pattern_service_mesh.html](https://philcalcado.com/2017/08/03/pattern_service_mesh.html)
- en: '*Golden Signals - Monitoring from first principles*: https://www.squadcast.com/blog/golden-signals-monitoring-from-first-principles'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*黄金信号 - 从基本原理监控*：[https://www.squadcast.com/blog/golden-signals-monitoring-from-first-principles](https://www.squadcast.com/blog/golden-signals-monitoring-from-first-principles)'
- en: 'gRPC official website: [https://grpc.io](https://grpc.io)'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: gRPC 官方网站：[https://grpc.io](https://grpc.io)
- en: 'Service Mesh Interface: [https://smi-spec.io](https://smi-spec.io)'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格接口：[https://smi-spec.io](https://smi-spec.io)
- en: 'Linkerd glossary and useful terms: [https://linkerd.io/service-mesh-glossary](https://linkerd.io/service-mesh-glossary
    )'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Linkerd 术语表和有用的术语：[https://linkerd.io/service-mesh-glossary](https://linkerd.io/service-mesh-glossary)
- en: 'Service meshes quick start and comparisons: [https://servicemesh.es](https://servicemesh.es)'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务网格快速入门与比较：[https://servicemesh.es](https://servicemesh.es)
- en: '*Observability vs. Monitoring*: [https://dzone.com/articles/observability-vs-monitoring](https://dzone.com/articles/observability-vs-monitoring)'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*可观察性 vs. 监控*：[https://dzone.com/articles/observability-vs-monitoring](https://dzone.com/articles/observability-vs-monitoring)'
- en: '*Monitoring and Observability — What’s the Difference and Why Does It Matter?*:
    [https://thenewstack.io/monitoring-and-observability-whats-the-difference-and-why-does-it-matter](https://thenewstack.io/monitoring-and-observability-whats-the-difference-and-why-does-it-matter)'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*监控与可观察性——它们的区别是什么，为什么重要？*: [https://thenewstack.io/monitoring-and-observability-whats-the-difference-and-why-does-it-matter](https://thenewstack.io/monitoring-and-observability-whats-the-difference-and-why-does-it-matter)'
- en: '*The 4 Golden Signals of API Health and Performance in Cloud Native Applications*:
    [https://blog.netsil.com/the-4-golden-signals-of-api-health-and-performance-in-cloud-native-applications-a6e87526e74](https://blog.netsil.com/the-4-golden-signals-of-api-health-and-performance-in-cloud-native-applications-a6e87526e74)'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*云原生应用中的 API 健康与性能的 4 个黄金信号*: [https://blog.netsil.com/the-4-golden-signals-of-api-health-and-performance-in-cloud-native-applications-a6e87526e74](https://blog.netsil.com/the-4-golden-signals-of-api-health-and-performance-in-cloud-native-applications-a6e87526e74)'
- en: 'Linkerd documentation: [https://linkerd.io/docs](https://linkerd.io/docs)'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Linkerd 文档: [https://linkerd.io/docs](https://linkerd.io/docs)'
- en: '*Service Mesh* *&* *Edge Computing Considerations*: [https://sunkur.medium.com/service-mesh-edge-computing-considerations-84126754d17a](https://sunkur.medium.com/service-mesh-edge-computing-considerations-84126754d17a)'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*服务网格* *与* *边缘计算的考虑因素*: [https://sunkur.medium.com/service-mesh-edge-computing-considerations-84126754d17a](https://sunkur.medium.com/service-mesh-edge-computing-considerations-84126754d17a)'
