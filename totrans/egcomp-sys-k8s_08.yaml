- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Observability and Traffic Splitting Using Linkerd
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Observability is important when you develop microservices or applications using
    containers, as it provides insights into complex systems. Monitoring mechanisms,
    analytics, and observability give you an idea of how your applications will work
    in production as a system. In production, observability provides logging, metrics,
    and traces of how services interact with one another to provide functionality.
    Service meshes are often used to implement observability in your services. A **service
    mesh** is a powerful tool that helps you to implement observability and other
    functionalities such as retries or timeout management, without modifying your
    applications. This chapter discusses **golden metrics**, commonly used metrics
    for understanding systems, how to implement observability using Linkerd for an
    application with an ingress controller, and how to implement traffic routing using
    a sample application.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Observability, monitoring, and analytics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Introduction to service meshes and Linkerd
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Implementing observability and traffic splitting with Linkerd
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Testing observability and traffic splitting with Linkerd
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uninstalling Linkerd
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ideas to implement using service meshes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In this chapter, to implement observability with Linkerd, you will need the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: A single or multi-node K3s cluster using ARM devices with MetalLB installed
    and with the option to avoid Traefik being installed as the default ingress controller.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubectl configured to be used in your local machine to avoid using the `--kubeconfig`
    parameter.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Helm command installed.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Clone the repository at [https://github.com/PacktPublishing/Edge-Computing-Systems-with-Kubernetes/tree/main/ch8](https://github.com/PacktPublishing/Edge-Computing-Systems-with-Kubernetes/tree/main/ch8)
    if you want to run the YAML configuration by using `kubectl apply` instead of
    copying the code from the book. Take a look at the `yaml` directory for the YAML
    examples, inside the `ch8` directory.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We are going to install Linkerd to implement observability and traffic splitting
    on this cluster. So, let’s get started with the basic theory to understand the
    benefits of observability and how to implement it.
  prefs: []
  type: TYPE_NORMAL
- en: Observability, monitoring, and analytics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To start, let’s get familiar with the observability concept. Peter Waterhouse
    mentioned, in his article in *The New Stack*, that "*observability is a measure
    of how well internal states of a system can be inferred from knowledge of its
    external outputs*." He also mentioned that observability is more of a property
    of a system and not something that you actually do.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two concepts that are close to each other in this context: monitoring
    and observability. In Steve Waterworth’s article, available at [dzone.com](http://dzone.com),
    he mentioned this relation with the phrase, "*If you are observable, I can monitor
    you*."'
  prefs: []
  type: TYPE_NORMAL
- en: What this means is that observability is achieved when data about systems is
    managed. Monitoring, on the other hand, it is the actual task of collecting and
    displaying this data. Finally, the analysis occurs after collecting data with
    a monitoring tool, and you perform it either manually or automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'This relationship is represented by the Pyramid of Power:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – Pyramid of Power'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16945_08_01.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.1 – Pyramid of Power
  prefs: []
  type: TYPE_NORMAL
- en: The Pyramid of Power represents how analysis and monitoring are the base to
    implement observability. Together, they can bring the property to know the state
    of your system; this is what we call observability. Service meshes give observability
    to the system by measuring metrics that reflect the state of the system. These
    metrics are called golden metrics. Let’s explore golden metrics in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Golden metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Golden metrics were first introduced in the Google *Site Reliability Engineering*
    book and were defined as the minimum metrics required to monitor services. This
    is how the Pyramid of Power gets a place in the discussion about monitoring and
    observability. These metrics were also defined as a model, as a foundation for
    building monitoring around applications.
  prefs: []
  type: TYPE_NORMAL
- en: According to the Linkerd service mesh glossary web page, golden metrics are
    also called **golden signals**; these are the core metrics of application health.
    These metrics are defined or based on latency, traffic volume, error rate, and
    saturation. With these metrics, you can figure out the health of your application
    to finally build the property of observability in your applications and system.
    Golden metrics are the base for monitoring services and building observable systems.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s explore, in the next section, how service meshes implement these golden
    metrics to bring observability to your system.
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to service meshes and Linkerd
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: George Mirando, in his book, *The Service Mesh*, says that a service mesh "*is
    a dedicated infrastructure layer for handling service-to-service communication
    in order to make it visible, manageable, and controlled. The exact details of
    its architecture vary between implementations, but generally speaking, every service
    mesh is implemented as a series of interconnected network proxies designed to
    better manage service traffic*." In general, we can adopt the idea of a service
    mesh being built by this interconnected network of proxies that provides manageable,
    stable, and controlled service-to-service communication.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s see how this is implemented, starting with the explanation given
    in the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Service mesh implementation with a sidecar container'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16945_08_02.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.2 – Service mesh implementation with a sidecar container
  prefs: []
  type: TYPE_NORMAL
- en: 'Sidecar is a design pattern used on distributed systems that only have a single
    node. This pattern is commonly used in Kubernetes when deploying applications
    that use multiple containers. In this context, the sidecar pattern is made with
    two containers; the first container contains the application container (which
    is the core container), and the second sidecar container is a proxy that provides
    functionalities for a reliable network for your application, and both live inside
    a pod (which is an abstraction of a group of containers in Kubernetes for an application).
    This pod lives inside a data plane that contains all the services interconnected
    by proxies. To exemplify this, let’s look at the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Service mesh control plane and data plane'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16945_08_03.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.3 – Service mesh control plane and data plane
  prefs: []
  type: TYPE_NORMAL
- en: These proxies ask the control plane what to do with the incoming traffic, for
    example, block or encrypt the traffic. The control plane also evaluates and decides
    the corrective action to run in the proxies, such as a retry or redirect if a
    timeout occurs. The control plane contains rules to be applied to each service
    connect across the mesh. Collecting data to provide golden metrics makes the services
    observable. Some service meshes also provide a basic UI to manage all these service
    mesh functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: 'The need for service meshes exists because of wrong assumptions regarding distributed
    systems, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The network is reliable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Latency is zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bandwidth is infinite.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The network is secure.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Topology doesn’t change.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is one administrator.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The transport cost is zero.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The network is homogeneous.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service meshes exist to address all the wrong assumptions, helping to manage
    distributed systems from the logic in your application code and creating a reliable
    network for your application. In general, service meshes provide this reliability
    by just injecting a proxy as a sidecar without modifying the code of your application.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the relationship between service meshes and observability is that these
    proxies can generate the golden metrics when the proxies intercept network traffic,
    providing a graphical dashboard to provide a way to visualize the state of your
    applications; in other words, creating the observability property for your system.
  prefs: []
  type: TYPE_NORMAL
- en: Linkerd service mesh
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Linkerd is a service designed to run on Kubernetes. It provides debugging,
    observability, reliability, and security to your applications deployed on Kubernetes
    without modifying your application’s source code. So, Linkerd not only provides
    observability but also provides more features, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: HTTP, HTTP/2, and gRPC proxying
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Retries and timeouts
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Telemetry and monitoring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Load balancing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Authorization policy
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Automatic proxy injection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Distributed tracing
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fault injection
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traffic split
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Service profiles
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-cluster communication
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linkerd is also a fully open source software, part of the graduated projects
    of the **Cloud Native Computing Foundation** (**CNCF**). Linkerd is built by Buoyant.
  prefs: []
  type: TYPE_NORMAL
- en: As we explored in the introduction to service meshes, Linkerd works with a data
    plane and a control plane, and it has the Linkerd CLI to manage its installation.
    It also comes with a UI to explore the different graphics that show golden metrics
    for your injected services.
  prefs: []
  type: TYPE_NORMAL
- en: In order to use Linkerd, first, you have to inject your application with the
    Linkerd proxy using the Linkerd CLI, and then Linkerd will be ready to start collecting
    metrics and enable your application to communicate with other inject services
    across the data plane; and, of course, Linkerd will be ready to configure your
    application with all its features such as traffic splitting.
  prefs: []
  type: TYPE_NORMAL
- en: Linkerd was designed to be fast without consuming a lot of resources and to
    be easy to use compared to other service meshes such as **Istio**. Istio includes
    a full package of tools for implementing not only a service mesh functionality
    but also tracing and ingress controller functionalities, which could be too much
    for some solutions. Linkerd reduces the complexity, and it was built to work as
    a modular service mesh piece of software that can integrate with your current
    technology solution stack to add an observability layer to your system. Linkerd
    meets edge computing requirements supporting ARM architectures and low resource
    consumption and is simple to use. In this way, Linkerd could be an option to look
    at before considering another solution based on Envoy such as Istio.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to mention that, because service meshes work using proxies, some
    ingress controllers or cloud native proxies could match your needs before choosing
    a full service mesh solution such as Traefik, Emissary, and Contour. Some important
    features to consider while picking a service mesh or a cloud native proxy are
    security and rate limit implementations. You can explore some articles comparing
    these solutions in the *Further reading* section. But now, it’s time to understand
    how to implement observability and traffic splitting in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Implementing observability and traffic splitting with Linkerd
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To explain how we are going to use Linkerd for observability and traffic splitting,
    let’s explore the following diagram:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – Traffic splitting with Linkerd'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16945_08_04.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.4 – Traffic splitting with Linkerd
  prefs: []
  type: TYPE_NORMAL
- en: First of all, you have to install Linkerd in your Kubernetes cluster. For this
    small scenario, we are going to use two deployments. The first deployment is a
    simple API deployment that returns the message *Meshed application app1 with Linkerd*,
    and the second, a deployment that always returns error code `500`.
  prefs: []
  type: TYPE_NORMAL
- en: All the traffic will be sent by a client (in our case a loop that sends requests
    to the endpoint of the application) that is a load balancer created by your ingress
    controller service and used by an ingress definition. Every time the ingress object
    detects the traffic, the traffic will be split by 50% to the API deployment and
    50% to the faulty deployment. This is going to simulate an error rate of 50% in
    your requests and 50% for traffic without errors.
  prefs: []
  type: TYPE_NORMAL
- en: It’s necessary to inject the ingress, the application, and the faulty deployment
    that simulates errors. In this way, these services will communicate with each
    other using the Linkerd proxy injected on each deployment.
  prefs: []
  type: TYPE_NORMAL
- en: While the traffic is moving across the services, it is generating the golden
    metrics that the Linkerd dashboard can visualize with Grafana and other reports
    that Linkerd implements in its UI.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are ready to start installing Linkerd in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Installing Linkerd in your cluster
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So, let’s begin with the installation of Linkerd in your cluster. For this
    you have to follow the next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, install the Linkerd CLI by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'If you are using macOS, you can install the Linkerd CLI using the `brew` command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Add the directory where Linkerd is installed to your path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Run the following command to load the new path, instead of logging in again
    to load the new path:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'To check whether the cluster fits the requirements to install Linkerd, run
    the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Next, install Linkerd by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, install the Linkerd dashboard by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This command is going to wait while Linkerd is being installed before installing
    the Linkerd dashboard.
  prefs: []
  type: TYPE_NORMAL
- en: 'To check whether the installation was successful, run the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To open the Linkerd dashboard once everything is running, run the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The previous command will expose the Linkerd dashboard inside your device.
    To run this command, we are assuming that the command was run inside the devices,
    so you need to run the following line to resolve the URL `http://web.linkerd-viz.svc.cluster.local:50750`
    to point to your device:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '`IP_CLUSTER` is the IP address of your cluster.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, access the next URL to open the dashboard: `http://web.linkerd-viz.svc.cluster.local:50750`.'
  prefs: []
  type: TYPE_NORMAL
- en: Now, it’s time to install the NGINX ingress controller to be used in this implementation.
    Let’s explore this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Installing and injecting the NGINX ingress controller
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this scenario, we are going to use the NGINX ingress controller, using Helm
    to install it by following the given steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `nginx-ingress` namespace:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Add the NGINX ingress controller Helm chart and update the repositories configured
    in Helm:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Install the NGINX ingress controller:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, to inject the NGINX ingress controller pod, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Your ingress controller is now ready to be installed and injected. Let’s create
    the applications that we need in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a demo application and faulty pods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Now, let’s create our sample application and faulty pod to experiment with
    the traffic splitting feature and get some faulty traffic to simulate error requests.
    For this, follow the given steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Create the `myapps` namespace for your pods:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Create the sample application, `app1`, by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: 'The `linkerd inject` command inserts the `linkerd.io/inject: enabled` label
    in the `annotations` sections of your deployment or pod. This label is used by
    Linkerd to inject the services with the Linkerd proxy. You can also add this label
    manually in your YAML definitions to have a better approach using declarative
    definitions for your pods and deployments. To customize the code of app1demo check
    the link [https://github.com/sergioarmgpl/containers/tree/main/app1demo](https://github.com/sergioarmgpl/containers/tree/main/app1demo).'
  prefs: []
  type: TYPE_NORMAL
- en: 'To create our faulty pod, we are going to use NGINX as a web server and a custom
    configuration to return a request with a `500` code error in order for Linkerd
    to detect and count the request as an error. For this, let’s create the configuration
    by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s create the deployment that returns a `500` error in port `5000`
    when accessing the pod in the `/` path:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now that our applications have been deployed, let’s configure the services
    for these applications. Let’s start with the `error-injector` service:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, create the service for your application by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, let’s use the `app1` service and the other half for `error-injector`,
    so we are going to expect a 50% success rate:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Finally, let’s create our ingress rule to expose the endpoint to send traffic
    to this application using traffic splitting:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Important Note
  prefs: []
  type: TYPE_NORMAL
- en: Depending on which Kubernetes version you are using, you have to use the syntax
    for your ingress controller definition, *v1beta1* or *v1*. For more information,
    you can check [https://kubernetes.io/docs/concepts/services-networking/ingress](https://kubernetes.io/docs/concepts/services-networking/ingress),
    and change from different Kubernetes versions.
  prefs: []
  type: TYPE_NORMAL
- en: Now, we are ready to test the observability and traffic splitting configured
    with Linkerd. Let’s explore this in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Testing observability and traffic splitting with Linkerd
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, it’s time to test the observability. To start exploring the dashboard
    and see the observability, follow the given steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open your dashboard by running the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will automatically open the dashboard to the URL `http://localhost:50750`.
  prefs: []
  type: TYPE_NORMAL
- en: 'The dashboard will look as in the following screenshot:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – Linkerd dashboard'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16945_08_05.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.5 – Linkerd dashboard
  prefs: []
  type: TYPE_NORMAL
- en: To load the right information, select the **MYAPPS** namespace in the combo
    box in the left sidebar, and then click on the **Deployments** icon to load the
    **HTTP Metrics** and **TCP Metrics** information.
  prefs: []
  type: TYPE_NORMAL
- en: 'To see similar information as the previous dashboard, execute the following
    command to start sending traffic to our deployment:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'The first command assigns the load balancer IP address that your NGINX ingress
    controller is using as the endpoint to expose services using ingress definitions.
    Then, while the command sends traffic, it also shows the result of each request,
    showing a similar message to the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Or, the following output error is displayed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: This is a frequency of 50% for the message and 50% for the error, on average.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you click on the orange Grafana icon (let’s say, for example, in the **HTTP
    Metrics** section), you will see a similar Grafana graph to the following:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Grafana Linkerd HTTP Metrics graph'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16945_08_06.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.6 – Grafana Linkerd HTTP Metrics graph
  prefs: []
  type: TYPE_NORMAL
- en: In this graph, you can see the golden metrics and the success rate of the application
    for the `app1` deployment, the **requests per second** (**RPS**), and the latency
    of each request; these metrics represent the golden metrics for your application,
    which give you the basic observability feature for your system and your application.
  prefs: []
  type: TYPE_NORMAL
- en: 'If you click on **Traffic Splits** while the **myapps** namespace is selected,
    you will see a traffic splitting representation like this:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.7 – Linkerd traffic splitting dashboard'
  prefs: []
  type: TYPE_NORMAL
- en: '](img/B16945_08_07.jpg)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 8.7 – Linkerd traffic splitting dashboard
  prefs: []
  type: TYPE_NORMAL
- en: In this dashboard, you will see, in real time, how the traffic splitting configuration
    sends 50% of the traffic to the `app1` Kubernetes services and 50% to the error
    injector. The red color represents failure requests (requests that return the
    `500` request error code), while the green color represents valid traffic from
    the `app1` service returning a `200` request code. This, in general, gives you
    the live state of your application, which is the goal of implementing observability.
  prefs: []
  type: TYPE_NORMAL
- en: This basic implementation simulates a failure request for an application using
    a service mesh. You can also use the same implementation to split your traffic
    between applications or implement advanced deployment strategies such as blue/green
    deployments. This was a simple use case to implement observability in your applications
    and the power of traffic management from a service mesh. Now, let’s explore some
    useful commands if you want to use Linkerd using the CLI.
  prefs: []
  type: TYPE_NORMAL
- en: Using Linkerd’s CLI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In some cases where no UI is available, maybe for security reasons, it could
    be useful to use the Linkerd CLI. So, let’s explore four basic command-line options:
    `routes`, `top`, `tap`, and `edges`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`routes` shows the current routes that other applications or clients are using
    to access your application. Using our previous scenario as an example, you can
    show the routes of `app1` in the `myapps` namespace with the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`top` displays the traffic and path of your application. The following command
    is going to show how the ingress controller forwards the traffic to your applications,
    shows a counter to access the `/` path, and shows the success rate of the requests:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`tap` displays the information of the requests in real time for `app1`; for
    this, you have to run the following command:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '`edges` shows a table displaying how your application is connected with other
    injected applications in your cluster, and the source and destiny of each connection.
    For this, you have to run the following command for `app1`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: With this, you have an idea of how to use Linkerd with the CLI. Now, let’s move
    to the next section to learn how to uninstall Linkerd.
  prefs: []
  type: TYPE_NORMAL
- en: Uninstalling Linkerd
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'If you are evaluating Linkerd or doing some management in your clusters, for
    example, it could be useful to uninstall Linkerd. For this, follow the next steps:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Uninstall support for additional features of Linkerd (called **viz**) as follows:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Uninstall the Linkerd control plane. This is going to uninstall the rest of
    the core Linkerd components. For this, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: Now, Linkerd is uninstalled from your cluster. To end this chapter, let’s move
    to the last section to explore some useful ideas of where you can use Linkerd.
  prefs: []
  type: TYPE_NORMAL
- en: Ideas to implement when using service meshes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'To end this chapter, here are some ideas of how you can get the advantages
    of using service meshes at the edge. These ideas are not specific to the edge
    and could be used in a common infrastructure:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Implement rate limits**: You can use a service mesh to configure some rate
    limits in your applications, managing in this way how much input traffic is accepted.
    There are some awesome projects to implement this, including Linkerd and Envoy-based
    service meshes such as Istio and Ambassador.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Traffic splitting**: You can use this feature of service meshes to implement
    blue/green deployments and canary deployments; an example of this is the implementation
    of Argo Rollouts, which can use Linkerd to implement this kind of deployment strategy.
    You can also implement some chaos engineering tests using service meshes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security policies**: You can use service meshes to restrict traffic and encrypt
    end-to-end traffic. This could be useful to increase the security of your services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-cluster connection**: With a service mesh, you can connect your clusters
    without complex configurations. **Kuma** is a control plane for microservices
    and service meshes that can help you to connect multiple clusters; it was built
    on top of Envoy. You can also do the same using Linkerd and other Envoy-based
    service meshes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scaling based on networking**: You can use Prometheus metrics generated by
    service meshes to generate alerts or scale your services. You can also implement
    machine learning models to implement some intelligent scaling. You can use them
    with projects such as **Kubernetes-based Event-Driven Autoscaling** (**KEDA**),
    which reads information from an API to scale your services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: These are some ideas that you can explore when using service meshes. Now, it’s
    time to finish the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we learned how to implement observability and how to use a
    service mesh to set up traffic splitting. We focused on implementing this scenario
    using Linkerd, running a sample application that shows a message, and using traffic
    splitting. When the application receives the traffic, we showed how to explore
    the different graphics that can be used to get the real-time state of your system.
    We also learned how to use Linkerd with the CLI uninstalled. The chapter ended
    with some implementation ideas to explore when using service meshes and how this
    can impact your system. All of this forms the base to implement observability
    and basic traffic splitting in systems using a Linkerd service mesh. In the next
    chapter, we are going to learn how to implement serverless functions and simple
    event-driven pipelines using Knative.
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are a few questions to validate your new knowledge:'
  prefs: []
  type: TYPE_NORMAL
- en: How do service meshes help you to implement observability?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the features that service meshes provide to systems?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How do service meshes work internally?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What does Linkerd provide for users implementing observability?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How can Linkerd be compared to other service meshes?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What are the common use cases for service meshes?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can refer to the following resources for more information on the topics
    covered in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Design distributed systems* book, by *Brendan Burns*: [https://learning.oreilly.com/library/view/designing-distributed-systems/9781491983638](https://learning.oreilly.com/library/view/designing-distributed-systems/9781491983638)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Service mesh pattern: [https://philcalcado.com/2017/08/03/pattern_service_mesh.html](https://philcalcado.com/2017/08/03/pattern_service_mesh.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Golden Signals - Monitoring from first principles*: https://www.squadcast.com/blog/golden-signals-monitoring-from-first-principles'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'gRPC official website: [https://grpc.io](https://grpc.io)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Service Mesh Interface: [https://smi-spec.io](https://smi-spec.io)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Linkerd glossary and useful terms: [https://linkerd.io/service-mesh-glossary](https://linkerd.io/service-mesh-glossary
    )'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Service meshes quick start and comparisons: [https://servicemesh.es](https://servicemesh.es)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Observability vs. Monitoring*: [https://dzone.com/articles/observability-vs-monitoring](https://dzone.com/articles/observability-vs-monitoring)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Monitoring and Observability — What’s the Difference and Why Does It Matter?*:
    [https://thenewstack.io/monitoring-and-observability-whats-the-difference-and-why-does-it-matter](https://thenewstack.io/monitoring-and-observability-whats-the-difference-and-why-does-it-matter)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*The 4 Golden Signals of API Health and Performance in Cloud Native Applications*:
    [https://blog.netsil.com/the-4-golden-signals-of-api-health-and-performance-in-cloud-native-applications-a6e87526e74](https://blog.netsil.com/the-4-golden-signals-of-api-health-and-performance-in-cloud-native-applications-a6e87526e74)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Linkerd documentation: [https://linkerd.io/docs](https://linkerd.io/docs)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Service Mesh* *&* *Edge Computing Considerations*: [https://sunkur.medium.com/service-mesh-edge-computing-considerations-84126754d17a](https://sunkur.medium.com/service-mesh-edge-computing-considerations-84126754d17a)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
