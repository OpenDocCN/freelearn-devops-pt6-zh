- en: '10'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '10'
- en: Implementing Telemetry and Observability in the Cloud
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在云中实施遥测与可观察性
- en: As we already know, Cloud Native applications typically consist of multiple
    small services that communicate over the network. Cloud Native apps are frequently
    updated and replaced with newer versions and in this chapter, we emphasize the
    need to monitor and optimize them based on observations for best performance with
    cost in mind.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们已经知道的，云原生应用程序通常由多个小型服务组成，这些服务通过网络进行通信。云原生应用程序会频繁更新并用新版本替换，在本章中，我们强调基于观察来监控和优化这些应用程序，以便在考虑成本的情况下获得最佳性能。
- en: 'This chapter covers further requirements from *Cloud Native Observability*
    domain of KCNA exam that makes up 8% of the total exam questions. The following
    are the topics we’re going to focus on:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章涵盖了 KCNA 考试中*云原生可观察性*领域的进一步要求，占总考试题目的 8%。以下是我们将重点关注的主题：
- en: Telemetry and observability
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 遥测与可观察性
- en: Prometheus for monitoring and alerting
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Prometheus 用于监控和告警
- en: FinOps and cost management
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: FinOps 和成本管理
- en: Let’s get started!
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: Telemetry and observability
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 遥测与可观察性
- en: With the evolution of traditional monolithic architectures towards distributed
    loosely coupled microservice architectures, the need for detailed high-quality
    telemetry quickly became apparent. Before elaborating any further, let’s first
    define what **Telemetry** is in the context of IT infrastructure.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 随着传统单体架构向分布式松耦合微服务架构的演变，对高质量遥测的详细需求迅速变得显而易见。在进一步阐述之前，首先让我们定义一下在 IT 基础设施上下文中什么是**遥测**。
- en: Telemetry
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 遥测
- en: Refers to monitoring and collection of data about system performance for analysis
    that helps identify issues. Telemetry is a broad term for **logs**, **metrics**,
    and **traces** that are also known as telemetry types or signals.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 指监控和收集系统性能数据进行分析，帮助识别问题。遥测是**日志**、**指标**和**追踪**的统称，也称为遥测类型或信号。
- en: With Cloud Native applications being distributed by design, the ability to track
    and trace all communication between the parts plays a major role for troubleshooting,
    finding bottlenecks and providing insights on how application performs.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 由于云原生应用程序本身就是分布式的，因此追踪和跟踪各部分之间的所有通信在故障排除、找出瓶颈以及提供应用程序性能洞察方面发挥着重要作用。
- en: All three telemetry signals (**logs**, **metrics** and **traces**) help us to
    better understand the state of the application and infrastructure at any given
    point of time and take a corrective action if needed.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 三种遥测信号（**日志**、**指标**和**追踪**）帮助我们更好地理解应用程序和基础设施在任何给定时刻的状态，并在需要时采取纠正措施。
- en: Observability
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 可观察性
- en: Is the capability to continuously generate insights based on telemetry signals
    from the observed system. In other words, an observable system is the one, the
    state of which is clear with the *right data* provided at the *right time* to
    make the *right decision*.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 是指基于来自被观察系统的遥测信号持续生成洞察的能力。换句话说，一个可观察的系统就是那种通过*正确的数据*在*正确的时间*提供*正确的决策*来清晰了解其状态的系统。
- en: Let’s explain what this *right data* at the *right time* to make the *right
    decision* means with an example. Consider you are operating microservices on Kubernetes
    with most of the services persisting data in a database layer backed by **Persistent**
    **Volumes** (**PV**).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过一个例子来解释什么是*正确的数据*在*正确的时间*做出*正确的决策*。假设你在 Kubernetes 上操作微服务，其中大多数服务将数据持久化到由**持久化****存储卷**（**PV**）支持的数据库层。
- en: Obviously, you need to make sure that all databases are operational and that
    there is enough disk space available on the storage appliance serving the PVs.
    If you only collect and analyze the *logs* of the services, that will not be enough
    to make decision when the storage capacity should be extended. For instance, services
    using databases can crash suddenly because they cannot write to their databases
    anymore. Logs of the databases will point to the fact that the storage space has
    run out and more capacity is urgently required.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，你需要确保所有数据库都在正常运行，并且存储设备上为存储卷提供的磁盘空间足够。如果你仅仅收集并分析服务的*日志*，那将不足以决定何时扩展存储容量。例如，使用数据库的服务可能会突然崩溃，因为它们无法再向数据库写入数据。数据库的日志将指向存储空间已经用尽，并且急需更多的容量。
- en: In this case, the logs are helpful to find the culprit, but they are not exactly
    the right data provided at the right time. The *right data* would be continuous
    disk utilization metrics collected from the storage appliance. The *right time*
    would be predefined threshold (let’s say appliance is 70% full) that gives operator
    enough time to make the *right decision* of extending or freeing the capacity.
    Informing operator that the database storage is 100% full and services are down
    at 2AM is clearly not the best way to go.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，日志有助于找到罪魁祸首，但它们并不是在正确的时间提供的正确数据。*正确的数据*应该是从存储设备收集的连续磁盘利用率度量。*正确的时间*应该是预定义的阈值（假设设备已满70%），这样操作员有足够的时间做出*正确的决策*，比如扩展或释放容量。在凌晨2点告知操作员数据库存储已满且服务中断显然不是最佳做法。
- en: That is why relying on only one telemetry signal is almost never enough and
    we should have all three in place to ensure observability. Observability is one
    of the keys behind faster incident responses, increased productivity and optimal
    performance. However, having more information does not necessary translate into
    a more observable system. Sometimes, having too much information can have an opposite
    effect and make it harder to distinguish the valuable insights from the noise
    (e.g., excessive log records produced by the maximum debug level of an application).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么仅依赖一个遥测信号几乎永远不够，我们应该同时具备这三者以确保可观测性。可观测性是更快响应事故、提高生产力和优化性能的关键之一。然而，拥有更多的信息并不一定意味着系统更可观察。有时，信息过多可能会产生相反的效果，使得从噪声中辨别出有价值的见解变得更加困难（例如，由应用程序的最大调试级别生成的过多日志记录）。
- en: Let’s now see each of the telemetry signals in more details starting with logs.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们更详细地了解每个遥测信号，从日志开始。
- en: Logs
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 日志
- en: Are events described as text which are recorded by an application, an operating
    system or an appliance (for example, firewall, load balancer, etc.).
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 事件是由应用程序、操作系统或设备（例如防火墙、负载均衡器等）记录的文本描述。
- en: The events that log records represent could be pretty much anything ranging
    from a service restart and user login to an API request with payload received
    or an execution of a certain method in code. Logs often include timestamp, text
    message and further information such as status codes, severity levels (`DEBUG`,
    `INFO`, `WARNING`, `ERROR`, `CRITICAL`), user ids and so on.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录所代表的事件几乎可以是任何事情，从服务重启和用户登录到接收到有效载荷的API请求或代码中执行特定方法等。日志通常包括时间戳、文本消息以及进一步的信息，如状态码、严重性级别（`DEBUG`、`INFO`、`WARNING`、`ERROR`、`CRITICAL`）、用户ID等。
- en: Note
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: The log severity levels as well as instructions on how to access container logs
    in Kubernetes have been discussed in detail in [*Chapter 7*](B18970_07.xhtml#_idTextAnchor077)
    in section *Debugging applications in Kubernetes*. Make sure to go back, if you’ve
    skipped it before for any reason.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 日志的严重性级别以及如何在Kubernetes中访问容器日志的说明已经在[*第7章*](B18970_07.xhtml#_idTextAnchor077)的*在Kubernetes中调试应用程序*一节中详细讨论过。如果您之前因为任何原因跳过了它，请务必回去查看。
- en: 'Below you’ll find a sample log message recorded by Nginx webserver when processing
    an `HTTP v1.1` `GET` request received from client with IP `66.211.65.62` on the
    4th of October 2022:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是Nginx Web服务器记录的示例日志消息，该消息在处理来自IP `66.211.65.62`的客户端的`HTTP v1.1` `GET`请求时生成，时间为2022年10月4日：
- en: '[PRE0]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Additional information can be derived from the message, such as:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 还可以从消息中提取其他信息，如：
- en: response status code `200` (`HTTP OK`)
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 响应状态码`200`（`HTTP OK`）
- en: the number of bytes sent to the client `4556`
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 发送给客户端的字节数`4556`
- en: the URL and query string `/?q=%E0%A6%A6%E0%A7%8B%E0%A7%9F%E0%A6%`
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: URL和查询字符串`/?q=%E0%A6%A6%E0%A7%8B%E0%A7%9F%E0%A6%`
- en: as well as user agent `Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)`
    that in fact tells us that the request is done by Google’s web crawler.
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 以及用户代理`Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)`，这实际上告诉我们请求是由Google的网页爬虫发出的。
- en: Depending on the application, the log format can be adjusted to only include
    the information you’d like and skip any unnecessary details.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 根据应用程序的不同，日志格式可以进行调整，只包含您想要的信息，并跳过任何不必要的细节。
- en: Next on the signals list are metrics. Let’s figure out what they are.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下一项信号是度量。我们来弄清楚它们是什么。
- en: Metrics
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 度量
- en: Are regular measurements that describe the performance of an application or
    a system over the course of time in a time-series format.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 度量是常规的性能测量，描述了应用程序或系统在一段时间内的表现，以时间序列格式呈现。
- en: 'Common examples include metrics like CPU, RAM utilization, number of open connections
    or response time. If you think about it, single, irregular measurements do not
    provide much value or insight about the state of the system. There might be a
    short spike in utilization that is over in less than a minute, or the other way
    around: utilization dropping for some time.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 常见的例子包括像 CPU 使用率、RAM 利用率、打开的连接数或响应时间等指标。如果你仔细想一想，单独的、不规律的测量并不能提供系统状态的大量价值或洞察力。可能会出现短暂的利用率高峰，持续不到一分钟，或者反过来：利用率在一段时间内下降。
- en: 'With single measurements, it is not possible to make any prediction or analyze
    how the application or the system behaves. With time-series, we can analyze how
    one or another metric has changed, determine trends and patters, and envision
    upcoming changes. That is why metrics should be collected at a regular, short
    intervals typically in a range between 30 seconds to a few minutes. Time-series
    can also be plotted as a graph for visual representation as shown on *Figure*
    *10**.1* below:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 通过单个测量，无法对应用程序或系统的行为进行任何预测或分析。使用时间序列，我们可以分析一个或多个度量标准的变化，确定趋势和模式，并预测即将发生的变化。这就是为什么应该定期收集度量标准，通常在30秒到几分钟之间的短时间间隔内。时间序列还可以作为图表进行可视化表示，如下图*10**.1*所示：
- en: '![Figure 10.1 – CPU usage metric visualization (X = time, Y = utilization).](img/B18970_10_01.jpg)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.1 – CPU 使用率度量可视化（X = 时间，Y = 利用率）。](img/B18970_10_01.jpg)'
- en: Figure 10.1 – CPU usage metric visualization (X = time, Y = utilization).
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.1 – CPU 使用率度量可视化（X = 时间，Y = 利用率）。
- en: While it looks like there been a huge increase in CPU usage between 12:30 to
    13:15 according to the graph, the maximum utilization over the period shown was
    always under 10% suggesting that the system is heavily underutilized. Basic metrics
    like CPU, memory, or disk usage should always be collected, but often they are
    not enough to make the *right decisions*.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然根据图表，在12:30到13:15之间CPU使用率似乎有显著增加，但显示期间的最大利用率始终在10%以下，表明系统严重未利用。应始终收集基本的CPU、内存或磁盘使用率等基本度量标准，但通常这些是不足以做出*正确决策*的。
- en: Therefore, it is recommended to collect multiple application-specific metrics
    which could include number of API requests per minute, number of messages waiting
    in a queue, request response times, number of open connections, and so on. Some
    of those metrics can be well suited to making right autoscaling decisions and
    some to provide valuable insights on application performance.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，建议收集多个应用程序特定的度量标准，包括每分钟的 API 请求次数、队列中等待的消息数量、请求响应时间、打开的连接数等等。这些度量标准中的一些非常适合做出正确的自动扩展决策，另一些则可以提供有关应用程序性能宝贵的见解。
- en: That’s it about metrics for now. Let’s continue with request tracing as next.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 目前关于度量标准就介绍到这里。接下来我们将继续讲述请求追踪。
- en: Tracing
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 追踪
- en: Is a complete tracking of the requests passing through the components of a distributed
    system. It allows to see which components are involved in the processing of a
    particular request, how long the processing takes, and any additional events that
    happen along. *Traces* are the results of tracing requests.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 是对通过分布式系统组件传递的请求的完整跟踪。它允许查看哪些组件参与处理特定请求、处理时间多长以及沿途发生的任何额外事件。*追踪*是追踪请求的结果。
- en: 'Now imagine the following situation. You are investigating longer response
    times of a distributed, microservice based application you operate, yet the number
    of requests or load has not changed much. Since most of the application requests
    traverses’ multiple services, you’ll need to verify each and every service to
    find the one (or several ones) that are not performing well. However, if you integrate
    a tracing utility such as **Jaeger** or **Zipkin**, it would allow you to trace
    requests and store and analyze the results. Traces would show which service is
    having longer response times and might be slowing the whole application down.
    The traces collected can then be viewed in a dashboard such as the one shown on
    *Figure* *10**.2* below:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 现在想象一下以下情况。您正在调查您运行的基于分布式微服务的应用程序的较长响应时间，但请求或负载的数量并没有太大变化。由于大多数应用程序请求经过多个服务，您需要验证每个服务，找出表现不佳的服务（一个或多个）。但是，如果集成了像**Jaeger**或**Zipkin**这样的追踪工具，它将允许您追踪请求并存储和分析结果。追踪将显示哪个服务具有较长的响应时间，并可能减慢整个应用程序。然后可以在如下图*10**.2*所示的仪表板上查看收集到的追踪结果：
- en: '![Figure 10.2 – example trace view in Jaeger dashboard.](img/B18970_10_02.jpg)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.2 – 在 Jaeger 仪表板中查看示例追踪视图。](img/B18970_10_02.jpg)'
- en: Figure 10.2 – example trace view in Jaeger dashboard.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.2 – Jaeger 仪表板中的示例追踪视图。
- en: All-in-all, tracing contributes a lot to observability. It helps to understand
    the flow of traffic and detect the bottlenecks or issues quickly. Along with logs
    and metrics, the three telemetry types are a must for monitoring of modern applications
    and infrastructure. Without those, operators are *blind* and cannot be sure that
    all systems are operational and perform as expected. It might take some effort
    and time to implement the telemetry and observability right, but it always pays
    off as eventually it will save you a lot of time when it comes to troubleshooting
    problems.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，追踪对可观察性贡献巨大。它有助于理解流量的流向，并能快速检测到瓶颈或问题。与日志和度量值一起，这三种遥测类型是现代应用程序和基础设施监控的必备工具。如果没有它们，运维人员将是*盲目的*，无法确保所有系统正常运行并按预期执行。实现遥测和可观察性的正确方式可能需要一些努力和时间，但它总是值得的，因为最终它会在解决问题时为你节省大量时间。
- en: Speaking about implementation – there is a CNCF project called **OpenTelemetry**
    or **OTel** for short. It provides a set of standardized vendor-agnostic APIs,
    SDKs and tools to ingest, transform and send data to an observability backend.
    Support for a large number of open-source and commercial protocols and programming
    languages (*C++*, *Java*, *Go*, *Python*, *PHP*, *Ruby*, *Rust* and more) makes
    it easy to incorporate telemetry into practically any application. It is not strictly
    required for the scope of KCNA, but if you’d like to know more about it – there
    will be links in the *Further Reading* section below.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 说到实现，有一个 CNCF 项目叫做 **OpenTelemetry**（简称 **OTel**）。它提供了一套标准化的、与供应商无关的 API、SDK
    和工具，用于接收、转换和发送数据到可观察性后端。支持大量开源和商业协议及编程语言（*C++*、*Java*、*Go*、*Python*、*PHP*、*Ruby*、*Rust*
    等），使得几乎可以将遥测集成到任何应用程序中。虽然在 KCNA 范围内并非严格要求，但如果你想了解更多，下面的*进一步阅读*部分将提供相关链接。
- en: Moving on, in the next section we’ll learn about **Prometheus** – number one
    tool for Cloud Native observability.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，在下一部分我们将学习 **Prometheus** —— 云原生可观察性工具中的佼佼者。
- en: Prometheus for monitoring and alerting
  id: totrans-52
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Prometheus 用于监控和告警
- en: After its initial appearance in 2012, Prometheus quickly gained popularity with
    its rich functionality and **Time Series Database** (**TSDB**) that allowed to
    persisting metrics for querying, analysis, and predictions. Interestingly, Prometheus
    was inspired by Google’s **Borgmon** – tool used for monitoring Google’s **Borg**
    – the predecessor of Kubernetes.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在 2012 年首次亮相后，Prometheus 迅速凭借其丰富的功能和 **时间序列数据库** (**TSDB**) 获得了广泛关注，TSDB 使得度量数据可以持久化，便于查询、分析和预测。有趣的是，Prometheus
    的灵感来源于 Google 的 **Borgmon** —— 一个用于监控 Google **Borg**（Kubernetes 的前身）工具。
- en: In 2016, Prometheus was accepted as the second CNCF project (after K8s) that
    has reached *Graduated* status by the year 2018\. Today, Prometheus is considered
    an industry standard for monitoring and alerting and widely used with Kubernetes
    and other CNCF projects.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 2016 年，Prometheus 被接受为第二个 CNCF 项目（仅次于 K8s），并在 2018 年达到了*毕业*状态。今天，Prometheus
    被视为监控和告警的行业标准，广泛用于 Kubernetes 和其他 CNCF 项目中。
- en: But enough history, let’s get to the point. First, what is a TSDB?
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 够了，历史背景我们先放一边，直接进入正题。首先，什么是 TSDB？
- en: TSDB
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: TSDB
- en: Is a database optimized for storage of data with timestamps. The data could
    be measurements or events that are tracked and aggregated over time. In case of
    Prometheus, the data are metrics collected regularly from applications and parts
    of the infrastructure. The metrics are kept in Prometheus TSDB and can be queried
    with its own, powerful *PromQL* query language.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 是一种优化用于存储带有时间戳数据的数据库。这些数据可以是被跟踪和聚合的测量值或事件。在 Prometheus 的情况下，这些数据是从应用程序和基础设施的各个部分定期收集的度量值。这些度量值保存在
    Prometheus TSDB 中，可以使用其强大的*PromQL*查询语言进行查询。
- en: 'How are the metrics being collected? In general, there are two approaches on
    collecting monitoring metrics:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 度量数据是如何被收集的？一般来说，有两种收集监控度量数据的方法：
- en: '`/metrics` URL that is called with a simple HTTP `GET` request. This is the
    dominant way how Prometheus works. The service should make the metrics available
    and keep them up-to-date and Prometheus should make `GET` requests against `/metrics`
    to fetch the data regularly.'
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`/metrics` URL 是通过一个简单的 HTTP `GET` 请求调用的。这是 Prometheus 的主要工作方式。服务应该使度量数据可用并保持更新，Prometheus
    应定期通过 `GET` 请求访问 `/metrics` 来获取数据。'
- en: '`Pushgateway` and done with HTTP `PUT` requests. Helpful for the cases when
    service metrics cannot be *scrapped (pulled)* due to network restrictions (service
    behind a firewall or NAT gateway) or simply when the source of the metric has
    very short lifespan (e.g., quick batch job).'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Pushgateway` 是通过 HTTP `PUT` 请求完成的。它对于那些无法通过抓取（pull）获取服务指标的情况非常有用，比如由于网络限制（服务在防火墙或
    NAT 网关后面）或当指标源的生命周期非常短暂（例如快速批处理作业）时。'
- en: 'When we say *metrics data*, it means not just the metric name and value but
    also a timestamp and often additional labels. Labels indicate certain attributes
    of a metric and can hold the hostname of a server where the metric was scraped,
    the name of an application or pretty much anything else. Labels are very helpful
    for grouping and querying the metrics data with Prometheus’ PromQL language. Let’s
    see the following metric for an example:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们说到*指标数据*时，它不仅仅指指标名称和值，还包括时间戳和通常的附加标签。标签表示指标的某些属性，可以包含抓取该指标的服务器的主机名、应用程序的名称，或者其他几乎任何内容。标签对于使用
    Prometheus 的 PromQL 语言进行分组和查询指标数据非常有帮助。让我们看一个示例指标：
- en: '[PRE1]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Here, `nginx_ingress_controller_requests` is the name of the metric, `273175`
    is the value of the metric (representing number of requests) and everything else
    between `{}` are the labels. As you can see, labels are crucial to narrow down
    the metric scope, which service it applies to, or what exactly it represents.
    In this example, it shows the count of HTTP `GET` requests that were responded
    with HTTP `200 OK` for the service called `kcnamicroservice` located in `kcna`
    namespace.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，`nginx_ingress_controller_requests` 是指标名称，`273175` 是指标的值（表示请求数），`{}` 中的其他内容是标签。正如你所看到的，标签对于缩小指标范围至关重要，能够帮助确认它适用于哪个服务，或者它究竟表示什么。在这个例子中，它显示的是
    `kcnamicroservice` 服务在 `kcna` 命名空间下的 HTTP `GET` 请求被 HTTP `200 OK` 响应的计数。
- en: One other great feature of Prometheus is the dashboard that lets us visualize
    the data from TSDB directly in the Prometheus UI. While it is very easy to plot
    graphs with it, its functionality is somewhat limited and that is why many people
    use **Grafana** for visualization and metrics analytics.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 的另一个优秀功能是仪表盘，它允许我们直接在 Prometheus UI 中可视化 TSDB 中的数据。虽然它非常容易绘制图表，但其功能有些有限，这也是为什么许多人使用
    **Grafana** 来进行可视化和指标分析的原因。
- en: Now let’s think for a moment how we could collect metrics with Prometheus from
    applications that we cannot modify? We are talking about services that weren’t
    developed within your company and the ones that don’t expose the metrics on a
    `/metrics` endpoint. This also applies to software that does not come with a webserver
    such as databases and message buses or even for basic OS stats (CPU, RAM, disk
    utilization). The solution for such cases is called Prometheus **Exporter**.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们思考一下，如何在无法修改的应用程序中使用 Prometheus 收集指标？我们指的是那些没有在 `/metrics` 端点上公开指标的服务，或者那些并非在你公司内部开发的服务。这同样适用于没有内置
    Web 服务器的软件，如数据库、消息总线，甚至基本的操作系统统计数据（CPU、RAM、磁盘利用率）。针对这种情况的解决方案叫做 Prometheus **Exporter**。
- en: Prometheus Exporter
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus Exporter
- en: Is a small tool that bridges the gap between the Prometheus server and applications
    that don’t natively export metrics. Exporters aggregate custom metrics from a
    process or a service in the format supported by Prometheus and expose them over
    `/metrics` endpoint for collection.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个小工具，它弥合了 Prometheus 服务器与那些原生不导出指标的应用程序之间的差距。Exporter 聚合来自进程或服务的自定义指标，格式为
    Prometheus 支持的格式，并通过 `/metrics` 端点暴露供 Prometheus 收集。
- en: Essentially, an exporter is a minimalistic webserver that knows how to capture
    metrics from an application that must be monitored and transforms those into Prometheus
    format for collection. Let’s take PostgreSQL database as an example. Natively
    it does not expose any metrics, but we can run an exporter along with it that
    would query the DB and provide observability data that will be pulled into Prometheus
    TSDB. If run on Kubernetes, the typical way to place an exporter is to put it
    in the same Pod with the service monitored as a *Sidecar* container (in case you
    missed it, *Sidecar* containers are explained in [*Chapter 5*](B18970_05.xhtml#_idTextAnchor059)).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 本质上，Exporter 是一个简化的 Web 服务器，它知道如何从需要监控的应用程序中捕获指标，并将这些指标转换为 Prometheus 格式以供收集。我们以
    PostgreSQL 数据库为例，PostgreSQL 本身并不公开任何指标，但我们可以与它一起运行一个 exporter，该 exporter 会查询数据库并提供可观测数据，这些数据会被拉入
    Prometheus 的时序数据库（TSDB）。如果在 Kubernetes 上运行，典型的做法是将 exporter 与被监控的服务放在同一个 Pod 中，作为
    *Sidecar* 容器（如果你错过了，*Sidecar* 容器的介绍可以参考 [*第 5 章*](B18970_05.xhtml#_idTextAnchor059)）。
- en: Today, you’ll find a ton of ready-to-use exporters for popular software such
    as *MySQL*, *Redis*, *Nginx*, *HaProxy*, *Kafka* and more. However, if there is
    no exporter available – it is not a big deal to write one own using any popular
    programming language with Prometheus client libraries.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，你会发现许多现成的导出器可用于流行的软件，如*MySQL*、*Redis*、*Nginx*、*HaProxy*、*Kafka*等。然而，如果没有可用的导出器，使用任何流行的编程语言和Prometheus客户端库编写一个也并不难。
- en: Speaking about Kubernetes and Prometheus, there is a seamless integration between
    the two. Prometheus has *out-of-the-box* capabilities to monitor Kubernetes and
    automatically discover the service endpoints of the workloads you run in your
    K8s cluster. Besides Kubernetes, there is also support for various PaaS and IaaS
    offerings including those from Google Cloud, Microsoft Azure, Amazon Web Services
    and many other.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 说到Kubernetes和Prometheus，它们之间有无缝的集成。Prometheus具有*开箱即用*的能力来监控Kubernetes，并自动发现你在K8s集群中运行的工作负载的服务端点。除了Kubernetes，Prometheus还支持各种PaaS和IaaS服务，包括来自Google
    Cloud、Microsoft Azure、Amazon Web Services等的服务。
- en: 'With that, we’ve covered the part about monitoring with Prometheus and before
    moving on to the alerting, let’s have a look at *Figure* *10**.3* first:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 有了这些，我们已经涵盖了使用Prometheus进行监控的部分，在进入告警之前，让我们先看一下*图* *10.3*：
- en: '![Figure 10.3 – Prometheus architecture.](img/B18970_10_03.jpg)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图 10.3 – Prometheus架构。](img/B18970_10_03.jpg)'
- en: Figure 10.3 – Prometheus architecture.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10.3 – Prometheus架构。
- en: As you can see, Prometheus server will pull metrics from its *targets* that
    can be statically configured or discovered dynamically with service discovery.
    Short-lived jobs or services behind NAT can also push their metrics via `Pushgateway`.
    The metrics can be queried, displayed, and visualized with `PromQL` in *Prometheus
    web UI* or third-party tools.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，Prometheus服务器将从其*目标*中拉取指标，这些目标可以是静态配置的，也可以通过服务发现动态发现。短生命周期的作业或位于NAT后的服务也可以通过`Pushgateway`推送它们的指标。这些指标可以通过`PromQL`在*Prometheus
    Web UI*或第三方工具中查询、显示和可视化。
- en: Moving on, we are going to learn about Prometheus **Alertmanager** and its notification
    capabilities.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将学习关于Prometheus **Alertmanager**及其通知功能的内容。
- en: Alerts
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 告警
- en: Are reactive elements of a monitoring system triggered by a metric change or
    a crossing of a certain threshold.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 监控系统中的响应元素是由指标变化或某个阈值的突破触发的。
- en: Alerts are used to notify team or an engineer on duty about the change of state
    in an application or an infrastructure. The notification can take a form of an
    e-mail, SMS or a chat message as an example. Alertmanager, as you already guessed,
    is the component of Prometheus responsible for the alerts and notifications.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 告警用于通知团队或值班工程师应用程序或基础设施状态的变化。通知可以采取电子邮件、短信或聊天消息等形式。例如，Alertmanager，正如你已经猜到的，是Prometheus中负责告警和通知的组件。
- en: An alert is normally triggered when a certain metric (or a combination of multiple
    metrics) has crossed a predefined threshold and stayed above or beyond it for
    some minutes. Alert definitions are based on Prometheus expression language and
    accept mathematical operations which allows flexible definition of conditions.
    In fact, a quite unique feature of Prometheus is the ability to predict when a
    metric will reach a certain threshold and raise an alert early, before it actually
    happens. This way, you can define an alert that will notify you five days in advance
    before a host runs of disk space, as an example. This is possible thanks to Prometheus
    TSDB that keeps time-series and allows analyzing the data and its rate of change.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 当某个指标（或多个指标的组合）突破预设阈值并维持在该阈值以上或以下若干分钟时，通常会触发告警。告警定义基于Prometheus表达式语言，并接受数学运算，从而允许灵活地定义条件。事实上，Prometheus的一个独特功能是能够预测某个指标何时会达到某个阈值，并提前触发告警，在实际发生之前提醒你。这样，你可以定义一个告警，在主机磁盘空间不足时提前五天通知你。例如，这得益于Prometheus的TSDB，它保持时间序列数据，并允许分析数据及其变化速率。
- en: Overall, Prometheus is an ultimate solution for monitoring in the Cloud Native
    era. It is often used to monitor both Kubernetes itself and workloads that run
    on top of Kubernetes. Today you’ll find plenty of software that supports Prometheus
    natively by exposing metrics data via `/metrics` endpoint in the Prometheus format.
    Client libraries available in many languages make it possible to integrate Prometheus
    support directly in your own applications. This process is sometimes called **direct
    instrumentation** as it introduces native support of Prometheus. For applications
    and software that does not offer native support, you are likely to find exporters
    that extract the data and offer it in Prometheus metric format for collection.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，Prometheus 是云原生时代监控的终极解决方案。它通常用于监控 Kubernetes 本身以及运行在 Kubernetes 上的工作负载。如今，您会发现很多软件原生支持
    Prometheus，通过 `/metrics` 端点以 Prometheus 格式暴露度量数据。许多语言提供的客户端库使得将 Prometheus 支持直接集成到您自己的应用程序中成为可能。这个过程有时被称为**直接插桩**，因为它引入了
    Prometheus 的原生支持。对于不提供原生支持的应用程序和软件，您可能会找到导出器来提取数据并以 Prometheus 指标格式提供以供收集。
- en: Now, some of you probably cannot wait to make hands dirty with Prometheus, but
    in fact we’ve already covered it in more details than it is required to pass KCNA
    exam. Nevertheless, you are encouraged to check *Further Reading* section and
    try deploying Prometheus onto our miniKube K8s cluster yourself. And for now,
    we’re moving on to the topic of cost management.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，有些人可能迫不及待想要亲自动手操作 Prometheus，但事实上我们已经比 KCNA 考试所需的更详细地介绍了它。尽管如此，仍然鼓励您查看*进一步阅读*部分，并尝试将
    Prometheus 部署到我们的 miniKube K8s 集群上。现在，我们将进入成本管理的话题。
- en: FinOps and cost management
  id: totrans-82
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: FinOps 和成本管理
- en: 'With rapid transition from traditional data centers and collocation towards
    cloud, it has quickly became apparent that cloud services might be pretty expensive.
    In fact, if you’d see a bill of a public cloud provider, you’ll often find that
    *everything* is metered and *everything* costs money: cross availability zone
    traffic and Internet traffic, number of objects or usage of space, number of API
    requests, Internet IPs, different VM flavors, tiered storage and additional IOPS,
    storage of VMs that are shut down and the list goes on and on. Sometimes, prices
    also vary from region to region making it hard to estimate the costs in advance.
    This has led to the appearance of FinOps in the recent years.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 随着传统数据中心和共置环境迅速过渡到云计算，云服务的费用也很快显现出可能相当昂贵的特点。事实上，如果您看到公共云提供商的账单，通常会发现*所有东西*都被计量，*所有东西*都有费用：跨可用区流量和互联网流量、对象数量或空间使用、API
    请求数量、互联网 IP、不同的虚拟机规格、分级存储和额外的 IOPS、关闭的虚拟机存储，等等。价格有时还会因地区而异，这使得提前估算费用变得困难。这导致了近年来
    FinOps 的出现。
- en: FinOps
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: FinOps
- en: Is a cloud financial management discipline and cultural practice. It helps organizations
    to get the maximum business value based on collaboration of engineering, finance,
    technology and business teams to make data-driven spending decisions.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 是一种云财务管理学科和文化实践。它帮助组织通过工程、财务、技术和业务团队的协作，基于数据驱动的支出决策，获得最大的商业价值。
- en: Where DevOps puts a lot of focus on collaboration between *Development* and
    *Operations*, FinOps adds *Finance* to the mix. It helps the teams to manage their
    cloud spending and stresses the need of collaboration between engineering and
    business teams as a part of continuous improvement and optimization process. While
    you don’t need to know the details for the scope of KCNA exam, you’re still encouraged
    to check about FinOps in the *Further* *Reading* section.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在 DevOps 强调*开发*与*运维*之间的协作时，FinOps 将*财务*也加入到这个组合中。它帮助团队管理他们的云支出，并强调工程和业务团队之间的协作需求，作为持续改进和优化过程的一部分。尽管您不需要了解细节以通过
    KCNA 考试，但仍然鼓励您在*进一步阅读*部分了解更多关于 FinOps 的内容。
- en: When we talk about cloud, by default we assume that we can provision and terminate
    resources such as virtual machines at any time we want. And we only pay for the
    time the VM was running. This is known as **on-demand** capacity or on-demand
    pricing model, and this is the most popular way to consume cloud services today.
    You use it – you pay for it, if you’re running nothing – then nothing is charged.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论云计算时，默认假设我们可以随时提供和终止资源，如虚拟机，并且我们只需为虚拟机运行的时间付费。这就是所谓的**按需**容量或按需定价模型，这是当今最流行的云服务消费方式。您使用它——您为此付费，如果什么也不运行——那么就不会收费。
- en: 'However, there are two more options commonly offered by public cloud providers:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，公共云服务提供商通常还提供另外两种选项：
- en: '**Reserved instances** – These are VMs or bare-metal servers that you reserve
    for a longer period of time (typically one or more years) and pay the costs up
    front. Reserved instances come with a very good discount (30-70%) from the regular,
    on-demand pricing, but you don’t get the same flexibility. Meaning that you’ll
    keep paying for reserved resources even if you don’t need them.'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**保留实例** – 这些是你为较长时间（通常为一年或更长时间）预定的虚拟机或裸金属服务器，并且需要提前支付费用。保留实例相比于常规的按需定价，通常有非常好的折扣（30-70%），但你将失去一定的灵活性。这意味着即使你不再需要这些资源，你仍然需要为保留的资源付费。'
- en: '**Spot instances** (sometimes called **preemptible instances**) – are the instances
    that can be terminated (deleted) by the cloud provider at any point. Spot instances
    are leftover and spare capacities that providers offer with huge discounts (60-90%)
    from on-demand capacity. In some cases, you’ll need to bid (as on auction) for
    Spot instances and as long as you’re bidding more than the others your instance
    continues to run.'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**抢占式实例**（有时也叫做**可抢占实例**） – 这些实例可以在任何时候被云服务提供商终止（删除）。抢占式实例是云服务提供商提供的剩余和备用容量，通常会有大幅折扣（60-90%）相较于按需容量。在某些情况下，你需要竞标（类似拍卖）抢占式实例，只要你的出价高于其他竞标者，你的实例就会继续运行。'
- en: So, which instance type should you use?
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 那么，你应该使用哪种实例类型呢？
- en: There is no easy answer to this question as there are many variables that come
    into play and the answer varies from case to case. The rule of a thumb is to buy
    Reserved instances only for constant workloads or the minimal capacity that is
    always needed to run your applications. Spot instances can be used for non-critical
    workloads, batch processing and various non-real-time analytics. Workloads that
    can be restarted and completed later are a great fit for Spot. And on-demand can
    be used for everything else including temporarily scaling to accommodate higher
    loads. As you remember from the previous chapter, *Autoscaling* is one of the
    main features of Cloud Native architectures and this is where you’d normally use
    on-demand instances.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 对这个问题没有简单的答案，因为有许多变量会影响最终的决策，而且每种情况的答案都不同。一个基本的原则是，只为持续的工作负载或始终需要的最小容量购买保留实例，这样可以运行你的应用程序。对于非关键性的工作负载、批处理和各种非实时分析，可以使用**抢占式实例**。那些可以重新启动并稍后完成的工作负载非常适合使用抢占式实例。而按需实例则可以用于其他所有情况，包括临时扩展以应对更高的负载。正如你从前一章节中记得的，*自动扩展*是云原生架构的主要特点之一，通常情况下，你会在这里使用按需实例。
- en: Yet effective cost management in cloud needs more than just right capacity type
    (on-demand/reserved/spot). The instances should also be of the right size (flavor).
    This is known as **Righsizing**.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，云中的有效成本管理不仅仅依赖于正确的容量类型（按需/保留/抢占式）。实例的大小（规格）也必须正确。这就是所谓的**合理调整大小**。
- en: Rightsizing
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 合理调整大小
- en: Is the continuous process of matching instance size to workload performance
    and capacity requirements with cost in mind.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 是一种持续的过程，旨在将实例大小与工作负载的性能和容量需求相匹配，同时考虑成本因素。
- en: We already know that autoscaling is crucial for cost efficiency, and autoscaling
    can be seen as a part of Rightsizing strategy. You don’t want to run too many
    underutilized instances when the load is low and the opposite – not having enough
    instances to handle high load. Autoscaling should target the sweet spot between
    the capacity/performance and the associated infrastructure costs. But besides
    the number of instances, their size (number of CPUs, GBs of memory, network throughput,
    etc.) is also important.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经知道，自动扩展对于成本效益至关重要，自动扩展也可以视为合理调整大小策略的一部分。你不希望在负载较低时运行太多低效能的实例，而在负载较高时又缺乏足够的实例来处理负载。自动扩展应该瞄准容量/性能与相关基础设施成本之间的最佳平衡点。但除了实例的数量，实例的大小（如
    CPU 数量、内存 GB 数、网络吞吐量等）也是非常重要的。
- en: For example, running 40 Kubernetes worker nodes as VMs with only 4 CPUs and
    8 GB of RAM might cost you more than running 20 worker nodes with 8 CPUs and 16
    GB RAM each despite the same total number of CPUs and RAM. Additionally, many
    providers offer instances based on different CPU generations and flavors optimized
    for specific workloads. Some instances might be optimized for high network throughput
    and some for low-latency disk operations and thus be better suited for your applications.
    All of that should be taken into consideration as a part of rightsizing strategy
    and cost management in the cloud.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，运行 40 个 Kubernetes 工作节点作为虚拟机，每个只有 4 个 CPU 和 8 GB 的内存，可能比运行 20 个工作节点，每个有 8
    个 CPU 和 16 GB 内存的成本还要高，尽管它们的总 CPU 和内存数相同。此外，许多提供商提供基于不同 CPU 代次和优化特定工作负载的实例。有些实例可能针对高网络吞吐量进行了优化，而有些则针对低延迟磁盘操作进行了优化，因此可能更适合您的应用程序。所有这些都应作为正确资源规划和云端成本管理策略的一部分加以考虑。
- en: Summary
  id: totrans-98
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 摘要
- en: In this chapter we’ve learned a lot about Telemetry and Observability. The three
    telemetry types or signals are *logs*, *metrics* and *traces* which provide valuable
    insights into the system observed from slightly different perspectives. An observable
    system is the one that is constantly monitored where we know the state based on
    the telemetry data that serves as evidence.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们学习了很多关于遥测和可观察性（Observability）的内容。三种遥测类型或信号分别是 *日志*、*指标* 和 *追踪*，它们从不同的角度提供了对系统的宝贵洞察。一个可观察的系统是一个不断被监控的系统，我们通过遥测数据来了解系统的状态，这些数据充当了证据。
- en: We’ve also learned about projects such as *OpenTelemetry* that can help with
    instrumentation and simplify the work needed to implement telemetry. Had a quick
    introduction to projects such as *Zipkin* and *Jaeger* for tracing and had a closer
    look at Prometheus – a fully featured monitoring platform.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还了解了一些项目，如 *OpenTelemetry*，它可以帮助进行仪表化并简化实施遥测所需的工作。我们对如 *Zipkin* 和 *Jaeger*
    等项目进行了简要介绍，这些项目用于追踪，并且仔细看了 Prometheus——一个功能齐全的监控平台。
- en: Prometheus supports both *Push* and *Pull* operating models for metric collection,
    but dominantly uses *Pull* model to periodically scrape the metric data at (`/metrics`
    endpoint) and save it in TSDB in time-series format. Having metrics in TSDB allows
    us visualizing the data in software such as *Grafana* and define alerts that would
    notify us over the preferred channel when one or another metric is crossing the
    threshold defined.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 支持 *Push* 和 *Pull* 两种操作模型用于指标收集，但主要使用 *Pull* 模型定期抓取 (`/metrics` 端点)
    的指标数据，并以时间序列格式保存到 TSDB 中。将指标存储在 TSDB 中可以让我们使用 *Grafana* 等软件可视化数据，并定义告警，当某个指标超出预设的阈值时，通过首选通道通知我们。
- en: Another great point about Prometheus is the Kubernetes integration. Prometheus
    supports automatic discovery of targets that are running in Kubernetes which makes
    operator’s life easier. For software that doesn’t natively provide metrics in
    Prometheus format it is possible to run exporters – small tools that aggregate
    the metrics from the service or an application and expose them in Prometheus format
    via `/metrics` endpoint for collection. If you are in control of the source code
    of applications you run – it is also possible to add support for Prometheus with
    a help of client libraries available in many programming languages. This is known
    as *direct instrumentation*.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个关于 Prometheus 的优点是 Kubernetes 集成。Prometheus 支持自动发现运行在 Kubernetes 中的目标，这使得运维人员的工作更加轻松。对于那些没有原生提供
    Prometheus 格式指标的软件，可以运行 Exporters——这些小工具能够汇总来自服务或应用程序的指标，并通过 `/metrics` 端点以 Prometheus
    格式暴露出来以供收集。如果你控制着所运行应用程序的源代码，也可以通过多种编程语言中提供的客户端库来为 Prometheus 提供支持。这被称为 *直接仪表化*。
- en: Finally, we’ve got to know about FinOps and cost management in cloud. Most commonly,
    the so called *on-demand* capacities are consumed in the cloud. That means resources
    can be provisioned when needed and deleted when no longer required and only the
    time when they were running is billed. This is different from *Reserved* capacity
    when instances are paid in advance for longer periods of time. Reserved capacities
    come with very good discounts but will still cost money if unused. And *Spot*
    or *Preemptible* instances are spare capacity that cloud provider might just terminate
    at any time. They are the cheapest among three options, however, might not be
    the right choice for critical workloads that require maximum uptime.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们还需要了解 FinOps 和云中的成本管理。最常见的是所谓的*按需*容量，它们在云中被消费。这意味着资源可以在需要时配置，在不再需要时删除，并且只按它们运行的时间计费。这与*预留*容量不同，后者是为较长时间支付的实例，预付后可以获得较大的折扣，但如果未使用，仍然需要付费。而*Spot*或*Preemptible*实例是云服务商可能随时终止的备用容量。它们是三者中最便宜的选择，但对于需要最大正常运行时间的关键工作负载可能不是最佳选择。
- en: Last, but not least, we’ve covered *Rightsizing*. It’s a process of finding
    the best instance size and number of instances for current workload as a balance
    between performance requirements and cost.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 最后但同样重要的是，我们已经涵盖了*合理配置（Rightsizing）*。这是一个根据性能需求和成本之间的平衡，找到适合当前工作负载的最佳实例大小和实例数量的过程。
- en: Next chapter is about automation and delivery of Cloud Native applications.
    We will learn about best practices and see how we can ship better software faster
    and more reliably.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 下一章节将介绍云原生应用程序的自动化和交付。我们将学习最佳实践，并看到如何更快速、更可靠地交付更好的软件。
- en: Questions
  id: totrans-106
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Correct answers can be found at __TBD__
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 正确答案可以在 __TBD__ 找到
- en: Which of the following are valid telemetry signals (pick multiple)?
  id: totrans-108
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪些是有效的遥测信号（可以选择多个）？
- en: Tracks
  id: totrans-109
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟踪
- en: Pings
  id: totrans-110
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ping
- en: Logs
  id: totrans-111
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日志
- en: Metrics
  id: totrans-112
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指标
- en: Which is the dominant operation model of Prometheus for metrics collection?
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪种是 Prometheus 进行指标收集的主要操作模式？
- en: Push
  id: totrans-114
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 推送
- en: Pull
  id: totrans-115
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 拉取
- en: Commit
  id: totrans-116
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提交
- en: Merge
  id: totrans-117
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 合并
- en: Which of the following allows to collect metrics with Prometheus when native
    application support is missing?
  id: totrans-118
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个选项允许在缺少原生应用程序支持时通过 Prometheus 收集指标？
- en: Running application in Kubernetes
  id: totrans-119
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 中运行应用程序
- en: Installing Pushgateway
  id: totrans-120
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Pushgateway
- en: Installing Alertmanager
  id: totrans-121
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Alertmanager
- en: Installing application exporter
  id: totrans-122
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装应用程序导出器
- en: Which of the following signals does Prometheus collect?
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个信号是 Prometheus 收集的？
- en: Logs
  id: totrans-124
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日志
- en: Metrics
  id: totrans-125
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指标
- en: Traces
  id: totrans-126
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟踪
- en: Audits
  id: totrans-127
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 审计
- en: Which component can be used to allow applications to push metrics into Prometheus?
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个组件可以用来让应用程序将指标推送到 Prometheus？
- en: Zipkin
  id: totrans-129
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zipkin
- en: Grafana
  id: totrans-130
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Grafana
- en: Alertmanager
  id: totrans-131
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Alertmanager
- en: Pushgateway
  id: totrans-132
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pushgateway
- en: Which telemetry signal fits best to see how request traverses a microservice-base
    application?
  id: totrans-133
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪种遥测信号最适合查看请求如何穿越基于微服务的应用程序？
- en: Logs
  id: totrans-134
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 日志
- en: Traces
  id: totrans-135
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟踪
- en: Metrics
  id: totrans-136
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 指标
- en: Pings
  id: totrans-137
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Ping
- en: Which software allows visualizing metrics stored in Prometheus TSDB?
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 哪个软件可以用来可视化存储在 Prometheus TSDB 中的指标？
- en: Zipkin
  id: totrans-139
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zipkin
- en: Kibana
  id: totrans-140
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Kibana
- en: Grafana
  id: totrans-141
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Grafana
- en: Jaeger
  id: totrans-142
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Jaeger
- en: Which software can be used for end-to-end tracing of distributed applications
    (pick multiple)?
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪些软件可以用于分布式应用程序的端到端跟踪（可以选择多个）？
- en: Prometheus
  id: totrans-144
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Prometheus
- en: Grafana
  id: totrans-145
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Grafana
- en: Jaeger
  id: totrans-146
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Jaeger
- en: Zipkin
  id: totrans-147
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Zipkin
- en: What makes it possible to query Prometheus metrics from the past?
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 什么使得查询过去的 Prometheus 指标成为可能？
- en: Alertmanager
  id: totrans-149
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Alertmanager
- en: TSDB
  id: totrans-150
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: TSDB
- en: PVC
  id: totrans-151
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: PVC
- en: Graphite
  id: totrans-152
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Graphite
- en: Which endpoint Prometheus collects metrics from by default?
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Prometheus 默认从哪个端点收集指标？
- en: '`/``collect`'
  id: totrans-154
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`/``collect`'
- en: '`/``prometheus`'
  id: totrans-155
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`/``prometheus`'
- en: '`/``metric`'
  id: totrans-156
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`/``metric`'
- en: '`/``metrics`'
  id: totrans-157
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`/``metrics`'
- en: What is the format of Prometheus metrics?
  id: totrans-158
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Prometheus 指标的格式是什么？
- en: Timeseries
  id: totrans-159
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 时间序列
- en: Traces
  id: totrans-160
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 跟踪
- en: Spans
  id: totrans-161
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Span
- en: Plots
  id: totrans-162
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图表
- en: Which of the following allows direct instrumentation for applications to provide
    metrics in Prometheus format?
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个选项允许应用程序直接进行仪表化以提供 Prometheus 格式的指标？
- en: K8s service discovery
  id: totrans-164
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: K8s 服务发现
- en: Pushgateway
  id: totrans-165
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Pushgateway
- en: Exporters
  id: totrans-166
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 导出器
- en: Client libraries
  id: totrans-167
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 客户端库
- en: A periodic job takes only 30 seconds to complete, but Prometheus scrape interval
    is 60 seconds. What is the best way to collect the metrics from such job?
  id: totrans-168
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个定期任务只需要 30 秒就能完成，但 Prometheus 的抓取间隔是 60 秒。收集该任务的指标的最佳方式是什么？
- en: push the metrics to Pushgateway
  id: totrans-169
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将指标推送到 Pushgateway
- en: reduce scrape interval to 30 seconds
  id: totrans-170
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将抓取间隔缩短到 30 秒
- en: reduce scrape interval to 29 seconds
  id: totrans-171
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将抓取间隔缩短到 29 秒
- en: replace job with Kubernetes CronJob
  id: totrans-172
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Kubernetes CronJob 替代 job
- en: Which of the following is a crucial part of Rightsizing?
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪个是合理配置（Rightsizing）的关键部分？
- en: FinOps
  id: totrans-174
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: FinOps
- en: Reserved instances
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预留实例
- en: Autoscaling
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自动伸缩
- en: Automation
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 自动化
- en: Which of the following should be taken into consideration when implementing
    Autoscaling?
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在实施自动扩展时，以下哪些因素应该被考虑？
- en: CPU utilization metric
  id: totrans-179
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: CPU 利用率指标
- en: RAM utilization metric
  id: totrans-180
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: RAM 利用率指标
- en: CPU + RAM utilization metrics
  id: totrans-181
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: CPU + RAM 利用率指标
- en: CPU, RAM, and application specific metrics
  id: totrans-182
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: CPU、RAM 和应用程序特定指标
- en: Which of the following instance types are offered by many public cloud providers
    (pick multiple)?
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪些实例类型由多个公有云提供商提供（请选择多个）？
- en: On-demand
  id: totrans-184
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按需
- en: Serverless
  id: totrans-185
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无服务器
- en: Spot
  id: totrans-186
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Spot
- en: Reserved
  id: totrans-187
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预留
- en: Which of the following instance types fits for constant workloads with no spikes
    in load that should run for few years straight?
  id: totrans-188
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪种实例类型适合用于负载稳定没有波动的持续工作负载，并且应运行几年不间断？
- en: On-demand
  id: totrans-189
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按需
- en: Serverless
  id: totrans-190
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无服务器
- en: Spot
  id: totrans-191
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Spot
- en: Reserved
  id: totrans-192
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预留
- en: Which of the following instance types fits for batch processing and periodic
    jobs that can be interrupted if lowest price is the main priority?
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下哪种实例类型适合用于批量处理和周期性任务，并且如果最低价格是主要优先考虑因素，可以中断任务？
- en: On-demand
  id: totrans-194
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按需
- en: Serverless
  id: totrans-195
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无服务器
- en: Spot
  id: totrans-196
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Spot
- en: Reserved
  id: totrans-197
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 预留
- en: Further reading
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'OpenTelemetry: [https://opentelemetry.io/docs/](https://opentelemetry.io/docs/)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenTelemetry: [https://opentelemetry.io/docs/](https://opentelemetry.io/docs/)'
- en: 'Jaeger: [https://www.jaegertracing.io/](https://www.jaegertracing.io/)'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jaeger: [https://www.jaegertracing.io/](https://www.jaegertracing.io/)'
- en: 'Grafana: [https://grafana.com/grafana/](https://grafana.com/grafana/)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Grafana: [https://grafana.com/grafana/](https://grafana.com/grafana/)'
- en: 'Prometheus query language: [https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/)'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Prometheus 查询语言: [https://prometheus.io/docs/prometheus/latest/querying/basics/](https://prometheus.io/docs/prometheus/latest/querying/basics/)'
- en: 'Prometheus exporters: [https://prometheus.io/docs/instrumenting/exporters/](https://prometheus.io/docs/instrumenting/exporters/)'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Prometheus 导出器: [https://prometheus.io/docs/instrumenting/exporters/](https://prometheus.io/docs/instrumenting/exporters/)'
- en: 'Kubernetes metrics for Prometheus: [https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/](https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/)'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kubernetes 用于 Prometheus 的指标: [https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/](https://kubernetes.io/docs/concepts/cluster-administration/system-metrics/)'
- en: 'Introduction to FinOps: [https://www.finops.org/](https://www.finops.org/)'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'FinOps 简介: [https://www.finops.org/](https://www.finops.org/)'
