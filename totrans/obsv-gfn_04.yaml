- en: '4'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '4'
- en: Looking at Logs with Grafana Loki
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Grafana Loki 查看日志
- en: In this chapter, we will get hands-on experience with **Grafana Loki**. We will
    learn how to use **LogQL**, which is the language used for querying Loki, how
    to select and filter log streams, and how to use the operators and aggregations
    available. This will give you the tools to extract the data in appropriate ways
    for your dashboard visualizations and alerts. We will review the benefits and
    drawbacks of the log format and how it impacts your use of Loki. To fully explore
    the benefits of Loki, we will explore the architecture and where it can be scaled
    for performance. To finish, we will look at advanced areas of LogQL, such as labels
    and transformations, and other tips and tricks to expand your use of Loki.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将亲身体验 **Grafana Loki**。我们将学习如何使用 **LogQL**，这是用于查询 Loki 的语言，如何选择和过滤日志流，以及如何使用可用的操作符和聚合。这将为你提供适当提取数据以用于仪表板可视化和警报的工具。我们还将回顾日志格式的优缺点以及它如何影响你对
    Loki 的使用。为了充分探索 Loki 的优势，我们将探索其架构及其在性能上的扩展性。最后，我们将探讨 LogQL 的高级内容，例如标签和转换，以及其他技巧和窍门，以扩展你对
    Loki 的使用。
- en: 'We will cover the following main topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: Introducing Loki
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 介绍 Loki
- en: Understanding LogQL
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 LogQL
- en: Exploring Loki’s architecture
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索 Loki 的架构
- en: Tips, tricks, and best practices
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示、技巧和最佳实践
- en: Technical requirements
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, you will work with LogQL using the Grafana Cloud instance and
    demo you set up in [*Chapter 3*](B18277_03.xhtml#_idTextAnchor063). The full LogQL
    language documentation can be found on the Grafana website at [https://grafana.com/docs/loki/latest/logql/](https://grafana.com/docs/loki/latest/logql/).
    Loki is in active development, so it’s worth checking for new features frequently.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将使用 Grafana Cloud 实例以及你在 [*第 3 章*](B18277_03.xhtml#_idTextAnchor063) 中设置的演示来操作
    LogQL。LogQL 的完整语言文档可以在 Grafana 网站的 [https://grafana.com/docs/loki/latest/logql/](https://grafana.com/docs/loki/latest/logql/)
    上找到。Loki 正在积极开发中，因此值得频繁检查新功能。
- en: You’ll find the code for this chapter in the GitHub repository at [https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter4](https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter4).
    You'll find the *Code in Action* videos for this chapter at [https://packt.link/aB4mP](https://packt.link/aB4mP).
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在 GitHub 仓库的 [https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter4](https://github.com/PacktPublishing/Observability-with-Grafana/tree/main/chapter4)
    找到本章的代码。在 [https://packt.link/aB4mP](https://packt.link/aB4mP) 上，你可以找到本章的 *Code
    in Action* 视频。
- en: Updating the OpenTelemetry demo application
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 更新 OpenTelemetry 演示应用程序
- en: First, let’s improve the logging for our demo application. For this chapter,
    we have provided an updated `OTEL-Collector.yaml` file with additional Loki log
    labels in the `chapter4` folder in the GitHub repository. These instructions assume
    you have already completed the demo project setup in [*Chapter 3*](B18277_03.xhtml#_idTextAnchor063).
    Full details on this process are available in the GitHub repository in the [*Chapter
    4*](B18277_04.xhtml#_idTextAnchor092) section of the `README.md` file.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们改进我们演示应用程序的日志记录。对于本章，我们在 GitHub 仓库的 `chapter4` 文件夹中提供了更新版的 `OTEL-Collector.yaml`
    文件，其中包含了额外的 Loki 日志标签。这些说明假设你已经完成了 [*第 3 章*](B18277_03.xhtml#_idTextAnchor063)
    的演示项目设置。关于此过程的完整细节可以在 GitHub 仓库的 `README.md` 文件的 [*第 4 章*](B18277_04.xhtml#_idTextAnchor092)
    部分找到。
- en: 'To upgrade the OpenTelemetry Collector, follow these steps:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 要升级 OpenTelemetry Collector，请按照以下步骤操作：
- en: 'Upgrade the collector with Helm:'
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用 Helm 升级采集器：
- en: '[PRE0]'
  id: totrans-15
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can validate that the upgrade was successful with this command:'
  id: totrans-16
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 你可以通过以下命令验证升级是否成功：
- en: '[PRE1]'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: You will now have a lot more labels available for your Loki log data. Let’s
    explore what that means in the next section.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你将可以为 Loki 日志数据提供更多标签。接下来让我们探索一下这意味着什么。
- en: Introducing Loki
  id: totrans-19
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 介绍 Loki
- en: '**Grafana Loki** was designed from the ground up to be a highly scalable multi-tenant
    logging solution. Its design was heavily influenced by Prometheus with a few main
    objectives:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**Grafana Loki** 从一开始就被设计为一个高度可扩展的多租户日志解决方案。它的设计深受 Prometheus 的影响，具有以下几个主要目标：'
- en: It was built with developers and operators in mind (such as *Diego* and *Ophelia*,
    who were introduced in [*Chapter 1*](B18277_01.xhtml#_idTextAnchor018))
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它是为开发者和运维人员设计的（例如在 [*第 1 章*](B18277_01.xhtml#_idTextAnchor018) 中介绍的 *Diego*
    和 *Ophelia*）
- en: It has simple ingestion; no pre-parsing is required
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它具有简单的摄取过程；不需要预处理
- en: It only indexes metadata about logs
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它仅索引关于日志的元数据
- en: It stores everything in an object store
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它将所有内容存储在对象存储中
- en: 'Let’s look at how Loki ingests data and uses labels as this will provide valuable
    insight into the way your queries source and then process the data for presentation:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下Loki如何获取数据并使用标签，因为这将为你提供宝贵的见解，帮助你理解查询如何获取和处理数据以进行展示：
- en: '**Log ingest**: Loki accepts logs from all sources with a wide choice of agents
    available to make that easy. You can even send log data directly to the Loki API.
    This makes it the perfect choice for complex environments featuring a multitude
    of systems and hardware components.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志获取**：Loki接受来自所有来源的日志，提供了多种代理选项，简化了这一过程。你甚至可以直接将日志数据发送到Loki API。这使得它成为复杂环境中包含众多系统和硬件组件的理想选择。'
- en: 'Loki stores its logs as log streams, where each entry has the following:'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Loki将其日志存储为日志流，每个条目都有以下内容：
- en: '**Timestamp**: It has nanosecond precision for accuracy.'
  id: totrans-28
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**时间戳**：它具有纳秒级精度，确保准确性。'
- en: '**Labels**: These are key-value pairs used for the identification and retrieval
    of your data; they form the Loki index.'
  id: totrans-29
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标签**：这些是用于识别和检索数据的键值对；它们构成了Loki的索引。'
- en: '**Content**: This refers to the raw log line. It is not indexed and is stored
    in compressed chunks.'
  id: totrans-30
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**内容**：指的是原始日志行。它没有被索引，而是以压缩块的形式存储。'
- en: 'The following diagram shows a log stream with a log line and its associated
    metadata:'
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下图示展示了一个日志流及其日志行和相关元数据：
- en: '![Figure 4.1 – Loki log structure](img/B18277_Figure_4.1.jpg)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![图4.1 – Loki日志结构](img/B18277_Figure_4.1.jpg)'
- en: Figure 4.1 – Loki log structure
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.1 – Loki日志结构
- en: '**Log labels**: Loki log labels provide the metadata for the log line and not
    only help identify the data but also are used to create the index for the log
    streams and structure the log storage. They have the following features:'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志标签**：Loki日志标签提供日志行的元数据，不仅有助于识别数据，还用于创建日志流的索引并构建日志存储结构。它们具有以下特点：'
- en: Each unique set of labels and values creates a log stream
  id: totrans-35
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每一组唯一的标签和值都会创建一个日志流
- en: Logs in a stream are batched, compressed, and stored as chunks
  id: totrans-36
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 流中的日志被批量处理、压缩并存储为块
- en: Labels are the index to Loki’s log streams
  id: totrans-37
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签是Loki日志流的索引
- en: Labels are used to search for logs
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标签用于搜索日志
- en: 'The following diagram demonstrates two log streams. As you can see, in a stream
    of logs, each log has the same unique set of labels. In this instance, `k8s_node_name`
    has two values:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示展示了两个日志流。正如你所见，在一个日志流中，每条日志都有相同的唯一标签集。在这个例子中，`k8s_node_name`有两个值：
- en: '![Figure 4.2 – Loki log streams](img/B18277_Figure_4.2.jpg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图4.2 – Loki日志流](img/B18277_Figure_4.2.jpg)'
- en: Figure 4.2 – Loki log streams
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.2 – Loki日志流
- en: Now that we have looked at the structure of a Loki log, let’s introduce **LogQL**,
    the query language used to extract value from your logs.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了Loki日志的结构，接下来让我们介绍**LogQL**，这是用于从日志中提取价值的查询语言。
- en: Understanding LogQL
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解LogQL
- en: Grafana developed LogQL as the query language for Loki using the **Prometheus
    Query Language** (**PromQL**) for inspiration. It was designed with developers
    (*Diego*) and operators (*Ophelia*) in mind (you can refer to [*Chapter 1*](B18277_01.xhtml#_idTextAnchor018)
    for an introduction to these personas), providing familiar filtering and aggregation
    mechanisms. Loki does not index the log content. Log events are grouped into log
    streams and indexed with labels (the log metadata). Executing a LogQL query in
    Loki invokes a type of distributed filtering against log streams to aggregate
    the log data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana开发了LogQL作为Loki的查询语言，并以**Prometheus查询语言**（**PromQL**）为灵感。它的设计考虑了开发人员（*Diego*）和运维人员（*Ophelia*）（你可以参考[*第1章*](B18277_01.xhtml#_idTextAnchor018)了解这些人物角色），提供了熟悉的过滤和聚合机制。Loki不会对日志内容进行索引。日志事件被分组为日志流，并通过标签（日志元数据）进行索引。在Loki中执行LogQL查询时，会对日志流进行一种分布式过滤，以聚合日志数据。
- en: Let’s explore the **Grafana explorer UI** for LogQL, where you will be executing
    most of your LogQL queries.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们探索用于LogQL的**Grafana Explorer UI**，你将在这里执行大多数LogQL查询。
- en: LogQL query builder
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LogQL查询构建器
- en: 'We took a brief look at the Grafana explorer UI in *Figure 3**.16* in [*Chapter
    3*](B18277_03.xhtml#_idTextAnchor063). For our examples, we will mostly work with
    raw LogQL in the **Code** editor. The following screenshot shows LogQL typed directly
    into the query builder code editor:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在[*第3章*](B18277_03.xhtml#_idTextAnchor063)的*图3.16*中简要查看了Grafana Explorer UI。对于我们的示例，我们将主要在**代码**编辑器中使用原始的LogQL。以下截图显示了直接在查询构建器代码编辑器中输入的LogQL：
- en: '![Figure 4.3 – LogQL query builder Code editor](img/B18277_Figure_4.3.jpg)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图4.3 – LogQL查询构建器代码编辑器](img/B18277_Figure_4.3.jpg)'
- en: Figure 4.3 – LogQL query builder Code editor
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图4.3 – LogQL查询构建器代码编辑器
- en: If you ever get stuck with your LogQL, you can lean on the **Log query starters**
    and **Explain query** tools to help you get started with your queries and understand
    what each step of your pipeline is doing.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在 LogQL 使用过程中遇到困难，可以依赖 **日志查询起始点** 和 **解释查询** 工具来帮助你入门，理解每个管道步骤的作用。
- en: '**Log query starters** provides some quick examples to work with your data
    and get you filtering and formatting it with ease:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '**日志查询起始点**提供了一些快速示例，帮助你轻松开始过滤和格式化数据：'
- en: '![Figure 4.4 – Log query starters](img/B18277_Figure_4.4.jpg)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.4 – 日志查询起始点](img/B18277_Figure_4.4.jpg)'
- en: Figure 4.4 – Log query starters
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.4 – 日志查询起始点
- en: 'Similarly, **Metric query starters** provides some quick examples to work with
    your data and generate metrics ready for use in dashboards and alerts:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，**度量查询起始点**提供了一些快速示例，帮助你与数据进行交互，并生成可在仪表板和警报中使用的度量值：
- en: '![Figure 4.5 – Metric query starters](img/B18277_Figure_4.5.jpg)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.5 – 度量查询起始点](img/B18277_Figure_4.5.jpg)'
- en: Figure 4.5 – Metric query starters
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.5 – 度量查询起始点
- en: 'Available in the LogQL query builder and the dashboard panel editor, **Explain
    query**, when toggled on, provides a breakdown of each stage of your LogQL pipeline.
    This tool is invaluable when analyzing an existing query or debugging your own
    during design:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 可在 LogQL 查询构建器和仪表板面板编辑器中使用，**解释查询**功能在启用时提供 LogQL 管道各阶段的详细分解。这个工具在分析现有查询或调试自己设计的查询时非常有用：
- en: '![Figure 4.6 – Explain query](img/B18277_Figure_4.6.jpg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.6 – 解释查询](img/B18277_Figure_4.6.jpg)'
- en: Figure 4.6 – Explain query
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.6 – 解释查询
- en: Let’s now explore the features of LogQL available for selecting, filtering,
    and parsing your log data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来探索 LogQL 中可用于选择、过滤和解析日志数据的功能。
- en: An overview of LogQL features
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: LogQL 功能概述
- en: 'A basic LogQL query consists of one or more log stream selectors to retrieve
    the raw log chunks for processing and an optional log pipeline to filter and parse
    the log data. The following figure shows a basic LogQL query with the `component="cartservice"`
    selector and a pipeline filter, `` |= `GetCartAsync` ``, which would return two
    lines from the log stream example in *Figure 4**.2*:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基本的 LogQL 查询由一个或多个日志流选择器组成，用于检索原始日志块进行处理，还可以选择使用日志管道过滤和解析日志数据。以下图展示了一个基本的
    LogQL 查询，使用了 `component="cartservice"` 选择器和管道过滤器，`` |= `GetCartAsync` ``, 这将返回来自
    *图 4.2* 中日志流示例的两行：
- en: '![Figure 4.7 – A basic LogQL query](img/B18277_Figure_4.7.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.7 – 一个基本的 LogQL 查询](img/B18277_Figure_4.7.jpg)'
- en: Figure 4.7 – A basic LogQL query
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.7 – 一个基本的 LogQL 查询
- en: 'The following reference table shows the different features available to you
    when building your LogQL query, which will help while you get familiar with querying
    your logs with Loki:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 下表展示了在构建 LogQL 查询时可用的不同功能，帮助你熟悉使用 Loki 查询日志：
- en: '| **LogQL Sections** | **Syntax** | **Operators** | **Scope** |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| **LogQL 部分** | **语法** | **运算符** | **范围** |'
- en: '| **Stream selector** | `{``label="value", foo!="bar"}` | `=`,`!=`,`=~`,`!~`
    | Select log streams to retrieve; there must always be at least one selector |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| **流选择器** | `{``label="value", foo!="bar"}` | `=`,`!=`,`=~`,`!~` | 选择要检索的日志流；必须始终至少有一个选择器
    |'
- en: '| **Line filter** | `` &#124;= ` [PRE2] emailservice` `` |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| **行过滤器** | `` &#124;= ` [PRE2] emailservice` `` |'
- en: '| `!=` | Log line does not contain a string | `` != ` [PRE3] email\w+` `` |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| `!=` | 日志行不包含某个字符串 | `` != ` [PRE3] email\w+` `` |'
- en: '| `!~` | Log line does not contain a match to the regex | `` !~ ` [PRE4] 2023-04-25T12:15:03.00Z+01:00"
    }}` ``'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '| `!~` | 日志行不包含与正则表达式匹配的内容 | `` !~ ` [PRE4] 2023-04-25T12:15:03.00Z+01:00"
    }}` `` |'
- en: 'Template functions can be broken down into the following distinct areas:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 模板函数可以分为以下几个不同的领域：
- en: Regex patterns
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 正则表达式模式
- en: String functions
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串函数
- en: Math functions
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数学函数
- en: JSON functions
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: JSON 函数
- en: Date and time functions
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日期和时间函数
- en: In addition, there are other functions that do not necessarily fit into a grouping
    but are nevertheless very useful. These include encode and decode functions, byte
    and duration conversions, counts, and default values.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一些不一定适合归类的其他函数，但它们同样非常有用。包括编码和解码函数、字节和持续时间转换、计数以及默认值。
- en: Line and label format
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 行和标签格式
- en: 'Two features are available for transforming logs:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 有两个功能可用于转换日志：
- en: '`| line_format "{{ .label }}"`, is used to rewrite log line content. This expression
    is used to modify your log line using the template functions referenced earlier.
    LogQL injects all labels as variables into the template, making them available
    for use, for example, `| line_format "{{.label_one}} {{.label_two}}"`. The format
    takes double quotes or backticks, where backticks allow you to avoid escaping
    characters.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`| line_format "{{ .label }}"` 用于重写日志行内容。此表达式用于使用前面提到的模板函数修改日志行。LogQL 将所有标签作为变量注入到模板中，使它们可供使用，例如，`|
    line_format "{{.label_one}} {{.label_two}}"`。格式可以使用双引号或反引号，反引号可以避免转义字符。'
- en: 'For example, if we have the following labels, `method=sent`, `status=200`,
    and `duration=15ms`, the following LogQL query would return `sent` `200 15ms`:'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，如果我们有以下标签，`method=sent`、`status=200` 和 `duration=15ms`，那么以下 LogQL 查询将返回 `sent`
    `200 15ms`：
- en: '[PRE5]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Important note
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: 'Only one instance of a label name can be used per expression; for example,
    `| label_format foo=bar,foo="new"` would fail. The desired result could be implemented
    with two expressions, one following the other, like this: `| label_format foo=bar
    |` `label_format foo="new"`.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 每个表达式中只能使用一个标签名称；例如，`| label_format foo=bar,foo="new"` 会失败。所需的结果可以通过两个表达式实现，依次执行，如下所示：`|
    label_format foo=bar |` `label_format foo="new"`。
- en: We’ve looked at how the label format gives you options to create, modify, and
    rename labels. Additionally, we have the `drop labels` command to remove labels
    completely. Let’s explore that expression now.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了标签格式如何为你提供创建、修改和重命名标签的选项。此外，我们还有 `drop labels` 命令来完全删除标签。现在让我们来探讨这个表达式。
- en: Dropping labels
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 删除标签
- en: The `drop labels` expression is used to remove labels from the pipeline. For
    example, if we have the `user=diego`, `status=200`, and `duration=1000(ms)` labels,
    the `|drop user` pipeline would drop the `user` label, leaving only `status` and
    `duration`.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '`drop labels` 表达式用于从管道中删除标签。例如，如果我们有 `user=diego`、`status=200` 和 `duration=1000(ms)`
    标签，则 `|drop user` 管道将删除 `user` 标签，只留下 `status` 和 `duration`。'
- en: We will now take a look at more of the LogQL features, exploring formatters,
    metric queries, and the UI for executing LogQL the **Grafana Explorer** where
    queries for all data sources are built.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将进一步了解 LogQL 的更多功能，探索格式化器、度量查询以及执行 LogQL 的 UI —— **Grafana Explorer**，在这里可以为所有数据源构建查询。
- en: Exploring LogQL metric queries
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 LogQL 度量查询
- en: One of the most powerful features of Loki and LogQL is the ability to create
    metrics from logs. With **metric queries**, you can, for example, calculate the
    rate of errors or the top 10 log sources with the highest volume of logs over
    the last hour. This makes it perfect for creating visualizations or triggering
    alerts.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Loki 和 LogQL 最强大的功能之一是能够从日志中创建度量指标。通过 **度量查询**，你可以，例如，计算错误率或过去一小时内日志量最大的前 10
    个日志来源。这使得它非常适合创建可视化或触发警报。
- en: If we combine metric queries with the parsers and formatters we looked at earlier
    in this section, they can be used to calculate metrics from sample data within
    a log line. For example, latency or request size can be extracted from log data
    and used as a metric. These will then be available for aggregations and the generation
    of new series.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们将度量查询与本节前面查看的解析器和格式化器结合使用，它们可以用来从日志行中的示例数据计算指标。例如，延迟或请求大小可以从日志数据中提取并用作指标。然后，这些指标将可用于聚合和生成新系列。
- en: Let’s now take a look at the aggregations available, namely, **range vector
    aggregations** and **built-in** **aggregation operators**.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下可用的聚合操作，即 **范围向量聚合** 和 **内建的** **聚合操作符**。
- en: Range vector aggregations
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 范围向量聚合
- en: 'The Prometheus concept of a **range vector** is shared by LogQL, where the
    range of samples is a range of log or label values. We will discuss the range
    vector concept in greater detail in [*Chapter 5*](B18277_05.xhtml#_idTextAnchor106).
    The selected aggregation is applied to a time interval specified as a number followed
    by a unit. The following time interval units can be used:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 中的 **范围向量** 概念在 LogQL 中得以共享，其中样本的范围是日志或标签值的范围。我们将在 [*第5章*](B18277_05.xhtml#_idTextAnchor106)
    中更详细地讨论范围向量的概念。所选聚合应用于一个时间区间，该区间以数字后跟单位的形式指定。可以使用以下时间区间单位：
- en: '`ms`: Milliseconds'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`ms`: 毫秒'
- en: '`s`: Seconds'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`s`: 秒'
- en: '`m`: Minutes'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`m`: 分钟'
- en: '`h`: Hours'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`h`: 小时'
- en: '`d`: Days'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`d`: 天'
- en: '`w`: Weeks'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`w`: 周'
- en: '`y`: Years'
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y`: 年'
- en: Examples are `6h`, `1h30m`, `10m`, and `20s`.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 示例包括 `6h`、`1h30m`、`10m` 和 `20s`。
- en: 'There are two types of range vector aggregations supported by Loki and LogQL:
    **log range aggregations** and **unwrapped range aggregations**. Let’s explore
    these in detail.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: Loki 和 LogQL 支持两种类型的范围向量聚合：**日志范围聚合** 和 **解包范围聚合**。我们来详细探讨一下这两者。
- en: Log range aggregation
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 日志范围聚合
- en: A `[10ms]`, with a function applied to it to aggregate the query over the duration.
    The duration can be placed after the log stream selector or at the end of the
    log pipeline.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 `[10ms]`，应用于该函数以在持续时间内聚合查询。持续时间可以放置在日志流选择器后面或日志管道的末尾。
- en: 'Here are the aggregation functions:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是聚合函数：
- en: '| **Aggregation** | **Description** |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| **聚合** | **描述** |'
- en: '| `rate(range)` | Will calculate the number of entries per second. |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| `rate(range)` | 将计算每秒的条目数。 |'
- en: '| `count_over_time(range)` | Will count the entries for each log stream within
    the given range. |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| `count_over_time(range)` | 将计算给定范围内每个日志流的条目数。 |'
- en: '| `bytes_rate(range)` | Useful to detect changes in log data volume. It will
    calculate the number of bytes per second for each log stream. |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| `bytes_rate(range)` | 用于检测日志数据量的变化。它会计算每个日志流每秒的字节数。 |'
- en: '| `bytes_over_time(range)` | Useful to calculate the volume of log data. It
    will count the amount of bytes used by each log stream for the given range. |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| `bytes_over_time(range)` | 用于计算日志数据量。它会计算给定区间内每个日志流使用的字节数。 |'
- en: '| `absent_over_time(range)` | Useful for alerting when there are no time series
    and logs streams for label combinations for a duration of time. It returns an
    empty vector if the range passed to it has elements and a single element vector
    with the value `1` if the range passed to it has no elements. |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| `absent_over_time(range)` | 用于在一段时间内没有时间序列和日志流时触发警报。如果传递的区间中有元素，它会返回一个空向量；如果区间中没有元素，它会返回一个包含值
    `1` 的单一元素向量。 |'
- en: Table 4.6 – Log range aggregation functions
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.6 – 日志范围聚合函数
- en: 'Here are a few log range aggregation examples:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些日志范围聚合的示例：
- en: 'To count all the log lines within the last 10 minutes for the `currencyservice`
    component:'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要计算过去 10 分钟内 `currencyservice` 组件的所有日志行数：
- en: '[PRE6]'
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'To sum the rate per second of errors by component within the last minute:'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在过去一分钟内按组件汇总每秒错误率：
- en: '[PRE7]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Unwrapped range aggregations
  id: totrans-119
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 解包区间聚合
- en: '`unwrap` function to extract a value to be used in the aggregation. They support
    grouping using the `by` or `without` clause to aggregate over distinct labels.
    The `without` aggregation removes the labels identified from the result vector
    while preserving all other labels. The `by` aggregation drops labels that are
    not identified in the `by` clause.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '`unwrap` 函数用于提取值以便在聚合中使用。它们支持使用 `by` 或 `without` 子句进行分组，以便根据不同的标签进行聚合。`without`
    聚合会从结果向量中删除标识的标签，同时保留所有其他标签。`by` 聚合会删除 `by` 子句中未标识的标签。'
- en: 'Here are the aggregation functions:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是聚合函数：
- en: '| **Aggregation** | **Description** |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| **聚合** | **描述** |'
- en: '| `rate(unwrapped-range)` | Will calculate the per-second rate of the sum of
    all of the values within the interval. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| `rate(unwrapped-range)` | 将计算区间内所有值的每秒总和的速率。 |'
- en: '| `rate_counter( unwrapped-range)` | Will calculate the per-second rate of
    all the values within the interval, treating them as counter metrics. |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| `rate_counter( unwrapped-range)` | 将计算区间内所有值的每秒速率，将它们视为计数器度量。 |'
- en: '| `sum_over_time( unwrapped-range)` | Will sum of all the values within the
    interval. |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| `sum_over_time( unwrapped-range)` | 将返回区间内所有值的总和。 |'
- en: '| `avg_over_time( unwrapped-range)` | Will return the average of all the points
    within the interval. |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| `avg_over_time( unwrapped-range)` | 将返回区间内所有点的平均值。 |'
- en: '| `max_over_time(range)` | Will return the maximum of all the points within
    the interval. |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| `max_over_time(range)` | 将返回区间内所有点的最大值。 |'
- en: '| `min_over_time( unwrapped-range)` | Will return the minimum of all the points
    within the interval. |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| `min_over_time( unwrapped-range)` | 将返回区间内所有点的最小值。 |'
- en: '| `first_over_time( unwrapped-range):` | Will return the first value of all
    the points within the interval. |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| `first_over_time( unwrapped-range):` | 将返回区间内所有点的第一个值。 |'
- en: '| `last_over_time( unwrapped-range)` | Will return the last value of all the
    points within the interval. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| `last_over_time( unwrapped-range)` | 将返回区间内所有点的最后一个值。 |'
- en: '| `stdvar_over_time( unwrapped-range)` | Will return the population standard
    variance of the values within the interval. |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| `stdvar_over_time( unwrapped-range)` | 将返回区间内值的总体标准差。 |'
- en: '| `stddev_over_time( unwrapped-range)` | Will return the population standard
    deviation of the values within the interval. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| `stddev_over_time( unwrapped-range)` | 将返回区间内值的总体标准差。 |'
- en: '| `quantile_over_time(scalar, unwrapped-range)` | Will return the specified
    quantile of the values within the interval. |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| `quantile_over_time(scalar, unwrapped-range)` | 将返回区间内指定分位数的值。 |'
- en: '| `absent_over_time( unwrapped-range)` | Useful for alerting when there are
    no time series and logs streams for label combinations for a duration of time.
    It returns an empty vector if the range passed to it has elements and a single
    element vector with the value `1` if the range passed to it has no elements. |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| `absent_over_time( unwrapped-range)` | 当标签组合在一段时间内没有时间序列和日志流时，适用于告警。若传入的范围包含元素，则返回一个空向量；若传入的范围没有元素，则返回一个单元素向量，值为
    `1`。 |'
- en: Table 4.7 – Unwrapped range aggregation functions
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.7 – 未封装范围聚合函数
- en: The `sum_over_time`, `absent_over_time`, `rate`, and `rate_counter` functions
    are excluded from grouping.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`sum_over_time`、`absent_over_time`、`rate` 和 `rate_counter` 函数不参与分组。'
- en: 'Here are a few unwrapped range aggregation examples:'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些未封装范围聚合的示例：
- en: 'To calculate the 99th percentile of the `webserver` container `request_time`
    excluding any JSON formatting errors by `path` within the last minute:'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算 `webserver` 容器中 `request_time` 的 99 百分位数，排除按 `path` 分类的 JSON 格式错误，并限制在过去的一分钟内：
- en: '[PRE8]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'To calculate the number of bytes processed by `org_id` within the last minute,
    filtering where the log contains the `metrics` string:'
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算过去一分钟内，`org_id` 处理的字节数，并筛选出日志中包含 `metrics` 字符串的记录：
- en: '[PRE9]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Built-in aggregation operators
  id: totrans-142
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 内置聚合运算符
- en: LogQL supports a subset of the **built-in aggregation operators** that PromQL
    supports. These can be used to aggregate the element of a single vector, resulting
    in a new vector of fewer elements but with aggregated values.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: LogQL 支持 PromQL 所支持的**内置聚合运算符**的子集。可以使用这些运算符对单一向量的元素进行聚合，得到一个新向量，包含更少的元素但具有聚合值。
- en: 'The following table shows some built-in range aggregation operators:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 下表展示了一些内置范围聚合运算符：
- en: '| **Aggregation** | **Description** |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| **聚合** | **描述** |'
- en: '| `sum` | Will calculate the sum by the labels specified |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| `sum` | 将根据指定的标签计算总和 |'
- en: '| `avg` | Will calculate the average by the labels specified |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| `avg` | 将根据指定的标签计算平均值 |'
- en: '| `min` | Will select the minimum by the labels specified |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| `min` | 将根据指定的标签选择最小值 |'
- en: '| `max` | Will select the maximum by the labels specified |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| `max` | 将根据指定的标签选择最大值 |'
- en: '| `stddev` | Will calculate the population standard deviation by the labels
    specified |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| `stddev` | 将根据指定的标签计算总体标准差 |'
- en: '| `stdvar` | Will calculate the population standard variance by the labels
    specified |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| `stdvar` | 将根据指定的标签计算总体标准方差 |'
- en: '| `count` | Will count the number of elements in a vector |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| `count` | 将计算向量中元素的数量 |'
- en: '| `topk` | Will select the largest `k` elements by sample value |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| `topk` | 将按样本值选择最大的 `k` 个元素 |'
- en: '| `bottomk` | Will select the smallest `k` elements by sample value |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| `bottomk` | 将按样本值选择最小的 `k` 个元素 |'
- en: '| `sort` | Will return the vector elements sorted by their sample values, in
    ascending order |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| `sort` | 将按样本值的升序返回向量元素 |'
- en: '| `sort_desc` | Will return the vector elements sorted by their sample values,
    in descending order |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| `sort_desc` | 将按样本值的降序返回向量元素 |'
- en: Table 4.8 – Built-in range aggregation functions
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4.8 – 内置范围聚合函数
- en: 'Here are a few built-in range aggregation operator examples:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是一些内置范围聚合运算符的示例：
- en: 'To return the top 10 applications by the highest log throughput for the last
    10 minutes by `name`:'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回过去 10 分钟内按 `name` 排名的前 10 个日志吞吐量最高的应用程序：
- en: '[PRE10]'
  id: totrans-160
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'To return the average rate of `GET` requests to the `/hello` endpoint for web
    server logs by region for the last 10 seconds:'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算过去 10 秒内，各区域 Web 服务器日志中 `/hello` 端点的 `GET` 请求的平均速率：
- en: '[PRE11]'
  id: totrans-162
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: We have looked at how LogQL can parse different log formats. Let’s now take
    a look at the Loki architecture and how Loki stores and queries the log data you
    send.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经了解了 LogQL 如何解析不同的日志格式。现在让我们来看看 Loki 的架构，以及 Loki 如何存储和查询你发送的日志数据。
- en: Exploring Loki’s architecture
  id: totrans-164
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 探索 Loki 的架构
- en: 'Grafana Loki has a full **microservices architecture** that can be run as a
    single binary and a simple scalable deployment to a full microservices deployment
    running all the components as distinct processes. At a high level, it is made
    up of features that implement write, read, and store functionality, as shown in
    the following diagram:'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana Loki 具有完整的 **微服务架构**，可以作为一个单一二进制文件运行，并且可以简单地扩展部署为完整的微服务架构，将所有组件作为独立的进程运行。从高层次来看，它由实现写入、读取和存储功能的特性组成，如下图所示：
- en: '![Figure 4.8 – High-level overview of Loki architecture](img/B18277_Figure_4.8.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.8 – Loki 架构的高级概览](img/B18277_Figure_4.8.jpg)'
- en: Figure 4.8 – High-level overview of Loki architecture
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.8 – Loki 架构的高级概览
- en: Both *write* and *read* functionality can be scaled independently to suit your
    particular needs and use cases.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '*写入* 和 *读取* 功能可以独立扩展，以适应您的特定需求和使用案例。'
- en: 'Under the hood, Loki has the following core components:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在幕后，Loki 有以下核心组件：
- en: Distributor
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 分发器
- en: Ingester
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ingester
- en: Query frontend
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询前端
- en: Querier
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询器
- en: 'Backend services:'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 后端服务：
- en: Ruler
  id: totrans-175
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 规则引擎
- en: Compactor
  id: totrans-176
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 压缩器
- en: Query scheduler
  id: totrans-177
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询调度器
- en: 'Let’s now look at the functionality and core components in more detail:'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们更详细地了解一下功能和核心组件：
- en: '**Writes**: Writes for the incoming log data hit the distributor, which is
    responsible for data sharding and partitioning, and sending them to the ingesters.
    The distributor validates each set of streams, checking labels, timestamps, and
    log line sizes, then batches log stream chunks to multiple ingesters.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**写入**：接收日志数据的写入请求会先到达分发器，分发器负责数据分片和分区，并将其发送到 ingester。分发器验证每个流集，检查标签、时间戳和日志行大小，然后将日志流块批量发送到多个
    ingester。'
- en: The ingester writes to the **write-ahead logs** (**WALs**) for resiliency and
    finally into the object storage backend.
  id: totrans-180
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Ingester 写入 **写前日志**（**WALs**）以确保数据的可靠性，并最终写入对象存储后端。
- en: Both the querier and ruler read the ingester to access the most recent data.
    The querier can additionally access the object storage data.
  id: totrans-181
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 查询器和规则引擎都会读取 ingester，以访问最新数据。查询器还可以访问对象存储中的数据。
- en: '**Reads**: The query frontend is responsible for accelerating query execution,
    distributing large queries across multiple queriers and ensuring retries in the
    event of failure.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**读取**：查询前端负责加速查询执行，将大型查询分发到多个查询器，并在失败时确保重试。'
- en: 'Queriers parse the LogQL and query the underlying systems: the ingester for
    the most recent data and object storage for older data. The querier de-duplicates
    data with the same nanosecond timestamp, labels, and log content.'
  id: totrans-183
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 查询器解析 LogQL 并查询底层系统：ingester 获取最新数据，对象存储获取较旧数据。查询器通过去重相同纳秒时间戳、标签和日志内容的数据。
- en: '**Storage**: The object storage is where the batched logs are stored. The compactor
    is responsible for maintaining the data. It monitors the object storage, de-duplicating
    data and removing old logs.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储**：对象存储是批量日志存储的地方。压缩器负责维护数据。它监控对象存储，进行数据去重并移除旧的日志。'
- en: '**Backend services**: The ruler evaluates queries and performs actions based
    on the result. The actions can be recording rules (generating new metrics for
    LogQL queries) or alerts for system events.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**后端服务**：规则引擎评估查询并根据结果执行操作。操作可以是记录规则（为 LogQL 查询生成新指标）或系统事件的告警。'
- en: The alert manager is responsible for notifications and alerts triggering and
    being sent from the system, but this is not included with Loki.
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 告警管理器负责系统中通知和告警的触发和发送，但这不包括在 Loki 中。
- en: '**Loki index**: In this chapter, so far, we have covered Loki log labels and
    LogQL log stream selectors. The underlying architecture completes the picture,
    explaining how the distributor shards the data. It is that sharding and subsequent
    storage using the label-based Loki index that makes Loki fast and inexpensive.
    It also validates the importance of a good labeling strategy to improving storage
    and retrieval, and essentially querying performance.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Loki 索引**：在本章到目前为止，我们已经介绍了 Loki 日志标签和 LogQL 日志流选择器。底层架构完成了这幅图，解释了分发器如何对数据进行分片。正是这种分片和随后使用基于标签的
    Loki 索引进行存储，使得 Loki 既快速又廉价。它还验证了良好的标签策略对于提升存储、检索和查询性能的重要性。'
- en: Now that we have built up a good understanding of Loki, let’s look at a few
    best practices and some tips for working with Loki log data.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经对 Loki 有了很好的理解，接下来让我们看看一些最佳实践和使用 Loki 日志数据的一些技巧。
- en: Tips, tricks, and best practices
  id: totrans-189
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示、技巧和最佳实践
- en: In this section, we will look at a few best practices for filtering and cardinality.
    We will then look at the LogQL Analyzer and LogCLI, which are tools that can help
    you when you are working with Grafana Loki log data.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将讨论一些过滤和基数的最佳实践。然后，我们将介绍 LogQL 分析器和 LogCLI，这些工具可以在你处理 Grafana Loki 日志数据时提供帮助。
- en: 'Here are some best practices to keep in mind:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些需要记住的最佳实践：
- en: '**Filter first**: Loki stores the raw log in object storage as compressed chunks.
    Because of this, it is important, from a speed point of view, to filter early.
    Processing complex parsing on smaller datasets will increase the response time.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**首先过滤**：Loki 将原始日志以压缩块的形式存储在对象存储中。因此，从速度的角度来看，早期进行过滤是非常重要的。在较小的数据集上处理复杂的解析将增加响应时间。'
- en: '`namespace`'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`namespace`'
- en: '`cluster`'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`cluster`'
- en: '`job`'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`job`'
- en: '`app`'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`app`'
- en: '`instance`'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`instance`'
- en: '`filename`'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`filename`'
- en: 'Some examples of poor labels (often vague with unlimited values) are the following:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些不好的标签示例（通常含糊不清，且值的范围没有限制）：
- en: '`userid`'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`userid`'
- en: '`traceid`'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`traceid`'
- en: '`path`'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`path`'
- en: '`status code`'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`status code`'
- en: '`date`'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`date`'
- en: 'Now, let’s take a closer look at the advantages offered by using the LogQL
    Analyzer and LogCLI:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们仔细看看使用 LogQL 分析器和 LogCLI 的优势：
- en: '**LogQL Analyzer**: The LogQL Analyzer provides an interface on the Grafana
    website for you to practice your LogQL queries. You can view detailed explanations
    of the actions implemented by your query on a sample log entry. Head over to [https://grafana.com/docs/loki/latest/query/analyzer/](https://grafana.com/docs/loki/latest/query/analyzer/)
    to try it out. Let’s take a look at the Loki LogQL Analyzer:'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**LogQL 分析器**：LogQL 分析器提供了一个在 Grafana 网站上使用的界面，供你练习 LogQL 查询。你可以查看你的查询在一个示例日志条目上所执行操作的详细解释。请访问[https://grafana.com/docs/loki/latest/query/analyzer/](https://grafana.com/docs/loki/latest/query/analyzer/)进行尝试。让我们来看看
    Loki LogQL 分析器：'
- en: '![Figure 4.9 – Loki LogQL Analyzer](img/B18277_Figure_4.9.jpg)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![图 4.9 – Loki LogQL 分析器](img/B18277_Figure_4.9.jpg)'
- en: Figure 4.9 – Loki LogQL Analyzer
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4.9 – Loki LogQL 分析器
- en: The explanations provided by the LogQL Analyzer are far more detailed than the
    **Explain query** feature in the query builder, so it’s worth checking out while
    you are learning LogQL.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: LogQL 分析器提供的解释比查询构建器中的**Explain 查询**功能更为详细，因此在学习 LogQL 时，值得一试。
- en: '**Using LogCLI**: For command-line lovers everywhere, Grafana Loki comes with
    a command-line interface called LogCLI that allows you to do the following at
    your terminal:'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**使用 LogCLI**：对于喜爱命令行的用户来说，Grafana Loki 提供了一个命令行接口 LogCLI，允许你在终端中执行以下操作：'
- en: Query your logs
  id: totrans-211
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查询你的日志
- en: Evaluate metric queries for a single point in time
  id: totrans-212
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估单一时间点的度量查询
- en: Identify Loki labels and obtain stats about their values
  id: totrans-213
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 识别 Loki 标签并获取其值的统计信息
- en: Return log streams for a time window with a label matcher
  id: totrans-214
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 返回带有标签匹配器的时间窗口日志流
- en: This is great if you need access to the power of LogQL without leaving the comfort
    of your own console.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你希望在不离开控制台的情况下访问 LogQL 的强大功能，这将是非常方便的。
- en: 'Full setup documentation and command references can be found here: [https://grafana.com/docs/loki/latest/query/](https://grafana.com/docs/loki/latest/query/).
    You can download the binary from the Loki releases page on GitHub.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的设置文档和命令参考可以在这里找到：[https://grafana.com/docs/loki/latest/query/](https://grafana.com/docs/loki/latest/query/)。你可以从
    Loki 的 GitHub 发布页面下载二进制文件。
- en: We will now wrap up this chapter with a reminder of what you have learned.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将总结本章内容，回顾你所学到的知识。
- en: Summary
  id: totrans-218
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have taken a look at Loki, exploring the log ingest format
    and the importance of log labels. We then started looking at the comprehensive
    features of LogQL, the query language of Loki, and how we can select log streams
    and then filter, parse, format, and transform log lines. These techniques will
    be invaluable when working with Loki to build dashboards in [*Chapter 8*](B18277_08.xhtml#_idTextAnchor172).
    Then, we looked at the Loki architecture to get an understanding of what’s going
    on behind the scenes. We also explained how our data is stored and how Loki can
    be scaled to increase performance. Lastly, we reviewed some tips and best practices
    that can help you improve your experience with Loki.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们介绍了 Loki，探讨了日志摄取格式和日志标签的重要性。接着，我们开始研究 Loki 的查询语言 LogQL 的全面功能，以及如何选择日志流，然后过滤、解析、格式化和转换日志行。当你使用
    Loki 构建仪表板时，这些技巧在[*第8章*](B18277_08.xhtml#_idTextAnchor172)中将非常宝贵。然后，我们了解了 Loki
    的架构，以便了解幕后发生的事情。我们还解释了数据是如何存储的，以及 Loki 如何通过扩展来提高性能。最后，我们回顾了一些可以帮助你提升 Loki 使用体验的技巧和最佳实践。
- en: In the next chapter, we’ll move on from logs to explore **metrics** and **Prometheus**,
    where Loki took its original inspiration from.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将从日志转向探索**度量**和**Prometheus**，Loki就是从这些地方汲取了最初的灵感。
