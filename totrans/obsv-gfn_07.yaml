- en: '7'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '7'
- en: Interrogating Infrastructure with Kubernetes, AWS, GCP, and Azure
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Kubernetes、AWS、GCP 和 Azure 查询基础设施
- en: This chapter will introduce the setup and configuration required to capture
    **telemetry** from various common cloud infrastructure providers. You will learn
    about the different options available for Kubernetes. Additionally, you will investigate
    the main plugins that allow Grafana to query data from cloud vendors such as **Amazon
    Web Services** (**AWS**), **Google Cloud Platform** (**GCP**), and Azure. You
    will look at solutions for handling large volumes of telemetry where direct connections
    are not scalable. The chapter will also cover options for filtering and selecting
    telemetry data before it gets to Grafana for **security** and **cost optimization**.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍捕获来自各大常见云基础设施提供商的**遥测**所需的设置和配置。你将了解 Kubernetes 的不同选项。此外，你将探讨使 Grafana
    能够查询来自云服务商（如**Amazon Web Services**（**AWS**）、**Google Cloud Platform**（**GCP**）和
    Azure）的数据的主要插件。你还将研究如何处理大量遥测数据的解决方案，尤其是在直接连接不可扩展的情况下。本章还将介绍在遥测数据到达 Grafana 之前进行过滤和选择的选项，以实现**安全性**和**成本优化**。
- en: 'We will cover the following main topics in this chapter:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要主题：
- en: Monitoring Kubernetes using Grafana
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Grafana 监控 Kubernetes
- en: Visualizing AWS telemetry with Grafana Cloud
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Grafana Cloud 可视化 AWS 遥测
- en: Monitoring GCP using Grafana
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Grafana 监控 GCP
- en: Monitoring Azure using Grafana
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Grafana 监控 Azure
- en: Best practices and approaches
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最佳实践与方法
- en: Technical requirements
  id: totrans-9
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'In this chapter, you will work with multiple cloud providers using a Grafana
    Cloud instance. You will need the following:'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你将使用 Grafana Cloud 实例与多个云提供商进行协作。你将需要以下内容：
- en: A Grafana Cloud instance (set up in [*Chapter 3*](B18277_03.xhtml#_idTextAnchor063))
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个 Grafana Cloud 实例（在[*第 3 章*](B18277_03.xhtml#_idTextAnchor063)中设置）
- en: Kubernetes and Helm (set up in [*Chapter 3*](B18277_03.xhtml#_idTextAnchor063))
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 和 Helm（在[*第 3 章*](B18277_03.xhtml#_idTextAnchor063)中设置）
- en: Accounts with the AWS, GCP, and Azure cloud providers with admin-level permissions
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 拥有 AWS、GCP 和 Azure 云提供商管理员权限的账户
- en: Monitoring Kubernetes using Grafana
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Grafana 监控 Kubernetes
- en: Kubernetes has been designed to be monitored, and as such, it presents multiple
    options for anyone wanting to monitor it or the workloads running on it using
    Grafana. In this section, we will focus on monitoring Kubernetes, as we have already
    worked with Kubernetes workloads in previous chapters using the OpenTelemetry
    Demo application.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 设计时就考虑到了监控，因此它为任何希望使用 Grafana 监控其本身或运行在其上的工作负载的人提供了多种选项。本节将重点介绍 Kubernetes
    的监控，因为我们在前几章中已经使用 OpenTelemetry 演示应用程序处理了 Kubernetes 工作负载。
- en: 'The OpenTelemetry Collector introduced in [*Chapter 3*](B18277_03.xhtml#_idTextAnchor063)
    provides receivers, processors, and exporters to implement Kubernetes monitoring
    with data collection and enrichment. The following table identifies those components
    with a brief explanation for each of them:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第 3 章*](B18277_03.xhtml#_idTextAnchor063)中介绍的 OpenTelemetry Collector 提供了接收器、处理器和出口程序，用于实现
    Kubernetes 监控和数据收集与增强。下表列出了这些组件，并对每个组件做了简要说明：
- en: '| **OpenTelemetry Component** | **Description** |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| **OpenTelemetry 组件** | **描述** |'
- en: '| Kubernetes Attributes Processor | The Kubernetes Attributes Processor appends
    Kubernetes metadata to telemetry, providing the necessary context for correlation.
    |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| Kubernetes 属性处理器 | Kubernetes 属性处理器将 Kubernetes 元数据附加到遥测数据，为关联提供必要的上下文。 |'
- en: '| Kubeletstats Receiver | The Kubeletstats Receiver obtains Pod metrics via
    a pull mechanism from the kubelet API. It collects node and workload metrics from
    each node it is installed on. |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| Kubeletstats 接收器 | Kubeletstats 接收器通过拉取机制从 kubelet API 获取 Pod 指标。它收集安装在每个节点上的节点和工作负载指标。
    |'
- en: '| Filelog Receiver | The Filelog Receiver collects Kubernetes and workload
    logs that are written to `stdout` and `stderr`. |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| Filelog 接收器 | Filelog 接收器收集写入 `stdout` 和 `stderr` 的 Kubernetes 和工作负载日志。 |'
- en: '| Kubernetes Cluster Receiver | The Kubernetes Cluster Receiver collects cluster-level
    metrics and entity events using the Kubernetes API. |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| Kubernetes 集群接收器 | Kubernetes 集群接收器通过 Kubernetes API 收集集群级别的指标和实体事件。 |'
- en: '| Kubernetes Object Receiver | The Kubernetes Object Receiver collects objects
    for example events from the Kubernetes API. |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| Kubernetes 对象接收器 | Kubernetes 对象接收器收集来自 Kubernetes API 的对象，例如事件。 |'
- en: '| Prometheus Receiver | The Prometheus Receiver scrapes metrics using Prometheus
    `scrape_config` settings. |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| Prometheus 接收器 | Prometheus 接收器使用 Prometheus `scrape_config` 设置抓取指标。 |'
- en: '| Host Metrics Receiver | The Host Metrics Receiver scrapes metrics from Kubernetes
    nodes. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 主机度量接收器 | 主机度量接收器从 Kubernetes 节点抓取度量数据。 |'
- en: Table 7.1 – Kubernetes receivers
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 表 7.1 – Kubernetes 接收器
- en: Let’s now explore each component and how to implement them.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们探讨每个组件及其实现方式。
- en: Kubernetes Attributes Processor
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 属性处理器
- en: The OpenTelemetry **Kubernetes Attributes Processor** can automatically discover
    Pods, extract metadata from them, and add the extracted metadata to spans, metrics,
    and logs as additional resource attributes. It provides necessary context to your
    telemetry, enabling the correlation of your application’s metrics, events, logs,
    traces, and signals with your Kubernetes telemetry, such as Pod metrics and traces.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry **Kubernetes 属性处理器**可以自动发现 Pods，提取其元数据，并将提取的元数据添加到跨度、度量和日志中，作为额外的资源属性。它为你的遥测提供了必要的上下文，能够将你的应用程序的度量、事件、日志、跟踪和信号与
    Kubernetes 的遥测数据进行关联，如 Pod 的度量和跟踪。
- en: Data passing through the processor is by default associated to a Pod via the
    incoming request’s IP address, but different rules can be configured.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 通过处理器传递的数据默认通过传入请求的 IP 地址与 Pod 关联，但可以配置不同的规则。
- en: 'The OpenTelemetry Collector Helm chart comes with several presets. For instance,
    the `kubernetesAttributes` preset, when enabled, will add the necessary RBAC roles
    to a ClusterRole and will add a `k8sattributesprocessor` to each enabled pipeline:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry Collector Helm chart 配置有多个预设。例如，启用 `kubernetesAttributes` 预设时，它会将必要的
    RBAC 角色添加到 ClusterRole，并会在每个启用的管道中添加一个 `k8sattributesprocessor`：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Kubernetes comes with its own metadata to document its components. When using
    the `kubernetesAttributes` preset, the following attributes are added by default:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 自带元数据用于文档化其组件。当使用 `kubernetesAttributes` 预设时，默认情况下会添加以下属性：
- en: '`k8s.namespace.name`: The namespace the Pod is deployed to.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`k8s.namespace.name`：Pod 部署的命名空间。'
- en: '`k8s.pod.name`: The name of the Pod.'
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`k8s.pod.name`：Pod 的名称。'
- en: '`k8s.pod.uid`: The unique ID for the Pod.'
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`k8s.pod.uid`：Pod 的唯一标识符。'
- en: '`k8s.pod.start_time`: The timestamp for Pod creation, useful when understanding
    Pod restarts.'
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`k8s.pod.start_time`：Pod 创建的时间戳，在理解 Pod 重启时非常有用。'
- en: '`k8s.deployment.name`: The Kubernetes deployment name for the application.'
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`k8s.deployment.name`：应用程序的 Kubernetes 部署名称。'
- en: '`k8s.node.name`: The name of the node the Pod is running on. As Kubernetes
    distributes the Pods over all of its nodes, it is important to understand whether
    any are having specific problems.'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`k8s.node.name`：Pod 所运行节点的名称。由于 Kubernetes 会将 Pods 分布到所有节点上，了解是否有节点出现特定问题非常重要。'
- en: Additionally, the Kubernetes Attributes Processor creates custom resource attributes
    for your telemetry using Pod and namespace labels and annotations.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Kubernetes 属性处理器还会使用 Pod 和命名空间的标签与注释，为你的遥测创建自定义资源属性。
- en: 'There are two methods applied to obtain and associate your data, that is, `extract`
    and `pod_association`. You can enable them in your Helm chart as detailed in the
    following code:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可用于获取和关联数据，即 `extract` 和 `pod_association`。你可以在 Helm chart 中启用它们，如以下代码所示：
- en: '[PRE1]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Let’s look at these methods in greater detail:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地了解这些方法：
- en: '`extract`: This method provides the ability to use metadata, annotations, and
    labels as resource attributes for your telemetry. It has the following options:'
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`extract`：该方法允许使用元数据、注释和标签作为遥测的资源属性。它有以下选项：'
- en: '`metadata`: Used to extract values from the Pod and namespace, such as `k8s.namespace.name`
    and `k8s.pod.name`'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`metadata`：用于从 Pod 和命名空间提取值，如 `k8s.namespace.name` 和 `k8s.pod.name`'
- en: '`annotations`: Used to extract the value of a Pod or namespace annotation with
    a key and insert it as a resource attribute:'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`annotations`：用于提取 Pod 或命名空间注释中指定键的值，并将其作为资源属性插入：'
- en: '[PRE2]'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '`labels`: Used to extract the value of a Pod or namespace label with a key
    and insert it as a resource attribute:'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`labels`：用于提取 Pod 或命名空间标签中指定键的值，并将其作为资源属性插入：'
- en: '[PRE3]'
  id: totrans-48
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Both `annotations` and `labels` can also be used with regex to extract part
    of the value for the new resource attribute.
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '`annotations` 和 `labels` 也可以与正则表达式一起使用，从值中提取部分内容作为新的资源属性。'
- en: '`pod_association`: This method associates data with the relevant Pod. You can
    configure multiple sources and the agent will try them in order, stopping when
    it finds a match. `pod_association` has the `sources` option, which is used to
    identify the resource attribute to use for the association, or it uses the IP
    attribute from the connection context:'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pod_association`：此方法将数据与相关的 Pod 关联。您可以配置多个源，代理会按顺序尝试这些源，直到找到匹配的为止。`pod_association`
    有一个 `sources` 选项，用于标识要用于关联的资源属性，或者它会使用连接上下文中的 IP 属性：'
- en: '[PRE4]'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Permissions
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 权限
- en: If you are not using the `kubernetesAttributes` preset, you will have to provide
    the necessary permissions to allow access to the Kubernetes API. Usually, being
    able to access Pod, namespace, and ReplicaSet resources is adequate, but this
    will depend upon your cluster configuration.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您没有使用 `kubernetesAttributes` 预设，则需要提供必要的权限，以允许访问 Kubernetes API。通常，能够访问 Pod、命名空间和
    ReplicaSet 资源就足够了，但这取决于您的集群配置。
- en: Kubeletstats Receiver
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubeletstats 接收器
- en: The **Kubeletstats Receiver** connects to the kubelet API to collect metrics
    about the node and the workloads running on the node, which is why the preferred
    deployment mode is DaemonSet. Metrics are collected for Pods and nodes by default
    but can additionally be configured to collect metrics from containers and volumes.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubeletstats 接收器**连接到 kubelet API，以收集关于节点和在节点上运行的工作负载的度量，因此推荐的部署模式是 DaemonSet。默认情况下，度量会收集
    Pod 和节点的指标，但也可以额外配置以收集来自容器和卷的指标。'
- en: 'The following code shows the configuration of the Kubeletstats Receiver:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 以下代码显示了 Kubeletstats 接收器的配置：
- en: '[PRE5]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Filelog Receiver
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 文件日志接收器
- en: Although not a Kubernetes-specific receiver, the **Filelog Receiver** is the
    most popular log collection mechanism for Kubernetes. It tails and parses logs
    from files using operators chained together to process log data.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管不是 Kubernetes 特定的接收器，**文件日志接收器**是 Kubernetes 中最受欢迎的日志收集机制。它通过操作符链式处理日志数据，从文件中获取并解析日志。
- en: 'The OpenTelemetry Collector Helm chart has the `logsCollection` preset to add
    the necessary RBAC roles to the ClusterRole, and it will add a `filelogreceiver`
    instance to each enabled pipeline (we will explain `includeCollectorLogs` in [*Chapter
    10*](B18277_10.xhtml#_idTextAnchor204)):'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: OpenTelemetry Collector Helm 图表具有 `logsCollection` 预设，用于将必要的 RBAC 角色添加到 ClusterRole
    中，并且它会将 `filelogreceiver` 实例添加到每个启用的管道中（我们将在[*第 10 章*](B18277_10.xhtml#_idTextAnchor204)中解释
    `includeCollectorLogs`）：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'If configuring this yourself, you will have to add the roles and `filelogreceiver`
    into your pipelines manually. A basic Filelog Receiver shows what to include and
    exclude, along with additional processing options:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 如果自己配置，您需要手动将角色和`filelogreceiver`添加到管道中。一个基本的文件日志接收器显示了要包括和排除的内容，以及其他处理选项：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Additionally, operators can be applied for log processing, filtering, and parsing.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还可以应用操作符进行日志处理、过滤和解析。
- en: 'The following is a list of Filelog Receiver parsers:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是文件日志接收器解析器的列表：
- en: '`json_parser`: To parse JSON'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`json_parser`：用于解析 JSON'
- en: '`regex_parser`: To perform regular expression parsing'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`regex_parser`：用于执行正则表达式解析'
- en: '`csv_parser`: To parse comma-separated values'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`csv_parser`：用于解析以逗号分隔的值'
- en: '`key_value_parser`: To process structured key-value pairs'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`key_value_parser`：用于处理结构化的键值对'
- en: '`uri_parser`: To process structured web paths'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`uri_parser`：用于处理结构化的 web 路径'
- en: '`syslog_parser`: To process the standard syslog log format'
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`syslog_parser`：用于处理标准的 syslog 日志格式'
- en: Kubernetes Cluster Receiver
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 集群接收器
- en: The **Kubernetes Cluster Receiver**, as its name suggests, collects metrics
    and events from the cluster using the Kubernetes API server. This receiver is
    used to obtain information regarding Pod phases, node conditions, and other cluster-level
    operations. The receiver must be deployed as a single instance; otherwise, the
    data would be duplicated.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes 集群接收器**顾名思义，使用 Kubernetes API 服务器收集集群的度量和事件。该接收器用于获取关于 Pod 阶段、节点状态和其他集群级操作的信息。接收器必须作为单个实例部署，否则数据会重复。'
- en: 'An example cluster receiver configuration follows:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个集群接收器配置示例：
- en: '[PRE8]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Kubernetes Object Receiver
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes 对象接收器
- en: The **Kubernetes Objects Receiver** can be used to collect any type of object
    from the Kubernetes API server. As with the Kubernetes Cluster Receiver, this
    must be deployed as a single instance to prevent duplicate data.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '**Kubernetes 对象接收器**可用于从 Kubernetes API 服务器收集任何类型的对象。与 Kubernetes 集群接收器一样，它必须作为单个实例部署，以防止数据重复。'
- en: 'The receiver can be implemented to pull or watch objects by using `pull` or
    `watch`:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 该接收器可以通过使用 `pull` 或 `watch` 来拉取或监视对象：
- en: When `pull` is implemented, the receiver periodically polls the Kubernetes API
    and lists all the objects in the cluster. Each object will be converted to its
    own log.
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当实现`pull`时，接收器定期轮询Kubernetes API并列出集群中的所有对象。每个对象将被转换为其自己的日志。
- en: When `watch` is configured, the receiver creates a stream with the Kubernetes
    API to receive updates as and when objects change; this is the most common use
    case.
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当配置`watch`时，接收器会创建一个与Kubernetes API的流，以便在对象更改时接收更新；这是最常见的用例。
- en: 'Let’s look at an example of Kubernetes Object Receiver configuration:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看一个Kubernetes对象接收器配置的示例：
- en: '[PRE9]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Prometheus Receiver
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Prometheus接收器
- en: 'The `scrape_config` options are supported by the receiver. An example of this
    implementation and `scrape_configs` can be seen in the [*Chapter 5*](B18277_05.xhtml#_idTextAnchor106)
    demo project code. Here is an example Prometheus Receiver configuration:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '`scrape_config`选项由接收器支持。此实现和`scrape_configs`的示例可以在[*第5章*](B18277_05.xhtml#_idTextAnchor106)演示项目代码中看到。以下是Prometheus接收器配置示例：'
- en: '[PRE10]'
  id: totrans-85
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'The Prometheus Receiver is stateful, so the following points need to be taken
    into consideration when using it:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus接收器是有状态的，因此在使用时需要考虑以下几点：
- en: The receiver cannot auto-scale the scraping process with multiple replicas
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 接收器无法通过多个副本自动扩展抓取过程
- en: Running multiple replicas with the same config will scrape targets multiple
    times
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用相同配置运行多个副本将会多次抓取目标
- en: To manually scale the scraping process, each replica will need to be configured
    with a different scraping configuration
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 要手动扩展抓取过程，每个副本需要配置不同的抓取配置
- en: Host Metrics Receiver
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主机度量接收器
- en: The **Host Metrics Receiver** collects metrics from a host using a variety of
    scrapers; the receiver will need access to the host filesystem volume to work
    correctly.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '**主机度量接收器**使用多种抓取器从主机收集度量指标；接收器需要访问主机文件系统卷才能正常工作。'
- en: '*Table 7.2* shows the metrics available to scrape. The OpenTelemetry Collector
    Helm chart has the `hostMetrics` preset to add the necessary configurations:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '*表7.2*显示了可供抓取的度量指标。OpenTelemetry Collector Helm图表有`hostMetrics`预设来添加必要的配置：'
- en: '[PRE11]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'By default, the preset will scrape every 10 seconds, which may generate too
    many metrics for your backend system. Be aware of this and consider overriding
    it to 60 seconds. The following table also shows the metrics that will be scraped
    by default using the preset:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 默认情况下，预设将每10秒抓取一次数据，这可能会为你的后端系统生成过多的度量指标。请注意这一点，并考虑将抓取间隔重写为60秒。下表还显示了使用预设时默认会抓取的度量指标：
- en: '| **Metric Scraper** | **Description** | **Included when using the** **hostMetrics
    preset** |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| **度量抓取器** | **描述** | **使用hostMetrics预设时包含** |'
- en: '| CPU | Scrapes CPU utilization metrics | Yes |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| CPU | 抓取CPU利用率度量指标 | 是 |'
- en: '| Disk | Scrapes disk I/O metrics | Yes |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 磁盘 | 抓取磁盘I/O度量指标 | 是 |'
- en: '| Load | Scrapes CPU load metrics | Yes |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 负载 | 抓取CPU负载度量指标 | 是 |'
- en: '| Filesystem | Scrapes filesystem utilization metrics | Yes |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 文件系统 | 抓取文件系统利用率度量指标 | 是 |'
- en: '| Memory | Scrapes memory utilization metrics | Yes |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 内存 | 抓取内存利用率度量指标 | 是 |'
- en: '| Network | Scrapes network interface I/O metrics and TCP connection metrics
    | Yes |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 网络 | 抓取网络接口I/O度量指标和TCP连接度量指标 | 是 |'
- en: '| Paging | Scrapes paging and swap space utilization and I/O metrics | No |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 分页 | 抓取分页和交换空间利用率以及I/O度量指标 | 否 |'
- en: '| Processes | Scrapes process count metrics | No |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 进程 | 抓取进程计数度量指标 | 否 |'
- en: '| Process | Scrapes per-process CPU, memory, and disk I/O metrics | No |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 进程 | 抓取每个进程的CPU、内存和磁盘I/O度量指标 | 否 |'
- en: Table 7.2 – Host Metrics Receiver scrapers
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 表7.2 – 主机度量接收器抓取器
- en: Let’s now take a look at our first cloud provider, AWS, and the connectivity
    options available.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看我们的第一个云服务提供商AWS以及可用的连接选项。
- en: Visualizing AWS telemetry with Grafana Cloud
  id: totrans-107
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用Grafana Cloud可视化AWS遥测数据
- en: 'There are two main ways in which you can visualize your AWS telemetry with
    Grafana Cloud:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种主要方式可以使用Grafana Cloud可视化你的AWS遥测数据：
- en: '**Amazon CloudWatch data source**: Amazon CloudWatch telemetry remains in AWS
    and Grafana is configured to remotely read the data at query time'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Amazon CloudWatch数据源**：Amazon CloudWatch遥测数据保留在AWS中，Grafana被配置为在查询时远程读取数据'
- en: '**AWS integration**: AWS CloudWatch telemetry data is either sent to or scraped
    and stored in Grafana Cloud (logs in Loki and metrics in Mimir).'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AWS集成**：AWS CloudWatch遥测数据要么发送到Grafana Cloud，要么被抓取并存储在Grafana Cloud中（Loki中的日志和Mimir中的度量数据）。'
- en: Let’s take a look at the differences between these two options to understand
    whether the integration option or the data source option best fits your use case.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下这两种选项的区别，以便了解集成选项或数据源选项哪个最适合你的使用场景。
- en: Amazon CloudWatch data source
  id: totrans-112
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 亚马逊 CloudWatch 数据源
- en: Grafana Cloud comes with support for **Amazon CloudWatch**, allowing you to
    query, trigger alerts, and visualize your data in Grafana dashboards. To read
    CloudWatch telemetry, you will need to configure the AWS **Identity and Access
    Management** (**IAM**) permissions and provide the necessary authentication details
    in the data source configuration screen. This does not store any telemetry data
    in Grafana; it only retrieves it at query time.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana Cloud 支持**亚马逊 CloudWatch**，允许你在 Grafana 仪表板中查询、触发警报和可视化数据。要读取 CloudWatch
    遥测数据，你需要配置 AWS **身份与访问管理**（**IAM**）权限，并在数据源配置页面提供必要的认证信息。这不会将任何遥测数据存储在 Grafana
    中；它仅在查询时获取数据。
- en: Let’s now look at the different configuration steps.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看不同的配置步骤。
- en: Configuring the data source
  id: totrans-115
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置数据源
- en: 'Data sources can be accessed from the menu under the `CloudWatch`. For existing
    ones, search for `CloudWatch` in the **Data sources** search box. You will see
    a screen similar to the following. Click **CloudWatch** to open the **Settings**
    page:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 数据源可以通过`CloudWatch`菜单访问。对于现有数据源，可以在**数据源**搜索框中搜索`CloudWatch`。你将看到类似下图的界面。点击**CloudWatch**以打开**设置**页面：
- en: '![Figure 7.1 – Grafana Connections Data sources screen](img/B18277_Figure_7.1.jpg)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.1 – Grafana 连接数据源页面](img/B18277_Figure_7.1.jpg)'
- en: Figure 7.1 – Grafana Connections Data sources screen
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.1 – Grafana 连接数据源页面
- en: 'The **Settings** screen requires the AWS configuration details needed to establish
    the connection, as shown in the following screenshot. Here, you can also configure
    namespace details for custom metrics, log query timeouts, and X-Ray trace links:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**设置**页面需要提供建立连接所需的 AWS 配置详情，如下图所示。在这里，你还可以配置自定义指标的命名空间详情、日志查询超时以及 X-Ray 跟踪链接：'
- en: '![Figure 7.2 – Amazon CloudWatch data source settings](img/B18277_Figure_7.2.jpg)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.2 – 亚马逊 CloudWatch 数据源设置](img/B18277_Figure_7.2.jpg)'
- en: Figure 7.2 – Amazon CloudWatch data source settings
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.2 – 亚马逊 CloudWatch 数据源设置
- en: Using the Amazon CloudWatch query editor
  id: totrans-122
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用亚马逊 CloudWatch 查询编辑器
- en: The CloudWatch data source comes with its own specialized query editor that
    can query data from both CloudWatch metrics and logs.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: CloudWatch 数据源配备了专门的查询编辑器，可以查询来自 CloudWatch 指标和日志的数据。
- en: 'From the data explorer, you can select **CloudWatch Metrics** or **CloudWatch
    Logs** as the source data, as shown in the following screenshot:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据浏览器中，你可以选择**CloudWatch 指标**或**CloudWatch 日志**作为源数据，如下图所示：
- en: '![Figure 7.3 – Amazon CloudWatch query editor](img/B18277_Figure_7.3.jpg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.3 – 亚马逊 CloudWatch 查询编辑器](img/B18277_Figure_7.3.jpg)'
- en: Figure 7.3 – Amazon CloudWatch query editor
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.3 – 亚马逊 CloudWatch 查询编辑器
- en: With the metrics editor in **Builder** mode, you can create a valid metric search
    query by specifying the namespace, metric name, and at least one statistic.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 在**构建器**模式下使用指标编辑器，你可以通过指定命名空间、指标名称和至少一个统计数据来创建有效的指标查询。
- en: The logs editor provides a **Log group** selector, allowing you to specify the
    target log groups and then use AWS CloudWatch Logs Query Language [https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html)
    in the query editor.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 日志编辑器提供了一个**日志组**选择器，允许你指定目标日志组，然后在查询编辑器中使用 AWS CloudWatch Logs 查询语言 [https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html](https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/CWL_QuerySyntax.html)。
- en: Using Amazon CloudWatch dashboards
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用亚马逊 CloudWatch 仪表板
- en: On the data source **Settings** screen, there is a **Dashboards** tab with a
    set of pre-configured dashboards to get you started.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据源**设置**页面上，有一个**仪表板**标签，提供了一些预配置的仪表板，帮助你快速入门。
- en: 'The following figure shows the list of available dashboards and import details
    (if a dashboard has already been imported, you will see the options to delete
    or reimport):'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 下图显示了可用仪表板的列表及导入详情（如果已经导入了仪表板，你将看到删除或重新导入的选项）：
- en: '![Figure 7.4 – Amazon CloudWatch pre-configured dashboards](img/B18277_Figure_7.4.jpg)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.4 – 亚马逊 CloudWatch 预配置仪表板](img/B18277_Figure_7.4.jpg)'
- en: Figure 7.4 – Amazon CloudWatch pre-configured dashboards
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.4 – 亚马逊 CloudWatch 预配置仪表板
- en: Let’s now take a look at the AWS integration option.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下 AWS 集成选项。
- en: Exploring AWS integration
  id: totrans-135
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索 AWS 集成
- en: The AWS integration option can be added to your account. It will then be available
    as a connection. When added and configured, you will be able to ingest metric
    and log data directly into Grafana, which provides a query time benefit as the
    data is contained within your Grafana Cloud stack. The metrics and logs can then
    be queried using LogQL or PromQL; see [*Chapter 4*](B18277_04.xhtml#_idTextAnchor092)
    and [*Chapter 5*](B18277_05.xhtml#_idTextAnchor106) for refreshers.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 集成选项可以添加到你的账户中。添加并配置后，它将作为连接可用。配置后，你将能够直接将指标和日志数据导入到 Grafana，因为数据保存在你的 Grafana
    Cloud 堆栈中，这为查询提供了时间优势。然后可以使用 LogQL 或 PromQL 查询这些指标和日志；有关详细信息，请参见 [*第 4 章*](B18277_04.xhtml#_idTextAnchor092)
    和 [*第 5 章*](B18277_05.xhtml#_idTextAnchor106)。
- en: Let’s now look at the different configuration steps.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看看不同的配置步骤。
- en: Configuring the integration
  id: totrans-138
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 配置集成
- en: 'The AWS connection can be accessed from the menu under the `aws` from the **Add
    new connection** screen; you will see a screen similar to the following. You will
    see this is an **Infrastructure** connection and is labeled as **Guide**. This
    means there will be comprehensive instructions to help you connect the account
    and walk you through the process:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 可以从 **添加新连接** 屏幕中的 `aws` 菜单访问 AWS 连接；你将看到类似以下的屏幕。你会看到这是一个 **基础设施** 连接，并标记为 **指南**。这意味着将提供全面的说明，帮助你连接账户并引导你完成过程：
- en: '![Figure 7.5 – Grafana Add new connection screen](img/B18277_Figure_7.5.jpg)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.5 – Grafana 添加新连接屏幕](img/B18277_Figure_7.5.jpg)'
- en: Figure 7.5 – Grafana Add new connection screen
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.5 – Grafana 添加新连接屏幕
- en: 'Selecting the AWS integration option presents you with several options for
    integration – **CloudWatch metrics**, **Logs with Lambda**, and **Logs with Firehose**
    – as shown in the following screenshot:'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 选择 AWS 集成选项后，会向你展示几个集成选项 —— **CloudWatch 指标**、**带 Lambda 的日志** 和 **带 Firehose
    的日志** —— 如下图所示：
- en: '![Figure 7.6 – AWS integration screen](img/B18277_Figure_7.6.jpg)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.6 – AWS 集成屏幕](img/B18277_Figure_7.6.jpg)'
- en: Figure 7.6 – AWS integration screen
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.6 – AWS 集成屏幕
- en: Next, we will discuss CloudWatch metrics and Logs with Lambda.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将讨论带有 Lambda 的 CloudWatch 指标和日志。
- en: CloudWatch metrics
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: CloudWatch 指标
- en: The CloudWatch integration allows you to scrape Amazon CloudWatch metrics without
    installing any collector or agent infrastructure. Multiple scrape jobs can be
    created to separate concerns, but metrics can only be discovered for AWS resources
    with tags.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: CloudWatch 集成功能允许你在不安装任何收集器或代理基础设施的情况下抓取 Amazon CloudWatch 指标。可以创建多个抓取作业来分离不同的关注点，但只能为带标签的
    AWS 资源发现指标。
- en: 'As mentioned earlier, this integration is guided and presents you with all
    the necessary details to get started by using infrastructure as code or by manually
    connecting and configuring scrape jobs. The following screenshot shows the CloudWatch
    metrics **Configuration** **Details** screen:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，此集成是引导式的，提供了所有必要的细节，可以通过使用基础设施即代码或手动连接并配置抓取作业来开始。以下截图展示了 CloudWatch 指标
    **配置** **详情** 屏幕：
- en: '![Figure 7.7 – CloudWatch Configuration Details screen](img/B18277_Figure_7.7.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.7 – CloudWatch 配置详情屏幕](img/B18277_Figure_7.7.jpg)'
- en: Figure 7.7 – CloudWatch Configuration Details screen
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.7 – CloudWatch 配置详情屏幕
- en: 'Additionaly there are some pre-built dashboards that are ready to use. The
    following figure shows the list of pre-built dashboards that come with the integration
    option at the time of writing:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一些预构建的仪表板可以直接使用。以下图示展示了在撰写本文时与集成选项一起提供的预构建仪表板列表：
- en: '![Figure 7.8 – Sample CloudWatch Metrics dashboard](img/B18277_Figure_7.8.jpg)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.8 – 示例 CloudWatch 指标仪表板](img/B18277_Figure_7.8.jpg)'
- en: Figure 7.8 – Sample CloudWatch Metrics dashboard
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.8 – 示例 CloudWatch 指标仪表板
- en: Logs with Lambda
  id: totrans-154
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 带 Lambda 的日志
- en: The Logs with Lambda integration enables you to send CloudWatch logs to Grafana
    Cloud. The integration will guide you through the deployment of an AWS Lambda
    function that forwards CloudWatch logs to Grafana Cloud Loki, where they can be
    queried using LogQL. [*Chapter 4*](B18277_04.xhtml#_idTextAnchor092) explains
    Loki and LogQL in detail.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 启用 Lambda 集成的日志功能使你能够将 CloudWatch 日志发送到 Grafana Cloud。此集成将引导你部署一个 AWS Lambda
    函数，该函数将 CloudWatch 日志转发到 Grafana Cloud Loki，在那里可以使用 LogQL 进行查询。[*第 4 章*](B18277_04.xhtml#_idTextAnchor092)详细解释了
    Loki 和 LogQL。
- en: 'The following screenshot shows the **Logs with Lambda** configuration screen
    where you can select your deployment approach:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了 **带 Lambda 的日志** 配置屏幕，在这里你可以选择部署方式：
- en: '![Figure 7.9 – Logs with Lambda configuration details](img/B18277_Figure_7.9.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.9 – 带 Lambda 的日志配置详情](img/B18277_Figure_7.9.jpg)'
- en: Figure 7.9 – Logs with Lambda configuration details
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.9 – 带有 Lambda 配置详情的日志
- en: 'The following screenshot shows the configuration steps as the onscreen guide
    walks you through the connection and configuration of the logs integration:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了配置步骤，屏幕上的指南会引导你完成日志集成的连接和配置：
- en: '![Figure 7.10 – Logs with Lambda CloudFormation configuration](img/B18277_Figure_7.10.jpg)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.10 – 带有 Lambda CloudFormation 配置的日志](img/B18277_Figure_7.10.jpg)'
- en: Figure 7.10 – Logs with Lambda CloudFormation configuration
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.10 – 带有 Lambda CloudFormation 配置的日志
- en: Let’s now look at our second cloud provider – GCP.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下我们的第二个云服务提供商——GCP。
- en: Monitoring GCP using Grafana
  id: totrans-163
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Grafana 监控 GCP
- en: Grafana Cloud comes with support for **Google Cloud Monitoring**, allowing you
    to query, trigger alerts, and visualize your data in Grafana dashboards. It does
    not store any telemetry data in Grafana; it only retrieves it at query time.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana Cloud 支持**Google Cloud Monitoring**，允许你在 Grafana 仪表盘中查询、触发警报和可视化数据。它不会在
    Grafana 中存储任何遥测数据；它仅在查询时提取数据。
- en: Let’s now look at the steps for configuring the data source.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下配置数据源的步骤。
- en: Configuring the data source
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置数据源
- en: 'Data sources can be accessed from the menu under the `Google Cloud Monitoring`
    in the **Data sources** search box; you will see a screen similar to the one shown
    in *Figure 7**.11*. Click on **Google Cloud Monitoring** to open the settings
    page. The settings screen prompts for the Google configuration needed to establish
    and test the connection. The **Connections** search results screen is shown here:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过**数据源**搜索框中的`Google Cloud Monitoring`菜单访问数据源；你将看到类似于*图 7.11*所示的屏幕。点击**Google
    Cloud Monitoring**以打开设置页面。设置屏幕会提示你进行Google配置，以建立和测试连接。下面显示的是**连接**搜索结果屏幕：
- en: '![Figure 7.11 – Connections search results screen](img/B18277_Figure_7.11.jpg)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.11 – 连接搜索结果屏幕](img/B18277_Figure_7.11.jpg)'
- en: Figure 7.11 – Connections search results screen
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.11 – 连接搜索结果屏幕
- en: 'The configuration settings for **Google Cloud Monitoring** shown in the following
    screenshot walk you through the configuration, helping you to choose an authentication
    method of either **JSON Web Token** (**JWT**) or **GCE Default** **Service Account**:'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 下图中的**Google Cloud Monitoring**配置设置将引导你完成配置，帮助你选择身份验证方式，可以选择**JSON Web Token**（**JWT**）或**GCE
    默认** **服务帐户**：
- en: '![Figure 7.12 – Google Cloud Monitoring configuration settings](img/B18277_Figure_7.12.jpg)'
  id: totrans-171
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.12 – Google Cloud Monitoring 配置设置](img/B18277_Figure_7.12.jpg)'
- en: Figure 7.12 – Google Cloud Monitoring configuration settings
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.12 – Google Cloud Monitoring 配置设置
- en: Depending upon the size of your GCP deployment, you may have to consider, as
    part of your design, any limits imposed on the token or service account.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 根据你的GCP部署规模，你可能需要在设计时考虑任何关于令牌或服务帐户的限制。
- en: Google Cloud Monitoring query editor
  id: totrans-174
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Google Cloud Monitoring 查询编辑器
- en: The Google Cloud Monitoring data source comes with its own specialized query
    editor that can help you build queries for metrics and GCP **Service Level Objectives**
    (**SLOs**), both of which return time-series data (you will learn more about visualizing
    time-series data in [*Chapter 8*](B18277_08.xhtml#_idTextAnchor172)). Metrics
    can be queried using the **Builder** interface or using GCP’s **Monitoring Query
    Language** (**MQL**). The SLO query builder helps you visualize SLO data in a
    time-series format. To understand the basic concepts of GCP service monitoring,
    refer to the GCP documentation at https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Google Cloud Monitoring 数据源自带有一个专用的查询编辑器，可以帮助你构建用于度量和 GCP **服务水平目标**（**SLOs**）的查询，二者都返回时序数据（你将在[*第
    8 章*](B18277_08.xhtml#_idTextAnchor172)中了解更多关于时序数据的可视化）。可以使用**构建器**界面或 GCP 的**监控查询语言**（**MQL**）来查询度量数据。SLO
    查询构建器帮助你以时序格式可视化 SLO 数据。要了解 GCP 服务监控的基本概念，请参阅 GCP 文档，网址为 https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring。
- en: 'The **Google Cloud Monitoring** query editor in the following screenshot shows
    the three available choices:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 下图中的**Google Cloud Monitoring**查询编辑器显示了三个可用选项：
- en: '![Figure 7.13 – Google Cloud Monitoring query editor selection](img/B18277_Figure_7.13.jpg)'
  id: totrans-177
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.13 – Google Cloud Monitoring 查询编辑器选择](img/B18277_Figure_7.13.jpg)'
- en: Figure 7.13 – Google Cloud Monitoring query editor selection
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.13 – Google Cloud Monitoring 查询编辑器选择
- en: 'Let’s look at the different Explorer query types:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一下不同的 Explorer 查询类型：
- en: '**Metrics queries**: The metrics query editor builder helps you select metrics,
    group and aggregate them by labels and time, and specify time filters for the
    time-series data you want to query:'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**指标查询**：指标查询编辑器构建器帮助您选择指标，通过标签和时间进行分组和聚合，并为您要查询的时间序列数据指定时间过滤器：'
- en: '![Figure 7.14 – Google Cloud Monitoring query editor metrics builder](img/B18277_Figure_7.14.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.14 – Google Cloud Monitoring 查询编辑器指标构建器](img/B18277_Figure_7.14.jpg)'
- en: Figure 7.14 – Google Cloud Monitoring query editor metrics builder
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.14 – Google Cloud Monitoring 查询编辑器指标构建器
- en: 'The following screenshot shows the query editor for MQL, which provides an
    interface to create and execute your MQL query:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 以下截图展示了 MQL 查询编辑器，它提供了一个接口，用于创建和执行您的 MQL 查询：
- en: '![Figure 7.15 – Google Cloud Monitoring query editor metrics MQL interface](img/B18277_Figure_7.15.jpg)'
  id: totrans-184
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.15 – Google Cloud Monitoring 查询编辑器指标 MQL 接口](img/B18277_Figure_7.15.jpg)'
- en: Figure 7.15 – Google Cloud Monitoring query editor metrics MQL interface
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.15 – Google Cloud Monitoring 查询编辑器指标 MQL 接口
- en: Full documentation for the MQL language specification can be found on the Google
    Cloud website at [https://cloud.google.com/monitoring/mql](https://cloud.google.com/monitoring/mql).
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: MQL 语言规范的完整文档可以在 Google Cloud 网站上找到，网址为 [https://cloud.google.com/monitoring/mql](https://cloud.google.com/monitoring/mql)。
- en: '**SLO queries**: The SLO query builder helps you visualize SLO data in time-series
    format. Documentation to explain the basic concepts of service monitoring can
    be found on the Google Cloud website at [https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring](https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring).'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**SLO 查询**：SLO 查询构建器帮助您以时间序列格式可视化 SLO 数据。有关服务监控基本概念的文档，可以在 Google Cloud 网站上找到，网址为
    [https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring](https://cloud.google.com/stackdriver/docs/solutions/slo-monitoring)。'
- en: 'The Google Cloud Monitoring SLO query editor is shown in the following screenshot:'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下截图展示了 Google Cloud Monitoring 的 SLO 查询编辑器：
- en: '![Figure 7.16 – Google Cloud Monitoring query editor metrics SLO builder](img/B18277_Figure_7.16.jpg)'
  id: totrans-189
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.16 – Google Cloud Monitoring 查询编辑器指标 SLO 构建器](img/B18277_Figure_7.16.jpg)'
- en: Figure 7.16 – Google Cloud Monitoring query editor metrics SLO builder
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.16 – Google Cloud Monitoring 查询编辑器指标 SLO 构建器
- en: Google Cloud Monitoring dashboards
  id: totrans-191
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Google Cloud Monitoring 仪表板
- en: 'From the **Data source** | **Settings** screen, the **Dashboards** tab lists
    a set of pre-configured dashboards to get you started. The following screenshot
    shows the list of available dashboards at the time of writing and import details
    (if a dashboard has already been imported, there are options to delete or reimport).
    You can see from the list the various GCP components that are covered, including
    firewalls, data processing, SQL, and so on:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **数据源** | **设置** 屏幕中，**仪表板** 选项卡列出了帮助您入门的一组预配置仪表板。以下截图展示了撰写时可用的仪表板列表以及导入详情（如果仪表板已经导入，可以选择删除或重新导入）。从列表中，您可以看到涵盖的各种
    GCP 组件，包括防火墙、数据处理、SQL 等等：
- en: '![Figure 7.17 – Google Cloud Monitoring pre-built dashboards](img/B18277_Figure_7.17.jpg)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.17 – Google Cloud Monitoring 预构建仪表板](img/B18277_Figure_7.17.jpg)'
- en: Figure 7.17 – Google Cloud Monitoring pre-built dashboards
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.17 – Google Cloud Monitoring 预构建仪表板
- en: Let’s now look at our third cloud provider, Azure.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们来看一下第三个云服务提供商，Azure。
- en: Monitoring Azure using Grafana
  id: totrans-196
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Grafana 监控 Azure
- en: Grafana Cloud comes with support for Azure, allowing you to query, trigger alerts,
    and visualize your data in Grafana dashboards. This is called the **Azure Monitor**
    data source. As with the other cloud data sources, it does not store any telemetry
    data in Grafana; it only retrieves it at query time.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana Cloud 支持 Azure，可以在 Grafana 仪表板中查询、触发警报并可视化您的数据。这被称为 **Azure Monitor**
    数据源。与其他云数据源一样，它不会在 Grafana 中存储任何遥测数据；它只会在查询时检索数据。
- en: Let’s now step through the configuration.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们一步步进行配置。
- en: Configuring the data source
  id: totrans-199
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置数据源
- en: 'Data sources can be accessed from the menu under the `Azure Monitor` in the
    **Data sources** search box; you will see a screen similar to the following:'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 可以通过 **数据源** 搜索框中的 `Azure Monitor` 菜单访问数据源；您将看到类似以下的屏幕：
- en: '![Figure 7.18 – Connection search results screen for Azure Monitor](img/B18277_Figure_7.18.jpg)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.18 – Azure Monitor 的连接搜索结果屏幕](img/B18277_Figure_7.18.jpg)'
- en: Figure 7.18 – Connection search results screen for Azure Monitor
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.18 – Azure Monitor 的连接搜索结果屏幕
- en: 'Click on **Azure Monitor** to open the settings page. The configuration settings
    for **Azure Monitor** shown in the following screenshot walk you through the configuration,
    helping you to set up authentication using the Azure **Client Secret** configuration,
    and test the connection:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 点击 **Azure Monitor** 打开设置页面。下图显示的 **Azure Monitor** 配置设置将引导您完成配置过程，帮助您通过 Azure
    **Client Secret** 配置设置身份验证，并测试连接：
- en: '![Figure 7.19 – Azure Monitor data source settings screen](img/B18277_Figure_7.19.jpg)'
  id: totrans-204
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.19 – Azure Monitor 数据源设置屏幕](img/B18277_Figure_7.19.jpg)'
- en: Figure 7.19 – Azure Monitor data source settings screen
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.19 – Azure Monitor 数据源设置屏幕
- en: Using the Azure Monitor query editor
  id: totrans-206
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Azure Monitor 查询编辑器
- en: The Azure Monitor data source comes with its own specialized query editor that
    can help you build queries for metrics and logs, Azure Resource Graph, and Application
    Insights traces.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Monitor 数据源配备了专门的查询编辑器，帮助您构建针对度量、日志、Azure 资源图和应用程序洞察跟踪的查询。
- en: 'The following Azure Monitor query editor screenshot shows four choices:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是 Azure Monitor 查询编辑器的截图，展示了四个选择：
- en: '![Figure 7.20 – Azure Monitor query editor selector](img/B18277_Figure_7.20.jpg)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.20 – Azure Monitor 查询编辑器选择器](img/B18277_Figure_7.20.jpg)'
- en: Figure 7.20 – Azure Monitor query editor selector
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.20 – Azure Monitor 查询编辑器选择器
- en: 'Let’s look at these options in detail:'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们详细看看这些选项：
- en: '**Metrics queries**: The Azure Monitor metrics queries collect numeric data
    from Azure-supported resources, which are listed here on the Microsoft Azure website:
    [https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference](https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference).'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**度量查询**：Azure Monitor 度量查询从 Azure 支持的资源中收集数字数据，这些资源可在 Microsoft Azure 网站上找到：[https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference](https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference)。'
- en: 'The metrics store numeric data only, and in a specific structure that allows
    for near real-time detection of platform health, performance, and usage. The Azure
    Monitor metrics query builder is shown here:'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 度量只存储数字数据，并以特定的结构存储，这使得近实时检测平台健康状况、性能和使用情况成为可能。Azure Monitor 度量查询构建器如下所示：
- en: '![Figure 7.21 – Azure Monitor metrics query builder](img/B18277_Figure_7.21.jpg)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.21 – Azure Monitor 度量查询构建器](img/B18277_Figure_7.21.jpg)'
- en: Figure 7.21 – Azure Monitor metrics query builder
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.21 – Azure Monitor 度量查询构建器
- en: '**Log queries**: The Azure Monitor logs queries collect and organize log data
    from Azure-supported resources. A variety of data types, each with their own defined
    structure, are accessible, and to access these, the **Kusto Query Language** (**KQL**)
    can be used. An overview of KQL can be found on the Microsoft Azure website here:
    [https://learn.microsoft.com/en-us/azure/data-explorer/kusto/query/](https://learn.microsoft.com/en-us/azure/data-explorer/kusto/query/).
    The Azure Monitor logs query editor is shown in the following screenshot:'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志查询**：Azure Monitor 日志查询从 Azure 支持的资源中收集和整理日志数据。可以访问各种数据类型，每种类型都有其定义的结构，并且可以使用
    **Kusto 查询语言**（**KQL**）进行访问。KQL 的概述可以在 Microsoft Azure 网站上找到：[https://learn.microsoft.com/en-us/azure/data-explorer/kusto/query/](https://learn.microsoft.com/en-us/azure/data-explorer/kusto/query/)。下图显示了
    Azure Monitor 日志查询编辑器：'
- en: '![Figure 7.22 – Azure Monitor logs query editor](img/B18277_Figure_7.22.jpg)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.22 – Azure Monitor 日志查询编辑器](img/B18277_Figure_7.22.jpg)'
- en: Figure 7.22 – Azure Monitor logs query editor
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.22 – Azure Monitor 日志查询编辑器
- en: Azure Monitor logs can store a variety of data types, each with its own structure.
    For more details, you can refer to [https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference](https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference).
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: Azure Monitor 日志可以存储多种数据类型，每种类型都有自己的结构。更多详细信息，请参考 [https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference](https://learn.microsoft.com/en-us/azure/azure-monitor/monitor-reference)。
- en: '**Traces queries**: The Azure Monitor traces queries can be regarded as Azure
    Application Insights under the hood. The Azure Application Insights service provides
    **application performance monitoring** (**APM**) features to its workloads. The
    Azure Monitor traces can be used to interrogate and visualize various metrics
    and trace data. The query editor looks like this:'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**跟踪查询**：Azure Monitor 跟踪查询可以看作是 Azure 应用程序洞察的底层实现。Azure 应用程序洞察服务为其工作负载提供**应用程序性能监控**（**APM**）功能。Azure
    Monitor 跟踪可以用来查询和可视化各种度量和跟踪数据。查询编辑器的界面如下所示：'
- en: '![Figure 7.23 – Azure Monitor traces query editor](img/B18277_Figure_7.23.jpg)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.23 – Azure Monitor 跟踪查询编辑器](img/B18277_Figure_7.23.jpg)'
- en: Figure 7.23 – Azure Monitor traces query editor
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.23 – Azure Monitor 跟踪查询编辑器
- en: '**Azure Resource Graph** (**ARG**): The ARG service extends the functionality
    of Azure Resource Manager by providing the ability to query across multiple Azure
    subscriptions in a scalable manner. This allows you to query Azure resources using
    the resource graph query language, making it ideal for querying and analyzing
    larger Azure cloud infrastructure deployments. Full documentation for the resource
    graph query language can be found at [https://learn.microsoft.com/en-us/azure/governance/resource-graph/samples/starter?tabs=azure-cli](https://learn.microsoft.com/en-us/azure/governance/resource-graph/samples/starter?tabs=azure-cli).'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure 资源图**（**ARG**）：ARG 服务通过提供跨多个 Azure 订阅进行可扩展查询的功能，扩展了 Azure 资源管理器的功能。这使得使用资源图查询语言查询
    Azure 资源成为可能，非常适合查询和分析较大的 Azure 云基础设施部署。有关资源图查询语言的完整文档，请访问 [https://learn.microsoft.com/en-us/azure/governance/resource-graph/samples/starter?tabs=azure-cli](https://learn.microsoft.com/en-us/azure/governance/resource-graph/samples/starter?tabs=azure-cli)。'
- en: 'The following example query shows all resources by name:'
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以下示例查询显示按名称列出的所有资源：
- en: '[PRE12]'
  id: totrans-225
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Here’s what the ARG query editor looks like:'
  id: totrans-226
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 下面是 ARG 查询编辑器的界面：
- en: '![Figure 7.24 – Azure Resource Graph query editor](img/B18277_Figure_7.24.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.24 – Azure Resource Graph 查询编辑器](img/B18277_Figure_7.24.jpg)'
- en: Figure 7.24 – Azure Resource Graph query editor
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.24 – Azure Resource Graph 查询编辑器
- en: Using Azure Monitor dashboards
  id: totrans-229
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Azure Monitor 仪表板
- en: 'From the **Data source** | **Settings** screen, the **Dashboards** tab shows
    a set of pre-configured dashboards that will get you started with Azure Monitor.
    In the following screenshot, there is a list of the various Azure components that
    have dashboards designed for them; they include applications, SQL servers, and
    storage accounts:'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在 **数据源** | **设置** 屏幕中，**仪表板** 选项卡显示了一组预配置的仪表板，帮助你快速开始使用 Azure Monitor。在以下截图中，列出了为其设计了仪表板的各种
    Azure 组件，包括应用程序、SQL 服务器和存储帐户：
- en: '![Figure 7.25 – Azure Monitor pre-built dashboards](img/B18277_Figure_7.25.jpg)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
  zh: '![图 7.25 – Azure Monitor 预构建仪表板](img/B18277_Figure_7.25.jpg)'
- en: Figure 7.25 – Azure Monitor pre-built dashboards
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7.25 – Azure Monitor 预构建仪表板
- en: Let’s now review some of the best practices we have covered for each of the
    cloud infrastructure providers we have discussed in this chapter.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们回顾一下本章中我们为每个云基础设施提供商介绍的最佳实践。
- en: Best practices and approaches
  id: totrans-234
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 最佳实践和方法
- en: 'In this chapter, we have provided an overview of several popular cloud infrastructures.
    Let’s now discuss some of the best practices that should be considered when implementing
    observability on any application or system:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 本章提供了几种流行的云基础设施的概述。接下来，我们将讨论在任何应用程序或系统中实施可观察性时应考虑的一些最佳实践：
- en: '**Performance**: The process of retrieving telemetry data can potentially incur
    a performance overhead. For example, with a remote Grafana data source, the telemetry
    data is fetched at query time over a great distance. This can introduce latency
    when compared to data stored closer to the Grafana query engine using one of the
    Grafana Cloud data sources, such as Loki, Mimir, and Tempo. Where performance
    is important and there is an option to ship telemetry into Grafana, that could
    be the best choice. Alternatively, several data sources have caching options to
    improve query speed; improvements in query speed can also be made using specific
    configurations. Take the time to understand your data and ensure you are using
    it in an optimal way.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**性能**：检索遥测数据的过程可能会带来性能开销。例如，使用远程 Grafana 数据源时，遥测数据会在查询时通过较远的距离进行获取。与使用诸如 Loki、Mimir
    和 Tempo 等 Grafana Cloud 数据源，在距离 Grafana 查询引擎较近的地方存储数据相比，这可能会引入延迟。如果性能至关重要，并且有选项将遥测数据传输到
    Grafana，那么这可能是最佳选择。或者，许多数据源都提供缓存选项来提高查询速度；通过特定配置也可以改进查询速度。花时间理解你的数据，并确保以最佳方式使用它。'
- en: '**Cost**: Alongside the increased network and storage costs of shipping data
    into Grafana Cloud, there can also be costs when querying a cloud provider API.
    It is important to understand where charges are raised. This ensures that they
    are factored in when you’re designing your observability solution for the specific
    platform that your systems utilize.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**成本**：除了将数据传输到 Grafana Cloud 增加的网络和存储成本外，在查询云提供商 API 时也可能产生费用。了解费用产生的地方非常重要，这可以确保在为你的系统设计可观察性解决方案时考虑到这些费用。'
- en: '**Constraints**: In general, infrastructure platforms come configured with
    constraints in place to protect the system. Sometimes these are soft limits that
    can be relaxed after careful consideration, but they may be hard limits. Before
    committing to a solution for a specific platform, understand your requirements
    and the volume of data or query transactions expected. You can compare these to
    any documented limits, your API key use, or your network egress volumes, therefore
    validating that the system will support your needs.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**限制**：通常，基础设施平台会配置一些限制以保护系统。这些有时是可以在谨慎考虑后放宽的软限制，但也可能是硬限制。在为特定平台选择解决方案之前，了解你的需求以及预期的数据量或查询事务量。你可以将这些与任何文档中列出的限制、API
    密钥的使用情况或网络出站流量进行比较，从而验证系统是否能满足你的需求。'
- en: '**Security**: For most of the configuration options we discussed in this chapter,
    we identified how they can be set up to generate separation of concerns. Having
    separate data sources or other controls on the data being queried or ingested
    will allow you to improve your security posture based on the underlying data and
    use case.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性**：在本章中讨论的大多数配置选项，我们已识别出它们如何设置以实现关注点分离。通过拥有独立的数据源或对查询或摄取的数据进行其他控制，可以基于底层数据和用例提升安全防护水平。'
- en: Important note
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 重要提示
- en: As this book was nearing publication, Grafana Labs released **private data source
    connect** (**PDC**), which gives administrators the ability to connect to any
    network-secured data source, regardless of where it is hosted. We have not covered
    this topic, but it is likely to be of interest to readers.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 当本书即将出版时，Grafana Labs 发布了**私有数据源连接**（**PDC**），使管理员能够连接到任何网络安全的数据源，无论其托管在哪里。我们未在本书中涵盖这一主题，但它可能会引起读者的兴趣。
- en: We will now wrap this chapter up with a summary and set the stage for the next
    chapter.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将通过总结来结束本章，并为下一章做好铺垫。
- en: Summary
  id: totrans-243
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we have looked at various common cloud infrastructure providers,
    starting with Kubernetes, and we presented examples that can be used with the
    demo project provided alongside this book. We then looked at the big three cloud
    providers, AWS, GCP, and Azure. We presented an overview of the connection options
    and how to get started with the pre-built dashboards and the data explorer. Lastly,
    we covered some of the best practices that need to be considered with all observability
    integrations.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们查看了各种常见的云基础设施提供商，从 Kubernetes 开始，并展示了可以与本书附带的示例项目一起使用的示例。接着，我们介绍了三大云提供商：AWS、GCP
    和 Azure。我们提供了连接选项的概述，并展示了如何使用预构建的仪表板和数据探索器入门。最后，我们介绍了一些在所有可观测性集成中需要考虑的最佳实践。
- en: In the next chapter, we move on from getting telemetry data into Grafana and
    on to the visualization of that data using dashboards. This is where the fun starts!
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将从将遥测数据导入 Grafana 转到使用仪表板可视化数据。这才是有趣的开始！
- en: 'Part 3: Grafana in Practice'
  id: totrans-246
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 第3部分：Grafana 实践
- en: In practice, Grafana is used to understand the current system state and take
    appropriate actions to give customers the best results. This part will cover the
    wide variety of activities that may be needed to complete that goal and what should
    be considered along the way. You will learn how to present your data while considering
    the requirements of your audience. You will explore how to build a world-class
    incident management process. You will also learn approaches to automating and
    architecting your observability platform.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，Grafana 被用于了解当前系统状态，并采取适当的行动为客户提供最佳结果。本部分将涵盖为实现这一目标可能需要的各种活动，并且在过程中应考虑的事项。你将学习如何展示数据，同时考虑受众的需求。你将探索如何建立一流的事件管理流程。你还将了解自动化和构建可观测性平台的策略。
- en: 'This part has the following chapters:'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 本部分包含以下章节：
- en: '[*Chapter 8*](B18277_08.xhtml#_idTextAnchor172)*, Displaying Data with Dashboards*'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第8章*](B18277_08.xhtml#_idTextAnchor172)*，使用仪表板展示数据*'
- en: '[*Chapter 9*](B18277_09.xhtml#_idTextAnchor183)*, Managing Incidents Using
    Alerts*'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第9章*](B18277_09.xhtml#_idTextAnchor183)*，使用警报管理事件*'
- en: '[*Chapter 10*](B18277_10.xhtml#_idTextAnchor204)*, Automation with Infrastructure
    as Code*'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第10章*](B18277_10.xhtml#_idTextAnchor204)*，使用基础设施即代码进行自动化*'
- en: '[*Chapter 11*](B18277_11.xhtml#_idTextAnchor218)*, Architecting an Observability
    Platform*'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[*第11章*](B18277_11.xhtml#_idTextAnchor218)*，构建可观测性平台架构*'
