- en: '15'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '15'
- en: Monitoring Clusters and Workloads
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 集群与工作负载的监控
- en: So far in this book, we’ve spent a considerable amount of time standing up different
    aspects of an enterprise Kubernetes infrastructure. Once it’s stood up, how do
    you know it’s healthy? How do you know it’s running? Do you know when there’s
    a problem before your users do, or are you first finding out when someone can’t
    access a critical system? Monitoring is a critical aspect of any well-run infrastructure
    that has its own unique challenges in the Kubernetes and Cloud Native world. In
    this chapter, we’re going to look at two specific aspects of monitoring. First,
    we’re going to work with the Prometheus project and its integration with Kubernetes
    to understand how to inspect our cluster and what to look for. Next, we’re going
    to centralize our logs using the popular ELK stack. Along the way, we’ll include
    typical enterprise discussions around security and compliance to make sure we’re
    working within our enterprise’s requirements.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，在本书中，我们花了相当多的时间来搭建企业 Kubernetes 基础设施的不同方面。搭建完成后，如何知道它是否健康？如何知道它是否在运行？你是否在用户之前就能发现问题，还是直到某人无法访问关键系统时才知道？监控是任何良好运作的基础设施中的一个关键环节，在
    Kubernetes 和云原生环境中具有其独特的挑战。本章中，我们将重点关注监控的两个具体方面。首先，我们将使用 Prometheus 项目及其与 Kubernetes
    的集成，了解如何检查我们的集群以及需要关注的内容。接下来，我们将使用流行的 ELK 堆栈集中管理日志。在此过程中，我们还将涉及有关安全性和合规性的典型企业讨论，以确保我们符合企业的要求。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要内容：
- en: Managing Metrics in Kubernetes
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 中的指标管理
- en: Log Management in Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 中的日志管理
- en: Next, let’s review the technical requirements.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，让我们回顾一下技术要求。
- en: Technical Requirements
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: 'This chapter will involve a larger workload than previous chapters, so a more
    powerful cluster will be needed. This chapter has the following technical requirements:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的工作量将比前几章更大，因此需要一个更强大的集群。本章有以下技术要求：
- en: An Ubuntu 22.04+ server running Docker with a minimum of 8 GB of RAM, though
    16 GB is suggested
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一台运行 Docker 的 Ubuntu 22.04+ 服务器，至少 8 GB 内存，推荐 16 GB 内存
- en: 'Scripts from the `chapter15` folder from the repo, which you can access by
    going to this book’s GitHub repository: [https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition)'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 从 GitHub 仓库的 `chapter15` 文件夹中的脚本，你可以通过访问本书的 GitHub 仓库来获取：[https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition)
- en: Getting Help
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 获取帮助
- en: We do our best to test everything, but there are sometimes half a dozen systems
    or more in our integration labs. Given the fluid nature of technology, sometimes
    things that work in our environment don’t work in yours. Don’t worry, we’re here
    to help! Open an issue on our GitHub repo at [https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/issues](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/issues)
    and we’ll be happy to help you out!
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们尽力测试所有内容，但有时我们的集成实验室中可能有六个以上的系统。由于技术的快速发展，有时在我们的环境中正常运行的东西，在你们的环境中可能无法运行。别担心，我们会提供帮助！在我们的
    GitHub 仓库上提交一个问题，[https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/issues](https://github.com/PacktPublishing/Kubernetes-An-Enterprise-Guide-Third-Edition/issues)，我们会很乐意帮助你！
- en: Managing Metrics in Kubernetes
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 中的指标管理
- en: Once upon a time, monitoring and metrics were a complex and very proprietary
    corner of the industry. While there were some open-source projects that did monitoring,
    the majority of “enterprise” systems were large, cumbersome, and proprietary.
    There were a few standards, such as SNMP, but for the most part, every vendor
    had their own agents, their own configurations, their own…everything. If you wanted
    to write an application that generated metrics or alerts, then you needed to write
    to their SDK. This led to monitoring being one of the centralized services, like
    databases, but required much deeper understanding of what’s being monitored. Changes
    were difficult and ultimately, many systems followed either **you only live once**
    (**YOLO**) monitoring or very basic high-level monitoring that “checked the compliance
    box,” but didn’t provide much value.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 曾几何时，监控和指标是行业中一个复杂且非常专有的领域。虽然有一些开源项目进行监控，但大多数“企业”系统都庞大、笨重且专有。虽然存在一些标准，如 SNMP，但大多数情况下，每个供应商都有自己的代理、配置，甚至是…一切。如果你想编写一个生成指标或警报的应用程序，那么你需要使用他们的
    SDK。这导致了监控成为集中式服务之一，像数据库一样，但需要对被监控内容有更深入的理解。变更困难，最终许多系统采取了**你只活一次**（**YOLO**）监控或非常基础的高层次监控，只是“勾选合规框”，但并没有提供太多价值。
- en: Then came the Prometheus project, which made two critical improvements to the
    monitoring process that really changed the way we approach monitoring. The first
    change was to do everything via simple HTTP requests. If you want to monitor something,
    it needs to expose a URL that provides metrics data. It doesn’t matter whether
    it’s a website or a database. The second major impact was that these metrics endpoints
    provide data text format that makes it easy to dynamically generate a response
    regardless of the monitoring system. We’ll dive into the details later, but this
    format is so powerful and flexible that it has been adopted by SaaS monitoring
    systems in addition to Prometheus. Datadog, AWS CloudWatch, and so on all support
    the Prometheus endpoint and format, making it much easier to start with Prometheus
    and move to a provided solution without changing your applications.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 随后出现了 Prometheus 项目，它对监控过程进行了两项关键改进，真正改变了我们对监控的处理方式。第一个变化是通过简单的 HTTP 请求来实现所有操作。如果你想监控某个东西，它需要暴露一个提供指标数据的
    URL。无论是网站还是数据库都无关紧要。第二个重大影响是，这些指标端点提供了文本格式的数据，使得无论监控系统是什么，都可以轻松动态生成响应。我们稍后会深入探讨这些细节，但这种格式非常强大且灵活，除了
    Prometheus 外，还被 SaaS 监控系统所采用。Datadog、AWS CloudWatch 等都支持 Prometheus 的端点和格式，这使得从
    Prometheus 开始并转向其他提供的解决方案变得更加容易，而无需更改你的应用程序。
- en: In addition to opening the ability to monitor disparate systems, Prometheus
    made it easier for operators to interact with that data by providing it via APIs.
    Now, common visualization tools, such as Grafana, can access that data without
    a vendor’s proprietary UI. These tools build on the base offering of Prometheus,
    expanding your capabilities to monitoring and alerting as well.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 除了开启了监控不同系统的能力，Prometheus 还通过提供 API，使得操作员能够更轻松地与数据交互。现在，常见的可视化工具，如 Grafana，可以在没有供应商专有
    UI 的情况下访问这些数据。这些工具基于 Prometheus 的基础功能，扩展了你的监控和警报能力。
- en: Now that we’ve explained why Prometheus has had such a large impact on the monitoring
    world, we’ll next walk through how your Kubernetes clusters provide metrics data
    and how to leverage it.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经解释了为什么 Prometheus 对监控世界产生了如此大的影响，接下来我们将逐步介绍 Kubernetes 集群如何提供指标数据以及如何利用它。
- en: How Kubernetes Provides Metrics
  id: totrans-18
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何 Kubernetes 提供指标
- en: 'Kubernetes provides a `/metrics` URI on the API server. This API requires an
    authorized token to be able to access it. To access this endpoint, let’s create
    a `ServiceAccount`, `ClusterRole`, and `ClusterRoleBinding`:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 在 API 服务器上提供了一个 `/metrics` URI。此 API 需要授权令牌才能访问。要访问这个端点，我们需要创建一个
    `ServiceAccount`、`ClusterRole` 和 `ClusterRoleBinding`：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: This is going to take a while; there are too many metrics that are collected
    to document here. We’ll talk about some individual metrics after we get some context
    on how the metrics are created and consumed by Prometheus. The main point to understand
    now is that all metrics from your cluster come from a single URL and that those
    metrics require authentication. You could disable this requirement by making the
    `/metrics` endpoint available to the system (unauthenticated user, which is what
    all unauthenticated requests are assigned to), but this would now open your cluster
    up to potential escalation attacks. It’s better to keep this resource protected.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这需要一些时间，因为收集的度量指标太多，无法在这里一一列举。我们将在稍后的部分讨论一些具体的度量指标，先了解一下 Prometheus 如何创建和消费这些度量指标。现在要理解的主要观点是，来自集群的所有度量指标都来自一个
    URL，并且这些度量指标需要认证。你可以通过让 `/metrics` 端点对系统开放（未经认证的用户，即所有未认证的请求都被分配给该用户）来禁用此要求，但这会使集群暴露在潜在的提升攻击面前。最好将该资源保持保护。
- en: If you spend even a moment looking at this data, you’ll see there is an incredible
    amount. We’re going to first dive into deploying Prometheus to make it easier
    for you to interact with this data. Thankfully, deploying a full monitoring stack
    on Kubernetes is pretty simple!
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你稍微查看一下这些数据，你会看到数据量是惊人的。我们将首先介绍如何部署 Prometheus，以便你可以更方便地与这些数据进行交互。幸运的是，在 Kubernetes
    上部署完整的监控堆栈是相当简单的！
- en: Deploying the Prometheus Stack
  id: totrans-23
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 部署 Prometheus 堆栈
- en: 'So far, we’ve found how to access the Kubernetes metrics endpoint; next, we’re
    going to deploy Prometheus using the `kube-prometheus-stack` project ([https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack))
    from the Prometheus Community. This chart combines the Prometheus project with
    Grafana and Alertmanager to create a mostly complete monitoring solution. We’ll
    walk through some of the gaps later in the chapter. First, let’s get Prometheus
    deployed:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经找到了如何访问 Kubernetes 度量指标端点；接下来，我们将使用 Prometheus 社区的 `kube-prometheus-stack`
    项目 ([https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack](https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack))
    来部署 Prometheus。这个图表将 Prometheus 项目与 Grafana 和 Alertmanager 结合，创建了一个几乎完整的监控解决方案。我们将在本章稍后部分讨论一些缺口。首先，让我们部署
    Prometheus：
- en: '[PRE1]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This script creates the monitoring namespace, deploys the Helm chart, and creates
    an Ingress object with the host `prometheus.apps.X-X-X-X.nip.io`, where `X-X-X-X`
    is your API server’s IP address but with dashes instead of dots. For me, my API
    server is running on `192.168.2.82`, so, to access the Prometheus UI in my browser,
    I go to `https://prometheus.apps.192-168-2-82.nip.io/`.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本创建了监控命名空间，部署了 Helm 图表，并创建了一个 Ingress 对象，主机为 `prometheus.apps.X-X-X-X.nip.io`，其中
    `X-X-X-X` 是你的 API 服务器的 IP 地址，但使用破折号代替了点。对于我来说，我的 API 服务器运行在 `192.168.2.82`，所以，要在浏览器中访问
    Prometheus 的 UI，我访问 `https://prometheus.apps.192-168-2-82.nip.io/`。
- en: Now that Prometheus is running and we can access it, the next step is to walk
    through some of Prometheus’ capabilities.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 现在 Prometheus 已经在运行并且我们可以访问它，接下来的步骤是介绍一些 Prometheus 的功能。
- en: Introduction to Prometheus
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Prometheus 介绍
- en: The first thing you’ll notice when accessing Prometheus is there’s no login
    screen. Prometheus has no concept of security. Anyone with access to your URL
    will have access to your Prometheus in the current setup. We’ll take care of this
    problem later in the chapter as we look at operationalizing Prometheus.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 访问 Prometheus 时你首先会注意到的是没有登录界面。Prometheus 没有安全性的概念。在当前设置下，任何能够访问你的 URL 的人都可以访问你的
    Prometheus。我们将在本章稍后处理这个问题，看看如何将 Prometheus 正常化运营。
- en: 'Having seen that there’s no security in Prometheus, the next thing to note
    is that the main screen, known as the **Graph** view, gives you an **Expression**
    box. This is where you can look for any of the expressions available using PromQL,
    Prometheus’ query language. For instance, using the `sum by (namespace) (kube_pod_info)`
    query gives you a list of all the pods in each namespace:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 看到 Prometheus 没有安全性后，接下来要注意的是，主屏幕，称为 **Graph** 视图，给你提供了一个 **Expression** 框。在这里，你可以使用
    Prometheus 的查询语言 PromQL 查找任何可用的表达式。例如，使用 `sum by (namespace) (kube_pod_info)`
    查询可以列出每个命名空间中的所有 pod：
- en: '![A screenshot of a computer  Description automatically generated](img/B21165_15_01.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图，自动生成的描述](img/B21165_15_01.png)'
- en: 'Figure 15.1: Prometheus query'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.1：Prometheus 查询
- en: This screen has a menu bar that includes **Alerts** and **Status** menu options
    as well. If you click on **Alerts**, you’ll see several alerts are red and firing.
    This is because we’re running inside of KinD, which has its own networking quirks.
    Depending on the kind of Kubernetes distribution, you’ll find that some alerts
    are firing on a regular basis and can be ignored.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 这个屏幕有一个菜单栏，包括 **Alerts**（警报）和 **Status**（状态）菜单选项。如果你点击 **Alerts**，你会看到几个警报处于红色并触发。这是因为我们正在
    KinD 环境中运行，它有一些独特的网络特性。根据 Kubernetes 发行版的不同，你会发现一些警报会定期触发，并且可以忽略。
- en: While Prometheus is configured to generate alerts, it doesn’t have any mechanism
    for notification. It instead relies on an outside system. The typical open source
    tool used is Alertmanager, but we’ll cover that later in the chapter. For now,
    what’s important to know is that alerts are defined in Prometheus and you can
    check their status from the **Alerts** view.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然 Prometheus 已配置为生成警报，但它没有任何通知机制。相反，它依赖于外部系统。通常使用的开源工具是 Alertmanager，但我们将在本章后面讨论它。现在，重要的是要知道，警报在
    Prometheus 中定义，你可以从 **Alerts**（警报）视图查看它们的状态。
- en: '![Graphical user interface, application  Description automatically generated](img/B21165_15_02.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，应用程序  描述自动生成](img/B21165_15_02.png)'
- en: 'Figure 15.2: Alerts view'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.2：警报视图
- en: Finally, there’s the **Status** menu, which provides several views. The one
    I find myself using the most is the **Targets** view, which will tell you if any
    targets aren’t available.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 最后是 **Status**（状态）菜单，它提供了几个视图。我最常用的是 **Targets**（目标）视图，它可以告诉你是否有目标不可用。
- en: '![A screenshot of a computer screen  Description automatically generated](img/B21165_15_03.png)'
  id: totrans-38
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图  描述自动生成](img/B21165_15_03.png)'
- en: 'Figure 15.3: Targets view'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.3：目标视图
- en: It was important to get Prometheus up and running before we dove into the details
    of how metrics are collected or queried. As we saw when we first looked at Kubernetes’
    metrics, there is a massive amount of data and it’s not in a format that’s easily
    analyzed via command-line tools. With the GUI in hand, we can begin to look at
    how Prometheus collects and stores metrics.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入了解度量的收集或查询细节之前，首先让 Prometheus 启动并运行是非常重要的。正如我们第一次查看 Kubernetes 的度量时所见，数据量非常庞大，且其格式不易通过命令行工具进行分析。通过图形界面，我们可以开始查看
    Prometheus 如何收集和存储度量数据。
- en: How Does Prometheus Collect Metrics?
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Prometheus 如何收集度量？
- en: 'So far, we’ve polled the metrics endpoint for Kubernetes and gotten the Prometheus
    stack up and running to query and analyze that data. Earlier, we created a simple
    query to look for the number of pods by `Namespace`: `sum by (namespace) (kube_pod_info)`.
    Looking at the output of our API server metrics pull, we can grep for `kube_pod_info`,
    and we won’t find anything! That’s because this particular metric doesn’t come
    directly from the API server. It instead comes from the `kube-state-metrics` project
    ([https://github.com/kubernetes/kube-state-metrics](https://github.com/kubernetes/kube-state-metrics)),
    which is deployed with the Prometheus stack chart. This tool generates data about
    the API server in a way that can be integrated into Prometheus. If we look at
    its `/metrics` output, we’ll find:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经轮询了 Kubernetes 的度量端点，并使 Prometheus 堆栈启动并运行，以查询和分析这些数据。之前，我们创建了一个简单的查询来查找按
    `Namespace` 分类的 pod 数量：`sum by (namespace) (kube_pod_info)`。查看我们 API 服务器的度量数据输出时，我们可以
    grep 搜索 `kube_pod_info`，但什么也找不到！这是因为这个特定的度量并不是直接来自 API 服务器，而是来自 `kube-state-metrics`
    项目（[https://github.com/kubernetes/kube-state-metrics](https://github.com/kubernetes/kube-state-metrics)），该项目与
    Prometheus 堆栈图表一起部署。这个工具生成有关 API 服务器的数据，以便集成到 Prometheus 中。如果我们查看它的 `/metrics`
    输出，我们会发现：
- en: '[PRE2]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The lines with a hash mark or pound, `#`, provide metadata for the upcoming
    metrics. For each metric, the form is:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 带有井号或井号标记 `#` 的行提供了即将出现的度量的元数据。每个度量的形式为：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: The annotations on each metric are what allow Prometheus to be able to index
    so much information and make it easy to query. Looking at the `kube_pod_info`
    metrics, we see an annotation for `namespace`. This means that we can ask Prometheus
    to give us all the instances of the `kube_pod_info` metric, broken up by the annotation
    of `namespace`. We could also ask for any pods on a specific `host_ip`, `node`,
    or any other of the annotations.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 每个度量的注释使得 Prometheus 能够索引大量信息并便于查询。查看 `kube_pod_info` 度量时，我们看到一个 `namespace`
    注释。这意味着我们可以请求 Prometheus 提供所有 `kube_pod_info` 度量的实例，并按 `namespace` 注释进行划分。我们也可以请求查看特定
    `host_ip`、`node` 或任何其他注释下的 pod。
- en: 'The type of the `kube_pod_info` metric is a gauge. There are four types of
    metrics in Prometheus:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '`kube_pod_info` 指标的类型是 Gauge。Prometheus 中有四种类型的指标：'
- en: '**Counter**:Counters can only increase over time or go back down to zero. An
    example of a counter would be the number of requests an application responded
    to over its lifetime. The number of requests will only increase until the pods
    dies, at which point, it goes back to zero.'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计数器**：计数器只能随着时间的推移增加，或者归零。计数器的一个例子是应用程序在其生命周期内响应的请求数量。请求数量只会增加，直到 Pod 终止，此时计数器会归零。'
- en: '**Gauge**: These metrics can go up or down over time. For instance, the number
    of open sessions a pod has would be a gauge because it can fluctuate over time.'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**仪表**：这些指标可以随时间波动。例如，一个 Pod 的开放会话数量就是一个仪表，因为它会随时间变化。'
- en: '**Histogram**: This type is more complex. It’s designed to allow you to track
    ranges, or buckets, of request types. For instance, if you wanted to track response
    times for requests, you could create buckets for likely times and increase the
    count for each bucket. This is much more efficient than generating a new metric
    instance for each request. If we did generate a metric instance for each request,
    we might have thousands of data points every second that need to be indexed and
    stored and that data just wouldn’t be helpful. Instead of using a histogram, we
    can categorize ranges and track them that way, saving on processing and data storage.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**直方图**：这种类型更复杂。它设计用来跟踪请求类型的范围或桶。例如，如果你想跟踪请求的响应时间，可以为可能的时间创建不同的桶，并增加每个桶的计数。这比为每个请求生成新的指标实例要高效得多。如果我们为每个请求都生成一个指标实例，那么每秒可能会有成千上万的数据点需要被索引和存储，而这些数据对我们来说并不有用。与其使用直方图，我们可以将范围进行分类并跟踪，这样可以节省处理和数据存储的开销。'
- en: '**Summary**: Summary metrics are similar to histograms but are managed by the
    client. Generally speaking, you’ll want to use histograms.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**摘要**：摘要指标类似于直方图，但由客户端管理。一般来说，你会想使用直方图。'
- en: When Prometheus collects these metrics, they’re stored in an internal database.
    You’ll see that both the Prometheus and Alertmanager pods are part of `StatefulSets`,
    not `Deployments`. That’s because they store data locally. For Prometheus, the
    data is stored so that you can not only see the latest version of the metric but
    also the past instances of that metric, too. From the main **Graph** screen in
    Prometheus, you can click on **Graph** for any result to see the result over time.
    Our cluster is small and isn’t running much, but what if we had an explosion of
    new `pods`? That could trigger an alarm. Another area where keeping the history
    of metrics is important is for alerting. When we get to defining our alerting
    rules, we’ll see that we can specify to only fire or clear an alert if it happens
    over a certain period of time. Stuff happens; you don’t want your pager going
    off for every packet that gets dropped. Tracking this information is very important
    for both the value of the data and accurate alerting.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 当 Prometheus 收集这些指标时，它们会存储在一个内部数据库中。你会看到，Prometheus 和 Alertmanager 的 Pod 都属于
    `StatefulSets`，而不是 `Deployments`。这是因为它们会本地存储数据。对于 Prometheus，数据会存储起来，这样你不仅可以看到该指标的最新版本，还能查看过去的指标实例。在
    Prometheus 的主 **图表** 页面，你可以点击任何结果旁边的 **图表**，查看该结果的时间变化。我们的集群很小，运行的负载也不多，但如果我们突然增加大量新的
    `pods` 呢？这可能会触发警报。另一个保持指标历史记录重要的领域是告警。当我们定义告警规则时，会看到我们可以指定只在某个时间段内触发或清除告警。事情总是会发生的；你不希望因每一个丢包就收到警报。追踪这些信息对于数据的价值和准确的告警至关重要。
- en: In this section, we looked at how Prometheus collects and stores metrics. Next,
    we’ll dive into common metrics you’ll want to keep an eye on for Kubernetes.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们介绍了 Prometheus 如何收集和存储指标。接下来，我们将深入探讨一些你需要关注的 Kubernetes 常见指标。
- en: Common Kubernetes Metrics
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 常见的 Kubernetes 指标
- en: So far, we’ve talked about deploying Prometheus with Kubernetes and how Prometheus
    pulls metrics, but which metrics are important? To say there is a large number
    of metrics to choose from in Kubernetes is an understatement. There are 212 individual
    metrics coming from the API server. There are 194 metrics from the kube-state-metrics
    project. There are also metrics from the kubelet and etcd. Instead of focusing
    on specific metrics, which will vary based on your projects, I would instead point
    you to the built-in Grafana that comes with the charts we deployed.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们讨论了如何使用Kubernetes部署Prometheus以及Prometheus如何拉取指标，但哪些指标才是重要的呢？说Kubernetes中有大量的指标可供选择，这绝对是轻描淡写。API服务器就有212个独立的指标，kube-state-metrics项目有194个指标，还有来自kubelet和etcd的指标。与其专注于具体的指标（这会根据你的项目而有所不同），我更建议你关注我们部署的图表中自带的Grafana。
- en: To access Grafana, go to `https://grafana.apps.X-X-X-X.nip.io/`, where `X-X-X-X`
    is your server’s IP address but with dashes instead of dots. Since my cluster
    is on `192.168.2.82`, I go to `https://grafana.apps.192-168-2-82.nip.io/`. The
    username is `admin` and the password is `prom-operator`. You can navigate through
    any of the available dashboards and click to edit them to see how they get their
    data. For instance, in *Figure 15.4*, I’ve navigated to the compute resources
    in the cluster, which breaks down CPU usage by namespace.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问Grafana，请前往`https://grafana.apps.X-X-X-X.nip.io/`，其中`X-X-X-X`是你服务器的IP地址，只不过用短横线代替了点。例如，如果我的集群位于`192.168.2.82`，那么我访问的是`https://grafana.apps.192-168-2-82.nip.io/`。用户名是`admin`，密码是`prom-operator`。你可以浏览任何可用的仪表板，并点击编辑它们，查看它们是如何获取数据的。例如，在*图15.4*中，我进入了集群中的计算资源，显示按命名空间划分的CPU使用情况。
- en: These dashboards were all installed as part of the Helm chart we deployed. We’ll
    cover how to create your own dashboards later in the chapter.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这些仪表板都是我们部署的Helm图表的一部分。我们将在本章后面讨论如何创建你自己的仪表板。
- en: 'From here, I can click on the menu and the **edit** option:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我可以点击菜单并选择**编辑**选项：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B21165_15_04.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，描述自动生成，信心中等](img/B21165_15_04.png)'
- en: 'Figure 15.4: Grafana compute resources for the cluster'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.4：Grafana计算资源展示集群
- en: 'With the graph editor open, you can now view the PromQL expression used to
    generate the data:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 打开图形编辑器后，你现在可以查看用于生成数据的PromQL表达式：
- en: '![A screenshot of a computer  Description automatically generated](img/B21165_15_05.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，描述自动生成](img/B21165_15_05.png)'
- en: 'Figure 15.5: Edit screen in Grafana'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.5：Grafana中的编辑屏幕
- en: 'If you take this expression, you can drop it into the **Graph** screen in Prometheus
    and see the raw data used to generate the graph:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你将这个表达式复制到Prometheus的**图形**界面中，就能看到用于生成图表的原始数据：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B21165_15_06.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![计算机屏幕截图，描述自动生成，信心中等](img/B21165_15_06.png)'
- en: 'Figure 15.6: Prometheus with a Grafana query'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.6：带有Grafana查询的Prometheus
- en: If you look closely at the query, you’ll see that the Prometheus version doesn’t
    reference a cluster. That’s because the Grafana dashboards were built with the
    idea of managing multiple clusters, whereas Prometheus was set up to inspect only
    a single cluster. The data isn’t annotated with the `cluster` attribute so Prometheus
    can’t search on it. We’ll talk more about this when we get to Grafana.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你仔细查看查询，会发现Prometheus版本没有引用集群。这是因为Grafana仪表板是基于管理多个集群的思路构建的，而Prometheus只配置为检查单个集群。数据没有被标注`cluster`属性，因此Prometheus无法基于此进行查询。我们将在后面的Grafana部分深入讨论这个问题。
- en: Now that we know where we can find examples of important metrics for our cluster
    and how to test them, we should spend some time on PromQL, the query language
    for Grafana.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了在哪里可以找到集群的重要指标示例以及如何测试它们，我们应该花一些时间来学习Grafana的查询语言——PromQL。
- en: Querying Prometheus with PromQL
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 使用PromQL查询Prometheus
- en: The majority of this chapter so far has been focused on deploying Prometheus
    and gathering data. We started to dive into how to query data, but we haven’t
    yet dived into the details of the Prometheus query language, called PromQL. If
    you’re familiar with other query languages, this won’t look too different.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，本章的大部分内容集中在部署Prometheus和收集数据上。我们已经开始探讨如何查询数据，但尚未深入讨论Prometheus查询语言（PromQL）的细节。如果你熟悉其他查询语言，这应该不会看起来太陌生。
- en: 'At a high level, the query language looks similar to the data. You start with
    a metric and which annotations you want to apply. For instance, looking at the
    compute query by namespace, first, let’s look at what happens when we start with
    `node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate`:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，查询语言与数据很相似。你从一个度量指标开始，选择你想应用的注解。例如，查看按命名空间的计算查询，首先，让我们看看当我们从`node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate`开始时会发生什么：
- en: '![Chart, histogram  Description automatically generated](img/B21165_15_07.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![图表，直方图  描述自动生成](img/B21165_15_07.png)'
- en: 'Figure 15.7: CPU metrics'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.7：CPU 度量
- en: 'Since we didn’t include any annotations in our query, we received the CPU usage
    for every pod on the cluster. If we wanted to see the CPU used in a specific namespace,
    we would specify that the same way it’s specified in the metrics data but adding
    a `{annotation="value"}` to our metric. To see all of the containers’ CPU usage
    in the `monitoring` namespace, add `{namespace="monitoring"}` to your query:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在查询中没有包含任何注解，所以我们得到了集群中每个 Pod 的 CPU 使用情况。如果我们想查看特定命名空间的 CPU 使用情况，我们可以像在度量数据中指定的那样，添加`{annotation="value"}`到我们的度量中。要查看`monitoring`命名空间中所有容器的
    CPU 使用情况，只需在查询中添加`{namespace="monitoring"}`：
- en: '![Graphical user interface, chart  Description automatically generated](img/B21165_15_08.png)'
  id: totrans-75
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，图表  描述自动生成](img/B21165_15_08.png)'
- en: 'Figure 15.8: CPU in the monitoring namespace'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.8：监控命名空间中的 CPU 使用情况
- en: 'Once you’ve limited the data you want, you may wish to aggregate the data.
    The current details show all of the running containers in the `monitoring` namespace,
    but that doesn’t give you a great idea as to how much total CPU is being used.
    You can add functions that will aggregate for you, such as the `sum` function:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你限定了想要的数据，你可能希望对数据进行聚合。目前的细节显示的是`monitoring`命名空间中所有运行中的容器，但这并不能让你清楚地了解总共使用了多少
    CPU。你可以添加一些聚合函数，比如`sum`函数：
- en: '![Chart  Description automatically generated](img/B21165_15_09.png)'
  id: totrans-78
  prefs: []
  type: TYPE_IMG
  zh: '![图表  描述自动生成](img/B21165_15_09.png)'
- en: 'Figure 15.9: Sum of all CPU usage in the monitoring namespace'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.9：监控命名空间中所有 CPU 使用情况的总和
- en: 'Finally, you may want to `sum` by a specific annotation, such as the pod since
    most of the pods have multiple containers. You can add a grouping using the `by`
    keyword:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，你可能希望根据特定的注解来进行`sum`，比如 Pod，因为大多数 Pod 中有多个容器。你可以使用`by`关键字进行分组：
- en: '![A screenshot of a computer  Description automatically generated with medium
    confidence](img/B21165_15_10.png)'
  id: totrans-81
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图  描述自动生成，置信度中等](img/B21165_15_10.png)'
- en: 'Figure 15.10: CPU usage of pods in the monitoring namespace'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.10：监控命名空间中 Pod 的 CPU 使用情况
- en: 'In addition to functions, you can perform math operations, too. Let’s say you
    want to know what percentage of total CPU has been used in your cluster. You need
    to know the CPU utilization at any moment, and the total amount of CPU available.
    We already know how to get the total CPU being utilized by all the containers
    in our cluster. Next, we need to know the total available CPU across the cluster.
    Then, we need to do some math to get the percentage. When doing math with PromQL,
    you would use the typical infix notation that you would use in most other programming
    and query languages. For instance, the `(sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate)
    / max(count without(cpu,mode,pod) (node_cpu_seconds_total{mode="idle"}))) * 100`
    query combines multiple metrics and calculation to get the CPU utilization across
    the cluster:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 除了函数之外，你还可以执行数学运算。假设你想知道集群中总共使用了多少 CPU 百分比。你需要知道在任何时刻的 CPU 利用率，以及可用的总 CPU 数量。我们已经知道如何获取集群中所有容器使用的总
    CPU。接下来，我们需要知道整个集群中可用的总 CPU。然后，我们需要做一些数学运算来得到百分比。在使用 PromQL 进行数学运算时，你会使用大多数其他编程和查询语言中的典型中缀表示法。例如，查询`(sum(node_namespace_pod_container:container_cpu_usage_seconds_total:sum_irate)
    / max(count without(cpu,mode,pod) (node_cpu_seconds_total{mode="idle"}))) * 100`将多个度量和计算结合起来，以获取整个集群的
    CPU 利用率：
- en: '![Chart  Description automatically generated](img/B21165_15_11.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![图表  描述自动生成](img/B21165_15_11.png)'
- en: 'Figure 15.11: Percentage of CPU used across the cluster'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.11：整个集群的 CPU 使用百分比
- en: Now, we have a way of knowing how much CPU we’re using in the cluster. We could
    incorporate this knowledge into our capacity planning by creating an alert that
    tells us that our cluster has reached a certain capacity level. This leads us
    to our next section, which will focus on this very question.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们已经知道了集群中使用的 CPU 的数量。我们可以通过创建一个警报，将此信息纳入我们的容量规划中，当集群达到某个容量水平时，这个警报就会告诉我们。这引出了我们下一节的内容，专注于这个问题。
- en: Alerting with Alertmanager
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Alertmanager 进行警报
- en: Thus far, we’ve deployed Prometheus, integrated it with our Kubernetes cluster,
    and learned how to query the database for useful information about our cluster.
    We’ve seen that Prometheus tracks alerts on the **Alerts** screen of the UI, but
    how do cluster operators get notified there’s an issue?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经部署了 Prometheus，并将其与我们的 Kubernetes 集群集成，学会了如何查询数据库以获取关于集群的有用信息。我们已经看到
    Prometheus 在 UI 的 **警报** 屏幕上跟踪警报，但集群操作员如何知道有问题呢？
- en: The Alertmanager project ([https://prometheus.io/docs/alerting/latest/alertmanager/](https://prometheus.io/docs/alerting/latest/alertmanager/))
    is a generic tool that knows how to query for alerts and then send them to the
    correct people. It’s not simply a notification conduit; it also helps with deduplication
    and grouping, too. Finally, it provides an interface for silencing alerts that
    don’t need to continue firing.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Alertmanager 项目（[https://prometheus.io/docs/alerting/latest/alertmanager/](https://prometheus.io/docs/alerting/latest/alertmanager/)）是一个通用工具，它知道如何查询警报并将其发送给正确的人。它不仅仅是一个通知通道；它还帮助去重和分组。最后，它提供了一个界面，用于对不需要继续触发的警报进行静音处理。
- en: The helm charts we deployed earlier include an instance of Alertmanager and
    an `Ingress` for it too. Like with the other projects, you can access it with
    the `https://alertmanager.apps.X-X-X-X.nip.io/` with the `X-X-X-X` URL replaced
    with your cluster’s IP address. Since my cluster is on `192.168.2.82`, my URL
    is `https://alertmanager.apps.192-168-2-82.nip.io/`.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们之前部署的 Helm 图表中包括了一个 Alertmanager 实例以及一个用于它的 `Ingress`。与其他项目一样，你可以通过 `https://alertmanager.apps.X-X-X-X.nip.io/`
    访问它，其中的 `X-X-X-X` 需要替换为你集群的 IP 地址。由于我的集群在 `192.168.2.82` 上，所以我的 URL 是 `https://alertmanager.apps.192-168-2-82.nip.io/`。
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B21165_15_12.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本，应用程序，电子邮件  描述自动生成](img/B21165_15_12.png)'
- en: 'Figure 15.12: Alertmanager UI'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.12：Alertmanager 用户界面
- en: Similar to Prometheus, you’ll notice there’s no authentication because, just
    like Prometheus, there’s no security model. There is more information on that
    later in the chapter. What you will see is that there are already alerts! That’s
    because running Kubernetes in KinD will lead to some interesting networking issues
    that aren’t expected. If you run the Prometheus stack in a cloud-hosted Kubernetes,
    you will find similar results.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 与 Prometheus 类似，你会注意到这里没有身份验证，因为就像 Prometheus 一样，这里没有安全模型。关于这一点，章节后面会有更多信息。你会看到的是，已经有警报！这是因为在
    KinD 上运行 Kubernetes 会导致一些意料之外的网络问题。如果你在云托管的 Kubernetes 上运行 Prometheus 堆栈，你会发现类似的结果。
- en: You’ll notice that there are multiple sets of alerts. Alertmanager provides
    for tagging of alerts so you can better organize them. For instance, you may want
    to only send alerts for critical issues or route alerts based on where they’re
    from.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你会注意到有多个警报组。Alertmanager 提供了警报标签功能，以便你更好地组织它们。例如，你可能只想发送关键问题的警报，或者根据警报来源来路由警报。
- en: You can silence an alert from this UI as well. This is useful when you want
    to stop notifications because you’re working on the problem or because you know
    of the issue and it’s an issue another team needs to address and you don’t need
    to get continuous alerts while that team is addressing the problem. Many teams
    do not get direct access to this UI because of the lack of security, but we’ll
    cover how to fix that later in the chapter.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 你也可以从这个用户界面静音一个警报。这在你处理问题时，或者你知道问题存在且是另一个团队需要处理的问题时非常有用，这样你就不需要在他们解决问题时持续接收警报。由于缺乏安全性，许多团队无法直接访问此用户界面，但我们将在本章后面讲解如何解决这个问题。
- en: While the UI lets you see what alerts there are and silence them, what it won’t
    do is allow you to configure alerts or where to send them. That’s done in custom
    resource objects, which we’ll cover in the next section.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然用户界面让你能够查看警报并将其静音，但它不能让你配置警报或配置警报的发送目标。那部分是在自定义资源对象中完成的，我们将在下一节中讲解。
- en: How Do You Know Whether Something Is Broken?
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你怎么知道某些东西坏了？
- en: 'So far, we’ve seen how to access the Alertmanager UI and we’ve seen that the
    alerts are configured in Prometheus, but we’ve not yet configured an alert. There
    are two steps to configuring an alert:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经了解了如何访问Alertmanager UI，并且看到警报是在Prometheus中配置的，但我们还没有配置警报。配置警报的过程有两个步骤：
- en: Create an instance of a `PrometheusRule` to define under what conditions an
    alert should be generated. This involves creating a PromQL expression to define
    the data, how long you want the condition to be met, and finally, how to label
    the alert.
  id: totrans-99
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`PrometheusRule`实例，用来定义在什么条件下应该生成警报。这涉及到创建一个PromQL表达式来定义数据，定义希望条件满足的时间长度，最后，如何标记警报。
- en: Create an `AlertmanagerConfig` object to group and route the alert to a receiver.
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个`AlertmanagerConfig`对象，用于将警报分组并路由到接收器。
- en: 'We already have plenty of `PrometheusRule` objects thanks to the great set
    of pre-configured rules that come with the chart we deployed. The next question
    is how to build an `AlertmanagerConfig`. The tricky part about this is that we
    need something to send the alerts to. There are plenty of options including email,
    Slack, and various notification SaaS services. To keep things simple, let’s deploy
    an NGINX server that can act as a webhook that will let us see the JSON payload.
    Our pagers won’t go off, but it will at least give us a feel for what we’re seeing.
    From inside the source repo:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经拥有了大量的`PrometheusRule`对象，这得益于我们部署的图表中包含的丰富预配置规则。接下来的问题是如何构建`AlertmanagerConfig`。这一部分的难点在于，我们需要某个东西来接收警报。我们有很多选择，包括电子邮件、Slack以及各种通知SaaS服务。为了简化操作，让我们部署一个NGINX服务器，作为一个webhook，它可以让我们查看JSON负载。我们的提醒设备不会响起，但至少它能让我们大致了解我们看到的内容。在源代码库内部：
- en: '[PRE4]'
  id: totrans-102
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'This will launch an NGINX pod in the `alert-manager-webhook` namespace. Now,
    let’s configure an `AlertmanagerConfig` to send all critical alerts to our webhook:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 这将启动一个NGINX Pod，在`alert-manager-webhook`命名空间中运行。现在，让我们配置一个`AlertmanagerConfig`，将所有关键警报发送到我们的webhook：
- en: '[PRE5]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The `receivers` section tells Alertmanager to send all events to our web server.
    The `route.matchers` section tells Alertmanager which alerts to send. In our example,
    we will send any alerts with a `severity` of `critical` being generated from the
    `kube-system` namespace. When working with `AlertmanagerConfig` objects, the namespace
    the object is created in automatically gets added to your matchers. You can create
    this object from `chapter15/alertmanager-webhook/critical-alerts.yaml`. Once created,
    wait a few minutes. There will eventually be an alert that gets fired from Prometheus,
    which will result in a log entry like:'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '`receivers`部分告诉Alertmanager将所有事件发送到我们的Web服务器。`route.matchers`部分则告诉Alertmanager要发送哪些警报。在我们的示例中，我们将发送任何来自`kube-system`命名空间、`severity`为`critical`的警报。当处理`AlertmanagerConfig`对象时，对象创建所在的命名空间会自动添加到你的matchers中。你可以从`chapter15/alertmanager-webhook/critical-alerts.yaml`创建这个对象。创建后，稍等几分钟。最终会有一个来自Prometheus的警报被触发，并会产生如下日志条目：'
- en: '[PRE6]'
  id: totrans-106
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The JSON in the log message is too large to provide here, but it provides all
    the information available to Alertmanager. There are very few times when you should
    be writing your own receiver. There are so many pre-built ones that it’s unlikely
    you’ll need to build your own.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 日志消息中的JSON内容过大，无法在此提供，但它包含了Alertmanager可以访问的所有信息。在大多数情况下，你不需要自己编写接收器。已经有很多现成的接收器，几乎不需要自己去构建。
- en: Now that we know how to configure Alertmanager to send an alert, next, we’ll
    walk through how to design metrics-based alerts.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道了如何配置Alertmanager发送警报，接下来我们将介绍如何设计基于指标的警报。
- en: Alerting Your Team Based on Metrics
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 根据指标向你的团队发送警报
- en: In the previous section, we walked through how to send an alert to a receiver
    using Alertmanager. Next, we’ll walk through how to generate an alert. Alerts
    are not configured in Alertmanager but in Prometheus. The only job Alertmanager
    has is to forward the generated alerts to receivers. The job of determining whether
    an alert should be fired is up to Prometheus.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们介绍了如何使用Alertmanager将警报发送到接收器。接下来，我们将讲解如何生成一个警报。警报并不是在Alertmanager中配置的，而是在Prometheus中配置的。Alertmanager的唯一任务是将生成的警报转发到接收器。是否触发警报的判断由Prometheus来决定。
- en: The `PrometheusRule` object is used to configure Prometheus to fire an alert.
    This object defines metadata for the rule, conditions for when the rule will fire,
    and how often the rule needs to fire for the alert to be sent to Alertmanager.
    The `kube-prometheus` project that we deployed comes with about forty pre-built
    rules. These rules are constantly being updated based on experience and you shouldn’t
    update them on your own. You can, however, build your own rules for your own infrastructure.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '`PrometheusRule` 对象用于配置 Prometheus 触发警报。此对象定义了规则的元数据、规则触发的条件，以及触发规则的频率，以便将警报发送到
    Alertmanager。我们部署的 `kube-prometheus` 项目包含约四十个预构建的规则。这些规则会根据经验不断更新，你不应该自行更新它们。不过，你可以为自己的基础设施构建自定义规则。'
- en: 'To demonstrate this, let’s deploy OpenUnison into our cluster:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示这个过程，让我们将 OpenUnison 部署到我们的集群中：
- en: '[PRE7]'
  id: totrans-113
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: We’ll get into the details of what this script does when we get to the *Monitoring
    Applications* section later in the chapter. For now, know that this script deploys
    OpenUnison and integrates it with our kube-prometheus chart for both adding the
    login to our apps and providing something to monitor.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在稍后的 *监控应用* 部分详细介绍这个脚本的作用。现在，你只需要知道这个脚本部署了 OpenUnison，并将其与我们的 kube-prometheus
    图表集成，既为我们的应用程序添加了登录功能，又提供了监控内容。
- en: 'Now that we’re using OpenUnison to provide authentication for our cluster,
    if it goes down, you want to know before your users start calling. We deployed
    the below `PrometheusRule` as part of our deployment script earlier:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们使用 OpenUnison 为我们的集群提供身份验证服务，如果它出现故障，你肯定希望在用户打电话之前就知道。我们之前作为部署脚本的一部分，部署了以下的
    `PrometheusRule`：
- en: '[PRE8]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: In our `PrometheusRule`, we created a single `group` with a single `rule`. The
    rule creates an `alert` called `no-sessions` that checks for the absence of the
    `active_sessions` metric. This metric is provided by OpenUnison to track how many
    sessions are currently open. If we simply had something like `active_sessions
    < 1`, then this rule wouldn’t fire because there is no `active_sessions` metric.
    The language for specifying the `expr` is the same PromQL that we used with Prometheus
    to query our data. This means you can test your expressions in the Prometheus
    web app before creating your `PrometheusRule` objects.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的 `PrometheusRule` 中，我们创建了一个包含单个 `rule` 的 `group`。该规则创建了一个名为 `no-sessions`
    的 `alert`，检查是否缺少 `active_sessions` 指标。这个指标由 OpenUnison 提供，用于跟踪当前打开的会话数。如果我们仅仅使用像
    `active_sessions < 1` 这样的条件，那么该规则不会触发，因为没有 `active_sessions` 指标。指定 `expr` 的语言与我们在
    Prometheus 中查询数据时使用的 PromQL 语言相同。这意味着你可以在创建 `PrometheusRule` 对象之前，在 Prometheus
    Web 应用中测试你的表达式。
- en: 'Let’s fire this rule by deleting the `metrics` `Application` object from OpenUnison:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们通过删除 OpenUnison 中的 `metrics` `Application` 对象来触发这个规则：
- en: '[PRE9]'
  id: totrans-119
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'After about thirty seconds, if we log in to Prometheus and click on the **Alerts**
    link, we’ll see:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 大约三十秒后，如果我们登录到 Prometheus 并点击 **Alerts** 链接，我们会看到：
- en: '![A screenshot of a computer  Description automatically generated](img/B21165_15_13.png)'
  id: totrans-121
  prefs: []
  type: TYPE_IMG
  zh: '![计算机截图 描述自动生成](img/B21165_15_13.png)'
- en: 'Figure 15.13: Pending alert in Prometheus'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.13：Prometheus 中的待处理警报
- en: 'The screenshot shows that there’s a pending alert. This is happening because,
    in our rule, we said that the conditions of the rule must be met for at least
    one minute. This is an important tuning option to help prevent false positives.
    Depending on what you’re monitoring, you could find you’re getting alerts that
    are being cleared very quickly on their own. After another thirty seconds or so,
    you’ll see that the alert has moved from pending to firing:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 截图显示有一个待处理的警报。这是因为在我们的规则中，我们指定了规则条件必须满足至少一分钟。这是一个重要的调整选项，有助于防止误报。根据你监控的内容，你可能会发现有些警报会在短时间内自动被清除。大约过了三十秒后，你会看到警报从待处理状态变为触发状态：
- en: '![Graphical user interface, application  Description automatically generated](img/B21165_15_14.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，应用程序 描述自动生成](img/B21165_15_14.png)'
- en: 'Figure 15.14: Prometheus alert firing'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.14：Prometheus 警报触发
- en: 'Now that our rule is firing, we can look in the Alertmanager application and
    see an alert is firing:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们的规则正在触发，我们可以在 Alertmanager 应用中查看到一个警报正在触发：
- en: '![](img/B21165_15_15.png)'
  id: totrans-127
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B21165_15_15.png)'
- en: 'Figure 15.15: Alert firing in Alertmanager'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.15：Alertmanager 中的警报触发
- en: 'We don’t have anything to collect the alert, but if we did, we’d now be receiving
    alerts that OpenUnison is down! Let’s fix the problem by re-adding the monitoring
    application:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 我们目前没有任何方式来收集警报，但如果有的话，我们现在应该会收到 OpenUnison 出现故障的警报！让我们通过重新添加监控应用来解决这个问题：
- en: '[PRE10]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Once this command is done, the same process will go in reverse. The first time
    that OpenUnison responds with the active_`sessions` metric, the alert will move
    into a pending status. If everything is OK after a full minute, the alert will
    be cleared.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦该命令完成，相同的过程将反向进行。第一次当OpenUnison响应`active_sessions`指标时，警报将进入待处理状态。如果一分钟后没有问题，警报将被清除。
- en: You may be asking why we simply deleted the metrics application instead of stopping
    OpenUnison. The Deployment script added security to our infrastructure, which
    would have made it harder to access the Prometheus and Alertmanager applications
    without OpenUnison. While you could have used port forwarding to access both Prometheus
    and Alertmanager, that could be complicated based on how your cluster is deployed,
    so we went with a simpler approach.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会问，为什么我们直接删除了度量应用程序，而不是停止OpenUnison。部署脚本为我们的基础设施增加了安全性，这使得没有OpenUnison的情况下更难访问Prometheus和Alertmanager应用程序。虽然你可以使用端口转发来访问Prometheus和Alertmanager，但根据集群的部署方式，这可能会比较复杂，所以我们选择了一个更简单的方法。
- en: Now that we know how to generate an alert, what happens if we want to ignore
    it? We’ll cover that in the next section.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何生成警报，如果我们想忽略它会发生什么呢？我们将在下一节中讲解。
- en: Silencing Alerts
  id: totrans-134
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 静默警报
- en: 'Now that we know how to generate an alert, how do we silence it? There are
    many reasons why you’d want to silence an alert:'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们知道如何生成警报，如何静默它呢？你可能有很多理由想要静默警报：
- en: '**Known outage**:You’ve been informed that ongoing work will cause an outage
    and there’s no reason to act on the alerts.'
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**已知故障**：你已经被告知正在进行的工作将导致故障，因此没有必要对警报作出反应。'
- en: '**Outage outside your control**: Your outage is caused by a system outside
    of your control. For instance, if there’s an issue with your Active Directory
    that you have no control over and OpenUnison fails to authenticate because of
    it, you shouldn’t be getting alerts.'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**超出你控制范围的故障**：你的故障是由你无法控制的系统引起的。例如，如果你的Active Directory出现问题，而你无法控制，且由于此问题OpenUnison无法进行身份验证，你就不应该收到警报。'
- en: '**Ongoing outage**: You know there’s an issue; the alert doesn’t need to keep
    firing.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**持续故障**：你知道存在问题；警报无需继续触发。'
- en: 'You can enable a silence based on labels provided by your alerts. When you
    see an alert you want to silence, you can click on the **Silence** button in the
    Alertmanager application:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以根据警报提供的标签启用静默。当你看到想要静默的警报时，可以点击Alertmanager应用程序中的**静默**按钮：
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B21165_15_16.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本，应用程序，电子邮件 说明自动生成](img/B21165_15_16.png)'
- en: 'Figure 15.16: Create a silence in Alertmanager from an alert'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.16：在Alertmanager中从警报创建静默
- en: You can now customize the alert, specify who created it, and how long it should
    last. This silence isn’t persisted in the API server as an object, so you can’t
    scan for it via the Kubernetes API (though that would be a great feature).
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你可以自定义警报，指定谁创建了它，以及它应持续多长时间。这个静默不会作为对象保存在API服务器中，所以你无法通过Kubernetes API扫描它（虽然这将是一个很棒的功能）。
- en: Security-minded readers may be thinking, could an attacker create a silence
    to cover their tracks? Of course! You could silence warnings about CPU while running
    Bitcoin miners, for example. We’ll talk more about the security of Prometheus
    when we get to adding SSO to the monitoring stack at the end of the chapter.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 安全意识强的读者可能会想，攻击者能否创建一个静默来掩盖他们的痕迹？当然可以！比如，你可以在运行比特币挖矿程序时静默CPU警告。关于Prometheus的安全性，我们将在本章最后讨论将SSO添加到监控堆栈时详细介绍。
- en: We’ve worked through most of the operational portions of our monitoring stack.
    The next step is to visualize all of the data collected. We’ll cover that next
    by looking at Grafana.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经完成了监控堆栈的大部分操作部分。下一步是可视化所有收集的数据。接下来，我们将通过Grafana来讲解这一部分。
- en: Visualizing Data with Grafana
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用Grafana可视化数据
- en: So far, we’ve worked with the data collected by Prometheus in an operational
    way. We’ve focused on how to react to changes in data in a way that impacts our
    cluster and our users. While it’s great to be able to act on this data, there’s
    too much to be able to process without some help. This is where Grafana comes
    in; it provides a way for us to build dashboards based on the data from Prometheus
    (as well as other sources). We already looked at some of the out-of-the-box graphs
    earlier in the chapter. Now, we’ll create our own graphs and integrate those graphs
    into the kube-prometheus stack we’ve deployed.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经以操作的方式处理了 Prometheus 收集的数据。我们专注于如何根据数据的变化采取行动，这些变化会影响到我们的集群和用户。虽然能够对这些数据做出反应是很好的，但数据量太大，单靠自己无法处理。此时，Grafana
    就派上用场了；它为我们提供了基于 Prometheus（以及其他来源）数据构建仪表盘的方法。我们在本章前面已经看过一些开箱即用的图表。接下来，我们将创建自己的图表，并将这些图表集成到我们部署的
    kube-prometheus 堆栈中。
- en: Creating Your Own Graphs
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创建你自己的图表
- en: 'A graph is a combination of a dataset and a set of visualization rules. The
    graph itself is defined by JSON. This means that it can be persisted as a Kubernetes
    object and loaded as part of our stack instead of being stored in a persisted
    database. The downside to this approach is that you’ll need to first generate
    that JSON. Thankfully, the Grafana web UI makes it easy to do:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图表是数据集和一组可视化规则的组合。图表本身由 JSON 定义。这意味着它可以作为 Kubernetes 对象持久化，并作为我们堆栈的一部分加载，而不是存储在持久化数据库中。该方法的缺点是，你需要先生成那个
    JSON。幸运的是，Grafana 的 Web UI 使这一过程变得容易：
- en: Log in to Grafana.
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 登录到 Grafana。
- en: 'Create a new dashboard: We created a simple dashboard for OpenUnison’s `active_sessions`
    metric.'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个新仪表盘：我们为 OpenUnison 的 `active_sessions` 度量指标创建了一个简单的仪表盘。
- en: Once you’ve created the dashboard, export it to JSON.
  id: totrans-151
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建仪表盘后，将其导出为 JSON 格式。
- en: Create a `ConfigMap` with the `label` `grafana_dashboard="1"`.
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个 `ConfigMap`，并使用 `label` `grafana_dashboard="1"`。
- en: 'Here are the important parts of `chapter15/user-auth/grafana-custom-dashboard.yaml`:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下是 `chapter15/user-auth/grafana-custom-dashboard.yaml` 的重要部分：
- en: '[PRE11]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Once the `ConfigMap` is created, Grafana will pick it up almost immediately!
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦 `ConfigMap` 创建完成，Grafana 会几乎立即识别到它！
- en: Having created a dashboard, you may have noticed that there are other capabilities
    in Grafana, such as alerting. Grafana can be used for this process, but that’s
    outside of the scope of the kube-prometheus project and this book.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 创建了仪表盘后，你可能注意到 Grafana 还有其他功能，比如告警。Grafana 可以用于这一过程，但这超出了 kube-prometheus 项目和本书的范围。
- en: Now that you are familiar with the various components of the kube-prometheus
    stack, the next step is to look at how you can use it to monitor applications
    and systems running in your cluster.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经熟悉了 kube-prometheus 堆栈的各个组件，下一步是看看你如何使用它来监控运行在集群中的应用程序和系统。
- en: Monitoring Applications
  id: totrans-158
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 监控应用程序
- en: In the previous sections of this chapter, we focused on working with the operational
    aspects of the kube-prometheus stack for monitoring and alerting. We integrated
    OpenUnison into our cluster and created monitors and alerts, but we didn’t detail
    how this worked. We’re going to use OpenUnison as a model for integrating other
    systems into your monitoring stack.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章的前几节中，我们专注于使用 kube-prometheus 堆栈进行监控和告警的操作方面。我们将 OpenUnison 集成到集群中，创建了监控和告警，但并没有详细讲解它是如何工作的。我们将以
    OpenUnison 为模型，讲解如何将其他系统集成到你的监控堆栈中。
- en: Why You Should Add Metrics to Your Applications
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 为什么你应该在应用程序中添加度量指标
- en: Before we move forward with how we added metrics and monitoring to OpenUnison,
    the first question we should answer is why. Your clusters are made of more than
    just your Kubernetes implementation. Most clusters today have automation frameworks,
    authentication systems, external integrations, GitOps frameworks, and so on. If
    any of these components go down, to your users, your cluster is down. From a customer-management
    perspective, you want to know before they start opening alerts.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 在继续讲解如何将度量指标和监控添加到 OpenUnison 之前，我们需要先回答一个问题：为什么要这样做？你的集群不仅仅由 Kubernetes 实现组成。如今大多数集群都有自动化框架、身份验证系统、外部集成、GitOps
    框架等。如果这些组件中的任何一个发生故障，对于你的用户来说，你的集群就不可用。从客户管理的角度来看，你希望在他们开始打开告警之前就知道问题所在。
- en: In addition to your systems, you may be dependent on outside systems. When these
    go down, and they impact you and your customers, your customers will come to you
    first.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 除了你的系统，你还可能依赖外部系统。当这些系统发生故障，并且它们影响到你和你的客户时，你的客户会首先找到你。
- en: This is very true in the authentication world, where, if the login process doesn’t
    “complete,” the authentication process is assumed to be the problem. I have dozens
    of anecdotes to demonstrate this reality, but I’ll focus on a couple where downstream
    monitoring helped me identify the root cause and stay ahead of my customers’ tickets.
    First off, many of my customers use OpenUnison to integrate with Active Directory
    via LDAP. While Active Directory is a very solid system, the network access is
    susceptible to issues. An errant firewall rule can cut off access, and adding
    monitoring of OpenUnison’s downstream Active Directory has provided quick evidence
    that an outage of the login process isn’t an OpenUnison issue.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 这在身份验证领域是非常真实的，如果登录过程没有“完成”，通常会认为是身份验证过程出了问题。我有很多例子可以证明这一现实，但我将重点介绍几个例子，其中下游监控帮助我识别了根本原因，并提前处理了客户的工单。首先，我的许多客户使用
    OpenUnison 通过 LDAP 集成 Active Directory。尽管 Active Directory 是一个非常稳定的系统，但网络访问易受问题影响。一个错误的防火墙规则就可能切断访问，添加对
    OpenUnison 下游 Active Directory 的监控提供了快速证据，证明登录过程的中断并非 OpenUnison 的问题。
- en: The Prometheus format for metrics has become a de facto standard in the cloud-native
    world. Even systems that aren’t built on Prometheus have built-in support for
    it, such as commercial systems like Datadog and Amazon CloudWatch. This means
    that most monitoring systems you’ll have deployed have support for Prometheus
    metric endpoints, even if you’re not using Prometheus internally. For systems
    that aren’t web-based, there are often “bolt-on” solutions for monitoring via
    Prometheus, such as databases.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 的度量标准格式已经成为云原生世界的事实标准。即使是没有基于 Prometheus 构建的系统，也内建了对它的支持，比如像 Datadog
    和 Amazon CloudWatch 这样的商业系统。这意味着大多数你部署的监控系统都支持 Prometheus 度量端点，即使你内部没有使用 Prometheus。对于那些不是基于
    Web 的系统，通常也有通过 Prometheus 进行监控的“附加”解决方案，比如数据库。
- en: Having discussed why you should be monitoring your cluster systems, not just
    Kubernetes, let’s step through how we’re monitoring our OpenUnison.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论了为什么你应该监控你的集群系统，而不仅仅是 Kubernetes 后，让我们一步一步看看我们如何监控 OpenUnison。
- en: Adding Metrics to OpenUnison
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 向 OpenUnison 添加度量标准
- en: 'Earlier in the chapter, we redeployed our monitoring stack with an OpenUnison
    instance. Now, it’s time to walk through what that integration looks like. If
    you haven’t already, redeploy your monitoring stack and OpenUnison:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章之前，我们重新部署了包含 OpenUnison 实例的监控栈。现在，是时候走一遍这种集成的过程了。如果你还没有这样做，重新部署你的监控栈和 OpenUnison：
- en: '[PRE12]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'Prometheus’ operator looks for various objects for things to monitor; we’re
    going to focus on the `ServiceMonitor`. If you look in the `monitoring` namespace,
    you’ll notice a dozen or so predefined `ServiceMonitor` objects. The point of
    a `ServiceMonitor` is to tell Prometheus to look up which pods to monitor based
    on a `Service` object. This makes sense as a cloud-native pattern, you wouldn’t
    want to hardcode your metrics endpoints. pods get rescheduled, scaled, and so
    on. Relying on a `Service` object helps Prometheus scale in a cloud-native way.
    For OpenUnison, here’s our `ServiceMonitor` object:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Prometheus 的操作员会查找各种对象来进行监控；我们将重点关注 `ServiceMonitor`。如果你查看 `monitoring` 命名空间，你会注意到大约有十几个预定义的
    `ServiceMonitor` 对象。`ServiceMonitor` 的目的是告诉 Prometheus 根据 `Service` 对象查找要监控的 Pod。这作为云原生模式是很有意义的，你不希望将你的度量端点硬编码进去。Pod
    会重新调度、扩展等等。依赖于 `Service` 对象可以帮助 Prometheus 以云原生的方式进行扩展。对于 OpenUnison，以下是我们的 `ServiceMonitor`
    对象：
- en: '[PRE13]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The first thing to point out is that there’s a `label` called `release="prometheus"`.
    This `label` is needed for kube-prometheus to pick up our monitor. Prometheus
    is not a multitenant system, so it’s reasonable to expect there to be multiple
    instances for different use cases. Requiring this label makes sure that the `ServiceMonitor`
    object is picked up by the correct Prometheus operator deployment.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 首先需要指出的是，那里有一个名为 `release="prometheus"` 的 `label`。这个 `label` 是 kube-prometheus
    用来识别我们的监控的必要条件。Prometheus 不是一个多租户系统，所以可以合理地期望会有多个实例用于不同的用例。要求这个标签确保 `ServiceMonitor`
    对象被正确的 Prometheus 操作员部署所识别。
- en: Next, we’ll point out that the endpoint lines up with the `openunison-orchestra`
    Service in the `openunison` namespace. We didn’t name it directly, but we did
    identify it by labels. It’s important to make sure you don’t get multiple `Service`
    objects integrated by having overly broad labels. Finally, we included the `bearerTokenFile`
    option to tell Prometheus to use its own identity when accessing OpenUnison’s
    metrics endpoint. We’ll cover this in more detail in the next section.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将指出该端点与 `openunison-orchestra` 服务在 `openunison` 命名空间中的匹配情况。我们没有直接命名它，但通过标签将其识别出来。确保不要因标签过于宽泛而导致集成多个
    `Service` 对象是非常重要的。最后，我们包括了 `bearerTokenFile` 选项，以告诉 Prometheus 在访问 OpenUnison
    的指标端点时使用它自己的身份。我们将在下一节中更详细地介绍这一点。
- en: 'If we deployed just this object, the Prometheus operator would complain that
    it can’t load the correct `Service` objects because it doesn’t have RBAC permissions.
    The next step is to create an RBAC `Role` and `RoleBinding` for the operator to
    be able to look up the `Services`:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们仅部署了这个对象，Prometheus 操作员会抱怨它无法加载正确的`Service`对象，因为它没有 RBAC 权限。接下来的步骤是为操作员创建一个
    RBAC `Role` 和 `RoleBinding`，使其能够查找`Services`：
- en: '[PRE14]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This should look straightforward if you’ve already read through our chapter
    on Kubernetes RBAC. We included services, endpoints, and pods because once you
    retrieve a `Service`, you use an `Endpoint` object to get to a pod that has the
    correct IP. Each `/metrics` endpoint is then accessed based on the `Pod's` IP
    address, not the `Service` host. This means you’ll need to keep in mind that,
    if your system uses hostnames for routing, you’ll need to accept the `/metrics`
    on all hostnames.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你已经阅读了我们关于 Kubernetes RBAC 的章节，那么这应该显得很直接。我们包括了服务、端点和 pod，因为一旦你检索到一个 `Service`，你就可以使用
    `Endpoint` 对象找到具有正确 IP 的 pod。每个 `/metrics` 端点接着是基于 `Pod` 的 IP 地址而不是 `Service`
    主机进行访问的。这意味着如果你的系统使用主机名进行路由，你需要接受所有主机名上的 `/metrics`。
- en: 'Once you have Prometheus configured, you’ll start seeing your metrics in a
    few minutes. If they don’t show up, there are three places to look:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你配置了 Prometheus，几分钟后你就会开始看到你的指标。如果它们没有显示出来，有三个地方需要检查：
- en: '**Prometheus operator**:The operator will show whether there were any issues
    loading the `Service`/`Endpoint`/`Pod`.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus 操作员**：操作员将显示加载`Service`/`Endpoint`/`Pod`时是否有任何问题。'
- en: '**Prometheus Pod, configuration reloader container**: The Prometheus pod has
    a sidecar container that reloads the configuration. Check here next to see whether
    there was an issue loading the configuration.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus Pod，配置重载容器**：Prometheus pod 包含一个侧车容器，用于重新加载配置。接下来请检查此处，看看加载配置时是否出现问题。'
- en: '**Prometheus Pod, Prometheus container**: Finally, check the Prometheus container
    in the Prometheus pod to see whether there is an issue in Prometheus loading the
    metrics.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Prometheus Pod，Prometheus 容器**：最后，检查 Prometheus pod 中的 Prometheus 容器，看看是否有
    Prometheus 加载指标时出现问题。'
- en: Having walked through how to set up a monitor in Prometheus, the next question
    is why, and how, to secure your metrics endpoints.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解如何在 Prometheus 中设置监控后，接下来的问题是为什么以及如何保护你的指标端点。
- en: Securing Access to the Metrics Endpoint
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 保护指标端点的访问
- en: 'Throughout this chapter, we’ve only tangentially mentioned security. That’s
    because, for the most part, Prometheus follows the **SNMP** approach: **Security
    is Not My Problem**. There are some good reasons for this. If you’re using your
    Prometheus stack to debug an outage, you don’t want security to break that process.
    At the same time, making all of the data that can be gleaned from metrics for
    an attacker publicly visible is dangerous. In their 2019 keynote at KubeCon North
    America, Ian Coldwater said, “Attackers think in graphs” (Ian is quoting John
    Lambert: [https://github.com/JohnLaTwC/Shared/blob/master/Defenders%20think%20in%20lists.%20Attackers%20think%20in%20graphs.%20As%20long%20as%20this%20is%20true%2C%20attackers%20win.md](https://github.com/JohnLaTwC/Shared/blob/master/Defenders%20think%20in%20lists.%20Attackers%20think%20in%20graphs.%20As%20long%20as%20this%20is%20true%2C%20attackers%20win.md)),
    which comes to mind as I think about this because you can map out an environment
    based on metrics endpoints! Think about all the data about workloads and distributions,
    when and where nodes work the hardest, and so on. Take the `active_sessions` metric
    we worked with earlier in the chapter. Simply mapping that number over time will
    tell you when a spike in usage may not trigger alarms because it’s within norms.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们只稍微提到了安全性。这是因为大多数情况下，Prometheus 遵循 **SNMP** 方法：**安全性不是我的问题**。这样做有一些合理的原因。如果你正在使用
    Prometheus 栈来调试停机问题，你不希望安全性中断这个过程。同时，将所有可以从指标中提取的、可能被攻击者获取的数据公开是危险的。在 2019 年 KubeCon
    北美大会的主题演讲中，Ian Coldwater 说过：“攻击者思维是基于图表的”（Ian 引用了 John Lambert：[https://github.com/JohnLaTwC/Shared/blob/master/Defenders%20think%20in%20lists.%20Attackers%20think%20in%20graphs.%20As%20long%20as%20this%20is%20true%2C%20attackers%20win.md](https://github.com/JohnLaTwC/Shared/blob/master/Defenders%20think%20in%20lists.%20Attackers%20think%20in%20graphs.%20As%20long%20as%20this%20is%20true%2C%20attackers%20win.md))，这让我想到了，因为你可以根据指标端点绘制出一个环境的图谱！想一想关于工作负载和分布的所有数据，节点何时何地工作最辛苦，等等。以我们在本章早些时候讨论的
    `active_sessions` 指标为例。只需将该数字随时间映射出来，就可以告诉你什么时候使用量的激增可能不会触发警报，因为它仍在正常范围内。
- en: 'The good news is that because Prometheus runs in clusters, it gets its own
    identity. That’s why our `ServiceMonitor` included the `bearerTokenFile` option
    to the `Pod''s` built-in Kubernetes identity. OpenUnison validates this identity
    against the API server using a `SubjectAccessReview`. That’s why, when you look
    at the OpenUnison logs, you’ll see something like:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，因为 Prometheus 在集群中运行，它拥有自己的身份。这就是为什么我们的 `ServiceMonitor` 向 `Pod` 内建的 Kubernetes
    身份添加了 `bearerTokenFile` 选项。OpenUnison 使用 `SubjectAccessReview` 将此身份与 API 服务器进行验证。这就是为什么，当你查看
    OpenUnison 的日志时，你会看到类似下面的内容：
- en: '[PRE15]'
  id: totrans-184
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Whenever Prometheus attempts to scrape the metrics from OpenUnison, we know
    it’s with a token that is bound to a running pod and is still valid. When evaluating
    systems that provide metrics, check to see whether they support some kind of token
    validation. It’s not a bad idea to use `NetworkPolicies` to limit access, too,
    but as we’ve discussed several times, you’ll get the best protection based on
    a `Pod's` identity.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 每当 Prometheus 尝试从 OpenUnison 抓取指标时，我们知道它是使用一个绑定到运行中的 Pod 且仍然有效的令牌。当评估提供指标的系统时，请检查它们是否支持某种令牌验证。使用
    `NetworkPolicies` 限制访问也不是一个坏主意，但正如我们之前多次讨论的那样，你会根据 `Pod` 的身份获得最佳保护。
- en: Having reviewed how to secure your application metrics, the last section on
    Prometheus will focus on adding security to the kube-prometheus stack.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 在回顾如何保护应用程序指标之后，关于 Prometheus 的最后一节将专注于为 kube-prometheus 堆栈添加安全性。
- en: Securing Access to Your Monitoring Stack
  id: totrans-187
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 保护你的监控栈访问
- en: The kube-prometheus stack is a combination of Prometheus, Alertmanager, and
    Grafana combined with operators to automate the deployment and management of the
    stack. When we went through each of the applications in the stack, we pointed
    out that neither Prometheus nor Alertmanager has any sense of what a user is.
    Grafana does have its own user model, but kube-prometheus ships with a hardcoded
    credential. It’s assumed that you’ll access these tools via the `kubectl port-forward`
    directive. This is a similar scenario to the Kubernetes dashboard that we secured
    earlier in the book. While none of these applications use the user’s identity
    to communicate with the API server, they can be abused to provide extensive knowledge
    about the environment, so usage should be tracked.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: kube-prometheus 堆栈是一个由 Prometheus、Alertmanager 和 Grafana 组成的组合，结合了运维工具来自动化堆栈的部署和管理。当我们逐一讨论堆栈中的每个应用程序时，我们指出
    Prometheus 和 Alertmanager 都无法识别用户的身份。Grafana 拥有自己的用户模型，但 kube-prometheus 带有硬编码凭证。假定你会通过
    `kubectl port-forward` 指令访问这些工具。这与我们在本书早些时候保护的 Kubernetes 仪表盘情景相似。虽然这些应用程序都没有使用用户的身份与
    API 服务器通信，但它们可能被滥用以提供有关环境的广泛知识，因此应该跟踪使用情况。
- en: For Prometheus and Alertmanager, the easiest approach is to place an authenticating
    reverse proxy in front of them, something like an **OAuth2** proxy, for example.
    For this chapter, we used OpenUnison because it’s a built-in capability and requires
    fewer things to deploy.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 Prometheus 和 Alertmanager，最简单的方法是在它们前面放置一个身份验证的反向代理，例如一个**OAuth2**代理。对于本章，我们使用了
    OpenUnison，因为它是内建功能，部署时所需的东西较少。
- en: 'Grafana is more complicated because it does have several options for authentication.
    It also has its own user authorization model based on teams and roles. The Grafana
    that ships with the kube-prometheus charts is the Community edition, which only
    supports two roles: **Admin** and **Viewers**. While Grafana does support OpenID
    Connect out of the box, that would involve a more complicated helm configuration,
    and since we’re already using OpenUnison’s reverse proxy to authenticate Prometheus
    and Alertmanager, we went with the same approach with Grafana. The user’s identity
    is injected via an HTTP header in the request from OpenUnison to Grafana, with
    all users being considered administrators. Then, Grafana is configured in the
    helm chart using the proxy authentication method. So, where originally, we had
    `Ingress` objects that pointed directly to our applications, now we have a single
    Ingress pointing to OpenUnison, which is responsible for authenticating and authorizing
    access to these applications:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: Grafana 更复杂，因为它确实有多个身份验证选项。它还拥有基于团队和角色的用户授权模型。与 kube-prometheus 图表一起发布的 Grafana
    是社区版，只支持两种角色：**管理员**和**查看者**。虽然 Grafana 开箱即用支持 OpenID Connect，但这会涉及更复杂的 helm 配置。由于我们已经在使用
    OpenUnison 的反向代理来对 Prometheus 和 Alertmanager 进行身份验证，因此我们也使用相同的方法来处理 Grafana。用户的身份通过
    OpenUnison 向 Grafana 发出的请求中的 HTTP 头注入，所有用户都被视为管理员。然后，在 helm 图表中使用代理身份验证方法配置 Grafana。所以，原本指向我们应用程序的
    `Ingress` 对象，现在只有一个指向 OpenUnison 的 Ingress，它负责对这些应用程序进行身份验证和授权访问：
- en: '![Diagram  Description automatically generated](img/B21165_15_17.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![图示 说明自动生成](img/B21165_15_17.png)'
- en: 'Figure 15.17: Adding SSO to kube-prometheus'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.17：为 kube-prometheus 添加 SSO
- en: 'A bonus to integrating the kube-prometheus stack into OpenUnison is that you
    don’t need to memorize the URLs because they’re included as badges along with
    the dashboard and tokens:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 将 kube-prometheus 堆栈集成到 OpenUnison 中的一个好处是，你不需要记住 URLs，因为它们已经作为徽章与仪表盘和令牌一起包含在内：
- en: '![Graphical user interface, logo, company name  Description automatically generated](img/B21165_15_18.png)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，徽标，公司名称 说明自动生成](img/B21165_15_18.png)'
- en: 'Figure 15.18: OpenUnison with kube-prometheus “badges”'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.18：带有 kube-prometheus “徽章”的 OpenUnison
- en: What happens if OpenUnison goes down? It’s important to always have a “break
    glass in case of emergency” plan! You can still fall back on port forwarding access
    to all three of the applications.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 OpenUnison 出现故障会发生什么？始终拥有一个“紧急情况时打破玻璃”的计划非常重要！你仍然可以通过端口转发访问所有三个应用程序。
- en: This concludes our section on monitoring Kubernetes using Prometheus. Next,
    we’ll explore how logs work in Kubernetes and how to manage them.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 本节内容到此结束，介绍了如何使用 Prometheus 监控 Kubernetes。接下来，我们将探讨 Kubernetes 中日志的工作原理及其管理方法。
- en: Log Management in Kubernetes
  id: totrans-198
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 中的日志管理
- en: 'Throughout this book, after running an exercise, we will often ask you to view
    the logs of a container by running a command such as:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书中，进行完一个练习后，我们通常会要求你通过运行类似下面的命令来查看容器的日志：
- en: '[PRE16]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: This allows us to view logs, but what’s happening to get the logs? Where are
    the logs stored and how are they managed? What are the processes to manage archiving
    logs? It turns out this is a complex topic that often gets overlooked when getting
    started with Kubernetes. The rest of this chapter will be dedicated to answering
    these questions. First, let’s discuss how Kubernetes stores logs, and then we’ll
    get into pulling those logs into a centralized system.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 这让我们能够查看日志，但获取日志的过程是怎样的呢？日志存储在哪里，如何管理？如何管理日志的归档？事实证明，这是一个复杂的话题，在刚开始使用 Kubernetes
    时，往往会被忽视。本章的其余部分将致力于回答这些问题。首先，让我们讨论 Kubernetes 如何存储日志，然后我们将介绍如何将这些日志拉入集中式系统。
- en: Understanding Container Logs
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解容器日志
- en: Before we ran containers, logging was relatively straightforward. Your application
    usually had a library that was responsible for sending data to logs. That library
    would rotate the logs and often clean out old logs. It wasn’t unusual to have
    multiple logs for multiple purposes. For instance, most web servers had at least
    two logs. There was an access log to record who made requests to the web server
    and an error log to track any error or debug messages. In the early 2000s, companies
    like Splunk came out with systems that would ingest your logs into a time series
    database that you could use to query them in real time across multiple systems,
    making log management even easier.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 在运行容器之前，日志记录相对简单。你的应用程序通常有一个库，负责将数据发送到日志中。该库会轮换日志，并且通常会清理旧的日志。多个日志文件用于不同的目的也并不罕见。例如，大多数
    web 服务器至少有两个日志文件，一个是访问日志，用于记录谁向 web 服务器发出了请求；另一个是错误日志，用于跟踪任何错误或调试信息。在 2000 年代初期，像
    Splunk 这样的公司推出了系统，将你的日志导入时间序列数据库，以便你可以在多个系统中实时查询它们，使得日志管理变得更加轻松。
- en: Then came Docker containers, which broke this model. Containers are self-contained
    and not meant to generate data on their own. Instead of generating log data to
    a volume, containers were encouraged to pipe all log data to standard out so that
    the Docker API could be used to watch the logs without directly accessing the
    volume they were stored on. This standard continued with Kubernetes, so that as
    an operator, I never need access to the file where logs are stored, just access
    to the Kubernetes API. While this vastly simplifies accessing a log directly,
    it makes managing logs much more difficult. First off, an application can no longer
    break up logs by function, so as an operator, I need to filter out the parts of
    the logs I want. Additionally, the logs are no longer rotated in a way that is
    standard or configurable by the application owner. Finally, how do you archive
    logs in a way that satisfies your compliance requirements? The answer is to pipe
    your logs into a central log management system. Next, we’ll walk through the OpenSearch
    project, which is the log management system we chose to illustrate how container
    log management works.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 然后是 Docker 容器的出现，打破了这种模式。容器是自包含的，不用于生成数据。容器鼓励将所有日志数据管道化到标准输出，而不是将日志数据写入某个存储卷，这样可以通过
    Docker API 来观看日志，而不需要直接访问存储日志的卷。这个标准在 Kubernetes 中得到了延续，所以作为操作员，我不需要访问日志存储的文件，只需要访问
    Kubernetes API。虽然这种方式大大简化了直接访问日志的过程，但也使得日志的管理变得更加复杂。首先，应用程序不再按功能划分日志，因此作为操作员，我需要筛选出我需要的日志部分。此外，日志不再按照应用程序拥有者可以配置的标准进行轮换。最后，如何以满足合规要求的方式归档日志？答案是将日志管道化到一个中央日志管理系统。接下来，我们将介绍
    OpenSearch 项目，这是我们选择的日志管理系统，用来说明容器日志管理是如何工作的。
- en: Introducing OpenSearch
  id: totrans-205
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍 OpenSearch
- en: 'There are several log management systems. Splunk is often the most well known,
    but there is an entire industry built around log management. There are multiple
    open source log management systems as well. Probably the best known is the “ELK”
    stack, which is a combination of:'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 有多个日志管理系统。Splunk 通常是最为人知的，但围绕日志管理构建了一个完整的行业。也有多个开源的日志管理系统。最著名的可能是 “ELK” 堆栈，它是由以下组件组成：
- en: '**Elasticsearch**:A time series database and indexing system for storing and
    sorting logs'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Elasticsearch**：一个用于存储和排序日志的时间序列数据库和索引系统'
- en: '**Logstash**: A project for getting logs into Elasticsearch'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Logstash**：一个将日志导入 Elasticsearch 的项目'
- en: '**Kibana:** A dashboard and UI for Elasticsearch'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kibana**：一个 Elasticsearch 的仪表盘和 UI'
- en: The ELK stack is not the only open source log management system. Another project
    called Graylog is popular as well. Unfortunately, both projects hide their SSO
    support for OpenID Connect in commercial offerings. In 2021, Amazon forked the
    ELK stack from Elasticsearch 7.0 into the OpenSearch project. The two projects
    have since diverged. We decided to focus on OpenSearch for this chapter because
    it’s fully open source and we can show how it integrates into your cluster’s enterprise
    requirements via OpenID Connect.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: ELK堆栈并不是唯一的开源日志管理系统。另一个名为Graylog的项目也非常受欢迎。不幸的是，这两个项目都将它们对OpenID Connect的SSO支持隐藏在商业版本中。2021年，亚马逊将Elasticsearch
    7.0的ELK堆栈分叉到OpenSearch项目中。此后，两个项目已经分道扬镳。我们决定在本章中聚焦于OpenSearch，因为它是完全开源的，我们可以展示它如何通过OpenID
    Connect集成到集群的企业需求中。
- en: '![Diagram  Description automatically generated](img/B21165_15_19.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![Diagram  Description automatically generated](img/B21165_15_19.png)'
- en: 'Figure 15.19: OpenSearch architecture'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.19：OpenSearch架构
- en: 'In the above diagram, we see the major components of an OpenSearch deployment:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述图中，我们可以看到OpenSearch部署的主要组件：
- en: '**Masters**:This is the engine of OpenSearch that indexes log data.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Masters**：这是OpenSearch的引擎，负责索引日志数据。'
- en: '**Node**: The nodes are the integration points for services interacting with
    OpenSearch. It hosts the API used to query indices and to push logs into the cluster.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Node**：节点是与OpenSearch交互的服务的集成点。它托管用于查询索引和将日志推送到集群的API。'
- en: '**Kibana**: OpenSearch has a bundled Kibana dashboard for interacting with
    the OpenSearch API via a web application.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kibana**：OpenSearch附带了一个Kibana仪表板，用于通过Web应用程序与OpenSearch API交互。'
- en: '**Logstash/Fluent Bit/Fluentd**: A `DaemonSet` that tails the logs in the cluster
    and sends them to OpenSearch.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Logstash/Fluent Bit/Fluentd**：一个`DaemonSet`，用于尾随集群中的日志并将其发送到OpenSearch。'
- en: We’re not going too deeply into how OpenSearch works, because it’s a complex
    system that deserves its own book (and there are a few out there). We’re going
    to go deep enough to see how it relates to our enterprise Kubernetes requirements
    for aggregating logs and meeting our enterprise security requirements using our
    centralized Active Directory and managing access via our directory groups. Now
    that we’ve got an overview of the different components of our OpenSearch cluster,
    next, we’ll deploy it.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会深入探讨OpenSearch是如何工作的，因为它是一个复杂的系统，值得专门撰写一本书（实际上已经有几本）。我们将深入到足够的程度，了解它如何与我们的企业Kubernetes需求相关，如何通过我们的集中式Active
    Directory聚合日志，并通过目录组来管理访问。现在我们已经对OpenSearch集群的不同组件有了概述，接下来我们将进行部署。
- en: Deploying OpenSearch
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署OpenSearch
- en: 'We’ve automated the deployment of OpenSearch using scripts. There’s a dependency
    in OpenSearch for the CRDs from Prometheus’ operator, so we’re going to need that
    deployed, too. We’re going to start with a fresh cluster:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经通过脚本自动化了OpenSearch的部署。OpenSearch依赖Prometheus操作符的CRDs，因此我们也需要部署它。我们将从一个全新的集群开始：
- en: '[PRE17]'
  id: totrans-221
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'These scripts:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 这些脚本：
- en: Deploy a new KinD cluster with an NGINX Ingress controller.
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署一个新的KinD集群，并使用NGINX Ingress控制器。
- en: Deploy the kube-prometheus project for Prometheus, Alertmanager, and Grafana.
  id: totrans-224
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署kube-prometheus项目，用于Prometheus、Alertmanager和Grafana。
- en: Deploy “Active Directory” and OpenUnison, and integrate SSO into the Prometheus
    stack applications.
  id: totrans-225
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署“Active Directory”和OpenUnison，并将SSO集成到Prometheus堆栈应用中。
- en: 'This is the same place where you would be had you followed throughout this
    chapter. Next, we’ll deploy OpenSearch:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 这是你如果按照本章内容操作时应该到达的地方。接下来，我们将部署OpenSearch：
- en: '[PRE18]'
  id: totrans-227
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This script does several things:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这个脚本执行了几个操作：
- en: Increases file limits to support both OpenSearch and FluentBit opening every
    log and tailing them
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 增加文件限制，以支持OpenSearch和FluentBit同时打开每个日志并进行尾随处理
- en: Deploys the OpenSearch operator via Helm
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过Helm部署OpenSearch操作符
- en: Creates OpenUnison configuration objects to integrate OpenSearch
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建OpenUnison配置对象，以集成OpenSearch
- en: Deploys an OpenSearch cluster, configured to use SSO from OpenUnison using OpenID
    Connect
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署一个OpenSearch集群，配置为通过OpenUnison使用OpenID Connect进行SSO认证
- en: Deploys Fluent Bit via Helm
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过Helm部署Fluent Bit
- en: We’re not going to spend lots of time diving into individual configurations.
    Given how quickly things change, it would be better to get individual instructions
    directly from the OpenSearch project. We will instead walk through how these components
    relate to each other, our cluster, and our enterprise security requirements. Now
    that everything is deployed, we’re going to walk through how a log gets from your
    container into OpenSearch, and how you access it.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不会花太多时间深入探讨个别配置。鉴于事物变化如此之快，最好直接从OpenSearch项目获取个别指令。我们将重点介绍这些组件如何相互关联，如何与集群以及企业安全需求相匹配。既然一切都已经部署好了，我们将演示日志如何从容器进入OpenSearch，以及如何访问它。
- en: Tracing Logs from Your Container to Your Console
  id: totrans-235
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 从容器到控制台的追踪日志
- en: With OpenSearch in place and integrated into your cluster, let’s follow how
    logs get from your `ingress-nginx` container into your console. The first place
    to look is in the `fluentbit` namespace, where you’ll find a single `DaemonSet`
    called `fluent-bit`. Recall that a `DaemonSet` is a pod that gets deployed to
    every node in your cluster. Since we only have one node in our KinD cluster, we
    only have one pod for the `fluent-bit DaemonSet`. This pod is responsible for
    scanning all of the logs on the node and tailing them, similar to how you might
    tail a log on a local file system. What’s important about Fluent Bit is that in
    addition to sending log data to OpenSearch, it’s also adding metadata, which will
    allow us to easily search for log data inside of OpenSearch.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 在集成到集群中的OpenSearch已就绪后，让我们跟踪日志从`ingress-nginx`容器到控制台的过程。首先要查看的是`fluentbit`命名空间，您将在其中找到一个名为`fluent-bit`的`DaemonSet`。回想一下，`DaemonSet`是一个会部署到集群中每个节点的pod。由于我们在KinD集群中只有一个节点，因此`fluent-bit
    DaemonSet`只有一个pod。这个pod负责扫描节点上的所有日志，并对其进行尾随，类似于您在本地文件系统上查看日志的方式。Fluent Bit的重要之处在于，除了将日志数据发送到OpenSearch，它还会添加元数据，这使我们能够轻松地在OpenSearch中搜索日志数据。
- en: You might be wondering why we’re not using Logstash since it’s one of the named
    components in the ELK stack. Logstash isn’t the only log aggregator project. FluentD
    and FluentBit are both very popular tools for pulling logs from your cluster.
    Fluentd is much heavier than Fluent Bit and has many more capabilities for transforming
    and parsing log data before sending it to OpenSearch. FluentBit is simpler but
    is also much smaller. We went with FluentBit for its simplicity and size given
    we’re already filling out the cluster with other tools.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 您可能会问，为什么我们不使用Logstash，毕竟它是ELK栈中的一个重要组件。Logstash并不是唯一的日志聚合工具，FluentD和FluentBit也是非常流行的从集群中提取日志的工具。Fluentd比FluentBit更重，且具有更多在发送日志到OpenSearch之前对日志数据进行转换和解析的能力。FluentBit则更简洁，体积也小。考虑到我们已经在集群中使用了其他工具，我们选择了FluentBit，因为它的简便和轻便。
- en: 'Let’s look at the `Pod''s` logs and look for `ingress-nginx`:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们查看`Pod`的日志，寻找`ingress-nginx`。
- en: '[PRE19]'
  id: totrans-239
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: As you can see, FluentBit found the logs on the node. You may be asking whether
    or not the FluentBit pods need special permissions to access the logs on the node,
    and the answer is yes! If we look at the `fluent-bit DaemonSet`, we’ll see that
    the `securityContext` is empty, meaning there are no constraints on the pod, and
    that the `volumes` include `hostMount` directives to where the logs are stored
    on standard kubeadm deployments. These `Pods` are privileged and should be protected
    as such by limiting access to the `fluentbit` namespace and adding policies, such
    as with GateKeeper, that limit which containers can run in the `fluentbit` namespace,
    too.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，FluentBit找到了节点上的日志。您可能会问FluentBit pod是否需要特殊权限才能访问节点上的日志，答案是肯定的！如果我们查看`fluent-bit
    DaemonSet`，我们会发现`securityContext`为空，意味着该pod没有任何约束，而`volumes`则包含`hostMount`指令，指向在标准kubeadm部署中存储日志的位置。这些`Pods`是特权的，应该通过限制对`fluentbit`命名空间的访问以及通过使用GateKeeper等策略，限制哪些容器可以在`fluentbit`命名空间中运行，从而受到保护。
- en: Once the watch is placed on the `ingress-nginx` logs, those logs and additional
    metadata are sent to the OpenSearch node. As we discussed earlier, the OpenSearch
    node hosts the API and is the conduit for the masters, which are responsible for
    managing the indexes. The fluent-bit `DaemonSet` communicates with OpenSearch
    using the Logstash protocol and a simple authentication using basic authentication.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦将监视器放置在`ingress-nginx`日志上，这些日志和附加的元数据将被发送到OpenSearch节点。正如我们之前所讨论的，OpenSearch节点托管着API，并作为主节点的通道，主节点负责管理索引。fluent-bit的`DaemonSet`使用Logstash协议与OpenSearch通信，并通过基本身份验证进行简单的认证。
- en: It would be great for our FluentBit deployment to use its `ServiceAccount` token
    to communicate with OpenSearch securely in the same way we configured our pods
    to communicate with Vault, but unfortunately, this feature doesn’t exist in either
    the nodes or in FluentBit. Instead, you should make sure to give your Logstash
    account an extremely long password and make sure to rotate it with your enterprise
    policies. You could even leverage a secrets manager…
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的 FluentBit 部署，使用其 `ServiceAccount` 令牌与 OpenSearch 安全地通信，就像我们配置 Pods 与 Vault
    通信一样，将会非常理想，但不幸的是，这个功能在节点或 FluentBit 中都不存在。相反，你应该确保为 Logstash 账户设置一个非常长的密码，并确保按照企业政策定期更换密码。你甚至可以利用一个秘密管理器……
- en: As the OpenSearch node pulls in the data, it’s sent to the masters to be indexed.
    This is where the magic of OpenSearch happens because this is where all that data
    gets stored in an index and is made available to you and your cluster’s administrators.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 当 OpenSearch 节点拉取数据时，它会将数据发送给主节点进行索引。这是 OpenSearch 魔力的所在，因为所有数据会存储在索引中，并提供给你和你的集群管理员。
- en: Now that the data is in OpenSearch, how are you going to access it? OpenSearch
    includes a Kibana dashboard for accessing and visualizing log data. The default
    implementation uses a single admin username and password, but that’s not going
    to work for us! Log data is extremely sensitive, and we want to make sure we’re
    using our enterprise security requirements when accessing it! That said, we’ll
    want to integrate OpenSearch with OpenUnison the same way we’ve integrated the
    rest of our cluster management applications. Thankfully, OpenSearch supports OpenID
    Connect, which makes integration with OpenUnison very straightforward!
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 既然数据已经存储在 OpenSearch 中，接下来你打算如何访问它？OpenSearch 包含一个 Kibana 仪表盘，用于访问和可视化日志数据。默认实现使用一个管理员用户名和密码，但这对我们来说行不通！日志数据极为敏感，我们希望在访问它时遵循企业安全要求！也就是说，我们需要将
    OpenSearch 与 OpenUnison 集成，就像我们集成其余集群管理应用程序一样。幸运的是，OpenSearch 支持 OpenID Connect，这使得与
    OpenUnison 的集成变得非常直接！
- en: OpenSearch supports multiple authentication systems in addition to OpenID Connect,
    including LDAP. We could use this LDAP functionality to integrate with the “Active
    Directory” we deployed with OpenUnison. This integration provides some major limitations,
    though. If our enterprise decides to move off of Active Directory to an identity-as-a-service
    platform, such as Entra (formerly known as Azure AD) or Okta, this solution wouldn’t
    work anymore. Also, if a multi-factor solution is added, this method would no
    longer work. Using OpenID Connect with an integration tool like OpenUnison, Dex,
    or KeyCloak will make your deployment much more manageable.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 OpenID Connect，OpenSearch 还支持多种身份验证系统，包括 LDAP。我们可以使用这个 LDAP 功能与我们与 OpenUnison
    部署的“Active Directory”进行集成。然而，这种集成有一些重大限制。如果我们的企业决定将身份管理平台从 Active Directory 切换到身份即服务平台，比如
    Entra（前身为 Azure AD）或 Okta，那么这个解决方案将不再有效。另外，如果添加了多因素身份验证方案，这种方法也将失效。使用 OpenID Connect
    结合像 OpenUnison、Dex 或 KeyCloak 这样的集成工具，将使你的部署更加可管理。
- en: What’s interesting about the OpenSearch OpenID Connect implementation is that
    it is very similar to how the Kubernetes dashboard worked. The Kibana that is
    bundled with OpenSearch can use OpenID Connect to redirect the user to OpenUnison
    to authenticate and also knows how to refresh the user’s `id_token` to keep the
    session open. Once authenticated, Kibana then uses the user’s token to interact
    with the OpenSearch nodes using their identity. This means that, in addition to
    configuring Kibana, we need to configure the OpenSearch nodes to trust OpenUnison’s
    tokens.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: OpenSearch OpenID Connect 实现的有趣之处在于，它与 Kubernetes 仪表盘的工作方式非常相似。捆绑在 OpenSearch
    中的 Kibana 可以使用 OpenID Connect 将用户重定向到 OpenUnison 进行身份验证，并且知道如何刷新用户的 `id_token`
    以保持会话开放。身份验证通过后，Kibana 使用用户的令牌与 OpenSearch 节点交互，保持其身份。这意味着，除了配置 Kibana，我们还需要配置
    OpenSearch 节点以信任 OpenUnison 的令牌。
- en: There are two configuration points to do this. In `chapter15/opensearch/opensearch-sso.yaml`,
    you’ll find an OpenSearch cluster object with a `spec.dashboard.additionalConfig`
    that contains the dashboard (Kibana) configuration. If we deployed with just this,
    we’d be able to authenticate to Kibana, but we wouldn’t be able to interact with
    OpenSearch because the API calls would fail.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 要完成此操作，有两个配置点。在 `chapter15/opensearch/opensearch-sso.yaml` 文件中，你将找到一个 OpenSearch
    集群对象，其中包含一个 `spec.dashboard.additionalConfig`，该配置包含了仪表盘（Kibana）的配置。如果我们仅仅部署了这个，我们可以进行
    Kibana 身份验证，但我们无法与 OpenSearch 进行交互，因为 API 调用会失败。
- en: Next, there’s a `Secret` called `opensearch-security-config`, which contains
    a key called `config.yml` that stores the OpenSearch node security main configuration.
    Here, we tell OpenSearch where to retrieve the OpenUnison OpenID Connect discovery
    document so that the `id_token` sent by Kibana can be validated. Similar to the
    Kubernetes dashboard, when using OpenID Connect, the API isn’t able to refresh
    or manage a user’s session. The nodes are only validating the user’s `id_token`.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，有一个名为`Secret`的秘密，叫做`opensearch-security-config`，它包含一个名为`config.yml`的键，用于存储OpenSearch节点的主要安全配置。在这里，我们告诉OpenSearch从哪里获取OpenUnison的OpenID
    Connect发现文档，以便Kibana发送的`id_token`可以得到验证。与Kubernetes仪表板类似，使用OpenID Connect时，API无法刷新或管理用户的会话。节点仅验证用户的`id_token`。
- en: We’ve tracked our data from our container’s log into OpenSearch and seen how
    we will access it. Next, let’s log in to Kibana and view our log data!
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经追踪了来自容器日志的数据，并将其存储到OpenSearch中，接下来我们将展示如何访问这些数据。接下来，让我们登录Kibana查看我们的日志数据！
- en: Viewing Log Data in Kibana
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Kibana中查看日志数据
- en: We’ve spent quite a bit of time describing how OpenSearch is deployed and how
    log data is ingested into the OpenSearch cluster from Kubernetes. Next, we’ll
    log in to Kibana and view the logs from our `ingress-nginx` Deployment.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经花费了相当多的时间描述OpenSearch是如何部署的，以及如何从Kubernetes将日志数据摄取到OpenSearch集群中。接下来，我们将登录到Kibana，并查看来自`ingress-nginx`部署的日志。
- en: 'First, open a web browser and enter the URL for your OpenUnison deployment.
    Just as in prior chapters, it will be `https://k8sou.apps.X-X-X-X.nip.io/`, where
    `X-X-X-X` is your cluster’s IP address with dashes instead of dots. Since my cluster
    is running on `192.168.2.93`, I navigate to `https://k8sou.apps.192-168-2-93.nip.io/`.
    Use the username **mmosley** and the password **start123** to log in. You’ll now
    see an OpenSearch badge:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，打开一个Web浏览器，输入你的OpenUnison部署的URL。就像之前章节所示，它将是`https://k8sou.apps.X-X-X-X.nip.io/`，其中`X-X-X-X`是你的集群IP地址，使用破折号代替点。由于我的集群运行在`192.168.2.93`，因此我将导航到`https://k8sou.apps.192-168-2-93.nip.io/`。使用用户名**mmosley**和密码**start123**登录。现在你应该会看到一个OpenSearch徽章：
- en: '![Graphical user interface, logo, company name  Description automatically generated](img/B21165_15_20.png)Figure
    15.20: OpenUnison with OpenSearch “badge”'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '![图形用户界面，徽标，公司名称 自动生成的描述](img/B21165_15_20.png)图 15.20：OpenUnison与OpenSearch的“徽章”'
- en: 'Click on the OpenSearch badge. You may be asked to add data, but skip this
    so we can get straight to our data. Next, click on the three horizontal bars in
    the upper-left corner to open the menu, scroll down to **Management**, and click
    on **Dashboards Management**:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 点击OpenSearch徽章。你可能会被要求添加数据，但跳过此步骤，我们直接进入查看数据。接下来，点击左上角的三条水平线以打开菜单，滚动到**管理**，然后点击**仪表板管理**：
- en: '![Graphical user interface, application, Teams  Description automatically generated](img/B21165_15_21.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，应用程序，Teams 自动生成的描述](img/B21165_15_21.png)'
- en: 'Figure 15.21: OpenSearch Dashboard Management menu'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.21：OpenSearch仪表板管理菜单
- en: 'Next, click on **Index patterns** on the left and then **Create index pattern**
    on the right:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，点击左侧的**索引模式**，然后点击右侧的**创建索引模式**：
- en: '![Graphical user interface, application, Teams  Description automatically generated](img/B21165_15_22.png)'
  id: totrans-258
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，应用程序，Teams 自动生成的描述](img/B21165_15_22.png)'
- en: 'Figure 15.22: Index patterns'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.22：索引模式
- en: On the next screen, use `logstash-*` for the **Index pattern name** to load
    all our indices from FluentBit and click **Next step**.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个屏幕上，使用`logstash-*`作为**索引模式名称**，以加载来自FluentBit的所有索引，然后点击**下一步**。
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B21165_15_23.png)'
  id: totrans-261
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本，应用程序，电子邮件 自动生成的描述](img/B21165_15_23.png)'
- en: 'Figure 15.23: Create index pattern'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.23：创建索引模式
- en: 'On the next screen, choose **@timestamp** for the **Time field** and, finally,
    click **Create index pattern**:'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个屏幕上，选择**@timestamp**作为**时间字段**，然后点击**创建索引模式**：
- en: '![Graphical user interface, application  Description automatically generated](img/B21165_15_24.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，应用程序 自动生成的描述](img/B21165_15_24.png)'
- en: 'Figure 15.24: Index Time field'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15.24：索引时间字段
- en: 'The next screen will show you the list of all the fields that can be searched.
    These fields are what are created by FluentBit and provide much easier searching
    of logs. They have all kinds of metadata from Kubernetes, including the namespace,
    labels, annotations, pod names, and so on. With our index pattern created, next,
    we’ll want to query the log data to find which logs are coming from `ingress-nginx`.
    Next, click on the three horizontal bars in the upper-left corner again to reveal
    the menu and, under **Observability**, click **Logs**:'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 下一屏幕将显示可以搜索的所有字段列表。这些字段由FluentBit创建，并提供更便捷的日志搜索。它们包含来自Kubernetes的各种元数据，包括命名空间、标签、注解、Pod名称等。有了我们创建的索引模式，接下来我们将查询日志数据，找出哪些日志来自`ingress-nginx`。接下来，再次点击左上角的三个横线，显示菜单，在**可观察性**下点击**日志**：
- en: '![Graphical user interface, application  Description automatically generated](img/B21165_15_25.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，应用程序 描述自动生成](img/B21165_15_25.png)'
- en: 'Figure 15.25: Logs menu item'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.25：日志菜单项
- en: 'We haven’t created any visualization, so there’s nothing to see yet! Click
    on **Event Explorer**:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还没有创建任何可视化，因此暂时没有内容可见！点击**事件浏览器**：
- en: '![Graphical user interface, application, Teams  Description automatically generated](img/B21165_15_26.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，应用程序，Teams 描述自动生成](img/B21165_15_26.png)'
- en: 'Figure 15.26: The Logs screen'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.26：日志屏幕
- en: On the next screen, set the **index pattern** to `logstash-*`, and the **timeframe**
    to the last 15 hours. Finally, click **Refresh**.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个屏幕上，将**索引模式**设置为`logstash-*`，并将**时间范围**设置为过去15小时。最后，点击**刷新**。
- en: '![Graphical user interface, application  Description automatically generated](img/B21165_15_27.png)'
  id: totrans-273
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，应用程序 描述自动生成](img/B21165_15_27.png)'
- en: 'Figure 15.27: Logs Explorer'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.27：日志浏览器
- en: 'This will load quite a bit of data, most of which is meaningless to us. We
    only want data from the `ingress-nginx` namespace. So, we’ll want to constrain
    the results to our `ingress-nginx` namespace. Next to **PPL**, paste in the following
    and click **Refresh**:'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 这将加载大量数据，其中大部分对我们来说没有意义。我们只想要来自`ingress-nginx`命名空间的数据。所以，我们需要将结果限制为`ingress-nginx`命名空间。接下来，在**PPL**旁边粘贴以下内容并点击**刷新**：
- en: '[PRE20]'
  id: totrans-276
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'Now, you’ll see the access logs from NGINX:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你将看到来自NGINX的访问日志：
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B21165_15_28.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本，应用程序，电子邮件 描述自动生成](img/B21165_15_28.png)'
- en: 'Figure 15.28: Searching for NGINX logs'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 图15.28：搜索NGINX日志
- en: While we’re now able to search our logs from a central location, this only scratches
    the surface of what OpenSearch is capable of. As we said earlier in the chapter,
    there are books written on this topic alone, so we’ll not be able to get too proficient
    in OpenSearch in this chapter but we have covered enough to demonstrate how logs
    move from your containers into a centralized system. Whether you’re deploying
    an on-premises cluster, like our KinD cluster, or a cloud-based cluster, the same
    concepts will exist.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然我们现在能够从一个集中位置搜索日志，但这仅仅是OpenSearch能力的冰山一角。正如我们在本章之前所说，仅此主题就有书籍专门介绍，因此我们无法在本章中深入掌握OpenSearch，但我们已经涵盖了足够的内容，展示了日志如何从容器移动到集中式系统。无论你是部署本地集群（如我们的KinD集群），还是基于云的集群，相同的概念都会存在。
- en: Summary
  id: totrans-281
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: Logging and monitoring are crucial to being able to track the health of your
    cluster, planning for ongoing maintenance and capacity, and also making sure to
    maintain compliance. In this chapter, we started with monitoring, walking through
    the Prometheus stack, and exploring each component and how they interact. After
    looking at the stack, we worked on how to monitor systems running on our cluster
    by integrating our OpenUnison into Prometheus. The last Prometheus topic we explored
    was integrating the stack into our enterprise authentication system using OpenUnison.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 日志记录和监控对于能够跟踪集群健康、规划持续维护和容量，并确保维持合规性至关重要。在本章中，我们从监控开始，讲解了Prometheus栈，并探索了每个组件及其交互方式。在查看栈之后，我们通过将OpenUnison集成到Prometheus中，研究了如何监控在我们集群上运行的系统。我们探讨的最后一个Prometheus话题是如何将栈集成到我们的企业认证系统中，使用OpenUnison。
- en: After working through Prometheus, we explored logging in Kubernetes by deploying
    an OpenSearch cluster to centralize our log aggregation. After deployment, we
    tracked logs from the container that generates them into OpenSearch’s indexes
    and then how to access them securely using OpenSearch’s Kibana dashboard.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 在研究完 Prometheus 后，我们通过部署 OpenSearch 集群来集中处理日志聚合，从而探索了 Kubernetes 中的日志记录。部署后，我们跟踪生成日志的容器，将日志存储到
    OpenSearch 的索引中，然后学习如何通过 OpenSearch 的 Kibana 仪表板安全地访问这些日志。
- en: In the next chapter, we’re going to learn how service meshes work and deploy
    Istio.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将学习服务网格的工作原理，并部署 Istio。
- en: Questions
  id: totrans-285
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 问题
- en: Prometheus’ metrics are transferred using JSON.
  id: totrans-286
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Prometheus 的度量标准使用 JSON 进行传输。
- en: 'True'
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确
- en: 'False'
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误
- en: Where can Alertmanager send alerts to?
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Alertmanager 可以将警报发送到哪里？
- en: Webhook
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Webhook
- en: Slack
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: Slack
- en: Email
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 邮件
- en: All of the above
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以上所有
- en: What label does a ConfigMap that stores a Grafana dashboard need?
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 存储 Grafana 仪表板的 ConfigMap 需要什么标签？
- en: '`grafana_dashboard: 1`'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`grafana_dashboard: 1`'
- en: '`dashboard_type: grafana`'
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`dashboard_type: grafana`'
- en: None needed
  id: totrans-297
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 无需任何配置
- en: OpenSearch is compatible with Elasticsearch.
  id: totrans-298
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: OpenSearch 与 Elasticsearch 兼容。
- en: 'True'
  id: totrans-299
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确
- en: 'False'
  id: totrans-300
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误
- en: Logstash is required for log management.
  id: totrans-301
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: Logstash 是日志管理所必需的。
- en: 'True'
  id: totrans-302
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 正确
- en: 'False'
  id: totrans-303
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 错误
- en: Answers
  id: totrans-304
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 答案
- en: 'b: False: Prometheus has its own format for metrics.'
  id: totrans-305
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'b: 错误：Prometheus 有其自己的度量标准格式。'
- en: 'd: Alertmanager can send notifications to all of these systems and more.'
  id: totrans-306
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'd: Alertmanager 可以将通知发送到所有这些系统以及更多系统。'
- en: 'a: Grafana looks for all ConfigMaps across the cluster with `grafana_dashboard`:
    1 to load dashboards.'
  id: totrans-307
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'a: Grafana 会查找集群中所有带有 `grafana_dashboard`: 1 的 ConfigMap，以加载仪表板。'
- en: 'b: False: OpenSearch was forked from Elasticsearch 7.0; the two systems have
    since diverged.'
  id: totrans-308
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'b: 错误：OpenSearch 是从 Elasticsearch 7.0 分支出来的；这两个系统此后已经发生了分歧。'
- en: 'b: False: Logstash is not required; systems such as FluentD and FluentBit are
    also compatible with OpenSearch and Elasticsearch.'
  id: totrans-309
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 'b: 错误：Logstash 不是必需的；像 FluentD 和 FluentBit 这样的系统也与 OpenSearch 和 Elasticsearch
    兼容。'
- en: Join our book’s Discord space
  id: totrans-310
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 加入我们书籍的 Discord 空间
- en: 'Join the book’s Discord workspace for a monthly *Ask Me Anything* session with
    the authors:'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 加入书籍的 Discord 工作区，参加每月的 *Ask Me Anything* 会话，与作者互动：
- en: '[https://packt.link/K8EntGuide](https://packt.link/K8EntGuide)'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: '[https://packt.link/K8EntGuide](https://packt.link/K8EntGuide)'
- en: '![](img/QR_Code965214276169525265.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
  zh: '![](img/QR_Code965214276169525265.png)'
