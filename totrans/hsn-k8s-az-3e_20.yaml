- en: 14\. Serverless functions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Serverless computing and serverless functions have gained tremendous traction
    over the past few years due to scalability and reduced management overhead. Cloud
    services such as Azure Functions, AWS Lambda, and GCP Cloud Run have made it very
    easy for users to run their code as serverless functions.
  prefs: []
  type: TYPE_NORMAL
- en: The word **serverless** refers to any solution where you don't need to manage
    servers. Serverless functions refer to a subset of serverless computing where
    you can run your code as a function on-demand. This means that your code in the
    function will only run and be executed when there is a demand. This architectural
    style is called event-driven architecture. In an event-driven architecture, the
    event consumers are triggered when there is an event. In the case of serverless
    functions, the event consumers will be these serverless functions. An event can
    be anything from a message in a queue to a new object uploaded to storage, or
    even an HTTP call.
  prefs: []
  type: TYPE_NORMAL
- en: Serverless functions are frequently used for backend processing. A common example
    of serverless functions is creating thumbnails of a picture that is uploaded to
    storage, as shown in *Figure 14.1*. Since you cannot predict how many pictures
    will be uploaded and when they will be uploaded, it is hard to plan traditional
    infrastructure and how many servers you should have available for this process.
    If you implement the creation of that thumbnail as a serverless function, this
    function will be called on each picture that is uploaded. You don't have to plan
    the number of functions since each new picture will trigger a new function to
    be executed.
  prefs: []
  type: TYPE_NORMAL
- en: '![Example architecture of a serverless function to generate thumbnails of images](img/B17338_14_01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.1: Example architecture of a serverless function to generate thumbnails
    of images'
  prefs: []
  type: TYPE_NORMAL
- en: As you saw in the previous example, functions will automatically scale to meet
    increased or decreased demand. Additionally, each function can scale independently
    from other functions. However, this automatic scaling is just one benefit of using
    serverless functions. Another benefit of serverless functions is the ease of development.
    Using serverless functions, you can focus on writing the code and don't have to
    deal with the underlying infrastructure. Serverless functions allow code to be
    deployed without worrying about managing servers and middleware. Finally, in public
    cloud serverless functions, you pay per execution of the function. This means
    that you pay each time your functions are run, and you are charged nothing for
    the idle time when your functions are not run.
  prefs: []
  type: TYPE_NORMAL
- en: 'The popularity of public cloud serverless function platforms has caused multiple
    open-source frameworks to be created to enable users to create serverless functions
    on top of Kubernetes. In this chapter, you will learn how to deploy serverless
    functions on **Azure Kubernetes Service** (**AKS**) directly using the open-source
    version of Azure Functions. You will start by running a simple function that is
    triggered based on an HTTP message. Afterward, you will install a function **autoscaler**
    feature on your cluster. You will also integrate AKS-deployed applications with
    Azure storage queues. We will be covering the following topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Overview of different functions platforms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying an HTTP-triggered function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deploying a queue-triggered function
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let's start this chapter by exploring the various functions platforms that are
    available for Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Various functions platforms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Functions platforms, such as Azure Functions, AWS Lambda, and Google Cloud Functions,
    have gained tremendous popularity. The ability to run code without the need to
    manage servers and having virtually limitless scale is very popular. The downside
    of using the functions implementation of a cloud provider is that you are locked
    into the cloud provider's infrastructure and their programming model. Also, you
    can only run your functions in the public cloud and not in your own datacenter.
  prefs: []
  type: TYPE_NORMAL
- en: 'A number of open-source functions frameworks have been launched to solve these
    downsides. There are a number of popular frameworks that can be run on Kubernetes:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Knative** (https://cloud.google.com/knative/): Knative is a serverless platform
    written in the Go language and developed by Google. You can run Knative functions
    either fully managed on Google Cloud or on your own Kubernetes cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`OpenFaaSCloud`. The platform is written in the Go language.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Kubeless`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fission.io** (https://fission.io/): Fission is a serverless framework backed
    by the company Platform9\. It is written in the Go language and is Kubernetes-native.
    It can run on any Kubernetes cluster.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache OpenWhisk** (https://openwhisk.apache.org/): OpenWhisk is an open-source,
    distributed serverless platform maintained by the Apache organization. It can
    be run on Kubernetes, Mesos, or Docker Compose. It is primarily written in the
    Scala language.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Microsoft has taken an interesting strategy with its functions platform. Microsoft
    operates Azure Functions as a managed service on Azure and has open-sourced the
    complete solution and made it available to run on any system (https://github.com/Azure/azure-functions-host).
    This also makes the Azure Functions programming model available on top of Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft has also released an additional open-source project in partnership
    with Red Hat called **Kubernetes Event-driven Autoscaling** (**KEDA**) to make
    scaling functions on top of Kubernetes easier. KEDA is a custom autoscaler that
    can allow deployments on Kubernetes to scale down to and up from zero pods, which
    is not possible using the default **Horizontal Pod Autoscaler** (**HPA**) in Kubernetes.
    The ability to scale from zero to one pod is important so that your application
    can start processing events, but scaling down to zero instances is useful for
    preserving resources in your cluster. KEDA also makes additional metrics available
    to the Kubernetes HPA to make scaling decisions based on metrics from outside
    the cluster (for example, the number of messages in a queue).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We introduced and explained the HPA in *Chapter 4*, *Building scalable applications*.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, you will deploy Azure Functions to Kubernetes with two examples:'
  prefs: []
  type: TYPE_NORMAL
- en: An HTTP-triggered function (without KEDA)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A queue-triggered function (with KEDA)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Before starting with these functions, the next section will consider the necessary
    prerequisites for these deployments.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up the prerequisites
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, you will set up the prerequisites needed to build and run functions
    on your Kubernetes cluster. You need to set up an **Azure container registry**
    (**ACR**) and a **virtual machine** (**VM**) in Azure that will be used to develop
    the functions. The ACR will be used to store custom container images that contain
    the functions you will develop. You will also use a VM to build the functions
    and create Docker images, since you cannot do this from Azure Cloud Shell.
  prefs: []
  type: TYPE_NORMAL
- en: Container images and a container registry were introduced in *Chapter 1*, *Introduction
    to containers and Kubernetes*, in the section on *Container images*. A container
    image contains all the software required to start an actual running container.
    In this chapter, you will build custom container images that contain your functions.
    You need a place to store these images so that Kubernetes can pull them and run
    the containers at scale. You will use ACR for this. ACR is a private container
    registry that is fully managed by Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Up to now in this book, you have run all the examples on Azure Cloud Shell.
    For the example in this chapter, you will need a separate VM because Azure Cloud
    Shell doesn't allow you to build container images. You will create a new VM in
    Azure to do these tasks.
  prefs: []
  type: TYPE_NORMAL
- en: Let's begin by creating an ACR.
  prefs: []
  type: TYPE_NORMAL
- en: Azure Container Registry
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Azure Functions on Kubernetes needs an image registry to store its container
    images. In this section, you will create an ACR and configure your Kubernetes
    cluster to have access to this cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: In the Azure search bar, search for `container registry` and click on Container
    registries, as shown in *Figure 14.2*:![Navigating to Container registries through
    the Azure portal](img/B17338_14_02.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 14.2: Navigating to Container registry services through the Azure portal'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the Add button at the top to create a new registry. To organize the resources
    in this chapter together, create a new resource group. To do this, click on Create
    new under the Resource group field to create a new resource group, and call it
    `Functions-KEDA`, as shown in *Figure 14.3*:![Creating a new resource group to
    create the registry](img/B17338_14_03.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 14.3: Creating a new resource group'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Provide the details to create the registry. The registry name needs to be globally
    unique, so consider adding your initials to the registry name. It is recommended
    to create the registry in the same location as your cluster. To reduce spending
    for the demo, you can change SKU to Basic. Select the Review + create button at
    the bottom to create the registry, as shown in *Figure 14.4*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Review the details provided and hit Review + create to create the registry](img/B17338_14_04.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.4: Providing details to create the registry'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: In the resulting pane, click the Create button to create the registry.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once your registry is created, open Cloud Shell so that you can configure your
    AKS cluster to get access to your container registry. Use the following command
    to give AKS permissions to your registry:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will return an output similar to *Figure 14.5*. The figure has been cropped
    to show only the top part of the output:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Giving AKS permissions on your registry](img/B17338_14_05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.5: Allowing AKS cluster to access the container registry'
  prefs: []
  type: TYPE_NORMAL
- en: You now have an ACR that is integrated with AKS. In the next section, you will
    create a VM that will be used to build the Azure functions.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a VM
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, you will create a VM and install the tools necessary to run
    Azure Functions on this machine:'
  prefs: []
  type: TYPE_NORMAL
- en: The Docker runtime
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Azure CLI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Functions
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kubectl
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: To ensure a consistent experience, you will be creating a VM on Azure that will
    be used for development. If you prefer to run the sample on your local machine,
    you can install all the required tools locally.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Let''s get started with creating the VM:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To ensure this example works with the Azure trial subscription, you will need
    to scale down your cluster to one node. You can do this using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To authenticate to the VM you are going to create, you''ll need a set of SSH
    keys. If you followed the example in *Chapter 9*, *Azure Active Directory pod-managed
    identities in AKS* in the *Setting up a new cluster with AAD pod-managed identity*
    section, you will already have a set of SSH keys. To verify that you have SSH
    keys, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should show you the presence of an SSH private key (`id_rsa`) and a public
    key (`id_rsa.pub`), as shown in *Figure 14.6*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Verifying the SSH keys that are present](img/B17338_14_06.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will be prompted for a location and a passphrase. Keep the default location
    and input an empty passphrase.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You will now create the VM. You will create an Ubuntu VM using the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will take a couple of minutes to complete. Once the VM is created, Cloud
    Shell should show you its public IP, as displayed in *Figure 14.7*:![Running the
    az vm create command and getting the public ip of the VM from the command](img/B17338_14_07.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: You will be prompted about whether you trust the machine's identity. Type `yes`
    to confirm.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You''re now connected to a new VM on Azure. On this machine, we will begin
    by installing Docker:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To make the operation smoother, add the user to the Docker group. This will
    ensure you can run Docker commands without `sudo`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You should now be able to run the `hello-world` command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will show you an output similar to *Figure 14.8*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Verifying that Docker runs on the virtual machine](img/B17338_14_08.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.8: Verifying Docker runs on the VM'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, you will install the Azure CLI on this VM. You can install the CLI using
    the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Verify that the CLI was installed successfully by signing in:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will display a login code that you need to enter at https://microsoft.com/devicelogin:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Logging in to the Azure CLI](img/B17338_14_09.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[PRE11]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The credentials to ACR expire after 3 hours. If you run into the following
    error during this demonstration, you can sign in to ACR again using the following
    command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Potential error that you might get while authenticating your machine to ACR](img/B17338_14_10.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.10: Potential authentication error in the future'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, you''ll install `kubectl` on your machine. The Azure CLI has a shortcut
    to install the CLI, which you can use to install it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Let''s verify that `kubectl` can connect to our cluster. For this, we''ll first
    get the credentials and then execute a `kubectl` command:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, you can install the Azure Functions tools on this machine. To do this,
    run the following commands:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will return an output similar to *Figure 14.11*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Installing Azure Functions Core Tools](img/B17338_14_11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.11: Installing Functions core tools'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: If you are running a newer version of Ubuntu than 18.04, please make sure that
    you download the correct `dpkg` package by changing the URL in the first line
    to reflect your Ubuntu version.
  prefs: []
  type: TYPE_NORMAL
- en: You now have the prerequisites to start working with functions on Kubernetes.
    You created an ACR to store custom container images, and you have a VM that will
    be used to create and build Azure functions. In the next section, you will build
    your first function, which is HTTP-triggered.
  prefs: []
  type: TYPE_NORMAL
- en: Creating an HTTP-triggered Azure function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this first example, you will create an HTTP-triggered Azure function. This
    means that you can browse to the page hosting the actual function:'
  prefs: []
  type: TYPE_NORMAL
- en: 'To begin, create a new directory and navigate to that directory:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now, you will initialize a function using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The `––docker` parameter specifies that you will build the function as a Docker
    container. This will result in a Dockerfile being created. Select the Python language,
    which is option 3 in the following screenshot:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Creating a Python function](img/B17338_14_12.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.12: Creating a Python function'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This will create the required files for your function to work.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Next, you will create the actual function. Enter the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should result in an output like the following. Select the eighth option,
    HTTP trigger, and name the function `python-http`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Creating an HTTP-triggered function using the required option](img/B17338_14_13.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.13: Creating an HTTP-triggered function'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The code of the function is stored in the directory called `python-http`. You
    are not going to make code changes to this function. If you want to check out
    the source code of the function, you can run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'You will need to make one change to the function''s configuration file. By
    default, functions require an authenticated request. You will change this to `anonymous`
    for this demo. Make the change using the `vi` command by executing the following
    command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Replace `authLevel` on *line 5* with `anonymous`. To make that change, press
    *I* to go into insert mode, then remove `function` and replace it with `anonymous`:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Modifying the configuration file by changing the authLevelfunction to anonymous](img/B17338_14_14.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.14: Changing the authLevel function to anonymous'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Hit *Esc*, type `:wq!`, and then hit *Enter* to save and quit `vi`.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: You changed the authentication requirement for your function to `anonymous`.
    This will make the demo easier to execute. If you plan to release functions to
    production, you need to carefully consider this setting, since this controls who
    has access to your function.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You are now ready to deploy your function to AKS. You can deploy the function
    using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will cause the functions runtime to do a couple of steps. First, it will
    build a container image, then it will push that image to the registry, and finally,
    it will deploy the function to Kubernetes:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Using the func kubernetes deploy command for deploying the function to AKS](img/B17338_14_15.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.15: Deploying the function to AKS'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: You can click the Invoke url URL that is shown to get access to your function.
    Before doing so, however, let's explore what was created on the cluster.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'To create the function, a regular deployment on top of Kubernetes was used.
    To check the deployment, you can run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will show you the deployment, as in *Figure 14.16*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Checking the deployment](img/B17338_14_16.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.16: Deployment details'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'This process also created a service on top of your Kubernetes cluster. You
    can get the public IP of the service that was deployed and connect to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: This will show you the service and its public IP, as shown in *Figure 14.17*.
    Notice how this public IP is the same as the one shown in the output of *Step
    4*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Getting the service’s public IP](img/B17338_14_17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.17: Getting the service''s public IP'
  prefs: []
  type: TYPE_NORMAL
- en: 'Open a web browser and browse to `http://<external-ip>/api/python-http?name=handsonaks`.
    You should see a web page showing you Hello, handsonaks. This HTTP triggered function
    executed successfully. This is shown in *Figure 14.18*:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Navigating to the external IP will return the HTTP function output](img/B17338_14_18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.18: Output of the HTTP triggered function'
  prefs: []
  type: TYPE_NORMAL
- en: 'You have now created a function with an HTTP trigger. Using an HTTP-triggered
    function is useful in scenarios where you are providing an HTTP API with unpredictable
    load patterns. Let''s clean up this deployment before moving on to the next section:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: In this section, you created a sample function using an HTTP trigger. Let's
    take that one step further and integrate a new function with storage queues and
    set up the KEDA autoscaler in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a queue-triggered function
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the previous section, you created a sample HTTP function. In this section,
    you'll build another sample using a queue-triggered function. Queues are often
    used to pass messages between different components of an application. A function
    can be triggered based on messages in a queue to then perform additional processing
    on these messages.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, you'll create a function that is integrated with Azure storage
    queues to consume events. You will also configure KEDA to allow scaling to/from
    zero pods in the case of low traffic.
  prefs: []
  type: TYPE_NORMAL
- en: Let's start by creating a queue in Azure.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a queue
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, you will create a new storage account and a new queue in that
    storage account. You will connect functions to that queue in the next section,
    *Creating a queue-triggered function*.
  prefs: []
  type: TYPE_NORMAL
- en: To begin, create a new storage account. Search for `storage accounts` in the
    Azure search bar and select Storage accounts:![Navigating to the storage account
    services through the Azure portal](img/B17338_14_19.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 14.19: Navigating to Storage accounts service through the Azure portal'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Click the + New button at the top to create a new storage account. Provide the
    details to create the storage account. The storage account name has to be globally
    unique, so consider adding your initials. It is recommended to create the storage
    account in the same region as your AKS cluster. Finally, to save on costs, you
    are recommended to downgrade the replication setting to Locally-redundant storage
    (LRS) as shown in *Figure 14.20*:![Providing resource group and storage account
    details to create the storage account ](img/B17338_14_20.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 14.20: Providing the details to create the storage account'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once you're ready, click the Review + create button at the bottom. On the resulting
    screen, select Create to start the creation process.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: It will take about a minute to create the storage account. Once it is created,
    open the account by clicking on the Go to resource button. In the Storage account
    pane, select Access keys in the left-hand navigation, click on Show keys, and
    copy the primary connection string, as shown in *Figure 14.21*. Note down this
    string for now:![Navigating to Access keys and copying the Connection string](img/B17338_14_21.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Figure 14.21: Copying the primary connection string'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: For production use cases, it is not recommended to connect to Azure Storage
    using the access key. Any user with that access key has full access to the storage
    account and can read and delete all files on it. It is recommended to either generate
    a **shared access signatures** (**SAS**) token to connect to storage or to use
    Azure AD-integrated security. To learn more about SAS token authentication to
    storage, refer to https://docs.microsoft.com/rest/api/storageservices/delegate-access-with-shared-access-signature.
    To learn more about Azure AD authentication to Azure Storage, please refer to
    https://docs.microsoft.com/rest/api/storageservices/authorize-with-azure-active-directory.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The final step is to create our queue in the storage account. Look for `queue`
    in the left-hand navigation, click the + Queue button to add a queue, and provide
    it with a name. To follow along with this demo, use `function` as the queue name:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Creating a Queue service](img/B17338_14_22.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.22: Creating a new queue'
  prefs: []
  type: TYPE_NORMAL
- en: You have now created a storage account in Azure and have its connection string.
    You created a queue in this storage account. In the next section, you will create
    a function that will consume messages from the queue.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a queue-triggered function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous section, you created a queue in Azure. In this section, you
    will create a new function that will monitor this queue and remove messages from
    the queue. You will need to configure this function with the connection string
    to this queue:'
  prefs: []
  type: TYPE_NORMAL
- en: 'From within the VM, begin by creating a new directory and navigating to it:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Now we can create the function. We will start with the initialization:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will ask you two questions now. For the runtime, select node (option 2),
    and for the language, select JavaScript (option 1). This should result in the
    output shown in *Figure 14.23*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Creating a new javaScript function of type javaScript](img/B17338_14_23.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[PRE26]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will ask you for a trigger. Select Azure Queue Storage trigger (option
    10). Give the name `js-queue` to the new function. This should result in the output
    shown in *Figure 14.24*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Creating a new function using the Azure Queue Storage trigger](img/B17338_14_24.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.24: Creating a queue-triggered function'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You will now need to make a couple of configuration changes. You need to provide
    the function you created the connection string on to Azure Storage and provide
    the queue name. First, open the `local.settings.json` file to configure the connection
    strings for storage:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To make the changes, follow these instructions:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Hit *I* to go into insert mode.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Replace the connection string for `AzureWebJobsStorage` with the connection
    string you copied earlier. Add a comma to the end of this line.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Add a new line and then add the following text on that line:'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'The result should look like *Figure 14.25*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Editing the Queue connection string in the local.settings.json file ](img/B17338_14_25.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.25: Editing the local.settings.json file'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Save and close the file by hitting the *Esc* key, type `:wq!`, and then press
    *Enter*.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The next file you need to edit is the function configuration itself. Here,
    you will refer to the connection string from earlier, and provide the queue name
    we chose in the *Creating a queue* section. To do that, use the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To make the changes, follow these instructions:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Hit *I* to go into insert mode.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Change the queue name to the name of the queue you created (`function`).
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: Next, add `QueueConnString` to the `connection` field.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Your configuration should now look like *Figure 14.26*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Editing the js-queue/function.json file](img/B17338_14_26.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.26: Editing the js-queue/function.json file'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Save and close the file by hitting the *Esc* key, type `:wq!`, and then press *Enter*.
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You are now ready to publish your function to Kubernetes. You will start by
    setting up KEDA on your Kubernetes cluster:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should return an output similar to *Figure 14.27*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Setting up KEDA on your Kubernetes cluster](img/B17338_14_27.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[PRE31]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This should return an output similar to *Figure 14.28*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Ensuring that the KEDA pod is running in the keda namespace](img/B17338_14_28.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.28: Verifying the KEDA installation succeeded'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'You can now deploy the function to Kubernetes. You will configure KEDA to look
    at the number of queue messages every 5 seconds (`polling-interval=5`) to have
    a maximum of 15 replicas (`max-replicas=15`), and to wait 15 seconds before removing
    pods (`cooldown-period=15`). To deploy and configure KEDA in this way, use the
    following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will return an output similar to *Figure 14.29*:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Deploying the queue-triggered function](img/B17338_14_29.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: '[PRE33]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'This will show you all the resources that were deployed. As you can see in
    *Figure 14.30*, this setup created a deployment, ReplicaSet, and an HPA. In the
    HPA, you should see that there are no replicas currently running:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Verifying that the setup created a deployment, a ReplicaSet, and an HPA](img/B17338_14_30.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.30: Verifying the objects created by the setup'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Now you will create a message in the queue to trigger KEDA and create a pod.
    To see the scaling event, run the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'To create a message in the queue, we are going to use the Azure portal. To
    create a new message, open the queue in the storage that you created earlier.
    Click on the + Add message button at the top of your screen, create a test message,
    and click on OK. This is shown in *Figure 14.31*:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Adding a message to the queue](img/B17338_14_31.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.31: Adding a message to the queue'
  prefs: []
  type: TYPE_NORMAL
- en: 'After creating this message, have a look at the output of the previous command
    you issued. It might take a couple of seconds, but soon enough, your HPA should
    scale to one replica. Afterward, it should also scale back down to zero replicas:'
  prefs: []
  type: TYPE_NORMAL
- en: '![KEDA scaling from 0 to 1 and back to 0 replicas](img/B17338_14_32.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.32: KEDA scaling from 0 to 1 and back to 0 replicas'
  prefs: []
  type: TYPE_NORMAL
- en: This has shown you that KEDA enabled the Kubernetes HPA to scale from zero to
    one pod when there are messages in the queue, and also from one to zero pods when
    those messages are processed.
  prefs: []
  type: TYPE_NORMAL
- en: You have now created a function that is triggered by messages being added to
    a queue. You were able to verify that KEDA scaled the pods from 0 to 1 when you
    created a message in the queue, and back down to 0 when there were no messages
    left. In the next section, you will execute a scale test, and you will create
    multiple messages in the queue and see how the functions react.
  prefs: []
  type: TYPE_NORMAL
- en: Scale testing functions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the previous section, you saw how functions reacted when there was a single
    message in the queue. In this example, you are going to send 1,000 messages into
    the queue and see how KEDA will first scale out the function, and then scale back
    in, and eventually scale back down to zero:'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the current Cloud Shell, watch the HPA using the following command:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: To start pushing the messages, you are going to open a new Cloud Shell session.
    To open a new session, select the Open new session button in Cloud Shell:![Opening
    a new Cloud Shell instance](img/B17338_14_33.jpg)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once that is installed, you will need to provide this script with your storage
    account connection string. To do this, open the file using:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Edit the storage connection string on *line 8* to your connection string:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Pasting in your connection string for your storage account on line 8](img/B17338_14_34.jpg)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 14.34: Pasting in your connection string for your storage account on
    line 8'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once you have pasted in your connection string, you can execute the Python
    script and send 1,000 messages to your queue:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: While the messages are being sent, switch back to the previous Cloud Shell instance
    and watch KEDA scale from 0 to 1, and then watch the HPA scale to the number of
    replicas. The HPA uses metrics provided by KEDA to make scaling decisions. Kubernetes,
    by default, doesn't know about the number of messages in an Azure storage queue
    that KEDA provides to the HPA.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_IND
  - PREF_H4
  type: TYPE_NORMAL
- en: Depending on how quickly KEDA in your cluster scales up the application, your
    deployment might not scale to the 15 replicas that are shown in *Figure 14.29*.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Once the queue is empty, KEDA will scale back down to zero replicas:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![KEDA will scale from 0 to 1, and the HPA will scale to 15 pods . When the
    load has decreased, KEDA scaled down to 0 again](img/B17338_14_35.jpg)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14.35: KEDA will scale from 0 to 1, and the HPA will scale to 15 pods'
  prefs: []
  type: TYPE_NORMAL
- en: As you can see in the output of this command, the deployment was scaled first
    from zero to one replica, and then gradually got scaled out to a maximum of 15
    replicas. When there were no more messages in the queue, the deployment was scaled
    down again to zero replicas.
  prefs: []
  type: TYPE_NORMAL
- en: 'This concludes the examples of running serverless functions on top of Kubernetes.
    Let''s make sure to clean up the objects that were created. Run the following
    command from within the VM you created (the final step will delete this VM; if
    you want to keep the VM, don''t run the final step):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: In this section, you ran a function that was triggered by messages in a storage
    queue on top of Kubernetes. You used a component called KEDA to achieve scaling
    based on the number of queue messages. You saw how KEDA can scale from 0 to 1
    and back down to 0\. You also saw how the HPA can use metrics provided by KEDA
    to scale out a deployment.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this chapter, you deployed serverless functions on top of your Kubernetes
    cluster. To achieve this, you first created a VM and an ACR.
  prefs: []
  type: TYPE_NORMAL
- en: You started the functions deployments by deploying a function that used an HTTP
    trigger. The Azure Functions core tools were used to create that function and
    to deploy it to Kubernetes.
  prefs: []
  type: TYPE_NORMAL
- en: Afterward, you installed an additional component on your Kubernetes cluster
    called KEDA. KEDA allows serverless scaling in Kubernetes. It allows deployments
    to and from zero pods, and it also provides additional metrics to the HPA. You
    used a function that was triggered on messages in an Azure storage queue.
  prefs: []
  type: TYPE_NORMAL
- en: In the next – and final – chapter of this book, you'll learn how to integrate
    containers and Kubernetes in a **continuous integration and continuous delivery**
    (**CI/CD**) pipeline using GitHub Actions.
  prefs: []
  type: TYPE_NORMAL
