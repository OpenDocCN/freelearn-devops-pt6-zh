- en: '1'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '1'
- en: Kubernetes Fundamentals
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 基础
- en: Welcome to *The Kubernetes Bible*, and we are happy to accompany you on your
    journey with Kubernetes. If you are working in the software development industry,
    you have probably heard about Kubernetes. This is normal because the popularity
    of Kubernetes has grown a lot in recent years.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 欢迎来到 *Kubernetes 圣经*，我们很高兴陪伴你一起走上 Kubernetes 的学习之旅。如果你从事软件开发行业，你可能听说过 Kubernetes。这是很正常的，因为
    Kubernetes 的受欢迎程度在近几年大幅上升。
- en: 'Built by Google, Kubernetes is the leading container orchestrator solution
    in terms of popularity and adoption: it’s the tool you need if you are looking
    for a solution to manage containerized applications in production at scale, whether
    it’s on-premises or on a public cloud. Be focused on the word. Deploying and managing
    containers at scale is extremely difficult because, by default, container engines
    such as Docker do not provide any way on their own to maintain the availability
    and scalability of containers at scale.'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 由 Google 构建的 Kubernetes 是目前最流行且被广泛采用的容器编排解决方案：如果你在寻找一个解决方案来管理生产环境中大规模的容器化应用，无论是在本地还是公共云中，它都是你所需要的工具。请专注于这个词。大规模部署和管理容器是极其困难的，因为默认情况下，像
    Docker 这样的容器引擎本身并不提供任何方法来保持容器的大规模可用性和可扩展性。
- en: Kubernetes first emerged as a Google project, and Google has put a lot of effort
    into building a solution to deploy a huge number of containers on their massively
    distributed infrastructure. By adopting Kubernetes as part of your stack, you’ll
    get an open source platform that was built by one of the biggest companies on
    the internet, with the most critical needs in terms of stability.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 最初作为 Google 的一个项目出现，Google 在构建一个能够在其大规模分布式基础设施上部署大量容器的解决方案上投入了大量的精力。通过将
    Kubernetes 作为你技术栈的一部分，你将获得一个由互联网最大公司之一构建的开源平台，该公司在稳定性方面有着最为严苛的需求。
- en: Although Kubernetes can be used with a lot of different container runtimes,
    this book is going to focus on the Kubernetes and containers (Docker and Podman)
    combination.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Kubernetes 可以与许多不同的容器运行时一起使用，本书将专注于 Kubernetes 与容器（Docker 和 Podman）的组合。
- en: Perhaps you are already using Docker on a daily basis, but the world of container
    orchestration might be completely unknown to you. It is even possible that you
    do not even see the benefits of using such technology because everything looks
    fine to you with just raw Docker. That’s why, in this first chapter, we’re not
    going to look at Kubernetes in detail. Instead, we will focus on explaining what
    Kubernetes is and how it can help you manage your application containers in production.
    It will be easier for you to learn a new technology if you understand why it was
    built.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 也许你已经在日常工作中使用 Docker，但容器编排的世界对你来说可能完全陌生。甚至可能你看不到使用这种技术的好处，因为对于你来说，仅仅使用原生 Docker
    就已经足够了。这就是为什么在本章中，我们不会详细讲解 Kubernetes。相反，我们将重点解释 Kubernetes 是什么，以及它如何帮助你管理生产环境中的应用容器。如果你了解它为什么被构建出来，那么学习这项新技术会更容易。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将涵盖以下主要内容：
- en: Understanding monoliths and microservices
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解单体应用与微服务
- en: Understanding containers
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解容器
- en: How can Kubernetes help you to manage containers?
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kubernetes 如何帮助你管理容器？
- en: Understanding the history of Kubernetes
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 理解 Kubernetes 的历史
- en: Exploring the problems that Kubernetes solves
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 探索 Kubernetes 解决的问题
- en: You can download the latest code samples for this chapter from the official
    GitHub repository at [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter01](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter01)
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从官方 GitHub 仓库下载本章的最新代码示例，地址是 [https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter01](https://github.com/PacktPublishing/The-Kubernetes-Bible-Second-Edition/tree/main/Chapter01)
- en: Understanding monoliths and microservices
  id: totrans-14
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 理解单体应用与微服务
- en: Let’s put Kubernetes and Docker to one side for the moment, and instead, let’s
    talk a little bit about how the internet and software development evolved together
    over the past 20 years. This will help you to gain a better understanding of where
    Kubernetes sits and the problems it solves.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们暂时把 Kubernetes 和 Docker 放到一边，换个角度来谈一谈过去 20 年里互联网和软件开发是如何共同发展的。这将帮助你更好地理解
    Kubernetes 的定位及其所解决的问题。
- en: Understanding the growth of the internet since the late 1990s
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解自 1990 年代末以来互联网的增长
- en: Since the late 1990s, the popularity of the internet has grown rapidly. Back
    in the 1990s, and even in the early 2000s, the internet was only used by a few
    hundred thousand people in the world. Today, almost 2 billion people are using
    the internet for email, web browsing, video games, and more.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 自1990年代末以来，互联网的普及迅速增长。在1990年代，甚至是2000年代初期，全球只有几十万人在使用互联网。如今，几乎有20亿人使用互联网进行电子邮件、网页浏览、视频游戏等活动。
- en: There are now a lot of people on the internet, and we’re using it for tons of
    different needs, and these needs are addressed by dozens of applications deployed
    on dozens of devices.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 现在互联网用户数量庞大，我们用它来满足各种不同的需求，而这些需求由部署在不同设备上的数十个应用程序来解决。
- en: 'Additionally, the number of connected devices has increased, as each person
    can now have several devices of a different nature connected to the internet:
    laptops, computers, smartphones, TVs, tablets, and more.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，联网设备的数量也在增加，因为现在每个人可以有多种不同类型的设备连接到互联网：笔记本电脑、台式电脑、智能手机、电视、平板电脑等。
- en: Today, we can use the internet to shop, to work, to entertain, to read, or to
    do whatever. It has entered almost every part of our society and has led to a
    profound paradigm shift in the last 20 years. All of this has given the utmost
    importance to software development.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如今，我们可以使用互联网购物、工作、娱乐、阅读或做任何事情。互联网几乎渗透到我们社会的每个角落，并且在过去20年里引发了深刻的范式转变。所有这些都使得软件开发变得至关重要。
- en: Understanding the need for more frequent software releases
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解更频繁发布软件版本的需求
- en: To cope with this ever-increasing number of users who are always demanding more
    in terms of features, the software development industry had to evolve in order
    to make new software releases faster and more frequent.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这不断增长的用户需求，这些用户总是希望软件能提供更多的功能，软件开发行业不得不进化，以便更快、更频繁地发布新版本。
- en: Indeed, back in the 1990s, you could build an application, deploy it to production,
    and simply update it once or twice a year. Today, companies must be able to update
    their software in production, sometimes several times a day, whether to deploy
    a new feature, integrate with a social media platform, support the resolution
    of the latest fashionable smartphone, or even release a patch to a security breach
    identified the day before. Everything is far more complex today, and you must
    go faster than before.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 事实上，回到1990年代，你可以构建一个应用程序，将其部署到生产环境中，并且每年更新一次或两次。今天，企业必须能够在生产环境中更新软件，有时甚至是一天好几次，无论是部署新功能、与社交媒体平台集成、支持最新流行智能手机的分辨率，还是发布一个前一天发现的安全漏洞补丁。今天的一切都变得更加复杂，你必须比以前更快。
- en: We constantly need to update our software, and in the end, the survival of many
    companies directly depends on how often they can offer releases to their users.
    But how do we accelerate software development life cycles so that we can deliver
    new versions of our software to our users more frequently?
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不断需要更新软件，最终，许多公司的生存直接取决于它们能多频繁地向用户发布新版本。但我们如何加速软件开发生命周期，以便能更频繁地向用户交付新版本呢？
- en: IT departments of companies had to evolve, both in an organizational sense and
    a technical sense. Organizationally, they changed the way they managed projects
    and teams in order to shift to agile methodologies, and technically, technologies
    such as cloud computing platforms, containers, and virtualization were adopted
    widely and helped a lot to align technical agility with organizational agility.
    All of this is to ensure more frequent software releases! So, let’s focus on this
    evolution next.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 企业的IT部门必须进行转型，无论是从组织层面还是技术层面。在组织上，他们改变了管理项目和团队的方式，以便转向敏捷方法；在技术上，云计算平台、容器技术和虚拟化等技术被广泛采用，并在很大程度上帮助将技术敏捷性与组织敏捷性对齐。所有这些都是为了确保更频繁的软件发布！接下来，我们将重点讨论这一演变。
- en: Understanding the organizational shift to agile methodologies
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解组织向敏捷方法论转型
- en: From a purely organizational point of view, agile methodologies such as Scrum,
    Kanban, and DevOps became the standard way to organize IT teams.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 从纯粹的组织角度来看，敏捷方法论如Scrum、Kanban和DevOps成为组织IT团队的标准方式。
- en: Typical IT departments that do not apply agile methodologies are often made
    of three different teams, each of them having a single responsibility in the development
    and release process life cycle.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 典型的IT部门如果不采用敏捷方法，通常由三个不同的团队组成，每个团队在开发和发布生命周期中负责单一的任务。
- en: Rest assured, even though we are currently discussing agile methodologies and
    the history of the internet, this book is really about Kubernetes! We just need
    to explain some of the problems that we have faced before introducing Kubernetes
    for real!
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 请放心，尽管我们目前讨论的是敏捷方法论和互联网的历史，但这本书的主题实际上是Kubernetes！我们只是需要解释一些在正式引入Kubernetes之前遇到的问题！
- en: Before the adoption of agile methodologies, development and operations often
    worked in separate silos. This could lead to inefficiency and communication gaps.
    Agile methodologies helped bridge these gaps and foster collaboration. The three
    isolated teams are shown below.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在采用敏捷方法论之前，开发和运维通常在不同的孤岛中工作。这可能导致低效和沟通障碍。敏捷方法论帮助弥补了这些沟通空白，促进了合作。以下是三个孤立的团队。
- en: '**The business team**: They’re like the voice of the customer. Their job is
    to explain what features are needed in the app to meet user needs. They translate
    business goals into clear instructions for the developers.'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**业务团队**：他们就像是客户的声音。他们的工作是解释应用程序中需要哪些功能，以满足用户需求。他们将业务目标转化为开发人员的明确指令。'
- en: '**The development team**: These are the engineers who bring the app to life.
    They translate the business team’s feature requests into code, building the functionalities
    and features users will interact with. Clear communication from the business team
    is crucial. If the instructions aren’t well defined, it can be like a game of
    telephone – misunderstandings lead to delays and rework.'
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开发团队**：这些是将应用程序付诸实践的工程师。他们将业务团队的功能需求转化为代码，构建用户将交互的功能和特性。来自业务团队的清晰沟通至关重要。如果指令定义不清，就像打电话游戏一样——误解会导致延迟和返工。'
- en: '**The operation team**: They’re the keepers of the servers. Their main focus
    is keeping the app running smoothly. New features can be disruptive because they
    require updates, which can be risky. In the past, they weren’t always aware of
    what new features were coming because they weren’t involved in the planning.'
  id: totrans-33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**运维团队**：他们是服务器的守护者。他们的主要工作是保持应用程序的平稳运行。新功能可能会带来干扰，因为它们需要更新，这可能具有风险。过去，他们并不总是知道即将推出的新功能，因为他们未参与计划。'
- en: 'These are what we call silos, as illustrated in *Figure 1.1*:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 这些就是我们所说的孤岛，如*图1.1*所示：
- en: '![](img/B22019_01_01.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_01_01.png)'
- en: 'Figure 1.1: Isolated teams in a typical IT department'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.1：典型IT部门中孤立的团队
- en: The roles are clearly defined, people from the different teams do not work together
    that much, and when something goes wrong, everyone loses time finding the right
    information from the right person.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 各角色分工明确，来自不同团队的人很少一起合作，当出现问题时，每个人都浪费时间寻找正确的信息来源。
- en: 'This kind of siloed organization has led to major issues:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 这种孤立的组织方式已经导致了许多重大问题：
- en: A significantly longer development time
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 显著更长的开发时间
- en: Greater risk in the deployment of a release that might not work at all in production
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 部署的发布版本可能完全无法在生产环境中运行的更大风险
- en: And that’s essentially what agile methodologies and DevOps fixed. The change
    agile methodologies made was to make people work together by creating multidisciplinary
    teams.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是敏捷方法论和DevOps所解决的问题。敏捷方法论带来的改变是通过创建跨职能团队，让人们一起工作。
- en: DevOps is a collaborative culture and set of practices that aims to bridge the
    gap between development (Dev) and operations (Ops) teams. DevOps promotes collaboration
    and automation throughout the software lifecycle, from development and testing
    to deployment and maintenance.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: DevOps是一种协作文化和一套实践，旨在弥合开发（Dev）和运维（Ops）团队之间的鸿沟。DevOps推动了整个软件生命周期中的协作和自动化，从开发、测试到部署和维护。
- en: An agile team consists of a product owner describing concrete features by writing
    them as user stories that are readable by the developers who are working in the
    same team as them. Developers should have visibility of the production environment
    and the ability to deploy on top of it, preferably using a **continuous integration
    and continuous deployment** (**CI/CD**) approach. Testers should also be part
    of agile teams in order to write tests.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一个敏捷团队由产品负责人组成，他们通过将功能写成用户故事的方式，向开发人员描述具体特性，开发人员在同一个团队中工作。开发人员应当能看到生产环境，并能够在其上进行部署，最好是采用**持续集成和持续部署**（**CI/CD**）方法。测试人员也应该是敏捷团队的一部分，以便编写测试。
- en: With the collaborative approach, the teams will get better and clearer visibility
    of the full picture, as illustrated in the following diagram.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 通过协作方式，团队将更好地理解整体情况，如下图所示。
- en: '![](img/B22019_01_02.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_01_02.png)'
- en: 'Figure 1.2: Team collaboration breaks silos'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1.2: 团队协作打破了隔阂'
- en: Simply understand that, by adopting agile methodologies and DevOps, these silos
    were broken and multidisciplinary teams capable of formalizing a need, implementing
    it, testing it, releasing it, and maintaining it in the production environment
    were created. *Table 1.1* presents a shift from traditional development to agile
    and DevOps methodology.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 只需要理解的是，通过采用敏捷方法和 DevOps，这些隔阂被打破了，能够将需求正式化、实施、测试、发布，并在生产环境中维护的跨职能团队得以建立。*表 1.1*
    展示了从传统开发到敏捷和 DevOps 方法的转变。
- en: '| **Feature** | **Traditional Development** | **Agile & DevOps** |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| **特性** | **传统开发** | **敏捷 & DevOps** |'
- en: '| Team Structure | Siloed departments (Development, Operations) | Cross-functional,
    multi-disciplinary teams |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 团队结构 | 隔离的部门（开发、运维） | 跨职能、多学科的团队 |'
- en: '| Work Style | Isolated workflows, limited communication | Collaborative, iterative
    development cycles |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 工作方式 | 隔离的工作流程，有限的沟通 | 协作的，迭代的开发周期 |'
- en: '| Ownership | Development hands off to Operations for deployment and maintenance
    | “You Build It, You Run It” - Teams own the entire lifecycle |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 拥有权 | 开发交给运维进行部署和维护 | “你构建它，你运行它” - 团队负责整个生命周期 |'
- en: '| Focus | Features and functionality | Business value, continuous improvement
    |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 关注点 | 特性和功能 | 商业价值，持续改进 |'
- en: '| Release Cycle | Long release cycles, infrequent deployments | Short sprints,
    frequent releases with feedback loops |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 发布周期 | 长周期发布，部署不频繁 | 短冲刺，频繁发布并带有反馈循环 |'
- en: '| Testing | Separate testing phase after development | Integrated testing throughout
    the development cycle |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 测试 | 开发后单独的测试阶段 | 在整个开发周期中进行集成测试 |'
- en: '| Infrastructure | Static, manually managed infrastructure | Automated infrastructure
    provisioning and management (DevOps) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 基础设施 | 静态、手动管理的基础设施 | 自动化的基础设施配置和管理（DevOps） |'
- en: 'Table 1.1: DevOps vs traditional development – a shift in collaboration'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1.1: DevOps 与传统开发 – 协作方式的转变'
- en: So, we’ve covered the organizational transition brought about by the adoption
    of agile methodologies. Now, let’s discuss the technical evolution that we’ve
    gone through over the past several years.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 所以，我们已经讨论了采用敏捷方法所带来的组织转型。现在，让我们来讨论过去几年我们经历的技术演变。
- en: Understanding the shift from on-premises to the cloud
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解从本地托管到云托管的转变
- en: Having agile teams is very nice, but agility must also be applied to how software
    is built and hosted.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 拥有敏捷团队非常好，但敏捷性也必须应用到软件的构建和托管方式上。
- en: 'With the aim to always achieve faster and more recurrent releases, agile software
    development teams had to revise two important aspects of software development
    and release:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 为了始终实现更快速和更频繁的发布，敏捷软件开发团队必须重新审视软件开发和发布的两个重要方面：
- en: Hosting
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 托管
- en: Software architecture
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 软件架构
- en: Today, apps are not just for a few hundred users but potentially for millions
    of users concurrently. Having more users on the internet also means having more
    computing power capable of handling them. And, indeed, hosting an application
    became a very big challenge.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，应用程序不仅仅是为几百个用户提供服务，而是可能为数百万个用户同时使用。更多的互联网用户意味着需要更多的计算能力来处理这些用户。的确，托管应用程序已成为一个非常大的挑战。
- en: 'In the early days of web hosting, businesses primarily relied on two main approaches
    to housing their applications: one of these approaches is on-premises hosting.
    This method involved physically owning and managing the servers that ran their
    applications. There are two main ways to achieve on-premises hosting:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在早期的网页托管时代，企业主要依赖两种主要方法来托管其应用程序：其中一种方法是本地托管。这种方式涉及到物理拥有和管理运行其应用程序的服务器。实现本地托管有两种主要方式：
- en: '**Dedicated Servers**: Renting physical servers from established data center
    providers: This involved leasing dedicated server hardware from a hosting company.
    The hosting provider would manage the physical infrastructure (power, cooling,
    security) but the responsibility for server configuration, software installation,
    and ongoing maintenance fell to the business. This offered greater control and
    customization compared to shared hosting, but still required significant in-house
    technical expertise.'
  id: totrans-65
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**专用服务器**：从已有的数据中心供应商租用物理服务器：这涉及到从托管公司租用专用服务器硬件。托管服务提供商管理物理基础设施（电力、冷却、安全），但服务器配置、软件安装和持续维护的责任则由业务方承担。这种方式相比共享托管提供了更大的控制和定制化，但仍然需要大量的内部技术专长。'
- en: '**Building Your Own Data Center**: Constructing and maintaining a private data
    center: This option involved a massive investment by the company to build and
    maintain its own physical data center facility. This included purchasing server
    hardware, networking equipment, and storage solutions, and implementing robust
    power, cooling, and security measures. While offering the highest level of control
    and security, this approach was very expensive and resource-intensive and was
    typically only undertaken by large corporations with significant IT resources.'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**建设您自己的数据中心**：建设和维护私有数据中心：此选项涉及公司大量投资以建设和维护其自己的物理数据中心设施。这包括购买服务器硬件、网络设备和存储解决方案，并实施强大的电源、冷却和安全措施。尽管提供了最高级别的控制和安全性，但这种方法非常昂贵且资源密集，通常只由具有重要IT资源的大公司才能承担。'
- en: Also note that on-premises hosting also encompasses managing the operating system,
    security patches, backups, and disaster recovery plans for the servers. Companies
    often needed a dedicated IT staff to manage and maintain their on-premises infrastructure,
    adding to the overall cost.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，本地托管还涵盖了操作系统的管理、安全补丁、备份和服务器灾难恢复计划。公司通常需要专门的IT人员来管理和维护其本地基础设施，从而增加了总体成本。
- en: When your user base grows, you need to get more powerful machines to handle
    the load. The solution is to purchase a more powerful server and install your
    app on it from the start or to order and rack new hardware if you manage your
    data center. This is not very flexible. Today, a lot of companies are still using
    an on-premises solution, and often, it’s not very flexible.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 当您的用户基础增长时，您需要获取更强大的机器来处理负载。解决方案是购买一台更强大的服务器，并从一开始就在其上安装您的应用程序，或者如果您管理您的数据中心，则是订购和安装新的硬件。这不是很灵活。今天，许多公司仍在使用本地解决方案，通常情况下，这种方案不是很灵活。
- en: The game-changer was the adoption of the other approach, which is the public
    cloud, which is the opposite of on-premises. The idea behind cloud computing is
    that big companies such as Amazon, Google, and Microsoft, which own a lot of datacenters,
    decided to build virtualization on top of their massive infrastructure to ensure
    the creation and management of virtual machines was accessible by APIs. In other
    words, you can get virtual machines with just a few clicks or just a few commands.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 改变游戏规则的是采用另一种方法，即公共云，这与本地不同。云计算的理念是，像亚马逊、谷歌和微软这样的大公司，拥有大量数据中心，决定在其庞大的基础设施上构建虚拟化，以确保通过API访问虚拟机的创建和管理。换句话说，您只需点击几下或输入几个命令就可以获得虚拟机。
- en: The following table provides high-level information about why cloud computing
    is good for organizations.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 下表提供了云计算对组织有益的高级信息。
- en: '| **Feature** | **On-Premises** | **Cloud** |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| **特性** | **本地** | **云** |'
- en: '| Scalability | Limited – requires purchasing new hardware when scaling up
    | Highly scalable – easy to add or remove resources on demand |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 可扩展性 | 有限 – 扩展时需要购买新硬件 | 高度可扩展 – 可按需增加或减少资源 |'
- en: '| Flexibility | Inflexible – changes require physical hardware adjustments
    | Highly flexible – resources can be provisioned and de-provisioned quickly |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 灵活性 | 不灵活 – 变更需要物理硬件调整 | 高度灵活 – 资源可以快速配置和去配置 |'
- en: '| Cost | High upfront cost for hardware, software licenses, and IT staff |
    Low upfront cost – pay-as-you-go model for resources used |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 成本 | 硬件、软件许可和IT人员的高前期成本 | 低前期成本 – 按使用资源付费模式 |'
- en: '| Maintenance | Requires dedicated IT staff for maintenance and updates | Minimal
    maintenance required – cloud provider manages infrastructure |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 维护 | 需要专门的IT人员进行维护和更新 | 最小维护要求 – 云服务提供商管理基础设施 |'
- en: '| Security | High level of control over security, but requires significant
    expertise | Robust security measures implemented by cloud providers |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 安全性 | 对安全性有很高的控制，但需要显著的专业知识 | 云服务提供商实施了强大的安全措施 |'
- en: '| Downtime | Recovery from hardware failures can be time-consuming | Cloud
    providers offer high availability and disaster recovery features |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 宕机时间 | 从硬件故障中恢复可能耗时 | 云提供商提供高可用性和灾难恢复功能 |'
- en: '| Location | Limited to the physical location of datacenter | Access from anywhere
    with an internet connection |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 位置 | 仅限于数据中心的物理位置 | 可通过任何具有互联网连接的地方访问 |'
- en: 'Table 1.2: Importance of cloud computing for organizations'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 表1.2：云计算对组织的重要性
- en: We will learn how cloud computing technology has helped organizations scale
    their IT infrastructure in the next section.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中学习云计算技术如何帮助组织扩展其IT基础设施。
- en: Understanding why the cloud is well suited for scalability
  id: totrans-81
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解为什么云计算非常适合可扩展性
- en: Today, virtually anyone can get hundreds or thousands of servers, in just a
    few clicks, in the form of virtual machines or instances created on physical infrastructure
    maintained by cloud providers such as **Amazon Web Services**, **Google Cloud
    Platform**, and **Microsoft Azure**. A lot of companies decided to migrate their
    workloads from on-premises to a cloud provider, and their adoption has been massive
    over the last few years.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 今天，几乎任何人都可以通过几次点击，获得数百或数千台服务器，这些服务器以虚拟机或实例的形式存在，由**亚马逊AWS**、**谷歌云平台**和**微软Azure**等云服务提供商在物理基础设施上维护。许多公司决定将其工作负载从本地迁移到云服务提供商，并且在过去几年中，这种采用率巨大。
- en: Thanks to that, now, computing power is one of the simplest things you can get.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 借助这一点，现在计算能力是你最容易获取的资源之一。
- en: Cloud computing providers are now typical hosting solutions that agile teams
    possess in their arsenal. The main reason for this is that the cloud is extremely
    well suited to modern development.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 云计算提供商如今是敏捷团队工具库中的典型托管解决方案。其主要原因是云计算非常适合现代开发。
- en: Virtual machine configurations, CPUs, OSes, network rules, and more are publicly
    displayed and fully configurable, so there are no secrets for your team in terms
    of what the production environment is made of. Because of the programmable nature
    of cloud providers, it is very easy to replicate a production environment in a
    development or testing environment, providing more flexibility to teams, and helping
    them face their challenges when developing software. That’s a useful advantage
    for an agile development team built around the DevOps philosophy that needs to
    manage the development, release, and maintenance of applications in production.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟机配置、CPU、操作系统、网络规则等都是公开显示并完全可配置的，因此你的团队在了解生产环境构成时没有任何秘密。由于云服务提供商的可编程特性，复制一个生产环境到开发或测试环境变得非常容易，这为团队提供了更多的灵活性，帮助他们在开发软件时应对挑战。这对于基于DevOps理念的敏捷开发团队来说，是一个非常有用的优势，他们需要管理生产环境中的应用开发、发布和维护。
- en: 'Cloud providers have provided many benefits, as follows:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 云服务提供商提供了许多好处，具体如下：
- en: Elasticity and scalability
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 弹性和可扩展性
- en: Helping to break up silos and enforcing agile methodologies
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有助于打破信息孤岛并推动敏捷方法论的实施
- en: Fitting well with agile methodologies and DevOps
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 与敏捷方法论和DevOps高度契合
- en: Low costs and flexible billing models
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 低成本和灵活的计费模型
- en: Ensuring there is no need to manage physical servers
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确保无需管理物理服务器
- en: Allowing virtual machines to be destroyed and recreated at will
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 允许虚拟机随时销毁并重新创建
- en: More flexible compared to renting a bare-metal machine monthly
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 相较于每月租用裸金属机器，更加灵活
- en: Due to these benefits, the cloud is a wonderful asset in the arsenal of an agile
    development team. Essentially, you can build and replicate a production environment
    over and over again without the hassle of managing the physical machine by yourself.
    The cloud enables you to scale your app based on the number of users using it
    or the computing resources they are consuming. You’ll make your app highly available
    and fault tolerant. The result is a better experience for your end users.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些好处，云计算成为了敏捷开发团队工具库中的宝贵资产。本质上，你可以不断构建和复制生产环境，而无需自己管理物理机器。云计算使你能够根据使用者数量或他们消耗的计算资源来扩展你的应用。你将使你的应用高可用并具备容错能力。结果是为终端用户提供更好的体验。
- en: '**IMPORTANT NOTE**'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: Please note that Kubernetes can run both on the cloud and on-premises. Kubernetes
    is very versatile, and you can even run it on a Raspberry Pi. Kubernetes and the
    public cloud are a good match, but you are not required or forced to run it on
    the cloud.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，Kubernetes可以在云端和本地运行。Kubernetes非常灵活，你甚至可以在Raspberry Pi上运行它。Kubernetes与公共云非常匹配，但你并不需要或被强制在云端运行它。
- en: Now that we have explained the changes the cloud produced, let’s move on to
    software architecture because, over the years, a few things have also changed
    there.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 既然我们已经解释了云计算带来的变化，让我们接着谈谈软件架构，因为多年来，这里也发生了一些变化。
- en: Exploring the monolithic architecture
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索单体架构
- en: In the past, applications were mostly composed of monoliths. A typical monolith
    application consists of a simple process, a single binary, or a single package,
    as shown in *Figure 1.3*.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 过去，应用程序大多由单体架构构成。一个典型的单体应用程序由一个简单的进程、一个二进制文件或一个包组成，如*图1.3*所示。
- en: 'This unique component is responsible for the entire implementation of the business
    logic, to which the software must respond. Monoliths are a good choice if you
    want to develop simple applications that might not necessarily be updated frequently
    in production. Why? Well, because monoliths have one major drawback. If your monolith
    becomes unstable or crashes for some reason, your entire application will become
    unavailable:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这个独立组件负责整个业务逻辑的实现，软件必须对其作出响应。如果你想开发一些不一定会频繁更新的简单应用程序，单体架构是一个不错的选择。为什么？因为单体架构有一个主要的缺点。如果你的单体架构因某些原因变得不稳定或崩溃，整个应用程序将无法使用：
- en: '![](img/B22019_01_03.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_01_03.png)'
- en: 'Figure 1.3: A monolith application consists of one big component that contains
    all your software'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.3：单体应用程序由一个大组件组成，包含了所有的软件
- en: 'The monolithic architecture can allow you to gain a lot of time during your
    development and that’s perhaps the only benefit you’ll find by choosing this architecture.
    However, it also has many disadvantages. Here are a few of them:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 单体架构可以在开发过程中为你节省大量时间，也许这是你选择这种架构时唯一能找到的好处。然而，它也有许多缺点。以下是其中的一些：
- en: A failed deployment to production can break your whole application.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个部署到生产环境的失败可能会破坏整个应用程序。
- en: Scaling activities become difficult to achieve; if you fail to scale, all your
    applications might become unavailable.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展活动变得难以实现；如果你无法扩展，所有的应用程序可能都会变得无法使用。
- en: A failure of any kind on a monolith can lead to a complete outage of your app.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 单体应用程序的任何类型的失败都可能导致整个应用程序的宕机。
- en: In the 2010s, these drawbacks started to cause real problems. With the increase
    in the frequency of deployments, it became necessary to think of a new architecture
    that would be capable of supporting frequent deployments and shorter update cycles,
    while reducing the risk or general unavailability of the application. This is
    why the microservices architecture was designed.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在2010年代，这些缺点开始带来实际问题。随着部署频率的增加，必须考虑一种新架构，能够支持频繁的部署和更短的更新周期，同时降低应用程序的风险或一般不可用性。这就是为什么微服务架构被设计出来的原因。
- en: Exploring the microservices architecture
  id: totrans-108
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 探索微服务架构
- en: The microservices architecture consists of developing your software application
    as a suite of independent micro-applications. Each of these applications, which
    is called a **microservice**, has its own versioning, life cycle, environment,
    and dependencies. Additionally, it can have its own deployment life cycle. Each
    of your microservices must only be responsible for a limited number of business
    rules, and all your microservices, when used together, make up the application.
    Think of a microservice as real full-featured software on its own, with its own
    life cycle and versioning process.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构是将软件应用程序作为一组独立的微应用程序进行开发。每个应用程序被称为**微服务**，它有自己的版本控制、生命周期、环境和依赖关系。此外，它还可以有自己的部署生命周期。每个微服务只能负责有限数量的业务规则，所有的微服务一起构成整个应用程序。可以将微服务视为独立的完整软件，具有自己的生命周期和版本控制过程。
- en: Since microservices are only supposed to hold a subset of all the features that
    the entire application has, they must be accessible in order to expose their functions.
    You must get data from a microservice, but you might also want to push data into
    it. You can make your microservice accessible through widely supported protocols
    such as HTTP or AMQP, and they need to be able to communicate with each other.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 由于微服务仅应承载整个应用程序的一部分功能，它们必须是可访问的，以便暴露其功能。你必须从一个微服务获取数据，但也可能希望向其推送数据。你可以通过广泛支持的协议（如HTTP或AMQP）使你的微服务可访问，并且它们需要能够相互通信。
- en: That’s why microservices are generally built as web services that expose their
    functionality through well-defined APIs. While HTTP (or HTTPS) REST APIs are a
    popular choice due to their simplicity and widespread adoption, other protocols,
    such as GraphQL, AMQP, and gRPC, are gaining traction and are used commonly.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么微服务通常作为通过明确定义的API暴露其功能的Web服务构建的原因。虽然HTTP（或HTTPS）REST API由于其简单性和广泛采用而成为流行的选择，但其他协议，如GraphQL、AMQP和gRPC，正在获得关注并被广泛使用。
- en: The key requirement is that a microservice provides a well-documented and discoverable
    API endpoint, regardless of the chosen protocol. This allows other microservices
    to seamlessly interact and exchange data.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 关键要求是微服务提供一个良好文档化且可发现的API端点，无论选择何种协议。这允许其他微服务无缝地进行交互并交换数据。
- en: 'This is something that greatly differs from the monolithic architecture:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 这是与单体架构大不相同的地方：
- en: '![](img/B22019_01_04.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_01_04.png)'
- en: 'Figure 1.4: A microservice architecture where different microservices communicate
    via the HTTP protocol'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.4：一个微服务架构，其中不同的微服务通过HTTP协议进行通信
- en: 'Another key aspect of the microservice architecture is that microservices need
    to be decoupled: if a microservice becomes unavailable or unstable, it must not
    affect the other microservices or the entire application’s stability. You must
    be able to provision, scale, start, update, or stop each microservice independently
    without affecting anything else. If your microservices need to work with a database
    engine, bear in mind that even the database must be decoupled. Each microservice
    should have its own database and so on. So, if the database of **microservice
    A** crashes, it won’t affect **microservice B**:'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务架构的另一个关键方面是微服务需要解耦：如果一个微服务变得不可用或不稳定，它必须不会影响其他微服务或整个应用程序的稳定性。你必须能够独立地部署、扩展、启动、更新或停止每个微服务，而不影响其他任何部分。如果你的微服务需要与数据库引擎一起工作，记住即使是数据库也必须解耦。每个微服务应该有自己的数据库，等等。所以，如果**微服务A**的数据库崩溃，它不会影响到**微服务B**：
- en: '![](img/B22019_01_05.png)'
  id: totrans-117
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_01_05.png)'
- en: 'Figure 1.5: A microservice architecture where different microservices communicate
    with each other and with a dedicated database server; this way, the microservices
    are isolated and have no common dependencies'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图1.5：一个微服务架构，其中不同的微服务相互通信并与专用的数据库服务器进行交互；通过这种方式，微服务是隔离的，没有共同的依赖关系
- en: The key rule is to decouple as much as possible so that your microservices are
    fully independent. Because they are meant to be independent, microservices can
    also have completely different technical environments and be implemented in different
    languages. You can have one microservice implemented in Go, another one in Java,
    and another one in PHP, and all together they form one application. In the context
    of a microservice architecture, this is not a problem. Because HTTP is a standard,
    they will be able to communicate with each other even if their underlying technologies
    are different.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 关键规则是尽可能地解耦，使你的微服务完全独立。因为微服务旨在独立运作，它们还可以拥有完全不同的技术环境，并且可以用不同的语言实现。你可以有一个用Go实现的微服务，一个用Java实现的微服务，另一个用PHP实现的微服务，它们共同构成一个应用程序。在微服务架构的背景下，这不是问题。因为HTTP是标准协议，它们即使底层技术不同，也能够互相通信。
- en: Microservices must be decoupled from other microservices, but they must also
    be decoupled from the operating system running them. Microservices should not
    operate at the host system level but at the upper level. You should be able to
    provision them, at will, on different machines without needing to rely on a strong
    dependency on the host system; that’s why microservice architectures and containers
    are a good combination.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务必须与其他微服务解耦，但它们也必须与运行它们的操作系统解耦。微服务不应该在主机系统级别操作，而应该在更高层次上操作。你应该能够根据需要将它们部署到不同的机器上，而无需依赖于主机系统的强依赖性；这就是为什么微服务架构和容器是一个很好的组合。
- en: If you need to release a new feature in production, you simply deploy the microservices
    that are impacted by the new feature version. The others can remain the same.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你需要在生产环境中发布新特性，你只需要部署受到新特性版本影响的微服务，其他的可以保持不变。
- en: 'As you can imagine, the microservice architecture has tremendous advantages
    in the context of modern application development:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可以想象的那样，微服务架构在现代应用开发中具有巨大的优势：
- en: It is easier to enforce recurring production deliveries with minimal impact
    on the stability of the whole application.
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它更容易执行周期性的生产交付，同时对整个应用的稳定性影响最小。
- en: You can only upgrade to a specific microservice each time, not the whole application.
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你每次只能升级特定的微服务，而不是整个应用程序。
- en: Scaling activities are smoother since you might only need to scale specific
    services.
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 扩展活动更加顺畅，因为你可能只需要扩展特定的服务。
- en: 'However, on the other hand, the microservice architecture has a couple of disadvantages
    too:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，从另一方面来看，微服务架构也有一些缺点：
- en: The architecture requires more planning and is hard to develop.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 该架构需要更多的规划，并且开发难度较大。
- en: There are problems in managing each microservice’s dependencies.
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 管理每个微服务的依赖关系存在问题。
- en: Microservice applications are considered hard to develop. This approach might
    be hard to understand, especially for junior developers. Dependency management
    can also become complex since all microservices can potentially have different
    dependencies.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 微服务应用被认为难以开发。这种方法可能很难理解，尤其是对于初级开发人员而言。依赖关系管理也可能变得复杂，因为所有微服务可能具有不同的依赖关系。
- en: Choosing between monolithic and microservices architectures
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在单体架构和微服务架构之间做出选择
- en: 'Building a successful software application requires careful planning, and one
    of the key decisions you’ll face is which architecture to use. Two main approaches
    dominate the scene: monoliths and microservices:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 构建一个成功的软件应用需要谨慎的规划，而你面临的关键决策之一就是选择使用哪种架构。两种主要的架构方法主导了这一领域：单体架构和微服务架构：
- en: '**Monoliths**: Imagine a compact, all-in-one system. That’s the essence of
    a monolith. Everything exists in a single codebase, making development and initial
    deployment simple for small projects or teams with limited resources. Additionally,
    updates tend to be quick for monoliths because there’s only one system to manage.'
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**单体架构**：想象一个紧凑的、集成的系统。这就是单体架构的精髓。一切都存在于同一个代码库中，使得对于小型项目或资源有限的团队来说，开发和初始部署都变得简单。此外，单体架构的更新往往很快，因为只需要管理一个系统。'
- en: '**Microservices**: Think of a complex application broken down into independent,
    modular components. Each service can be built, scaled, and deployed separately.
    This approach shines with large, feature-rich projects and teams with diverse
    skillsets. Microservices provide flexibility and potentially fast development
    cycles. However, they also introduce additional complexity in troubleshooting
    and security management.'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**微服务**：可以把它看作是一个复杂的应用被分解成独立的、模块化的组件。每个服务都可以单独构建、扩展和部署。这种方法在大型功能丰富的项目和拥有多样技能团队中表现尤为出色。微服务提供了灵活性和可能较快的开发周期。然而，它们也带来了在故障排除和安全管理上的额外复杂性。'
- en: Ultimately, the choice between a monolith and microservices hinges on your specific
    needs. Consider your project’s size, team structure, and desired level of flexibility.
    Don’t be swayed by trends – pick the architecture that empowers your team to develop
    and manage your application efficiently.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，单体架构和微服务架构的选择取决于你的具体需求。考虑项目的规模、团队结构以及所需的灵活性水平。不要被趋势左右——选择能帮助你的团队高效开发和管理应用的架构。
- en: Kubernetes provides flexibility. It caters to both fast-moving monoliths and
    microservices, allowing you to choose the architecture that best suits your project’s
    needs.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 提供了灵活性，适用于快速变化的单体架构和微服务架构，允许你选择最适合你项目需求的架构。
- en: In the next section, we will learn about containers and how they help microservice
    software architectures.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将了解容器以及它们如何帮助微服务软件架构。
- en: Understanding containers
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 了解容器
- en: Following this comparison between monolithic and microservice architectures,
    you should have understood that the architecture that best combines agility and
    DevOps is the microservice architecture. It is this architecture that we will
    discuss throughout the book because this is the architecture that Kubernetes manages
    well.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 通过单体架构和微服务架构的比较，你应该已经明白，最能结合敏捷性和 DevOps 的架构是微服务架构。正是这种架构，我们将在本书中讨论，因为它是 Kubernetes
    能够很好管理的架构。
- en: Now, we will move on to discuss how Docker, which is a container engine for
    Linux, is a good option for managing microservices. If you already know a lot
    about Docker, you can skip this section. Otherwise, I suggest that you read through
    it carefully.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将讨论如何使用 Docker，作为 Linux 的容器引擎，来管理微服务。如果你已经对 Docker 有很多了解，可以跳过这一节。否则，我建议你仔细阅读这一节。
- en: Understanding why containers are good for microservices
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 了解为什么容器适用于微服务
- en: 'Recall the two important aspects of the microservice architecture:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 回顾微服务架构的两个重要方面：
- en: Each microservice can have its own technical environment and dependencies.
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 每个微服务可以有自己的技术环境和依赖关系。
- en: At the same time, it must be decoupled from the operating system it’s running
    on.
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 同时，它必须与运行它的操作系统解耦。
- en: 'Let’s put the latter point aside for the moment and discuss the first one:
    two microservices of the same app can be developed in two different languages
    or be written in the same language but as two different versions. Now, let’s say
    that you want to deploy these two microservices on the same Linux machine. That
    would be a nightmare.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们暂时搁置后面提到的问题，先讨论第一个问题：同一个应用的两个微服务可能使用两种不同的编程语言开发，或者使用相同的编程语言，但作为两个不同的版本。现在，假设你想在同一台
    Linux 机器上部署这两个微服务，那将是一个噩梦。
- en: The reason for this is that you’ll have to install all the versions of the different
    runtimes, as well as the dependencies, and there might also be different versions
    or overlaps between the two microservices. Additionally, all of this will be on
    the same host operating system. Now, let’s imagine you want to remove one of these
    two microservices from the machine to deploy it on another server and clean the
    former machine of all the dependencies used by that microservice. Of course, if
    you are a talented Linux engineer, you’ll succeed in doing this. However, for
    most people, the risk of conflicts between the dependencies is huge, and in the
    end, you might just make your app unavailable while running such a nightmarish
    infrastructure.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 原因在于你需要安装所有不同运行时的版本，以及相应的依赖项，而且两个微服务之间可能也存在版本冲突或重叠。此外，所有这些都将运行在同一宿主操作系统上。现在，假设你想从机器上移除其中一个微服务，将其部署到另一台服务器上，并清理掉该微服务使用的所有依赖项。当然，如果你是一个才华横溢的
    Linux 工程师，你会成功做到这一点。但是对于大多数人来说，依赖项之间冲突的风险非常大，最终你可能只是让你的应用在这种噩梦般的基础设施下变得不可用。
- en: 'There is a solution to this: you could build a machine image for each microservice
    and then put each microservice on a dedicated virtual machine. In other words,
    you refrain from deploying multiple microservices on the same machine. However,
    in this example, you will need as many machines as you have microservices. Of
    course, with the help of AWS or GCP, it’s going to be easy to bootstrap tons of
    servers, each of them tasked with running one and only one microservice, but it
    would be a huge waste of money to not mutualize the computing power provided by
    the host.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这有一个解决方案：你可以为每个微服务构建一个机器镜像，然后将每个微服务部署到一个专用的虚拟机上。换句话说，你避免在同一台机器上部署多个微服务。然而，在这个例子中，你将需要与微服务数量相等的机器。当然，在
    AWS 或 GCP 的帮助下，启动大量服务器，每台服务器只负责运行一个微服务将变得非常容易，但如果不共享宿主机提供的计算能力，这将是一个巨大的浪费。
- en: You have similar solutions in the container world, but not with the default
    container runtimes because they don’t guarantee complete isolation between microservices.
    This is exactly how the **Kata runtime** and the **Confidential Container** projects
    come into play. These technologies provide enhanced security and isolation for
    containerized applications. We’ll delve deeper into these container isolation
    concepts later in this book.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 在容器世界中有类似的解决方案，但默认的容器运行时并不提供微服务之间的完全隔离。这正是**Kata 运行时**和**保密容器**项目发挥作用的地方。这些技术为容器化应用程序提供了增强的安全性和隔离性。我们将在本书的后续章节中深入探讨这些容器隔离的概念。
- en: We will learn about how containers help with isolation in the next section.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在下一节中学习容器如何帮助实现隔离。
- en: Understanding the benefits of container isolation
  id: totrans-149
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 理解容器隔离的好处
- en: Container engines such as Docker and Podman play a crucial role in managing
    microservices. Unlike **virtual machines** (**VMs**) that require a full guest
    operating system, containers are lightweight units that share the host machine’s
    Linux kernel. This makes them much faster to start and stop than VMs.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 像 Docker 和 Podman 这样的容器引擎在管理微服务中起着至关重要的作用。与需要完整操作系统的**虚拟机**（**VMs**）不同，容器是轻量级单元，它们共享宿主机的
    Linux 内核。这使得容器比虚拟机更快地启动和停止。
- en: Container engines provide a user-friendly API to build, deploy, and manage containers.
    Container engines don’t introduce an additional layer of virtualization. Instead,
    they use the built-in capabilities of the Linux kernel for process isolation,
    security, and resource allocation. This efficient approach makes containerization
    a compelling solution for deploying microservices.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 容器引擎提供了一个用户友好的 API，用于构建、部署和管理容器。容器引擎并不会引入额外的虚拟化层，而是利用 Linux 内核的内建能力来实现进程隔离、安全性和资源分配。这种高效的方式使得容器化成为部署微服务的一个有吸引力的解决方案。
- en: 'The following diagram shows how containers are different from virtual machines:'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了容器与虚拟机的区别：
- en: '![](img/B22019_01_06.png)'
  id: totrans-153
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_01_06.png)'
- en: 'Figure 1.6: The difference between virtual machines and containers'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.6：虚拟机与容器之间的区别
- en: Your microservices are going to be launched on top of this layer, not directly
    on the host system whose sole role will be to run your containers.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 您的微服务将会在这一层之上启动，而不是直接在宿主系统上运行，宿主系统的唯一角色是运行您的容器。
- en: Since containers are isolated, you can run as many containers as you want and
    have them run applications written in different languages without any conflicts.
    Microservice relocation becomes as easy as stopping a running container and launching
    another one from the same image on another machine.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 由于容器是隔离的，您可以根据需要运行任意数量的容器，并且让它们运行用不同语言编写的应用程序，而不会发生任何冲突。微服务的迁移变得像停止运行一个容器并从相同镜像在另一台机器上启动一个新容器一样简单。
- en: 'The usage of containers with microservices provides three main benefits:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 使用容器与微服务结合提供了三个主要的好处：
- en: It reduces the footprint on the host system.
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它减少了对宿主系统的占用。
- en: It mutualizes the host system without conflicts between different microservices.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它使得宿主系统可以互相共享，而不会有不同微服务之间的冲突。
- en: It removes the coupling between the microservice and the host system.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它消除了微服务与宿主系统之间的耦合。
- en: Once a microservice has been containerized, you can eliminate its coupling with
    the host operating system. The microservice will only depend on the container
    in which it will operate. Since a container is much lighter than a real full-featured
    Linux operating system, it will be easy to share and deploy on many different
    machines. Therefore, the container and your microservice will work on any machine
    that is running a container engine.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦微服务被容器化，您可以消除它与宿主操作系统的耦合。微服务将仅依赖于它所运行的容器。由于容器比真正的全功能 Linux 操作系统轻得多，因此它可以轻松地共享并部署到多台不同的机器上。因此，容器和您的微服务可以在任何运行容器引擎的机器上工作。
- en: 'The following diagram shows a microservice architecture where each microservice
    is wrapped by a container:'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 下图展示了一个微服务架构，其中每个微服务都被一个容器封装：
- en: '![](img/B22019_01_07.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_01_07.png)'
- en: 'Figure 1.7: A microservice application where all microservices are wrapped
    by a container; the life cycle of the app becomes tied to the container, and it
    is easy to deploy it on any machine that is running a container engine'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.7：一个微服务应用，其中所有微服务都被容器封装；应用的生命周期与容器绑定，并且可以轻松地在任何运行容器引擎的机器上进行部署。
- en: Containers fit well with the DevOps methodology too. By developing locally in
    a container, which would later be built and deployed in production, you ensure
    you develop in the same environment as the one that will eventually run the application.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 容器也与 DevOps 方法论非常契合。通过在容器中本地开发，稍后在生产环境中构建并部署，您可以确保在与最终运行应用程序的环境相同的环境中进行开发。
- en: Container engines are not only capable of managing the life cycle of a container
    but also an entire ecosystem around containers. They can manage networks, and
    the intercommunication between different containers, and all these features respond
    particularly well to the properties of the microservice architecture that we mentioned
    earlier.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 容器引擎不仅能管理容器的生命周期，还能管理围绕容器的整个生态系统。它们可以管理网络、不同容器之间的通信，这些特性特别适应我们之前提到的微服务架构的特点。
- en: By using the cloud and containers together, you can build a very strong infrastructure
    to host your microservice. The cloud will give you as many machines as you want.
    You simply need to install a container engine on each of them, and you’ll be able
    to deploy multiple containerized microservices on each of these machines.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将云和容器结合使用，您可以构建一个非常强大的基础设施来托管您的微服务。云将为您提供任意数量的机器。您只需在每台机器上安装容器引擎，就可以在这些机器上部署多个容器化的微服务。
- en: Container engines such as Docker or Podman are very nice tools on their own.
    However, you’ll discover that it’s hard to run them in production alone, just
    as they are.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 或 Podman 等容器引擎本身就是非常优秀的工具。然而，您会发现，单独在生产环境中运行它们是很困难的，就像它们本身一样。
- en: 'Container engines excel in development environments because of their:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 容器引擎在开发环境中表现出色，原因在于：
- en: '**Simplicity**: Container engines are easy to install and use, allowing developers
    to quickly build, test, and run containerized applications.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**简便性**：容器引擎易于安装和使用，允许开发人员快速构建、测试和运行容器化的应用程序。'
- en: '**Flexibility**: Developers can use container engines to experiment with different
    container configurations and explore the world of containerization.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灵活性**：开发人员可以使用容器引擎尝试不同的容器配置，探索容器化的世界。'
- en: '**Isolation**: Container engines ensure isolation between applications, preventing
    conflicts and simplifying debugging.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**隔离**：容器引擎确保应用程序之间的隔离，防止冲突并简化调试。'
- en: 'However, production environments have strict requirements. Container engines
    alone cannot address all of these needs:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，生产环境有严格的要求，仅依靠容器引擎无法满足所有需求：
- en: '**Scaling**: Container engines (such as Docker or Podman) don’t provide built-in
    auto-scaling features to dynamically adapt container deployments based on resource
    utilization.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**扩展性**：容器引擎（如 Docker 或 Podman）并不提供内建的自动扩展功能，无法根据资源利用率动态调整容器部署。'
- en: '**Disaster Recovery**: Container engines don’t provide comprehensive disaster
    recovery capabilities to ensure service availability in case of outages.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**灾难恢复**：容器引擎并不提供全面的灾难恢复能力，无法确保在故障发生时服务的可用性。'
- en: '**Security**: While container engines provide basic isolation, managing security
    policies for large-scale containerized deployments across multiple machines can
    be challenging.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全性**：尽管容器引擎提供基本的隔离功能，但在多个机器上管理大规模容器化部署的安全策略可能是一个挑战。'
- en: '**Standardization**: Container engines require custom scripting or integrations
    for interacting with external systems, such as CI/CD pipelines or monitoring tools.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**标准化**：容器引擎需要自定义脚本或集成来与外部系统交互，例如 CI/CD 流水线或监控工具。'
- en: While container engines excel in development environments, production deployments
    demand a more robust approach. Kubernetes, a powerful container orchestration
    platform, tackles this challenge by providing a comprehensive suite of functionalities.
    It manages the entire container lifecycle, from scheduling them to run on available
    resources to scaling deployments up or down based on demand and distributing traffic
    for optimal performance (load balancing). Unlike custom scripting with container
    engines, Kubernetes provides a well-defined API for interacting with containerized
    applications, simplifying integration with other tools used in production environments.
    Beyond basic isolation, Kubernetes provides advanced security features such as
    role-based access control and network policies. This allows the efficient management
    of containerized workloads from multiple teams or projects on the same infrastructure,
    optimizing resource utilization and simplifying complex deployments.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管容器引擎在开发环境中表现出色，但生产部署需要更强大的方法。Kubernetes 是一个强大的容器编排平台，通过提供全面的功能套件来解决这个挑战。它管理整个容器生命周期，从调度容器运行在可用资源上，到根据需求扩展或缩减部署规模，再到分配流量以优化性能（负载均衡）。与容器引擎的自定义脚本不同，Kubernetes
    提供了一个明确定义的 API，用于与容器化应用程序交互，简化了与生产环境中其他工具的集成。除了基本的隔离，Kubernetes 还提供了高级安全功能，如基于角色的访问控制和网络策略。这使得能够高效管理多个团队或项目在同一基础设施上运行的容器化工作负载，优化资源利用，并简化复杂的部署。
- en: Before we dive into the Kubernetes topics, let’s discuss the basics of containers
    and container engines in the next section.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们深入探讨 Kubernetes 相关话题之前，让我们先在下一节讨论容器和容器引擎的基础知识。
- en: Container engines
  id: totrans-180
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器引擎
- en: A **container engine** acts as the interface for end-users and REST clients,
    managing user inputs, downloading container images from container registries,
    extracting downloaded images onto the disk, transforming user or REST client data
    for interaction with container engines, preparing container mount points, and
    facilitating communication with container engines. In essence, container engines
    serve as the user-facing layer, streamlining image and container management, while
    the underlying container runtimes handle the intricate low-level details of container
    and image management.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 一个 **容器引擎** 作为终端用户和 REST 客户端的接口，管理用户输入，从容器注册中心下载容器镜像，将下载的镜像提取到磁盘，转换用户或 REST
    客户端数据以与容器引擎交互，准备容器挂载点，并促进与容器引擎的通信。从本质上讲，容器引擎作为面向用户的层，简化了镜像和容器管理，而底层的容器运行时处理容器和镜像管理的复杂低级细节。
- en: Docker stands out as one of the most widely adopted container engines, but it’s
    important to note that various alternatives exist in the containerization landscape.
    Some notable ones are **LXD**, **Rkt**, **CRI-O**, and **Podman**.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 脱颖而出，成为最广泛采用的容器引擎之一，但需要注意的是，容器化领域中存在各种替代品。值得注意的有 **LXD**、**Rkt**、**CRI-O**
    和 **Podman**。
- en: At its core, Docker relies on the `containerd` container runtime, which oversees
    critical aspects of container management, including the container life cycle,
    image transfer and storage, execution, and supervision, as well as storage and
    network attachments. `containerd`, in turn, relies on components such as `runc`
    and `hcsshim`. Runc is a command-line tool that facilitates creating and running
    containers in Linux, while `hcsshim` plays a crucial role in the creation and
    management of Windows containers.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: Docker 的核心依赖于 `containerd` 容器运行时，后者负责容器管理的关键方面，包括容器生命周期、镜像传输和存储、执行与监控，以及存储和网络附件。`containerd`
    进一步依赖于诸如 `runc` 和 `hcsshim` 等组件。`runc` 是一个命令行工具，用于在 Linux 中创建和运行容器，而 `hcsshim`
    在创建和管理 Windows 容器方面发挥着关键作用。
- en: It’s worth noting that `containerd` is typically not meant for direct end-user
    interaction. Instead, container engines, such as Docker, interact with the container
    runtime to facilitate the creation and management of containers. The essential
    role of `runc` is evident, serving not only `containerd` but also being used by
    Podman, CRI-O, and indirectly by Docker itself.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 值得注意的是，`containerd` 通常不是为了直接与终端用户交互而设计的。相反，像 Docker 这样的容器引擎通过与容器运行时交互来促进容器的创建和管理。`runc`
    的核心作用非常明显，它不仅服务于 `containerd`，还被 Podman、CRI-O 以及间接地被 Docker 本身使用。
- en: The basics of containers
  id: totrans-185
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 容器基础知识
- en: As we learned in the previous section, Docker is a well-known and widely used
    container engine. Let’s learn the basic terminology related to containers in general.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在上一节中所学，Docker 是一个广为人知且被广泛使用的容器引擎。现在，让我们了解一些与容器相关的基本术语。
- en: Container image
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 容器镜像
- en: A container image is a kind of template used by container engines to launch
    containers. A container image is a self-contained, executable package that encapsulates
    an application and its dependencies. It includes everything needed to run the
    software, such as code, runtime, libraries, and system tools. Container images
    are created from a `Dockerfile` or `Containerfile`, which specify the build steps.
    Container images are stored in image repositories and shared through container
    registries such as Docker Hub, making them a fundamental component of containerization.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 容器镜像是一种由容器引擎用来启动容器的模板。容器镜像是一个自包含的可执行包，封装了应用程序及其依赖项。它包含运行软件所需的一切，如代码、运行时、库和系统工具。容器镜像是从
    `Dockerfile` 或 `Containerfile` 创建的，这些文件指定了构建步骤。容器镜像存储在镜像仓库中，并通过 Docker Hub 等容器注册中心共享，是容器化的基本组成部分。
- en: Container
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 容器
- en: A container can be considered a running instance of a container image. Containers
    are like modular shipping containers for applications. They bundle an application’s
    code, dependencies, and runtime environment into a single, lightweight package.
    Containers run consistently across different environments because they include
    everything needed. Each container runs independently, preventing conflicts with
    other applications on the same system. Containers share the host operating system’s
    kernel, making them faster to start and stop than virtual machines.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 容器可以视为容器镜像的一个运行实例。容器就像是应用程序的模块化运输箱。它们将应用程序的代码、依赖关系和运行时环境打包成一个轻量级的单一包裹。容器在不同的环境中运行时保持一致，因为它们包含运行软件所需的所有内容。每个容器独立运行，避免了与系统中其他应用程序的冲突。容器共享主机操作系统的内核，使得容器比虚拟机启动和停止更快。
- en: Container registry
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 容器注册中心
- en: A container registry is a centralized repository for storing and sharing container
    images. It acts as a distribution mechanism, allowing users to push and pull images
    to and from the registry. Popular public registries include Docker Hub, Red Hat
    Quayi, Amazon’s **Elastic Container Registry** (**ECR**), Azure Container Registry,
    Google Container Registry, and GitHub Container Registry. Organizations often
    use private registries to securely store and share custom images. Registries play
    a crucial role in the Docker ecosystem, facilitating collaboration and efficient
    management of containerized applications.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 容器注册表是一个集中式仓库，用于存储和共享容器镜像。它充当分发机制，允许用户将镜像推送到注册表或从注册表拉取镜像。流行的公共注册表包括 Docker Hub、Red
    Hat Quayi、Amazon 的 **Elastic Container Registry** (**ECR**)、Azure Container Registry、Google
    Container Registry 和 GitHub Container Registry。组织通常使用私有注册表来安全地存储和共享自定义镜像。注册表在
    Docker 生态系统中起着至关重要的作用，促进了容器化应用程序的协作和高效管理。
- en: Dockerfile or Containerfile
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Dockerfile 或 Containerfile
- en: A Dockerfile or Containerfile is a text document that contains a set of instructions
    for building a container image. It defines the base image, sets up the environment,
    copies the application code, installs the dependencies, and configures the runtime
    settings. Dockerfiles or Containerfiles provide a reproducible and automated way
    to create consistent images, enabling developers to version and share their application
    configurations.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Dockerfile 或 Containerfile 是一个包含构建容器镜像一系列指令的文本文件。它定义了基础镜像、设置环境、复制应用程序代码、安装依赖项，并配置运行时设置。Dockerfile
    或 Containerfile 提供了一种可重复和自动化的方式来创建一致的镜像，使开发人员能够对应用程序配置进行版本管理并共享。
- en: 'A sample Dockerfile can be seen in the following code snippet:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一个示例 Dockerfile 可以在以下代码片段中看到：
- en: '[PRE0]'
  id: totrans-196
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'And, here’s a line-by-line explanation of the provided Dockerfile:'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是对所提供的 Dockerfile 的逐行解释：
- en: '`# syntax=docker/dockerfile:1`: This line defines the Dockerfile syntax version
    used to build the image. In this case, it specifies version 1 of the standard
    Dockerfile syntax.'
  id: totrans-198
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`# syntax=docker/dockerfile:1`：这一行定义了构建镜像时使用的 Dockerfile 语法版本。在本例中，它指定了标准 Dockerfile
    语法的版本 1。'
- en: '`FROM node:18-alpine`: This line defines the base image for your container.
    It instructs the container engine to use the official Node.js 18 image with the
    Alpine Linux base. This provides a lightweight and efficient foundation for your
    application.'
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`FROM node:18-alpine`：这一行定义了容器的基础镜像。它指示容器引擎使用官方的 Node.js 18 镜像，并基于 Alpine Linux。这样为您的应用程序提供了一个轻量高效的基础。'
- en: '`WORKDIR /app`: This line sets the working directory within the container.
    Here, it specifies /app as the working directory. This is where subsequent commands
    in the Dockerfile will be executed relative to.'
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`WORKDIR /app`：这一行设置了容器内的工作目录。这里，它将 `/app` 设置为工作目录。接下来的 Dockerfile 命令将相对于这个目录执行。'
- en: '`COPY . .`: This line copies all files and directories from the current context
    (the directory where you have your Dockerfile) into the working directory (`/app`)
    defined in the previous step. This essentially copies your entire application
    codebase into the container.'
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`COPY . .`：这一行将当前上下文中的所有文件和目录（即包含 Dockerfile 的目录）复制到前一步中定义的工作目录（`/app`）中。实际上，它是将整个应用程序代码库复制到容器中。'
- en: '`RUN yarn install --production`: This line instructs the container engine to
    execute a command within the container. In this case, it runs `yarn install --production`.
    This command uses the `yarn` package manager to install all production dependencies
    listed in your `package.json` file. The `--production` flag ensures that only
    production dependencies are installed, excluding development dependencies.'
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`RUN yarn install --production`：这一行指示容器引擎在容器内执行一个命令。这里，它运行 `yarn install --production`。这个命令使用
    `yarn` 包管理器安装 `package.json` 文件中列出的所有生产环境依赖项。`--production` 标志确保只安装生产依赖项，排除开发依赖项。'
- en: '`CMD ["node", "src/index.js"]`: This line defines the default command to be
    executed when the container starts. Here, it specifies an array with two elements:
    `“node”` and `“src/index.js”`. This tells Docker to run the Node.js interpreter
    (node) and execute the application’s entry point script (`src/index.js`) when
    the container starts up.'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`CMD ["node", "src/index.js"]`：这一行定义了容器启动时执行的默认命令。这里，它指定了一个包含两个元素的数组：`"node"`
    和 `"src/index.js"`。这告诉 Docker 启动 Node.js 解释器（node）并执行应用程序的入口脚本（`src/index.js`）。'
- en: '`EXPOSE 3000`: This line exposes a port on the container. Here, it exposes
    port `3000` within the container. This doesn’t map the port to the host machine
    by default, but it allows you to do so later when running the container with the
    `-p` flag (e.g., `docker run -p 3000:3000 my-image`). Exposing port `3000` suggests
    your application might be listening on this port for incoming connections.'
  id: totrans-204
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`EXPOSE 3000`：这一行暴露了容器中的一个端口。在这里，它暴露了容器中的端口 `3000`。这默认并不会将端口映射到主机，但允许你在稍后运行容器时通过
    `-p` 标志来映射（例如 `docker run -p 3000:3000 my-image`）。暴露端口 `3000` 表明你的应用可能正在此端口监听传入连接。'
- en: '**IMPORTANT NOTE**'
  id: totrans-205
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**重要提示**'
- en: To build the container image, you can use a supported container engine (such
    as Docker or Podman) or a container build tool, such as Buildah or kaniko.
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 要构建容器镜像，你可以使用支持的容器引擎（如 Docker 或 Podman）或容器构建工具，例如 Buildah 或 kaniko。
- en: Docker Compose or Podman Compose
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Docker Compose 或 Podman Compose
- en: Docker Compose is a tool for defining and running multi-container applications.
    It uses a YAML file to configure the services, networks, and volumes required
    for an application, allowing developers to define the entire application stack
    in a single file. Docker Compose or Podman Compose simplifies the orchestration
    of complex applications, making it easy to manage multiple containers as a single
    application stack.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: Docker Compose 是一个定义和运行多容器应用程序的工具。它使用 YAML 文件来配置应用所需的服务、网络和数据卷，允许开发人员在一个文件中定义整个应用堆栈。Docker
    Compose 或 Podman Compose 简化了复杂应用程序的编排，使得管理多个容器作为一个单一应用堆栈变得更加容易。
- en: 'The following `compose.yaml` file will spin up two containers for a WordPress
    application stack using a single `docker compose` or `podman compose` command:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 以下 `compose.yaml` 文件将通过单个 `docker compose` 或 `podman compose` 命令启动两个容器，构建一个
    WordPress 应用堆栈：
- en: '[PRE1]'
  id: totrans-210
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the next section, we will learn how Kubernetes can efficiently orchestrate
    all these container operations.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将学习 Kubernetes 如何高效地编排所有这些容器操作。
- en: How can Kubernetes help you to manage your containers?
  id: totrans-212
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 如何帮助你管理容器？
- en: In this section, we will focus on Kubernetes, which is the purpose of this book.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将重点讨论 Kubernetes，这也是本书的目的所在。
- en: Kubernetes – designed to run workloads in production
  id: totrans-214
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Kubernetes – 旨在运行生产环境中的工作负载
- en: 'If you open the official Kubernetes website (at [https://kubernetes.io](https://kubernetes.io)),
    the title you will see is **Production-Grade Container Orchestration**:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你打开官方 Kubernetes 网站（[https://kubernetes.io](https://kubernetes.io)），你会看到的标题是
    **生产级容器编排**：
- en: '![](img/B22019_01_08.png)'
  id: totrans-216
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B22019_01_08.png)'
- en: 'Figure 1.8: The Kubernetes home page showing the header and introducing Kubernetes
    as a production container orchestration platform'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1.8：Kubernetes 首页展示标题并将 Kubernetes 介绍为生产级容器编排平台
- en: 'Those four words perfectly sum up what Kubernetes is: it is a container orchestration
    platform for production. Kubernetes does not aim to replace Docker or any of the
    features of Docker or other container engines; rather, it aims to manage the clusters
    of machines running container runtimes. When working with Kubernetes, you use
    both Kubernetes and the full-featured standard installations of container runtimes.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 这四个词完美地总结了 Kubernetes 的功能：它是一个面向生产的容器编排平台。Kubernetes 并不旨在取代 Docker 或 Docker
    或其他容器引擎的任何功能；而是旨在管理运行容器运行时的机器集群。在使用 Kubernetes 时，你同时使用 Kubernetes 和完整功能的标准容器运行时安装。
- en: 'The title mentions **production**. Indeed, the concept of production is central
    to Kubernetes: it was conceived and designed to answer modern production needs.
    Managing production workloads is different today compared to what it was in the
    2000s. Back in the 2000s, your production workload would consist of just a few
    bare-metal servers, if not even one on-premises. These servers mostly ran monoliths
    directly installed on the host Linux system. However, today, thanks to public
    cloud platforms such as **Amazon Web Services** (**AWS**) or **Google Cloud Platform**
    (**GCP**), anyone can now get hundreds or even thousands of machines in the form
    of instances or virtual machines with just a few clicks. Even better, we no longer
    deploy our applications on the host system but as containerized microservices
    on top of Docker Engine instead, thereby reducing the footprint of the host system.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: 'A problem will arise when you must manage Docker installations on each of these
    virtual machines on the cloud. Let’s imagine that you have 10 (or 100 or 1,000)
    machines launched on your preferred cloud and you want to achieve a very simple
    task: deploy a containerized Docker app on each of these machines.'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: You could do this by running the `docker run` command on each of your machines.
    It would work, but of course, there is a better way to do it. And that’s by using
    a **container orchestrator** such as **Kubernetes**. To give you an extremely
    simplified vision of Kubernetes, it is a **REST API** that keeps a registry of
    your machines executing a Docker daemon.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: Again, this is an extremely simplified definition of Kubernetes. In fact, it’s
    not made of a single centralized REST API, because as you might have gathered,
    Kubernetes was built as a suite of microservices.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: Also note that while Kubernetes excels at managing containerized workloads,
    it doesn’t replace virtual machines (**VMs**) entirely. VMs can still be valuable
    for specific use cases, such as running legacy applications or software with complex
    dependencies that are difficult to containerize. However, Kubernetes is evolving
    to bridge the gap between containers and VMs.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
- en: KubeVirt – a bridge between containers and VMs
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '**KubeVirt** is a project that extends Kubernetes’ ability to manage virtual
    machines using the familiar Kubernetes API. This allows users to leverage the
    power and flexibility of Kubernetes for VM deployments alongside containerized
    applications. KubeVirt embraces **Infrastructure as Code** (**IaC**) principles,
    enabling users to define and manage VMs declaratively within their Kubernetes
    manifests. This simplifies VM management and integrates it seamlessly into existing
    Kubernetes workflows.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: By incorporating VMs under the Kubernetes umbrella, KubeVirt provides a compelling
    approach for organizations that require a hybrid environment with both containers
    and VMs. It demonstrates the ongoing evolution of Kubernetes as a platform for
    managing diverse workloads, potentially leading to a more unified approach to
    application deployment and management.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: We have learned about containers and the complications of managing and orchestrating
    containers at a large scale. In the next section, we will learn about the history
    and evolution of Kubernetes.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the history of Kubernetes
  id: totrans-228
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Now, let’s discuss the history of the Kubernetes project. It will be useful
    for you to understand the context in which the Kubernetes project started and
    the people who are keeping this project alive.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Understanding how and where Kubernetes started
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Since its founding in 1998, Google has gained huge experience in managing high-demanding
    workloads at scale, especially container-based workloads. Since the mid-2000s,
    Google has been at the forefront of developing its applications as Linux containers.
    Well before Docker simplified container usage for the general public, Google recognized
    the advantages of containerization, giving rise to an internal project known as
    Borg. To enhance the architecture of Borg, making it more extensible and robust,
    Google initiated another container orchestrator project called Omega. Subsequently,
    several improvements introduced by Omega found their way into the Borg project.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes was born as an internal project at Google, and the first commit of
    Kubernetes was in 2014 by Brendan Burns, Joe Beda, and Craig McLendon, among others.
    However, Google didn’t open source Kubernetes on its own. It was the efforts of
    individuals like Clayton Coleman, who was working at Red Hat at the time, and
    who played a crucial role in championing the idea of open-sourcing Kubernetes
    and ensuring its success as a community-driven project. Kelsey Hightower, an early
    Kubernetes champion at CoreOS, became a prominent voice advocating for the technology.
    Through his work as a speaker, writer, and co-founder of KubeCon, he significantly
    boosted Kubernetes’ adoption and community growth.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: Today, in addition to Google, Red Hat, Amazon, Microsoft, and other companies
    are also contributing to the Kubernetes project actively.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: '**IMPORTANT NOTE**'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'Borg is not the ancestor of Kubernetes because the project is not dead and
    is still in use at Google. It would be more appropriate to say that a lot of ideas
    from Borg were reused to make Kubernetes. Bear in mind that Kubernetes is not
    Borg or Omega. Borg was built in C++ and Kubernetes in Go. In fact, they are two
    entirely different projects, but one is heavily inspired by the other. This is
    important to understand: Borg and Omega are two internal Google projects. They
    were not built for the public.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes was developed with the experience gained by Google to manage containers
    in production. Most importantly, it inherited Borg’s and Omega’s ideas, concepts,
    and architectures. Here is a brief list of ideas and concepts taken from Borg
    and Omega, which have now been implemented in Kubernetes:'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'The concept of Pods to manage your containers: Kubernetes uses a logical object,
    called a pod, to create, update, and delete your containers.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Each pod has its own IP address in the cluster.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are distributed components that all watch the central Kubernetes API to
    retrieve the cluster state.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is internal load balancing between Pods and Services.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Labels and selectors are metadata that are used together to manage and orchestrate
    resources in Kubernetes.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: That’s why Kubernetes is so powerful when it comes to managing containers in
    production at scale. In fact, the concepts you’ll learn from Kubernetes are older
    than Kubernetes itself. Although Kubernetes is a young project, it was built on
    solid foundations.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: Who manages Kubernetes today?
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes is no longer maintained by Google because Google handed over operational
    control of the Kubernetes project to the **Cloud Native Computing Foundation**
    (**CNCF**) on August 29, 2018\. CNCF is a non-profit organization that aims to
    foster and sustain an open ecosystem of cloud-native technologies.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: Google is a founding member of CNCF, along with companies such as Cisco, Red
    Hat, and Intel. The Kubernetes source code is hosted on GitHub and is an extremely
    active project on the platform. The Kubernetes code is under Apache License version
    2.0, which is a permissive open source license. You won’t have to pay to use Kubernetes,
    and if you are good at coding with Go, you can even contribute to the code.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: Where is Kubernetes today?
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the realm of container orchestration, Kubernetes faces competition from
    various alternatives, including both open-source solutions and platform-specific
    offerings. Some notable contenders include:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: Apache Mesos
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: HashiCorp Nomad
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker Swarm
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amazon ECS
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While each of these orchestrators comes with its own set of advantages and drawbacks,
    Kubernetes stands out as the most widely adopted and popular choice in the field.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes has won the fight for popularity and adoption and has become the
    standard way of deploying container-based workloads in production. As its immense
    growth has made it one of the hottest topics in the IT industry, it has become
    crucial for cloud providers to come up with a Kubernetes offering as part of their
    services. Therefore, Kubernetes is supported almost everywhere now.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: 'The following Kubernetes-based services can help you get a Kubernetes cluster
    up and running with just a few clicks:'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Google Kubernetes Engine (GKE) on Google Cloud Platform
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elastic Kubernetes Service (Amazon EKS)
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Azure Kubernetes Service on Microsoft Azure
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alibaba Cloud Container Service for Kubernetes (ACK)
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It’s not just about the cloud offerings. It’s also about the Platform-as-a-Service
    market. **Red Hat** started incorporating Kubernetes into its OpenShift container
    platform with the release of OpenShift version 3 in 2015\. This marked a significant
    shift in OpenShift’s architecture, moving from its original design to a Kubernetes-based
    container orchestration system, providing users with enhanced container management
    capabilities and offering a complete set of enterprise tools to build, deploy,
    and manage containers entirely on top of Kubernetes. In addition to this, other
    projects, such as Rancher, were built as **Kubernetes distributions** to offer
    a complete set of tools around the Kubernetes orchestrator, whereas projects such
    as **Knative** manage serverless workloads with the Kubernetes orchestrator.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '**IMPORTANT NOTE**'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: AWS is an exception because it has two container orchestrator services. The
    first one is Amazon ECS, which is entirely made by AWS. The second one is Amazon
    EKS, which was released later than ECS and is a complete Kubernetes offering on
    AWS. These services are not the same, so do not be misguided by their similar
    names.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Where is Kubernetes going?
  id: totrans-262
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Kubernetes isn’t stopping at containers! It’s evolving to manage a wider range
    of workloads. KubeVirt extends its reach to virtual machines, while integration
    with AI/ML frameworks such as TensorFlow could allow Kubernetes to orchestrate
    even machine learning tasks. The future of Kubernetes is one of flexibility, potentially
    becoming a one-stop platform for managing diverse applications across containers,
    VMs, and even AI/ML workflows.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: Learning Kubernetes today is one of the smartest decisions you can take if you
    are into managing cloud-native applications in production. Kubernetes is evolving
    rapidly, and there is no reason to wonder why its growth would stop.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: By mastering this wonderful tool, you’ll get one of the hottest skills being
    searched for in the IT industry today. We hope you are now convinced!
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will learn how Kubernetes can simplify operations.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
- en: Exploring the problems that Kubernetes solves
  id: totrans-267
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Now, why is Kubernetes such a good fit for DevOps teams? Here’s the connection:
    Kubernetes shines as a container orchestration platform, managing the deployment,
    scaling, and networking of containerized applications. Containers are lightweight
    packages that bundle an application with its dependencies, allowing faster and
    more reliable deployments across different environments. Users leverage Kubernetes
    for several reasons:'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '**Automation**: Kubernetes automates many manual tasks associated with deploying
    and managing containerized applications, freeing up time for developers to focus
    on innovation.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Scalability**: Kubernetes facilitates easy scaling of applications up or
    down based on demand, ensuring optimal resource utilization.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Consistency**: Kubernetes ensures consistent deployments across different
    environments, from development to production, minimizing configuration errors
    and streamlining the delivery process.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Flexibility**: Kubernetes is compatible with various tools and technologies
    commonly used by DevOps teams, simplifying integration into existing workflows.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'You can imagine that launching containers on your local machine or a development
    environment is not going to require the same level of planning as launching these
    same containers on remote machines, which could face millions of users. Problems
    specific to production will arise, and Kubernetes is a great way to address these
    problems when using containers in production:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Ensuring high availability
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling release management and container deployments
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Autoscaling containers
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network isolation
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Role-Based Access Control (RBAC)
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stateful workloads
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resource management
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ensuring high availability
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: High availability is the central principle of production. This means that your
    application should always remain accessible and should never be down. Of course,
    it’s utopian. Even the biggest companies experience service outages. However,
    you should always bear in mind that this is your goal. Kubernetes includes a whole
    battery of functionality to make your containers highly available by replicating
    them on several host machines and monitoring their health on a regular and frequent
    basis.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: When you deploy containers, the accessibility of your application will directly
    depend on the health of your containers. Let’s imagine that for some reason, a
    container containing one of your microservices becomes inaccessible; with Docker
    alone, you cannot automatically guarantee that the container is terminated and
    recreated to ensure the service restoration. With Kubernetes, it becomes possible
    as Kubernetes will help you design applications that can automatically repair
    themselves by performing automated tasks such as health checking and container
    replacement.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: If one machine in your cluster were to fail, all the containers running on it
    would disappear. Kubernetes would immediately notice that and reschedule all the
    containers on another machine. In this way, your applications will become highly
    available and fault tolerant as well.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: Release management and container deployment
  id: totrans-285
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deployment management is another of these production-specific problems that
    Kubernetes solves. The process of deployment consists of updating your application
    in production to replace an old version of a given microservice with a new version.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: Deployments in production are always complex because you have to update the
    containers that are responding to requests from end users. If you miss them, the
    consequences could be severe for your application because it could become unstable
    or inaccessible, which is why you should always be able to quickly revert to the
    previous version of your application by running a rollback. The challenge of deployment
    is that it needs to be performed in the least visible way to the end user, with
    as little friction as possible.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: 'Whenever you release a new version of the application, there are multiple processes
    involved, as follows:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: Update the `Dockerfile` or `Containerfile` with the latest application info
    (if any).
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Build a new Docker container image with the latest version of the application.
  id: totrans-290
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Push the new container image to the container registry.
  id: totrans-291
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Pull the new container image from the container registry to the staging/UAT/production
    system (Docker host).
  id: totrans-292
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Stop and delete the existing (old version) of the application container running
    on the system.
  id: totrans-293
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Launch the new container image with the new version of the application container
    image in the staging/UAT/production system.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Refer to the following image to understand the high-level flow in a typical
    scenario (please note that this is an ideal scenario because, in an actual environment,
    you might be using different and isolated container registries for development,
    staging, and production environments).
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22019_01_09.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.9: High-level workflow of container management'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: '**IMPORTANT NOTE**'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: 'The container build process has absolutely nothing to do with Kubernetes: it’s
    purely a container image management part. Kubernetes will come into play later
    when you have to deploy new containers based on a newly built image.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Without Kubernetes, you’ll have to run all these operations including `docker
    pull`, `docker stop`, `docker delete`, and `docker run` on the machine where you
    want to deploy a new version of the container. Then, you will have to repeat this
    operation on each server that runs a copy of the container. It should work, but
    it is extremely tedious since it is not automated. And guess what? Kubernetes
    can automate this for you.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: 'Kubernetes has features that allow it to manage deployments and rollbacks of
    Docker containers, and this will make your life a lot easier when responding to
    this problem. With a single command, you can ask Kubernetes to update your containers
    on all of your machines as follows:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-302
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: On a real Kubernetes cluster, this command will update the container called
    `myapp_container`, which is running as part of the application deployment called
    `myapp`, on every single machine where `myapp_container` runs to the `1.0.0` tag.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: Whether it must update one container running on one machine or millions over
    multiple datacenters, this command works the same. Even better, it ensures high
    availability.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Remember that the goal is always to meet the requirement of high availability;
    a deployment should not cause your application to crash or cause a service disruption.
    Kubernetes is natively capable of managing deployment strategies such as rolling
    updates, which aim to prevent service interruptions.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, Kubernetes keeps in memory all the revisions of a specific deployment
    and allows you to revert to a previous version with just one command. It’s an
    incredibly powerful tool that allows you to update a cluster of Docker containers
    with just one command.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: Autoscaling containers
  id: totrans-307
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Scaling is another production-specific problem that has been widely democratized
    using public clouds such as **Amazon Web Services** (**AWS**) and **Google Cloud
    Platform** (**GCP**). Scaling is the ability to adapt your computing power to
    the load you are facing, again to meet the requirement of high availability and
    load balancing. Never forget that the goal is to prevent outages and downtime.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: 'When your production machines are facing a traffic spike and one of your containers
    is no longer able to cope with the load, you need to find a way to scale the container
    workloads efficiently. There are two scaling methods:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '**Vertical scaling**: This allows your container to use more computing power
    offered by the host machine.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Horizontal scaling**: You can duplicate your container in the same or another
    machine, and you can load-balance the traffic between the multiple containers.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Docker is not able to respond to this problem alone; however, when you manage
    Docker with Kubernetes, it becomes possible.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B22019_01_10.png)'
  id: totrans-313
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1.10: Vertical scaling versus horizontal scaling for pods'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes can manage both vertical and horizontal scaling automatically. It
    does this by letting your containers consume more computing power from the host
    or by creating additional containers that can be deployed on the same or another
    node in the cluster. And if your Kubernetes cluster is not capable of handling
    more containers because all your nodes are full, Kubernetes will even be able
    to launch new virtual machines by interfacing with your cloud provider in a fully
    automated and transparent manner by using a component called a **cluster autoscaler**.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: '**IMPORTANT NOTE**'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: The cluster autoscaler only works if the Kubernetes cluster is deployed on a
    supported cloud provider (a private or public cloud).
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: These goals cannot be achieved without using a container orchestrator. The reason
    for this is simple. You can’t afford to do these tasks; you need to think about
    DevOps’ culture and agility and seek to automate these tasks so that your applications
    can repair themselves, be fault-tolerant, and be highly available.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: Contrary to scaling out your containers or cluster, you must also be able to
    decrease the number of containers if the load starts to decrease to adapt your
    resources to the load, whether it is rising or falling. Again, Kubernetes can
    do this, too.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: Network isolation
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In a world of millions of users, ensuring secure communication between containers
    is paramount. Traditional approaches can involve complex manual configuration.
    This is where Kubernetes shines:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '**Pod networking**: Kubernetes creates a virtual network overlay for your pods.
    By default, containers within the same Pod can communicate directly, while containers
    in different Pods are isolated by default. This prevents unintended communication
    between containers and enhances security.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network policies**: Kubernetes allows you to define granular network policies
    that further restrict how pods can communicate. You can specify allowed ingress
    (incoming traffic) and egress (outgoing traffic) for pods, ensuring they only
    access the resources they need. This approach simplifies network configuration
    and strengthens security in production environments.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Role-Based Access Control (RBAC)
  id: totrans-324
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Managing access to container resources in a production environment with multiple
    users is crucial. Here’s how Kubernetes empowers secure access control:'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
- en: '**User roles**: Kubernetes defines user roles that specify permissions for
    accessing and managing container resources. These roles can be assigned to individual
    users or groups, allowing granular control over who can perform specific actions
    (such as viewing pod logs and deploying new containers).'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service accounts**: Kubernetes utilizes service accounts to provide identities
    for pods running within the cluster. These service accounts can be assigned roles,
    ensuring pods only have the access they require to function correctly.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This multi-layered approach of using user roles and service accounts strengthens
    security and governance in production deployments.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: Stateful workloads
  id: totrans-329
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While containers are typically stateless (their data doesn’t persist after
    they stop), some applications require persistent storage. Kubernetes provides
    solutions to manage stateful workloads: **Persistent Volumes (PVs)** and **Persistent
    Volume Claims (PVCs)**. Kubernetes introduces the concept of PVs, which are persistent
    storage resources provisioned by the administrator (e.g., host directory, cloud
    storage). Applications can then request storage using PVCs. This abstraction decouples
    storage management from the application, allowing containers to leverage persistent
    storage without worrying about the underlying details.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: Resource management
  id: totrans-331
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Efficiently allocating resources to containers becomes critical in production
    to optimize performance and avoid resource bottlenecks. Kubernetes provides functionalities
    for managing resources:'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: '**Resource quotas**: Kubernetes allows you to set resource quotas (limits and
    requests) for CPU, memory, and other resources for namespaces or pods. This ensures
    fair resource allocation and prevents individual pods from consuming excessive
    resources that could starve other applications.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource limits and requests**: When defining deployments, you can specify
    resource requests (minimum guaranteed resources) and resource limits (maximum
    allowed resources) for containers. These ensure your application has the resources
    it needs to function properly while preventing uncontrolled resource usage.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will learn about all of these features in the upcoming chapters.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: Should we use Kubernetes everywhere? Let’s discuss that in the next section.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: When and where is Kubernetes not the solution?
  id: totrans-337
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Kubernetes has undeniable benefits; however, it is not always advisable to
    use it as a solution. Here, we have listed several cases where another solution
    might be more appropriate:'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: '**Container-less architecture**: If you do not use a container at all, Kubernetes
    won’t be of any use to you.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**A very small number of microservices or applications**: Kubernetes stands
    out when it must manage many containers. If your app consists of two to three
    microservices, a simpler orchestrator might be a better fit.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  id: totrans-341
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: This first chapter gave us room for a big introduction. We covered a lot of
    subjects, such as monoliths, microservices, Docker containers, cloud computing,
    and Kubernetes. We also discussed how this project came to life. You should now
    have a global vision of how Kubernetes can be used to manage your containers in
    production. You have also learned why Kubernetes was introduced and how it became
    a well-known container orchestration tool.
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss the process Kubernetes follows to launch
    a Docker container. You will discover that you can issue commands to Kubernetes,
    and these commands will be interpreted by Kubernetes as instructions to run containers.
    We will list and explain each component of Kubernetes and its role in the whole
    cluster. There are a lot of components that make up a Kubernetes cluster, and
    we will discover all of them. We will explain how Kubernetes was built with a
    focus on the distinction between master nodes, worker nodes, and control plane
    components.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-344
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kubernetes documentation: [https://kubernetes.io/docs/home/](https://kubernetes.io/docs/home/)'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Podman documentation: [https://docs.podman.io/en/latest/](https://docs.podman.io/en/latest/)'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Docker docs: [https://docs.docker.com/](https://docs.docker.com/)'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kata containers: [https://katacontainers.io/](https://katacontainers.io/)'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'kaniko: [https://github.com/GoogleContainerTools/kaniko](https://github.com/GoogleContainerTools/kaniko)'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Buildah: [https://buildah.io](https://buildah.io)'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'KubeVirt: [https://kubevirt.io](https://kubevirt.io)'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Knative: [https://knative.dev/docs/](https://knative.dev/docs/ )'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kubernetes: The Documentary [PART 1]: [https://www.youtube.com/watch?v=BE77h7dmoQU](https://www.youtube.com/watch?v=BE77h7dmoQU)'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kubernetes: The Documentary [PART 2]: [https://www.youtube.com/watch?v=318elIq37PE](https://www.youtube.com/watch?v=318elIq37PE)'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Technically Speaking: Clayton Coleman on the History of Kubernetes: [https://www.youtube.com/watch?v=zUJTGqWZtq0](https://www.youtube.com/watch?v=zUJTGqWZtq0)'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Join our community on Discord
  id: totrans-356
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the authors and other
    readers:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code119001106479081656.png)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
