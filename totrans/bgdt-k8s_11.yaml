- en: '11'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '11'
- en: Generative AI on Kubernetes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Kubernetes 上的生成式 AI
- en: '**Generative** **artificial intelligence** (**GenAI**) has emerged as a transformative
    technology, revolutionizing how we interact with and leverage AI. In this chapter,
    we will explore the exciting world of generative AI and learn how to harness its
    power on Kubernetes. We will dive into the fundamentals of generative AI and understand
    its main differences from traditional AI.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**生成式人工智能**（**GenAI**）已成为一项变革性技术，彻底改变了我们与 AI 的互动方式以及如何利用 AI。本章将带你探索生成式 AI 的精彩世界，学习如何在
    Kubernetes 上利用其强大功能。我们将深入了解生成式 AI 的基础知识，并理解它与传统 AI 的主要区别。'
- en: Our focus will be on leveraging **Amazon Bedrock**, a comprehensive suite of
    services designed to simplify the development and deployment of generative AI
    applications. Through hands-on examples, you will gain practical experience in
    building a generative AI application on Kubernetes using **Streamlit**, a powerful
    Python library for creating interactive data applications. We will cover the entire
    process, from the development to deploying the application on a Kubernetes cluster.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的重点将放在利用 **Amazon Bedrock**，这是一个旨在简化生成式 AI 应用开发和部署的综合服务套件。通过实际操作示例，你将获得在 Kubernetes
    上构建生成式 AI 应用的实践经验，并使用 **Streamlit**，一个强大的 Python 库，用于创建互动数据应用。我们将覆盖整个过程，从开发到将应用部署到
    Kubernetes 集群。
- en: Moreover, we will explore the concept of **retrieval-augmented generation**
    (**RAG**), which combines the power of generative AI with external knowledge bases.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们将探索 **检索增强生成**（**RAG**）的概念，RAG 将生成式 AI 的力量与外部知识库结合起来。
- en: Finally, we will introduce **Agents for Amazon Bedrock**, a powerful feature
    that allows you to automate tasks and create intelligent assistants. You will
    learn how to build an agent, define its capabilities through an OpenAPI schema,
    and create the underlying Lambda function that serves as the backend for your
    agent.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们将介绍 **Amazon Bedrock** 的 **Agents**，这是一项强大的功能，允许你自动化任务并创建智能助手。你将学习如何构建代理，如何通过
    OpenAPI 架构定义其能力，以及如何创建作为代理后端的 Lambda 函数。
- en: By the end of this chapter, you will have a solid understanding of generative
    AI, its applications, and the tools and techniques required to build and deploy
    generative AI applications on Kubernetes.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 到本章结束时，你将对生成式 AI 有一个扎实的理解，了解其应用以及构建和部署生成式 AI 应用到 Kubernetes 上所需的工具和技术。
- en: 'In this chapter, we’re going to cover the following main topics:'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将涵盖以下主要主题：
- en: What generative AI is and what it is not
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是生成式 AI，什么不是
- en: Using Amazon Bedrock to work with foundational models
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Amazon Bedrock 与基础模型进行工作
- en: Building a generative AI application on Kubernetes
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上构建生成式 AI 应用
- en: Building RAG with **Knowledge Bases for** **Amazon Bedrock**
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 **Amazon Bedrock** 构建 RAG 知识库
- en: Building action models with agents
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用代理构建行动模型
- en: Technical requirements
  id: totrans-13
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: For this chapter, you will need an AWS account and a running Kubernetes cluster.
    We will also be using **LangChain** and Streamlit libraries. Although it is not
    necessary to have them installed for application deployment in Kubernetes, the
    installation is advised if you want to test the code locally and modify it to
    your own experiments.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本章需要一个 AWS 账户和一个正在运行的 Kubernetes 集群。我们还将使用 **LangChain** 和 Streamlit 库。虽然部署应用到
    Kubernetes 时不需要它们，但如果你希望在本地测试代码并修改以适应自己的实验，建议安装这些库。
- en: Also, it will be necessary to install the **Beautiful Soup** library to get
    data for the RAG exercise (fourth section).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了获取 RAG 练习（第四部分）的数据，必须安装 **Beautiful Soup** 库。
- en: All the code for this chapter is available at [https://github.com/PacktPublishing/Bigdata-on-Kubernetes](https://github.com/PacktPublishing/Bigdata-on-Kubernetes)
    under the `Chapter11` folder.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本章的所有代码可以在 [https://github.com/PacktPublishing/Bigdata-on-Kubernetes](https://github.com/PacktPublishing/Bigdata-on-Kubernetes)
    的 `Chapter11` 文件夹中找到。
- en: What generative AI is and what it is not
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 什么是生成式 AI，什么不是
- en: At its core, generative AI refers to AI systems capable of generating new, original
    content, such as text, images, audio, or code, based on the training data they
    have been exposed to. Generative AI models are trained on large datasets of existing
    content, and they learn the patterns and relationships within that data. When
    prompted, these models can then generate new, original content that resembles
    the training data but is not an exact copy of any specific example.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性 AI 的核心是指能够基于其所接触到的训练数据生成新的原创内容的 AI 系统，这些内容可以是文本、图像、音频或代码。生成性 AI 模型在大量现有内容的数据集上进行训练，并学习其中的模式和关系。在得到提示后，这些模型可以生成新的原创内容，这些内容类似于训练数据，但并不是任何特定示例的精确复制。
- en: This contrasts with traditional machine learning models, which are focused on
    making predictions or classifications based on existing data.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这与传统的机器学习模型形成对比，后者侧重于基于现有数据进行预测或分类。
- en: Traditional machine learning models, such as those used for image recognition,
    natural language processing, or predictive analytics, are designed to take in
    input data and make predictions or classifications based on that data. Machine
    learning models excel at tasks such as classification (e.g., identifying objects
    in images or topics in texts), regression (e.g., predicting house prices based
    on features such as square footage and location), and clustering (e.g., grouping
    customers based on similar behavior patterns).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的机器学习模型，例如用于图像识别、自然语言处理或预测分析的模型，旨在接收输入数据，并基于该数据进行预测或分类。机器学习模型擅长处理分类任务（例如，识别图像中的物体或文本中的主题）、回归任务（例如，根据面积和位置等特征预测房价）以及聚类任务（例如，根据相似行为模式将客户分组）。
- en: For example, an image recognition model might be trained on a large dataset
    of labeled images to learn to recognize and classify objects in new, unseen images.
    Similarly, a natural language processing model might be trained on a corpus of
    text data to perform tasks such as sentiment analysis, named entity recognition,
    or language translation.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，一个图像识别模型可能会基于大量带标签的图像数据集进行训练，学习识别和分类新图像中的物体。同样，一个自然语言处理模型可能会基于文本数据语料库进行训练，执行情感分析、命名实体识别或语言翻译等任务。
- en: In a credit risk assessment scenario, a machine learning model would be trained
    on a dataset containing information about past loan applicants, such as their
    income, credit history, and other relevant features, along with labels indicating
    whether they defaulted on their loans or not. The model would learn the patterns
    and relationships between these features and the loan default outcomes. When presented
    with a new loan application, the trained model can then predict the likelihood
    of the applicant defaulting on the loan.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在信用风险评估场景中，一个机器学习模型会基于包含过去贷款申请者信息的数据集进行训练，例如他们的收入、信用历史和其他相关特征，以及是否违约的标签。该模型会学习这些特征与贷款违约结果之间的模式和关系。当遇到新的贷款申请时，经过训练的模型便可以预测该申请者违约的可能性。
- en: In these cases, the machine learning model is not generating new content; instead,
    it is using the patterns and relationships it has learned from the training data
    to make informed predictions or decisions about new, unseen data.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，机器学习模型并不生成新内容；相反，它是在使用从训练数据中学习到的模式和关系，对新的、未见过的数据进行有根据的预测或决策。
- en: In contrast, for instance, a generative AI model trained on a vast corpus of
    text can generate human-like writing on any given topic or in any desired style.
    Similarly, models trained on images can create entirely new, realistic-looking
    images based on textual descriptions or other input data.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，例如，经过大量文本语料库训练的生成性 AI 模型可以在任何给定的主题或所需的风格下生成类似人类的写作。同样，经过图像训练的模型可以根据文本描述或其他输入数据创建全新的、逼真的图像。
- en: 'While the end result of generative AI is the creation of new content, the underlying
    mechanism is still based on the same principles of machine learning: making predictions.
    However, instead of predicting a single output (such as a classification or a
    numerical value), generative AI models are trained to predict the next element
    in a sequence, whether that sequence is a sequence of words, pixels, or any other
    type of data.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管生成性 AI 的最终结果是创造新的内容，但其基本机制仍然基于相同的机器学习原理：进行预测。然而，生成性 AI 模型不仅仅是预测单一输出（如分类或数值），它们被训练来预测序列中的下一个元素，无论这个序列是由单词、像素或任何其他类型的数据组成。
- en: The power of large neural networks
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 大型神经网络的力量
- en: While the concept of predicting the next element in a sequence is relatively
    simple, the ability of generative AI models to generate coherent, high-quality
    content lies in the sheer scale and complexity of the neural networks used to
    power these models.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然预测序列中下一个元素的概念相对简单，但生成性人工智能模型生成连贯、高质量内容的能力在于所使用的神经网络的规模和复杂性。
- en: Generative AI models typically employ large, deep neural networks with billions
    or even trillions of parameters. These neural networks are trained on vast amounts
    of data, often spanning millions or billions of examples, allowing them to capture
    incredibly nuanced patterns and relationships within the data.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性人工智能模型通常使用拥有数十亿甚至万亿个参数的大型深度神经网络。这些神经网络在大量数据上进行训练，通常涉及数百万或数十亿个示例，从而使模型能够捕捉数据中极其微妙的模式和关系。
- en: For example, the Anthropic models, such as Claude, are trained on an enormous
    corpus of text data, spanning a wide range of topics and domains. This allows
    the models to develop a deep understanding of language, context, and domain-specific
    knowledge, enabling them to generate text that is not only grammatically correct
    but also semantically coherent and relevant to the given context.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Anthropic的模型，如Claude，是在一个庞大的文本数据集上进行训练的，这些数据涵盖了广泛的主题和领域。这使得模型能够深入理解语言、上下文和领域特定的知识，从而生成不仅语法正确，而且在语义上连贯且与给定上下文相关的文本。
- en: Challenges and limitations
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 挑战与局限性
- en: While generative AI has demonstrated remarkable capabilities, it is not without
    its challenges and limitations. One of the primary concerns is the potential for
    these models to generate biased, harmful, or misleading content, especially when
    trained on datasets that reflect societal biases or contain inaccurate information.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管生成性人工智能展现出了显著的能力，但它并非没有挑战和局限性。一个主要的担忧是，这些模型可能生成带有偏见、有害或误导性内容，尤其是在训练数据集包含反映社会偏见或不准确信息的情况下。
- en: Additionally, generative AI models can sometimes produce outputs that are nonsensical,
    inconsistent, or factually incorrect, even though they may appear coherent and
    plausible on the surface. This is known as the “hallucination” problem, where
    the model generates content that is not grounded in factual knowledge or the provided
    context. Here are two well-known real-life cases. Air Canada’s AI-powered chatbot
    provided misleading information to a passenger regarding the airline’s bereavement
    fare policy. The chatbot incorrectly stated that passengers could apply for reduced
    bereavement fares retroactively, even after travel had already occurred, which
    contradicted Air Canada’s actual policy. The passenger relied on this hallucinated
    response from the chatbot and subsequently filed a successful small claims case
    against Air Canada when the airline refused to honor the chatbot’s advice ([https://www.forbes.com/sites/marisagarcia/2024/02/19/what-air-canada-lost-in-remarkable-lying-ai-chatbot-case/](https://www.forbes.com/sites/marisagarcia/2024/02/19/what-air-canada-lost-in-remarkable-lying-ai-chatbot-case/)).
    Also, a federal judge in Brazil used the ChatGPT AI system to research legal precedents
    for a ruling he was writing. However, the AI provided fabricated information,
    citing non-existent rulings from the Superior Court of Justice as the basis for
    the judge’s decision ([https://g1.globo.com/politica/blog/daniela-lima/post/2023/11/13/juiz-usa-inteligencia-artificial-para-fazer-decisao-e-cita-jurisprudencia-falsa-cnj-investiga-caso.ghtml](https://g1.globo.com/politica/blog/daniela-lima/post/2023/11/13/juiz-usa-inteligencia-artificial-para-fazer-decisao-e-cita-jurisprudencia-falsa-cnj-investiga-caso.ghtml)).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，生成式 AI 模型有时可能会产生无意义、不一致或事实不准确的输出，尽管它们可能在表面上看起来合乎逻辑且可信。这被称为“幻觉”问题，即模型生成的内容并未基于事实知识或提供的背景。以下是两个著名的真实案例。加拿大航空的
    AI 聊天机器人向一名乘客提供了有关航空公司丧亲票价政策的误导性信息。该聊天机器人错误地表示，即使在旅行已发生后，乘客仍可追溯申请减价的丧亲票价，这与加拿大航空的实际政策相矛盾。乘客依赖该聊天机器人“幻觉”般的回应，最终在航空公司拒绝兑现聊天机器人建议时，成功提起小额索赔案件并获胜（[https://www.forbes.com/sites/marisagarcia/2024/02/19/what-air-canada-lost-in-remarkable-lying-ai-chatbot-case/](https://www.forbes.com/sites/marisagarcia/2024/02/19/what-air-canada-lost-in-remarkable-lying-ai-chatbot-case/)）。此外，巴西的一名联邦法官使用
    ChatGPT AI 系统来研究他所撰写判决的法律先例。然而，AI 提供了伪造的信息，引用了不存在的最高法院裁决作为该法官判决的依据（[https://g1.globo.com/politica/blog/daniela-lima/post/2023/11/13/juiz-usa-inteligencia-artificial-para-fazer-decisao-e-cita-jurisprudencia-falsa-cnj-investiga-caso.ghtml](https://g1.globo.com/politica/blog/daniela-lima/post/2023/11/13/juiz-usa-inteligencia-artificial-para-fazer-decisao-e-cita-jurisprudencia-falsa-cnj-investiga-caso.ghtml)）。
- en: Despite these challenges, generative AI is a rapidly evolving field, and researchers
    and developers are actively working on addressing these issues. Techniques such
    as fine-tuning, prompt engineering, and the use of external knowledge sources
    (e.g., knowledge bases or RAG) are being explored to improve the reliability,
    safety, and factual accuracy of generative AI models.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在这些挑战，生成式 AI 仍是一个快速发展的领域，研究人员和开发者正在积极解决这些问题。诸如微调、提示工程和使用外部知识来源（例如，知识库或 RAG）等技术，正在被探索以提高生成式
    AI 模型的可靠性、安全性和事实准确性。
- en: In the following sections, we will dive deeper into the practical aspects of
    building and deploying generative AI applications using Amazon Bedrock and its
    foundational models, knowledge base, and agent-based architectures.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，我们将深入探讨如何使用 Amazon Bedrock 及其基础模型、知识库和基于代理的架构来构建和部署生成式 AI 应用的实际操作。
- en: Using Amazon Bedrock to work with foundational models
  id: totrans-35
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Amazon Bedrock 来与基础模型进行协作
- en: Amazon Bedrock provides a suite of foundational models that can be used as building
    blocks for your generative AI applications. It’s important to understand the capabilities
    and intended use cases of each model to choose the right one for your application.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: Amazon Bedrock 提供了一套基础模型，可作为构建生成式 AI 应用的模块。了解每个模型的能力和预期使用场景非常重要，以便为你的应用选择合适的模型。
- en: The available models in Amazon Bedrock include language models, computer vision
    models, and multimodal models. Language models excel at understanding and generating
    human-like text. They can be employed for tasks such as text summarization, question
    answering, and content generation. Computer vision models, on the other hand,
    are adept at analyzing and understanding visual data, making them ideal for applications
    such as image recognition, object detection, and scene understanding.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Amazon Bedrock 中可用的模型包括语言模型、计算机视觉模型和多模态模型。语言模型擅长理解和生成类人文本，可以用于文本摘要、问答和内容生成等任务。而计算机视觉模型则擅长分析和理解视觉数据，非常适合图像识别、物体检测和场景理解等应用。
- en: Multimodal models, as the name suggests, can handle multiple modalities simultaneously.
    This makes it suitable for tasks such as image captioning, visual question answering,
    and data chart analysis.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如同名称所示，多模态模型可以同时处理多种模态。这使得它适用于图像标注、视觉问答和数据图表分析等任务。
- en: It’s important to note that each model has its own strengths and limitations,
    and the choice of model should be guided by the specific requirements of your
    application. For example, if your application primarily deals with text-based
    tasks, a language model such as Llama might be the most appropriate choice. However,
    if you need to process both text and images, a multimodal model such as Claude
    would be a better fit.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，每个模型都有其自身的优点和局限性，选择模型时应根据应用的具体需求来决定。例如，如果你的应用主要处理基于文本的任务，那么像 Llama 这样的语言模型可能是最合适的选择。然而，如果你需要处理文本和图像，那么像
    Claude 这样的多模态模型则会更为合适。
- en: 'To effectively integrate Amazon Bedrock’s foundational models into our generative
    AI applications, follow these steps:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将 Amazon Bedrock 的基础模型有效集成到我们的生成型 AI 应用程序中，请按照以下步骤操作：
- en: To use Amazon Bedrock’s available foundational models, first, we need to activate
    them. Go to the AWS console and search for the Amazon Bedrock page. Then, click
    on **Modify model access** (*Figure 11**.1*).
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要使用 Amazon Bedrock 上的可用基础模型，首先需要激活它们。进入 AWS 控制台，搜索 Amazon Bedrock 页面。然后，点击 **修改模型访问权限**
    (*图 11.1*)。
- en: '![Figure 11.1 – Modifying model access on Amazon Bedrock](img/B21927_11_01.jpg)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.1 – 修改 Amazon Bedrock 上的模型访问权限](img/B21927_11_01.jpg)'
- en: Figure 11.1 – Modifying model access on Amazon Bedrock
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – 修改 Amazon Bedrock 上的模型访问权限
- en: On the next page, select the **Claude 3 Sonnet** and **Claude 3 Haiku** Anthropic
    models. Those are the foundational models we will use for our generative AI applications.
    You can select all the available models if you wish to play and experiment with
    different models (*Figure 11**.2*).
  id: totrans-44
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页，选择 **Claude 3 Sonnet** 和 **Claude 3 Haiku** Anthropic 模型。这些是我们将用于生成型 AI
    应用程序的基础模型。如果你愿意尝试和实验不同的模型，也可以选择所有可用的模型 (*图 11.2*)。
- en: '![Figure 11.2 – Requesting access for Anthropic’s Claude 3 models](img/B21927_11_02.jpg)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.2 – 请求访问 Anthropic 的 Claude 3 模型](img/B21927_11_02.jpg)'
- en: Figure 11.2 – Requesting access for Anthropic’s Claude 3 models
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.2 – 请求访问 Anthropic 的 Claude 3 模型
- en: Click **Next** and, on the next page, review the changes and click **Submit**.
    Those models can take a few minutes to get access granted.
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 点击 **下一步**，在下一页上查看更改并点击 **提交**。这些模型可能需要几分钟才能获得访问权限。
- en: Once access has been granted, we have all we need to develop a generative AI
    application. Let’s get to it.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦获得访问权限，我们就拥有了开发生成型 AI 应用程序所需的一切。让我们开始吧。
- en: Building a generative AI application on Kubernetes
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上构建生成型 AI 应用程序
- en: In this section, we will build a generative AI application with Streamlit. A
    diagram representing the architecture for this application is shown in *Figure
    11**.3*. In this application, the user will be able to choose which foundational
    model they are going to talk to.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们将使用 Streamlit 构建一个生成型 AI 应用程序。该应用程序架构的示意图如 *图 11.3* 所示。在这个应用程序中，用户将能够选择与之交互的基础模型。
- en: '![Figure 11.3 – Foundational models’ application architecture](img/B21927_11_03.jpg)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.3 – 基础模型的应用架构](img/B21927_11_03.jpg)'
- en: Figure 11.3 – Foundational models’ application architecture
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.3 – 基础模型的应用架构
- en: 'Let’s start with the Python code for the application. The complete code is
    available under the [*Chapter 11*](B21927_11.xhtml#_idTextAnchor167)`/streamlit-claude/app`
    folders on GitHub. We will walk through the code, block by block:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从应用程序的 Python 代码开始。完整的代码可以在 GitHub 上的 [*第 11 章*](B21927_11.xhtml#_idTextAnchor167)`/streamlit-claude/app`
    文件夹中找到。我们将逐块分析代码：
- en: 'Create a folder named `app` and inside it, create a `main.py` code file. First,
    we import the necessary files and create a client to access Amazon Bedrock runtime
    APIs:'
  id: totrans-54
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个名为`app`的文件夹，并在其中创建一个`main.py`代码文件。首先，我们导入必要的文件并创建一个客户端以访问Amazon Bedrock运行时API：
- en: '[PRE0]'
  id: totrans-55
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Next, we define a dictionary of parameters that are important for working with
    Claude:'
  id: totrans-56
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们定义一个重要的参数字典，用于与Claude进行交互：
- en: '[PRE1]'
  id: totrans-57
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Next, we will configure a function to allow the choosing of the preferred foundational
    model. With the choice, we will return a model object that can access Bedrock
    through Langchain:'
  id: totrans-58
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将配置一个函数，以允许选择首选的基础模型。通过选择，我们将返回一个可以通过Langchain访问Bedrock的模型对象：
- en: '[PRE2]'
  id: totrans-59
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Now, we will add a small function to reset the conversation history:'
  id: totrans-60
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将添加一个小功能，用于重置对话历史记录：
- en: '[PRE3]'
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Next, we will begin the development of the `main` function and add some widgets
    to the application interface. The following code creates a sidebar. In it, we
    add a selection box with Claude 3 Haiku and Claude 3 Sonnet as options, we write
    a confirmation message to tell the user which model they are talking to, and we
    add a `choose_model` function to return the class that connects to Bedrock and
    write the title of the application, *Chat with* *Claude 3*:'
  id: totrans-62
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将开始开发`main`函数，并为应用程序界面添加一些小部件。以下代码创建了一个侧边栏。在其中，我们添加了一个选择框，选项包括Claude 3
    Haiku和Claude 3 Sonnet，我们写了一个确认消息告诉用户他们正在与哪个模型对话，并添加了一个`choose_model`函数来返回连接到Bedrock的类，并写下应用程序的标题，*Chat
    with* *Claude 3*：
- en: '[PRE4]'
  id: totrans-63
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Next, we will initialize the chat history as an empty list if it doesn’t already
    exist in `st.session_state`. `st.session_state` is a Streamlit object that persists
    data across app reruns. Then, we iterate over the `messages` list in `st.session_state`
    and display each message in a chat message container. The `st.chat_message` function
    creates a chat message container with the specified role (e.g., `user` or `assistant`).
    The `st.markdown` function displays the message content inside the container:'
  id: totrans-64
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，如果`st.session_state`中尚未存在聊天历史记录，我们将初始化一个空列表。`st.session_state`是一个Streamlit对象，可以在应用程序重新运行时保持数据的持久性。然后，我们遍历`st.session_state`中的`messages`列表，并在聊天消息容器中显示每条消息。`st.chat_message`函数根据指定的角色（例如`user`或`assistant`）创建聊天消息容器。`st.markdown`函数在容器内显示消息内容：
- en: '[PRE5]'
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Next, we handle user input and display the conversation. The `st.chat_input`
    function creates an input field where the user can enter their prompt. If the
    user enters a prompt, the following steps are executed: (1) the user’s prompt
    is added to the `messages` list in `st.session_state` with the `user` role; (2)
    the user’s prompt is displayed in a chat message container with the `user` role;
    (3) the `model.stream(prompt)` function is called, which sends the user’s prompt
    to the Bedrock model and streams the response back. The `st.write_stream` function
    displays the streamed response in real-time; (4) the assistant’s response is added
    to the `messages` list in `st.session_state` with the `assistant` role:'
  id: totrans-66
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们处理用户输入并显示对话。`st.chat_input`函数创建一个输入框，用户可以在其中输入提示。如果用户输入了提示，将执行以下步骤：（1）将用户的提示以`user`角色添加到`st.session_state`中的`messages`列表中；（2）将用户的提示以`user`角色显示在聊天消息容器中；（3）调用`model.stream(prompt)`函数，将用户的提示发送到Bedrock模型并实时返回响应。`st.write_stream`函数实时显示流式响应；（4）助手的响应以`assistant`角色添加到`st.session_state`中的`messages`列表中：
- en: '[PRE6]'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Finally, we call the main function to start the Streamlit application:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们调用主函数来启动Streamlit应用程序：
- en: '[PRE7]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'If you want to run this application locally, here is a `requirements.txt` file:'
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你想在本地运行此应用程序，这里有一个`requirements.txt`文件：
- en: '[PRE8]'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'If you have the libraries already installed, authenticate your AWS CLI with
    the `aws configure` command and start the application locally with the following:'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如果你已经安装了所需的库，使用`aws configure`命令对AWS CLI进行身份验证，然后通过以下命令在本地启动应用程序：
- en: '[PRE9]'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This is an awesome way of testing the application before building a container
    image for deployment. You can test and modify the application as you wish.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这是在构建用于部署的容器镜像之前测试应用程序的绝妙方法。你可以随心所欲地测试和修改应用程序。
- en: When it is ready, now, let’s build a container image for deployment.
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 准备好后，现在，让我们构建一个用于部署的容器镜像。
- en: 'The following is a simple **Dockerfile** to build the image:'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下是一个简单的**Dockerfile**，用于构建镜像：
- en: '**Dockerfile**'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**Dockerfile**'
- en: '[PRE10]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: This Dockerfile starts with the Python 3.9 slim base image and sets the working
    directory to `/app`. It then installs various system packages required for the
    application, such as `build-essential`, `curl`, `software-properties-common`,
    and `git`. The application code is copied into the `/app` directory, and the container
    exposes port `8501`. A health check is set up to check whether the Streamlit application
    is running correctly on [http://localhost:8501/_stcore/health](http://localhost:8501/_stcore/health).
    The required Python packages are installed using `pip3` based on the `requirements.txt`
    file. Finally, the `ENTRYPOINT` command starts the Streamlit application by running
    `streamlit run main.py` and specifying the server port and address.
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这个 Dockerfile 从 Python 3.9 slim 基础镜像开始，并将工作目录设置为 `/app`。它接着安装应用程序所需的各种系统包，例如
    `build-essential`、`curl`、`software-properties-common` 和 `git`。应用程序代码被复制到 `/app`
    目录，容器暴露 `8501` 端口。健康检查会检查 Streamlit 应用程序是否在 [http://localhost:8501/_stcore/health](http://localhost:8501/_stcore/health)
    正常运行。通过 `pip3` 安装所需的 Python 包，依据 `requirements.txt` 文件。最后，`ENTRYPOINT` 命令通过运行
    `streamlit run main.py` 启动 Streamlit 应用程序，并指定服务器端口和地址。
- en: 'To build the image locally, type the following:'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要在本地构建镜像，请输入以下命令：
- en: '[PRE11]'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Remember to change `<YOUR_USERNAME>` to your actual Docker Hub username. Then,
    push the image with the following:'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 记得将 `<YOUR_USERNAME>` 替换成你实际的 Docker Hub 用户名。然后，使用以下命令推送镜像：
- en: '[PRE12]'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Remember that this image is going to be publicly available on Docker Hub. Don’t
    put any authentication credentials or sensitive data in the code or as environment
    variables!
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，这个镜像将在 Docker Hub 上公开可用。不要在代码中或作为环境变量放入任何认证凭据或敏感数据！
- en: Now, let’s deploy our application on Kubernetes.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，让我们在 Kubernetes 上部署我们的应用程序。
- en: Deploying the Streamlit app
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署 Streamlit 应用程序
- en: 'As we have seen before, to deploy our app on Kubernetes, we need a `Deployment`
    and a `Service` `.yaml` definition. We can provide both in a single file:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们之前所看到的，要在 Kubernetes 上部署我们的应用程序，我们需要一个 `Deployment` 和一个 `Service` `.yaml`
    定义。我们可以将两者合并到一个文件中：
- en: 'First, create a `deploy_chat_with_claude.yaml` file with this code:'
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，创建一个 `deploy_chat_with_claude.yaml` 文件，内容如下：
- en: '**deploy_chat_with_claude.yaml**'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '**deploy_chat_with_claude.yaml**'
- en: '[PRE13]'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The first part of the code defines a `Deployment` resource named `chat-with-claude`.
    It takes a previously built image (which you can change to your own new image)
    and opens port `8501` in the container to be accessed from outside the pod. The
    `spec.template.spec.containers.env` block mounts AWS credentials as environment
    variables in the container from a secret called `aws-credentials`.
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 代码的第一部分定义了一个名为 `chat-with-claude` 的 `Deployment` 资源。它使用一个预先构建的镜像（你可以将其更改为自己的新镜像），并在容器中打开
    `8501` 端口，供外部访问。`spec.template.spec.containers.env` 块会将 AWS 凭证作为环境变量挂载到容器中，这些凭证来自名为
    `aws-credentials` 的密钥。
- en: 'The second part of the code defines a `LoadBalancer` service for the pods defined
    in `Deployment`, which listens on port `8501` and directs traffic to port `8501`
    in the container. Don’t forget `---`, which is necessary to separate several resources
    in a single file:'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 代码的第二部分定义了一个 `LoadBalancer` 服务，为 `Deployment` 中定义的 pod 提供服务，该服务监听 `8501` 端口并将流量转发到容器中的
    `8501` 端口。别忘了 `---`，它是分隔多个资源的必需项：
- en: '[PRE14]'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Now, we are going to create the namespace and the secret and deploy the application
    with the following:'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将创建命名空间和密钥，并使用以下命令部署应用程序：
- en: '[PRE15]'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'That’s it. Wait a few minutes for `LoadBalancer` to be up and running and check
    its URL with the following:'
  id: totrans-96
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 就这些。等待几分钟，直到 `LoadBalancer` 启动并运行，然后使用以下命令检查其 URL：
- en: '[PRE16]'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: Now, paste the URL with `:8501` at the end to define the correct port *et voilà!*
    (*Figure 11**.4*).
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，粘贴带有 `:8501` 的 URL 以定义正确的端口，*瞧瞧！*（*图 11.4*）。
- en: '![Figure 11.4 – The Chat with Claude 3 app UI](img/B21927_11_04.jpg)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.4 – Chat with Claude 3 应用程序 UI](img/B21927_11_04.jpg)'
- en: Figure 11.4 – The Chat with Claude 3 app UI
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.4 – Chat with Claude 3 应用程序 UI
- en: Now, play a little bit with the assistant. Try Haiku and Sonnet and note their
    differences in speed and quality of answer. After a few shots, you will notice
    that asking specific questions to foundational models leads to a hallucination.
    Ask the model, for instance, who are you. You are going to have a nice surprise
    (and some laughs). This model needs context.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，和助手玩一玩。试试 Haiku 和 Sonnet，并注意它们在速度和回答质量上的差异。试几次之后，你会注意到，向基础模型提问特定问题会导致幻觉。比如问模型：“你是谁？”你会得到一个惊喜（还会笑出声）。这个模型需要上下文。
- en: In the next section, we will provide some context using RAG.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将使用 RAG 提供一些上下文。
- en: Building RAG with Knowledge Bases for Amazon Bedrock
  id: totrans-103
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用知识库构建 Amazon Bedrock 的 RAG
- en: RAG is a technique used in generative AI models to provide additional context
    and knowledge to foundational models during the generation process. It works by
    first retrieving relevant information from a knowledge base or corpus of documents,
    and then using this retrieved information to augment the input to the generative
    model.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 是一种用于生成 AI 模型的技术，通过在生成过程中为基础模型提供额外的上下文和知识。其工作原理是首先从知识库或文档语料库中检索相关信息，然后使用这些检索到的信息来增强输入到生成模型的内容。
- en: RAG is a good choice for giving context to generative AI models because it allows
    the model to access and utilize external knowledge sources, which can significantly
    improve the quality, accuracy, and relevance of the generated output. Without
    RAG, the model would be limited to the knowledge and patterns it learned during
    training, which may not always be sufficient or up to date, especially for domain-specific
    or rapidly evolving topics.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 是为生成 AI 模型提供上下文的良好选择，因为它允许模型访问并利用外部知识源，这可以显著提高生成输出的质量、准确性和相关性。如果没有 RAG，模型将仅限于在训练过程中学到的知识和模式，而这些可能并不总是充足或最新的，尤其是对于特定领域或快速发展的主题。
- en: One of the key advantages of RAG is that it enables the model to leverage large
    knowledge bases or document collections, which would be impractical or impossible
    to include in the model’s training data. This allows the model to generate more
    informed and knowledgeable outputs, as it can draw upon a vast amount of relevant
    information. Additionally, RAG can help mitigate issues such as hallucination
    and bias, as the model has access to authoritative and factual sources.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: RAG 的一个关键优势是它使模型能够利用大型知识库或文档集合，这些内容在模型的训练数据中包含是不现实或不可能的。这使得模型能够生成更为知情和专业的输出，因为它可以从大量相关信息中提取内容。此外，RAG
    有助于缓解如幻觉和偏见等问题，因为模型可以访问权威和事实性的来源。
- en: However, RAG also has some limitations. The quality of the generated output
    heavily depends on the relevance and accuracy of the retrieved information, which
    can be influenced by the quality of the knowledge base, the effectiveness of the
    retrieval mechanism, and the ability of the model to properly integrate the retrieved
    information. Additionally, RAG can introduce computational overhead and latency,
    as it requires an additional retrieval step before the generation process.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，RAG 也存在一些局限性。生成输出的质量在很大程度上依赖于检索信息的相关性和准确性，而这些因素会受到知识库质量、检索机制效果以及模型是否能够正确整合检索信息的影响。此外，RAG
    还可能带来计算开销和延迟，因为它需要在生成过程之前执行额外的检索步骤。
- en: To build an AI assistant with RAG, we will use the Knowledge Bases for Amazon
    Bedrock service, a feature in Bedrock that allows you to create and manage a knowledge
    base seamlessly. Let’s get to it.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用 RAG 构建 AI 助手，我们将使用亚马逊 Bedrock 服务中的知识库功能，这是 Bedrock 中允许你无缝创建和管理知识库的功能。让我们开始吧。
- en: 'For our exercise, we will build an AI assistant capable of giving information
    about the AWS Competency Program. A visual representation of this assistant’s
    architecture is shown in *Figure 11**.5*:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于我们的练习，我们将构建一个能够提供 AWS 能力计划信息的 AI 助手。该助手架构的视觉表示如 *图 11.5* 所示：
- en: '![Figure 11.5 – Knowledge Bases for Amazon Bedrock application architecture](img/B21927_11_05.jpg)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.5 – 亚马逊 Bedrock 应用架构的知识库](img/B21927_11_05.jpg)'
- en: Figure 11.5 – Knowledge Bases for Amazon Bedrock application architecture
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.5 – 亚马逊 Bedrock 应用架构的知识库
- en: The AWS Competency Program is a validation program offered by AWS that recognizes
    partners who have demonstrated technical proficiency and proven customer success
    in specialized solution areas. AWS Competencies are awarded to **AWS Partner Network**
    (**APN**) members who have undergone technical validation related to specific
    AWS services or workloads, ensuring they have the expertise needed to deliver
    consistent, high-quality solutions on AWS. These competencies span various areas
    such as DevOps, migration, data and analytics, machine learning, and security.
    Each competency has its own rules document and can be quite challenging to understand.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: AWS 能力计划是 AWS 提供的一个验证计划，旨在认可在特定解决方案领域中展示出技术熟练度和客户成功的合作伙伴。AWS 能力授予 **AWS 合作伙伴网络**
    (**APN**) 成员，这些成员经过与特定 AWS 服务或工作负载相关的技术验证，确保他们具备提供一致且高质量解决方案的专业能力。这些能力涵盖了 DevOps、迁移、数据与分析、机器学习和安全等多个领域。每个能力都有自己的规则文档，理解起来可能相当具有挑战性。
- en: 'First, we will gather some context information about the program. On GitHub,
    under the [*Chapter 11*](B21927_11.xhtml#_idTextAnchor167)`/claude-kb/knowledge-base/`
    folder, you will find a Python code that will gather information on conversational
    AI, data and analytics, DevOps, education, energy, financial services, machine
    learning, and security programs. After saving this code locally, install the Beautiful
    Soup library with the following:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们将收集一些有关该程序的上下文信息。在 GitHub 上的[*第 11 章*](B21927_11.xhtml#_idTextAnchor167)`/claude-kb/knowledge-base/`文件夹下，您将找到一段
    Python 代码，该代码将收集关于对话式 AI、数据与分析、DevOps、教育、能源、金融服务、机器学习和安全程序的信息。将此代码保存到本地后，使用以下命令安装
    Beautiful Soup 库：
- en: '[PRE17]'
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: After a few seconds, data should be saved locally on your machine.
  id: totrans-115
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 几秒钟后，数据应保存到您本地的机器上。
- en: Next, create an S3 bucket and upload these files. This will be the base for
    our RAG layer.
  id: totrans-116
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建一个 S3 存储桶并上传这些文件。这将成为我们 RAG 层的基础。
- en: Next, go to the **Bedrock** page in the AWS console. In the side menu, click
    on **Knowledge Bases** and then, click on **Create knowledge base** (*Figure 11**.6*).
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，进入 AWS 控制台中的**Bedrock**页面。在侧边菜单中，点击**知识库**，然后点击**创建知识库**（*图 11.6*）。
- en: '![Figure 11.6 – The Knowledge bases landing page](img/B21927_11_06.jpg)'
  id: totrans-118
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.6 – 知识库首页](img/B21927_11_06.jpg)'
- en: Figure 11.6 – The Knowledge bases landing page
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.6 – 知识库首页
- en: On the next page, choose a name for your knowledge base and select **Create
    and use a new service role** under the **IAM permissions** section. Then, click
    **Next**.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页面，选择一个名称为您的知识库，并在**IAM 权限**部分选择**创建并使用新服务角色**。然后，点击**下一步**。
- en: Next, you will configure the data source. Choose a data source name as you wish.
    For **Data source location**, make sure the **This AWS account** box option is
    checked. Then, in the **S3 URI** section, click on **Browse S3** to search for
    your S3 bucket that contains the AWS Competency datasets (the bucket we created
    in *Step 2*). An example of that configuration is shown in *Figure 11**.7*. After
    selecting the S3 bucket, click **Next**.
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，您将配置数据源。为**数据源名称**选择一个您喜欢的名称。对于**数据源位置**，确保选中了**此 AWS 账户**选项框。然后，在**S3 URI**部分，点击**浏览
    S3**，搜索包含 AWS Competency 数据集的 S3 存储桶（我们在*步骤 2*中创建的存储桶）。该配置的示例如*图 11.7*所示。选择 S3
    存储桶后，点击**下一步**。
- en: '![Figure 11.7 – Choosing a data source for the knowledge base](img/B21927_11_07.jpg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.7 – 选择知识库的数据源](img/B21927_11_07.jpg)'
- en: Figure 11.7 – Choosing a data source for the knowledge base
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.7 – 选择知识库的数据源
- en: Next, we are going to choose the embeddings model. This embeddings model is
    responsible for transforming text or image files into vector representations called
    **embeddings**. These embeddings capture the semantic and contextual information
    of the input data, allowing for efficient similarity comparisons and retrieval
    operations. One of Bedrock’s embeddings models, Amazon Titan, should be available
    by default. If it is not, do the same process of asking for access in the console.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将选择嵌入模型。此嵌入模型负责将文本或图像文件转换为称为**嵌入**的向量表示。这些嵌入捕捉输入数据的语义和上下文信息，从而支持高效的相似性比较和检索操作。默认情况下，Bedrock
    的嵌入模型 Amazon Titan 应该是可用的。如果不可用，请在控制台中按照相同的过程申请访问权限。
- en: On the next page, in the **Embeddings model** section, choose **Titan Embeddings
    G1 - Text**. In the **Vector database** section, make sure the **Quick create
    a new vector store** option is checked. This quick creation option creates a vector
    database based on OpenSearch Serverless. Leave the other options unmarked and
    click **Next**.
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页面的**嵌入模型**部分，选择**Titan Embeddings G1 - Text**。在**向量数据库**部分，确保选中了**快速创建新的向量存储**选项。此快速创建选项基于
    OpenSearch Serverless 创建一个向量数据库。将其他选项保持未选中状态，然后点击**下一步**。
- en: Note
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 注意
- en: OpenSearch is an open-source distributed search and analytics engine based on
    Apache Lucene and derived from Elasticsearch. It is a great option for a RAG vector
    database because it provides efficient full-text search and nearest-neighbor search
    capabilities for vector embeddings. OpenSearch supports dense vector indexing
    and retrieval, making it suitable for storing and querying large collections of
    vector embeddings, which are essential for the retrieval component of RAG models.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: OpenSearch 是一个开源分布式搜索与分析引擎，基于 Apache Lucene，并来源于 Elasticsearch。它是 RAG 向量数据库的一个优秀选择，因为它提供了高效的全文搜索和最近邻搜索功能，适用于向量嵌入的检索。OpenSearch
    支持稠密向量索引与检索，非常适合存储和查询大量的向量嵌入，这对于 RAG 模型的检索组件至关重要。
- en: Next, review the information to see whether it was correctly provided. If everything
    looks good, click on **Create knowledge base**. Be patient. This creation will
    take several minutes to complete.
  id: totrans-128
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，检查信息是否正确提供。如果一切看起来正常，点击**创建知识库**。请耐心等待，创建过程将需要几分钟才能完成。
- en: After the knowledge base is up and running, go back to the **Knowledge base**
    page in Bedrock and click on the knowledge base you just created. On the next
    page, scroll until you find the **Data source** section (as shown in *Figure 11**.8*).
    Select the data source and click **Sync** to start the embedding of the text content.
    This will also take a few minutes.
  id: totrans-129
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 知识库启动并运行后，返回Bedrock中的**知识库**页面，点击你刚创建的知识库。在下一个页面中，滚动直到找到**数据源**部分（如*图 11.8*所示）。选择数据源并点击**同步**，以开始嵌入文本内容。这也需要几分钟。
- en: '![Figure 11.8 – Syncing the knowledge base with its data source](img/B21927_11_08.jpg)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.8 – 同步知识库与其数据源](img/B21927_11_08.jpg)'
- en: Figure 11.8 – Syncing the knowledge base with its data source
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.8 – 同步知识库与其数据源
- en: After the “sync” is ready, we have everything we need to run our generative
    AI assistant with RAG. Now, it is time to adjust the code to let Claude work with
    the knowledge base.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 在“同步”准备好之后，我们已经具备了运行生成式AI助手与RAG所需的一切。现在，是时候调整代码，让Claude与知识库配合使用。
- en: Adjusting the code for RAG retrieval
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 调整RAG检索代码
- en: We will start from the code we developed earlier to work with the pure Claude
    model. As we just need some small modifications, we won’t go through the entire
    code again. We will take a closer look at the necessary modifications. The complete
    code for the RAG application is available at [https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/claude-kb/app](https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/claude-kb/app)
    folder. If you don’t want to customize your code, you can use the ready-to-go
    docker image I provided for this example.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从之前开发的代码开始，使用纯Claude模型。由于我们只需要进行一些小修改，因此不需要重新查看整个代码。我们将仔细看看必要的修改。RAG应用程序的完整代码可以在[https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/claude-kb/app](https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/claude-kb/app)文件夹中找到。如果你不想自定义代码，可以使用我为此示例提供的现成docker镜像。
- en: 'First, we need extra imports:'
  id: totrans-135
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要额外的导入：
- en: '[PRE18]'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: Here, we import the `os` library to get environment variables. The `Config`
    class will help build a configuration object to access the `bedrock-agent` API.
    All the other imports relate to accessing the knowledge base and merging the retrieved
    documents with AI responses.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这里，我们导入`os`库以获取环境变量。`Config`类将帮助构建一个配置对象，以访问`bedrock-agent` API。所有其他导入与访问知识库并将检索到的文档与AI响应合并有关。
- en: 'Next, we will get the ID for the Knowledge Bases for Amazon Bedrock service
    from an environment variable. This can be a very helpful approach. If we need
    to change the knowledge base in the future, there is no need to rebuild the image.
    We just change the environment variable. Then, we set some configurations and
    create a client for the `bedrock-agent-runtime` API (needed for the knowledge
    base):'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将从环境变量中获取Amazon Bedrock服务的知识库ID。这是一个非常有用的方法。如果将来需要更改知识库，就无需重新构建镜像，只需更改环境变量。然后，我们设置一些配置并为`bedrock-agent-runtime`
    API（用于知识库）创建一个客户端：
- en: '[PRE19]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Next, we will configure a prompt template that will help us chain the retrieved
    documents from the knowledge base and the user questions. At the end, we instantiate
    an object that will hold the template and receive the documents and the user questions
    as inputs:'
  id: totrans-140
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将配置一个提示模板，帮助我们将从知识库中检索的文档与用户问题串联起来。最后，我们将实例化一个对象，该对象将保存模板，并接收文档和用户问题作为输入：
- en: '[PRE20]'
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After setting the `choose_model()` function, we need to instantiate a `retriever`
    class that will pull documents from the knowledge base:'
  id: totrans-142
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 设置完`choose_model()`函数后，我们需要实例化一个`retriever`类，用于从知识库中拉取文档：
- en: '[PRE21]'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Now, inside the `main` function, we will add `RetrievalQA`. This class is used
    for building question-answering systems that can retrieve relevant information
    from the knowledge base:'
  id: totrans-144
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在`main`函数中，我们将添加`RetrievalQA`。这个类用于构建能够从知识库中检索相关信息的问答系统：
- en: '[PRE22]'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'Finally, we will modify the response to give the entire answer:'
  id: totrans-146
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，我们将修改响应以提供完整的答案：
- en: '[PRE23]'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE23]'
- en: That’s it. The code is ready to be built in a new image. You can rebuild it
    by creating a new Dockerfile with the same code we used before. When running the
    `docker build` command, remember to choose a different image name (or, at least,
    a different version).
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 就这样。代码已经准备好，可以构建新的镜像。你可以通过创建一个新的 Dockerfile，使用之前的代码重新构建它。在运行 `docker build`
    命令时，记得选择一个不同的镜像名称（或者至少选择一个不同的版本）。
- en: 'Next, we will start the deployment. The `.yaml` file is also very similar to
    the one we did in the last section (but remember to change all the names for the
    deployment, services, container, and label to `rag-with-claude`). A full version
    of this code is available in the GitHub repository). We only need to declare the
    environment variable for the knowledge base ID. As this is not a sensitive credential,
    we don’t need to use a Kubernetes secret for that. We will use `ConfigMap`. The
    `spec.template.spec.container.env` section of your `.yaml` file should look like
    this:'
  id: totrans-149
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将开始部署。`.yaml` 文件与上一节中的文件非常相似（但记得更改部署、服务、容器和标签的所有名称为 `rag-with-claude`）。该代码的完整版可在
    GitHub 仓库中找到。我们只需声明知识库 ID 的环境变量。由于这不是敏感凭证，因此我们不需要使用 Kubernetes 秘密来处理它。我们将使用 `ConfigMap`。`.yaml`
    文件中的 `spec.template.spec.container.env` 部分应该如下所示：
- en: '[PRE24]'
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE24]'
- en: Note that we added a new environment variable called `KB_ID` that will be imported
    from `ConfigMap`.
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 注意，我们添加了一个新的环境变量 `KB_ID`，它将从 `ConfigMap` 导入。
- en: 'To deploy the new application, we run the following:'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 要部署新应用程序，我们运行以下命令：
- en: '[PRE25]'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'We run the preceding to deploy the application. Wait a few minutes for `LoadBalancer`
    to be up and use the following command:'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们运行前面的命令来部署应用程序。等待几分钟，直到 `LoadBalancer` 启动，然后使用以下命令：
- en: '[PRE26]'
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Use the preceding command to get the URL for `LoadBalancer`. Copy and paste
    the service named `rag-with-claude` in a browser and add `:8501` to connect to
    the exposed port. *Et voilà!* You should see your new application running as shown
    in *Figure 11**.9*.
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用前面的命令获取 `LoadBalancer` 的 URL。将名为 `rag-with-claude` 的服务复制并粘贴到浏览器中，并添加 `:8501`
    以连接到暴露的端口。*瞧！* 你应该能看到新应用程序在运行，正如*图 11.9* 所示。
- en: '![Figure 11.9 – RAG application UI](img/B21927_11_09.jpg)'
  id: totrans-157
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.9 – RAG 应用 UI](img/B21927_11_09.jpg)'
- en: Figure 11.9 – RAG application UI
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.9 – RAG 应用 UI
- en: Try to play a little bit with this application. You will see that if you ask
    questions not related to its scope (AWS Competency program), the assistant will
    say it cannot answer.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试稍微玩一下这个应用程序。你会发现，如果你提问与其范围无关的问题（如 AWS 能力计划以外的内容），助手会告诉你它无法回答。
- en: Now, we will move to the final part of this chapter and learn how to make generative
    AI models execute actions with agents.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们将进入本章的最后部分，学习如何让生成性 AI 模型通过代理执行操作。
- en: Building action models with agents
  id: totrans-161
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用代理构建行动模型
- en: Agents are the newest feature in the generative AI world. They are powerful
    tools that enable the automation of tasks by allowing generative AI models to
    take actions on our behalf. They act as intermediaries between the generative
    AI models and external systems or services, facilitating the execution of tasks
    in the real world.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 代理是生成性 AI 世界中最新的功能。它们是强大的工具，通过允许生成性 AI 模型代表我们执行任务，实现了任务的自动化。它们充当生成性 AI 模型与外部系统或服务之间的中介，促进了现实世界任务的执行。
- en: Under the hood, an agent “understands” what the user wants and calls a backend
    function that performs the action. The scope within which the agent can act is
    defined by an OpenAPI schema that it will use both to “understand” what it does
    and how to properly call the backend function.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 在后台，代理“理解”用户的需求，并调用执行操作的后端函数。代理能够执行的范围由 OpenAPI 架构定义，它将用于“理解”它的功能以及如何正确调用后端函数。
- en: So, in summary, to build an agent we need an OpenAPI schema, a backend function,
    and a knowledge base. The knowledge base is optional, but it can greatly improve
    a user’s experience with the AI assistant.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，要构建一个代理，我们需要一个 OpenAPI 架构、一个后端函数和一个知识库。知识库是可选的，但它能大大提升用户与 AI 助手的交互体验。
- en: For this section’s exercise, we will build an agent that “knows” the available
    information about the AWS Competency program. A visual representation of the agent’s
    application architecture is shown in *Figure 11**.10*.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节的练习中，我们将构建一个“了解” AWS 能力计划相关信息的代理。该代理的应用架构的可视化表示如*图 11.10*所示。
- en: '![Figure 11.10 – Agent application architecture](img/B21927_11_10.jpg)'
  id: totrans-166
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.10 – 代理应用架构](img/B21927_11_10.jpg)'
- en: Figure 11.10 – Agent application architecture
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.10 – 代理应用架构
- en: 'This agent is going to build a simple worksheet with a use case’s information,
    save the worksheet to Amazon S3, and register the information on a DynamoDB table
    for consultation. Let’s get to it:'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这个代理将创建一个简单的工作表，包含用例信息，将工作表保存到 Amazon S3，并在 DynamoDB 表中注册该信息以供查询。我们开始吧：
- en: First, we need an OpenAPI schema defining the methods available for our agent.
    In this case, we will define two methods. The first one, `generateCaseSheet`,
    registers the use case information and builds the worksheet. The second, `checkCase`,
    takes the use case ID and returns information about it. As this is a long JSON
    file, we will not display it here. The complete code is available at [https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent](https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent)
    folder. Copy this code and save it in an S3 bucket.
  id: totrans-169
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，我们需要一个 OpenAPI 模式，定义代理可用的方法。在这种情况下，我们将定义两个方法。第一个方法 `generateCaseSheet` 注册用例信息并创建工作表。第二个方法
    `checkCase` 接收用例 ID 并返回相关信息。由于这是一个较长的 JSON 文件，我们不会在此展示。完整的代码可以在 [https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent](https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent)
    文件夹中找到。复制这段代码并将其保存在 S3 桶中。
- en: 'Next, we will define a Lambda function that will serve as a backend for the
    agent. The complete Python code for the function is available in the book’s GitHub
    repository under the [*Chapter 11*](B21927_11.xhtml#_idTextAnchor167)`/agent/function`
    folder. In your machine, create a folder named `function` and save this code as
    `lambda_function.py` in the `function` folder. This code defines a Lambda function
    that serves as the backend for a Bedrock agent. The function handles two different
    API paths: `/generateCaseSheet` and `/checkCase`. Let’s go through the code block
    by block. After importing the necessary folders, we define two helper functions
    to extract parameter values from the event object (`get_named_parameter` and `get_named_property`).
    The `generateCaseSheet` function is responsible for creating a new case sheet
    based on the provided information. It extracts the required parameters from the
    event object, generates a unique ID, creates a new Excel workbook using the `CaseTemplate`
    class, fills in the template with the provided parameters, saves the workbook
    to a temporary file, uploads it to an S3 bucket, and stores the case sheet information
    in a DynamoDB table. Finally, it returns a response object containing the case
    details. The `checkCase` function retrieves the case sheet information from the
    DynamoDB table based on the provided `caseSheetId` parameter and returns a response
    object containing the case details. The `lambda_handler` function is the entry
    point for the Lambda function. It determines the appropriate action based on the
    `apiPath` value in the event object. The function constructs the appropriate response
    object based on the action and returns it.'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将定义一个 Lambda 函数，作为代理的后端。该函数的完整 Python 代码可以在书籍的 GitHub 仓库中找到，位于 [*第 11 章*](B21927_11.xhtml#_idTextAnchor167)`/agent/function`
    文件夹中。在你的机器上，创建一个名为 `function` 的文件夹，并将此代码保存为 `lambda_function.py`。这段代码定义了一个 Lambda
    函数，作为 Bedrock 代理的后端。该函数处理两个不同的 API 路径：`/generateCaseSheet` 和 `/checkCase`。让我们逐块分析这段代码。在导入必要的文件夹之后，我们定义了两个辅助函数，从事件对象中提取参数值（`get_named_parameter`
    和 `get_named_property`）。`generateCaseSheet` 函数负责根据提供的信息创建一个新的用例表格。它从事件对象中提取所需的参数，生成一个唯一的
    ID，使用 `CaseTemplate` 类创建一个新的 Excel 工作簿，将提供的参数填充到模板中，保存工作簿到临时文件，上传到 S3 桶，并将用例信息存储到
    DynamoDB 表中。最后，它返回一个包含用例详情的响应对象。`checkCase` 函数根据提供的 `caseSheetId` 参数从 DynamoDB
    表中检索用例表格信息，并返回一个包含用例详情的响应对象。`lambda_handler` 函数是 Lambda 函数的入口点，它根据事件对象中的 `apiPath`
    值决定执行的操作。该函数根据操作构建相应的响应对象并返回。
- en: Next, inside the `function` folder, create a new file called `lambda_requirements.txt`
    where we will list the dependencies for the Lambda function code. In the `lambda_requirements.txt`
    file, type `openpyxl==3.0.10` and save it.
  id: totrans-171
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在 `function` 文件夹中，创建一个名为 `lambda_requirements.txt` 的新文件，在其中列出 Lambda 函数代码的依赖项。在
    `lambda_requirements.txt` 文件中输入 `openpyxl==3.0.10` 并保存。
- en: Now, before deploying the function, we need to create an IAM role that will
    give Lambda the necessary permissions. On the AWS console, go to the IAM page,
    choose **Roles** in the side menu, and click on **Create a** **new role**.
  id: totrans-172
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在部署该函数之前，我们需要创建一个 IAM 角色，授予 Lambda 所需的权限。在 AWS 控制台中，进入 IAM 页面，选择侧边菜单中的 **角色**，然后点击
    **创建新角色**。
- en: On the next page, select **AWS service** for the **Trusted entity type** and
    **Lambda** for the **Use case** (as shown in *Figure 11**.11*). Click **Next**.
  id: totrans-173
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页，选择**AWS服务**作为**受信实体类型**，并选择**Lambda**作为**使用案例**（如*图11.11*所示）。点击**下一步**。
- en: '![Figure 11.11 – Selecting trusted entity and AWS service](img/B21927_11_11.jpg)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![图11.11 – 选择受信实体和AWS服务](img/B21927_11_11.jpg)'
- en: Figure 11.11 – Selecting trusted entity and AWS service
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.11 – 选择受信实体和AWS服务
- en: Now, we will select a permission policy. Choose **Administrator Access** and
    click **Next**. Remember that having such open permissions is *not* a good practice
    for production environments. You should set permissions only for the actions and
    resources needed.
  id: totrans-176
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将选择权限策略。选择**Administrator Access**并点击**下一步**。记住，拥有这样的开放权限在生产环境中*不是*一个好做法。你应该仅为所需的操作和资源设置权限。
- en: Then, choose a name for your IAM role (`BDOK-Lambda-service-role`, for instance)
    and click on **Create role**.
  id: totrans-177
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，为你的IAM角色选择一个名称（例如`BDOK-Lambda-service-role`），并点击**创建角色**。
- en: Then, you will see the IAM **Roles** page again. Search for your created role
    and click on it (*Figure 11**.12*).
  id: totrans-178
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，你将再次看到IAM **角色**页面。搜索你创建的角色并点击它（*图11.12*）。
- en: '![Figure 11.12 – Selecting your created IAM role](img/B21927_11_12.jpg)'
  id: totrans-179
  prefs: []
  type: TYPE_IMG
  zh: '![图11.12 – 选择你创建的IAM角色](img/B21927_11_12.jpg)'
- en: Figure 11.12 – Selecting your created IAM role
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.12 – 选择你创建的IAM角色
- en: On the role’s page, you will see the **Amazon Resource Name** (**ARN**) of the
    role. Copy it and save it for later. We will need that name to deploy the Lambda
    function.
  id: totrans-181
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在角色页面，你将看到角色的**Amazon资源名称**（**ARN**）。复制并保存它，稍后我们将需要这个名称来部署Lambda函数。
- en: Next, inside the `function` folder you created, create a new folder called `worksheet`.
    Copy two files from [https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent/function/worksheet](https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent/function/worksheet),
    the first named `__init__.py` and the second named `template.py` and place those
    code files inside the `worksheet` folder. This code contains a class named `CaseTemplate`
    that builds an Excel worksheet with the `openpyxl` Python library.
  id: totrans-182
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在你创建的`function`文件夹内，创建一个名为`worksheet`的新文件夹。从[https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent/function/worksheet](https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent/function/worksheet)复制两个文件，第一个命名为`__init__.py`，第二个命名为`template.py`，将这些代码文件放入`worksheet`文件夹中。这段代码包含一个名为`CaseTemplate`的类，它使用`openpyxl`
    Python库构建一个Excel工作表。
- en: Next, copy another two files in [https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent/scripts](https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent/scripts)
    folder named `build_lambda_package.sh` and `create_lambda_function.sh`. Those
    files contain bash code that will install the dependencies for the Lambda function
    and deploy it to AWS.
  id: totrans-183
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，复制[https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent/scripts](https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent/scripts)文件夹中的另外两个文件，分别命名为`build_lambda_package.sh`和`create_lambda_function.sh`。这些文件包含bash代码，将为Lambda函数安装依赖项并将其部署到AWS。
- en: 'Now, we will deploy our Lambda function. This is a good time to check whether
    your project structure is correct. The folder and file structure should look like
    this:'
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，我们将部署Lambda函数。这是检查项目结构是否正确的好时机。文件夹和文件结构应该如下所示：
- en: '[PRE27]'
  id: totrans-185
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: sh build_lambda_package.sh
  id: totrans-186
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: sh build_lambda_package.sh
- en: sh create_lambda_function.sh "<YOUR_ROLE_ARN>"
  id: totrans-187
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: sh create_lambda_function.sh "<YOUR_ROLE_ARN>"
- en: '[PRE28]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE28]'
- en: Remember to change `<YOUR_ROLE_ARN>` to the actual ARN of your Lambda IAM role.
    Now, we have some more work to do. Next, we will create the DynamoDB table to
    store information about the use cases.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 记得将`<YOUR_ROLE_ARN>`替换为你实际的Lambda IAM角色ARN。现在，我们还有一些工作要做。接下来，我们将创建DynamoDB表格，用于存储关于使用案例的信息。
- en: Creating a DynamoDB table
  id: totrans-190
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 创建DynamoDB表
- en: 'DynamoDB is a fully managed NoSQL database service. It is a key-value and document
    database that can deliver single-digit millisecond performance at any scale. DynamoDB
    is optimized for running serverless applications and is designed to scale up or
    down automatically to meet demand, without having to provision or manage servers.
    It is particularly well suited for applications that need low-latency read and
    write access to data at any scale. Its extremely low latency makes it a very good
    choice for an AI assistant application. Let’s get to it:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: DynamoDB是一个完全托管的NoSQL数据库服务。它是一个键值和文档数据库，可以在任何规模下提供单数毫秒级的性能。DynamoDB已针对运行无服务器应用进行了优化，并且设计上能够根据需求自动向上或向下扩展，无需预配置或管理服务器。它特别适合需要在任何规模下对数据进行低延迟读写访问的应用程序。其极低的延迟使其成为AI助手应用程序的一个非常好的选择。让我们开始吧：
- en: In the AWS console, navigate to the **DynamoDB** page. In the side menu, click
    on **Tables** and then, click on **Create table**.
  id: totrans-192
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在AWS控制台中，导航到**DynamoDB**页面。在侧边菜单中，点击**表格**，然后点击**创建表格**。
- en: On the next page, fill in `case-sheets` and the `caseSheetId`. Remember to select
    **Number** to indicate that this entry is a number, as shown in *Figure 11**.13*.
    Leave all the other configurations to default and click **Create table**.
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页中，填写`case-sheets`和`caseSheetId`。记得选择**数字**，表示此条目为数字，如*图11.13*所示。将所有其他配置保留为默认，然后点击**创建表格**。
- en: '![Figure 11.13 – Creating a DynamoDB table](img/B21927_11_13.jpg)'
  id: totrans-194
  prefs: []
  type: TYPE_IMG
  zh: '![图11.13 – 创建DynamoDB表格](img/B21927_11_13.jpg)'
- en: Figure 11.13 – Creating a DynamoDB table
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.13 – 创建DynamoDB表格
- en: In a few seconds, you should have your DynamoDB table ready for use. Now, we
    will configure the Bedrock agent.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 几秒钟后，你应该能够看到已准备好的DynamoDB表格。现在，我们将配置Bedrock代理。
- en: Configuring the agent
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 配置代理
- en: 'Now, in the last part of this section, we will configure a Bedrock agent and
    link it to its backend Lambda function and the knowledge base database. Let’s
    get to it:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，在本节的最后部分，我们将配置一个Bedrock代理，并将其链接到其后端Lambda函数和知识库数据库。让我们开始吧：
- en: First, in the AWS console, search for `Bedrock` and, in the side menu, click
    on **Agents**.
  id: totrans-199
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，在AWS控制台中，搜索`Bedrock`，然后在侧边菜单中点击**代理**。
- en: In the pop-up box, enter the name of your agent (`aws-competency-agent`) and
    click on **Create**.
  id: totrans-200
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在弹出框中，输入你的代理名称（`aws-competency-agent`），然后点击**创建**。
- en: Next, you will see the agent configuration page. Scroll down to **Select model**
    and choose the Anthropic model **Claude 3 Haiku** (you can also play with the
    other available models as you like).
  id: totrans-201
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，你将看到代理配置页面。滚动到**选择模型**，然后选择Anthropic模型**Claude 3 Haiku**（你也可以根据需要尝试其他可用的模型）。
- en: In the `You are a friendly AI assistant. Your main goal is to help AWS partner
    companies build case sheets for the AWS Competency program, register those cases,
    and tell the user the information about the registered cases. When you generate
    a case sheet, always show back to the user the ID of the case sheet (id), the
    client's name (client), and the name of the case (casename) and confirm that the
    case was successfully created. Also, answer the questions of the user about what
    you can do and how you can help.` This is a very important part of the agent configuration.
    Play with these instructions as much as you like. An example of this screen is
    shown in *Figure 11**.14*.
  id: totrans-202
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`你是一个友好的AI助手。你的主要目标是帮助AWS合作伙伴公司为AWS能力认证计划创建案例表格，注册这些案例，并向用户提供已注册案例的信息。当你生成案例表格时，总是要向用户展示案例表格的ID（id）、客户的名称（client）和案例名称（casename），并确认案例已成功创建。同时，回答用户关于你能做什么以及如何帮助他们的问题。`
    这是代理配置中非常重要的一部分。可以根据这些指令进行多次操作。此屏幕的示例如*图11.14*所示。
- en: '![Figure 11.14 – Configuring the agent’s instructions](img/B21927_11_14.jpg)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![图11.14 – 配置代理的指令](img/B21927_11_14.jpg)'
- en: Figure 11.14 – Configuring the agent’s instructions
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.14 – 配置代理的指令
- en: After that, click on the **Save** button at the top of the page to make AWS
    create the necessary permission policy.
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 之后，点击页面顶部的**保存**按钮，让AWS创建必要的权限策略。
- en: Next, scroll down to the **Action groups** section and click on **Add**.
  id: totrans-206
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，滚动到**操作组**部分，点击**添加**。
- en: On the next page, select a name for your action group. For **Action group type**,
    select **Define with API schemas**. In **Action group invocation**, select **Select
    an existing Lambda function** and select the Lambda function we just created (*Figure
    11**.15*).
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页中，为你的操作组选择一个名称。对于**操作组类型**，选择**使用API模式定义**。在**操作组调用**中，选择**选择一个现有的Lambda函数**，然后选择我们刚才创建的Lambda函数（*图11.15*）。
- en: '![Figure 11.15 – Selecting a Lambda function for the agent’s action group](img/B21927_11_15.jpg)'
  id: totrans-208
  prefs: []
  type: TYPE_IMG
  zh: '![图11.15 – 为代理的操作组选择Lambda函数](img/B21927_11_15.jpg)'
- en: Figure 11.15 – Selecting a Lambda function for the agent’s action group
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.15 – 为代理的操作组选择Lambda函数
- en: Now, in the **Action group schema** section, choose **Select an existing API
    schema** and then, click on **Browse S3** to search for the OpenAPI schema we
    have saved on S3 (*Figure 11**.16*). Then, click on **Create**.
  id: totrans-210
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，在**操作组架构**部分，选择**选择现有API架构**，然后点击**浏览S3**，搜索我们保存在S3上的OpenAPI架构（*图11.16*）。然后，点击**创建**。
- en: '![Figure 11.16 – Selecting the OpenAPI schema](img/B21927_11_16.jpg)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![图11.16 – 选择OpenAPI架构](img/B21927_11_16.jpg)'
- en: Figure 11.16 – Selecting the OpenAPI schema
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.16 – 选择OpenAPI架构
- en: Next, in the **Knowledge base** section, click on **Add**.
  id: totrans-213
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，在**知识库**部分，点击**添加**。
- en: 'Select the knowledge base we have created before and type some instructions
    for the agent on how to use it. For instance: `This knowledge base contains information
    on the following AWS Competency programs: conversational AI, data and analytics,
    DevOps, education, energy, financial services, machine learning, and security`.
    Make sure **Knowledge base status** is set to **Enabled** (*Figure 11**.17*).
    Click **Save** **and exit**.'
  id: totrans-214
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 选择我们之前创建的知识库，并为代理输入一些使用说明。例如：`此知识库包含以下AWS能力程序的信息：对话式AI、数据与分析、DevOps、教育、能源、金融服务、机器学习和安全`。确保**知识库状态**设置为**启用**（*图11.17*）。点击**保存**
    **并退出**。
- en: '![Figure 11.17 – Attaching a knowledge base to the agent](img/B21927_11_17.jpg)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![图11.17 – 将知识库附加到代理](img/B21927_11_17.jpg)'
- en: Figure 11.17 – Attaching a knowledge base to the agent
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.17 – 将知识库附加到代理
- en: Now, you are back to the agent’s editing page. Nothing else is needed here,
    so you can click on **Prepare** at the top to get your agent ready to run, and
    then click on **Save** **and exit**.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您已返回到代理的编辑页面。这里不需要其他操作，所以您可以点击顶部的**准备**，使代理准备运行，然后点击**保存** **并退出**。
- en: Now, you will be led back to the agent’s main page. Scroll down to the **Aliases**
    section and click on **Create**.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，您将被带回代理的主页。向下滚动到**别名**部分并点击**创建**。
- en: Type in an alias name (`aws-competency`, for instance) and click on **Create
    Alias**.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 输入一个别名名称（例如`aws-competency`），然后点击**创建别名**。
- en: '![Figure 11.18 – Creating an alias](img/B21927_11_18.jpg)'
  id: totrans-220
  prefs: []
  type: TYPE_IMG
  zh: '![图11.18 – 创建别名](img/B21927_11_18.jpg)'
- en: Figure 11.18 – Creating an alias
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.18 – 创建别名
- en: Now, the last thing to do is register a permission on Lambda for this agent
    to trigger the function execution. On the agent’s main page, copy the agent ARN.
  id: totrans-222
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，最后一步是为Lambda注册一个权限，以便这个代理能够触发函数执行。在代理的主页上，复制代理ARN。
- en: Next, go to the **Lambda** page and click on the function we created for this
    exercise. On the function’s main page, scroll down, click on **Configuration**,
    and then click on **Permissions** in the side menu (*Figure 11**.19*).
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，转到**Lambda**页面，点击我们为此练习创建的函数。在函数的主页上，向下滚动，点击**配置**，然后点击侧边菜单中的**权限**（*图11.19*）。
- en: '![Figure 11.19 – Lambda permissions](img/B21927_11_19.jpg)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![图11.19 – Lambda权限](img/B21927_11_19.jpg)'
- en: Figure 11.19 – Lambda permissions
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.19 – Lambda权限
- en: Scroll down again to the **Resource-based policy statements** section and click
    on **Add permissions**.
  id: totrans-226
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 再次向下滚动到**基于资源的策略声明**部分，点击**添加权限**。
- en: On the next page, fill in the `lambda:InvokeFunction` (*Figure 11**.20*). Then,
    click on **Save**.
  id: totrans-227
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在下一页中，填写`lambda:InvokeFunction`（*图11.20*）。然后，点击**保存**。
- en: '![Figure 11.20 – Configuring the Lambda permission for the Bedrock agent](img/B21927_11_20.jpg)'
  id: totrans-228
  prefs: []
  type: TYPE_IMG
  zh: '![图11.20 – 配置Bedrock代理的Lambda权限](img/B21927_11_20.jpg)'
- en: Figure 11.20 – Configuring the Lambda permission for the Bedrock agent
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.20 – 配置Bedrock代理的Lambda权限
- en: That’s all the configuration we need to get the agent running. Now, it’s time
    for deployment. Let’s get our Streamlit application to Kubernetes.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是我们让代理运行所需的所有配置。现在，是时候进行部署了。让我们把Streamlit应用程序部署到Kubernetes上。
- en: Deploying the application on Kubernetes
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在Kubernetes上部署应用程序
- en: 'Deploying the agent Streamlit application on Kubernetes follows the same path
    we did for the other two applications deployed before. The only thing different
    is that we must create a new `configmap` with the agent’s ID and its alias ID:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kubernetes上部署代理Streamlit应用程序遵循与之前部署的其他两个应用程序相同的路径。唯一不同的是我们必须创建一个新的`configmap`，并包含代理的ID及其别名ID：
- en: Go to the **Agent** page in the AWS console and copy the agent’s ID (in the
    top section) and the alias ID (in the bottom section).
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 进入 AWS 控制台中的**代理**页面，复制代理的 ID（位于顶部区域）和别名 ID（位于底部区域）。
- en: 'Now, create `configmap` with those parameters with the following command:'
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，使用以下命令创建带有这些参数的 `configmap`：
- en: '[PRE29]'
  id: totrans-235
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE29]'
- en: Remember to replace the `<YOUR_ALIAS_ID>` and `<YOUR_AGENT_ID>` placeholders
    with the actual values.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 记得将 `<YOUR_ALIAS_ID>` 和 `<YOUR_AGENT_ID>` 占位符替换为实际值。
- en: Build a custom image if you want to customize the application. If you don’t,
    use the ready image from DockerHub ([https://hub.docker.com/r/neylsoncrepalde/chat-with-claude-agent](https://hub.docker.com/r/neylsoncrepalde/chat-with-claude-agent)).
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你想自定义应用程序，可以构建一个自定义镜像。如果不想，可以使用来自 DockerHub 的现成镜像（[https://hub.docker.com/r/neylsoncrepalde/chat-with-claude-agent](https://hub.docker.com/r/neylsoncrepalde/chat-with-claude-agent)）。
- en: Next, we will define a `deploy_agent.yaml` file for the application and service
    deployment. The content for this file is available at [https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent](https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent)
    folder.
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将为应用程序和服务部署定义一个 `deploy_agent.yaml` 文件。该文件的内容可以在 [https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent](https://github.com/PacktPublishing/Bigdata-on-Kubernetes/tree/main/Chapter11/agent)
    文件夹中找到。
- en: 'With this file copied locally, now run the following:'
  id: totrans-239
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将此文件复制到本地后，现在运行以下命令：
- en: '[PRE30]'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Wait for a few seconds for `LoadBalancer` to get started. Then, run the following
    to get the URL of `LoadBalancer`:'
  id: totrans-241
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等待几秒钟，直到 `LoadBalancer` 启动完成。然后，运行以下命令以获取 `LoadBalancer` 的 URL：
- en: '[PRE31]'
  id: totrans-242
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE31]'
- en: Paste it in a browser adding the correct port (`:8501`) to see the magic happening
    (*Figure 11**.21*).
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将其粘贴到浏览器中，并添加正确的端口（`:8501`），查看魔法的发生（*图 11.21*）。
- en: '![Figure 11.21 – AWS Competency agent application UI](img/B21927_11_21.jpg)'
  id: totrans-244
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.21 – AWS 能力代理应用程序 UI](img/B21927_11_21.jpg)'
- en: Figure 11.21 – AWS Competency agent application UI
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.21 – AWS 能力代理应用程序 UI
- en: Try inserting a prompt for the creation of a new use case as in *Figure 11**.18*.
    Also, you can check specific information about this case passing the case’s ID
    (*Figure 11**.22*).
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试插入一个用于创建新用例的提示，如*图 11.18*所示。同时，你也可以通过传递用例的 ID 来查看该用例的具体信息（*图 11.22*）。
- en: '![Figure 11.22 – Checking use case information with the agent](img/B21927_11_22.jpg)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
  zh: '![图 11.22 – 使用代理检查用例信息](img/B21927_11_22.jpg)'
- en: Figure 11.22 – Checking use case information with the agent
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.22 – 使用代理检查用例信息
- en: Play a little bit. Ask questions about the Competency program and try registering
    different cases. Also, you can check AWS DynamoDB and see the information ingested
    in our created table and check S3 to see the Excel files the agent created.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 玩一玩。提出关于能力计划的问题，尝试注册不同的用例。同时，你也可以检查 AWS DynamoDB，查看我们创建的表中摄取的信息，并查看 S3 中代理创建的
    Excel 文件。
- en: That is it! Congratulations! You have just deployed a full generative AI agent
    application that can perform tasks for you using natural language on Kubernetes.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这样！恭喜你！你刚刚部署了一个完整的生成式 AI 代理应用程序，它可以通过自然语言在 Kubernetes 上为你执行任务。
- en: Summary
  id: totrans-251
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: In this chapter, we explored the exciting world of generative AI and learned
    how to harness its power on Kubernetes. We started by understanding the fundamental
    concepts of generative AI, its underlying mechanisms, and how it differs from
    traditional machine learning approaches.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们探索了生成式 AI 的激动人心的世界，并学习了如何在 Kubernetes 上利用其力量。我们首先了解了生成式 AI 的基本概念、其底层机制以及它与传统机器学习方法的区别。
- en: We then leveraged Amazon Bedrock, a comprehensive suite of services, to build
    and deploy generative AI applications. We learned how to work with Bedrock’s foundational
    models, such as Claude 3 Haiku and Claude 3 Sonnet, and how to integrate them
    into a Streamlit application for interactive user experiences.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，我们利用 Amazon Bedrock，一个全面的服务套件，来构建和部署生成式 AI 应用程序。我们学习了如何使用 Bedrock 的基础模型，如
    Claude 3 Haiku 和 Claude 3 Sonnet，并将它们集成到 Streamlit 应用程序中，以提供交互式用户体验。
- en: Next, we delved into the concept of RAG, which combines the power of generative
    AI with external knowledge bases. We built a RAG system using Knowledge Bases
    for Amazon Bedrock, enabling our application to access and leverage vast amounts
    of structured data, improving the accuracy and relevance of the generated output.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们深入探讨了 RAG 的概念，它将生成式 AI 的强大功能与外部知识库相结合。我们使用 Amazon Bedrock 构建了一个 RAG 系统，使我们的应用程序能够访问和利用大量的结构化数据，从而提高生成输出的准确性和相关性。
- en: Finally, we explored Agents for Amazon Bedrock, a powerful feature that allows
    generative AI models to automate tasks and take actions on our behalf. We learned
    how to build an agent, define its capabilities through an OpenAPI schema, and
    create the underlying Lambda function that serves as the backend for our agent.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们探讨了 Amazon Bedrock 的代理功能，这是一个强大的特性，允许生成式 AI 模型自动化任务并代替我们采取行动。我们学习了如何构建代理，通过
    OpenAPI 架构定义其能力，并创建作为代理后台的 Lambda 函数。
- en: Throughout this chapter, we gained hands-on experience in building and deploying
    generative AI applications on Kubernetes. The skills and knowledge acquired in
    this chapter are invaluable in today’s rapidly evolving technological landscape.
    Generative AI is transforming industries and revolutionizing how we interact with
    and leverage AI. By mastering the tools and techniques presented in this chapter,
    you will be well equipped to build innovative and intelligent applications that
    can generate human-like content, leverage external knowledge sources, and automate
    tasks.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们通过实践经验学习了如何在 Kubernetes 上构建和部署生成式 AI 应用。通过本章获得的技能和知识，在当今快速发展的技术环境中具有不可估量的价值。生成式
    AI 正在改变各行各业，彻底革新我们与 AI 的互动方式及其应用。通过掌握本章中介绍的工具和技术，你将能够构建创新且智能的应用，生成类人内容，利用外部知识来源，并实现任务自动化。
- en: In the next chapter, we will discuss some important points needed for a production-ready
    Kubernetes environment, which we did not have space to discuss throughout the
    book.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章，我们将讨论一些构建生产就绪的 Kubernetes 环境所需的重要要点，这些内容由于篇幅原因在本书中未能展开。
