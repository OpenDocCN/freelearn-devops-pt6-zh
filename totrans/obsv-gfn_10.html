<html><head></head><body>
		<div id="_idContainer153">
			<h1 id="_idParaDest-192" class="chapter-number"><a id="_idTextAnchor204"/>10</h1>
			<h1 id="_idParaDest-193"><a id="_idTextAnchor205"/>Automation with Infrastructure as Code</h1>
			<p>This chapter will explore how to use <strong class="bold">Infrastructure as Code</strong> (<strong class="bold">IaC</strong>) tools to automate the management of the various components<a id="_idIndexMarker841"/> of the Grafana observability platform. We will focus on <strong class="bold">Ansible</strong>, <strong class="bold">Terraform</strong>, and <strong class="bold">Helm</strong>, which allow teams to manage<a id="_idIndexMarker842"/> many aspects<a id="_idIndexMarker843"/> of their systems repeatably<a id="_idIndexMarker844"/> and automatically. This chapter divides the platform into the <em class="italic">collection and processing</em> layer, the <em class="italic">storage</em> layer, and the <em class="italic">visualization</em> layer and will outline how to automate each of these components. This chapter will provide the technical tools to create an easy-to-manage and very scalable observability platform, and combined with the information in <a href="B18277_11.xhtml#_idTextAnchor218"><span class="No-Break"><em class="italic">Chapter 11</em></span></a>, you will be well placed to lead your organization in easily leveraging the power <span class="No-Break">of observability.</span></p>
			<p>In this chapter, we’re going to cover the following <span class="No-Break">main topics:</span></p>
			<ul>
				<li>Benefits of <span class="No-Break">automating Grafana</span></li>
				<li>Introducing the components of <span class="No-Break">observability systems</span></li>
				<li>Automating collection infrastructure with Helm <span class="No-Break">or Ansible</span></li>
				<li>Getting to grips with the <span class="No-Break">Grafana API</span></li>
				<li>Managing dashboards and alerts with Terraform <span class="No-Break">or Ansible</span></li>
			</ul>
			<h1 id="_idParaDest-194"><a id="_idTextAnchor206"/>Technical requirements</h1>
			<p>This chapter involves working with Ansible, Terraform, and Helm, and it is recommended that you install them before you start reading. The chapter will also discuss a couple of concepts that you should have at least a passing <span class="No-Break">familiarity with:</span></p>
			<ul>
				<li><span class="No-Break">Kubernetes objects</span></li>
				<li>The Kubernetes <span class="No-Break">operator pattern</span></li>
			</ul>
			<h1 id="_idParaDest-195"><a id="_idTextAnchor207"/>Benefits of automating Grafana</h1>
			<p>Observability tooling combines<a id="_idIndexMarker845"/> the collection, storage, and visualization of telemetry from many applications, infrastructure services, and other components of systems. Automation offers us a way of providing a testable, repeatable way of delivering these needs. Using industry-standard tools such as Helm, Ansible, and Terraform helps us maintain these systems in the long term. There are a lot of benefits to using automation, including <span class="No-Break">the following:</span></p>
			<ul>
				<li>It reduces the risks associated with <span class="No-Break">manual processes.</span></li>
				<li>Domain experts can provide automation for systems that developers interact with. This gives development teams confidence that they are using unfamiliar systems correctly. This knowledge comes in the <span class="No-Break">following forms:</span><ul><li>Data architecture <span class="No-Break">for telemetry</span></li><li>Repeatable <span class="No-Break">system architecture</span></li><li>Best practices for managing <span class="No-Break">data visualizations</span></li></ul></li>
				<li>By providing automation, domain experts are able to focus on higher-value work by letting teams self-serve using more straightforward and <span class="No-Break">user-friendly systems.</span></li>
				<li>It provides a golden path so development teams can adopt observability easily and quickly and spend more time focusing on <span class="No-Break">value-adding activities.</span></li>
				<li>It allows for easy scaling of best practices and operational processes. This is especially important for organizations that are growing, where a process that may work with a handful of teams does not scale to dozens <span class="No-Break">of teams.</span></li>
				<li>It ensures that cost information is <span class="No-Break">always attributable.</span></li>
			</ul>
			<p>Now that we’ve introduced why you would want to use automation, let’s have a look at the components that make up an observability platform so we can easily automate the different aspects of <span class="No-Break">the system.</span></p>
			<h1 id="_idParaDest-196"><a id="_idTextAnchor208"/>Introducing the components of observability systems</h1>
			<p>Observability systems consist<a id="_idIndexMarker846"/> of many components involved in producing, consuming, transforming, storing, and using data. Over the course of this chapter, we will split these components into four distinct systems to be clear about which aspect of observability platforms we are discussing. The different aspects of automation will be of interest to different audiences. The systems we will discuss are <span class="No-Break">as follows:</span></p>
			<ol>
				<li><strong class="bold">Data production systems</strong>: These are the systems that generate data. The applications, infrastructure, and even<a id="_idIndexMarker847"/> components of the data collection system will produce data. Let’s look at the <span class="No-Break">key features:</span><ul><li>These systems are managed by developers such as <em class="italic">Diego</em>, or by operations experts such as <em class="italic">Ophelia</em> (refer to <a href="B18277_01.xhtml#_idTextAnchor018"><em class="italic">Chapter 1</em></a> for details on <span class="No-Break">these personas).</span></li><li>These systems are tested as part of the application- or component-testing process. If a data schema is in use, this can be validated using a tool such as <span class="No-Break">JSON Schema.</span></li></ul></li>
				<li><strong class="bold">Data collection systems</strong>: These systems collect the logs, metrics, and traces generated by data-producing<a id="_idIndexMarker848"/> systems. They typically offer tools for transforming data. Their key features are <span class="No-Break">the following:</span><ul><li>These systems are often run by specialist operations teams, observability engineers, site reliability engineers, or <span class="No-Break">platform engineers</span></li><li>These systems are <span class="No-Break">provisioned infrastructure</span></li><li>Automation involves the use of IaC tools and static analysis tools (where available) to validate <span class="No-Break">the infrastructure</span></li></ul></li>
				<li><strong class="bold">Data storage systems</strong>: These are the systems that store<a id="_idIndexMarker849"/> data and make it searchable. If your observability platform leverages SaaS tools, these systems will be provided by your vendor. Loki, Prometheus, Mimir, and Tempo are all examples<a id="_idIndexMarker850"/> of storage systems. Some of the important features of these systems include <span class="No-Break">the following:</span><ul><li>These systems<a id="_idIndexMarker851"/> are often managed by dedicated third parties, but when they are managed within an organization, they will typically be managed by the same team as the data <span class="No-Break">collection system</span></li><li>These systems are <span class="No-Break">provisioned infrastructure</span></li><li>Automation involves the use of IaC to provision on-prem resources, or leverages SaaS tooling such as Grafana Labs with <span class="No-Break">IaC configuration</span></li></ul></li>
				<li><strong class="bold">Data visualization systems</strong>: These are the systems that allow users to search the data stored<a id="_idIndexMarker852"/> in the storage systems and produce visualizations, alerts, and other methods of understanding the data. Grafana is an example of a visualization system. The following are some important features<a id="_idIndexMarker853"/> of <span class="No-Break">such systems:</span><ul><li>The management of this layer is typically a shared responsibility. The developers and operators who manage a particular system should be empowered to take ownership of their dashboards. The team managing the collection and storage layers will typically be the team empowering the rest of <span class="No-Break">the organization.</span></li><li>These systems are <span class="No-Break">provisioned infrastructure.</span></li><li>Automation involves the use of IaC to provision on-prem resources, or leveraging SaaS tooling such as Grafana Labs, with <span class="No-Break">IaC configuration.</span></li></ul></li>
			</ol>
			<p>In this chapter, we will discuss systems <em class="italic">2</em>, <em class="italic">3</em>, and <em class="italic">4</em> in the preceding list. <em class="italic">System 1</em>, while important, is a very<a id="_idIndexMarker854"/> broad area and the automation strategies differ for different types of data producers. However, in most cases, teams can rely on the testing done by the libraries they consume, or the third-party systems <span class="No-Break">they run.</span></p>
			<p>Let’s start by looking at how we can use Terraform or Ansible to deploy data <span class="No-Break">collection systems.</span></p>
			<h1 id="_idParaDest-197"><a id="_idTextAnchor209"/>Automating collection infrastructure with Helm or Ansible</h1>
			<p>Automating the installation of the infrastructure<a id="_idIndexMarker855"/> used to collect telemetry<a id="_idIndexMarker856"/> is a critical piece of building a great observability platform. The tools<a id="_idIndexMarker857"/> to support this depend on the infrastructure<a id="_idIndexMarker858"/> you are deploying to. In this section, we will examine the installation of the <strong class="bold">OpenTelemetry Collector</strong> and <strong class="bold">Grafana Agent</strong> using the <span class="No-Break">following tools:</span></p>
			<ul>
				<li><strong class="bold">Helm</strong> is a tool for packaging and managing Kubernetes<a id="_idIndexMarker859"/> applications. A Helm chart contains all the configuration files for the various Kubernetes components needed for an application, and typically handles setting the variables for the application. We will be using Helm in a <span class="No-Break">Kubernetes environment.</span></li>
				<li><strong class="bold">Ansible</strong> is a tool for standardizing operations<a id="_idIndexMarker860"/> into repeatable playbooks. It uses simple YAML configuration files to define the actions to be taken and leverages OpenSSH to connect to the target servers on which the actions are to be taken. We’ll be using Ansible in a virtual or bare-metal environment, but it can be used to manage Kubernetes environments <span class="No-Break">as well.</span></li>
			</ul>
			<p class="callout-heading">Important note</p>
			<p class="callout">OpenTelemetry and Grafana both offer a Kubernetes operator, which can be installed using Helm. We will provide an overview of these tools <span class="No-Break">as well.</span></p>
			<p>Now let’s look at how we can use Helm and Ansible to automate the installation of the OpenTelemetry Collector and <span class="No-Break">Grafana Agent.</span></p>
			<h2 id="_idParaDest-198"><a id="_idTextAnchor210"/>Automating the installation of the OpenTelemetry Collector</h2>
			<p>In this book, we have been using<a id="_idIndexMarker861"/> the OpenTelemetry Collector to collect data from the OpenTelemetry demo application and send it into our Grafana instance. First, we’ll use the configuration we have already deployed to explore using the Helm chart made by OpenTelemetry to deploy the collector <a id="_idIndexMarker862"/>into a <span class="No-Break">Kubernetes cluster.</span></p>
			<h3>OpenTelemetry Collector Helm chart</h3>
			<p>We first installed the<a id="_idIndexMarker863"/> OpenTelemetry Helm chart in <a href="B18277_03.xhtml#_idTextAnchor063"><span class="No-Break"><em class="italic">Chapter 3</em></span></a>, and then updated the configuration in <em class="italic">Chapters 4</em>, <em class="italic">5</em>, and <em class="italic">6</em>. OpenTelemetry provides detailed information about the configuration options that are available in its Git repository <span class="No-Break">at </span><span class="No-Break">https://github.com/open-telemetry/opentelemetry-helm-charts/tree/main/charts/opentelemetry-collector</span><span class="No-Break">.</span></p>
			<p>Let’s look at the final configuration that we applied in <a href="B18277_06.xhtml#_idTextAnchor134"><span class="No-Break"><em class="italic">Chapter 6</em></span></a> and see how we configure the OTEL Helm chart. You can find this file in the Git repository <span class="No-Break">at </span><span class="No-Break"><strong class="source-inline">/chapter6/OTEL-Collector.yaml</strong></span><span class="No-Break">.</span></p>
			<p>The first configuration block we’ll look at is <strong class="source-inline">mode</strong>, which describes how the collector is going to be deployed in Kubernetes. The options available are <strong class="source-inline">deployment</strong>, <strong class="source-inline">daemonset</strong>, and <strong class="source-inline">statefulset</strong>. Here, we use the <span class="No-Break"><strong class="source-inline">deployment</strong></span><span class="No-Break"> option:</span></p>
			<pre class="source-code">
mode: deployment</pre>			<p>Let’s explore the available options in <span class="No-Break">some detail:</span></p>
			<ul>
				<li>A <strong class="source-inline">deployment</strong> is deployed with a fixed number of Pods, which is the <strong class="source-inline">replicaCount</strong> in Kubernetes terms. For our reference system, we used this mode as we know the system will be deployed to a single-node Kubernetes cluster, and it allows us to combine presets that would usually be used independently in a <span class="No-Break">multi-node cluster.</span></li>
				<li>A <strong class="source-inline">daemonset</strong> is deployed with a collector to every node in <span class="No-Break">a cluster.</span></li>
				<li>A <strong class="source-inline">statefulset</strong> is deployed with unique network interfaces and <span class="No-Break">consistent deployments.</span></li>
			</ul>
			<p>We discuss selecting the appropriate mode in <a href="B18277_11.xhtml#_idTextAnchor218"><span class="No-Break"><em class="italic">Chapter 11</em></span></a> when we discuss architecture. These deployment modes can also be combined to provide specific functionality in a <span class="No-Break">Kubernetes cluster.</span></p>
			<p>The next configuration block we’ll look at <span class="No-Break">is </span><span class="No-Break"><strong class="source-inline">presets</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
presets:
  logsCollection:
    enabled: true
    includeCollectorLogs: false
  kubernetesAttributes:
    enabled: true
  kubernetesEvents:
    enabled: true
  clusterMetrics:
    enabled: true
  kubeletMetrics:
    enabled: true
  hostMetrics:
    enabled: true</pre>			<p>As you can see, this configuration<a id="_idIndexMarker864"/> involves simply enabling or disabling different functions. Let’s look at the parameters <span class="No-Break">in detail:</span></p>
			<ul>
				<li>The <strong class="source-inline">logsCollection</strong> parameter tells the collector to collect logs from the standard output of Kubernetes containers. We are not including the collector logs as this can cause a logging cascade, where the collector reads its own log output and writes the collected logs to that output, which are then read again. In real-life setups, it is recommended to only use the <strong class="source-inline">logsCollection</strong> parameter in <span class="No-Break"><strong class="source-inline">daemonset</strong></span><span class="No-Break"> mode.</span></li>
				<li>The <strong class="source-inline">kubernetesAttributes</strong> parameter collects Kubernetes metadata as the collector receives logs, metrics, and traces. This includes information such as <strong class="source-inline">k8s.pod.name</strong>, <strong class="source-inline">k8s.namespace.name</strong>, and <strong class="source-inline">k8s.node.name</strong>. The attribute collector is safe to use in <span class="No-Break">all modes.</span></li>
				<li>The <strong class="source-inline">kubernetesEvents</strong> parameter collects the events that occur in the cluster and publishes them in the log pipeline. Effectively, every event that occurs in the cluster receives a log entry in Loki with this configuration. Cluster events include things such as Pod creations and deletions, among others. It’s best practice to use <strong class="source-inline">kubernetesEvents</strong> in the <strong class="source-inline">deployment</strong> or <strong class="source-inline">statefulset</strong> modes to prevent the duplication <span class="No-Break">of events.</span></li>
				<li>The three metrics options collect metrics about <span class="No-Break">the system:</span><ul><li><strong class="source-inline">clusterMetrics</strong> looks at the full cluster. This should be used in <strong class="source-inline">deployment</strong> or <span class="No-Break"><strong class="source-inline">statefulset</strong></span><span class="No-Break"> modes.</span></li><li><strong class="source-inline">kubeletMetrics</strong> collects metrics from the kubelet about the node, Pods, and containers it is managing. This should be used in <span class="No-Break"><strong class="source-inline">daemonset</strong></span><span class="No-Break"> mode.</span></li><li><strong class="source-inline">hostMetrics</strong> collects data directly from the host, such as CPU, memory, and disk usage. This should be used in <span class="No-Break"><strong class="source-inline">daemonset</strong></span><span class="No-Break"> mode.</span></li></ul></li>
			</ul>
			<p>We’ll skip over a few blocks that are standard Kubernetes<a id="_idIndexMarker865"/> configurations and consider the <strong class="source-inline">config</strong> block next. The <strong class="source-inline">config</strong> block has a <span class="No-Break">few subblocks:</span></p>
			<ul>
				<li>The telemetry pipeline includes <span class="No-Break">the following:</span><ul><li><strong class="source-inline">receivers</strong>: Receivers are at the start of a pipeline. They receive data and translate it to add it to the pipeline for other components <span class="No-Break">to use.</span></li><li><strong class="source-inline">processors</strong>: Processors are used in a pipeline to carry out various functions. There are supported processors and contributed <span class="No-Break">processors available.</span></li><li><strong class="source-inline">exporters</strong>: Exporters come at the end of a pipeline. They receive data in the internal pipeline format and translate it to send the <span class="No-Break">data onwards.</span></li><li><strong class="source-inline">connectors</strong>: These combine <strong class="source-inline">receivers</strong> and <strong class="source-inline">exporters</strong> to link pipelines together. <strong class="source-inline">connectors</strong> act as <strong class="source-inline">exporters</strong> to send the data from one pipeline onwards, and as <strong class="source-inline">receivers</strong> to take that data and add it to <span class="No-Break">another pipeline.</span></li></ul></li>
				<li>Separate to the pipeline are <strong class="source-inline">extensions</strong>, which add additional functionality to the collector, but do not need access to the telemetry data in <span class="No-Break">the pipelines.</span></li>
				<li>Finally, there is a <strong class="source-inline">service</strong> block, which is used to define the pipelines and extensions <span class="No-Break">in use.</span></li>
			</ul>
			<p>The only extension we are using<a id="_idIndexMarker866"/> in our <strong class="source-inline">config</strong> block is the <span class="No-Break"><strong class="source-inline">health_check</strong></span><span class="No-Break"> extension:</span></p>
			<pre class="source-code">
config:
  extensions:
    health_check:
      check_collector_pipeline:
        enabled: false</pre>			<p>This enables an endpoint that can be used for a liveness and/or readiness probe in the Kubernetes cluster. This is helpful for you to be able to see easily whether the collector is working <span class="No-Break">as expected.</span></p>
			<p>In our <strong class="source-inline">receivers</strong> block we have configured two receivers, <strong class="source-inline">otlp</strong> <span class="No-Break">and </span><span class="No-Break"><strong class="source-inline">prometheus</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
config:
  receivers:
    otlp:
      protocols:
        http:
          endpoint: 127.0.0.1:4318
          cors:
            allowed_origins:
              - "http://*"
              - "https://*"
    prometheus:
      config:
        scrape_configs:
          - job_name: 'opentelemetry-collector'
            tls_config:
              insecure_skip_verify: true
            scrape_interval: 10s
            scrape_timeout: 2s
            kubernetes_sd_configs:
              - role: pod
            relabel_configs:
              - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                action: keep
                regex: "true"
              - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                action: replace
                target_label: __address__
                regex: ([^:]+)(?::\d+)?;(\d+)
                replacement: $$1:$$2</pre>			<p>Let’s look at these receivers<a id="_idIndexMarker867"/> <span class="No-Break">more closely:</span></p>
			<ul>
				<li>The <strong class="source-inline">OTLP</strong> receiver configures our collector instance to expose port <strong class="source-inline">4318</strong> on <strong class="source-inline">127.0.0.1</strong> on the Kubernetes node, which allows the demo applications to submit <span class="No-Break">telemetry easily.</span></li>
				<li>The <strong class="source-inline">Prometheus</strong> receiver is used to collect metrics from the collector itself. This receiver config shows an example of relabeling, where we take <strong class="source-inline">meta_kuberentes_pod_annotation_prometheus_io_port</strong> and rename it with <strong class="source-inline">__address__</strong>, which is the standard used <span class="No-Break">in OTLP.</span></li>
			</ul>
			<p>In our configuration, we have set up the <strong class="source-inline">k8sattributes</strong>, <strong class="source-inline">resource</strong>, and <strong class="source-inline">attributes</strong> processors. The <strong class="source-inline">k8sattributes</strong> processor extracts attributes from the kubelet and adds them to the telemetry in the pipelines. The <strong class="source-inline">resource</strong> and <strong class="source-inline">attributes</strong> processors will insert or modify the resource or attributes respectively. We’ll not discuss these concepts in detail, but resources are used to identify the source that is <span class="No-Break">producing telemetry.</span></p>
			<p>In our configuration, we are<a id="_idIndexMarker868"/> using both the <strong class="source-inline">spanmetrics</strong> and <span class="No-Break"><strong class="source-inline">servicegraph</strong></span><span class="No-Break"> connectors:</span></p>
			<pre class="source-code">
config:
  connectors:
    spanmetrics:
      dimensions:
      - name: http.method
        default: GET
      - name: http.status_code
      namespace: traces.spanmetrics
    servicegraph:
      latency_histogram_buckets: [1,2,3,4,5]</pre>			<p>Both <strong class="source-inline">connectors</strong> are used to export the data<a id="_idIndexMarker869"/> from the <strong class="source-inline">traces</strong> pipeline and receive it in the <strong class="source-inline">metrics</strong> pipeline. <strong class="source-inline">spanmetrics</strong> collects the <strong class="bold">request, error, and duration</strong> (<strong class="bold">RED</strong>) metrics from the span data (we introduced RED in <a href="B18277_09.xhtml#_idTextAnchor183"><span class="No-Break"><em class="italic">Chapter 9</em></span></a>). <strong class="source-inline">servicegraph</strong> generates metrics that describe the relationship between services, these metrics allow the service graphs to be shown <span class="No-Break">in Tempo.</span></p>
			<p>The final subblock in our <strong class="source-inline">config</strong> block is <strong class="source-inline">services</strong>. This subblock defines the extensions to be loaded and the configuration of the pipelines. Each pipeline (<strong class="source-inline">logs</strong>, <strong class="source-inline">metrics</strong>, and <strong class="source-inline">traces</strong>) defines the <strong class="source-inline">receivers</strong>, <strong class="source-inline">processors</strong>, and <strong class="source-inline">exporters</strong> used. Let’s look at the <strong class="source-inline">metrics</strong> pipeline <a id="_idIndexMarker870"/>as it is the <span class="No-Break">most complex:</span></p>
			<pre class="source-code">
metrics:
        receivers:
          - otlp
          - spanmetrics
          - servicegraph
        processors:
          - memory_limiter
          - filter/ottl
          - transform
          - batch
        exporters:
          - prometheusremotewrite
          - logging</pre>			<p>The receivers are <strong class="source-inline">OTLP</strong>, <strong class="source-inline">spanmetrics</strong>, and <strong class="source-inline">servicegraph</strong> as discussed previously. We then instruct the pipeline to use the <strong class="source-inline">memory_limiter</strong>, <strong class="source-inline">filter</strong>, <strong class="source-inline">transform</strong>, and <strong class="source-inline">batch</strong> processors, in the order listed. You may notice that our filter is named <strong class="source-inline">ottl</strong> using the syntax of <strong class="source-inline">processor/name</strong>, which is useful when you need to use the same processor with different configurations. Finally, the pipeline uses the <strong class="source-inline">prometheusremotewrite</strong> exporters and logging to <span class="No-Break">output data.</span></p>
			<p>You may have noticed that the exporters are not defined in the <strong class="source-inline">/chapter6/OTEL-Collector.yaml</strong> file – this is because they are defined in <strong class="source-inline">/OTEL-Creds.yaml</strong>, and this highlights a very useful feature of Helm, which is the ability to separate out configuration files based on their function. When we install the Helm chart, we use a command such as <span class="No-Break">the following:</span></p>
			<pre class="console">
helm install owg open-telemetry/opentelemetry-collector --values chapter3/OTEL-Collector.yaml --values OTEL-Creds.yaml</pre>			<p>The <strong class="source-inline">-f</strong> or <strong class="source-inline">--values</strong> option can be used multiple times for multiple YAML files – if there are conflicts, then precedence is always given to the last file used. By structuring the YAML files in such a way, we can split the full configuration in ways that allow us to protect secret information, such as API keys, while still making our main configuration easily available. We can also use this feature for other purposes such as overriding a default configuration in a test environment. It’s important to be careful with precedence here as duplicate arrays will not be merged. Deploying the collector in this way is fantastic in a lot of situations. However, it has a limitation – any time there is a change to the configuration, or a new version of the collector is to be installed, a Helm <strong class="source-inline">install</strong> or <strong class="source-inline">upgrade</strong> operation needs to be carried out. This introduces the need for a system that has knowledge of and access to each cluster in which the collector will be deployed, which can introduce bottlenecks and security risks. Let’s look at the OpenTelemetry Operator, which offers<a id="_idIndexMarker871"/> solutions to <span class="No-Break">these problems.</span></p>
			<h3>OpenTelemetry Kubernetes Operator</h3>
			<p>OpenTelemetry also offers a Kubernetes operator<a id="_idIndexMarker872"/> to manage both the OpenTelemetry Collector and allow for auto-instrumentation of workloads. This operator is still in active development and the feature set is expected <span class="No-Break">to increase.</span></p>
			<p>Kubernetes operators use <strong class="bold">Custom Resource Definitions</strong> (<strong class="bold">CRDs</strong>) to provide extensions to the Kubernetes API, which<a id="_idIndexMarker873"/> are used by the operators to manage the system. The advantages<a id="_idIndexMarker874"/> of using an operator include <span class="No-Break">the following:</span></p>
			<ul>
				<li>The complex logic involved in managing the OpenTelemetry Operator or the auto-instrumentation system can be designed by the experts working on the OpenTelemetry projects. For the person responsible for managing an OpenTelemetry installation, the operator offers a defined CRD specification against which to validate the proposed configuration in a <span class="No-Break">CI/CD pipeline.</span></li>
				<li>The OpenTelemetry operator also allows for limited automated upgrades. Minor and major version updates still need to be applied via a Helm upgrade due to the possibility of <span class="No-Break">breaking changes.</span></li>
				<li>It can be combined with GitOps tooling to move from a solution where a central system must know each cluster and have the necessary credentials to deploy to them, to a solution where each cluster reads the desired configuration from a central <span class="No-Break">version-controlled repository.</span></li>
				<li>The operator really excels when it comes to making the OpenTelemetry auto-instrumentation easily accessible to applications by adding annotations. For the majority of use cases, auto-instrumentation will provide ample metric and trace telemetry to understand<a id="_idIndexMarker875"/> <span class="No-Break">an application.</span></li>
			</ul>
			<p>The OpenTelemetry Collector can also be installed on virtual or bare-metal servers, this process can be automated with tools such as Ansible. Let’s see how you might <span class="No-Break">approach this.</span></p>
			<h3>OpenTelemetry and Ansible</h3>
			<p>OpenTelemetry does not provide an official collection<a id="_idIndexMarker876"/> for Ansible. It provides packaged versions of the collector for Alpine-, Debian-, and Red Hat-based systems as <strong class="source-inline">.apk</strong>, <strong class="source-inline">.deb</strong>, and <strong class="source-inline">.rpm</strong> files respectively. Using <strong class="source-inline">community.general.apk</strong>, <strong class="source-inline">ansible.builtin.apt</strong>, or <strong class="source-inline">ansible.builtin.yum</strong>, the package can be installed with a configuration similar to <span class="No-Break">the following:</span></p>
			<pre class="source-code">
- name: Install OpenTelemetry Collector
  ansible.builtin.apt:
    deb: https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v0.85.0/otelcol_0.85.0_linux_amd64.deb</pre>			<p>With the package installed, the only other thing to do to configure the collector is to apply a configuration file. The default configuration file is located at <strong class="source-inline">/etc/otelcol/config.yaml</strong> and is used when systemd starts the collector. Ansible can overwrite this file or modify it in place. This could be done with the <span class="No-Break">following configuration:</span></p>
			<pre class="source-code">
- name: Copy OpenTelemetry Collector Configuration
  ansible.builtin.copy:
    src: /srv/myfiles/OTEL-Collector.yaml
    dest: /etc/otelcol/config.yaml
    owner: root
    group: root
    mode: '0644'</pre>			<p>We have looked at the OpenTelemetry agent a lot during this book. One major reason for this is that<a id="_idIndexMarker877"/> OpenTelemetry also offers the Demo application we have used to produce realistic sample data. Next, let’s take a look at <span class="No-Break">Grafana Agent.</span></p>
			<h2 id="_idParaDest-199"><a id="_idTextAnchor211"/>Automating the installation of Grafana Agent</h2>
			<p>Grafana produces its own agent, which is recommended<a id="_idIndexMarker878"/> by Grafana for use with its cloud platform. Grafana Agent also provides automation options, which we will introduce in <span class="No-Break">this section.</span></p>
			<h3>Grafana Agent Helm charts</h3>
			<p>Grafana offers two Helm charts, the <strong class="bold">grafana-agent chart</strong> and the <strong class="bold">agent-operator chart</strong>. Similar to the OpenTelemetry<a id="_idIndexMarker879"/> charts, the Agent chart allows for a direct installation<a id="_idIndexMarker880"/> of the Grafana Agent on a Kubernetes<a id="_idIndexMarker881"/> cluster. The Operator chart deploys CRDs into the cluster and then manages the state of the Agent based on these definitions. At the time of writing, the Grafana Agent Operator offers CRDs for metrics and log collection. For full details of the <strong class="source-inline">grafana-agent</strong> chart and the configuration options, please check out the Helm chart documentation at https://github.com/grafana/agent/tree/main/operations/helm/charts/grafana-agent. Similarly, the documentation for the <strong class="source-inline">agent-operator</strong> chart can be found at <a href="https://github.com/grafana/helm-charts/tree/main/charts/agent-operator#upgrading-an-existing-release-to-a-new-major-version">https://github.com/grafana/helm-charts/tree/main/charts/agent-operator#upgrading-an-existing-release-to-a-new-major-version</a>. Details of the available CRDs are documented<a id="_idIndexMarker882"/> in the Operator architecture documentation <span class="No-Break">at </span><span class="No-Break">https://github.com/grafana/agent/blob/v0.36.2/docs/sources/operator/architecture.md</span><span class="No-Break">.</span></p>
			<h3>Grafana Agent and Ansible</h3>
			<p>Unlike OpenTelemetry, Grafana<a id="_idIndexMarker883"/> maintains an Ansible collection (https://docs.ansible.com/ansible/latest/collections/grafana/grafana) that includes tools to manage<a id="_idIndexMarker884"/> collection, storage, and visualization systems, and we will revisit it in <span class="No-Break">later sections.</span></p>
			<p>The included <strong class="source-inline">grafana_agent</strong> role is used to manage data collection and will install the agent on Red Hat, Ubuntu, Debian, CentOS, and Fedora distributions. This role can be used <span class="No-Break">as follows:</span></p>
			<pre class="source-code">
- name: Install Grafana Agent
  ansible.builtin.include_role:
    name: grafana_agent
  vars:
    grafana_agent_logs_config:
      &lt;CONFIG&gt;
    grafana_agent_metrics_config:
      &lt;CONFIG&gt;
    grafana_agent_traces_config:
      &lt;CONFIG&gt;</pre>			<p>The configuration for logs, metrics, and traces is specific to that telemetry type and the documentation available from Grafana covers using that configuration to manage <span class="No-Break">the Agent.</span></p>
			<h1 id="_idParaDest-200"><a id="_idTextAnchor212"/>Getting to grips with the Grafana API</h1>
			<p>Grafana offers a full-featured API<a id="_idIndexMarker885"/> for both Grafana Cloud and Grafana itself. This API is the same API used by the frontend, which means that we can also drive the functions<a id="_idIndexMarker886"/> of Grafana using either direct API calls in a script, or an IaC tool such as <strong class="bold">Terraform</strong>. We’ll start by having a high-level look at the APIs available in Grafana Cloud and Grafana, then we’ll look at the Grafana Terraform module and the Ansible collection, and see how to use them to manage a Grafana <span class="No-Break">Cloud instance.</span></p>
			<h2 id="_idParaDest-201"><a id="_idTextAnchor213"/>Exploring the Grafana Cloud API</h2>
			<p>The Grafana Cloud API is used<a id="_idIndexMarker887"/> to manage all aspects of a Grafana Cloud SaaS installation. Let’s have a high-level look at the functions provided by the Grafana <span class="No-Break">Cloud API:</span></p>
			<ul>
				<li><strong class="bold">Access policies and tokens</strong>: These API endpoints manage authentication and authorization<a id="_idIndexMarker888"/> resources. Here are their <span class="No-Break">major functions:</span><ul><li>Create, read, update, and delete functions for <span class="No-Break">access policies</span></li><li>Create, read, update, and delete functions <span class="No-Break">for tokens</span></li></ul><p class="list-inset">Tokens must be associated with an <strong class="source-inline">accessPolicyId</strong>, which is the unique ID for an access <span class="No-Break">policy object.</span></p></li>
				<li><strong class="bold">Stacks</strong>: These endpoints manage Grafana Cloud stacks. The following are their <span class="No-Break">key functions:</span><ul><li>Create, read, update, and delete functions <span class="No-Break">for stacks</span></li><li>Restart Grafana on a <span class="No-Break">specific stack</span></li><li>List data sources on a <span class="No-Break">specific stack</span></li></ul></li>
				<li><strong class="bold">Grafana plugins</strong>: These endpoints manage plugins installed on Grafana instances related to a stack. Their functions include creating, reading, updating, and deleting functions for Grafana plugins installed on a <span class="No-Break">specific stack.</span></li>
				<li><strong class="bold">Regions</strong>: These API endpoints list the Grafana Cloud regions available. They are used to read functions for the available Grafana Cloud regions that can be used to host <span class="No-Break">a stack.</span></li>
				<li><strong class="bold">API keys</strong>: These endpoints were for managing Cloud API keys and their major functions are the create, read, and delete functions for API keys. These endpoints are now deprecated as Grafana has moved to authentication techniques using access policies<a id="_idIndexMarker889"/> and tokens. API key endpoints will be removed in a <span class="No-Break">future update.</span></li>
			</ul>
			<p>We will discuss access policies and tokens in more detail in <a href="B18277_11.xhtml#_idTextAnchor218"><span class="No-Break"><em class="italic">Chapter 11</em></span></a> where we discuss <strong class="bold">access levels</strong> as part of architecting a great observability platform. All the Grafana Cloud endpoints<a id="_idIndexMarker890"/> have an associated access policy, and the token used must be authorized with that policy for a <span class="No-Break">successful response.</span></p>
			<p>More detailed information is available in Grafana’s documentation at https://grafana.com/docs/grafana-cloud/developer-resources/api-reference/cloud-api/, including information on the parameters<a id="_idIndexMarker891"/> and details needed in a request as well as example requests <span class="No-Break">and responses.</span></p>
			<p>We’ve now reviewed the API endpoints. Next, we'll discuss Grafana’s offerings of both a Terraform provider and the Ansible collection, which can be used to interact with the aforementioned APIs using <span class="No-Break">IaC automation.</span></p>
			<h2 id="_idParaDest-202"><a id="_idTextAnchor214"/>Using Terraform and Ansible for Grafana Cloud</h2>
			<p>Grafana provides both a Terraform<a id="_idIndexMarker892"/> provider and an Ansible collection<a id="_idIndexMarker893"/> for use in managing organizations’ Cloud<a id="_idIndexMarker894"/> instances. Let’s explore how we can use these tools<a id="_idIndexMarker895"/> with the Grafana Cloud API to manage a Grafana <span class="No-Break">Cloud instance.</span></p>
			<h3>The Grafana Terraform provider</h3>
			<p>The <strong class="bold">Grafana Terraform provider</strong> has resources that match the Cloud API<a id="_idIndexMarker896"/> endpoints we have discussed. The provider also offers resources for other Grafana API endpoints, which we will cover when we discuss managing dashboards and alerts later in this chapter. The official documentation for the provider can be found<a id="_idIndexMarker897"/> on the Terraform Registry <span class="No-Break">at </span><a href="https://registry.terraform.io/providers/grafana/grafana/latest/docs"><span class="No-Break">https://registry.terraform.io/providers/grafana/grafana/latest/docs</span></a><span class="No-Break">.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">This chapter was written with version 2.6.1 of the Grafana <span class="No-Break">Terraform provider.</span></p>
			<p>Here are some of the commonly<a id="_idIndexMarker898"/> used Terraform resources with examples of <span class="No-Break">their use:</span></p>
			<ul>
				<li>First, let’s have a look at using the provider. The <strong class="source-inline">grafana_cloud_stack</strong> data provider is used to find a stack called <strong class="source-inline">acme-preprod</strong>, which we will use later to specify where our access policy is to <span class="No-Break">be created:</span><pre class="source-code">
data "grafana_cloud_stack" "preprod" {
  slug = "acme-preprod"
}</pre></li>				<li>The <strong class="source-inline">grafana_cloud_access_policy</strong> resource allows us to create an access policy. Here, we set our <strong class="source-inline">region</strong> value to <strong class="source-inline">us</strong>, along with a name and a display name. Finally, we specify the scope of the policy – in this case, we want to be able to write logs, metrics, and traces. The <strong class="source-inline">stack</strong> ID we found earlier is then used to specify where to create this <span class="No-Break">access policy:</span><pre class="source-code">
resource "grafana_cloud_access_policy" "collector-write" {
  region       = "us"
  name         = "collector-write"
  display_name = "Collector write policy"
  scopes = ["logs:write", "metrics:write", "traces:write"]
  realm {
    type       = "stack"
    identifier = data.grafana_cloud_stack.preprod.id
  }
}</pre></li>				<li>Finally, the <strong class="source-inline">grafana_cloud_access_policy_token</strong> resource can be used to create a new token. We specify a region, the access policy to use, and a name. The token will then be able to be read <span class="No-Break">from </span><span class="No-Break"><strong class="source-inline">grafana_cloud_access_policy_token.collector-token.token</strong></span><span class="No-Break">:</span><pre class="source-code">
resource "grafana_cloud_access_policy_token" "collector-token" {
  region           = "us"
  access_policy_id = grafana_cloud_access_policy.collector-write.policy_id
  name             = "preprod-collector-write"
  display_name     = "Preprod Collector Token"
  expires_at       = "2023-01-01T00:00:00Z"
}</pre></li>			</ul>
			<p>This isn’t the only thing we can do with the Grafana Terraform provider: we’ll consider another example later in this chapter<a id="_idIndexMarker899"/> when we examine managing<a id="_idIndexMarker900"/> dashboards and alerts. Typically, this would be combined with another<a id="_idIndexMarker901"/> provider to record this newly created token in a secrets management tool, such as <strong class="bold">AWS Secrets Manager</strong> or <strong class="bold">HashiCorp Vault</strong>, where it can be accessed whenever a collector <span class="No-Break">is deployed.</span></p>
			<p>Let’s look managing a Grafana Cloud system with another IaC tool provided by Grafana, the <strong class="bold">Grafana </strong><span class="No-Break"><strong class="bold">Ansible collection</strong></span><span class="No-Break">.</span></p>
			<h3>The Grafana Ansible collection</h3>
			<p>The Grafana Ansible collection<a id="_idIndexMarker902"/> is not as feature rich as the Terraform provider for managing cloud instances. However, a lot of the functionality from the Grafana Cloud API can be accessed using the Ansible URI module. The official collection documentation is available on the Ansible site at <a href="https://docs.ansible.com/ansible/latest/collections/grafana/grafana/">https://docs.ansible.com/ansible/latest/collections/grafana/grafana/</a>. A community-provided collection is also available, but will not be discussed<a id="_idIndexMarker903"/> here. The relevant documentation is available <span class="No-Break">at </span><a href="https://docs.ansible.com/ansible/latest/collections/community/grafana/index.html"><span class="No-Break">https://docs.ansible.com/ansible/latest/collections/community/grafana/index.html</span></a><span class="No-Break">.</span></p>
			<p class="callout-heading">Important note</p>
			<p class="callout">This chapter was written with version 2.2.3 of the Grafana <span class="No-Break">Ansible collection.</span></p>
			<p>We’ll look at managing a Grafana Cloud stack using Ansible. The <strong class="source-inline">name</strong> and <strong class="source-inline">stack_slug</strong> (this is the stack we are interacting with) values are set to the same string by convention. We then need to set the <strong class="source-inline">region</strong> value for the stack, along with the organization the stack will belong to <span class="No-Break">using </span><span class="No-Break"><strong class="source-inline">org_slug</strong></span><span class="No-Break">:</span></p>
			<pre class="source-code">
- name: Create preprod stack
  grafana.grafana.cloud_stack:
    name: acme-preprod
    stack_slug: acme-preprod
    cloud_api_key: "{{ grafana_cloud_api_key }}"
    region: us
    org_slug: acme
    state: present</pre>			<p>We’ve so far looked at the API for Grafana Cloud. This API is great for managing an observability platform in Grafana Cloud, but a lot of teams will be more interested in managing dashboards, alerts, and other items in the Grafana UI. Grafana provides another API to manage objects in the Grafana UI – let’s look at <span class="No-Break">it now.</span></p>
			<h2 id="_idParaDest-203"><a id="_idTextAnchor215"/>Exploring the Grafana API</h2>
			<p>While the Grafana Cloud API <a id="_idIndexMarker904"/>is only used to manage Grafana Cloud SaaS instances, the <strong class="bold">Grafana API</strong> is very far reaching as Grafana has a lot of functionality. These APIs can be used on both Grafana Cloud and locally installed <span class="No-Break">Grafana instances.</span></p>
			<p>Similar to the Grafana Cloud API, all endpoints use role-based access control. However, the Grafana API offers an additional authentication option: service accounts. Service accounts should be used for any application that needs to interact <span class="No-Break">with Grafana.</span></p>
			<p>As most teams will use a small subset of APIs frequently, we will only discuss a few APIs here. However, there are a lot of other APIs that can be used to automate the management of a Grafana instance. Let’s take a closer look at some commonly <span class="No-Break">used APIs:</span></p>
			<ul>
				<li><strong class="bold">Dashboard and Folder</strong>: These endpoints manage dashboards and folders in Grafana. Their functions include <span class="No-Break">the following:</span><ul><li>Create, read, update, and delete functions for dashboards <span class="No-Break">or folders</span></li><li>Create, read, update, and delete the tags on <span class="No-Break">a dashboard</span></li></ul><p class="list-inset">Dashboards and folders have both an ID and a UID. The ID is only unique to a specific Grafana installation, while the UID is unique <span class="No-Break">across installations.</span></p></li>
				<li><strong class="bold">Dashboard Permissions and Folder Permissions</strong>: These APIs handle the access controls for dashboards and folders. They can be used to update permissions for a dashboard or folder. These endpoints use a UID, although there is a deprecated endpoint to update permissions for dashboards by ID. Permissions are set numerically: <strong class="source-inline">1</strong> = <strong class="source-inline">View</strong>, <strong class="source-inline">2</strong> = <strong class="source-inline">Edit</strong>, <strong class="source-inline">4</strong> = <strong class="source-inline">Admin</strong>. Permissions can be set for user roles or <span class="No-Break"><strong class="source-inline">teamId</strong></span><span class="No-Break"> values.</span></li>
				<li><strong class="bold">Folder/Dashboard Search</strong>: This API allows users to search for dashboards and folders. This endpoint allows for complex searches using query parameters. The response is a list of matching objects including the UID of <span class="No-Break">an object.</span></li>
				<li><strong class="bold">Teams</strong>: These endpoints manage Teams in Grafana. They can be used to do <span class="No-Break">the following:</span><ul><li>Create, read, update, and <span class="No-Break">delete teams</span></li><li>Get, add, and remove <span class="No-Break">team members</span></li><li>Get and update <span class="No-Break">team preferences</span></li></ul></li>
				<li><strong class="bold">Alerting</strong>: These complex APIs manage all of the aspects of alerts. This API manages everything to do with Grafana Alertmanager. It can be used to create, read, update, and delete alerts, alert rules, alert groups, silences, receivers, templates, and many more <span class="No-Break">alerting objects.</span></li>
			</ul>
			<p>These API endpoints are fantastic<a id="_idIndexMarker905"/> for managing Grafana. Grafana provides a detailed API reference <span class="No-Break">at </span><span class="No-Break">https://grafana.com/docs/grafana/latest/developers/http_api/</span><span class="No-Break">.</span></p>
			<p>Let’s now look at how <a id="_idIndexMarker906"/>these API endpoints allow us to use the IaC tools of Terraform and Ansible to manage dashboards <span class="No-Break">and alerts.</span></p>
			<h1 id="_idParaDest-204"><a id="_idTextAnchor216"/>Managing dashboards and alerts with Terraform or Ansible</h1>
			<p>As dashboards are typically managed<a id="_idIndexMarker907"/> by the teams responsible<a id="_idIndexMarker908"/> for a service or application, it is best practice<a id="_idIndexMarker909"/> to separate the tooling<a id="_idIndexMarker910"/> to deploy dashboards<a id="_idIndexMarker911"/> from the tooling<a id="_idIndexMarker912"/> to manage observability<a id="_idIndexMarker913"/> infrastructure. We will discuss the<a id="_idIndexMarker914"/> practicalities of this in <a href="B18277_14.xhtml#_idTextAnchor254"><span class="No-Break"><em class="italic">Chapter 14</em></span></a><span class="No-Break">.</span></p>
			<p>For managing dashboards, both Terraform and Ansible leverage the fact that Grafana dashboards are JSON objects, providing a mechanism to upload a JSON file with the dashboard configuration to the Grafana instance. Let’s look at how <span class="No-Break">this works.</span></p>
			<p>The <strong class="bold">Terraform</strong> code looks <span class="No-Break">like this:</span></p>
			<pre class="source-code">
resource "grafana_dashboard" "top_level " {
  config_json = file("top-level.json")
  overwrite = true
}</pre>			<p>A collection of dashboard JSON files can be iterated over using the Terraform <strong class="source-inline">fileset</strong> function with a <strong class="source-inline">for_each</strong> command. This makes it very easy for a team to manage all its dashboards in an automated manner by saving the correct dashboard to the <span class="No-Break">relevant folder.</span></p>
			<p>The <strong class="bold">Ansible</strong> collection works in a very <span class="No-Break">similar fashion:</span></p>
			<pre class="source-code">
- name: Create Top Level Dashboard
  grafana.grafana.dashboard:
    dashboard: "{{ lookup('ansible.builtin.file', ' top-level.json') }}"
    grafana_url: "{{ grafana_url }}"
    grafana_api_key: "{{ grafana_api_key }}"
    state: present</pre>			<p>Like the<a id="_idIndexMarker915"/> Terraform<a id="_idIndexMarker916"/> code, this could be iterated using<a id="_idIndexMarker917"/> the built-in <strong class="source-inline">with_fileglob</strong> function, allowing<a id="_idIndexMarker918"/> teams to manage <a id="_idIndexMarker919"/>all their<a id="_idIndexMarker920"/> dashboards <a id="_idIndexMarker921"/>in an <span class="No-Break">automated</span><span class="No-Break"><a id="_idIndexMarker922"/></span><span class="No-Break"> fashion.</span></p>
			<p>Unfortunately, with the latest changes to alerting in Grafana, the Ansible collection has not been updated to allow for alert management. With Terraform, you can manage Grafana Alerts in a very similar way to dashboards. Consider the following example <span class="No-Break">code block:</span></p>
			<pre class="source-code">
resource "grafana_rule_group" "ateam_alert_rule" {
  name             = "A Team Alert Rules"
  folder_uid       = grafana_folder.rule_folder.uid
  interval_seconds = 240
  org_id           = 1
  rule {
    name           = "Alert Rule 1"
  }
  rule {
    name           = "Alert Rule 2"
  }</pre>			<p>We’ve not included the full details of the two rules shown here as the required configuration block is too large. The Terraform<a id="_idIndexMarker923"/> documentation has a very clear example of a full alert <span class="No-Break">at </span><span class="No-Break">https://registry.terraform.io/providers/grafana/grafana/latest/docs/resources/rule_group</span><span class="No-Break">.</span></p>
			<p>Similar to the <strong class="source-inline">grafana_dashboard</strong> resource, <strong class="source-inline">grafana_rule_group</strong> can be iterated over by using a <strong class="source-inline">dynamic</strong> block to populate<a id="_idIndexMarker924"/> each rule from<a id="_idIndexMarker925"/> another source, such as<a id="_idIndexMarker926"/> a JSON file, for<a id="_idIndexMarker927"/> example. This makes the management of these<a id="_idIndexMarker928"/> rules<a id="_idIndexMarker929"/> significantly<a id="_idIndexMarker930"/> <span class="No-Break">more user-</span><span class="No-Break"><a id="_idIndexMarker931"/></span><span class="No-Break">friendly.</span></p>
			<h1 id="_idParaDest-205"><a id="_idTextAnchor217"/>Summary</h1>
			<p>In this chapter, you were introduced to the benefits of automating the management of your observability platform, and saw how investing in good automation can allow subject-matter experts to shift repetitive and low-value work to others in the organization. We discussed the different aspects of observability platforms, being data production, collection, storage, and visualization. You also learned who is typically responsible for each aspect of <span class="No-Break">the platform.</span></p>
			<p>With the theory largely covered, we then went on to discuss how to manage the data collection layer, presenting an in-depth analysis of the OpenTelemetry Collector Helm configuration that has been used to collect data throughout this book. We contrasted the way Helm works with Ansible to deploy to a virtual or physical setup, and you gained valuable skills in understanding the structure of the management files used by each tool. We rounded out the automation of data collection systems by introducing the Helm chart and the Ansible collection for Grafana Agent. While we did not go into this in the same depth as the OpenTelemtry configuration, the skills required for managing the Grafana Agent <span class="No-Break">are identical.</span></p>
			<p>Our next topic was the Grafana API, where you learned that there are two APIs, one to manage the SaaS Grafana Cloud solution, and one to manage Grafana instances (both cloud and local). You were then introduced to the Terraform provider for Grafana and learned through specific examples how to manage both their cloud stacks and their Grafana instances. We then also looked at the Grafana Ansible collection and saw how it can be used to manage cloud stacks and Grafana instances as well as the data <span class="No-Break">collection layer.</span></p>
			<p>In the next chapter of this book, we will discuss how to architect a full observability platform that scales to the needs of <span class="No-Break">your organization.</span></p>
		</div>
	</body></html>