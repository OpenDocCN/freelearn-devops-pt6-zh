["```\n\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: chatbot-ui-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: chatbot-ui-deployment\n  minReplicas: 1\n  maxReplicas: 5\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n```", "```\n\n$ kubectl apply -f chatbot-ui-hpa.yaml\nhorizontalpodautoscaler.autoscaling/chatbot-ui-hpa created\n```", "```\n\nbehavior:\n  scaleDown:\n    stabilizationWindowSeconds: 180\n    policies:\n    - type: Percent\n      value: 50\n      periodSeconds: 15\n  scaleUp:\n    stabilizationWindowSeconds: 0\n    policies:\n    - type: Pods\n      value: 2\n      periodSeconds: 15\n    selectPolicy: Max\n```", "```\n\ntype: ContainerResource\ncontainerResource:\n  name: cpu\n  container: web-app\n  target:\n    type: Utilization\n    averageUtilization: 60\n```", "```\n\napiVersion: autoscaling.k8s.io/v1\nkind: VerticalPodAutoscaler\nmetadata:\n  name: chatbot-ui-vpa\nspec:\n  targetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: chatbot-ui-deployment\n  updatePolicy:\n    updateMode: \"Auto\"\n  resourcePolicy:\n    containerPolicies:\n    - containerName: \"*\"\n      minAllowed:\n        cpu: \"1000m\"\n        memory: \"2Gi\"\n      maxAllowed:\n        cpu: \"2000m\"\n        memory: \"4Gi\"\n      controlledValues: \"RequestsAndLimits\"\n```", "```\n\n$ kubectl apply -f chatbot-ui-vpa.yaml\nverticalpodautoscaler.autoscaling.k8s.io/chatbot-ui-vpa created\n```", "```\n\napiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: amazonsqs-scaler\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: demo-deployment\n  minReplicaCount: 0\n  maxReplicaCount: 10\n  pollingInterval: 15\n  cooldownPeriod: 180\n  triggers:\n  - type: aws-sqs-queue\n    metadata:\n      queueURL: \"http://<aws-sqs-url\"\n      awsRegion: \"us-east-1\"\n      queueLength: \"10\"\n  authenticationRef:\n    name: keda-service-account\n```", "```\n\napiVersion: keda.sh/v1alpha1\nkind: ScaledObject\nmetadata:\n  name: my-llama-deployment-scaler\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: my-llama-deployment\n...\n  triggers:\n    - type: prometheus\n      metadata:\n        serverAddress: http://prometheus-server.default.svc:9090\n        metricName: http_requests_total\n        threshold: \"10\"\n        query: sum(rate(http_requests_total[1m]))\n    - type: prometheus\n      metadata:\n        serverAddress: http://prometheus-server.default.svc:9090\n        metricName: DCGM_FI_DEV_GPU_UTIL\n        threshold: \"70\"\n        query: avg(DCGM_FI_DEV_GPU_UTIL{pod=~\"my-llama-.*\"}[30s])\n```", "```\n\n$ helm list -n kube-system\nNAME                NAMESPACE             STATUS\nkarpenter           kube-system           deployed\n```", "```\n\nmodule \"eks\" {\n  source = \"terraform-aws-modules/eks/aws\"\n  ...\n  eks_managed_node_groups = {\n    ...\n    # eks-gpu-mng = {\n      # instance_types = [\"g6.2xlarge\"]\n      # ami_type = \"AL2_x86_64_GPU\"\n      # max_size = 2\n      # desired_size = 1\n      # capacity_type = \"SPOT\"\n      # disk_size = 100\n      # labels = {\n      #   \"hub.jupyter.org/node-purpose\" = \"user\"\n      # }\n      # taints = {\n      #   gpu = {\n      #     key    = \"nvidia.com/gpu\"\n      #     value = \"true\"\n      #     effect = \"NO_SCHEDULE\"\n      #   }\n      # }\n    # }\n ...\n$ terraform plan\n$ terraform apply -auto-approve\n```", "```\n\n$ kubectl get nodes -l nvidia.com/gpu.present\n```", "```\n\napiVersion: karpenter.sh/v1\nkind: NodePool\nmetadata:\n  name: eks-gpu-np\nspec:\n...\n      nodeClassRef:\n        group: karpenter.k8s.aws/v1\n        kind: EC2NodeClass\n        name: default\n      requirements:\n        - key: \"karpenter.k8s.aws/instance-generation\"\n          operator: In\n          values: [\"g6\"]\n        - key: \"karpenter.sh/capacity-type\"\n          operator: In\n          values: [\"spot\", \"on-demand\"]\n  disruption:\n    consolidationPolicy: WhenEmptyOrUnderutilized\n...\n$ kubectl apply -f eks-gpu-np.yaml\nnodepool.karpenter.sh/eks-gpu-np created\n```", "```\n\napiVersion: karpenter.k8s.aws/v1\nkind: EC2NodeClass\nmetadata:\n  name: default-gpu\nspec:\n  amiFamily: AL2023\n...\n  role: \"eks-demo\"\n...\n$ kubectl apply -f eks-gpu-nc.yaml\nec2nodeclass.karpenter.k8s.aws/default-gpu created\n```", "```\n\n$ kubectl delete job my-llama-job\njob.batch \"my-llama-job\" deleted\n$ kubectl apply -f llama-finetuning-job.yaml\njob.batch/my-llama-job is created\n```", "```\n\n$ kubectl get pods -l app=my-llama-job\nNAME                    READY     STATUS        RESTARTS         AGE\nmy-llama-job-plgb5      0/1       Pending       0                22s\n$ kubectl describe pod -l app=my-llama-job | grep Scheduling\nWarning  FailedScheduling  101s  default-scheduler  0/2 nodes are available: 2 Insufficient nvidia.com/gpu. preemption: 0/2 nodes are available: 2 No preemption victims found for incoming pod\n```", "```\n\n$ kubectl logs --selector app.kubernetes.io/instance=karpenter -n kube-system\n{\"level\":\"INFO\",\"time\":\"2025-01-31T14:34:03.899Z\",\"logger\":\"controller\",\"message\":\"found provisionable pod(s)\",\"commit\":\"b897114\",\"controller\":\"provisioner\",\"namespace\":\"\",\"name\":\"\",\"reconcileID\":\"bbdfdd41-e86f-4cfe-8fb5-e161f3ce4a72\",\"Pods\":\"default/my-llama-job-plgb5\",\"duration\":\"33.662142ms\"}\n...\n{\"level\":\"INFO\",\"time\":\"2025-01-31T14:36:01.277Z\",\"logger\":\"controller\",\"message\":\"initialized nodeclaim\",\"commit\":\"b897114\",\"controller\":\"nodeclaim.lifecycle\",\"controllerGroup\":\"karpenter.sh\",\"controllerKind\":\"NodeClaim\",\"NodeClaim\":{\"name\":\"eks-gpu-np-gkx7t\"},\"namespace\":\"\",\"name\":\"eks-gpu-np-gkx7t\",\"reconcileID\":\"f2b28556-4808-4577-a559-f946a451b46c\",\"provider-id\":\"aws:///us-west-2c/i-02e475780d3aed0a1\",\"Node\":{\"name\":\"ip-10-0-32-176.us-west-2.compute.internal\"},\"allocatable\":{\"cpu\":\"15890m\",\"ephemeral-storage\":\"95551679124\",\"hugepages-1Gi\":\"0\",\"hugepages-2Mi\":\"0\",\"memory\":\"60398040Ki\",\"nvidia.com/gpu\":\"1\",\"pods\":\"234\"}}\n```", "```\n\n$ kubectl get pods -l app=my-llama-job\nNAME                 READY   STATUS    RESTARTS   AGE\nmy-llama-job-plgb5   1/1     Running   0          9m20s\n$ kubectl get nodes -l nvidia.com/gpu.present\nNAME                                        STATUS   ROLES\nip-10-0-32-176.us-west-2.compute.internal   Ready    <none>\n```", "```\n\n$ kubectl logs --selector app.kubernetes.io/instance=karpenter -n kube-system\n\"level\":\"INFO\",\"time\":\"2025-01-31T14:50:18.104Z\",\"logger\":\"controller\",\"message\":\"tainted node\",\"commit\":\"b897114\",\"controller\":\"node.termination\",\"controllerGroup\":\"\",\"controllerKind\":\"Node\",\"Node\":{\"name\":\"ip-10-0-32-176.us-west-2.compute.internal\"},\"namespace\":\"\",\"name\":\"ip-10-0-32-176.us-west-2.compute.internal\",\"reconcileID\":\"874424bd-d2f7-45ab-a399-41e5314fb3d3\",\"taint.Key\":\"karpenter.sh/disrupted\",\"taint.Value\":\"\",\"taint.Effect\":\"NoSchedule\"}\n{\"level\":\"INFO\",\"time\":\"2025-01-31T14:54:03.281Z\",\"logger\":\"controller\",\"message\":\"deleted node\",\"commit\":\"b897114\",\"controller\":\"node.termination\",\"controllerGroup\":\"\",\"controllerKind\":\"Node\",\"Node\":{\"name\":\"ip-10-0-32-176.us-west-2.compute.internal\"},\"namespace\":\"\",\"name\":\"ip-10-0-32-176.us-west-2.compute.internal\",\"reconcileID\":\"eb99f292-2ea2-4aba-ac88-528746cc7e89\"}\n```"]