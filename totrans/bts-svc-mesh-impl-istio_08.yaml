- en: '8'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '8'
- en: Scaling Istio to Multi-Cluster Deployments Across Kubernetes
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 扩展Istio至跨Kubernetes的多集群部署
- en: '**Containers** have changed not only how applications are developed but also
    how applications connect. Application networking, that is, networking between
    applications, is critical for production deployments and must be automated, elastically
    scalable, and secure. Real-world applications are deployed across on-premises,
    multiple clouds, Kubernetes clusters, and namespaces within clusters. Hence, there
    is a need to provide a Service Mesh across legacy and modern environments, providing
    seamless connectivity between applications.'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '**容器**不仅改变了应用程序的开发方式，还改变了应用程序的连接方式。应用程序网络，即应用程序之间的网络连接，对于生产部署至关重要，必须是自动化的、弹性可扩展的且安全的。实际应用程序部署在本地、多云、Kubernetes集群以及集群中的命名空间中。因此，有必要在传统环境和现代环境之间提供一个服务网格，实现应用程序之间的无缝连接。'
- en: In *Chapter 3*, we briefly discussed deployment models for Istio control planes.
    We discussed a single cluster with a local control plane, a primary and remote
    cluster with a single control plane, and a single cluster with an external control
    plane. A single-mesh/single-cluster deployment is the simplest but is also a non-practical
    deployment model because your production workload will include multiple Kubernetes
    clusters, possibly spread across multiple data centers.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在*第3章*中，我们简要讨论了Istio控制平面的部署模型。我们讨论了带有本地控制平面的单个集群、带有单个控制平面的主集群和远程集群，以及带有外部控制平面的单个集群。单网格/单集群部署是最简单的，但也是一种不实际的部署模型，因为您的生产工作负载将包括多个Kubernetes集群，可能分布在多个数据中心。
- en: 'In this chapter, we will go through the following topics to learn how to deploy
    Istio across multiple Kubernetes clusters and then how to federate them:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将通过以下主题，学习如何在多个Kubernetes集群之间部署Istio，并如何将它们联合起来：
- en: Establishing mutual trust in multi-cluster deployments
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在多集群部署中建立相互信任
- en: Primary-remote on multi-network
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多网络上的主-远程集群
- en: Primary-remote on the same network
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一网络上的主-远程集群
- en: Multi-primary on different networks
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同网络上的多主集群
- en: Multi-primary on the same network
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 同一网络上的多主集群
- en: This chapter is extremely hands-on, so please pay special attention to the *Technical
    requirements* section. Also, in each section, please pay special attention to
    the instructions for setting up clusters and configuring Istio.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容极具实践性，因此请特别注意*技术要求*部分。此外，在每个部分，请特别注意设置集群和配置Istio的说明。
- en: Technical requirements
  id: totrans-11
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 技术要求
- en: In this chapter, we will be using **Google Cloud** for hands-on activities.
    If you are a first-time user, you may be eligible for free credits, as described
    at [https://cloud.google.com/free](https://cloud.google.com/free). You will need
    a Google account to sign up; once you are signed up, please follow the Google
    documentation to install the **Google CLI**, as described at [https://cloud.google.com/sdk/docs/install](https://cloud.google.com/sdk/docs/install).
    After installing the Google CLI, you will need to initialize it using the steps
    described at [https://cloud.google.com/sdk/docs/initializing](https://cloud.google.com/sdk/docs/initializing).
    The init steps will make the necessary configurations so that you can interact
    with your Google Cloud account using the CLI.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用**Google Cloud**进行实际操作。如果您是第一次使用，您可能符合获得免费信用额度的条件，详情请参考[https://cloud.google.com/free](https://cloud.google.com/free)。您需要一个Google帐户进行注册；注册后，请按照Google文档中的说明安装**Google
    CLI**，具体说明见[https://cloud.google.com/sdk/docs/install](https://cloud.google.com/sdk/docs/install)。安装Google
    CLI后，您需要按照[https://cloud.google.com/sdk/docs/initializing](https://cloud.google.com/sdk/docs/initializing)中的步骤进行初始化。初始化步骤将完成必要的配置，以便您可以通过CLI与您的Google
    Cloud帐户进行交互。
- en: Setting up Kubernetes clusters
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置Kubernetes集群
- en: 'Once you have the account set up, we will create two Kubernetes clusters using
    the **Google Kubernetes Engine service**. To do this, follow these steps:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您设置好帐户，我们将使用**Google Kubernetes Engine服务**创建两个Kubernetes集群。为此，请按照以下步骤操作：
- en: 'Create cluster 1 using the following commands:'
  id: totrans-15
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用以下命令创建集群1：
- en: '[PRE0]'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE0]'
- en: In this example, we are creating a cluster named `cluster1` in the `australia-southeast1-a`
    zone in the `australia-southeast1` region. The machine type to be used is `e2-medium`
    with a default pool size of `3`. You can change the regions to whatever is closest
    to your location. You can change the instance type and other parameters, but be
    conscious of any costs it may incur.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在此示例中，我们正在创建一个名为`cluster1`的集群，位于`australia-southeast1`区域的`australia-southeast1-a`可用区。所使用的机器类型为`e2-medium`，默认池大小为`3`。你可以将区域更改为最接近你位置的区域。你也可以更改实例类型和其他参数，但请注意可能产生的费用。
- en: 'Next, create cluster 2\. The process is the same as that in the previous step,
    but we are using a different region and different subnets:'
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，创建集群2。过程与前一步相同，但我们使用了不同的区域和子网：
- en: '[PRE1]'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Now, set up the environment variables to reference the created clusters. Find
    the cluster reference name from the `kubectl` config:'
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 现在，设置环境变量以引用已创建的集群。从`kubectl`配置中找到集群引用名称：
- en: '[PRE2]'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'Set up the following context variables in every terminal window you will be
    using in this chapter:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中使用的每个终端窗口中设置以下上下文变量：
- en: '[PRE3]'
  id: totrans-23
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This completes the setup of the Kubernetes cluster in Google Cloud. In the next
    section, you will set up OpenSSL on your workstation.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了在 Google Cloud 中设置 Kubernetes 集群的步骤。在下一部分，你将在工作站上设置 OpenSSL。
- en: Setting up OpenSSL
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设置 OpenSSL
- en: We will be using OpenSSL to generate a root and intermediate **certificate authority**
    (**CA**). You will need OpenSSL 3.0 or higher. Mac users can follow the instructions
    at [https://formulae.brew.sh/formula/openssl@3](https://formulae.brew.sh/formula/openssl@3).
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 OpenSSL 生成根证书和中间**证书授权机构**（**CA**）。你需要使用 OpenSSL 3.0 或更高版本。Mac 用户可以按照[https://formulae.brew.sh/formula/openssl@3](https://formulae.brew.sh/formula/openssl@3)上的说明进行操作。
- en: 'You may see the following response:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会看到以下响应：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'In this case, manually add OpenSSL to `PATH`:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，手动将 OpenSSL 添加到`PATH`中：
- en: '[PRE5]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: Please make sure that the path reflects the terminals from where you will be
    performing certificate-related commands.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 请确保路径反映了你将执行与证书相关命令的终端。
- en: Additional Google Cloud steps
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 额外的 Google Cloud 步骤
- en: 'The following steps are useful for establishing connectivity between the two
    Kubernetes clusters. Please do not perform the steps in this section yet. We will
    refer to these steps while carrying out the practical exercises in the subsequent
    sections:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 以下步骤对于在两个 Kubernetes 集群之间建立连接非常有用。请暂时不要执行本部分中的步骤，我们将在后续的实践环节中参考这些步骤：
- en: 'Calculate the **Classless Inter-Domain Routing** (**CIDR**) block of clusters
    1 and 2:'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 计算集群1和集群2的**无类域间路由**（**CIDR**）块：
- en: '[PRE6]'
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The value of `ALL_CLUSTER_CIDR` will be something similar to `10.124.0.0/14,10.84.0.0/14`.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '`ALL_CLUSTER_CIDR`的值将类似于`10.124.0.0/14,10.84.0.0/14`。'
- en: 'Get the `NETTAGS` of clusters 1 and 2:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 获取集群1和集群2的`NETTAGS`：
- en: '[PRE7]'
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE7]'
- en: The value of `ALL_CLUSTER_NETTAGS` will be something similar to `gke-primary-cluster-9d4f7718-node`,
    `gke-remote-cluster-c50b7cac-node`.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '`ALL_CLUSTER_NETTAGS`的值将类似于`gke-primary-cluster-9d4f7718-node`，`gke-remote-cluster-c50b7cac-node`。'
- en: 'Create a firewall rule to allow all traffic between clusters 1 and 2:'
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个防火墙规则，允许集群1和集群2之间的所有流量：
- en: '[PRE8]'
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Delete Google Cloud Kubernetes clusters and firewall rules by performing the
    following steps:'
  id: totrans-42
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过执行以下步骤删除 Google Cloud Kubernetes 集群和防火墙规则：
- en: 'Delete the firewall:'
  id: totrans-43
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 删除防火墙：
- en: '[PRE9]'
  id: totrans-44
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'cluster2:'
  id: totrans-45
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'cluster2:'
- en: '[PRE10]'
  id: totrans-46
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-47
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This concludes all the steps required to prepare for the upcoming sections.
    In the next section, we will start with the fundamentals required for multi-cluster
    deployments.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了为接下来的部分准备所需的所有步骤。在下一部分，我们将开始介绍多集群部署所需的基础知识。
- en: Establishing mutual trust in multi-cluster deployments
  id: totrans-49
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在多集群部署中建立相互信任
- en: When setting up multi-cluster deployments, we must also establish trust between
    the clusters. The Istio architecture is based on the zero-trust model, where the
    network is assumed to be hostile and there is no implicit trust for services.
    Thus, Istio authenticates each service communication to establish the authenticity
    of the workload. Every workload in the cluster is assigned an identity and service-to-service
    communication is performed over mTLS by sidecars. Also, all communication between
    the sidecar and control plane happens over mTLS. In the previous chapters, we
    used an Istio CA with a self-signed root certificate. When setting up multi-clusters,
    we must ensure that the workload is assigned identities that can be understood
    and trusted by all other services in the mesh. Istio does this by distributing
    a CA bundle to all workloads, which contains a chain of certificates that can
    then be used by sidecars to identify the sidecar at the other end of the communication.
    In a multi-cluster environment, we need to ensure that the CA bundle contains
    the correct certificate chain to validate all services in the data plane.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置多集群部署时，我们还必须在集群之间建立信任。Istio 架构基于零信任模型，假设网络是恶意的，并且服务之间没有隐式信任。因此，Istio 对每个服务的通信进行身份验证，以验证工作负载的真实性。集群中的每个工作负载都会被分配一个身份，服务与服务之间的通信通过
    sidecar 上的 mTLS 完成。此外，sidecar 与控制平面之间的所有通信也都通过 mTLS 进行。在前面的章节中，我们使用了带有自签名根证书的
    Istio CA。在设置多集群时，我们必须确保工作负载分配的身份能够被网格中所有其他服务理解和信任。Istio 通过将 CA 捆绑包分发到所有工作负载来实现这一点，捆绑包包含一条证书链，sidecar
    可以利用这条证书链来识别通信另一端的 sidecar。在多集群环境中，我们需要确保 CA 捆绑包包含正确的证书链，以验证数据平面中的所有服务。
- en: 'There are two options to achieve this:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 有两种方法可以实现这一点：
- en: '**Plugin CA certificate**: Using this option, we create root and intermediate
    certificates outside Istio and configure Istio to use the created intermediate
    certificate. This option allows you to make use of a known CA or even your own
    internal CA as a root CA to generate an intermediate CA for Istio. You provide
    the intermediate CA certificate and keys to Istio along with root CA certificates.
    Istio then makes use of the intermediate CA and key to sign workloads and embeds
    root CA certificates as a root of trust.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**插件 CA 证书**：使用此选项，我们在 Istio 外部创建根证书和中间证书，并配置 Istio 使用创建的中间证书。此选项允许您使用已知的 CA，甚至是您自己的内部
    CA 作为根证书颁发机构，为 Istio 生成中间 CA。您将中间 CA 证书和密钥与根 CA 证书一起提供给 Istio。然后，Istio 使用中间 CA
    和密钥来签署工作负载，并将根 CA 证书作为信任根嵌入其中。'
- en: '![Figure 8.1 – Intermediate CA as a plugin CA to Istio](img/B17989_08_01.jpg)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.1 – 作为 Istio 插件 CA 的中间 CA](img/B17989_08_01.jpg)'
- en: Figure 8.1 – Intermediate CA as a plugin CA to Istio
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.1 – 作为 Istio 插件 CA 的中间 CA
- en: '**CA external to Istio**: We make use of an external CA that can sign certificates
    without needing to store private keys inside the Kubernetes cluster. When Istio
    uses a self-signed certificate, it stores its self-signed private keys as a Secret
    in the Kubernetes cluster. If using a plugin CA, it still has to save its intermediate
    keys in the cluster. Storing private keys in the Kubernetes cluster is not a secure
    option if access to Kubernetes is not restricted. In such cases, we can make use
    of an external CA to act as a CA for signing certificates.'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**外部 CA 证书颁发机构**：我们使用外部 CA 来签发证书，而无需将私钥存储在 Kubernetes 集群内。当 Istio 使用自签名证书时，它会将自签名的私钥作为一个
    Secret 存储在 Kubernetes 集群内。如果使用插件 CA，它仍然需要在集群中保存中间密钥。如果 Kubernetes 的访问权限没有受到限制，那么将私钥存储在
    Kubernetes 集群中并不是一个安全的选择。在这种情况下，我们可以使用外部 CA 来作为证书签发机构。'
- en: '![Figure 8.2 – cert-manager](img/B17989_08_02.jpg)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.2 – cert-manager](img/B17989_08_02.jpg)'
- en: Figure 8.2 – cert-manager
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.2 – cert-manager
- en: One such certificate management software is **cert-manager**. It adds external
    certificates and certificate issuers as resource types in Kubernetes clusters
    and simplifies the process of obtaining, renewing, and using those certificates.
    It can integrate with a variety of supported sources, including Let’s Encrypt
    and HashiCorp Vault. It ensures certificates are valid and up to date, and it
    attempts to renew certificates at a configured time before expiry. The cert-manager
    software integrates with Kubernetes via the **Kubernetes CSR API**; you can read
    about it at [https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/](https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/).
    When using cert-manager, Istio approves the CSR from the service workload and
    forwards the request to cert-manager for signing. cert-manager signs the request
    and returns the certificates to istiod, which are then passed on to istio-agent.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一种这样的证书管理软件是**cert-manager**。它将外部证书和证书颁发者作为资源类型添加到 Kubernetes 集群中，并简化了获取、续订和使用这些证书的过程。它可以与多种支持的源集成，包括
    Let's Encrypt 和 HashiCorp Vault。它确保证书有效并及时更新，并在证书过期之前的配置时间尝试续订证书。cert-manager
    软件通过 **Kubernetes CSR API** 与 Kubernetes 集成；您可以在 [https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/](https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/)
    上阅读相关内容。当使用 cert-manager 时，Istio 批准来自服务工作负载的 CSR，并将请求转发给 cert-manager 进行签名。cert-manager
    签名该请求并将证书返回给 istiod，之后这些证书将传递给 istio-agent。
- en: In this chapter, we will make use of the plugin CA certificate option, which
    is the simpler and easier option to use, so that we can focus on the multi-cluster
    setup of Istio. In the following sections, we will go through setting up Istio
    in various cluster configurations.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将使用插件 CA 证书选项，这是一个更简单、易用的选项，这样我们就可以专注于 Istio 的多集群设置。在接下来的部分中，我们将介绍在不同集群配置中设置
    Istio。
- en: Primary-remote on multi-network
  id: totrans-60
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 多网络上的主远程
- en: In the primary-remote configuration, we will install the Istio control plane
    on cluster 1\. Clusters 1 and 2 are on different networks with no direct connectivity
    between the Pods. Cluster 1 will host the Istio control plane as well as a data
    plane. Cluster 2 will only host the data plane and uses the control plane from
    cluster 1\. Clusters 1 and 2 both use an intermediate CA signed by a root CA.
    In cluster 1, istiod observes the API server in clusters 1 and 2 for any changes
    to Kubernetes resources. We will create an Ingress gateway in both clusters, which
    will be used for cross-network communications between the workloads. We will call
    this Ingress gateway the east-west gateway because it is used for east-west communication.
    The east-west gateway takes care of authentication workloads between clusters
    1 and 2 and acts as a hub for all traffic traveling between the two clusters.
    In the following diagram, the dashed arrows in data plane traffic represent service
    requests from cluster 1 to cluster 2 traversing via the east-west gateway. In
    cluster 2, the dotted arrows represent data plane traffic traveling from cluster
    2 to cluster 1.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在主远程配置中，我们将在集群 1 上安装 Istio 控制平面。集群 1 和集群 2 位于不同的网络之间，Pods 之间没有直接连接。集群 1 将承载
    Istio 控制平面以及数据平面。集群 2 仅承载数据平面，并使用集群 1 的控制平面。集群 1 和集群 2 都使用由根 CA 签发的中间 CA。在集群 1
    中，istiod 观察集群 1 和集群 2 中的 API 服务器，以监控 Kubernetes 资源的任何变化。我们将在两个集群中都创建一个 Ingress
    网关，用于在工作负载之间进行跨网络通信。我们将这个 Ingress 网关称为东西网关，因为它用于东西方向的通信。东西网关负责处理集群 1 和集群 2 之间的身份验证工作负载，并充当两个集群之间所有流量的中心枢纽。在下图中，数据平面流量中的虚线箭头表示来自集群
    1 到集群 2 的服务请求，通过东西网关传递。在集群 2 中，虚线箭头表示数据平面流量从集群 2 到集群 1。
- en: '![Figure 8.3 – Primary-remote cluster on different networks](img/B17989_08_03.jpg)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.3 – 不同网络上的主远程集群](img/B17989_08_03.jpg)'
- en: Figure 8.3 – Primary-remote cluster on different networks
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.3 – 不同网络上的主远程集群
- en: In the next section, we will start with configuring mutual trust between the
    two Kubernetes clusters. We will make use of the plugin CA option, as described
    in the previous section, *Establishing mutual trust in* *multi-cluster deployments*.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一部分中，我们将从配置两个 Kubernetes 集群之间的相互信任开始。我们将使用上一部分中描述的插件 CA 选项，*在多集群部署中建立相互信任*。
- en: Establishing trust between the two clusters
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在两个集群之间建立信任
- en: We need to configure Istio CAs on both clusters to trust each other. As described
    in the previous section, we will do that by creating a root CA and using it to
    generate intermediate CAs for both clusters.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们需要在两个集群上配置 Istio CA 以相互信任。如前一部分所述，我们将通过创建根 CA 并使用它为两个集群生成中间 CA 来实现这一点。
- en: 'Go to the Istio installation directory and create a folder called `certs` to
    hold the generated certificates. Then, perform the following instructions from
    the `cert` directory:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 转到 Istio 安装目录，并创建一个名为 `certs` 的文件夹，用于存放生成的证书。然后，从 `cert` 目录执行以下指令：
- en: 'Generate the root certificate:'
  id: totrans-68
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 生成根证书：
- en: '[PRE12]'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This will generate `root-key.pem`, which is the private key, and `root-cert.pem`,
    which is the root certificate.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 这将生成 `root-key.pem`（私钥）和 `root-cert.pem`（根证书）。
- en: 'Generate the intermediate CA for `cluster1`:'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 `cluster1` 生成中间 CA：
- en: '[PRE13]'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This will generate an intermediate CA for `cluster1`, with the CA key in `ca-key.pem`,
    the certificate in `ca-cert.pem`, and the chain in `cert-chain.pem`.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为 `cluster1` 生成一个中间 CA，CA 密钥存放在 `ca-key.pem` 中，证书存放在 `ca-cert.pem` 中，链存放在
    `cert-chain.pem` 中。
- en: 'Generate an intermediate CA for `cluster2`:'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 `cluster2` 生成一个中间 CA：
- en: '[PRE14]'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE14]'
- en: This will generate an intermediate CA for `cluster2`, with the CA key in `ca-key.pem`,
    the certificate in `ca-cert.pem`, and the chain in `cert-chain.pem`.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这将为 `cluster2` 生成一个中间 CA，CA 密钥存放在 `ca-key.pem` 中，证书存放在 `ca-cert.pem` 中，链存放在
    `cert-chain.pem` 中。
- en: 'Set the environment variables as described in the third and fourth steps of
    the *Setting up Kubernetes clusters* subsection in the *Technical requirements*
    section. This helps to run commands targeting multiple Kubernetes clusters:'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照《技术要求》部分 *设置 Kubernetes 集群* 子部分中的第三步和第四步描述设置环境变量。这有助于执行针对多个 Kubernetes 集群的命令：
- en: '[PRE15]'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE15]'
- en: 'Create namespaces in the primary and remote clusters. We will install Istio
    in this namespace:'
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在主集群和远程集群中创建命名空间。我们将在此命名空间中安装 Istio：
- en: '[PRE16]'
  id: totrans-80
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'Create `secret` in `cluster1`, which will be used by Istio as an intermediate
    CA:'
  id: totrans-81
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `cluster1` 中创建 `secret`，该 `secret` 将作为中间 CA 供 Istio 使用：
- en: '[PRE17]'
  id: totrans-82
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Create `secret` in `cluster2`, which will be used by Istio as an intermediate
    CA:'
  id: totrans-83
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在 `cluster2` 中创建 `secret`，该 `secret` 将作为中间 CA 供 Istio 使用：
- en: '[PRE18]'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'Label the `namespace` in `cluster1` and `cluster2` with the network name:'
  id: totrans-85
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为 `cluster1` 和 `cluster2` 中的 `namespace` 添加网络名称标签：
- en: '[PRE19]'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'Configure `cluster1` as follows:'
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照以下方式配置 `cluster1`：
- en: 'Create the Istio operator config:'
  id: totrans-88
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建 Istio 操作员配置：
- en: '[PRE20]'
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE20]'
- en: The file is available in `Chapter08/01-Cluster1.yaml` on GitHub.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 该文件可以在 GitHub 上的 `Chapter08/01-Cluster1.yaml` 找到。
- en: 'Install Istio:'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 Istio：
- en: '[PRE21]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'In this step, we will install the east-west gateway in `cluster1`, which will
    expose all services in the mesh in `cluster1` to services in `cluster2`. This
    gateway is accessible to all services in `cluster2` but it can only be accessed
    by services with a trusted mTLS certificate and workload ID, that is, services
    that are part of a mesh:'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在此步骤中，我们将在 `cluster1` 中安装东西向网关，它将把 `cluster1` 中的所有服务暴露给 `cluster2` 中的服务。此网关可供
    `cluster2` 中的所有服务访问，但只能由具有信任的 mTLS 证书和工作负载 ID 的服务访问，也就是说，只有属于网格中的服务才能访问：
- en: '[PRE22]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'The east-west gateway is also used to expose istiod endpoints to `cluster2`.
    These endpoints are used by the mutating webhooks and `istio-proxy` in `cluster2`.
    The following configuration creates a gateway named `istiod-gateway` and exposes
    ports `15012` and `15017` over TLS:'
  id: totrans-95
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 东西向网关还用于将 istiod 端点暴露给 `cluster2`。这些端点由 `cluster2` 中的变更 webhook 和 `istio-proxy`
    使用。以下配置创建一个名为 `istiod-gateway` 的网关，并通过 TLS 暴露端口 `15012` 和 `15017`：
- en: '[PRE23]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The following virtual service routes inbound traffic on ports `15012` and `15017`
    to `15012` and `443` to the `istiod.istio-system.svc.cluster.local` service on
    `cluster1`:'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 以下虚拟服务将入站流量从端口 `15012` 和 `15017` 路由到 `cluster1` 上的 `istiod.istio-system.svc.cluster.local`
    服务的端口 `15012` 和 `443`：
- en: '[PRE24]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'The configuration is available in `samples/multicluster/expose-istiod.yaml`
    in the Istio installation folder. Apply the configuration using the following
    commands:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 配置文件可以在 Istio 安装文件夹中的 `samples/multicluster/expose-istiod.yaml` 找到。使用以下命令应用该配置：
- en: '[PRE25]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: 'Create another gateway for exposing workload services to `cluster2`. The configuration
    is very similar to `istiod-gateway` except that we are exposing port `15443`,
    which is specifically dedicated to traffic designated for services in the mesh:'
  id: totrans-101
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 为了将工作负载服务暴露给 `cluster2`，我们需要创建另一个网关。该配置与 `istiod-gateway` 非常相似，不同之处在于我们暴露的是专门为网格内服务设计的端口
    `15443`：
- en: '[PRE26]'
  id: totrans-102
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE26]'
- en: 'A sample file is available in `samples/multicluster/expose-services.yaml` in
    the Istio installation directory:'
  id: totrans-103
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 一个示例文件可以在 Istio 安装目录的 `samples/multicluster/expose-services.yaml` 中找到：
- en: '[PRE27]'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE27]'
- en: 'In this step, we will configure `cluster2`. To do this, you will need to note
    down the external IP for the east-west gateway created in the previous step. In
    the following steps, we will first prepare the configuration file for Istio and
    then use that to install Istio in `cluster2`:'
  id: totrans-105
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在这一步，我们将配置`cluster2`。为此，您需要记下在前一步中创建的东西方网关的外部 IP。在接下来的步骤中，我们将首先准备 Istio 的配置文件，然后使用该配置文件在`cluster2`中安装
    Istio：
- en: 'Configure the Istio operator configuration. The following is the sample configuration,
    and it has two noteworthy configurations:'
  id: totrans-106
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 配置 Istio 操作员配置。以下是示例配置，它包含两个需要注意的配置：
- en: '`injectionPath`: Constructed as `/inject/cluster/CLUSTER_NAME OF_REMOTE_CLUSTER/net/`
    `NETWORK_NAME OF_REMOTE_CLUSTER`'
  id: totrans-107
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`injectionPath`：构造为`/inject/cluster/REMOTE_CLUSTER的CLUSTER_NAME/net/` `REMOTE_CLUSTER的NETWORK_NAME`'
- en: '`remotePilotAddress`: IP of the east-west gateway exposing ports `15012` and
    `15017` and the network reachable to `cluster2`'
  id: totrans-108
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`remotePilotAddress`：东西方网关的 IP，暴露端口`15012`和`15017`，并且网络可以访问`cluster2`'
- en: 'The sample file is available in `Chapter08/01-Cluster2.yaml` on GitHub:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 示例文件可以在 GitHub 上的`Chapter08/01-Cluster2.yaml`中找到：
- en: '[PRE28]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: 'Label and annotate the namespace. Setting the `topology.istio.io/controlPlaneClusters`
    namespace annotation to `cluster1` instructs istiod running on `cluster1` to manage
    `cluster2`, when it is attached as a remote cluster:'
  id: totrans-111
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 标记并注解命名空间。将`topology.istio.io/controlPlaneClusters`命名空间注解设置为`cluster1`，指示在`cluster1`上运行的
    istiod 管理 `cluster2`，当它作为远程集群附加时：
- en: '[PRE29]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: 'Set the network for `cluster2` by adding a label to the `istio-system` namespace.
    The network name should be the same as you configured in the `01-Cluster2.yaml`
    file in the previous step:'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 通过向 `istio-system` 命名空间添加标签来设置 `cluster2` 的网络。网络名称应与您在前一步中 `01-Cluster2.yaml`
    文件中配置的名称相同：
- en: '[PRE30]'
  id: totrans-114
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: 'Install Istio in `cluster2`:'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`cluster2`中安装 Istio：
- en: '[PRE31]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'Provide primary cluster access to the API server of the remote cluster:'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 提供主集群访问远程集群 API 服务器：
- en: '[PRE32]'
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE32]'
- en: 'After performing this step, istiod in `cluster1` will be able to communicate
    with the Kubernetes API server in `cluster2`, giving it visibility of services,
    endpoints, and namespaces in `cluster2`. As soon the API server is accessible
    to istiod, it will patch the certificates in webhooks in `cluster2`. Now perform
    the following before and after *step 13*:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 执行此步骤后，`cluster1`中的 istiod 将能够与`cluster2`中的 Kubernetes API 服务器通信，从而能够看到`cluster2`中的服务、端点和命名空间。只要
    API 服务器对 istiod 可访问，它将修补`cluster2`中的 webhooks 中的证书。现在，在*第 13 步*之前和之后执行以下操作：
- en: '[PRE33]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: 'You will notice that the following has been updated in the sidecar injector:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 您会注意到以下内容已在边车注入器中更新：
- en: '[PRE34]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: 'Create the east-west gateway to handle traffic Ingress from the primary cluster
    to the remote cluster:'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建东西方网关以处理从主集群到远程集群的流量入口：
- en: '[PRE35]'
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE35]'
- en: 'Install CRDs so that you can configure traffic rules:'
  id: totrans-125
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装 CRDs，以便您可以配置流量规则：
- en: '[PRE36]'
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE36]'
- en: 'Expose all services in the remote cluster:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 暴露远程集群中的所有服务：
- en: '[PRE37]'
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE37]'
- en: This completes the installation and configuration of Istio in both clusters.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 这完成了在两个集群中安装和配置 Istio。
- en: Deploying the Envoy dummy application
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 部署 Envoy 虚拟应用
- en: 'In this section, we will first deploy two versions of the Envoy dummy application
    and then test the traffic distribution of the dummy application. Let’s get started
    with deploying two versions of the Envoy dummy application:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将首先部署两个版本的 Envoy 虚拟应用，然后测试虚拟应用的流量分配。让我们从部署两个版本的 Envoy 虚拟应用开始：
- en: 'Create namespaces and enable `istio-injection`:'
  id: totrans-132
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建命名空间并启用`istio-injection`：
- en: '[PRE38]'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'Create config maps:'
  id: totrans-134
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建配置映射：
- en: '[PRE39]'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE39]'
- en: 'Deploy the Envoy application:'
  id: totrans-136
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 部署 Envoy 应用：
- en: '[PRE40]'
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE40]'
- en: 'Expose Envoy using a gateway and virtual services. You can use any cluster
    as `context`; istiod will propagate the configuration to another cluster:'
  id: totrans-138
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用网关和虚拟服务暴露 Envoy。您可以使用任何集群作为`context`；istiod 将把配置传播到另一个集群：
- en: '[PRE41]'
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE41]'
- en: 'We have now successfully deployed the `envoydummy` application across both
    clusters. Now, let’s move on to testing the traffic distribution of the dummy
    application:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在已经成功地在两个集群中部署了`envoydummy`应用。现在，让我们继续测试虚拟应用的流量分配：
- en: 'The IP is the external IP of the Ingress gateway. Please note that it is different
    from the east-west gateway. The east-west gateway is used for inter-cluster communication
    between services workloads, whereas the Ingress gateway is used for north-south
    communication. As we are using `curl` from outside the cluster, we will make use
    of the north-south gateway:'
  id: totrans-141
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: IP 是 Ingress 网关的外部 IP，请注意，它与东西方网关不同。东西方网关用于服务工作负载之间的集群间通信，而 Ingress 网关用于南北向通信。由于我们将从集群外部使用
    `curl`，我们将使用南北向网关：
- en: '[PRE42]'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'Go ahead and call the Envoy dummy using the following commands:'
  id: totrans-143
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 继续使用以下命令调用Envoy虚拟机：
- en: '[PRE43]'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE43]'
- en: As you must have observed in the output, the traffic is distributed across both
    clusters. The Ingress gateway in `cluster1` has awareness of `v2` of the Envoy
    dummy in `cluster2` and is able to route traffic between `v1` and `v2` of the
    Envoy dummy services.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你在输出中观察到的，流量在两个集群间分布。`cluster1`中的Ingress网关能够识别`cluster2`中的Envoy虚拟机的`v2`，并能够在`v1`和`v2`之间路由流量。
- en: This concludes the setup of primary-remote on separate networks. In the next
    section, we will set up primate-remote on the same network.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了不同网络中主远程集群的设置。在下一节中，我们将设置同一网络中的主远程集群。
- en: Primary-remote on the same network
  id: totrans-147
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 同一网络上的主远程集群
- en: In primary-remote on the same network cluster, the services can access other
    inter-cluster services because they are on the same network. That means we don’t
    need an east-west gateway for inter-cluster communication between services. We
    will make `cluster1` the primary cluster and `cluster2` the remote cluster. We
    still need an east-west gateway to proxy istiod services. All control plane-related
    traffic from cluster 2 to cluster 1 will traverse via the east-west gateway.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一网络集群中的主集群和远程集群，服务可以访问其他集群间服务，因为它们位于同一网络中。这意味着我们不需要东-西网关来实现集群间服务的通信。我们将把`cluster1`设置为主集群，`cluster2`设置为远程集群。我们仍然需要一个东-西网关来代理istiod服务。所有从集群2到集群1的控制平面相关流量将通过东-西网关进行传输。
- en: '![Figure 8.4 – Primary remote cluster sharing the same network](img/B17989_08_04.jpg)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.4 – 主远程集群共享同一网络](img/B17989_08_04.jpg)'
- en: Figure 8.4 – Primary remote cluster sharing the same network
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.4 – 主远程集群共享同一网络
- en: Here, we will make use of the infrastructure we set up in the previous section,
    *Primary-remote on multi-network*, but if you want, you can also create a separate
    infrastructure.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们将使用上一节中设置的基础设施，*多网络上的主远程集群*，但如果你愿意，你也可以创建一个单独的基础设施。
- en: Let’s get started!
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！
- en: 'If you are using the Kubernetes cluster from the previous section, you will
    need to first uninstall Istio on the remote cluster using the following code block:'
  id: totrans-153
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 如果你使用的是上一节中的Kubernetes集群，你需要先使用以下代码块卸载远程集群上的Istio：
- en: '[PRE44]'
  id: totrans-154
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'We will then open the firewall between the two clusters by following the steps
    provided in the *Additional Google Cloud* *steps* section:'
  id: totrans-155
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将通过以下*额外的Google Cloud* *步骤*部分提供的步骤打开两个集群之间的防火墙：
- en: '[PRE45]'
  id: totrans-156
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '*Step 1* will assign a value of something similar to `10.124.0.0/14,10.84.0.0/14`,
    as seen in the following snippet:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤1*将分配类似于`10.124.0.0/14,10.84.0.0/14`的值，如下所示：'
- en: '[PRE46]'
  id: totrans-158
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: '*Step 2* will assign a value of something similar to `gke-primary-cluster-9d4f7718-node`,
    `gke-remote-cluster-c50b7cac-node`.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤2*将分配类似于`gke-primary-cluster-9d4f7718-node`，`gke-remote-cluster-c50b7cac-node`的值。'
- en: '*Step 3* creates a firewall rule to allow all traffic between clusters 1 and
    2:'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '*步骤3*创建一条防火墙规则，允许集群1和集群2之间的所有流量：'
- en: '[PRE47]'
  id: totrans-161
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: After performing these steps, both `cluster1` and `cluster2` will have bidirectional
    network access.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 执行这些步骤后，`cluster1`和`cluster2`将具有双向网络访问。
- en: 'Perform *step 7* from the *Primary-remote on multi-network* section. The step
    creates `secret` in `cluster2`, which will be used by Istio as an intermediate
    CA. We will also need to annotate the `istio-system` namespace using the following
    steps:'
  id: totrans-163
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行*步骤7*，这是*多网络上的主远程集群*一节中的步骤。此步骤将在`cluster2`中创建`secret`，它将被Istio作为中间CA使用。我们还需要使用以下步骤注释`istio-system`命名空间：
- en: '[PRE48]'
  id: totrans-164
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'Install Istio in `cluster2`. We will be using the following configuration in
    the installation:'
  id: totrans-165
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`cluster2`中安装Istio。我们将在安装中使用以下配置：
- en: '[PRE49]'
  id: totrans-166
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE49]'
- en: 'Note that `injectionPath` has the value `network1` instead of `network2`. `remotePilotAddress`
    is the external IP of the east-west gateway of `cluster1`. You will find this
    configuration in `Chapter08/02-Cluster2.yaml`. The following command will install
    Istio in cluster 2 using the configuration file:'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，`injectionPath`的值为`network1`，而不是`network2`。`remotePilotAddress`是`cluster1`的东-西网关的外部IP。你将在`Chapter08/02-Cluster2.yaml`中找到此配置。以下命令将使用配置文件在集群2中安装Istio：
- en: '[PRE50]'
  id: totrans-168
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: This will complete the installation of Istio in `cluster2`.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 这将完成在`cluster2`中安装Istio。
- en: 'Next, we will create a remote Secret that provides istiod in `cluster1` with
    access to the Kubernetes API server in `cluster2`:'
  id: totrans-170
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，我们将创建一个远程Secret，提供Istiod在`cluster1`中访问`cluster2`的Kubernetes API服务器：
- en: '[PRE51]'
  id: totrans-171
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE51]'
- en: This concludes the setup of the primary-remote cluster in the same network.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了同一网络中主远程集群的设置。
- en: 'Next, we will test the setup by deploying the Envoy dummy application as we
    did earlier in the *Primary-remote on multi-network* section. Follow *steps 1–4*
    of the *Deploying the Envoy dummy application* sub-section of Primary-remote on
    multi-network section to install the `envoydummy` app. Once it''s deployed, we
    can test whether the Envoy dummy service traffic is distributed across the two
    clusters:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过部署 Envoy 虚拟应用程序来测试设置，就像我们在*多网络上的主远程*部分中做的那样。按照*多网络上主远程*部分中*部署 Envoy
    虚拟应用程序*子部分的*步骤 1–4*来安装 `envoydummy` 应用程序。部署完成后，我们可以测试是否 Envoy 虚拟服务的流量会在两个集群之间分配：
- en: '[PRE52]'
  id: totrans-174
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: From the response, you can observe that traffic is distributed across both `cluster1`
    and `cluster2`. Both clusters are aware of each other’s services and the Service
    Mesh is able to distribute traffic across the two clusters.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 从响应中可以观察到，流量在 `cluster1` 和 `cluster2` 之间分配。两个集群都能识别彼此的服务，服务网格能够在两个集群之间分配流量。
- en: 'This concludes the setup of the primary remote cluster over the shared network.
    As we have made several changes to our Kubernetes cluster, it is recommended that
    you delete them, as well as the firewall rule, to get a clean slate before performing
    the tasks described in the subsequent sections. The following is an example of
    how you can delete clusters. Please change the parameter values as per your configuration:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 这标志着通过共享网络设置主远程集群的过程结束。由于我们对 Kubernetes 集群进行了多次修改，建议在执行后续任务之前删除这些更改，以及防火墙规则，以确保一个干净的环境。以下是删除集群的示例，请根据您的配置更改参数值：
- en: '[PRE53]'
  id: totrans-177
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: In the next section, we will perform a primary-primary setup of clusters on
    separate networks.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将执行一个在不同网络上的主-主集群设置。
- en: Multi-primary on different networks
  id: totrans-179
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 不同网络上的多主集群
- en: The control plane has high availability in a multi-primary setup. In the architecture
    options discussed in the previous sections, we had one primary cluster and the
    rest of the clusters didn’t use istiod, risking a loss of control if the primary
    control plane suffers an outage due to unforeseen circumstances. In a multi-primary
    cluster, we have multiple primary control planes providing uninterrupted access
    to the mesh even if one of the control planes suffers a temporary outage.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在多主集群中，控制平面具有高可用性。在前面讨论的架构选项中，我们有一个主集群，其他集群没有使用 istiod，因此如果主控制平面由于不可预见的情况发生故障，可能会导致控制丧失。在多主集群中，我们有多个主控制平面，即使其中一个控制平面发生短暂故障，网格仍能不间断提供服务。
- en: '![Figure 8.5 – Primary-primary on separate networks](img/B17989_08_05.jpg)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.5 – 在不同网络上的主-主集群](img/B17989_08_05.jpg)'
- en: Figure 8.5 – Primary-primary on separate networks
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.5 – 在不同网络上的主-主集群
- en: 'We will start by first setting up the clusters, followed by establishing trust
    between the two clusters. Perform the following steps to establish a multi-primary
    cluster:'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将首先设置集群，然后在两个集群之间建立信任。执行以下步骤以建立多主集群：
- en: Set up the two clusters as per the initial set of steps in the *Setting up Kubernetes
    clusters* section. This will complete the creation of the cluster as well as setting
    up the context variables. Because both clusters are primary, let’s call them `primary1`
    and `primary2` when creating the cluster in Google Cloud.
  id: totrans-184
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按照*设置 Kubernetes 集群*部分中的初始步骤设置这两个集群。这将完成集群的创建并设置上下文变量。由于这两个集群都是主集群，我们在 Google
    Cloud 中创建集群时，将它们命名为 `primary1` 和 `primary2`。
- en: Perform *steps 1–7* of the *Primary-remote on multi-network* section to establish
    trust between the cluster. These steps will create the certificates, create namespaces,
    and then create a Secret in the namespaces.
  id: totrans-185
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 执行*步骤 1–7*，这些步骤位于*多网络上的主远程*部分，以建立集群之间的信任。这些步骤将创建证书、创建命名空间，然后在命名空间中创建一个 Secret。
- en: Label the `istio-system` namespaces in both clusters with their network names.
  id: totrans-186
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在两个集群中为 `istio-system` 命名空间标记其网络名称。
- en: 'First, apply the `topology.istio.io/network` label with the value `network1`
    to the `istio-system` namespace in `cluster1`:'
  id: totrans-187
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 首先，将 `topology.istio.io/network` 标签应用到 `cluster1` 中 `istio-system` 命名空间，标签值为
    `network1`：
- en: '[PRE54]'
  id: totrans-188
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE54]'
- en: 'Next, apply the `topology.istio.io/network` label with the value `network2`
    to the `istio-system` namespace in `cluster2`:'
  id: totrans-189
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 接下来，将 `topology.istio.io/network` 标签应用到 `cluster2` 中 `istio-system` 命名空间，标签值为
    `network2`：
- en: '[PRE55]'
  id: totrans-190
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE55]'
- en: 'The Istio operator configuration for `cluster1` is similar to the primary remote
    configuration, so we will be using the `01-cluster1.yaml` file to install Istio
    in `cluster1`:'
  id: totrans-191
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '`cluster1` 的 Istio 操作符配置类似于主远程配置，因此我们将使用 `01-cluster1.yaml` 文件来安装 Istio 在 `cluster1`
    中：'
- en: '[PRE56]'
  id: totrans-192
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE56]'
- en: 'Install the east-west gateway in `cluster1`:'
  id: totrans-193
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 在`cluster1`中安装东西向网关：
- en: '[PRE57]'
  id: totrans-194
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE57]'
- en: 'Create a gateway configuration to expose all services in `cluster1` via the
    east-west gateway:'
  id: totrans-195
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个网关配置，以通过东西向网关公开`cluster1`中的所有服务：
- en: '[PRE58]'
  id: totrans-196
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE58]'
- en: 'We will be using the following Istio operator configuration to configure `cluster2`
    and install Istio:'
  id: totrans-197
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将使用以下Istio操作员配置来配置`cluster2`并安装Istio：
- en: '[PRE59]'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE59]'
- en: 'Note that we are not providing a profile in the configuration, which means
    a default configuration profile will be selected. In the default configuration,
    `istioctl` installs the Ingress gateway and istiod. To learn more about the configuration
    profile and what is included in each profile, please use the following command:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，我们没有在配置中提供配置文件，这意味着将选择默认配置文件。在默认配置中，`istioctl`会安装Ingress网关和istiod。要了解更多有关配置文件的信息，以及每个配置文件中包含的内容，请使用以下命令：
- en: '[PRE60]'
  id: totrans-200
  prefs: []
  type: TYPE_PRE
  zh: '[PRE60]'
- en: 'The sample file is available in `Chapter08/03-Cluster3.yaml`. Install Istio
    in `cluster2` using the following command:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 示例文件可以在`Chapter08/03-Cluster3.yaml`中找到。使用以下命令在`cluster2`中安装Istio：
- en: '[PRE61]'
  id: totrans-202
  prefs: []
  type: TYPE_PRE
  zh: '[PRE61]'
- en: 'Install the east-west gateway and expose all services:'
  id: totrans-203
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装东西向网关并公开所有服务：
- en: '[PRE62]'
  id: totrans-204
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE62]'
- en: 'Create a remote Secret for `cluster1` to be able to access the API server in
    `cluster2`:'
  id: totrans-205
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建一个远程密钥以便`cluster1`能够访问`cluster2`中的API服务器：
- en: '[PRE63]'
  id: totrans-206
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE63]'
- en: 'Finally, create a remote Secret for `cluster2` to be able to access the API
    server in `cluster1`:'
  id: totrans-207
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 最后，创建一个远程密钥以便`cluster2`能够访问`cluster1`中的API服务器：
- en: '[PRE64]'
  id: totrans-208
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE64]'
- en: Now it’s time to deploy and test our setup.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是时候部署并测试我们的设置了。
- en: Deploying and testing via Envoy dummy services
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 通过Envoy虚拟服务进行部署和测试
- en: Next, we will test the setup by deploying an Envoy dummy application as we did
    in previous sections. Follow *steps 1–4* of the *Deploying the Envoy dummy application*
    section under the *Primary-remote on* *multi-network* sub-section.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过部署Envoy虚拟应用程序来测试设置，正如我们在前几节中所做的那样。请按照*步骤1-4*，在*Primary-remote on* *multi-network*子节下的*部署Envoy虚拟应用程序*部分进行操作。
- en: 'Test the Envoy dummy application:'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 测试Envoy虚拟应用程序：
- en: '[PRE65]'
  id: totrans-213
  prefs: []
  type: TYPE_PRE
  zh: '[PRE65]'
- en: Another test to perform is for the high availability of the control plane. You
    can shut down istiod in any of the clusters but that will not impact control plane
    operations. You will still be able to publish new services into the mesh.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个需要执行的测试是验证控制平面的高可用性。你可以关闭任何集群中的istiod，但这不会影响控制平面的操作。你仍然可以将新服务发布到服务网格中。
- en: 'Perform the following tests to validate the high availability of the control
    plane. I have left out the command instructions because we have performed those
    steps several times in this book:'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 执行以下测试以验证控制平面的高可用性。我已经省略了命令说明，因为我们在本书中已经执行过这些步骤多次：
- en: Shut down istiod in `cluster1`.
  id: totrans-216
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 关闭`cluster1`中的istiod。
- en: Delete the Envoy dummy application from `cluster1` using `01-envoy-proxy.yaml`.
  id: totrans-217
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`01-envoy-proxy.yaml`从`cluster1`删除Envoy虚拟应用程序。
- en: Test the Envoy dummy application.
  id: totrans-218
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试Envoy虚拟应用程序。
- en: Deploy the Envoy dummy application in `cluster1` using `01-envoy-proxy.yaml`.
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`01-envoy-proxy.yaml`在`cluster1`中部署Envoy虚拟应用程序。
- en: Test the Envoy dummy application.
  id: totrans-220
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 测试Envoy虚拟应用程序。
- en: Because we have set up a multi-primary cluster, there should be no interruptions
    to control plane operations even if the `cluster1` control plane is not available.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们已经设置了一个多主控集群，即使`cluster1`的控制平面不可用，控制平面的操作也不会中断。
- en: In the next section, we will set up a multi-primary control plane where `cluster1`
    and `cluster2` share the same network.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节中，我们将设置一个多主控控制平面，其中`cluster1`和`cluster2`共享同一网络。
- en: Multi-primary on the same network
  id: totrans-223
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 同一网络上的多主控
- en: 'In this section, we will set up a multi-primary Istio cluster with a shared
    network. In this architecture, workloads in `cluster1` can directly access services
    in `cluster2` and vice versa. In multi-primary clusters, we don’t need an east-west
    gateway because of the following:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将设置一个具有共享网络的多主控Istio集群。在这种架构中，`cluster1`中的工作负载可以直接访问`cluster2`中的服务，反之亦然。在多主控集群中，我们不需要东西向网关，原因如下：
- en: Services can directly communicate with each other across cluster boundaries
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 服务可以跨集群边界直接相互通信
- en: Each control plane observes the API servers in both clusters
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 每个控制平面都会观察两个集群中的API服务器
- en: '![Figure 8.6 – Multi-primary on the same network](img/B17989_08_06.jpg)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![图 8.6 – 同一网络上的多主控](img/B17989_08_06.jpg)'
- en: Figure 8.6 – Multi-primary on the same network
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8.6 – 同一网络上的多主控
- en: 'As we set up multi-primary in a separate network in the previous section, we
    will first need to do some cleanup to set up the environment. To do this, we will
    need to perform the following steps:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们在上一节中将多主集群设置在一个独立网络中，首先需要进行一些清理工作以设置环境。为此，我们需要执行以下步骤：
- en: 'Uninstall Istio in both the primary and remote clusters:'
  id: totrans-230
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 卸载主集群和远程集群中的Istio：
- en: '[PRE66]'
  id: totrans-231
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE66]'
- en: 'Remove all the labels from the `istio-system` namespace in `cluster2`:'
  id: totrans-232
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 删除`cluster2`中`istio-system`命名空间的所有标签：
- en: '[PRE67]'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE67]'
- en: We will then open the firewall between the two clusters following the initial
    set of deployment steps in the *Additional Google Cloud* *steps* section.
  id: totrans-234
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 然后，我们将在初始部署步骤中，按照*附加Google Cloud步骤*部分打开两个集群之间的防火墙。
- en: 'After the preceding steps, the two clusters are ready for the next steps to
    install Istio. Perform the following steps to install Istio on both clusters:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 完成上述步骤后，两个集群已准备好进行下一步操作来安装Istio。请按照以下步骤在两个集群上安装Istio：
- en: 'Install Istio using `01-Cluster1.yaml`. The setup for the primary `cluster1`
    is the same as other architectures:'
  id: totrans-236
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 使用`01-Cluster1.yaml`安装Istio。`cluster1`的配置与其他架构相同：
- en: '[PRE68]'
  id: totrans-237
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE68]'
- en: 'For `cluster2`, we will be using the default profile, which will install istiod
    and the Ingress gateway. As `cluster2` is sharing the network with `cluster1`,
    we will use `cluster2` and `network1` values for the `clusterName` and `network`
    parameters, respectively:'
  id: totrans-238
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于`cluster2`，我们将使用默认配置文件，它将安装istiod和Ingress网关。由于`cluster2`与`cluster1`共享网络，我们将在`clusterName`和`network`参数中分别使用`cluster2`和`network1`值：
- en: '[PRE69]'
  id: totrans-239
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE69]'
- en: 'The sample file is available in `Chapter08/04-Cluster2.yaml`. Install Istio
    using the sample file using the following commands:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 示例文件位于`Chapter08/04-Cluster2.yaml`。使用以下命令通过示例文件安装Istio：
- en: '[PRE70]'
  id: totrans-241
  prefs: []
  type: TYPE_PRE
  zh: '[PRE70]'
- en: 'Create a remote Secret so that the `cluster1` control plane can access the
    Kubernetes API server in `cluster2`:'
  id: totrans-242
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建远程Secret，以便`cluster1`控制平面可以访问`cluster2`中的Kubernetes API服务器：
- en: '[PRE71]'
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE71]'
- en: 'Create a remote Secret so that the `cluster2` control plane can access the
    Kubernetes API server in `cluster1`:'
  id: totrans-244
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建远程Secret，以便`cluster2`控制平面可以访问`cluster1`中的Kubernetes API服务器：
- en: '[PRE72]'
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_PRE
  zh: '[PRE72]'
- en: 'Next, we will test the setup by deploying the Envoy dummy application as we
    did in previous sections. To install the `envoydummy` app, follow *steps 1–4*
    in the *Deploying the Envoy dummy application* section under the *Primary-remote
    on multi-network* section. Similarly, follow *steps 5–6* to perform the testing.
    The following code block demonstrates the distribution of traffic across both
    clusters:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将通过部署Envoy虚拟应用程序来测试设置，就像我们在之前的章节中所做的那样。要安装`envoydummy`应用程序，请按照*步骤1-4*，即*在多网络上部署Envoy虚拟应用程序*部分下的*主控-远程*章节操作。类似地，按照*步骤5-6*进行测试。以下代码块演示了如何在两个集群之间分配流量：
- en: '[PRE73]'
  id: totrans-247
  prefs: []
  type: TYPE_PRE
  zh: '[PRE73]'
- en: Also, test the dummy application by shutting down istiod in the primary cluster
    and redeploying the application to verify whether mesh operations are uninterrupted
    even if one of the primary cluster’s control planes is not available.
  id: totrans-248
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 另外，通过关闭主集群中的istiod并重新部署应用程序来测试虚拟应用程序，验证即使一个主集群的控制平面不可用，网格操作是否也不受影响。
- en: This concludes the setup of multi-primary on separate networks. Multi-primary
    on a shared network is arguably the simplest Istio setup, which doesn’t need an
    east-west gateway to coordinate traffic between various Kubernetes clusters.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这就完成了在独立网络上设置多主集群。共享网络上的多主集群无疑是最简单的Istio设置，它不需要东西向网关来协调不同Kubernetes集群之间的流量。
- en: Reminder
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 提醒
- en: 'Delete the clusters and firewall rule. The following is an example of how you
    can delete clusters. Please change the parameter values as per your configuration:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 删除集群和防火墙规则。以下是如何删除集群的示例。请根据您的配置更改参数值：
- en: '[PRE74]'
  id: totrans-252
  prefs: []
  type: TYPE_PRE
  zh: '[PRE74]'
- en: Summary
  id: totrans-253
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: This chapter was very hands-on, but we hope you learned how to set up Istio
    in various cluster configurations. Every section used two clusters as an example
    to demonstrate the setup, but we would recommend that you extend each of the examples
    by adding more clusters. Practice various scenarios by deploying an Envoy dummy
    application and `curl` Pod from the utilities namespace and then applying virtual
    and destination rules and testing the behavior of the services in a multi-cluster
    environment. Practice east-west traffic scenarios by configuring the east-west
    gateway to only be accessible cross-cluster and see how that plays out using the
    instructions in this chapter.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 本章内容非常实践性强，但我们希望你已经学会了如何在不同的集群配置中设置 Istio。每个部分都使用了两个集群作为示例来演示设置过程，但我们建议你通过增加更多的集群来扩展每个示例。通过部署一个
    Envoy 虚拟应用程序和来自 `utilities` 命名空间的 `curl` Pod，并应用虚拟规则和目标规则，测试在多集群环境中服务的行为，来练习各种场景。通过配置东西向网关使其仅在跨集群之间可访问，来练习东西向流量场景，并根据本章中的说明观察其效果。
- en: Although we discussed four deployment options, choosing the right deployment
    model depends on specific use cases, and you should consider your underlying infrastructure
    provider, application isolation, network boundaries, and service-level agreement
    requirements to consider which architecture is the best fit for you. By having
    multi-cluster deployments, you get better availability of the Service Mesh and
    restricted fault boundaries so that an outage doesn’t bring down the whole cluster.
    In an enterprise environment, multiple teams working together may need to isolate
    data planes but it might be OK to have a shared control plane to save operation
    costs. In that case, multi-cluster environments such as primary-remote provide
    isolation and centralized control.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们讨论了四种部署选项，但选择正确的部署模型取决于具体的使用场景，你需要考虑底层基础设施提供商、应用隔离、网络边界和服务级别协议（SLA）等要求，以确定最适合的架构。通过实现多集群部署，你可以提高服务网格的可用性，并设定更严格的故障边界，从而避免某个故障导致整个集群宕机。在企业环境中，多团队协作可能需要隔离数据平面，但为了节省运营成本，可能可以共享控制平面。在这种情况下，像主备远程这样的多集群环境可以提供隔离和集中控制。
- en: In the next chapter, we will read about web assembly and how it can be used
    to extend Istio data planes.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一章中，我们将了解 WebAssembly 以及它如何用于扩展 Istio 数据平面。
