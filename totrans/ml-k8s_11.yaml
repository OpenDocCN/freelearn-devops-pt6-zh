- en: '*Chapter 11*: Machine Learning on Kubernetes'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '*第11章*：在 Kubernetes 上进行机器学习'
- en: Throughout the chapters, you have learned about the differences between a traditional
    software development process and **machine learning** (**ML**). You have learned
    about the ML life cycle and you understand that it is pretty different from the
    conventional software development life cycle. We have shown you how open source
    software can be used to build a complete ML platform on Kubernetes. We presented
    to you the life cycle of ML projects, and by doing the activities, you have experienced
    how each phase of the project life cycle is executed.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 在各章中，您已经学习了传统软件开发过程与**机器学习**（**ML**）之间的差异。您了解了 ML 生命周期，并意识到它与传统软件开发生命周期有很大的不同。我们向您展示了如何使用开源软件在
    Kubernetes 上构建完整的 ML 平台。我们还展示了 ML 项目的生命周期，通过相关活动，您已经体验了项目生命周期每个阶段的执行方式。
- en: 'In this chapter, we will show you some of the key ideas that we wanted to bring
    forth to further your knowledge on the subject. The following topics will be covered
    in this chapter:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将展示一些关键概念，帮助您进一步理解该主题。以下是本章将涉及的内容：
- en: Identifying ML platform use cases
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 确定 ML 平台的应用场景
- en: Operationalizing ML
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 机器学习的操作化
- en: Running on Kubernetes
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上运行
- en: These topics will help you decide when and where to use the ML platform that
    we presented in this book and help you set up the right organizational structure
    for running and maintaining the platform in production.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 这些内容将帮助您决定何时以及如何使用我们在本书中介绍的 ML 平台，并帮助您为在生产环境中运行和维护平台设置合适的组织结构。
- en: Identifying ML platform use cases
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 确定 ML 平台的应用场景
- en: As discussed in the earlier chapters, it is imperative to understand what ML
    is and how it differs from other closely related disciplines, such as data analytics
    and data science. Data science may be required as a precursor to ML. It is instrumental
    in the research and exploration phase where you are unsure whether an ML algorithm
    can solve the problem. In the previous chapters, you have employed data science
    practices such as problem definitions, isolation of business metrics, and algorithm
    comparison. While data science is essential, there are also ML use cases that
    do not require as many data science activities. An example of such cases is the
    use of AutoML frameworks, which we will talk about in the next section.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前面几章所讨论的，理解什么是 ML 以及它与数据分析和数据科学等相关学科的区别至关重要。数据科学可能是 ML 的前置条件。在研究和探索阶段，您不确定
    ML 算法是否能解决问题时，数据科学非常重要。在前面的章节中，您使用了数据科学方法，如问题定义、业务指标隔离和算法对比。虽然数据科学是必不可少的，但也有一些
    ML 的应用场景不需要那么多数据科学活动。一个例子就是使用 AutoML 框架，我们将在下一节中讨论。
- en: Identifying whether ML can best solve the problem and selecting the ML platform
    is a bit of a chicken and egg problem. This is because, in order to be sure that
    an ML algorithm can best solve a certain business problem, it requires some data
    science work such as data exploration, and thus requires a platform to work on.
    If you are in this situation, your best bet is to choose an open source platform
    such as **Open Data Hub** (**ODH**), which we presented in this book. Because
    it is fully open source, there are no required commercial agreements and licenses
    to start installing and using the platform, and you have already seen how capable
    the platform is. Once you have a platform, you can then use it to initiate your
    research and data exploration until you can conclude whether ML is the right approach
    to solving the business problem or not. You can then either continue using the
    platform for the remainder of the project life cycle or abandon it without incurring
    any platform costs.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 确定 ML 是否能最好地解决问题并选择 ML 平台，实际上是一个“先有鸡还是先有蛋”的问题。因为，为了确定 ML 算法能否最好地解决某个业务问题，需要进行一些数据科学工作，比如数据探索，而这又需要一个平台来支持。如果您处于这种情况，最好的选择是选择一个像**Open
    Data Hub**（**ODH**）这样的开源平台，正如我们在本书中所介绍的那样。因为它完全开源，您可以在没有任何商业协议和许可证的情况下开始安装和使用平台，而且您已经看到这个平台的强大功能。一旦您有了平台，便可以利用它启动研究和数据探索，直到您能够得出结论，是否
    ML 是解决业务问题的正确方法。然后，您可以继续使用该平台进行项目生命周期的剩余部分，或者在没有任何平台费用的情况下放弃它。
- en: In some cases, you may already know that the business problem can be solved
    by ML because you have seen a similar implementation somewhere else. In such cases,
    choosing the ML platform we have presented is also a good option. However, you
    could also be in a situation where you do not have a strong data science team.
    You may have a few data engineers and ML engineers who understand the process
    of model development but are not confident about their data science skills. This
    is where AutoML comes into the picture as a consideration.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 在某些情况下，你可能已经知道商业问题可以通过机器学习来解决，因为你曾在其他地方看到过类似的实现。在这种情况下，选择我们所介绍的机器学习平台也是一个不错的选择。然而，你也可能面临没有强大数据科学团队的情况。你可能只有一些数据工程师和机器学习工程师，他们了解模型开发的过程，但对自己的数据科学技能不太自信。这时，AutoML
    就成为一个值得考虑的选项。
- en: Considering AutoML
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 考虑 AutoML
- en: To define it in its simplest form, AutoML is about automatically producing ML
    models, with little to no data science work needed. To elaborate a bit, it is
    about automatic algorithm selection, automatic hyperparameter tuning, and automatic
    model evaluation.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 简单来说，AutoML 是指自动生成机器学习模型，几乎不需要数据科学的工作。更详细地说，它涉及自动算法选择、自动超参数调优和自动模型评估。
- en: 'AutoML technology comes as a framework or a software library that can generate
    an ML model from a given dataset. There are several AutoML frameworks already
    available on the market as of writing this book. The following list shows some
    of the popular AutoML frameworks currently available. There are many other AutoML
    frameworks not listed here, and we encourage you to explore them:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: AutoML 技术作为框架或软件库出现，可以从给定的数据集生成机器学习模型。截至本书写作时，市场上已经有多种 AutoML 框架可用。以下列表展示了一些当前流行的
    AutoML 框架，还有许多其他未列出的 AutoML 框架，我们鼓励你去探索它们：
- en: '**BigML** – An end-to-end AutoML enterprise platform sold commercially.'
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**BigML** – 一个端到端的 AutoML 企业平台，商业化销售。'
- en: '**MLJAR** – An open source AutoML framework.'
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLJAR** – 一个开源的 AutoML 框架。'
- en: '**H2O.ai** – An open source full ML platform that includes an AutoML framework.'
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**H2O.ai** – 一个开源的全功能机器学习平台，包含一个 AutoML 框架。'
- en: '**TPOT** – Considers itself as a data scientist assistant. It''s an open source
    AutoML framework developed by the Computational Genetics Lab at the University
    of Pennsylvania.'
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**TPOT** – 将自己视为数据科学家的助手。它是由宾夕法尼亚大学计算遗传学实验室开发的开源 AutoML 框架。'
- en: '**MLBox** – An open source AutoML Python library.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**MLBox** – 一个开源的 AutoML Python 库。'
- en: '**Ludwig** – A toolbox featuring zero code ML model development that includes
    AutoML.'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Ludwig** – 一个零代码机器学习模型开发工具箱，包含 AutoML。'
- en: '**Auto-sklearn** – An open source AutoML toolkit based on scikit-learn ML libraries.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Auto-sklearn** – 基于 scikit-learn 机器学习库的开源 AutoML 工具包。'
- en: '**Auto-PyTorch** – An open source AutoML framework that features an automatic
    neural network architecture search. It can automatically optimize neural network
    architectures.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Auto-PyTorch** – 一个开源的 AutoML 框架，具有自动神经网络架构搜索功能。它可以自动优化神经网络架构。'
- en: '**AutoKeras** – An open source AutoML framework based on Keras ML libraries.'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AutoKeras** – 基于 Keras 机器学习库的开源 AutoML 框架。'
- en: It is also important to note that some of these frameworks and libraries can
    be used within, or in conjunction with, our ML platform or any ML platform.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 还需要注意的是，这些框架和库中的一些可以在我们的机器学习平台内，或者与任何机器学习平台一起使用。
- en: Commercial platforms
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 商业平台
- en: Commercial vendors of ML platforms, including cloud providers, also include
    AutoML products and services in their portfolio. Google has Google Cloud AutoML,
    Microsoft has Azure Machine Learning, Amazon has Sagemaker Autopilot, and IBM
    has Watson Studio with AutoML and AutoAI components. However, these vendors sell
    their AutoML products and services as part of their ML platform product, which
    means you will have to use their ML platform to take advantage of the AutoML features.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习平台的商业供应商，包括云服务提供商，也在他们的产品组合中提供 AutoML 产品和服务。谷歌有 Google Cloud AutoML，微软有
    Azure Machine Learning，亚马逊有 Sagemaker Autopilot，IBM 有 Watson Studio，其中包含 AutoML
    和 AutoAI 组件。然而，这些供应商将他们的 AutoML 产品和服务作为机器学习平台产品的一部分出售，这意味着你必须使用他们的机器学习平台才能利用 AutoML
    功能。
- en: ODH
  id: totrans-26
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: ODH
- en: You have seen how the ODH allows you to choose which components to install and
    it also allows you to replace one component with another by updating the `kfdef`
    manifest file. This adds additional flexibility as to what components you choose
    to be part of your platform. For example, suppose you only need JupyterHub and
    MLflow for your data science team to start exploring the possibility of using
    ML to solve your business problem. In that case, you can choose to install only
    these components. This will save you compute resources and, therefore, reduce
    cloud computing bills.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到ODH如何让你选择安装哪些组件，它还允许你通过更新`kfdef`清单文件将一个组件替换为另一个。这增加了你选择将哪些组件作为平台一部分的灵活性。例如，假设你只需要JupyterHub和MLflow，以便你的数据科学团队开始探索使用ML解决业务问题的可能性。那么，你可以选择仅安装这些组件。这样可以节省计算资源，从而减少云计算账单。
- en: Regardless of which ML platform you choose, it is also essential that the path
    to operationalizing your ML platform is clearly established. This includes finding
    the right people who can run the platform in production and mapping the personas
    in the ML life cycle to the existing organization. This also includes establishing
    some processes and communication channels, which brings us to our next topic.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 无论你选择哪种ML平台，明确操作化ML平台的路径同样至关重要。这包括找到合适的人来在生产环境中运行平台，并将ML生命周期中的角色映射到现有组织中。这还包括建立一些流程和沟通渠道，这也是我们接下来要讨论的话题。
- en: Operationalizing ML
  id: totrans-29
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 操作化ML
- en: As discussed in earlier chapters, you can enjoy the full benefits of ML in your
    business if your models get deployed and used in the production environment. Operationalization
    is more than just deploying the ML model. There are also other things that need
    to be addressed to have successful ML-enabled applications in production. Let's
    get into it.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 正如之前章节所讨论的，如果你的模型被部署并在生产环境中使用，你就能在业务中充分利用ML的全部好处。操作化不仅仅是部署ML模型。还需要解决其他一些问题，才能在生产中成功运行支持ML的应用程序。让我们深入探讨一下。
- en: Setting the business expectations
  id: totrans-31
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 设定业务预期
- en: It is extremely important to ensure that the business stakeholders understand
    the risk of making business decisions using the ML model's predictions. You do
    not want to be in a situation where your organization fails because of ML. Zillow,
    a real estate company that invested a lot in ML with their product *Zestimate,*
    lost 500 million dollars due to incorrect price estimates of real properties.
    They ended up buying properties at prices set by their ML model that they eventually
    ended up selling for a much lower price.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 确保业务相关方理解使用ML模型预测做出商业决策的风险极为重要。你不希望你的组织因为ML而失败。Zillow，这家在其产品*Zestimate*上投入大量资金的房地产公司，由于错误的房地产价格估算，损失了5亿美元。他们最终以ML模型设定的价格购买了房产，但这些房产最终以远低于购入价格的价格出售。
- en: ML models are not perfect; they make mistakes. The business must accept this
    fact and must not rely entirely on the ML model's prediction without looking at
    other data sources. If the business fails to accept this fact, this could lead
    to irreparable damages caused by wrong expectations. These damages include reputational
    damages, loss of trust by the business, and even regulatory fines and penalties.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: ML模型并不完美；它们会犯错。业务必须接受这个事实，不能完全依赖ML模型的预测而忽视其他数据源。如果业务未能接受这一事实，可能会导致由于错误预期而造成的不可挽回的损失。这些损失包括声誉损失、业务信任丧失，甚至是监管罚款和处罚。
- en: Another case is that some algorithms, particularly deep learning, are not explainable.
    It must be communicated to the business because, in some cases, an explainable
    algorithm may be required for regulatory purposes. Some regulators may need you
    to explain the reason behind the business decision. For example, suppose an ML
    model decided that a new bank customer is not a risky individual and it turned
    out to be a black-listed or sanctioned individual by some regulators; the financial
    organization may need to explain the reasoning behind this decision to the regulators
    during the investigation and the post-mortem analysis. Or, even worse, the organization
    could get fined millions of dollars.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个案例是，一些算法，特别是深度学习，无法解释其决策过程。必须向业务方传达这一点，因为在某些情况下，可能需要一个可解释的算法以符合监管要求。有些监管机构可能要求你解释业务决策背后的原因。例如，假设一个机器学习模型判定一个新银行客户不是高风险客户，但这个客户最终被某些监管机构列入了黑名单或受到制裁；金融机构可能需要在调查和事后分析过程中向监管机构解释这个决策背后的原因。更糟糕的是，组织可能会因此被罚款数百万美元。
- en: Avoid over-promising results to the business. IBM Watson had the idea that ML
    could diagnose cancer by making sense of diagnostic data from several medical
    institutions and potentially assisting, or even replacing, doctors in performing
    a more reliable cancer diagnosis in the future. This has gained a lot of attention,
    and many organizations invested in the idea. However, it turned out to be a very
    difficult task. It did not only result in losses, but it also somehow damaged
    the brand.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 避免向业务方做出过度承诺。IBM Watson 曾提出机器学习能够通过分析来自多个医疗机构的诊断数据来诊断癌症，并可能在未来帮助或甚至替代医生，进行更可靠的癌症诊断。这一想法吸引了大量关注，许多组织也投入了大量资金。然而，事实证明，这项任务非常困难。它不仅导致了损失，还在某种程度上损害了品牌形象。
- en: To summarize, before deciding whether to use ML models to predict business decisions,
    make sure that the business understands the risks and consequences if the model
    does not behave as expected. Set the expectations right. Be transparent about
    what is possible and what is hard. Some ML models may be able to replace a human
    in a particular business process, but not all ML models will achieve superhuman
    abilities.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，在决定是否使用机器学习模型来预测业务决策之前，确保业务方理解如果模型表现不如预期，可能带来的风险和后果。设定正确的期望值。明确哪些是可能的，哪些是困难的。一些机器学习模型可能在某些业务流程中替代人工，但并非所有机器学习模型都能达到超人的能力。
- en: Dealing with dirty real-world data
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理脏数据的实际情况
- en: The data you used for model training comes as prepared datasets tested in a
    controlled environment. However, this is not the case in the real-world setting.
    After your model gets deployed to production, you must expect dirty data. You
    may receive wrongly structured data, and most of the data is new and has never
    been seen by the model during training. To ensure that your model is fit for production,
    avoid overfitting, and test the model thoroughly with datasets that are as close
    as the ones it will see in production. If possible, use data augmentation techniques
    or even manufactured data to simulate production scenarios. For example, a model
    that works well in diagnosing a patient utilizing chest X-ray scans may work well
    in one clinic, but it may not work in another clinic using older medical equipment.
    There is a real story behind this, and the reason it did not work was that the
    X-ray scanners generated scans that showed dust particles present in the machine's
    sensors.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 你用于模型训练的数据通常是经过准备并在受控环境中测试过的数据集。然而，在实际环境中情况并非如此。模型部署到生产环境后，你必须预期会接收到脏数据。你可能会收到结构错误的数据，而且大部分数据是新的，在训练时模型从未见过。为了确保模型适用于生产环境，要避免过拟合，并使用与生产环境中看到的数据尽可能接近的数据集进行彻底测试。如果可能，使用数据增强技术或甚至是制造的数据来模拟生产场景。例如，一个在诊断使用胸部X光片的患者时表现良好的模型，可能在一个诊所效果很好，但在另一个使用旧设备的诊所中可能就无法工作。这个案例背后有一个真实的故事，原因是X光扫描仪生成的图像中显示了机器传感器上的灰尘颗粒。
- en: To summarize, avoid overfitting. Have a solid data cleaning process as part
    of your inference pipeline. Prepare for the worst possible input data by having
    suitable datasets from various sources. Be ready when your model does not return
    what is expected of it.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，要避免过拟合。确保数据清洗过程作为推理管道的一部分。通过拥有来自不同来源的合适数据集，为最糟糕的输入数据做准备。当模型没有返回预期结果时，要做好准备。
- en: Dealing with incorrect results
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理错误结果
- en: Imagine you have a credit card fraud detection and it marks a routine transaction
    as fraudulent. There could be many reasons for this, such as your model may not
    be aware of higher-than-normal spending during Christmas. You need the capability
    to investigate such scenarios and that's why it is crucial to have logging in
    place. This will allow you to recall the model's answer to a particular question
    thrown to it in production. You will need this to investigate model issues.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你有一个信用卡欺诈检测模型，它将一笔常规交易标记为欺诈交易。这可能有很多原因，例如模型可能没有意识到圣诞节期间的消费高于正常水平。你需要能够调查此类场景，因此，至关重要的是要有日志记录功能。这将使你能够回溯模型在生产环境中对特定问题的回答。你将需要此功能来调查模型问题。
- en: When this happens, you must be prepared to face the consequences of the wrong
    information your model returned. But also, you must be able to address the erroneous
    result in the future by updating the model with new sets of data from time to
    time. You must also have the ability to track the model's performance over time.
    You have seen in the previous chapter how monitoring is done. The change in model
    performance over time is also called a **drift**. There are two kinds of drift.
    **Data drift** happens when the model starts receiving new types of data that
    it has not been trained on. For example, an insurance fraud detection model worked
    well until it started seeing new data that included a new insurance product that
    the model hadn't seen before. In this case, the model will not produce a reliable
    result. In other words, your model performance has degraded. Another example is
    that your model was trained on a certain demographic or age group, and then suddenly
    a new age group started appearing. Similarly, there is a higher chance that the
    ML model will return an unreliable result. **Concept drift** is when the functional
    relationship between the input data and the label has changed. For example, in
    a fraud detection model, a transaction that was not previously considered fraudulent
    is now labeled as fraudulent or anomalous according to the new regulations. This
    means the model will produce more false-negative results, which renders the model
    unreliable.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 当这种情况发生时，你必须准备好面对模型返回错误信息的后果。但同样，你还必须能够通过定期用新的数据集更新模型来解决未来的错误结果。你还必须能够跟踪模型随时间变化的表现。在上一章中你已经看到过如何进行监控。模型表现随时间的变化也被称为**漂移**。漂移有两种类型。**数据漂移**发生在模型开始接收它未经过训练的新类型数据时。例如，一个保险欺诈检测模型在正常工作时，突然开始看到包含新保险产品的数据，而该模型之前未见过该产品。这种情况下，模型将无法产生可靠的结果。换句话说，你的模型表现已经退化。另一个例子是，你的模型是基于某一特定的人群或年龄组进行训练的，随后突然出现了一个新年龄组。类似地，机器学习模型返回不可靠结果的概率会更高。**概念漂移**指的是输入数据和标签之间的功能关系发生了变化。例如，在一个欺诈检测模型中，原本不被视为欺诈的交易，现在根据新的法规被标记为欺诈或异常。这意味着模型将产生更多的假阴性结果，从而使模型变得不可靠。
- en: In these scenarios, you must have a process set for addressing these problems.
    You must have a process for when to manually retrain the model, or even automatically
    retrain the model when it detects a drift. You may also want to implement anomaly
    detection in the input data. This ensures that your model only gives up results
    if the input data make sense. This avoids abuse or attacks on the model as well.
    These automation requirements can be integrated as part of your continuous integration
    and deployment pipelines.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些情况下，你必须为解决这些问题制定一个流程。你必须有一个流程来决定何时手动重新训练模型，或者在模型检测到漂移时自动重新训练模型。你可能还希望在输入数据中实现异常检测。这样可以确保模型只在输入数据合理的情况下给出结果。这也能避免对模型的滥用或攻击。这些自动化要求可以作为你持续集成和部署流水线的一部分进行集成。
- en: Maintaining continuous delivery
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 维护持续交付
- en: You have seen how to run model builds and model deployments in the platform
    manually. You have also seen how to automate the deployment workflow using Airflow.
    Although the data scientists or ML engineers in the team can manually perform
    or trigger such operations, in the real world, you will also need someone or a
    team to maintain these pipelines to make sure they are always working. You may
    want to have a dedicated platform team to maintain the underlying platform that
    executes the pipelines, or you may assign this responsibility to the data engineering
    team. Whatever approach you choose, the important thing is that someone must be
    responsible for ensuring that the deployment pipelines are always working.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你已经看到了如何手动在平台上运行模型构建和模型部署。你也看到过如何使用 Airflow 自动化部署工作流。尽管团队中的数据科学家或 ML 工程师可以手动执行或触发这些操作，但在现实世界中，你仍然需要有人或一个团队来维护这些管道，以确保它们始终在工作。你可能希望有一个专门的团队来维护执行管道的底层平台，或者你可以将这个责任分配给数据工程团队。无论你选择哪种方式，重要的是必须有人负责确保部署管道始终正常运行。
- en: Although the ODH operator completely manages the ML platform, you will still
    need someone responsible for maintaining it. Ensure that the Kubernetes operators
    are up to date. Apply security patches whenever necessary.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 ODH 操作员完全管理 ML 平台，但你仍然需要有人负责维护它。确保 Kubernetes 操作员是最新的，并在必要时应用安全补丁。
- en: For some critical workloads, you may not be able to deploy to production automatically.
    There will be manual approvals required before you can ship updates to a model
    in production. In this case, you need to establish this approval workflow by either
    embedding this process into the platform or through mutual agreement with manual
    approval processes. Nevertheless, the objective is to have someone accountable
    for maintaining continuous delivery services.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 对于某些关键工作负载，你可能无法自动将其部署到生产环境中。在将更新发布到生产环境中的模型之前，需要手动批准。在这种情况下，你需要通过将此过程嵌入到平台中或通过与手动批准流程的相互协议来建立此审批工作流。不过，目标是确保有人负责维护持续交付服务。
- en: In summary, continuous delivery must always work so that the model development
    life cycle can have a faster feedback cycle. Also, if drift is detected, you will
    always have a ready-to-go delivery pipeline that can ship a more up-to-date version
    of the model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 总结一下，持续交付必须始终有效，以便模型开发生命周期能够有更快速的反馈周期。此外，如果检测到漂移，你将始终有一个随时可用的交付管道，可以发布一个更新的模型版本。
- en: Managing security
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 管理安全
- en: Security is another critical area to focus on when operationalizing ML projects.
    You have seen in the preceding chapters that the ML platform can be secured by
    using **OpenID Connect** (**OIDC**) or **OAuth2**, a standard authentication mechanism.
    Different platform components can utilize the same authentication mechanism for
    a more seamless user experience. You have used an open source tool called Keycloak,
    an industry-standard implementation of the **identity and access management**
    (**IAM**) system that mainly supports OIDC, **Security Assertion Markup Language**
    (**SAML**), and more. The Seldon Core API allows the REST-exposed ML models to
    be protected behind the same authentication mechanism. Refer to the Seldon Core
    documentation for more details.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 安全性是将 ML 项目投入生产时需要关注的另一个关键领域。你在前几章中已经看到，ML 平台可以通过使用**OpenID Connect**（**OIDC**）或**OAuth2**，一种标准的认证机制，来进行安全保护。不同的平台组件可以利用相同的认证机制，提供更加无缝的用户体验。你已经使用了一个开源工具
    Keycloak，它是一个行业标准的**身份与访问管理**（**IAM**）系统的实现，主要支持 OIDC、**安全声明标记语言**（**SAML**）等。Seldon
    Core API 允许将 REST 暴露的 ML 模型保护在相同的认证机制后面。有关更多细节，请参阅 Seldon Core 文档。
- en: To summarize, the ML platform must be protected by an authentication mechanism,
    preferably OIDC. This also allows for the implementation of **single sign-on**
    (**SSO**). Additionally, you also need to protect your deployed models to ensure
    that only the intended audiences can access your ML models. And finally, there
    must be someone responsible for maintaining the Keycloak instance that your platform
    uses and someone, or a team, managing the access to the platform resources.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，ML 平台必须通过认证机制进行保护，最好使用 OIDC。这也允许实现**单点登录**（**SSO**）。此外，你还需要保护已部署的模型，确保只有目标用户才能访问你的
    ML 模型。最后，必须有人负责维护平台所使用的 Keycloak 实例，并且有人或团队负责管理平台资源的访问权限。
- en: Adhering to compliance policies
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 遵守合规性政策
- en: In some business settings, compliance is at the center of the operation. Financial
    institutions have a whole department managing compliance. These compliance rules
    typically come from the regulatory bodies that oversee the financial institution's
    operations. Depending on which country your ML platform will be used and hosted
    in, regulatory policies may prevent you from moving data out of the on-premises
    data centers. Or, there could be a requirement for encrypting data at rest.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在一些商业环境中，合规性是运营的核心。金融机构有一个专门的部门来管理合规性。这些合规规则通常来自监管机构，负责监督金融机构的运营。根据你的机器学习平台将要使用和托管的国家，监管政策可能会禁止你将数据从本地数据中心迁出，或者可能要求对静态数据进行加密。
- en: The good news is that your platform is flexible enough to be configured for
    such compliance measures. It can run on-premises or in any cloud provider, thanks
    to Kubernetes. You can also run the ML platform in the cloud while having the
    storage on-premises or take advantage of hybrid-cloud strategies.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 好消息是，你的平台足够灵活，可以配置为符合这些合规性措施。得益于Kubernetes，它可以在本地或任何云提供商上运行。你也可以在云中运行机器学习平台，同时将存储保存在本地，或利用混合云策略。
- en: Another thing is that each of the components in the platform is replaceable
    and pluggable. For example, instead of using a dedicated instance of Keycloak,
    you could use an existing regulator-approved OIDC provider.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个问题是，平台中的每个组件都是可替换和可插拔的。例如，你可以使用一个现有的、经过监管机构批准的OIDC提供者，而不是使用专用的Keycloak实例。
- en: Compliance could often become an impediment in progressing with ML projects.
    If you plan to use a commercial platform rather than the one you built in this
    book, always consider the compliance or regulatory requirements before deciding.
    Some commercial platforms in the cloud may not be able to comply with data sovereignty,
    especially in countries where the major cloud providers do not yet have a local
    data center.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 合规性通常可能成为推进机器学习项目的障碍。如果你打算使用商业平台而不是本书中构建的那个，始终在做出决定之前考虑合规性或监管要求。某些云中的商业平台可能无法遵守数据主权要求，尤其是在主要云提供商尚未在当地拥有数据中心的国家。
- en: In other words, always consider compliance requirements when planning for the
    architecture of your ML platform.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 换句话说，在规划你的机器学习平台架构时，始终考虑合规性要求。
- en: Applying governance
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 应用治理
- en: After taking into account the preceding considerations, another important area
    that needs to be cleared out to operationalize your ML platform is **governance**.
    This is where you will design the organizational structure, roles and responsibilities,
    collaboration model, and escalation points. The authors advocate for a more cross-functional
    team with very high collaboration levels. However, this is not always possible
    in the real world. There are organizations with very well-defined hierarchies
    and silos that refuse to change the way things are. If you are in this type of
    organization, you may face several hurdles in implementing the ML platform we
    have presented here.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在考虑了前述因素之后，另一个需要明确的问题是如何使你的机器学习平台具备可操作性，即**治理**。在这一部分，你将设计组织结构、角色和责任、协作模式以及上报点。作者提倡一个跨职能的团队，具有非常高的协作水平。然而，这在现实世界中并不总是可能的。有些组织拥有非常明确的等级制度和职能孤岛，不愿意改变现有的工作方式。如果你所在的组织是这种类型，你可能会在实施我们所介绍的机器学习平台时遇到一些障碍。
- en: One of the platform's main features is that it is a self-service platform. It
    allows data scientists, ML engineers, and data engineers to spin up their notebook
    servers and Spark clusters. However, this will also lead to less predictable cloud
    billings or operating costs. If you are the data architect of the project, part
    of your job is to convince the leadership team and the platform teams to trust
    their data scientists and ML engineers.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 该平台的主要特点之一是它是一个自助式平台。它允许数据科学家、机器学习工程师和数据工程师启动他们的笔记本服务器和Spark集群。然而，这也会导致云账单或运营成本的不可预测性。如果你是该项目的数据架构师，你的部分工作就是说服领导团队和平台团队信任他们的数据科学家和机器学习工程师。
- en: 'Ideally, the best way to design the organizational structure around the ML
    project is to have a platform team. This team is responsible for running the ML
    platform. This team then acts as a service provider to the data and application
    teams, also called the **stream-aligned teams**, in a **software as a service**
    (**SaaS**) model. The platform team''s objective is to ensure that the stream-aligned
    teams can perform their work on the platform as smoothly and as quickly as possible.
    The data science and data engineering teams can be the stream-aligned teams, and
    they are the main users of the platform and the main customers of the platform
    team. The DevSecOps or DevOps teams may sit together in the same organizational
    unit, as the platform team provides DevOps services to the stream-aligned teams.
    *Figure 11.1* shows an example of an organizational structure that you could implement
    to run an ML project using the Team Topologies notation:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 理想情况下，围绕 ML 项目设计组织结构的最佳方式是拥有一个平台团队。该团队负责运行 ML 平台。然后，这个团队作为服务提供商，向数据和应用团队提供服务，这些团队也被称为**流对齐团队**，并采用**软件即服务**（**SaaS**）模式。平台团队的目标是确保流对齐团队可以在平台上尽可能顺利、快速地完成他们的工作。数据科学团队和数据工程团队可以是流对齐团队，它们是平台的主要用户，也是平台团队的主要客户。DevSecOps
    或 DevOps 团队可能会在同一个组织单元内，因为平台团队为流对齐团队提供 DevOps 服务。*图 11.1* 展示了你可以实施的一个组织结构示例，用于使用
    Team Topologies 标注来运行 ML 项目：
- en: '![Figure 11.1 – Example ML project team structure'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '![图 11.1 – 示例 ML 项目团队结构'
- en: '](img/B18332_11_01.jpg)'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_11_01.jpg)'
- en: Figure 11.1 – Example ML project team structure
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11.1 – 示例 ML 项目团队结构
- en: 'In *Figure 11.1*, there are a total of three stream-aligned teams, namely,
    the data science team, the data engineering team, and the software engineering
    team. All three stream-aligned teams are collaborating with each other with the
    objective of delivering an ML-enabled application in production. There are also
    three platform teams. The cloud infrastructure team is providing a cloud **platform
    as a service** (**PaaS**) to the two other platform teams: the ML platform team
    and the MLOps team. Both the ML platform team and the MLOps team are providing
    ML PaaS and MLOps as a service to all the three stream-aligned teams. The purple
    box represents an enabling team. This is where the SMEs and product owners sit.
    This team enables and provides support to all the stream-aligned teams.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在*图 11.1*中，总共有三个流对齐团队，即数据科学团队、数据工程团队和软件工程团队。所有三个流对齐团队都在相互协作，目标是交付一个在生产环境中运行的
    ML 驱动的应用程序。还有三个平台团队。云基础设施团队为另外两个平台团队提供云**平台即服务**（**PaaS**）：ML 平台团队和 MLOps 团队。ML
    平台团队和 MLOps 团队为所有三个流对齐团队提供 ML PaaS 和 MLOps 即服务。紫色框表示一个支持团队。这里是 SME 和产品负责人所在的地方。这个团队为所有流对齐团队提供支持和帮助。
- en: You must take note that this is just an example; you may want to combine the
    ML platform team and MLOps team together, or the data science and data engineering
    teams, and that's perfectly okay.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 你必须注意，这只是一个示例；你也可以将 ML 平台团队和 MLOps 团队合并，或者将数据科学团队和数据工程团队合并，这完全没问题。
- en: If you want to learn more about this type of organizational design notation,
    you may want to read about Team Topologies.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想了解更多关于这种组织设计标注的内容，你可能想阅读关于 Team Topologies 的资料。
- en: 'We can summarize as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以总结如下：
- en: Use the ML life cycle diagram that you have seen in *Figure 2.7* in [*Chapter
    2*](B18332_02_ePub.xhtml#_idTextAnchor027), *Understanding MLOps*, to map the
    current organizational structure of your teams.
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用你在*图 2.7*中看到的 ML 生命周期图，结合 [*第二章*](B18332_02_ePub.xhtml#_idTextAnchor027)《理解
    MLOps》中的内容，来映射当前团队的组织结构。
- en: Communicate the roles and responsibilities clearly.
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 清晰地传达角色和责任。
- en: Set the collaboration channels and feedback points, such as design spike meetings
    and chatgroups.
  id: totrans-71
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 设置协作渠道和反馈点，例如设计冲刺会议和聊天组。
- en: Suppose you cannot break the silos; set up regular meetings between the silos
    and establish a more streamlined handover process. However, if you want to take
    advantage of the full potential of the ML platform, we strongly recommend that
    you form a cross-functional and self-organizing team to deliver your ML project.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 假设你无法打破团队之间的壁垒；可以设立定期会议，促进壁垒之间的沟通，并建立更加流畅的交接流程。然而，如果你想充分发挥 ML 平台的潜力，我们强烈建议你组建一个跨职能的自组织团队来交付你的
    ML 项目。
- en: Running on Kubernetes
  id: totrans-73
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 在 Kubernetes 上运行
- en: Using the ODH operator, the ML platform truly unlocks the full potential of
    Kubernetes as the infrastructure layer of your ML platform. The **Operator Lifecycle
    Management** (**OLM**) framework enables the ODH operator to simplify the operation
    and maintenance of the ML platform. Almost all operational work is done in a Kubernetes-native
    way, and you can even spin up multiple ML platforms with a few clicks. Kubernetes
    and the OLM also allow you to implement the **Platform as Code** (**PaC**) approach,
    enabling you to implement GitOps practices.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ODH 操作符，ML 平台真正释放了 Kubernetes 作为 ML 平台基础设施层的全部潜力。**操作符生命周期管理**（**OLM**）框架使
    ODH 操作符能够简化 ML 平台的操作和维护。几乎所有操作工作都以 Kubernetes 原生方式进行，您甚至可以通过几次点击启动多个 ML 平台。Kubernetes
    和 OLM 还允许您实施 **平台即代码**（**PaC**）方法，从而使您能够实施 GitOps 实践。
- en: The ML platform you've seen in this book works well with vanilla Kubernetes
    instances or any other flavors of Kubernetes or even a Kubernetes-based platform.
    In fact, the original ODH repository was mainly designed and built for Red Hat
    OpenShift.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 本书中展示的 ML 平台与原生 Kubernetes 实例或其他任何类型的 Kubernetes 平台，甚至是基于 Kubernetes 的平台，都能很好地配合使用。事实上，原始的
    ODH 仓库主要是为 Red Hat OpenShift 设计和构建的。
- en: Avoiding vendor lock-ins
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 避免供应商锁定
- en: Kubernetes protects you from vendor lock-ins. Because of the extra layer of
    containerization and container orchestration, all your workloads do not run directly
    on the infrastructure layer but through containers. This allows the ML platform
    to be hosted in any capable infrastructure. Whether on-premises or in the cloud,
    the operations will be the same. This also allows you to seamlessly switch to
    a different cloud provider when needed. This is one of the advantages of using
    this ML platform when compared to the commercial platforms provided by cloud vendors.
    You are not subject to vendor lock-in.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: Kubernetes 保护您免受供应商锁定的困扰。由于额外的容器化和容器编排层，所有工作负载都不会直接运行在基础设施层上，而是通过容器运行。这使得 ML
    平台可以托管在任何具有能力的基础设施上。无论是本地部署还是云端，操作都是一样的。这也使得您可以在需要时无缝切换到不同的云供应商。这是使用此 ML 平台与云供应商提供的商业平台相比的一个优势。您不受供应商锁定的限制。
- en: For example, if you use Azure ML as your platform of choice, you will be stuck
    with using Azure as your infrastructure provider. You will not be able to move
    your entire ML project to another cloud vendor without changing the platform and
    deployment architecture. In other words, the cost of switching to a different
    cloud vendor is so high that you are basically stuck with the original vendor.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果您选择 Azure ML 作为您的平台，您将被限制使用 Azure 作为基础设施提供商。您将无法在不更改平台和部署架构的情况下将整个 ML 项目迁移到另一个云供应商。换句话说，切换到不同的云供应商的成本非常高，基本上您会被原供应商“锁定”。
- en: Considering other Kubernetes platforms
  id: totrans-79
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 考虑其他 Kubernetes 平台
- en: It is not mandatory for this ML platform to run on the vanilla Kubernetes platform
    only. As mentioned in the previous section, the original ODH was designed to run
    on Red Hat OpenShift, whereas in this book, you managed to make it run on minikube,
    a single-node vanilla Kubernetes.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这个 ML 平台不必仅仅在原生 Kubernetes 平台上运行。如前一部分所述，原始的 ODH 是为在 Red Hat OpenShift 上运行而设计的，而在本书中，您已成功使其在
    minikube（一个单节点原生 Kubernetes）上运行。
- en: 'There are many other Kubernetes platforms out there, including those provided
    by the major cloud providers. The following list includes the most common ones
    in no particular order, but other emerging Kubernetes-based platforms have just
    entered the market or are either in beta or in development as of this writing:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 市面上还有许多其他 Kubernetes 平台，包括主要云供应商提供的。以下是按非特定顺序列出的最常见的一些，但在撰写本文时，其他新兴的基于 Kubernetes
    的平台刚刚进入市场，或者正在处于 Beta 测试或开发阶段：
- en: '**Kubernetes**'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Kubernetes**'
- en: '**Red Hat** **OpenShift Container Platform** (**OCP**)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Red Hat** **OpenShift 容器平台**（**OCP**）'
- en: '**Google Kubernetes Engine** (**GKE**)'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Google Kubernetes 引擎**（**GKE**）'
- en: '**Amazon** **Elastic Kubernetes Engine** (**EKS**)'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**亚马逊** **弹性 Kubernetes 引擎**（**EKS**）'
- en: '**Azure Kubernetes Service** (**AKS**)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Azure Kubernetes 服务**（**AKS**）'
- en: '**VMware Tanzu**'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**VMware Tanzu**'
- en: '**Docker Enterprise Edition** (**Docker EE**)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**Docker 企业版**（**Docker EE**）'
- en: Although we have tested this platform in Kubernetes and Red Hat OpenShift, the
    ML platform that you built in minikube can also be built in any of the above Kubernetes
    platforms, and others. But, what about in the future? Where is ODH heading?
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管我们在 Kubernetes 和 Red Hat OpenShift 上测试了该平台，但您在 minikube 上构建的 ML 平台也可以在上述任何
    Kubernetes 平台以及其他平台上构建。但是，未来会如何呢？ODH 的发展方向是什么？
- en: Roadmap
  id: totrans-90
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 路线图
- en: ODH is an active open source project primarily maintained by Red Hat, the largest
    open source company in the world. ODH will keep getting updated to bring more
    and more features to the product. However, because the ML and MLOps space is also
    relatively new and still evolving, it is not unnatural to see significant changes
    and pivots in the project over time.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: ODH是一个活跃的开源项目，主要由全球最大的开源公司Red Hat维护。ODH将不断更新，带来越来越多的功能。然而，由于ML和MLOps领域相对较新且仍在发展中，看到项目随时间发生显著变化和调整并不奇怪。
- en: 'As of writing this book, the next version of ODH includes the following changes
    (as shown in *Figure 11.2*):'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 在本书编写时，ODH的下一个版本包括以下更改（如*图11.2*所示）：
- en: '![Figure 11.2 – ODH''s next release'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '![图11.2 – ODH的下一个发布版本'
- en: '](img/B18332_11_02.jpg)'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '](img/B18332_11_02.jpg)'
- en: Figure 11.2 – ODH's next release
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图11.2 – ODH的下一个发布版本
- en: There are other features of ODH that you have not yet explored because they
    are more geared toward data engineering and the data analytics space. One example
    is data virtualization and visualization using Trino and Superset. If you want
    to learn more about these features, you can explore them in the same ML platform
    you built by simply updating the `kfdef` file to include Trino and Superset as
    components of your ML platform. You will find some examples of these `kfdef` files
    in the ODH GitHub project.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: ODH还有一些你尚未探索的功能，它们更多地面向数据工程和数据分析领域。一个例子是使用Trino和Superset进行数据虚拟化和可视化。如果你想了解这些功能，可以通过更新`kfdef`文件，将Trino和Superset作为你机器学习平台的组件，来在你构建的同一平台上进行探索。你可以在ODH的GitHub项目中找到这些`kfdef`文件的示例。
- en: 'You can look for future roadmaps of ODH at the following URL: [https://opendatahub.io/docs/roadmap/future.html](https://opendatahub.io/docs/roadmap/future.html).'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在以下网址查看ODH的未来路线图：[https://opendatahub.io/docs/roadmap/future.html](https://opendatahub.io/docs/roadmap/future.html)。
- en: In the future, there could be another open source ML platform project that will
    surface on the market. Keep an open mind, and never stop exploring other open
    source projects.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 未来，可能会有另一个开源机器学习平台项目在市场上出现。保持开放的心态，永远不要停止探索其他开源项目。
- en: Summary
  id: totrans-99
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 总结
- en: The knowledge that you have gained in this book about ML, data science and data
    engineering, MLOps, and the ML life cycle applies to any other ML platforms as
    well. You have not only gained important insights and knowledge about running
    ML projects in Kubernetes but also gained the experience of building the platform
    from scratch. In the later chapters, you were able to gain hands-on experience
    and wear the hats of a data engineer, data scientist, and MLOps engineer.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 你在本书中学到的关于机器学习（ML）、数据科学与数据工程、MLOps和机器学习生命周期的知识同样适用于其他任何机器学习平台。你不仅获得了关于在Kubernetes中运行机器学习项目的重要见解和知识，还积累了从零开始构建平台的经验。在接下来的章节中，你能够获得实践经验，并同时扮演数据工程师、数据科学家和MLOps工程师的角色。
- en: While writing this book, we realized that the subject is vast and that going
    deep into each of the topics covered in the book may be too much for some. Although
    we have touched upon most of the components of the ML platform, there is still
    a lot more to learn about each of the components, especially Seldon Core, Apache
    Spark, and Apache Airflow. To further your knowledge of these applications, we
    recommend going through the official documentation pages.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本书的过程中，我们意识到这个主题非常广泛，深入探讨书中涉及的每个主题可能对某些读者来说信息量过大。虽然我们已触及机器学习平台的大部分组件，但关于每个组件仍有很多内容值得学习，特别是关于Seldon
    Core、Apache Spark和Apache Airflow的知识。为了进一步了解这些应用，我们建议查阅它们的官方文档页面。
- en: ML, AI, and MLOps are still evolving. On the other hand, even though Kubernetes
    is almost 8 years old, it is still relatively new to most enterprise organizations.
    Because of this, most professionals in this space are still learning, while at
    the same time establishing new standards.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习（ML）、人工智能（AI）和MLOps仍在发展之中。另一方面，尽管Kubernetes已经有近8年历史，但对于大多数企业组织来说，它仍然相对较新。因此，这一领域的大多数专业人士仍在学习的同时，也在建立新的标准。
- en: Keep yourself updated on the latest ML and Kubernetes trends. You already have
    enough knowledge to advance your learning in this subject on your own.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 保持对最新的机器学习（ML）和Kubernetes趋势的关注。你已经掌握了足够的知识，可以独立推进在这一领域的学习。
- en: Further reading
  id: totrans-104
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深入阅读
- en: '*Seldon core documentation*: [https://docs.seldon.io/projects/seldon-core/en/latest/index.html](https://docs.seldon.io/projects/seldon-core/en/latest/index.html)'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*Seldon核心文档*：[https://docs.seldon.io/projects/seldon-core/en/latest/index.html](https://docs.seldon.io/projects/seldon-core/en/latest/index.html)'
- en: '*Team topologies*: [https://teamtopologies.com](https://teamtopologies.com)'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*团队拓扑*: [https://teamtopologies.com](https://teamtopologies.com)'
- en: '*Open Data Hub*: [https://opendatahub.io](https://opendatahub.io)'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '*开放数据中心*: [https://opendatahub.io](https://opendatahub.io)'
