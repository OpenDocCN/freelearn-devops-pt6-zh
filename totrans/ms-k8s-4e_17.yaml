- en: '17'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Running Kubernetes in Production
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In the previous chapter, we discussed governance and policy engines. This is
    an important part of managing large-scale Kubernetes-based systems in production.
    However, it is only one part. In this chapter, we will turn our attention to the
    overall management of Kubernetes in production. The focus will be on running multiple
    Managed Kubernetes clusters in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: 'The topics we will cover are:'
  prefs: []
  type: TYPE_NORMAL
- en: Understanding Managed Kubernetes in the cloud
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing multiple clusters
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Building effective processes for large-scale Kubernetes deployments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Handling infrastructure at scale
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Managing clusters and node pools
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upgrading Kubernetes
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cost management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Understanding Managed Kubernetes in the cloud
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Managed Kubernetes** is a service provided by cloud providers such as **Amazon
    Web Services** (**AWS**), **Google Cloud Platform** (**GCP**), and **Microsoft
    Azure** that simplifies the deployment, management, and scaling of containerized
    applications in the cloud. With Managed Kubernetes, organizations can focus on
    developing and deploying their applications without worrying too much about the
    underlying infrastructure.'
  prefs: []
  type: TYPE_NORMAL
- en: Managed Kubernetes provides a pre-configured and optimized environment for deploying
    containers, eliminating the need for the manual setup and maintenance of a Kubernetes
    cluster. This allows organizations to quickly deploy and scale their applications,
    reducing time to market and freeing up valuable resources.
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, Managed Kubernetes integrates with the cloud providers’ other
    services, such as databases, networking, storage solutions, security, identity,
    and observability features, making it easier to manage and secure the entire application
    stack. This also enables organizations to leverage the providers’ expertise in
    managing large-scale infrastructure, ensuring high availability, and reducing
    downtime.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, Managed Kubernetes provides a simplified and efficient way to deploy
    and manage containerized applications in the cloud, reducing operational overhead
    and improving time to market. This makes it an attractive option for organizations
    of all sizes looking to take advantage of the benefits of containers and the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Deep integration
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cloud providers utilize the extensibility of Kubernetes to offer deep integration
    of their Managed Kubernetes solutions with their cloud services via the CNI, the
    CSI, and authentication/authorization plugins. The cloud providers also implement
    the **Cloud Controller Interface** (**CCI**) to allow their compute infrastructure
    to serve Kubernetes nodes.
  prefs: []
  type: TYPE_NORMAL
- en: However, the integration runs deeper. The cloud providers often configure the
    kubelet, control the container runtime that runs on every node, and deploy various
    DaemonSets on every node.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, AKS leverages many Azure services:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Azure Compute**: AKS leverages Azure Compute resources such as **virtual**
    **machines** (**VMs**), availability sets, and scale sets to provide a managed
    Kubernetes experience.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Virtual Network**: AKS integrates with Azure Virtual Network, allowing
    users to create and manage their own virtual networks and subnets. This provides
    users with control over their network layout and the ability to tightly control
    network traffic.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Blob Storage**: AKS integrates with Azure Blob Storage, allowing users
    to store and manage their application data in the cloud. This provides users with
    scalable, secure, and highly available storage for their applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Key Vault**: AKS integrates with Azure Key Vault, allowing users to
    securely manage and store secrets such as passwords, keys, and certificates. This
    provides users with secure storage for their application secrets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Monitor**: AKS integrates with Azure Monitor, allowing users to collect
    and analyze metrics, logs, and traces from their applications. This provides users
    with the ability to monitor and troubleshoot their workloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Azure Active Directory** (**AAD**): AKS integrates with AAD to provide a
    secure, reliable, and highly available platform for running Kubernetes clusters.
    AAD provides an efficient and secure way to authenticate and authorize users and
    applications to access the cluster. AAD can also be integrated with Kubernetes
    **RBAC** (**role-based access control**) to provide granular control over access
    to cluster resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s move on and discuss one of the key elements of successfully managing a
    production Kubernetes-based system in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Quotas and limits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cloud infrastructure has revolutionized the way organizations store and manage
    their data and run their workloads. However, one major issue that requires consideration
    and attention is the use of quotas and limits by cloud service providers. These
    quotas and limits, while necessary for ensuring the stability and security of
    the cloud infrastructure, can be a major source of frustration and even outages
    for users.
  prefs: []
  type: TYPE_NORMAL
- en: Quotas and limits are restrictions placed on the number of resources that a
    user can consume. For example, there may be a limit on the number of VMs of a
    particular type that can be created in each region environment, or a quota on
    the amount of storage space that can be used. These quotas and limits are put
    in place to prevent a single user from consuming too many resources and potentially
    disrupting the overall performance of the cloud infrastructure. It also protects
    users from inadvertently provisioning a huge quantity of resources that they don’t
    really need but will have to pay for.
  prefs: []
  type: TYPE_NORMAL
- en: The cloud is in theory infinitely scalable and elastic. In practice, this is
    true only within the quotas and limits.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at some real-world examples in the next sections.
  prefs: []
  type: TYPE_NORMAL
- en: Real-world examples of quotas and limits
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: On GCP, quotas can generally be increased, while limits are fixed. Also, each
    service has its own page of quotas and limits. The **virtual private cloud** (**VPC**)
    page is found at [https://cloud.google.com/vpc/docs/quota](https://cloud.google.com/vpc/docs/quota).
  prefs: []
  type: TYPE_NORMAL
- en: 'You can view the quotas in the GCP console as well as request increases: [https://console.cloud.google.com/iam-admin/quotas](https://console.cloud.google.com/iam-admin/quotas).'
  prefs: []
  type: TYPE_NORMAL
- en: There are currently 9,441 quotas!
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a screenshot that shows some quotas for the GCP Compute Engine service:'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18998_17_01.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17.1: Screenshot of GCP compute engine quotas'
  prefs: []
  type: TYPE_NORMAL
- en: Now that we understand what quotas and limits are, let’s discuss capacity planning.
  prefs: []
  type: TYPE_NORMAL
- en: Capacity planning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the olden days, capacity planning meant thinking about how many servers you
    needed in your data centers, how big the disks should be, and the bandwidth of
    your network. This was based on the usage of your workloads as well as keeping
    healthy headroom for redundancy as well as growth. Then, you had to consider upgrades
    and how to phase out obsolete hardware. In the cloud, you don’t need to worry
    about hardware. However, you do need to plan around the quotas and limits. This
    means you need to monitor the quotas and limits and, whenever you get close to
    the current quota, request an increase. For quotas such as the number of VM instances
    of a particular VM family, I recommend staying below 50%-60% if possible. This
    should give you ample room for disaster recovery and growth, as well blue-green
    deployments where you run your new version and old version side by side for a
    while.
  prefs: []
  type: TYPE_NORMAL
- en: When should you not use Managed Kubernetes?
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Managed Kubernetes is great, but it is not a panacea. There are several situations
    and use cases where you may prefer to manage Kubernetes yourself, such as:'
  prefs: []
  type: TYPE_NORMAL
- en: The obvious use case is if you run Kubernetes on-prem and a managed solution
    is simply not available. However, you can run a similar stack to cloud-managed
    Kubernetes via platforms like GKE Anthos, AWS Outposts, and Azure Arc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You require extreme control over the control plane, the node components, and
    the daemonsets that run on each node.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You already have in-house expertise in running Kubernetes yourself and using
    Managed Kubernetes will require a steep learning curve and might cost more.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You manage highly sensitive information that you must fully control and can’t
    trust the cloud provider with.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You run Kubernetes on multiple cloud providers and/or hybrid environments and
    prefer to have a uniform way to manage Kubernetes in all environments.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You want to make sure you are not locked into a particular cloud provider.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In short, there are various situations where you may take on managing Kubernetes
    yourself. Let’s look at the various ways you may deploy and manage multiple clusters
    of Kubernetes in different environments.
  prefs: []
  type: TYPE_NORMAL
- en: Managing multiple clusters
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Kubernetes cluster is powerful and can manage a lot of workloads (thousands
    of nodes, and hundreds of thousands of pods). As a startup, you may get pretty
    far with just one cluster. However, at enterprise scale, you’ll need more than
    one cluster. Let’s consider some use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Geo-distributed clusters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Geo-distributed clusters are clusters that run in different locations. There
    are three main reasons for using geo-distributed clusters:'
  prefs: []
  type: TYPE_NORMAL
- en: Keeping your data and workloads close to their consumers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compliance and data privacy laws where data must remain in its country of origin.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: High availability and disaster recovery in case of a regional outage.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-cloud
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If you run on multiple clouds, then naturally you need at least one cluster
    per cloud provider.
  prefs: []
  type: TYPE_NORMAL
- en: Running on multiple clouds can be complicated, but at enterprise scale, it may
    be unavoidable and sometimes desirable. For example, your company may run Kubernetes
    on cloud X and acquire a company that runs Kubernetes on cloud Y. Migrating from
    Y to X might be too risky and expensive.
  prefs: []
  type: TYPE_NORMAL
- en: Another valid reason to run on multiple clouds is to have leverage against the
    cloud providers to secure better discounts and ensure you are not fully locked
    in. Finally, it may allow you to tolerate a complete cloud provider outage (this
    is not trivial to pull off).
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Hybrid Kubernetes means running some Kubernetes clusters in the cloud (with
    a single or multiple cloud providers) and some Kubernetes clusters on-prem.
  prefs: []
  type: TYPE_NORMAL
- en: This situation may arise as before because of an acquisition or even if you
    are in the process of migrating from on-prem Kubernetes to the cloud. Large systems
    might take years to migrate and during the migration, you’ll have to run a mix
    of Kubernetes clusters running in a hybrid environment.
  prefs: []
  type: TYPE_NORMAL
- en: You may also adopt patterns like burst to cloud where most of your Kubernetes
    clusters run on-prem, but you have the flexibility to deploy workloads to Kubernetes
    clusters running in the cloud, which can scale quickly if you are hit with unanticipated
    load or if your on-prem infrastructure is having issues.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes on the edge
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most enterprise data (around 90%) is generated in the cloud and private data
    centers; however, that number will drop to just 25% by 2025 according to Gartner.
  prefs: []
  type: TYPE_NORMAL
- en: This is mind-blowing. Edge computing (AKS IoT) will be responsible for this
    massive shift.
  prefs: []
  type: TYPE_NORMAL
- en: A lot of devices spread all over the place will generate constant streams of
    data. Some of that data will be sent back to the backend for processing, aggregation,
    and storage. However, it makes a lot of sense to perform various forms of data
    processing close to the data instead of sending the raw data as it is. In some
    cases, you can even run workloads locally close to the data and serve users completely
    on the edge.
  prefs: []
  type: TYPE_NORMAL
- en: This is the promise of edge computing. Running Kubernetes at the edge allows
    organizations to bring the processing of data closer to the source of data generation,
    reducing the latency and bandwidth requirements of sending data to a centralized
    data center or cloud. This results in improved response times and real-time processing
    of data, making it an ideal solution for use cases such as industrial IoT, autonomous
    vehicles, and other real-time data processing applications.
  prefs: []
  type: TYPE_NORMAL
- en: However, running Kubernetes at the edge comes with its own set of challenges.
    Edge devices are typically resource-constrained, making it necessary to optimize
    the deployment of Kubernetes for the edge environment. Organizations must also
    consider the network connectivity and reliability of edge devices, as well as
    the security and privacy implications of deploying a Kubernetes cluster at the
    edge.
  prefs: []
  type: TYPE_NORMAL
- en: Projects like CNCF KubeEdge ([https://kubeedge.io](https://kubeedge.io)) can
    get you started.
  prefs: []
  type: TYPE_NORMAL
- en: However, we will focus for the rest of this chapter on large-scale Kubernetes-based
    systems in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Building effective processes for large-scale Kubernetes deployments
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: To run multi-cluster Kubernetes systems in production, you must develop a set
    of effective processes and best practices that encompass every aspect of the operation.
    Here are some of the critical areas to address.
  prefs: []
  type: TYPE_NORMAL
- en: The development lifecycle
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The development lifecycle of a multi-cluster Kubernetes-based system in production
    can be a complex process, but it is possible to streamline it with the right approach.
  prefs: []
  type: TYPE_NORMAL
- en: You should absolutely implement a CI/CD pipeline that automatically builds,
    tests, and deploys code changes. This pipeline should be integrated with version
    control systems such as Git, and it should also include automated testing to ensure
    code quality.
  prefs: []
  type: TYPE_NORMAL
- en: It’s important to manage the ownership and approval process for different areas
    of the code base.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes namespaces can provide a convenient way to organize workloads and
    corresponding software assets and associate them with teams and stakeholders.
  prefs: []
  type: TYPE_NORMAL
- en: You should have a complete track of changes, ongoing builds, and deployments,
    and the ability to freeze activity and roll back changes of each workload.
  prefs: []
  type: TYPE_NORMAL
- en: It’s also important to control the gradual deployment to different clusters
    and regions to avoid a situation where a bad change is deployed simultaneously
    across the board and brings the entire system down.
  prefs: []
  type: TYPE_NORMAL
- en: Environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Code review and careful incremental deployment while monitoring the outcome
    are required, but they are insufficient for large enterprise systems with multiple
    Kubernetes clusters. Some changes might display a negative impact only after running
    for a while or under certain conditions, which will escape the control mechanisms
    we mentioned earlier. The best practice is to have multiple runtime environments
    such as production, staging, and development. The exact division of environments
    can vary, but you typically need at least a production environment, which is the
    actual system that manages all the data and your users interact with, and a staging
    environment, which mimics the production system and where you can test changes
    and new versions without impacting your users and risking bringing the production
    environment down.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider some aspects of using multiple environments.
  prefs: []
  type: TYPE_NORMAL
- en: Separated environments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is critical that the staging environment can’t accidentally contaminate and
    impact the production environment. For example, if you run a stress test in staging
    and some workloads in the staging environment are misconfigured and hit production
    endpoints, you will have a very unpleasant time untangling the mess.
  prefs: []
  type: TYPE_NORMAL
- en: Rigid network segmentation where the staging environment is unable to reach
    the production environment is a good first step. You will still need to be mindful
    of the interaction between staging and production through public endpoints. The
    staging workloads should not have secrets and identities that allow production
    access.
  prefs: []
  type: TYPE_NORMAL
- en: Staging environment fidelity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The primary motivation for the staging environment is to test changes and interactions
    with other sub-systems before deploying a change to production. This means that
    the staging environment should mimic the production environment as much as possible.
    However, running an exact replica of the production environment is prohibitively
    expensive.
  prefs: []
  type: TYPE_NORMAL
- en: The staging environment should be configured and set up using the same automated
    CI/CD pipeline that is able to deploy staging and production.
  prefs: []
  type: TYPE_NORMAL
- en: Staging infrastructure and resources should also be provisioned using the same
    tools as production although there will typically be fewer resources allocated
    to staging.
  prefs: []
  type: TYPE_NORMAL
- en: You may want to be able to temporarily scale down or even completely shut down
    some parts of the staging environment and be able to bring them back up only when
    necessary for running large-scale tests in staging.
  prefs: []
  type: TYPE_NORMAL
- en: Resource quotas
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Resource quotas in staging and production can ensure that misconfiguration or
    even an attack doesn’t cause excessive resource usage.
  prefs: []
  type: TYPE_NORMAL
- en: Promotion process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once a change has been thoroughly tested in staging, there should be a clear
    promotion process for deploying it to production. The process may be different
    for different components depending on the scope and impact of the change. The
    promotion may be completely automatic where the CI/CD pipeline detects that staging
    tests are completed successfully and moves ahead with production deployment or
    involve extra steps and possibly another explicit deployment to production.
  prefs: []
  type: TYPE_NORMAL
- en: Permissions and access control
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you manage a constellation of Kubernetes clusters running on cloud infrastructure,
    you need to pay a lot of attention to the permission model and your access control.
    This builds on the previous best practices of the development lifecycle and environments.
  prefs: []
  type: TYPE_NORMAL
- en: The principle of least privilege
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The principle of least privilege comes from the security field, but it is useful
    even beyond security for reliability, performance, and cost. Actors – either humans
    or workloads – should not have more permissions than necessary to accomplish their
    tasks. By reducing access to the bare minimum, you ensure that no accidental or
    malicious activity occurs for forbidden resources.
  prefs: []
  type: TYPE_NORMAL
- en: Also, when investigating an incident, it automatically narrows down the possible
    culprits to those who had the permissions to act on the misconfigured resource
    or take the invalid action.
  prefs: []
  type: TYPE_NORMAL
- en: If you follow the GitOps model, it is possible to create a workflow where every
    change to your clusters and your infrastructure is done by CI/CD and dedicated
    tooling. Human engineers have only read-only access. Some special exceptions can
    be made (see the *Break glass* section in this chapter).
  prefs: []
  type: TYPE_NORMAL
- en: Assign permissions to groups
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is highly recommended to assign permissions to groups or teams as opposed
    to individuals. Even if just a single person is currently carrying out a task
    that requires some set of permissions, you should define a group where this person
    is the single member. That will make it easier to add other people later or replace
    the person.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-tune your permission model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: However, sometimes too strict a permission model can be detrimental. You’ll
    have to maintain a very fine-grained set of permissions to a large set of resources.
    Whenever the slightest change occurs such that another action is needed on some
    resource, you’ll have to modify the permissions.
  prefs: []
  type: TYPE_NORMAL
- en: Find the golden path between granting super-admin permissions to everyone and
    painstakingly creating hundreds and thousands of roles for each and every resource.
  prefs: []
  type: TYPE_NORMAL
- en: In particular, consider relaxing the permission model in the development environment
    and potentially in the staging environment too. This is where a lot of experiments
    take place and where you discover what actions you need to perform and what permissions
    are actually necessary and then you can tweak your permissions model before deploying
    to production.
  prefs: []
  type: TYPE_NORMAL
- en: Break glass
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sometimes, your CI/CD pipeline itself will be broken or, due to incomplete coverage,
    some resources may have been provisioned manually. In these cases, human engineers
    must intervene and, so to speak, “*break the glass*” and take direct action against
    Kubernetes or cloud infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended to have a formal process of acquiring **break glass** access,
    who is allowed to have it, how long it lasts, and record who had it.
  prefs: []
  type: TYPE_NORMAL
- en: This brings us to the next section about observability.
  prefs: []
  type: TYPE_NORMAL
- en: Observability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A comprehensive observability stack is an absolute must. Complex systems composed
    of multiple Kubernetes clusters can be reasoned about and understood theoretically.
    You must have a complete record of events from cloud providers, Kubernetes itself,
    and workloads. Your CI/CD pipeline and other tools must also be fully observable.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at some elements of multi-cluster observability.
  prefs: []
  type: TYPE_NORMAL
- en: One-stop shop observability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cloud providers and Kubernetes itself provide a lot of observability in the
    form of logs and metrics out of the box. However, those are typically organized
    at the cluster level. If you are dealing with some widespread issue across multiple
    clusters, it is very difficult, and at a certain scale impossible, to go into
    each individual cluster, extract the observability data, and try to make sense
    of it. You must ship all observability data into a single centralized system where
    it can be aggregated, summarized, and be ready for multi-cluster analysis and
    response.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting your observability stack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Your observability stack is an indispensable component of your system. If it
    is down or degraded, you may be flying blind and unable to effectively respond
    to issues. Moreover, a cross-cluster issue may impact your observability stack
    as it impacts your entire system. Consider this scenario very carefully and make
    sure you have plenty of redundancies and observability alternatives if your primary
    observability stack is not up to the task temporarily. For example, you may rely
    on in-cluster observability solutions if your centralized observability stack
    is compromised. If you want complete redundancy, you may have a parallel observability
    stack on two cloud providers.
  prefs: []
  type: TYPE_NORMAL
- en: Consider testing these harsh scenarios of CI/CD pipeline and observability stack
    outages and see how you operate.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look more specifically into different types of infrastructure and how
    to handle them at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Handling infrastructure at scale
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the most demanding tasks when running large-scale multi-cluster Kubernetes
    in the cloud is dealing with the cloud infrastructure. In some respects, it is
    much better than being responsible for low-level compute, network, and storage
    infrastructure. However, you lose a lot of control, and troubleshooting issues
    is challenging.
  prefs: []
  type: TYPE_NORMAL
- en: Before diving into each category of infrastructure, let’s look at some general
    cloud-level considerations.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud-level considerations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the cloud, you organize your resources in entities such as AWS accounts,
    GCP projects, and Azure subscriptions. An organization may have multiple such
    groups, and each one has its own limits and quotas. For the sake of brevity, let’s
    call them accounts. Enterprise organizations’ infrastructure requirements will
    exceed the capacity of a single account. It’s critical to decide how to break
    down your infrastructure into different accounts. One good heuristic is to separate
    environments – production, staging, and development – into separate accounts.
    Account-level isolation is beneficial for these environments. However, this may
    not be sufficient and within a single environment, you might need more resources
    than can fit in one account.
  prefs: []
  type: TYPE_NORMAL
- en: Having a solid account management strategy is key. Accounts can also be a boundary
    of access control as even account administrators can’t access other accounts.
  prefs: []
  type: TYPE_NORMAL
- en: Consult with your security team about security-motivated account breakdowns.
  prefs: []
  type: TYPE_NORMAL
- en: Another important aspect is the breakdown of regions. If you manage infrastructure
    across multiple regions and workloads in these regions communicate with each other,
    then this has severe latency and cost implications. In particular, cross-region
    egress is typically not free.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at each category of infrastructure.
  prefs: []
  type: TYPE_NORMAL
- en: Compute
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Compute infrastructure for Managed Kubernetes includes the Kubernetes clusters
    themselves and their worker nodes. The worker nodes are typically grouped into
    node pools, which is not a Kubernetes concept. How you break down your system
    into Kubernetes clusters and what types of node pools exist in each cluster will
    greatly impact your ability to manage the system at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Ideally, you can treat clusters like cattle, provision identical clusters, and
    easily add or remove clusters in different locations. Each cluster will have the
    same node pools.
  prefs: []
  type: TYPE_NORMAL
- en: This uniform and consistent organization of clusters is not always possible.
    There are sometimes reasons to have different clusters for particular purposes.
    You should still strive for a small number of cluster types that can be replicated
    easily.
  prefs: []
  type: TYPE_NORMAL
- en: Design your cluster breakdown
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Clusters in the cloud typically allocate private IP addresses to nodes and pods
    from a virtual network that resides in one region. Yes, it’s possible to have
    wide clusters that cross regions, but this is the exception and not the rule.
    It is highly recommended to manage clusters as cattle if possible and automatically
    provision clusters across all regions of operations.
  prefs: []
  type: TYPE_NORMAL
- en: Design your node pool breakdown
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Node pools are groups of nodes that have the same instance type. They can typically
    autoscale to accommodate the needs of the cluster with the help of the cluster
    autoscaler. How you choose what node pools to provision in your clusters is a
    fundamental decision that impacts performance, cost, and operational complexity.
  prefs: []
  type: TYPE_NORMAL
- en: We will dive into a deeper discussion on this later in the chapter.
  prefs: []
  type: TYPE_NORMAL
- en: Networking
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Networking is a very dynamic area of infrastructure. There are many degrees
    of freedom. The interplay between latency and bandwidth has nuances. Workloads
    can’t request a certain amount of bandwidth or guaranteed latency. In addition,
    there are a lot of external factors that impact the connectivity, reachability,
    and performance of your network. Let’s look at some of the important topics we
    have to consider and plan for.
  prefs: []
  type: TYPE_NORMAL
- en: IP address space management
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When you run a multi-cluster Kubernetes-based system, every pod in a cluster
    gets a unique private IP address. However, if you want to connect multiple clusters
    and have workloads in one cluster reach workloads in other clusters via their
    private IP address, then two conditions must exist:'
  prefs: []
  type: TYPE_NORMAL
- en: The networks of the different clusters must be peered together.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The private IP address of pods must be unique across all clusters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: This requires centralized management of the private IP address space and carefully
    assigning IP ranges to different clusters.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud providers differ a little in their approach to assigning IP address ranges
    to clusters. AKS requires that each cluster belongs to a VNet with its own IP
    address range and then subnets are assigned to nodes and pods with sub-ranges
    from the VNet IP address range. GKE comes with a default network that has no IP
    address range of its own. Clusters are provisioned with subnets that have their
    own IP address ranges.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, services require their own IP addresses too, and possibly some
    other components.
  prefs: []
  type: TYPE_NORMAL
- en: 'The entire private IPv4 address space consists of several blocks:'
  prefs: []
  type: TYPE_NORMAL
- en: '`10.0.0.0/8` (class A)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`172.16.0.0/12` (class B)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`192.168.0.0/8` (class C)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: At scale, the most important one is `10.0.0.0/8`, which consists of 2^24 IP
    addresses, which is more than 16 million addresses. That is a lot of IP addresses,
    but if you don’t plan carefully, you may cause fragmentation and run out of large
    blocks even if you have plenty of unused IP addresses.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some best practices for managing the IP address space:'
  prefs: []
  type: TYPE_NORMAL
- en: Allocate CIDR blocks to pods, nodes, and services that will be sufficient and
    utilized without too much space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be aware of Kubernetes and cloud provider limits in terms of the number of supported
    nodes and pods.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider network peering and service meshes spanning clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Make sure you use non-overlapping CIDR blocks for connected clusters.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use proper tools to manage the address space.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Consider the impact of pod density on IP address space (e.g., on AKS, IP addresses
    are pre-allocated to the max number of pods on a node even if not utilized).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Be aware of limits such as the maximum number of IP addresses available in a
    region.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network topology
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: All cloud providers offer a virtual network or VPC concept. All cloud providers
    also have the concept of a region, which is a geographical area where cloud providers
    host resources. Specifically, virtual networks are always confined to a single
    region. Since a Kubernetes cluster in the cloud is associated with a virtual network,
    it follows that a single Kubernetes cluster can’t span more than one region. This
    has implications for availability and reliability. If you want to survive a regional
    outage, you need to run each critical workload across multiple clusters in different
    regions. Moreover, all these clusters typically need to be connected to each other.
    We will discuss this more in the *Cross-cluster communication* section that follows.
    However, as far as network topology goes, it may be better to have multiple clusters
    in the same region share the same virtual network.
  prefs: []
  type: TYPE_NORMAL
- en: Network segmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Network segmentation is about dividing a network into smaller subnets. In the
    context of Kubernetes, the most important subnets are the subnets for nodes, pods,
    and services. In some cases, the nodes and pods share the same subnet and in other
    cases, there are separate subnets for nodes and pods. Regardless, you need to
    plan and understand how many nodes and pods your cluster can accommodate and size
    your cluster subnets accordingly.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-cluster communication
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'When running multiple Kubernetes clusters, it is often beneficial to consider
    groups of clusters as a single conceptual cluster. This means that pods in any
    cluster can directly reach pods in other clusters via their private IP address.
    This flat IP address model is an extension of the standard Kubernetes networking
    model within a single cluster to multiple clusters. This requires two elements
    we discussed earlier:'
  prefs: []
  type: TYPE_NORMAL
- en: Non-conflicting IP address ranges for pods across all connected clusters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Network peering between clusters.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The network peering requirement might be tedious as clusters come and go. Having
    a single regional virtual network reduces the overhead and allows peering just
    the regional virtual networks. However, if you run a lot of clusters in the same
    region sharing the same virtual network, you might run into cloud provider limits
    that will stunt your growth. For example, on Azure, a VNet can have at most 64K
    unique IP addresses.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-cloud communication
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If your system spans multiple cloud providers, you need to consider how to connect
    your Kubernetes clusters across cloud providers. There are several ways, with
    different pros and cons.
  prefs: []
  type: TYPE_NORMAL
- en: First, you may decide to avoid direct communication between clusters on different
    cloud providers. If Kubernetes clusters deployed on different clouds need to communicate
    with each other, they can do so through public APIs. This approach is simple but
    eliminates the idea of a unified conceptual cluster where pods can communicate
    directly with each other regardless of where they are.
  prefs: []
  type: TYPE_NORMAL
- en: A site-to-site VPN is a communication method where different cloud providers
    can connect systems via BGP and establish a VPN connection to networks managed
    by another cloud provider via a VPN gateway that sits in front of the virtual
    networks. This establishes a secure channel; however, a VPN gateway is not trivial
    to set up and incurs a significant overhead.
  prefs: []
  type: TYPE_NORMAL
- en: Direct connect (AKA direct peering) is another option that requires installing
    a router in a cloud provider point of presence. This method allows connecting
    Kubernetes clusters running in private data centers to clusters in the cloud.
    In addition, the performance is much better because there is no VPN gateway in
    the middle. The downside is that it is quite complicated to set up and you might
    have to comply with various requirements. It’s a good option for organizations
    with deep low-level networking expertise.
  prefs: []
  type: TYPE_NORMAL
- en: Carrier or partner peering is similar to direct connect; however, you take advantage
    of the expertise of an established third party that specializes in providing this
    service and already has an established relationship and is certified with the
    cloud provider. You will have to pay for the service, of course.
  prefs: []
  type: TYPE_NORMAL
- en: Cross-cluster service meshes
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Service meshes bring tremendous value to Kubernetes, as we discussed in *Chapter
    14*, *Utilizing Service Meshes*. When running multiple Kubernetes clusters in
    production, it is arguably even more important to connect all the clusters via
    a service mesh. The advanced capabilities and policies of a service mesh can be
    applied and manage connectivity and routing across all clusters.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two approaches to consider here:'
  prefs: []
  type: TYPE_NORMAL
- en: A single fully connected service mesh.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Divide your clusters into multiple meshes.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The single fully connected single mesh aligns conceptually with the single conceptual
    Kubernetes cluster approach. Everything is straightforward. New clusters just
    join the mesh, and the mesh is configured to allow every pod to talk to every
    other pod (as long as the routing policies allow it).
  prefs: []
  type: TYPE_NORMAL
- en: However, you might eventually run into scalability barriers as a single mesh
    means that the mesh control plane needs to handle policies for all workloads in
    all the clusters, and updating sidecars for all pods can put a lot of burden on
    your clusters.
  prefs: []
  type: TYPE_NORMAL
- en: An alternative approach is to have multiple independent meshes. Pods in clusters
    that belong to a particular mesh can directly talk to pods in all other clusters
    in the same service mesh but must go through public endpoints to access clusters
    in other service meshes.
  prefs: []
  type: TYPE_NORMAL
- en: The multi-mesh approach is more scalable but much more complicated. You need
    to consider how to divide your system into different service meshes and when new
    clusters join or leave the system, and how it impacts your overall architecture.
  prefs: []
  type: TYPE_NORMAL
- en: The private IP address space management in the multi-service mesh case can be
    more nuanced too where different service meshes can have conflicting IP addresses.
    This means that you can manage the IP address space for each mesh separately.
  prefs: []
  type: TYPE_NORMAL
- en: Service meshes offer another interesting solution to the cross-cluster connectivity
    story, which is the east-west gateway. With the east-west gateway approach, workloads
    in different clusters communicate indirectly through dedicated gateways in each
    cluster. This means that the private IP addresses of each cluster are unknown
    and there is an extra hop for each cross-cluster communication.
  prefs: []
  type: TYPE_NORMAL
- en: Managing egress at scale
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Some systems need to access external systems aggressively. Maybe you frequently
    fetch data from external systems or maybe the purpose of your system is to manage
    some external systems via APIs.
  prefs: []
  type: TYPE_NORMAL
- en: There may be unique issues for egress traffic that require special attention.
    Some third-party organizations or even countries may have policies that block
    or throttle traffic coming from certain geographical areas or specific IP CIDR
    blocks. For example, China and its great firewall are famous for blocking and
    censoring a vast number of companies, such as Google and Facebook. If you run
    on GCP and need to access China, it might be a serious issue.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond total blocking, there may be limits and throttling in place if you try
    to access some third-party APIs at scale.
  prefs: []
  type: TYPE_NORMAL
- en: If you persist in accessing those third-party APIs, you could even be reported,
    and your cloud provider could potentially impose various sanctions.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s consider some solutions to deal with these real-world problems.
  prefs: []
  type: TYPE_NORMAL
- en: If your current cloud provider is not allowed to access your target destination,
    then you must establish an egress presence outside your cloud provider. This can
    be on another cloud provider or via an intermediate organization in good standing.
    This proxy approach can take many shapes, which is beyond the scope of this section.
  prefs: []
  type: TYPE_NORMAL
- en: If you are getting throttled, then the issue may be that you send too many requests
    from the same source IP address. A good solution here is to create a pool of egress
    nodes with different public IP addresses and distribute your requests through
    multiple different IP addresses. It can also help if you rotate your public IP
    addresses periodically, which is pretty easy in the cloud by just re-creating
    instances, which receive new public IP addresses.
  prefs: []
  type: TYPE_NORMAL
- en: The opposite issue is if you have an agreement with some third-party company
    and they specifically allow traffic from your organization by whitelisting some
    IP addresses you provide. In this case, you need to manage static public IP addresses
    that don’t change and ensure that all requests to that third-party organization
    go out through the whitelisted IP addresses.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to address the risk of being reported and flagged by your cloud provider,
    you may need to isolate your egress access to a separate account. Most cloud provider
    sanctions are at the account level. If your egress account is disabled by your
    cloud provider, at least it will not bring down the entire enterprise.
  prefs: []
  type: TYPE_NORMAL
- en: Managing the DNS at the cluster level
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Large-scale clusters with lots of pods and services may put a high load on CoreDNS,
    which is the internal DNS server of Kubernetes. It’s important to ensure sufficient
    DNS capacity since most internal communication between workloads in the cluster
    uses DNS names for addressing and not direct IP addresses.
  prefs: []
  type: TYPE_NORMAL
- en: It is recommended to use DNS autoscaling, which is often not enabled by default.
    See [https://kubernetes.io/docs/tasks/administer-cluster/dns-horizontal-autoscaling/](https://kubernetes.io/docs/tasks/administer-cluster/dns-horizontal-autoscaling/)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: Storage
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Storage is arguably the most critical element of your infrastructure. This is
    where your persistent data lives, which is the long-term memory of organizations.
  prefs: []
  type: TYPE_NORMAL
- en: Choose the right storage solutions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are many storage solutions available for Kubernetes clusters in the cloud,
    such as cloud-native blob storage, managed storage services, managed databases,
    and managed file systems. You should develop a deep understanding of the performance,
    durability, and cost of each storage solution and match them against your storage
    use cases.
  prefs: []
  type: TYPE_NORMAL
- en: Your baseline should always be cloud-native blob storage (AKA buckets) like
    AWS S3, GCP Google Cloud Storage, or Azure Blob Storage. It’s hard to imagine
    a large-scale Managed Kubernetes enterprise that doesn’t use buckets.
  prefs: []
  type: TYPE_NORMAL
- en: Then, consider more structured or high-level storage solutions. If you aim to
    stay cloud-agnostic, you may ignore cloud-based managed storage solutions and
    deploy your own solutions, as we saw in *Chapter 6*, *Managing Storage*.
  prefs: []
  type: TYPE_NORMAL
- en: At an enterprise scale, it may be worthwhile considering different levels of
    access speed and cost for data at different levels of importance.
  prefs: []
  type: TYPE_NORMAL
- en: Data backup and recovery
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Plan for data backup and recovery. Your data is valuable. Data backup and recovery
    are crucial for production environments. Consider implementing data backup and
    recovery processes that are reliable and scalable, and make sure they are regularly
    tested and updated.
  prefs: []
  type: TYPE_NORMAL
- en: You should also consider data retention policies and not automatically assume
    that all data must be kept forever.
  prefs: []
  type: TYPE_NORMAL
- en: Of course, to comply with data privacy laws and regulations like the GDPR, you
    will need to build the ability to selectively delete data too.
  prefs: []
  type: TYPE_NORMAL
- en: Storage monitoring
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Set up storage monitoring. Period. Monitoring storage performance, usage, and
    capacity is essential for identifying and resolving issues before they impact
    the availability or performance of your applications. Set up monitoring and alerting
    for storage utilization, latency, and throughput. This is important for managed
    storage, but also for node storage where logs can easily accumulate and render
    a node un-operational.
  prefs: []
  type: TYPE_NORMAL
- en: Data security
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Implement data security measures. Protecting sensitive data and ensuring compliance
    with data protection regulations is critical for production environments. Implement
    access controls, encryption, and data security policies to safeguard your data.
  prefs: []
  type: TYPE_NORMAL
- en: Optimize storage usage
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Kubernetes clusters in the cloud can be expensive, and storage costs can add
    up quickly. Optimize your storage usage by deleting unused data, using data compression
    or deduplication, and setting up storage tiering.
  prefs: []
  type: TYPE_NORMAL
- en: Test and validate storage performance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Before deploying applications in a production environment, test and validate
    the performance of your storage solution to ensure it meets the performance requirements
    of your workloads.
  prefs: []
  type: TYPE_NORMAL
- en: By considering these factors and implementing best practices for managing storage
    in production for Kubernetes clusters in the cloud, you can ensure reliable and
    scalable storage performance for your applications.
  prefs: []
  type: TYPE_NORMAL
- en: Now that we have covered a lot of guidelines and best practices for managing
    cloud infrastructure at scale for Kubernetes, let’s shine a spotlight on the management
    of clusters and node pools, which is at the heart of managing multi-cluster Kubernetes
    in production.
  prefs: []
  type: TYPE_NORMAL
- en: Managing clusters and node pools
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Managing your clusters and node pools is the top infrastructure administration
    activity for a large-scale Kubernetes-based enterprise. In this section, we will
    look at several crucial aspects, including provisioning, bin packing and utilization,
    upgrades, troubleshooting, and cost management.
  prefs: []
  type: TYPE_NORMAL
- en: Provisioning managed clusters and node pools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: There are different methods for provisioning clusters and node pools. You should
    choose the method that is best for your use case wisely because failure here can
    result in devastating outages. Let’s review some options. All cloud providers
    offer cluster and node pool provisioning via APIs, CLIs, and UIs. I highly recommend
    avoiding directly using any of these methods and instead using GitOps-based declarative
    approaches. Here are some solid options to consider.
  prefs: []
  type: TYPE_NORMAL
- en: The Cluster API
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Cluster API is an open-source project from the Cluster Lifecycle SIG. Its
    goal is to make provisioning, upgrading, and operating multiple Kubernetes clusters
    easier. It is focused on clusters’ and node pools’ lifecycles. However, it started
    mostly as a way to provision clusters using kubeadm. Managed cluster support on
    different cloud providers was added later, and it is still young. In particular,
    GKE is not supported (although you can provision Kubernetes clusters on GCP as
    an infrastructure layer). AKS and EKS are supported.
  prefs: []
  type: TYPE_NORMAL
- en: The Cluster API has a lot of momentum, and if you don’t operate GKE, you should
    definitely look into it.
  prefs: []
  type: TYPE_NORMAL
- en: Terraform/Pulumi
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Terraform and Pulumi are similar in their approach. They can provision clusters
    and node pools on all cloud providers. However, these tools on their own can’t
    respond to out-of-band changes and don’t monitor the state of the infrastructure
    after provisioning. Their internal state can deviate from the real world and that
    can cause difficult to recover from situations that require careful “surgery.”
    In particular, node pools often need to be provisioned or updated, and Terraform
    or Pulumi might not be up to the task. If you have a lot of experience with these
    tools and are aware of their quirks and special requirements, they may still be
    a good option for you.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes operators
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Another alternative is to use Kubernetes operators that reconcile CRDs with
    cluster and node pool specs with the cloud provider. Under the covers, the operator
    will invoke Managed Kubernetes APIs from the cloud provider. This requires non-trivial
    work and expertise in writing Kubernetes operators but gives you the ultimate
    control.
  prefs: []
  type: TYPE_NORMAL
- en: You may try to use Crossplane instead of writing your own operator; however,
    Crossplane support seems pretty basic and incomplete at the moment. One option
    to expand the scope is to use the Upjet project ([https://github.com/upbound/upjet](https://github.com/upbound/upjet))
    to generate Crossplane controllers from Terraform providers.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing managed nodes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: You can also try to use managed nodes, so you never need to deal with provisioning
    node pools and nodes directly. All cloud providers offer some form of managed
    nodes such as GKE AutoPilot, EKS + Fargate, and AKS + ACI. For enterprise use
    cases, I believe you will need more control than fully managed node pools provide.
    It may be a good option for a subset of your workloads. However, at scale, you
    will want to optimize your resource usage and performance and the limitations
    of managed node pools might be too severe.
  prefs: []
  type: TYPE_NORMAL
- en: Once you have figured out how to provision and manage your clusters and node
    pools, you should turn your attention to effectively using the resources you provisioned.
  prefs: []
  type: TYPE_NORMAL
- en: Bin packing and utilization
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Cloud resources are expensive. Efficient usage of resources on Kubernetes has
    two parts: efficiently scheduling pods to nodes based on their resource requests,
    and pods actually using the resources they requested.'
  prefs: []
  type: TYPE_NORMAL
- en: Bin packing means ensuring that the total sum of resource requests is as close
    as possible to the allocatable resources on the target node. Once a workload is
    scheduled to a node, it will not be evicted under normal conditions even if the
    node is highly underutilized, but components like the cluster autoscaler can help
    here.
  prefs: []
  type: TYPE_NORMAL
- en: Resource utilization measures what percentage of the requested resource is actually
    used. Resource utilization is in general not fixed as the resource usage of workloads
    may vary widely throughout their lifetimes.
  prefs: []
  type: TYPE_NORMAL
- en: There are a lot of nuances to bin packing, resource utilization, and the interplay
    between them. For example, there are different resources such as CPU, memory,
    disk, and network. A node may have 100% bin packing for CPU, but only 20% bin
    packing memory. Network and non-ephemeral disks on the node are shared resources
    that pods can request to ensure they will always have a certain amount. This complicates
    operation and reliability. Let’s discuss some principles and concepts that can
    assist in navigating this complicated topic.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding workload shape
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Workload shape is the ratio between the workload CPU requests and its memory
    requests. In the cloud, there is a standard ratio of 1 CPU to 4 GiB of memory.
    As a result, most VM types that you can choose offer resource capacities with
    this ratio. Some workloads need more memory or more CPU than this ratio. All cloud
    providers also offer high-memory VM types with a ratio of 1 CPU to 8 GiB of memory
    as well as high-CPU VM types with 1 CPU to 2 GiB of memory.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding the resource shape of your workloads is necessary to inform the
    VM types you choose to optimize your resource usage.
  prefs: []
  type: TYPE_NORMAL
- en: For example, if a workload requires 1 CPU and 8 GiB of memory and you schedule
    it on a VM type with a ratio of 1:4, you will need to run it on a node that has
    2 CPUs and 8 GiB of memory. No other pod can run on this node since the original
    workload uses all the 8 GiB of memory. However, 1 CPU out of 2 is not used at
    all. It would have been much better to schedule the workload on a node with a
    VM type of 1:8 ratio, which ensures optimal bin packing.
  prefs: []
  type: TYPE_NORMAL
- en: Setting requests and limits
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Setting requests and limits for your workloads is a key for proper resource
    utilization. As you recall when you set requests for your pod’s containers, it
    will be scheduled to a node that has at least the requested number of resources
    available for the total sum of the requests of all containers. The requested resources
    are allocated for the exclusive use of each container for as long as the pod running
    on the node. The containers may use more resources than the requests if available.
    If you specify CPU limits and the container tries to use more CPU than the limit,
    then the pod may get throttled. If you specify a memory limit and the container
    tries to use more memory than the limit, then the container will be OOMKilled
    and restarted.
  prefs: []
  type: TYPE_NORMAL
- en: It is best practice to set resource requests for CPU, memory, and even ephemeral
    storage if the container uses any. How do you know how much to request? You can
    start with a rough estimate and monitor the actual resource usage over time and
    fine-tune it later.
  prefs: []
  type: TYPE_NORMAL
- en: But even this straightforward method has some subtleties. Suppose a workload
    uses between 2 CPUs and 4 CPUs with an average of 3 CPUs. Should you request 4
    CPUs and know for sure that the workload will never get throttled? But then, you
    waste a whole CPU because the average usage is just 3 CPUs. If you request 3 CPUs,
    are you going to get throttled every time the workload needs more than 3 CPUs?
    That depends on the available CPU on the node the pod is scheduled to. If the
    overall CPU on the node is saturated because all the pods need a lot of CPU, then
    it is possible.
  prefs: []
  type: TYPE_NORMAL
- en: On top of plain requests, you can also assign priorities to workloads, which
    allow you to control the destiny of high-priority workloads and ensure they take
    precedence over non-prioritized or low-priority workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Yes, scheduling is far from trivial. If you need a refresher, check out the
    *Understanding the design of the Kubernetes scheduler* section in *Chapter 15*,
    *Extending Kubernetes*.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s turn our attention to limits. A simple approach is to set limits equal
    to the requests. This ensures in general that containers will not use more resources
    than they requested, which makes bin packing easy. However, in real-world situations,
    the resource usage of workloads varies. It is often more economical to request
    less than the maximal usage or sometimes even less than the average usage. In
    this case, you may opt not to set limits at all or set the limits higher than
    the requests. For example, if a workload uses 1 to 4 CPUs, then you may decide
    to request 2 CPUs and set the limits to 4 CPUs. Requesting just 2 CPUs will allow
    packing more pods into the same node or schedule the pod into a smaller node.
    So, why set limits at all? Well, setting some limits ensures the pods don’t get
    out of control, hog all the CPU, and starve all other pods that may also set lower
    requests but actually need additional CPU.
  prefs: []
  type: TYPE_NORMAL
- en: Setting memory high limits is even more important, especially for workloads
    that are more sensitive and that shouldn’t be restarted often since any attempt
    to use more allocated memory than the limit will result in a container restart.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing init containers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Some workloads need to do a lot of work when they just start and then their
    resource requirements are lower. For example, a workload needs 10 GiB of memory
    and 4 CPUs to fetch some data and process it in memory before it is ready to handle
    requests. However, once it’s running, it doesn’t need more than 1 CPU and 4 GiB.
    It would be pretty wasteful to request 4 CPUs and 10 GiB if the pod is a long-running
    one. This is where init containers are very useful. You can split your workload
    into two containers. All the initialization work that requires 4 CPUs and 10 GiB
    can be done by an init container and then the main container can request just
    1 CPU and 4 GiB.
  prefs: []
  type: TYPE_NORMAL
- en: Shared nodes vs. dedicated nodes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When designing your node pools, you have two fundamental choices to make. Shared
    node pools have multiple different workloads scheduled and run side by side on
    the same node. Dedicated node pools have a single workload taking over a single
    node (possibly multiple instances of the same workload).
  prefs: []
  type: TYPE_NORMAL
- en: Shared node pools are simple. The extreme case is that you have just a single
    node pool and all pods are scheduled to nodes from this node pool. If you have
    multiple shared node pools (e.g., one with regular nodes and one with spot instances),
    then you need to assign taints to node pools and tolerations to workloads as well
    as dealing with node and pod affinity.
  prefs: []
  type: TYPE_NORMAL
- en: Since you don’t know exactly which combination of pods will end up on which
    node, there might be inefficiencies with bin packing. However, as long as the
    overall average workload shape matches the resource ratio of your nodes, bin packing
    at a large scale should be close to optimal.
  prefs: []
  type: TYPE_NORMAL
- en: Workloads can request the CPU, memory, and ephemeral storage they need. However,
    there are some shared resources on the node, like network and disk I/O, that you
    can’t easily carve out for your workload when other workloads on the same node
    might try to use the same resource.
  prefs: []
  type: TYPE_NORMAL
- en: This is where dedicated node pools come in. Critical workloads like databases
    or event queues require predictable network and disk I/O. Scheduling such workloads
    on a dedicated node ensures the workload doesn’t have to worry about other workloads
    cannibalizing the shared resources.
  prefs: []
  type: TYPE_NORMAL
- en: It makes sense in this case for the workload to request more than 50% of the
    standard resources like CPU or memory to ensure exactly one pod of the critical
    workload is scheduled on the node.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that system daemons will also run on the node and have higher priority.
    If your dedicated workload requests too many resources, it might become unschedulable.
  prefs: []
  type: TYPE_NORMAL
- en: I have run into this issue after an upgrade where the daemonsets on the node
    required more resources and caused the dedicated workload to be unschedulable
    until it reduced its resource requests.
  prefs: []
  type: TYPE_NORMAL
- en: Large nodes vs, small nodes
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the cloud, nodes come in a variety of sizes, from 1 core to tens or even
    hundreds of cores. Should you have lots of small nodes or fewer large nodes?
  prefs: []
  type: TYPE_NORMAL
- en: First and foremost, you must have nodes that your largest workloads fit into.
    For example, if a workload requests 8 CPUs, then you must have a node with at
    least 8 CPUs available.
  prefs: []
  type: TYPE_NORMAL
- en: But what about much bigger nodes? There are advantages in terms of efficiency
    for larger nodes. In the cloud, when you provision (for example) a node with 1
    CPU core and 4 GIB of memory, you don’t really get all these resources. First,
    the OS, the container runtime, and kube-proxy take their resources, then the additional
    processes the cloud provider decides to run on each node, then various sys daemonsets
    and your own daemonsets. Finally, what’s left is available for your workloads.
    All these processes and workloads that always run on every node need a lot of
    resources. However, the resources they require are not proportional to the size
    of the node. This means that on small nodes, a much smaller percentage of the
    resources you pay for will be available for your pods. Let’s look at an example.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is the resource breakdown for a real node running on an AKS production
    cluster. It has a VM type of **Standard_F2s_v2** ([https://learn.microsoft.com/en-us/azure/virtual-machines/fsv2-series](https://learn.microsoft.com/en-us/azure/virtual-machines/fsv2-series)).
    It has 2 CPUs and 4 GIB of memory. However, the allocatable CPU and memory is
    1.9 CPU and 2.1 GiB. Yes, this is correct. You barely get a little more than 50%
    of the memory available on the node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'But the story doesn’t end here. There are system daemonsets running in kube-system.
    You can find them with the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at the resources requested by these workloads on our node:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: That’s a total of 0.56 CPU and 520Mi of memory. If we subtract it from the allocatable
    CPU and memory, we end up with 1.4 CPU and 1.58 GiB of memory.
  prefs: []
  type: TYPE_NORMAL
- en: This is quite eye-opening. On a small node with 2 CPUs and 4 GIB of memory,
    we end up with 70% of the CPU and less than 40% of the memory. Beyond the cost
    implications, if you miscalculate and assume you can schedule, for example, a
    pod that requests 2 GIB of memory on a 4 GiB node, you’ll have an unpleasant surprise
    when your pod remains pending because it doesn’t fit on this node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at large nodes. A Standard_D64ads_v5 Azure VM has a whopping 64
    cores and 256 GiB of memory. It is undoubtedly a beast. Let’s look at its capacity
    and allocatable resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Here, we lost 740 mcpu (as opposed to 100 mcpu on the small node) and 17 GiB
    of memory. This sounds like a lot, but proportionally, it is much better. Let’s
    look at system workloads to get the full picture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: That’s a total of 0.365 CPU and 520Mi of memory. Surprisingly, less CPU is requested
    than the small node and the memory requests are the same. If we subtract it from
    the allocatable CPU and memory, we end up with 62.9 CPU and 238.48 GiB of memory.
  prefs: []
  type: TYPE_NORMAL
- en: On a large node with 64 cores and 256 GiB of memory, we end up with more than
    98% of the CPU and more than 93% of the memory.
  prefs: []
  type: TYPE_NORMAL
- en: This is a pretty clear victory for large nodes in terms of resource provisioning
    efficiency and getting more resources available for your workloads.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are additional nuances and considerations to consider. Let’s
    consider small and short-lived workloads.
  prefs: []
  type: TYPE_NORMAL
- en: Small and short-lived workloads
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Suppose we use large nodes, and our cluster is bin-packed very efficiently.
    Some deployment needs to scale up and create a new pod. If there is no room for
    the new pod in any of the existing nodes, then a new node must be provisioned.
    However, if the new pod is small, then we actually waste a lot of resources by
    running just one small pod on a large node. At scale, and when a lot of pods come
    and go pretty quickly, this may not be a problem. However, consider the following
    scenario – our cluster is normally running on 100 large nodes. During a temporary
    spike of activity, our clusters scaled up to 200 large nodes and then the activity
    went back to normal. Our resource utilization is now 50% (the cluster needs 100
    nodes out of 200). In an ideal world, the cluster autoscaler will eventually scale
    down empty nodes until we have 100 properly bin-packed nodes. But, in the real
    world, especially in the presence of small short-lived pods, new pods may get
    scheduled arbitrarily to all 200 nodes and the autoscaler might have a difficult
    time scaling down. We will see later, in the custom scheduling section, some options.
  prefs: []
  type: TYPE_NORMAL
- en: Another issue with short-lived workloads is that even if they have room on an
    existing node, they can still waste resources if they take a while to get ready.
    Consider a pod that takes 1 minute to get ready and runs, on average, for 1 minute.
    This pod with optimal utilization of its resources still can do better than 50%
    because after it gets scheduled, it reserves its resources on the node for 2 minutes,
    but actually does work for only 1 minute. If the pod needs to pull its image,
    then it can easily take several minutes to get ready.
  prefs: []
  type: TYPE_NORMAL
- en: The Kubernetes scheduler is very sophisticated and can be extended too, as we
    covered in *Chapter 15*, *Extending Kubernetes*. The issues with the inefficient
    scheduling of pods in the different use cases we mentioned could potentially be
    addressed by choosing a different scoring strategy. The default scoring strategy
    of **RequestedToCapacityRatio** is intended to evenly distribute workloads across
    all nodes. This is not ideal for tight bin packing. The **MostAllocated** scoring
    strategy may be preferable here.
  prefs: []
  type: TYPE_NORMAL
- en: Check out [https://kubernetes.io/docs/concepts/scheduling-eviction/resource-bin-packing](https://kubernetes.io/docs/concepts/scheduling-eviction/resource-bin-packing)
    for more details.
  prefs: []
  type: TYPE_NORMAL
- en: Pod density
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Pod density is the maximum number of pods per node (the Kubernetes default is
    110). As mentioned earlier, some resources like private IP addresses or system
    daemon CPU and memory may be correlated with the pod density. If your pod density
    is too high, then you may waste the resources that were pre-allocated to support
    many pods on each node. However, if you set the pod density too low, then you
    may not be able to schedule enough pods to run on the node. Let’s consider a large
    node with 64 CPU cores and 256 GiB of memory. If the pod density is 100, then
    at most 100 pods can run on this node. Suppose we have a lot of small pods that
    use only 10 mcpu and 100 MiB of memory. 100 pods need only 10 CPU cores and 10
    GiB of memory combined. If 100 such pods get scheduled to one large node, the
    node will be highly underutilized. 54 CPU cores and 246 GIB of memory will be
    wasted.
  prefs: []
  type: TYPE_NORMAL
- en: If you go with the shared node pool model, then it’s an arbitrary mix of pods
    with different workload shapes, and resource requirements can get scheduled to
    nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Fallback node pools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Cloud providers suffer from temporary capacity issues from time to time, and
    as a result, are unable to provision new nodes. In addition, spot instances may
    disappear at any time if there is a lot of demand for regular nodes. The good
    news is that these outages are a zonal affair and also are typically limited to
    a specific instance type or VM family.
  prefs: []
  type: TYPE_NORMAL
- en: A good strategy to address this issue is to use fallback node pools.
  prefs: []
  type: TYPE_NORMAL
- en: A fallback node pool is an empty node pool with autoscaling disabled that has
    the same labels and taints as another active node pool but with a different VM
    family or a different node type (e.g., regular vs. spot). If the active node pool
    is unable to provision more nodes and there are pending pods, then the back node
    pool can be resized and/or become auto-scaling. This will allow the pending pods
    to be scheduled to the backup node pool until the situation with the native node
    pool is resolved.
  prefs: []
  type: TYPE_NORMAL
- en: If you choose this path, you need to come up with a proper procedure to activate
    the backup node pool, which includes detection of issues in the active node pool,
    a manual or automated process for backup node pool activation, and a scale-back
    process when the active node pool is back to normal.
  prefs: []
  type: TYPE_NORMAL
- en: It is very important to ensure the backup node pool has enough quota to replace
    its active node pool when needed.
  prefs: []
  type: TYPE_NORMAL
- en: This was a very thorough treatment of bin packing and resource utilization.
    Let’s turn our attention to upgrades.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading Kubernetes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Upgrading Kubernetes can be a very stressful operation. A hasty upgrade might
    remove support for resource versions, and if you have unsupported resources deployed,
    you will encounter catastrophic failures. Using Managed Kubernetes has its pros
    and cons. When it comes to upgrades, there is, at any point in time, a range of
    supported versions.
  prefs: []
  type: TYPE_NORMAL
- en: You may upgrade to more recent supported versions. However, if you delay and
    neglect to upgrade, then the cloud provider will upgrade your clusters and node
    pools automatically once you fall behind the cutting edge of supported versions.
    Let’s look at the various elements of upgrading Kubernetes you must be on top
    of.
  prefs: []
  type: TYPE_NORMAL
- en: Know the lifecycle of your cloud provider
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Cloud providers can’t support just any Kubernetes version in existence. It
    is critical to know when the current version of your clusters and node pools is
    going to be defunct. All cloud providers have a methodical process and share the
    information broadly. Here are the locations for each of the three major cloud
    providers:'
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS EKS: [https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html](https://docs.aws.amazon.com/eks/latest/userguide/kubernetes-versions.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Azure AKS: [https://learn.microsoft.com/en-us/azure/aks/supported-kubernetes-versions](https://learn.microsoft.com/en-us/azure/aks/supported-kubernetes-versions)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Google GKE: [https://cloud.google.com/kubernetes-engine/docs/release-schedule](https://cloud.google.com/kubernetes-engine/docs/release-schedule)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For example, AKS, at the time of writing, supports versions 1.23 through 1.26\.
    In addition, each version has an official end-of-life date. For example, the end-of-life
    date for 1.23 is April 2023\. If your cluster is still on 1.23, then AKS may upgrade
    your cluster automatically to version 1.24\. The process of cloud provider upgrade
    is gradual, done region by region, and might take several weeks.
  prefs: []
  type: TYPE_NORMAL
- en: All cloud providers offer an API and CLI to check the exact list of versions
    (including patch versions) in every region.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, at the moment, these are versions supported on AKS for the Central
    US region:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, for each minor version, there are several patch versions. It
    is even nice enough to mention which versions you may upgrade to yourself. Due
    to security concerns, the cloud provider may drop support for patch versions at
    any time.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s talk about the upgrade process of the control plane.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading clusters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'When using Managed Kubernetes in the cloud, you are not responsible for the
    operation of the control plane, but you still need to manage the upgrade process.
    You have two options:'
  prefs: []
  type: TYPE_NORMAL
- en: Auto upgrade
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Manual upgrade
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In an auto upgrade, the cloud provider will update your cluster according to
    their schedule, but you still must ensure that the versions of resources in your
    cluster are compatible with the new version. A manual upgrade requires you to
    upgrade yourself but gives you more control over timing. For example, you may
    choose to update earlier to benefit from some new features.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that a manual upgrade doesn’t mean you can stay on the same Kubernetes
    version forever. The cloud provider will forcefully upgrade you if you fall behind
    the minimal supported version.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes releases a new version roughly every 3 months. Cloud providers support
    roughly 4 versions. This means that if you just upgraded to the latest supported
    version, you may hold off for about a year on upgrades, but then you will be on
    the minimal supported version, which means you will now have to upgrade every
    3 months.
  prefs: []
  type: TYPE_NORMAL
- en: Note that you should upgrade the control plane one minor version at a time.
    If you are on version 1.24, and you want to upgrade to 1.26, you have to upgrade
    to 1.25 first and then from 1.25 to 1.26.
  prefs: []
  type: TYPE_NORMAL
- en: The bottom line is that upgrading the Kubernetes control plane is a standard
    operation that takes place multiple times per year. You should have a streamlined
    process for it.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at what is involved.
  prefs: []
  type: TYPE_NORMAL
- en: Planning an upgrade
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You should plan your upgrades and coordinate them with cluster users. Control
    plane upgrades typically take 20-45 minutes. This is a non-disruptive operation
    for your workloads. Your workloads will keep running, and new pods will be scheduled
    to existing nodes. However, node pool operations might be blocked during the control
    plane upgrade.
  prefs: []
  type: TYPE_NORMAL
- en: If you’re running multiple clusters with a redundancy scheme, it is best to
    perform the upgrades gradually and start with non-critical clusters (e.g., a development
    or staging environment).
  prefs: []
  type: TYPE_NORMAL
- en: I recommend having owners (engineers or teams) for every namespace. Notify all
    owners about upcoming upgrades so they can reserve time for converting incompatible
    resources.
  prefs: []
  type: TYPE_NORMAL
- en: Detecting incompatible resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The main concern with an upgrade is that the functionality of your system will
    be compromised or completely broken because it uses resources that are not supported
    anymore. In most cases, a specific version of a resource will be removed, and
    a newer version will be available.
  prefs: []
  type: TYPE_NORMAL
- en: But you don’t have to wait until the last minute to scramble and replace removed
    resources or versions. Kubernetes has a deprecation policy and resources will
    be deprecated for several versions before they are fully removed. I suggest making
    sure before each upgrade that all deprecated resources are updated or replaced.
    This will ensure that the upgrade process is not stressful because, even if you
    didn’t manage to update all resources, the deprecated resources are still going
    to be supported by the new version and you will have some extra time to update
    them before they are fully removed.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes publishes a migration guide with details about deprecated and removed
    APIs in each version. See [https://kubernetes.io/docs/reference/using-api/deprecation-guide](https://kubernetes.io/docs/reference/using-api/deprecation-guide).
  prefs: []
  type: TYPE_NORMAL
- en: For example, Kubernetes 1.25 stopped serving the `CronJob` resource with the
    API version of `batch/v1beta1`. Instead, the `batch/v1` `CronJob` resource has
    been available since Kubernetes 1.21\. Ideally, after you upgrade to Kubernetes
    1.21, you have updated all your `CronJob` resources to use `batch/v1`, and by
    the time you upgrade to Kubernetes 1.25, the fact that `batch/v1beta1` is removed
    is not an issue because you are already on the supported version.
  prefs: []
  type: TYPE_NORMAL
- en: There are several ways to make sure you detect all deprecated and/or removed
    resources that you currently use. You can use the manual method of reading the
    deprecation guide and just scanning your code and detecting incompatible resources.
    Most releases don’t have a lot of deprecations or removals. However, some releases
    may have up to ten different resources that are being deprecated or removed. For
    example, Kubernetes 1.25 stopped serving seven different resource versions.
  prefs: []
  type: TYPE_NORMAL
- en: A more systematic way is to use a tool like `kube-no-trouble` ([https://github.com/doitintl/kube-no-trouble](https://github.com/doitintl/kube-no-trouble)),
    which scans your clusters and can output a list of deprecated resources.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is how to install it:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: 'I have a 1.25 cluster that doesn’t contain any deprecated resources at the
    moment. However, in Kubernetes 1.26, the **HorizontalPodAutoscaler** of version
    autoscaling/v2beta2 will be removed as it has been deprecated since Kubernetes
    1.23\. Let’s create such a resource. There is a `kyverno` deployment in the cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'Here is an HPA that sets the min replicas to 1 and the max replicas to 3:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, kubectl gives a very nice warning when you create a deprecated
    resource version that tells when the resource was deprecated (1.23), when it will
    be removed (1.26), and which version to replace it with (autoscaling/v2).
  prefs: []
  type: TYPE_NORMAL
- en: This is nice, but it is not sufficient. You probably create your resources through
    CI/CD, which might not receive the same warning, and even if it does, might not
    surface it, because it is not an error. However, if you created the HPA when your
    cluster was on an earlier version of Kubernetes than 1.23, then you wouldn’t get
    any warning because at the time it wasn’t deprecated.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see if kubent can detect the deprecated HPA:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'Yes, it does. You get the same information: when it will be removed, when it
    was deprecated, and what to replace it with.'
  prefs: []
  type: TYPE_NORMAL
- en: Updating incompatible resources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Updating an incompatible resource may require some changes to your manifests.
    If the API change just adds new fields, then you may just change the API version
    and be done with it. However, sometimes it may require additional changes.
  prefs: []
  type: TYPE_NORMAL
- en: 'OK. We’re about to upgrade our cluster, and we detected some incompatible resources.
    Kubectl and the kubectl-convert plugin can help here. Follow the instructions
    here to install the plugin: [https://kubernetes.io/docs/tasks/tools/#kubectl](https://kubernetes.io/docs/tasks/tools/#kubectl).
    Let’s convert our HPA manifest and see what it looks like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'The conversion succeeded but created a few unnecessary fields. The `creationTimestamp:
    null` is useless as it will be updated on a live resource. Also, the status is
    useless as this is just a manifest file, and the status will be updated at runtime.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the main differences are that `apiVersion` was changed to `apiVersion:
    autoscaling/v1` and that the target CPU percentage is now specified as a single
    field:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: Using kubectl-convert saves time, and it is a well-tested tool.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with removed features
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There is one other situation we need to address, which is the complete removal
    of a feature without an upgrade path. Kubernetes 1.25 completely removed support
    for **Pod Security Policies** (**PSPS**). The application of PSPs to pods has
    caused confusion for many users who have attempted to utilize them. Check this
    link for more details: [https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/](https://kubernetes.io/blog/2021/04/06/podsecuritypolicy-deprecation-past-present-and-future/).'
  prefs: []
  type: TYPE_NORMAL
- en: 'If you used PSPs, then when the time comes to upgrade to Kubernetes 1.25, your
    PSPs will no longer work. The Kubernetes developers didn’t just remove the feature
    with no alternative. There are two alternatives to PSPs:'
  prefs: []
  type: TYPE_NORMAL
- en: Pod security admission
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A third-party admission controller
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The pod security admin is a simplified solution that may or may not be a complete
    replacement for PSPs. The Kubernetes developers published a detailed guide for
    migration. Check it out: [https://kubernetes.io/docs/tasks/configure-pod-container/migrate-from-psp/](https://kubernetes.io/docs/tasks/configure-pod-container/migrate-from-psp/).'
  prefs: []
  type: TYPE_NORMAL
- en: If you choose a third party (e.g., Kyverno), then you should check its documentation.
    Kyverno comes with a lot of sample policies for pod security and the transition
    is pretty straightforward.
  prefs: []
  type: TYPE_NORMAL
- en: Upgrading node pools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Upgrading the node pools of multiple clusters can be a major undertaking. If
    you have tens to hundreds of clusters and in each cluster, you have multiple node
    pools (5-20 is not uncommon), then be ready for a serious adventure. Control plane
    upgrades (once you have ensured your workloads are compatible with the new version)
    are pretty quick and painless. Node pool upgrades are very difficult. Realistically,
    it can take several weeks to upgrade all the node pools in a large Kubernetes-based
    system with tens to hundreds of node pools with thousands of nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Syncing with control plane upgrades
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Kubernetes imposes constraints on the versions of the control plane and the
    worker nodes. The Kubernetes node components may be two minor versions behind
    the control plane. If the control plane is on version N, then the node pools may
    be on version N-2\. Since node pool upgrades are much more disruptive and labor-intensive
    than control plane upgrades, I recommend upgrading node pools only to every other
    version of Kubernetes. For example, suppose we start with a Kubernetes cluster
    where both the control plane and the nodes are on version 1.24\. When we upgrade
    to version 1.25, we upgrade only the control plane to 1.25 and keep the node pools
    on 1.24, which is compatible. Then, when it’s time to upgrade to 1.26, we upgrade
    the control plane first from 1.25 to 1.26, and then we start upgrading all the
    node pools from 1.24 directly to 1.26\. Let’s see how to go about upgrading node
    pools.
  prefs: []
  type: TYPE_NORMAL
- en: How to perform node pool upgrades
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Node pool upgrades require a new node pool. It is not possible to upgrade nodes
    within the node pool. It is not even possible to add new nodes with a new version
    to an existing node pool. The node version is one of the essential properties
    of a node pool. What it means is that you actually don’t upgrade an existing node
    pool. You replace your node pool. First, you create a new node pool, scale it
    up, and start draining nodes from the old node pool until all the pods run on
    the new node pool and then you can delete the old (now empty) node pool.
  prefs: []
  type: TYPE_NORMAL
- en: 'If your original node pool was an autoscaling node pool, then before starting
    the upgrade process, you must turn off autoscaling; otherwise, the pods you evicted
    from a node in the old node pool might get scheduled right back to the old node
    pool. Let’s list the exact steps you need to take to upgrade a node pool:'
  prefs: []
  type: TYPE_NORMAL
- en: Create a new node pool with the exact same specifications (instance type, labels,
    tolerations) as the existing node with the new version.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You may pre-allocate some instances to the new pool, so they are ready to schedule
    pods from the old node pool.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Turn autoscaling off in the old node pool.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cordon all the nodes in the old node pool to prevent the scheduling of new pods
    to the old pool.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drain the nodes of the old node pool.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Observe and deal with problems.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wait for the cluster autoscaler to delete empty old pool nodes or delete them
    yourself to expedite the process.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s look at some problems that can delay or even hold up the upgrade process.
  prefs: []
  type: TYPE_NORMAL
- en: Concurrent draining
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: If you need to upgrade many node pools with lots of nodes in each, you may decide
    to provision new node pools and start draining all your node pools at once or
    in large batches. This can cause you to exceed your quota or hit cloud provider
    capacity issues.
  prefs: []
  type: TYPE_NORMAL
- en: You should pay attention to your quota and ensure you have a sufficient quota
    regardless of upgrades. If you’re getting close to your quota ceiling, I suggest
    bumping it before engaging in a complex operation like a node pool upgrade. The
    last thing you want is to be in the middle of an upgrade when you need to scale
    your capacity due to business needs and realize you maxed out your quota.
  prefs: []
  type: TYPE_NORMAL
- en: A good strategy for handling capacity issues and ramping up speed (how fast
    the cloud provider provision can instances for your new nodes) is to pre-allocate
    those instances. Again, this requires that you have a sufficient quota for the
    old node pool and the new node pool at the same time.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s understand what happens if you don’t pre-allocate nodes in the new node
    pool. When you drain a node from the old node pool, all the pods are evicted from
    the node and become pending pods. Kubernetes will try to schedule these pods to
    existing nodes if any are available. The old node pool is cordoned, so either
    Kubernetes can find suitable nodes on other existing node pools (it’s a good thing
    that improves bin packing) or the cluster autoscaler will need to provision a
    new node. That takes several minutes. If you drain multiple nodes at the same
    time, then all the pods from these nodes will be pending for a few minutes until
    new nodes can be provisioned and your system’s capacity is degraded. In addition,
    if the cloud provider has capacity issues, maybe it can’t provision new nodes
    and your pods will remain pending until then.
  prefs: []
  type: TYPE_NORMAL
- en: Pre-allocating nodes means that the new node pool will have nodes ready to go.
    The moment a pod is evicted from the old node pool, it will immediately be scheduled
    to an available node in the new node pool.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with workloads with no PDB
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When draining a node, Kubernetes is mindful of **pod disruption budgets** (**PDBs**).
    If a deployment has a PDB that says only one pod can be unavailable and there
    are two pods of this deployment on the drained node, then Kubernetes will evict
    just one pod and wait until it is eventually scheduled before evicting the other
    pod. However, if you have workloads without PDBs, then that means Kubernetes is
    allowed to evict all the pods of those workloads at the same time. For most workloads,
    this is unacceptable. You should identify these workloads and work with their
    owner to add a PDB. Note that in the scenario of draining all nodes at once, workloads
    with no PDB are vulnerable even if they have many pods running on different nodes.
  prefs: []
  type: TYPE_NORMAL
- en: Dealing with workloads with PDB zero
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: However, the opposite problem of unevictable pods is the bane of node pool upgrades.
    If a node contains an unevictable pod, then it can’t be drained, and Kubernetes
    will wait forever (or until the pod is manually deleted) before it fully drains
    the node. This can halt the upgrade process indefinitely and typically requires
    coordinating with the workload owner to resolve it.
  prefs: []
  type: TYPE_NORMAL
- en: 'If a workload has a PDB with `minUnavailable: 0`, it means that Kubernetes
    is not allowed to evict even a single pod from the workload regardless of how
    many replicas the workload has.'
  prefs: []
  type: TYPE_NORMAL
- en: Some workloads (usually stateful) are more sensitive than others and prefer
    not to be disrupted at all. This is, of course, an unrealistic expectation because
    the node itself might go bad or the underlying VM might disappear due to cloud
    provider issues, and then the pods scheduled on it will have to be evicted. It’s
    best to work with workload owners and come up with a solution that minimizes disruption,
    but still allows upgrades to progress. This has to be worked out before the upgrade
    process starts. You don’t want to be in a situation where a single workload holds
    a node pool upgrade process hostage, and you have to beg the workload owner to
    allow you to evict a pod.
  prefs: []
  type: TYPE_NORMAL
- en: 'But, in addition to strict PDB-zero workloads, you might run into effective
    PDB-zero situations. Consider a workload with a PDB of `minUnavailable: 1`. This
    is pretty common and means the workload allows one pod at a time to be unavailable.
    When draining the pods of this workload, Kubernetes is allowed to evict one pod
    as long as all the other pods are running. However, if even one of the pods of
    this workload is pending or unable to be ready due to any reason, then effectively
    the workload already has one pod unavailable, and the upgrade process will be
    halted again.'
  prefs: []
  type: TYPE_NORMAL
- en: The best practice here is to identify these workloads before the upgrade process
    starts and ensure that all workloads are healthy and can participate in the node
    pool upgrade process.
  prefs: []
  type: TYPE_NORMAL
- en: However, even if you did all the preparation work ahead of time, some workloads
    might get into an unhealthy state during the upgrade process (remember we’re talking
    about a process that can take weeks).
  prefs: []
  type: TYPE_NORMAL
- en: I recommend having strong monitoring of the progress of the upgrade process,
    detecting stuck pods, and working with owners to resolve issues. In the case of
    pods that are scheduled on the old node pool and can’t be ready, it is a simple
    solution to just delete the pod, see it is scheduled to the new node pool, and
    let the workload owner resolve the problem on the new node pool.
  prefs: []
  type: TYPE_NORMAL
- en: Other cases might require more creative solutions.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s turn our attention to various problems that can occur in a cluster and
    how to handle them, especially at scale.
  prefs: []
  type: TYPE_NORMAL
- en: Troubleshooting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this section, we will cover the troubleshooting process in a production cluster
    and the logical procession of actions to take. The pod lifecycle involves multiple
    phases and failures can occur at each phase. In addition, pod containers go through
    their own mini lifecycle where init containers are running to completion and then
    the main containers start running. Let’s see what can go wrong along the way and
    how to handle it.
  prefs: []
  type: TYPE_NORMAL
- en: First, let’s look at pending pods.
  prefs: []
  type: TYPE_NORMAL
- en: Handling pending pods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When a new pod was created, Kubernetes used to place it in the Pending state
    and try to find a node to schedule it on. However, since Kubernetes 1.26, there
    is an even earlier state where a pod can’t be scheduled.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s create a new 1.26 kind cluster called “`trouble`" and enable the pod
    scheduling readiness feature. Here is the configuration file (`cluster-config.yaml`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'And here is how to create the kind cluster:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Next, we’ll create a new namespace called `trouble` and take it from there.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s create a pod with a scheduling gate called `no-scheduling-yet`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: As you can see, the pod has a status of `SchedulingGated`.
  prefs: []
  type: TYPE_NORMAL
- en: The benefit of the scheduling gate is that if the pod can’t be scheduled yet
    due to issues like the quota, which need to be resolved externally, then the pod
    in this state will not cause a lot of churns to the Kubernetes scheduler, which
    will ignore it. After the external issue is resolved, you (or more likely an operator)
    can remove the feature gate and the pod will become a pending pod ready to be
    scheduled.
  prefs: []
  type: TYPE_NORMAL
- en: Now, let’s turn our attention to pending pods. It’s okay for a pod to be pending;
    however, if a pod is pending for more than a few minutes, something is wrong and
    we need to investigate it. I suggest having an alert set up for pods pending for
    more than X minutes (reasonable values for X can be between 10 and 60 minutes).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two types of pending pods: temporarily pending pods and permanent
    pending pods. Temporarily pending pods may be scheduled to one of the existing
    node pools; however, there is currently no room on any of the nodes. If the node
    pool has autoscaling enabled, the cluster autoscaler will try to provision a new
    node. If the node pool has autoscaling disabled, then the pod will remain pending
    until some other pods complete or are evicted from a node to make room. Another
    category of temporarily unschedulable pods is if the target namespace has a resource
    quota that is maxed out at the moment. Here is an example, where the namespace
    has a resource quota of 1 CPU and a deployment with 3 replicas is created where
    each pod requests 0.5 CPU. Only 2 pods can fit with the namespace quota. The third
    pod will be pending:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'Now, let’s create the deployment and see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'We end up with just two running pods as expected:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Note, that there is no third pending pod in this case. Kubernetes is smart enough
    to create only two pods in this case.
  prefs: []
  type: TYPE_NORMAL
- en: 'The reason is the namespace quota:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Permanent pending pods are pods that can’t be scheduled on any of the available
    node pools, so provisioning a new node will not help. There are several categories
    of such permanently unschedulable pods:'
  prefs: []
  type: TYPE_NORMAL
- en: All the node pools have taints, and the pod doesn’t have the proper tolerations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The pod requests more resources than are available on any of the node pools.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The pod is waiting for a persistent volume.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The pod has incorrect `nodeSelector` or `nodeAffinity`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Let’s delete the previous deployment and resource quota and look at an example
    of a pod that just requests way too many resources (666 CPU cores):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'If we look at the pod that was created now, we can see it is indeed pending:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'To understand why it is pending, we can look at the status of the pod:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: The message is pretty clear and explains that 0 out of 1 node is available to
    schedule. It even says that 1 node has insufficient CPU. If there were other nodes
    in the cluster with other reasons, it would list them too.
  prefs: []
  type: TYPE_NORMAL
- en: Pending pods don’t use resources and don’t take up space in nodes; however,
    they put some pressure on the API server and also it means that some workloads
    don’t get to do their work and they are waiting for a node to be scheduled on,
    which might be very serious in production. Mind your pending pods and make sure
    to resolve any issues quickly.
  prefs: []
  type: TYPE_NORMAL
- en: The next category of problems is about pods that are scheduled to a node but
    are unable to run.
  prefs: []
  type: TYPE_NORMAL
- en: Handling scheduled pods that are not running
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'There may be several reasons why a scheduled pod is not running. One of the
    most common ones is failure to pull an image required by one of the pod’s containers.
    The kubelet will just keep trying and the pod’s status will show as `ErrImagePull`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s check the pods:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'To see a more elaborate message, we can check the `containerStatuses` field
    of the status:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: Image pull errors could relate to a misconfigured image. The image name or the
    image tag might be wrong. However, the image may be correct but might have been
    deleted accidentally from the registry. If you try to pull from a private registry,
    then possibly you don’t have the correct permissions. Finally, the image registry
    may be unavailable. For example, Docker Hub often has rate limits.
  prefs: []
  type: TYPE_NORMAL
- en: You may prefer to pull all your images from a single source you control, where
    you can scan and curate the images and ensure that images don’t disappear from
    you. If you’re on the cloud, then every cloud provider offers their image registry.
    This should be the preferred option in most cases. You may save some money by
    using a private registry, and you may prefer a different solution in hybrid cloud
    scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another reason that a pod doesn’t start running is an init container that doesn’t
    complete:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: 'Checking the pod status, we can see that it is stuck in the init phase because
    our init container is in the pause container, which never completes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'Sometimes the pod starts running, but the container keeps failing. In this
    case, you need to check your pod’s logs or your Dockerfile for the reason. Here
    is a pod that keeps crashing because its Dockerfile command just exists with exit
    code 1:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'The result is that the pod will have a status of `RunContainerError`. Kubernetes
    will keep restarting the pod (assuming the default restart policy of always):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: Getting your pods and containers to a running state is a good start, but it
    is not enough. In order for Kubernetes to send requests to your pods, all the
    containers must be ready. Let’s see what problems you might run into.
  prefs: []
  type: TYPE_NORMAL
- en: Handling running pods that are not ready
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If all your init containers are completed and all your main containers are running
    with no errors, then probes come into play. Kubernetes considers a pod with running
    containers ready to receive requests if no probes are defined or if all probes
    for all containers succeed. The startup probe is checked initially until it succeeds.
    If it fails, the pod is not considered ready. If your container has a hung startup
    pod, it will never be ready.
  prefs: []
  type: TYPE_NORMAL
- en: Kubernetes will eventually kill and restart your container and the startup probe
    will have another chance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is a deployment where the main container has a startup probe that will
    always fail (the pause container doesn’t even listen on port 80). The pod will
    never get to the ready state. After some retries and delays defined by the startup
    probe, Kubernetes will restart the container and the cycle will repeat:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'Checking the pod shows that the pod is in `CrashloopBackoff` and Kubernetes
    keeps restarting the container:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: Note that the delay between restarts grows exponentially to avoid a bad container
    putting a lot of stress on the API server and the kubelet having to keep restarting
    often.
  prefs: []
  type: TYPE_NORMAL
- en: If there is no startup probe or it succeeds, the hurdle is the readiness probe.
    It works very similar to a startup probe, except Kubernetes will not restart the
    container. It will just keep checking the readiness probe. When a readiness probe
    fails, the pod will be removed from the endpoints list of any service that matches
    its labels, so it doesn’t get to handle any requests. However, the pod remains
    alive and consumes resources on the node.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s see it in action:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'As you can see, the pod is running for an hour, it never gets ready, and it
    is not restarted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: The last type of probe is the liveness probe. It works just like the startup
    probe (the container will get restarted and the pod will be in `CrashloopBackoff`),
    except it is checked periodically, even if it succeeds while the startup probe
    is a one-time deal. Once it succeeds, it is never checked again.
  prefs: []
  type: TYPE_NORMAL
- en: The reason both startup and liveness probes are needed is that some containers
    need a longer startup period, but once they are initialized, then periodic liveness
    checks should be shorter.
  prefs: []
  type: TYPE_NORMAL
- en: That covers troubleshooting the pod lifecycle. When pods are scheduled but are
    not running or are not ready, it has cost implications. Let’s move on and consider
    cost management.
  prefs: []
  type: TYPE_NORMAL
- en: Cost management
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'When running Kubernetes at a large scale in the cloud, one of the major concerns
    is the cost of the infrastructure. Cloud providers offer a variety of infrastructure
    options and services for your Kubernetes clusters. These are expensive. To harness
    your costs, make sure you follow best practices such as:'
  prefs: []
  type: TYPE_NORMAL
- en: Having a cost mindset
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cost observability
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The smart selection of resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Efficient usage of resources
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Discounts, reserved instances, and spot instances
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Invest in local environments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s review them one by one.
  prefs: []
  type: TYPE_NORMAL
- en: Cost mindset
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Engineers often neglect cost or put it way down the priority list. I often
    think in this order: make it work, make it fast, make it last, make it secure,
    and only then make it cheap. This is not necessarily a bad thing, especially for
    startup companies or new projects. Growth and velocity are often the top priorities.
    After all, if you don’t have a good product, and you don’t have customers, then
    the business will fail even if your costs are zero.'
  prefs: []
  type: TYPE_NORMAL
- en: In addition, when the system is small, the absolute cost might be relatively
    small even if there is a lot of waste. Add to that the fact that cloud providers
    lure companies in with generous credits.
  prefs: []
  type: TYPE_NORMAL
- en: However, if you are part of a large enterprise or your startup succeeds and
    grows, at some point, cost will become a significant concern. At this point, you
    need to shift your thinking and have cost as the primary concern for everything
    you do. Cost may or may not be aligned with other initiatives. For example, everybody
    loves Pareto improvements. If you just manage to use 20% fewer VMs to accomplish
    the same task, then you will automatically save a lot of money without negatively
    impacting any other aspect.
  prefs: []
  type: TYPE_NORMAL
- en: But those easy wins and low-hanging fruit will eventually dry up. Then, you
    get to harder decisions. For example, caching the last week of data in memory
    will give you excellent response times, but at a large cost. What if you just
    cache one day?
  prefs: []
  type: TYPE_NORMAL
- en: Availability and redundancy are often at odds with cost as well. Do you really
    need a full-fledged zero-downtime active-active setup across multiple availability
    zones, regions, and cloud providers or can you get by with some downtime and recovery
    from backups in the event of catastrophic failure?
  prefs: []
  type: TYPE_NORMAL
- en: You may end up choosing the more expensive option, but you should do it with
    an explicit understanding of how much you pay for it and ensure the value you
    receive is greater.
  prefs: []
  type: TYPE_NORMAL
- en: That takes us to the next topic of cost observability.
  prefs: []
  type: TYPE_NORMAL
- en: Cost observability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To manage your infrastructure cost on Kubernetes and in the cloud in general,
    you must have strong cost-oriented observability. Let’s look at some of the ways
    to accomplish it.
  prefs: []
  type: TYPE_NORMAL
- en: Tagging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Tagging is associating every resource with a set of tags or labels. From a cost
    perspective, tags should enable you to attribute the cost of any infrastructure
    resource to the relevant stakeholders. For example, you may have a team tag or
    an owner tag. If the resources provisioned by a specific team suddenly grow rapidly,
    you can narrow down the issue more quickly. The specific tags are up to you. Common
    tags may include environment (production, staging, and development), release,
    and git sha. Many resources in the cloud come with cloud-provider tags that you
    can take advantage of.
  prefs: []
  type: TYPE_NORMAL
- en: Policies and budgets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Policies and budgets let you rein in wild spending on infrastructure. Some
    policies are implicit, such as a namespace resource quota that will block the
    provisioning of excess resources. However, other policies may be more cost-specific
    and be informed by cost tracking. Budgets let you set a hard limit on spending
    at different scopes. All cloud providers offer budgets as part of their cost management
    solutions:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Tutorial: Create and manage Azure budgets: [https://learn.microsoft.com/en-us/azure/cost-management-billing/costs/tutorial-acm-create-budgets](https://learn.microsoft.com/en-us/azure/cost-management-billing/costs/tutorial-acm-create-budgets)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Managing your costs with AWS Budgets: [https://docs.aws.amazon.com/cost-management/latest/userguide/budgets-managing-costs.html](https://docs.aws.amazon.com/cost-management/latest/userguide/budgets-managing-costs.html)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Create, edit, or delete budgets and budget alerts in GCP: [https://cloud.google.com/billing/docs/how-to/budgets](https://cloud.google.com/billing/docs/how-to/budgets)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Policies and budgets are great, but sometimes they are not sufficient, or you
    don’t have the cycles to specify and update them. This is where alerting comes
    into play.
  prefs: []
  type: TYPE_NORMAL
- en: Alerting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Budgets are often the last resort to mitigate against rogue infrastructure provisioning
    or accidental runaway provisioning. For example, you may set broad budgets for
    several overall categories, like no more than $500,000 of compute spending. These
    budgets of course need to align with business growth and make sure that they don’t
    cause an incident if you temporarily need to provision more infrastructure to
    handle a temporary spike in demand. Budgets are often set or modified only with
    top management approval.
  prefs: []
  type: TYPE_NORMAL
- en: Fine-grained and day-to-day cost management alerts are much more nimble and
    practical. If you cross or come close to some cost limit, you can set alerts that
    will let you know and escalate as necessary. The alerts rely on proper tagging,
    so you can have meaningful information to evaluate the cause of the cost increase
    and the responsible party.
  prefs: []
  type: TYPE_NORMAL
- en: As you can see, managing costs is a dynamic and complex activity. You need good
    tools to help you.
  prefs: []
  type: TYPE_NORMAL
- en: Tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'All the cloud providers have strong cost management tools. Check out:'
  prefs: []
  type: TYPE_NORMAL
- en: 'AWS Cost Explorer: [https://aws.amazon.com/aws-cost-management/aws-cost-explorer/](https://aws.amazon.com/aws-cost-management/aws-cost-explorer/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Azure Cost Analyzer: [https://www.serverless360.com/azure-cost-analysis](https://www.serverless360.com/azure-cost-analysis)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'GCP Cost Management: [https://cloud.google.com/cost-management/](https://cloud.google.com/cost-management/)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: In addition, you may opt to use a multi-cloud open-source tool like kubecost
    ([https://www.kubecost.com](https://www.kubecost.com)) or a paid product like
    cast.ai ([https://cast.ai](https://cast.ai)). Of course, you can do everything
    yourself, ingest cost metrics from the cloud provider into Prometheus, and build
    your Grafana dashboards and alerts on top of them.
  prefs: []
  type: TYPE_NORMAL
- en: Remember that picking the right set of tools can literally pay for itself very
    quickly.
  prefs: []
  type: TYPE_NORMAL
- en: The smart selection of resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The cloud offers a plethora of choices and combinations for resources like VMs,
    networking, and disks. We covered all the considerations in the *Bin packing and
    utilization* section earlier in this chapter. However, with a focus on cost, you
    should ensure that you understand that you may be able to get the job done with
    a cheaper alternative and reduce your costs significantly. Familiarize yourself
    with the inventory of resources and stay up to date as cloud providers update
    their offerings and may change prices too.
  prefs: []
  type: TYPE_NORMAL
- en: Efficient usage of resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When you’re cutting costs, any unused resources are a red flag. You leave money
    on the table. It is often necessary to build in flexibility. For example, the
    industry average CPU utilization is in the range of 40%-60%. This might seem low,
    but it is not easy to improve on that in a very dynamic environment with constraints
    like high availability, quick recovery, and the ability to scale up quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Discounts, reserved instances, and spot instances
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: One of the best ways to reduce costs is to just pay less money to the cloud
    providers for the same resources. The common ways to accomplish this are discounts,
    reserved instances, and spot instances.
  prefs: []
  type: TYPE_NORMAL
- en: Discounts and credits
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Discounts are the best. They only have an upside. You simply pay less than the
    sticker price. That’s it. Well, it’s not that easy. You will need to negotiate
    to get the best prices and often show promise for growth and commitment to stay
    longer on the platform.
  prefs: []
  type: TYPE_NORMAL
- en: Credits are another great way to offset initial cloud spending. All the major
    cloud providers offer various credit programs, and you may be able to negotiate
    more credits too.
  prefs: []
  type: TYPE_NORMAL
- en: AWS has the Activate program, targeted mostly at startups, where you can get
    up to $100,000 of AWS credit. See [https://aws.amazon.com/activate/](https://aws.amazon.com/activate/).
  prefs: []
  type: TYPE_NORMAL
- en: Azure has the Microsoft for Startups program, which offers up to $150,000 of
    Azure credit. See [https://www.microsoft.com/en-us/startups](https://www.microsoft.com/en-us/startups).
  prefs: []
  type: TYPE_NORMAL
- en: GCP has the Google for Startups cloud program, which offers (like AWS) up to
    $100,000 of GCP credit. See [https://cloud.google.com/startup](https://cloud.google.com/startup).
  prefs: []
  type: TYPE_NORMAL
- en: These programs are designed to boost young startups without a lot of revenue.
    Let’s move on to options for established enterprise organizations that still want
    to reduce their cloud spending.
  prefs: []
  type: TYPE_NORMAL
- en: Reserved instances
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Reserved instances are a very good way to reduce your costs. They require that
    you purchase capacity in bulk and commit for a long period (one year or three
    years). The longer period carries better discounts. Overall, the discounts are
    significant and can vary from 30% to 75% compared to on-demand prices.
  prefs: []
  type: TYPE_NORMAL
- en: Beyond the price, reserved instances also ensure capacity compared to on-demand
    instances, which may temporarily be unavailable for particular instance types
    in a particular availability zone.
  prefs: []
  type: TYPE_NORMAL
- en: The downsides of reserved instances are that you typically have to prepay, and
    the commitment is often tied to specific instance types and regions. You may be
    able to exchange equivalent reservations, but you’ll have to check the terms and
    conditions of the cloud provider. Also, if you are unable to use all your reserved
    capacity, you still pay for it (although at a very discounted price).
  prefs: []
  type: TYPE_NORMAL
- en: If you consider reserved instances (RIs), you may opt for a limited capacity
    of reserved instances, which you know you can always utilize, and then use on-demand
    and spot instances to handle spikes and take advantage of the elasticity of the
    cloud. If you discover later that you spend too much on on-demand, you can always
    reserve more instances and come up with a mix of three-year reserved instances,
    one-year reserved instances, on-demand, and spot instances. This is a great segue
    to the next item on the list, which is spot instances.
  prefs: []
  type: TYPE_NORMAL
- en: Spot instances
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cloud providers love reserved instances. They sell them, provision them, make
    their profit, and can forget about them (except for making sure they’re up and
    running). The on-demand side is very different. Cloud providers have to make sure
    they can reasonably provision more capacity when their customers demand it. In
    particular, cloud providers should roughly have enough capacity to handle the
    quota of each customer even if the customer significantly underutilizes their
    quota. That means that, in practice, under normal conditions, cloud providers
    have a lot of idle or underutilized capacity. This is where spot instances come
    in. Cloud providers can sell this excess capacity, which is in theory allocated
    for on-demand use. If it is needed, then the cloud provider just takes away the
    spot instances and provides them to the on-demand customers.
  prefs: []
  type: TYPE_NORMAL
- en: Why should you use spot instances? Well, because they are much cheaper. Due
    to their potentially ephemeral nature, they carry significant discounts of up
    to 90%. Remember, from the cloud provider’s point of view, this is free money.
    Those instances are already accounted for and paid for by the markup of on-demand
    instances in use and the quota ratio of each customer.
  prefs: []
  type: TYPE_NORMAL
- en: In practice, spot instances don’t disappear from under you very quickly. The
    Kubernetes way advocates that workloads shouldn’t care too much about specific
    nodes. If you run on a spot instance and it goes away, all your pods will be evicted
    and scheduled to other nodes. If you have sensitive workloads that don’t handle
    eviction from their node well, then these workloads are not good Kubernetes citizens
    in the first place. Nodes become unhealthy all the time, regardless, and your
    workloads should be able to handle eviction.
  prefs: []
  type: TYPE_NORMAL
- en: However, there is one situation that needs to be addressed, specifically if
    you run critical workloads on spot instances. In case of a zonal outage of a specific
    instance type, it is possible that many spot instances will be taken by the cloud
    provider. I suggest having empty fallback on-demand node pools with the same or
    similar instance type and the same labels and taints. If a node pool using spot
    instances suddenly loses a lot of nodes and is unable to scale up (because the
    spot instances are unavailable), then you can scale up your empty on-demand node
    pool and your pods will be scheduled there until spot instances become available
    again.
  prefs: []
  type: TYPE_NORMAL
- en: Make sure you have enough quota for the fallback node pools to pick up the slack
    if the equivalent spot instances are unavailable.
  prefs: []
  type: TYPE_NORMAL
- en: Next, let’s talk about local environments and how they can help us save money.
  prefs: []
  type: TYPE_NORMAL
- en: Invest in local environments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Organizations practice different protocols of development and testing. Some
    organizations do a lot of testing in the cloud in staging and development environments.
    Sometimes, engineers provision infrastructure for various experiments and tests.
    Such development and test environments can be difficult to manage effectively
    as infrastructure is often provisioned in an ad hoc manner. There are solutions
    like disposable Kubernetes clusters and virtual clusters. Another direction is
    to invest in local development environments that engineers can run on their local
    machines. The advantages are that these environments are often very quick to set
    up and discard, and they don’t incur any expensive cloud costs. The downside is
    that such environments might not be fully representative of the staging or production
    environments. I suggest looking into local environments and finding use cases
    that will save cloud costs without compromising other critical aspects of the
    system.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we covered in depth what it takes to run large-scale Managed
    Kubernetes systems in production. We looked at managing multiple clusters, building
    effective processes, handling infrastructure at scale, managing clusters and node
    pools, bin packing and utilization, upgrading Kubernetes, and troubleshooting
    and cost management. That’s a lot, but even that is just the tip of the iceberg.
    There is no substitute for in-depth familiarity with your use cases and special
    concerns. The bottom line is that large-scale enterprise systems are complex to
    manage, but Kubernetes gives you a lot of industrial-strength tools to accomplish
    it.
  prefs: []
  type: TYPE_NORMAL
- en: 'The next chapter will conclude the book. We will look at the future of Kubernetes
    and the road ahead. Spoiler alert: the future is very bright. Kubernetes has established
    itself as the gold standard for cloud-native computing. It is being used across
    the board, and it keeps evolving responsibly. An entire support system has developed
    around Kubernetes, including training, open-source projects, tools, and products.
    The community is amazing, and the momentum is very strong.'
  prefs: []
  type: TYPE_NORMAL
- en: Join us on Discord!
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Read this book alongside other users, cloud experts, authors, and like-minded
    professionals.
  prefs: []
  type: TYPE_NORMAL
- en: Ask questions, provide solutions to other readers, chat with the authors via.
    Ask Me Anything sessions and much more.
  prefs: []
  type: TYPE_NORMAL
- en: Scan the QR code or visit the link to join the community now.
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/cloudanddevops](https://packt.link/cloudanddevops)'
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code844810820358034203.png)'
  prefs: []
  type: TYPE_IMG
